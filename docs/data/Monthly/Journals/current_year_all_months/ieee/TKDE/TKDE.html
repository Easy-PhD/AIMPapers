<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkde">TKDE - 430</h2>
<ul>
<li><details>
<summary>
(2025). Win-win cooperation: Bundling sequence and span models for named entity recognition. <em>TKDE</em>, <em>37</em>(10), 6246-6258. (<a href='https://doi.org/10.1109/TKDE.2024.3423838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Named Entity Recognition (NER), sequence labeling-based and span-based paradigms are quite different. Previous studies have demonstrated the clear complementary advantages of the two paradigms, but few models have tried to incorporate them into a single NER model as far as we know. In our previous work, we proposed a paradigm called Bundling Learning (BL) to explore the above issue, which bundles the two NER paradigms, enabling NER models to jointly tune their parameters by weighted summing each paradigm's training loss. However, three critical issues remain unresolved: When does BL work? Why does BL work? Can BL enhance existing state-of-the-art NER models? To address the first two issues, we design three NER models: a sequence labeling-based model – SeqNER, a span-based NER model – SpanNER, and BL-NER which bundles SeqNER and SpanNER. We draw two conclusions regarding the two issues based on the experimental results on eleven NER datasets. To investigate the third issue, we apply BL to five existing state-of-the-art NER models, including three sequence labeling-based and two span-based models. Experimental results indicate consistent NER performance gains, suggesting a feasible way to construct new state-of-the-art NER systems by applying BL to the current state-of-the-art systems. Moreover, investigation results show that BL reduces both entity boundary and type prediction errors. In addition, we compare two commonly used label tagging methods and three types of span semantic representations.},
  archive      = {J_TKDE},
  author       = {Bin Ji and Huijun Liu and Shasha Li and Jun Ma and Jie Yu},
  doi          = {10.1109/TKDE.2024.3423838},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6246-6258},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Win-win cooperation: Bundling sequence and span models for named entity recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised concept drift detection from deep learning representations in real-time. <em>TKDE</em>, <em>37</em>(10), 6232-6245. (<a href='https://doi.org/10.1109/TKDE.2025.3593123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept drift is the phenomenon in which the underlying data distributions and statistical properties of a target domain change over time, leading to a degradation in model performance. Consequently, production models require continuous drift detection monitoring. Most drift detection methods to date are supervised, relying on ground-truth labels. However, they are inapplicable in many real-world scenarios, as true labels are often unavailable. Although recent efforts have proposed unsupervised drift detectors, many lack the accuracy required for reliable detection or are too computationally intensive for real-time use in high-dimensional, large-scale production environments. Moreover, they often fail to characterize or explain drift effectively. To address these limitations, we propose DriftLens, an unsupervised framework for real-time concept drift detection and characterization. Designed for deep learning classifiers handling unstructured data, DriftLens leverages distribution distances in deep learning representations to enable efficient and accurate detection. Additionally, it characterizes drift by analyzing and explaining its impact on each label. Our evaluation across classifiers and data-types demonstrates that DriftLens (i) outperforms previous methods in detecting drift in 15/17 use cases; (ii) runs at least 5 times faster; (iii) produces drift curves that align closely with actual drift (correlation $\geq \!0.85$); (iv) effectively identifies representative drift samples as explanations.},
  archive      = {J_TKDE},
  author       = {Salvatore Greco and Bartolomeo Vacchetti and Daniele Apiletti and Tania Cerquitelli},
  doi          = {10.1109/TKDE.2025.3593123},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6232-6245},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised concept drift detection from deep learning representations in real-time},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TokenRec: Learning to tokenize ID for LLM-based generative recommendations. <em>TKDE</em>, <em>37</em>(10), 6216-6231. (<a href='https://doi.org/10.1109/TKDE.2025.3599265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in utilizing large language models (LLMs) to advance next-generation Recommender Systems (RecSys), driven by their outstanding language understanding and reasoning capabilities. In this scenario, tokenizing users and items becomes essential for ensuring seamless alignment of LLMs with recommendations. While studies have made progress in representing users and items using textual contents or latent representations, challenges remain in capturing high-order collaborative knowledge into discrete tokens compatible with LLMs and generalizing to unseen users/items. To address these challenges, we propose a novel framework called TokenRec, which introduces an effective ID tokenization strategy and an efficient retrieval paradigm for LLM-based recommendations. Our tokenization strategy involves quantizing the masked user/item representations learned from collaborative filtering into discrete tokens, thus achieving smooth incorporation of high-order collaborative knowledge and generalizable tokenization of users and items for LLM-based RecSys. Meanwhile, our generative retrieval paradigm is designed to efficiently recommend top-K items for users, eliminating the need for the time-consuming auto-regressive decoding and beam search processes used by LLMs, thus significantly reducing inference time. Comprehensive experiments validate the effectiveness of the proposed methods, demonstrating that TokenRec outperforms competitive benchmarks, including both traditional recommender systems and emerging LLM-based recommender systems.},
  archive      = {J_TKDE},
  author       = {Haohao Qu and Wenqi Fan and Zihuai Zhao and Qing Li},
  doi          = {10.1109/TKDE.2025.3599265},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6216-6231},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TokenRec: Learning to tokenize ID for LLM-based generative recommendations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thinking on context: Inductive relation prediction guided by the reasoning ability of large language models. <em>TKDE</em>, <em>37</em>(10), 6202-6215. (<a href='https://doi.org/10.1109/TKDE.2025.3591056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive relation prediction aims to predict missing connections between entities unseen during training. Recent approaches adopt binary (positive or negative) training labels, which indicate whether the query relation exists between the entities, as supervision to teach models recognizing the entity-independent relation patterns in the context (enclosed subgraph or connective path). However, we argue that in this kind of method, the trained models are guided to make relation predictions by remembering whether the query relation and its contextual relational pattern co-occur more frequently in positive or negative samples. This solution could introduce two major limitations: 1) the model struggles with long-tail combinations, i.e., the combination between query relation and the relational pattern rarely occurs during training; 2) when noisy relational patterns, which fail to provide evidence for predicting the query relation, frequently occur with the query relation in positive training samples, the model will be misled into considering the noisy relational patterns as a feature supporting the existence of the query relation. To solve these problems, we propose ToC (Thinking on Context). ToC first utilizes large language models (LLMs) to incorporate a chain of thought as an additional supervisory constraint, guiding the model to make relational predictions based on logical reasoning instead of co-occurrence frequency. Additionally, ToC employs the reasoning capabilities of LLMs to construct context-level negative samples, aiding the model in identifying and disregarding noisy relational patterns. Extensive experiments show that ToC significantly outperforms state-of-the-art methods across three widely used datasets in multiple inductive settings.},
  archive      = {J_TKDE},
  author       = {Xiaoshu Chen and Sihang Zhou and Ke Liang and Jiafei Wu and Xinwang Liu and Dongsheng Li and Kai Lu},
  doi          = {10.1109/TKDE.2025.3591056},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6202-6215},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Thinking on context: Inductive relation prediction guided by the reasoning ability of large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teaching MLPs to master heterogeneous graph-structured knowledge for efficient and accurate inference. <em>TKDE</em>, <em>37</em>(10), 6189-6201. (<a href='https://doi.org/10.1109/TKDE.2025.3589596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) have achieved promising results in various heterogeneous graph learning tasks, owing to their superiority in capturing the intricate relationships and diverse relational semantics inherent in heterogeneous graph structures. However, the neighborhood-fetching latency incurred by structure dependency in HGNNs makes it challenging to deploy for latency-constrained applications that require fast inference. Inspired by recent GNN-to-MLP knowledge distillation frameworks, we introduce HG2M and HG2M+ to combine both HGNN’s superior performance and MLP’s efficient inference. HG2M directly trains student MLPs with node features as input and soft labels from teacher HGNNs as targets, and HG2M+ further distills reliable and heterogeneous semantic knowledge into student MLPs through reliable node distillation and reliable meta-path distillation. Experiments conducted on six heterogeneous graph datasets show that despite lacking structural dependencies, HG2Ms can still achieve competitive or even better performance than HGNNs and significantly outperform vanilla MLPs. Moreover, HG2Ms demonstrate a 379.24× speedup in inference over HGNNs on the large-scale IGB-3M-19 dataset, showcasing their ability for latency-sensitive deployments.},
  archive      = {J_TKDE},
  author       = {Yunhui Liu and Xinyi Gao and Tieke He and Jianhua Zhao and Hongzhi Yin},
  doi          = {10.1109/TKDE.2025.3589596},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6189-6201},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Teaching MLPs to master heterogeneous graph-structured knowledge for efficient and accurate inference},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smoothness-induced efficient incomplete multi-view clustering. <em>TKDE</em>, <em>37</em>(10), 6173-6188. (<a href='https://doi.org/10.1109/TKDE.2025.3591500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient incomplete multi-view clustering has received increasing attention due to its ability to handle large-scale and missing data. Although existing methods have promising performance, 1) they typically generate anchors directly from incomplete and noisy raw data, resulting in uncomprehensive anchor coverage and unreliable results; 2) they typically use only sparse regularization to remove noise and overlook outliers; 3) they ignore the inherent consistency of features in a view. To address these issues, we propose a smoothness-induced efficient incomplete multi-view clustering (SEIC) method. SEIC regards available data as natural anchors selected from complete data, and performs matrix decomposition only on them to obtain reliable small-size representation matrices. View-specific representation matrices are constructed as a tensor to capture consensus and guide matrix decomposition. More significantly, we enforce both smoothness and low-rank coupling on the tensor. Smoothness induces continuous variation of the tensor to further eliminate noise and enhance the relation among features. Benefiting from the noise robustness of SEIC, we design an adaptive noise balance parameter that renders SEIC parameter-free. Furthermore, by constructing a sparse anchor graph on the learned tensor, we propose the spectral clustering version SEIC-SC. Experiments on multiple datasets demonstrate the superior performance and efficiency of SEIC and SEIC-SC.},
  archive      = {J_TKDE},
  author       = {Tianchuan Yang and Haiqiang Chen and Haoyan Yang and Man-Sheng Chen and Xiangcheng Li and Youming Sun and Chang-Dong Wang},
  doi          = {10.1109/TKDE.2025.3591500},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6173-6188},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Smoothness-induced efficient incomplete multi-view clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplified graph contrastive learning model without augmentation. <em>TKDE</em>, <em>37</em>(10), 6159-6172. (<a href='https://doi.org/10.1109/TKDE.2025.3590482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burgeoning graph contrastive learning (GCL) stands out in the graph domain with low annotated costs and high model performance improvements, which is typically composed of three standard configurations: 1) graph data augmentation (GraphDA), 2) multi-branch graph neural network (GNN) encoders and projection heads, 3) and contrastive loss. Unfortunately, the diverse GraphDA may corrupt graph semantics to different extents and meanwhile greatly burdens the time complexity on hyperparameter search. Besides, the multi-branch contrastive framework also demands considerable training consumption on encoding and projecting. In this paper, we propose one simplified GCL model to simultaneously address these problems via the minimal components of a general graph contrastive framework, i.e., a GNN encoder and a projection head. The proposed model treats the node representations generated by the GNN encoder and the projection head as positive pairs while considering all other representations as negatives, which not only liberates the model from the dependency on GraphDA but also streamlines the traditional multi-branch contrastive learning framework into a more efficient single-streamlined one. Through the in-depth theoretical analysis on the objective function, the mystery of why the proposed model works is illustrated. Empirical experiments on multiple public datasets demonstrate that the proposed model still ensures performance to be comparative with current advanced self-supervised GNNs.},
  archive      = {J_TKDE},
  author       = {Yuena Lin and Gengyu Lyu and Haichun Cai and Deng-Bao Wang and Haobo Wang and Zhen Yang},
  doi          = {10.1109/TKDE.2025.3590482},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6159-6172},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Simplified graph contrastive learning model without augmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust cross-platform news event detection via self-supervised modality complementation. <em>TKDE</em>, <em>37</em>(10), 6147-6158. (<a href='https://doi.org/10.1109/TKDE.2025.3594200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal news event detection aims to identify and categorize significant events across media platforms using multimodal data. Previous work was limited to a single platform and assumed complete multimodal data. In this paper, we explore a novel task of cross-platform multimodal news event detection to enhance model generalization for cross-platform scenarios. We propose a Self-Supervised Modality Complementation (SSMC) method to tackle the challenges of incomplete modalities and platform heterogeneity presented in this task. Specifically, a Missing Data Complementation (MDC) module is designed to overcome the limitations caused by incomplete modalities. It employs a separation mechanism that distinguishes between modality-specific and modality-shared features across all modalities, allowing for the augmentation of missing modalities with information extracted from common features. Meanwhile, a Multimodal Self-Learning (MSL) module addresses platform heterogeneity by extracting pseudo labels from the target platform’s multimodal views and incorporating a self-penalization mechanism to reduce reliance on low-confidence labels. Additionally, we collect a comprehensive cross-platform news event detection (CNED) dataset encompassing 37,711 multimodal samples from Twitter, Flickr, and online news media, covering 40 public news events verified by Wikipedia. Extensive experiments on the CNED dataset demonstrate the superior performance of our proposed method.},
  archive      = {J_TKDE},
  author       = {Zehang Lin and Zhenguo Yang and Qing Li},
  doi          = {10.1109/TKDE.2025.3594200},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6147-6158},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust cross-platform news event detection via self-supervised modality complementation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RConE: Rough cone embedding for multi-hop logical query answering on multi-modal knowledge graphs. <em>TKDE</em>, <em>37</em>(10), 6135-6146. (<a href='https://doi.org/10.1109/TKDE.2025.3584054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop query answering over a Knowledge Graph (KG) involves traversing one or more hops from the start node to answer a query. Path-based and logic-based methods are state-of-the-art for multi-hop question answering. The former is used in link prediction tasks. The latter is for answering complex logical queries. The logical multi-hop querying technique embeds the KG and queries in the same embedding space. The existing work incorporates First Order Logic (FOL) operators, such as conjunction ($\wedge$), disjunction ($\vee$), and negation ($\lnot$), in queries. Though current models have most of the building blocks to execute the FOL queries, they cannot use the dense information of multi-modal entities in the case of Multi-Modal Knowledge Graphs (MMKGs). We propose RConE, an embedding method to capture the multi-modal information needed to answer a query. The model first shortlists candidate (multi-modal) entities containing the answer. It then finds the solution (sub-entities) within those entities. Several existing works tackle path-based question-answering in MMKGs. However, to our knowledge, we are the first to introduce logical constructs in querying MMKGs and to answer queries that involve sub-entities of multi-modal entities as the answer. Extensive evaluation of four publicly available MMKGs indicates that RConE outperforms the current state-of-the-art.},
  archive      = {J_TKDE},
  author       = {Mayank Kharbanda and Rajiv Ratn Shah and Raghava Mutharaju},
  doi          = {10.1109/TKDE.2025.3584054},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6135-6146},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RConE: Rough cone embedding for multi-hop logical query answering on multi-modal knowledge graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Querying interval data on steroids. <em>TKDE</em>, <em>37</em>(10), 6120-6134. (<a href='https://doi.org/10.1109/TKDE.2025.3597399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wide range of applications manage interval data with selections and overlap joins being the most fundamental querying operations. Selection queries are typically evaluated using interval indexing. However, the statethe-of-art HINT index and its competitors, are only designed for single query requests while modern systems receive a large number of queries at the same time. In view of this challenge, we study the batch processing of selection queries on HINT. We propose two novel strategies termed level-based and partition-based, which operate in a per-level fashion, i.e., they collect the results for all queries at an index level before moving to the next. The new strategies reduce the cache misses when climbing the index hierarchy, and in particular, partition-based can prevent scanning every index partition more than once. Our experiments on real-world intervals showed that our batch strategies always outperform a baseline which executes queries in a serial fashion, and that partition-based is overall the most efficient one. Motivated by our shared computation techniques for query batches, we also study overlap joins anew across the entire spectrum of different setups, based on the (pre)-existence of interval indexing. For unindexed inputs, we enhance the state-of-the-art optFS join algorithm with effective partitioning proposed for HINT and for indexed inputs, we propose a novel algorithm HINT-join which concurrently scans the input indices, joining partition pairs with optFS. Our tests showed the advantage of HINT-join over indexed nestedloops solutions that employ either B+-trees or probing a single HINT even powered by our partition-based batch processing.},
  archive      = {J_TKDE},
  author       = {Panagiotis Bouros and George Christodoulou and Christian Rauch and Artur Titkov and Nikos Mamoulis},
  doi          = {10.1109/TKDE.2025.3597399},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6120-6134},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Querying interval data on steroids},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise bayes regression: Approaching optimality, using multi-dimensional space partitioning trees. <em>TKDE</em>, <em>37</em>(10), 6107-6119. (<a href='https://doi.org/10.1109/TKDE.2025.3592074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Conditional Expectation Function (CEF) is an optimal estimator in real space. Artificial Neural Networks (ANN), as the current state-of-the-art method, lack interpretability. Estimating CEF offers a path to achieve both accuracy and interpretability. Previous attempts to estimate CEF rely on limiting assumptions such as independence and distributional form or perform the expensive nearest neighbor search. We propose Dynamically Ordered Precise Bayes Regression (DO-PBR), a novel method to estimate CEF in discrete space. We prove DO-PBR approaches optimality with increasing number of samples. DO-PBR dynamically learns importance rankings for the predictors, which are region-specific, allowing the importance of a predictor vary across the space. DO-PBR is fully interpretable and makes no assumptions on independence or the distributional form, while requiring minimal parameter setting. In addition, DO-PBR avoids the costly nearest-neighbor search, by using a hierarchy of binary trees. Our experiments confirm our theoretical claims on approaching optimality and show that DO-PBR achieves substantially higher accuracy compared to ANN, when given the same amount of time. Our experiments show that on average, ANN takes 32 times longer to achieve the same level of accuracy as DO-PBR.},
  archive      = {J_TKDE},
  author       = {Amin Vahedian},
  doi          = {10.1109/TKDE.2025.3592074},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6107-6119},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Precise bayes regression: Approaching optimality, using multi-dimensional space partitioning trees},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online outlier detection in open feature spaces. <em>TKDE</em>, <em>37</em>(10), 6091-6106. (<a href='https://doi.org/10.1109/TKDE.2025.3593895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is essential for data compliance, fraud prevention, and strategic decision-making. Finding outliers relies on study of feature space to find anomalous instances. As the feature dimension increases, it will inevitably complicate the process and hinder the models from finding genuine outliers. In this paper, we investigate an ever-more challenging task, online outlier detection (OOD) problem, where data points to be examined for outlier detection are characterized by two dynamic changes: (1) increasing volume instead of a static set; and (2) evolving feature space instead of a known set. Such instance and feature space dynamics impedes traditional OD techniques reliant on geometric data structure for distinguishing outliers. To aid, we propose a new approach coined Online Outlier Detection in Open Feature Spaces, which circumvents this limitation by learning a latent hypersphere representation, respectively positioning regular and anomalous data points inside and outside its boundary. The crux of our approach tailors a reconstruction loss, allowing each data point to be represented as an addition of its pertinent feature embeddings. Each of these embeddings is updated non-intrusively, championing both efficient and incremental learning of the latent hypersphere. Extensive experiments on twelve benchmark datasets underscore the robustness and superior performance of our method against seven leading counterparts.},
  archive      = {J_TKDE},
  author       = {Heng Lian and Yi He and Di Wu and Zhong Chen and Xingquan Zhu and Xindong Wu},
  doi          = {10.1109/TKDE.2025.3593895},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6091-6106},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Online outlier detection in open feature spaces},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-pass online learning under feature evolution data streams with a fast rate. <em>TKDE</em>, <em>37</em>(10), 6075-6090. (<a href='https://doi.org/10.1109/TKDE.2025.3592685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning under feature evolution data streams has attracted widespread attention in recent years. Existing methods usually assume that the model predicts and learns from all instances in the data stream. However, when the data stream rate is faster than the model update rate, the model can only learn from some instances. Therefore, this assumption may not always hold in practical scenarios. Additionally, existing methods often update based only on the current instance, ignoring the impact of data stream changes, which further limits their application in practical data streams. This paper proposes a novel learning paradigm to solve this problem: Online Learning under Feature Evolution data streams with A Fast Rate, called OLFE-FR. Specifically, OLFE-FR introduces the concept of relative rate to adaptively determine the prediction mode and update node of the model in the data stream. Additionally, OLFE-FR proposes an adaptive learning rate adjustment strategy based on the upper bound of dynamic regret minimization. This strategy enables the model to find a suitable learning rate based on weights change induced by known data stream variations before using the instance update. Theoretical analysis and experimental results show that OLFE-FR can effectively handle feature evolution data streams with a fast rate.},
  archive      = {J_TKDE},
  author       = {Peng Zhang and Hongpeng Yin and Xuanhong Deng and Sheng-Qing Lv},
  doi          = {10.1109/TKDE.2025.3592685},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6075-6090},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {One-pass online learning under feature evolution data streams with a fast rate},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level task-agnostic graph representation learning with isomorphic-consistent variational graph auto-encoders. <em>TKDE</em>, <em>37</em>(10), 6061-6074. (<a href='https://doi.org/10.1109/TKDE.2025.3591732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning is a fundamental research theme and can be generalized to benefit multiple downstream tasks from the node and link levels to the higher graph level. In practice, it is desirable to develop task-agnostic graph representation learning methods that are typically trained in an unsupervised manner. However, existing unsupervised graph models, represented by the variational graph auto-encoders (VGAEs), can only address node- and link-level tasks while manifesting poor generalizability on the more difficult graph-level tasks because they can only keep low-order isomorphic consistency within the subgraphs of one-hop neighborhoods. To overcome the limitations of existing methods, in this paper, we propose the Isomorphic-Consistent VGAE (IsoC-VGAE) for multi-level task-agnostic graph representation learning. We first devise an unsupervised decoding scheme to provide a theoretical guarantee of keeping the high-order isomorphic consistency within the VGAE framework. We then propose the Inverse Graph Neural Network (Inv-GNN) decoder as its intuitive realization, which trains the model via reconstructing the node embeddings and neighborhood distributions learned by the GNN encoder. Extensive experiments on multi-level graph learning tasks verify that our model achieves superior or comparable performance compared to both the state-of-the-art unsupervised methods and representative supervised methods with distinct advantages on the graph-level tasks.},
  archive      = {J_TKDE},
  author       = {Hanxuan Yang and Qingchao Kong and Wenji Mao},
  doi          = {10.1109/TKDE.2025.3591732},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6061-6074},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-level task-agnostic graph representation learning with isomorphic-consistent variational graph auto-encoders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to discriminate while contrasting: Combating false negative pairs with coupled contrastive learning for incomplete multi-view clustering. <em>TKDE</em>, <em>37</em>(10), 6046-6060. (<a href='https://doi.org/10.1109/TKDE.2025.3592126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of incomplete multi-view clustering (IMvC) aims to partition multi-view data with a lack of completeness into different clusters. The incompleteness can be typically categorized into the case of instance-missing and view-unaligned MvC. However, prior methods either consider each of them or struggle to pursue consistent latent representations among views. In this paper, we propose two forms of contrastive learning paradigms to jointly handle both cases for IMvC. Specifically, we design an instance-oriented contrastive (IOC) learning strategy to achieve intra-class consistency. As negative samples within different datasets can exhibit diverse distributions, we formulate a parameterized boundary for IOC learning to flexibly deal with such differing data modes. To preserve inter-view consistency, we further devise category-oriented contrastive (COC) learning such that data from different views can be seamlessly integrated into a combined semantic space. We also recover the missing instances with the learned latent representations in a reconstructing manner for realigning the incomplete multi-view data to facilitate clustering. Our approach unifies the solution to both incomplete cases into one formulation. To demonstrate the effectiveness of our model, we conduct four types of MvC tasks on six benchmark multi-view datasets and compare our method against state-of-the-art IMvC methods. Extensive experiments show that our method achieves state-of-the-art performance, quantitatively and qualitatively.},
  archive      = {J_TKDE},
  author       = {Yu Ding and Katsuya Hotta and Chunzhi Gu and Ao Li and Jun Yu and Chao Zhang},
  doi          = {10.1109/TKDE.2025.3592126},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6046-6060},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning to discriminate while contrasting: Combating false negative pairs with coupled contrastive learning for incomplete multi-view clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent semantics and anchor graph multi-layer learning for multi-view unsupervised feature selection. <em>TKDE</em>, <em>37</em>(10), 6032-6045. (<a href='https://doi.org/10.1109/TKDE.2025.3591515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-view unsupervised feature selection has gained significant interest for its ability to efficiently handle multi-view datasets while offering better interpretability. However, most existing methods face the following challenges: First, the presence of noisy features in the data significantly impacts the process of learning accurate feature importance. Second, the selected features contain redundant information due to ignored redundancy between them. Third, graph structure learning is performed on all samples, resulting in large computational and space overheads, which is not conducive to expansion to large-scale data. To address these challenges, we propose a multi-view unsupervised feature selection method based on latent semantics and anchor graph learning. Specifically, this method designs a feature-weighted orthogonal regression and subspace learning framework to suppress noise interference in the consensus latent semantics discovery and anchor graph construction process, enhance the robustness of multi-view representation learning and reduce the computation of graph construction. Meanwhile, the proposed method employs explicit redundancy mitigation mechanisms that penalize discriminative weight allocation to highly correlated features. Furthermore, the proposed method unifies feature weighting, consensus latent semantics discovery, and adaptive graph learning within a multi-layer learning framework, enabling comprehensive feature importance evaluation through interactive learning between multiple layers. Finally, an efficient iterative algorithm is designed to solve the proposed model. The superiority of the proposed algorithm is demonstrated by comparing it with seven state-of-the-art algorithms on seven public multi-view datasets.},
  archive      = {J_TKDE},
  author       = {Qi Liu and Suyuan Liu and Xinwang Liu and Jianhua Dai},
  doi          = {10.1109/TKDE.2025.3591515},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6032-6045},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Latent semantics and anchor graph multi-layer learning for multi-view unsupervised feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent factor modeling with expert network for multi-behavior recommendation. <em>TKDE</em>, <em>37</em>(10), 6020-6031. (<a href='https://doi.org/10.1109/TKDE.2025.3591503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation methods, which typically focus on modeling a single user behavior (e.g., purchase), often face severe data sparsity issues. Multi-behavior recommendation methods offer a promising solution by leveraging user data from diverse behaviors. However, most existing approaches entangle multiple behavioral factors, learning holistic but imprecise representations that fail to capture specific user intents. To address this issue, we propose a multi-behavior method by modeling latent factors with an expert network (MBLFE). In our approach, we design a gating expert network, where the expert network models all latent factors within the entire recommendation scenario, with each expert specializing in a specific latent factor. The gating network dynamically selects the optimal combination of experts for each user, enabling a more accurate representation of user preferences. To ensure independence among experts and factor consistency of a particular expert, we incorporate self-supervised learning during the training process. Furthermore, we enrich embeddings with multi-behavior data to provide the expert network with more comprehensive collaborative information for factor extraction. Extensive experiments on three real-world datasets demonstrate that our method significantly outperforms state-of-the-art baselines, validating its effectiveness.},
  archive      = {J_TKDE},
  author       = {Mingshi Yan and Zhiyong Cheng and Yahong Han and Meng Wang},
  doi          = {10.1109/TKDE.2025.3591503},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6020-6031},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Latent factor modeling with expert network for multi-behavior recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph-based patent clustering. <em>TKDE</em>, <em>37</em>(10), 6009-6019. (<a href='https://doi.org/10.1109/TKDE.2025.3590406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patent data generally includes information from different perspectives or different types, and its heterogeneous attributes can be greatly beneficial to data clustering analysis. However, the existing patent analysis method always focus on the patent text cues, and such a strategy merely depends on the feature information to capture the data characteristics, failing to multi-type informative patent representation. Therefore, in this paper, to model the underlying structure/relationships of patent data, we employ the knowledge graph to depict the heterogeneous attributes of patent, and propose a novel Knowledge Graph-based Patent Clustering (KGPC) method, where the relationship reconstruction in knowledge graph as well as clustering-oriented representation refinement for patent clustering are jointly considered. With this model, there are three components, i.e., entity representation refinement, relationship reconstruction and self-supervised entity clustering. Given a patent knowledge graph as input, the entity representation refinement can be mutually boosted by the relationship reconstruction and self-supervised clustering objective, thereby leading to a balanced clustering-oriented output. Extensive experiments on several real-world patent knowledge graph datasets validate the effectiveness of KGPC while compared with the state-of-the-art.},
  archive      = {J_TKDE},
  author       = {Pei-Yuan Lai and Man-Sheng Chen and Qing-Yun Dai and Chang-Dong Wang and Min Chen and Mohsen Guizani},
  doi          = {10.1109/TKDE.2025.3590406},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {6009-6019},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Knowledge graph-based patent clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-dependent incomplete multi-label feature selection by fuzzy tolerance relation and fuzzy mutual implication granularity. <em>TKDE</em>, <em>37</em>(10), 5994-6008. (<a href='https://doi.org/10.1109/TKDE.2025.3591461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an effective approach to mitigate the high-dimensional feature problem in multi-label learning. Most existing multi-label feature selection methods either assume that the data is complete, or that either the features or the labels are incomplete. So far, there are few studies on multi-label data with missing features and labels. In many cases, missing features in instances of multi-label data often lead to missing labels, which is ignored by existing studies. We define this type of data as instance-dependent incomplete multi-label data. In this paper, we propose a feature selection method for instance-dependent incomplete multi-label data. Firstly, we use the positive correlations between features to reconstruct the feature space, thereby recovering missing values and enhancing non-missing values. Secondly, we use fuzzy tolerance relation to guide label recovery, and utilize fuzzy mutual implication granularity to impose structural constraint on the projection matrix. Thirdly, we achieve feature selection by eliminating the impact of incomplete instances and imposing sparse regularization on the projection matrix. Finally, we provide a convergent solution for the proposed feature selection framework. Comparative experiments with existing multi-label feature selection methods show that our method can perform effective feature selection on instance-dependent incomplete multi-label data.},
  archive      = {J_TKDE},
  author       = {Jianhua Dai and Wenxiang Chen and Yuhua Qian and Witold Pedrycz},
  doi          = {10.1109/TKDE.2025.3591461},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5994-6008},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Instance-dependent incomplete multi-label feature selection by fuzzy tolerance relation and fuzzy mutual implication granularity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IGES-RCI: Improved greedy equivalence search and recursive causal inference for industrial equipment failure prediction. <em>TKDE</em>, <em>37</em>(10), 5983-5993. (<a href='https://doi.org/10.1109/TKDE.2025.3591827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting equipment failures plays a pivotal role in minimizing maintenance costs and boosting production efficiency within the industrial sector. This paper introduces a novel approach that integrates Causal Inference with predictive modeling to enhance prediction accuracy, tackling key challenges such as noise interference, insufficient causal validation, and missing data. We first validate the causal connections identified by the Greedy Equivalence Search algorithm using conditional mutual information to strengthen the reliability of the causal graph. An information bottleneck strategy is then employed to isolate essential causal features, effectively filtering out irrelevant noise and refining the causal structure. Crucially, in the actual prediction phase, we propose a recursive causal inference-based imputation method to handle missing data, leveraging the causal graph to iteratively infer and fill gaps, thereby improving data completeness and prediction accuracy. Experimental results demonstrate that the proposed method significantly outperforms existing approaches, exhibiting superior accuracy and robustness in managing complex industrial datasets.},
  archive      = {J_TKDE},
  author       = {Xu Zhao and Weibing Wan and Zhijun Fang},
  doi          = {10.1109/TKDE.2025.3591827},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5983-5993},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {IGES-RCI: Improved greedy equivalence search and recursive causal inference for industrial equipment failure prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IBACon: ImBalance-aware contrastive learning for time series forecasting. <em>TKDE</em>, <em>37</em>(10), 5967-5982. (<a href='https://doi.org/10.1109/TKDE.2025.3589693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting (TSF) has gained significant attention as a widely explored research area in diverse applications. Existing methods, which focus on improvements in the most common scenarios, focus little on performance in rare cases. Despite their scarce occurrences in the data, these rare samples are more challenging and easily overlooked by models, significantly contributing to the total loss. In this paper, we propose a novel approach (dubbed iBACon) that overcomes this limitation by employing imbalance-aware contrastive learning and trend-seasonal decomposition architecture, specifically designed to solve TSF. To this end, we first introduce the Input-Output Difference (IOD) metric as a pseudo-label and reveal the data imbalance phenomenon in TSF. This label continuity inherently provides a meaningful distance between targets, implying a similarity between nearby targets in both label and feature spaces. Based on this similarity, the proposed imbalance-aware contrastive loss aims to reshape feature embeddings to facilitate knowledge dissemination among challenging samples and learn specific predictive features. Finally, when combined with our trend-seasonal decomposition network, iBACon significantly improves TSF accuracy. Experiments show that iBACon enhances overall average accuracy and substantially improves the 1-3% most challenging samples.},
  archive      = {J_TKDE},
  author       = {Jing Zhang and Qun Dai and Rui Ye},
  doi          = {10.1109/TKDE.2025.3589693},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5967-5982},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {IBACon: ImBalance-aware contrastive learning for time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling out-of-distribution data: A survey. <em>TKDE</em>, <em>37</em>(10), 5948-5966. (<a href='https://doi.org/10.1109/TKDE.2025.3592614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Machine Learning (ML) and data-driven applications, one of the significant challenge is the change in data distribution between the training and deployment stages, commonly known as distribution shift. This paper outlines different mechanisms for handling two main types of distribution shifts: (i) Covariate shift: where the value of features or covariates change between train and test data, and (ii) Concept/Semantic-shift: where model experiences shift in the concept learned during training due to emergence of novel classes in the test phase. We sum up our contributions in three folds. First, we formalize distribution shifts, recite on how the conventional method fails to handle them adequately and urge for a model that can simultaneously perform better in all types of distribution shifts. Second, we discuss why handling distribution shifts is important and provide an extensive review of the methods and techniques that have been developed to detect, measure, and mitigate the effects of these shifts. Third, we discuss the current state of distribution shift handling mechanisms and propose future research directions in this area. Overall, we provide a retrospective synopsis of the literature in the distribution shift, focusing on OOD data that had been overlooked in the existing surveys.},
  archive      = {J_TKDE},
  author       = {Lakpa Tamang and Mohamed Reda Bouadjenek and Richard Dazeley and Sunil Aryal},
  doi          = {10.1109/TKDE.2025.3592614},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5948-5966},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Handling out-of-distribution data: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GI-graph: A generative invariant graph learning scheme towards out-of-distribution generalization. <em>TKDE</em>, <em>37</em>(10), 5934-5947. (<a href='https://doi.org/10.1109/TKDE.2025.3592640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When distribution shifts occur between testing and training graph data, out-of-distribution (OOD) samples undermine the performance of graph neural networks (GNNs). To improve adaptive OOD generalization of GNNs, this paper introduces a novel generative invariant graph learning framework, named GI-Graph. It consists of four modules: subgraph extractor, generative environment subgraph augmentation, generative invariant subgraph learning, and query feedback module. The subgraph extractor decomposes a graph sample into an environment subgraph and an invariant subgraph and improves extraction accuracy through query feedback. GI-Graph uses a diffusion model to generate diverse environment subgraphs, augmenting the OOD data. By combining diffusion models, contrastive learning, and attribute prediction networks, GI-Graph also generates augmented invariant subgraphs with significant identically distributed features and consistency of labels. Experimental results demonstrate that the controllable environment subgraph and invariant subgraph augmentation effectively improve the OOD generalization capability of GI-Graph, especially in capturing invariant features and maintaining category consistency across environments. Additionally, the contrastive learning-based fine-tuning method enables GI-Graph to quickly adapt to evolving environments. This paper verifies the effectiveness of the generative invariant graph learning scheme in graph OOD generalization.},
  archive      = {J_TKDE},
  author       = {Sanfeng Zhang and Xinyi Liu and Zihao Qi and Xingchen Yan and Wang Yang},
  doi          = {10.1109/TKDE.2025.3592640},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5934-5947},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GI-graph: A generative invariant graph learning scheme towards out-of-distribution generalization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoRecover: Recovery from poisoning attacks for LDP-enabled spatial density aggregation. <em>TKDE</em>, <em>37</em>(10), 5919-5933. (<a href='https://doi.org/10.1109/TKDE.2025.3593289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial density distribution collected and aggregated from users’ trajectory data is vital for location-based services like regional popularity analysis and congestion measurement. However, spatial density aggregation poses privacy concerns since trajectory data usually originate from users. Local differential privacy (LDP) addresses these concerns by allowing users to perturb their data before reporting it. Yet, LDP is vulnerable to poisoning attacks where attackers manipulate data from malicious users. Recent studies attempt to defend against such attacks in LDP-enabled frequency estimation but suffer from inaccurate data recovery due to empirical presets of malicious user proportions and inaccurate malicious data estimation. These issues worsen in spatial density aggregation, as high-dimensional trajectory data help conceal malicious information. In this work, we propose GeoRecover, a method to defend against poisoning attacks in LDP-enabled spatial density aggregation by addressing previous limitations. GeoRecover designs an adaptive model to unify these attacks. Under this model, GeoRecover estimates the proportion of malicious users using statistical differences between genuine and malicious data and learns malicious data statistics through LDP properties. This allows GeoRecover to recover accurate spatial density distribution by subtracting malicious users’ contributions. Evaluations on two real-world datasets show GeoRecover outperforms state-of-the-art methods in recovery accuracy, defense capability, and practical performance.},
  archive      = {J_TKDE},
  author       = {Xinyue Sun and Qingqing Ye and Haibo Hu and Jiawei Duan and Hui He and Weizhe Zhang},
  doi          = {10.1109/TKDE.2025.3593289},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5919-5933},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GeoRecover: Recovery from poisoning attacks for LDP-enabled spatial density aggregation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAN-based hybrid sampling method for transaction fraud detection. <em>TKDE</em>, <em>37</em>(10), 5905-5918. (<a href='https://doi.org/10.1109/TKDE.2025.3589885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital era, effective Transaction Fraud Detection (TFD) is essential to ensuring financial security. The considerable class imbalance, with legitimate transactions vastly outnumbering fraudulent ones, presents a significant challenge for TFD models to accurately identify fraudulent patterns. While existing sample-balancing strategies address class imbalance effectively in many contexts, they often fall short in TFD due to fraudsters’ sophisticated concealment tactics, which lead to pronounced behavioral overlap between fraudulent and legitimate transactions. In this paper, we introduce a novel Generative Adversarial Network-based Hybrid Sampling method (GANHS) to effectively address the class imbalance issue. GANHS employs a dual-discriminator generative adversarial network to generate synthetic samples that accurately reflect the characteristics of fraudulent activity, while an adaptive neighborhood-based undersampling technique refines these samples to minimize overlap with legitimate ones. This hybrid approach not only enhances the model’s ability to learn fraud patterns by generating high-quality samples but also improves its resilience against highly concealed fraudulent activities. Experiments on real-world and public datasets demonstrate that GANHS outperforms its competitive peers, with gains of 0.5%–8.7% in average $F_{1}$-Score and 1.0%–7.0% in G-mean, highlighting its strong potential for improving the reliability and effectiveness of TFD systems in complex, high-risk financial scenarios.},
  archive      = {J_TKDE},
  author       = {Yu Xie and Junkai Shan and Lifei Wei and Jiamin Yao and MengChu Zhou},
  doi          = {10.1109/TKDE.2025.3589885},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5905-5918},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GAN-based hybrid sampling method for transaction fraud detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FocusCores of multilayer graphs. <em>TKDE</em>, <em>37</em>(10), 5890-5904. (<a href='https://doi.org/10.1109/TKDE.2025.3597995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining dense subgraphs on multilayer graphs offers the opportunity for more in-depth discoveries than classical dense subgraph mining on single-layer graphs. However, the existing approaches fail to ensure the denseness of a discovered subgraph on layers of users’ interest and simultaneously gain partial supports on the denseness from other layers. In this paper, we introduce a novel dense subgraph model called FocusCore (FoCore for short) for multilayer graphs, which can pay more attention to the layers focused by users. The FoCore decomposition problem, that is, identifying all nonempty FoCores in a multilayer graph, can be addressed by executing the peeling process with respect to all possible configurations of focus and background layers. Using the nice properties of FoCores, we devise an interleaved peeling algorithm and a vertex-centric algorithm toward efficient FoCore decomposition. We further design a novel cache to minimize the average retrieval time for an arbitrary FoCore without the need for full FoCore decomposition, which significantly improves efficiency in large-scale graph mining tasks. As an application, we propose a FoCore-decomposition-based algorithm to approximate the densest subgraph in a multilayer graph with a provable approximation guarantee. The extensive experiments on real-world datasets verify the effectiveness of the FoCore model and the efficiency of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Run-An Wang and Zhaonian Zou and Dandan Liu and Xudong Liu},
  doi          = {10.1109/TKDE.2025.3597995},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5890-5904},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FocusCores of multilayer graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast density peaks clustering algorithm based on approximate k-nearest neighbors. <em>TKDE</em>, <em>37</em>(10), 5878-5889. (<a href='https://doi.org/10.1109/TKDE.2025.3589794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peaks clustering (DPC) is one of the density-based clustering algorithms and has been widely studied and applied in recent years because of its unique parameter, non-iteration and good robustness. However, it cannot effectively identify the cluster centers, and time and space complexities are too high. To this end, this paper proposes a fast density peaks clustering algorithm based on approximate k-nearest neighbors (FDPAN). Firstly, it uses Balanced K-means based Hierarchical K-means (BKHK) method to partition the data and quickly find the approximate k-nearest neighbors (AKNN), improving the algorithm’s efficiency on large-scale high-dimensional data. Meanwhile, three-way clustering is used to improve the neighbor search of the boundary points of the partition. Then, the local density and relative distance of DPC are recalculated by AKNN. Finally, according to the similar density chain, the connected high-density points are labeled while searching for the cluster center, and the remaining points are assigned to the clusters where their nearest higher-density points are located. Theoretical analysis and experiments on synthetic and real datasets show that FDPAN can obtain higher clustering results and shorten the operation time on large-scale high-dimensional data compared with DPC and its variants.},
  archive      = {J_TKDE},
  author       = {Shifei Ding and Chao Li and Xiao Xu and Lili Guo and Ling Ding and Xindong Wu},
  doi          = {10.1109/TKDE.2025.3589794},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5878-5889},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast density peaks clustering algorithm based on approximate k-nearest neighbors},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact and efficient unlearning for large language model-based recommendation. <em>TKDE</em>, <em>37</em>(10), 5866-5877. (<a href='https://doi.org/10.1109/TKDE.2025.3594687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the trend of enhancing recommender systems with large language models (LLMs), namely, LLMRec. A common way is to fine-tune the LLMs with the instruction data transformed from user behaviors, stimulating the recommendation ability of LLMs. Similar to traditional recommender systems, integrating user data into LLMs raises privacy concerns. Users desire a tool to erase the impacts of their sensitive data from the trained models. To meet this user demand, LLMRec unlearning becomes pivotal to enable the removal of unusable data (e.g., historical behaviors) from established LLMRec models. However, existing methods mostly focus on partition strategies and approximate unlearning. These methods are not well-suited for the unique characteristics of LLMRec due to computational costs or incomplete removal. In this study, we propose the Adapter Partition and Aggregation (APA) framework for exact and efficient LLMRec unlearning while maintaining recommendation performance. APA achieves this by retraining PEFT adapters using data partitioning, constructing adapters for partitioned training data shards, and retraining only the affected adapters. To preserve recommendation performance and avoid significant inference costs, APA incorporates balanced and heterogeneous data partitioning, and parameter-level adapter aggregation with sample-adaptive adapter attention for each testing sample. Extensive experiments demonstrate the effectiveness and efficiency of our method.},
  archive      = {J_TKDE},
  author       = {Zhiyu Hu and Yang Zhang and Minghao Xiao and Wenjie Wang and Fuli Feng and Xiangnan He},
  doi          = {10.1109/TKDE.2025.3594687},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5866-5877},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exact and efficient unlearning for large language model-based recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EGNN: Exploring structure-level neighborhoods in graphs with varying homophily ratios. <em>TKDE</em>, <em>37</em>(10), 5852-5865. (<a href='https://doi.org/10.1109/TKDE.2025.3591771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have garnered significant attention for their competitive performance on graph-structured data. However, many existing methods are commonly constrained by the homophily assumption, making them overly reliant on the uniform neighbor propagation, which limits their ability to generalize to heterophilous graphs. Although some approaches extend aggregation to multi-hop neighbors, adapting neighborhood sizes on a per-node basis remains a significant challenge. In view of this, we propose an Evolutionary Graph Neural Network (EGNN) with adaptive structure-level aggregation and label smoothing, offering a novel solution to the aforementioned drawback. The core innovation of EGNN lies in assigning each node a personalized neighborhood structure utilizing behavior-level crossover and mutation. Specifically, we first adaptively search for the optimal structure-level neighborhoods for nodes within the solution space, leveraging the exploratory capabilities of evolutionary computation. This approach enhances the exchange of information between the target node and surrounding nodes, achieving a smooth vector representation. Subsequently, we adopt the optimal structure obtained through evolutionary search to perform label smoothing, further boosting the robustness of the framework. We conduct experiments on nine real-world networks with different homophily ratios, where outstanding performance demonstrates that the ability of EGNN can match or surpass SOTA baselines.},
  archive      = {J_TKDE},
  author       = {Songwei Zhao and Bo Yu and Sinuo Zhang and Zhejian Yang and Jifeng Hu and Philip S. Yu and Hechang Chen},
  doi          = {10.1109/TKDE.2025.3591771},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5852-5865},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {EGNN: Exploring structure-level neighborhoods in graphs with varying homophily ratios},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVCAE: Semi-supervised dual variational cascade autoencoders for information popularity prediction. <em>TKDE</em>, <em>37</em>(10), 5838-5851. (<a href='https://doi.org/10.1109/TKDE.2025.3591395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting information popularity in social networks has become a central focus of network analysis. While recent advancements have been made, most existing approaches rely solely on the final cascade size as the primary supervision signal for model optimization. This narrow focus limits the model generalization ability, particularly when faced with highly heterogeneous cascades. Additionally, in real-world scenarios, obtaining detailed social relationships is challenging, complicating effective structural feature learning. To address these issues, this paper proposes a semi-supervised model called Dual Variational Cascade AutoEncoders (DVCAE), which leverages parallel structural and temporal variational autoencoders for enhanced feature learning and popularity prediction. The model first aggregates multiple cascades into a global interaction graph, enabling structural information sharing across cascades. Then, it applies sparse matrix factorization-based graph embedding and graph filtering techniques on global and local cascade graphs respectively, generating initial node embeddings that are insensitive to topological perturbations. After that, two parallel variational autoencoders are designed to generate hidden representations for structural and temporal features respectively, with two self-supervised reconstruction losses integrated into the prediction loss to enrich supervision signals. Extensive experiments conducted on three real-world datasets demonstrate that DVCAE outperforms state-of-the-art models in terms of prediction accuracy.},
  archive      = {J_TKDE},
  author       = {Jiaxing Shang and Xueqi Jia and Xiaoquan Li and Fei Hao and Ruiyuan Li and Geyong Min},
  doi          = {10.1109/TKDE.2025.3591395},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5838-5851},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DVCAE: Semi-supervised dual variational cascade autoencoders for information popularity prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can uncertainty quantification improve learned index benefit estimation?. <em>TKDE</em>, <em>37</em>(10), 5823-5837. (<a href='https://doi.org/10.1109/TKDE.2025.3591237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Index tuning is crucial for optimizing database performance by selecting optimal indexes based on workload. The key to this process lies in an accurate and efficient benefit estimator. Traditional methods relying on what-if tools often suffer from inefficiency and inaccuracy. In contrast, learning-based models provide a promising alternative but face challenges such as instability, lack of interpretability, and complex management. To overcome these limitations, we adopt a novel approach: quantifying the uncertainty in learning-based models’ results, thereby combining the strengths of both traditional and learning-based methods for reliable index tuning. We propose Beauty, the first uncertainty-aware framework that enhances learning-based models with uncertainty quantification and uses what-if tools as a complementary mechanism to improve reliability and reduce management complexity. Specifically, we introduce a novel method that combines AutoEncoder and Monte Carlo Dropout to jointly quantify uncertainty, tailored to the characteristics of benefit estimation tasks. In experiments involving sixteen models, our approach outperformed existing uncertainty quantification methods in the majority of cases. We also conducted index tuning tests on six datasets. By applying the Beauty framework, we eliminated worst-case scenarios and more than tripled the occurrence of best-case scenarios.},
  archive      = {J_TKDE},
  author       = {Tao Yu and Zhaonian Zou and Hao Xiong},
  doi          = {10.1109/TKDE.2025.3591237},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5823-5837},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Can uncertainty quantification improve learned index benefit estimation?},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). B2BGAN: A backbone-to-branches GAN-based oversampling approach for class-imbalanced tabular data. <em>TKDE</em>, <em>37</em>(10), 5808-5822. (<a href='https://doi.org/10.1109/TKDE.2025.3593637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabular data is prevalent in many fields. In practice, tabular data classification may encounter severe challenges due to class imbalance, i.e., some majority classes overwhelm minority ones. Such imbalance could lead to biased prediction tendency of trained classifiers towards majority classes. Oversampling minority classes is an essential solution due to its generality and independence of downstream tasks. Recent years have witnessed the advantages of generative adversarial networks (GANs) in synthetic data generation, favored for their ability to generate quasi-realistic samples. However, challenges arise when the size of minority classes is too small to provide sufficient information for learning real data distributions. Furthermore, the generated minority-class samples could exacerbate the class overlap problem, i.e., some generated samples unexpectedly overlap with partial majority-class samples. To address these challenges, this paper presents B2BGAN, a novel GAN-based approach for oversampling imbalanced tabular data. To capture the real data distribution in a fine-grained manner, we propose a novel backbone-to-branches neural network for the generator to fit the majority and minority classes simultaneously. The backbone network fits the whole distribution of the entire data, while each branch network grasps the distinctive characteristics of individual classes. To alleviate the class overlap problem of generated samples, we develop a prototype-guided loss function to ensure that generated samples are closer to the corresponding class prototypes. We evaluate the effectiveness of B2BGAN on six real-world datasets using six metrics. Experimental results demonstrate that our method outperforms state-of-the-art models by 5.38% in AUC and 10.19% in AP.},
  archive      = {J_TKDE},
  author       = {Xiaoguang Wang and Chenxu Wang and Mengqin Wang and Jun Liu and Xiaohong Guan},
  doi          = {10.1109/TKDE.2025.3593637},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5808-5822},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {B2BGAN: A backbone-to-branches GAN-based oversampling approach for class-imbalanced tabular data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-encoding neural tucker factorization. <em>TKDE</em>, <em>37</em>(10), 5795-5807. (<a href='https://doi.org/10.1109/TKDE.2025.3590198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank latent factorization of tensors is a powerful method for analyzing high-dimensional and incomplete (HDI) data derived from cyber-physical systems, particularly when computational resources are limited. However, traditional tensor factorization models are inherently linear and struggle to capture the complex nonlinear spatiotemporal dependencies embedded in the data. This paper introduces a novel latent factorization model, namely Auto-encoding Neural Tucker Factorization (ANTucF) for accurate spatiotemporal representation learning on the HDI tensor. It constructs a low-rank Tucker factorization-based neural network to capture a potential latent manifold in space and time, built upon three core ideas: a) applying density-oriented modeling principles with neural networks to facilitate latent feature learning via positional and temporal encoding of mode indices; b) constructing a Tucker interaction tensor to represent all possible spatiotemporal interactions among distinct spatial and temporal modes; and c) enhancing the uniqueness of the core tensor in Tucker factorization by incorporating nonlinear spatiotemporal representation learning via auto-encoding latent interaction learning. The ANTucF model outperforms several state-of-the-art LFT models in estimating missing observations on real-world datasets. Additionally, visualizations demonstrate its ability to capture finer spatiotemporal dynamics by nonlinearly exploiting an optimal Tucker core tensor using a data-driven approach.},
  archive      = {J_TKDE},
  author       = {Peng Tang and Xin Luo and Jim Woodcock},
  doi          = {10.1109/TKDE.2025.3590198},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5795-5807},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Auto-encoding neural tucker factorization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AuCoGNN: Enhancing graph fairness learning under distribution shifts with automated graph generation. <em>TKDE</em>, <em>37</em>(10), 5781-5794. (<a href='https://doi.org/10.1109/TKDE.2025.3586276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown strong performance on graph-structured data but may inherit bias from training data, leading to discriminatory predictions based on sensitive attributes like gender and race. Existing fairness methods assume that training and testing data share the same distribution, but how fairness is affected under distribution shifts remains largely unexplored. To address this, we first identify theoretical factors that cause bias in graphs and explore how fairness is influenced by distribution shifts, particularly focusing on representation distances between groups in training and testing graphs. Based on this, we propose FatraGNN, which uses a graph generator to create biased graphs from different distributions and an alignment module to reduce representation distances for specific groups. This improves fairness and classification performance on unseen graphs. However, FatraGNN has limitations in generating realistic graphs and addressing group differentiation. To overcome these, we introduce AuCoGNN, which includes an automated graph generation module and a contrastive alignment mechanism. This ensures better fairness by maximizing the representation distance between the same certain groups while minimizing the representation distance between different groups. Experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of both models in improving fairness and accuracy.},
  archive      = {J_TKDE},
  author       = {Xiao Wang and Yibo Li and Yujie Xing and Shaohua Fan and Chuan Shi},
  doi          = {10.1109/TKDE.2025.3586276},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5781-5794},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AuCoGNN: Enhancing graph fairness learning under distribution shifts with automated graph generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing and enhancing LDP perturbation mechanisms in federated learning. <em>TKDE</em>, <em>37</em>(10), 5767-5780. (<a href='https://doi.org/10.1109/TKDE.2025.3580796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, federated learning (FL) has become a prevalent algorithm to harvest data while preserving privacy. However, private information can still be compromised by local parameters during transmissions between local parties and the central server. To address this problem, local differential privacy (LDP) has been adopted. Known as federated LDP-SGD, each local device only sends perturbed parameters to the central server. However, due to the low model efficiency caused by overwhelming LDP noise, only a relaxed LDP privacy scheme, namely Gaussian mechanism, is explored in the federated LDP-SGD literature. The objective of this paper is to enable other LDP mechanisms (e.g., Laplace, Piecewise, Square Wave and Gaussian) in federated learning by enhancing their model efficiency. We first propose an analytical framework that generalizes federated LDP-SGD and derives its model efficiency. Serving as a benchmark, this framework can compare performances of different LDP mechanisms in federated learning. Based on this framework, we identify a new perspective to generally optimize federated LDP-SGD, namely, the vectorized perturbation strategy LDPVec. By only perturbing the direction of a gradient, LDPVec better preserves the descending direction of the gradient, which consequently leads to comprehensive efficiency improvements in terms of various LDP mechanisms.},
  archive      = {J_TKDE},
  author       = {Jiawei Duan and Qingqing Ye and Haibo Hu and Xinyue Sun},
  doi          = {10.1109/TKDE.2025.3580796},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5767-5780},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Analyzing and enhancing LDP perturbation mechanisms in federated learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive magnetic-graph clustering. <em>TKDE</em>, <em>37</em>(10), 5755-5766. (<a href='https://doi.org/10.1109/TKDE.2025.3594622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation provides a more effective method for describing the underlying data relationships. Nonetheless, the vast majority of data consists solely of feature information without a corresponding graph structure, rendering graph representation techniques ineffective. Much of the existing research on graph data has concentrated on how to effectively characterize graph nodes, with little focus on how to adaptively construct internal structures and potential connections between the sample pairs. On the other hand, the existing graph construction techniques generate linear inter-instance affinity distributions based on a probabilistic perspective, which might not give a true picture of the relationships. To overcome the above problems, motivated by the fact that sample and inter-sample affinities can be viewed as the source and strength of the magnetic field, respectively, a novel tangent-based affinity measurement algorithm that utilizes a parameter to dynamically adjust the sparsity of the magnetic field is derived. In addition, Adaptive Magnetic-Graph Clustering (AMGC) is designed for graph representation and clustering. AMGC ensures instance-level and cluster-level consistency using a novel dual decoder, where the reconstructed graph retains local affinity and global topology, and contrastive learning defines new sample pairs based on positive-incentive noise, making the learned embedding more discriminative. Eventually, we perform empirical experiments to demonstrate the superiority of the model.},
  archive      = {J_TKDE},
  author       = {Rui Zhang and Yuelong Cheng and Xiang Shi and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3594622},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5755-5766},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive magnetic-graph clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of text-to-SQL in the era of LLMs: Where are we, and where are we going?. <em>TKDE</em>, <em>37</em>(10), 5735-5754. (<a href='https://doi.org/10.1109/TKDE.2025.3592032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translating users’ natural language queries (NL) into SQL queries (i.e., Text-to-SQL, a.k.a. NL2SQL) can significantly reduce barriers to accessing relational databases and support various commercial applications. The performance of Text-to-SQL has been greatly enhanced with the emergence of Large Language Models (LLMs). In this survey, we provide a comprehensive review of Text-to-SQL techniques powered by LLMs, covering its entire lifecycle from the following four aspects: (1) Model: Text-to-SQL translation techniques that tackle not only NL ambiguity and under-specification, but also properly map NL with database schema and instances; (2) Data: From the collection of training data, data synthesis due to training data scarcity, to Text-to-SQL benchmarks; (3) Evaluation: Evaluating Text-to-SQL methods from multiple angles using different metrics and granularities; and (4) Error Analysis: analyzing Text-to-SQL errors to find the root cause and guiding Text-to-SQL models to evolve. Moreover, we offer a rule of thumb for developing Text-to-SQL solutions. Finally, we discuss the research challenges and open problems of Text-to-SQL in the LLMs era.},
  archive      = {J_TKDE},
  author       = {Xinyu Liu and Shuyu Shen and Boyan Li and Peixian Ma and Runzhi Jiang and Yuxin Zhang and Ju Fan and Guoliang Li and Nan Tang and Yuyu Luo},
  doi          = {10.1109/TKDE.2025.3592032},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5735-5754},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of text-to-SQL in the era of LLMs: Where are we, and where are we going?},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight learned cardinality estimation model. <em>TKDE</em>, <em>37</em>(10), 5719-5734. (<a href='https://doi.org/10.1109/TKDE.2025.3591025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardinality estimation is a fundamental task in database management systems, aiming to predict query results accurately without executing the queries. However, existing techniques either achieve low estimation accuracy or take high inference latency. Simultaneously achieving high speed and accuracy becomes critical for the cardinality estimation problem. In this paper, we propose a novel data-driven approach called CoDe (Covering with Decompositions) to address this problem. CoDe employs the concept of covering design, which divides the table into multiple smaller, overlapping segments. For each segment, CoDe utilizes tensor decomposition to accurately model its data distribution. Moreover, CoDe introduces innovative algorithms to select the best-fitting distributions for each query, combining them to estimate the final result. By employing multiple models to approximate distributions, CoDe excels in effectively modeling discrete distributions and ensuring computational efficiency. Notably, experimental results show that our method represents a significant advancement in cardinality estimation, achieving state-of-the-art levels of both estimation accuracy and inference efficiency. Across various datasets, CoDe achieves absolute accuracy in estimating more than half of the queries.},
  archive      = {J_TKDE},
  author       = {Yaoyu Zhu and Jintao Zhang and Guoliang Li and Jianhua Feng},
  doi          = {10.1109/TKDE.2025.3591025},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  number       = {10},
  pages        = {5719-5734},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A lightweight learned cardinality estimation model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying lane-level traffic prediction from a graph structural perspective: Benchmark and baseline. <em>TKDE</em>, <em>37</em>(9), 5699-5718. (<a href='https://doi.org/10.1109/TKDE.2025.3580465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction has long been a focal and pivotal area in research, witnessing both significant strides from city-level to road-level predictions in recent years. With the advancement of Vehicle-to-Everything (V2X) technologies, autonomous driving, and large-scale models in the traffic domain, lane-level traffic prediction has emerged as an indispensable direction. However, further progress in this field is hindered by the absence of comprehensive and unified evaluation standards, coupled with limited public availability of data and code. In this paper, we present the first systematic classification framework for lane-level traffic prediction, offering a structured taxonomy and analysis of existing methods. We construct three representative datasets from two real-world road networks, covering both regular and irregular lane configurations, and make them publicly available to support future research. We further establishes a unified spatial topology structure and prediction task formulation, and proposes a simple yet effective baseline model, GraphMLP, based on graph structure and MLP networks. This unified framework enables consistent evaluation across datasets and modeling paradigms. We also reproduce previously unavailable code from existing studies and conduct extensive experiments to assess a range of models in terms of accuracy, efficiency, and applicability, providing the first benchmark that jointly considers predictive performance and training cost for lane-level traffic scenarios.},
  archive      = {J_TKDE},
  author       = {Shuhao Li and Yue Cui and Jingyi Xu and Libin Li and Lingkai Meng and Weidong Yang and Fan Zhang and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2025.3580465},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5699-5718},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unifying lane-level traffic prediction from a graph structural perspective: Benchmark and baseline},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust recommendation: A review and an adversarial robustness evaluation library. <em>TKDE</em>, <em>37</em>(9), 5679-5698. (<a href='https://doi.org/10.1109/TKDE.2025.3581553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, recommender system has achieved significant success. However, due to the openness of recommender systems, they remain vulnerable to malicious attacks. Additionally, natural noise in training data and issues such as data sparsity can also degrade the performance of recommender systems. Therefore, enhancing the robustness of recommender systems has become an increasingly important research topic. In this survey, we provide a comprehensive overview of the robustness of recommender systems. Based on our investigation, we categorize the robustness of recommender systems into adversarial robustness and non-adversarial robustness. In the adversarial robustness, we introduce the fundamental principles and classical methods of recommender system adversarial attacks and defenses. In the non-adversarial robustness, we analyze non-adversarial robustness from the perspectives of data sparsity, natural noise, and data imbalance. Additionally, we summarize commonly used datasets and evaluation metrics for evaluating the robustness of recommender systems. Finally, we also discuss the current challenges in the field of recommender system robustness and potential future research directions. Additionally, to facilitate fair and efficient evaluation of attack and defense methods in adversarial robustness, we propose an adversarial robustness evaluation library–ShillingREC, and we conduct evaluations of basic attack models and recommendation models.},
  archive      = {J_TKDE},
  author       = {Lei Cheng and Xiaowen Huang and Jitao Sang and Jian Yu},
  doi          = {10.1109/TKDE.2025.3581553},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5679-5698},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards robust recommendation: A review and an adversarial robustness evaluation library},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological information utilization in label enhancement and label distribution learning based on optimal transport theory. <em>TKDE</em>, <em>37</em>(9), 5666-5678. (<a href='https://doi.org/10.1109/TKDE.2025.3589681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) offers a promising solution to label ambiguity by employing Label Distributions (LDs) instead of traditional logical labels. However, acquiring LDs for real-world data is both expensive and challenging. To address this issue, Label Enhancement (LE) techniques have been proposed to derive LDs from readily available logical labels. While much of the prior work has focused on enhancing LE for better recovery performance, the ultimate objective remains improving LDL’s overall effectiveness. In this paper, we introduce a novel LE method, Topological Label Enhancement via Optimal Transport (TLEOT), which integrates Optimal Transport (OT) theory with topological space analysis. This method goes beyond improving LE, targeting the enhancement of LDL performance by aligning the feature and label distributions within a unified topological framework. Additionally, we present two innovative topological techniques designed to further improve LDL. Extensive experimental evaluations on real-world datasets demonstrate that TLEOT consistently outperforms nine state-of-the-art methods in predictive tasks. Furthermore, the proposed topological techniques significantly enhance LDL’s performance, validating their practical utility in real-world applications.},
  archive      = {J_TKDE},
  author       = {Ziyuan Gu and Qi Hong and Zhen Zhou and Xin Geng and Zhiyuan Liu and Mo Jia},
  doi          = {10.1109/TKDE.2025.3589681},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5666-5678},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Topological information utilization in label enhancement and label distribution learning based on optimal transport theory},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TimeRAF: Retrieval-augmented foundation model for zero-shot time series forecasting. <em>TKDE</em>, <em>37</em>(9), 5654-5665. (<a href='https://doi.org/10.1109/TKDE.2025.3579137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays a crucial role across numerous domains, driving rapid development in the field. With the advent of large models, time series foundation models (TSFMs) have exhibited great generalization capabilities, such as zero-shot learning, through large-scale pre-training. Meanwhile, Retrieval-Augmented Generation (RAG) methods are widely employed to enhance the performance of foundation models on unseen data across various domains, including Large Language Models (LLMs). To explore the integration of TSFMs with retrieval-augmented methods, we introduce TimeRAF, a Retrieval-Augmented Foundation model for zero shot time series Forecasting. A learnable retriever is employed and trained in an end-to-end fashion to extract useful information from a curated time series knowledge base. Additionally, we propose an approach called Channel Prompting for knowledge integration. Augmented by the retrieved knowledge, our TimeRAF demonstrates significant improvement across various domain and datasets. Furthermore, TimeRAF can leverage specialized knowledge bases to meet diverse application requirements. Extensive ablation studies and visualizations are provided to validate the effectiveness of our approach.},
  archive      = {J_TKDE},
  author       = {Huanyu Zhang and Chang Xu and Yi-Fan Zhang and Zhang Zhang and Liang Wang and Jiang Bian},
  doi          = {10.1109/TKDE.2025.3579137},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5654-5665},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TimeRAF: Retrieval-augmented foundation model for zero-shot time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural clustering of multi-layer graphs. <em>TKDE</em>, <em>37</em>(9), 5639-5653. (<a href='https://doi.org/10.1109/TKDE.2025.3579684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-layer graphs have emerged as a new representation of multi-faceted relationships between entities in the real world. Community detection on multi-layer graphs has been investigated to gain deeper insights into the modular structures of real-world graphs. As an effective and efficient approach to community detection, structural clustering has been investigated on single-layer graphs. However, it has been overlooked in the study of community detection on multi-layer graphs. In this paper, we give a formulation of structural clustering on multi-layer graphs for the first time. Two polynomial-time algorithms are proposed to solve the problem. Furthermore, two indexes, namely the core index and the interval index, with respective preferences to time efficiency and space efficiency, are designed to improve the efficiency of the algorithms. The experiments demonstrate the effectiveness of structural clustering in improving the quality of community detection results on multi-layer graphs. The experiments also verify the improvement in running time due to the use of the proposed indexes.},
  archive      = {J_TKDE},
  author       = {Xudong Liu and Zhaonian Zou and Run-An Wang and Dandan Liu},
  doi          = {10.1109/TKDE.2025.3579684},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5639-5653},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Structural clustering of multi-layer graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability of machine learning predictive features under limited data. <em>TKDE</em>, <em>37</em>(9), 5627-5638. (<a href='https://doi.org/10.1109/TKDE.2025.3580671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a world where Machine Learning (ML) is increasingly used to make predictions about critical events, such as health outcomes, it is crucial to ensure decision-makers have access to explainable, consistent, and relevant predictive features. ML prediction relies on perfect data with similar distributions for testing and validation. These results are compared with those of humans, who use more noisy and limited data. Human predictions overcome those limitations by learning from abstractions. This paper addresses these issues by conducting experiments comparing traditional machine learning methods and a previously proposed method that uses data abstractions to learn predictive feature significance. The results indicate that the previously proposed descriptive ML approach maintains higher classification accuracy and ensures the stability of feature selection as data incompleteness increases, becoming valuable under limited data scenarios. It demonstrates the possibility of developing ML capable of automatic decision-making.},
  archive      = {J_TKDE},
  author       = {Karol Capała and Paulina Tworek and Jose Sousa},
  doi          = {10.1109/TKDE.2025.3580671},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5627-5638},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Stability of machine learning predictive features under limited data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMLE: Semi-supervised multi-label learning with label enhancement. <em>TKDE</em>, <em>37</em>(9), 5613-5626. (<a href='https://doi.org/10.1109/TKDE.2025.3579536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised multi-label learning (SSMLL) involves learning a multi-label classifier from a small set of labeled data and a large set of unlabeled data. Label enhancement (LE), accounting for the relative importance of labels, has been effective in improving the performance of supervised multi-label learning models. Nevertheless, generating a robust SSMLL model with LE based on incomplete label information remains challenging. In this paper, we pioneer the idea of applying LE to SSMLL. First, we design a kNN aggregation-based method, aiming to assign pseudo-labels to unlabeled data and perform the LE process by aggregating label information from neighboring instances. Leveraging the topological structure of the feature space is an effective LE approach for training. However, LE, decoupled from the training process, lacks the dynamic feedback of the training model. To improve this, we incorporate a label propagation mechanism that iteratively optimizes the LE process with the guidance of the available label information. Moreover, we consider local label correlations according to local linear embedding to further enhance the generalization ability of the learning model. Extensive experiments demonstrate that the proposed approach can effectively recover latent label information, resulting in significant performance improvement in SSMLL.},
  archive      = {J_TKDE},
  author       = {Qianzhi Ye and Jia Zhang and Hanrui Wu and Tianlong Gu and C. L. Philip Chen and Jinyi Long},
  doi          = {10.1109/TKDE.2025.3579536},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5613-5626},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SMLE: Semi-supervised multi-label learning with label enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampling enhanced contrastive multi-view remote sensing data clustering with long-short range information mining. <em>TKDE</em>, <em>37</em>(9), 5598-5612. (<a href='https://doi.org/10.1109/TKDE.2025.3580139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) for remote sensing data has demonstrated significant potential in Earth observation, given its ability to aggregate multi-source information without relying on labels. Despite achieving compelling results through the combination of deep encoders and contrastive learning, existing algorithms still face two limitations: inadequate exploration of diverse spatial relationships and inability to guide the selection of sample pairs leads to blind sampling, both of which lead to suboptimal clustering performance. To tackle these challenges, we propose a sampling enhanced contrastive multi-view clustering method for remote sensing data, namely SEC-LSRM. The proposed method incorporates long- and short-range information mining to enhance clustering performance. By aggregating short-range information extracted through autoencoders and long-range information obtained via graph autoencoders, our method improves the sampling quality of positive and negative sample pairs. To render the extracted features more compact, a multi-view correlation reduction strategy is devised to filter out irrelevant information. With the extracted comprehensive features, an adaptive sampling strategy is designed to obtain high-quality positive and negative samples. Subsequently, we select positive and negative sample pairs based on these affinity matrices with idempotence and block diagonal constraints. Moreover, we integrate the optimization of these sample pairs and contrastive learning within the same framework to achieve iterative updates of both. Experiments conducted on multiple multi-view remote sensing datasets illustrate that our proposed SEC-LSRM method achieves excellent and reliable clustering performance.},
  archive      = {J_TKDE},
  author       = {Renxiang Guan and Tianrui Liu and Wenxuan Tu and Chang Tang and Wenhan Luo and Xinwang Liu},
  doi          = {10.1109/TKDE.2025.3580139},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5598-5612},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Sampling enhanced contrastive multi-view remote sensing data clustering with long-short range information mining},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust fuzzy local K-plane clustering with mixture distance of hinge loss and $L_{1}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math> norm. <em>TKDE</em>, <em>37</em>(9), 5584-5597. (<a href='https://doi.org/10.1109/TKDE.2025.3582849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-plane clustering (KPC), hyperplane clustering, and mixture regression all essentially fall within the same class of problems. This problem can be conceptualized as clustering in relatively high-dimensional K subspaces or K linear manifolds. Traditional KPC or fuzzy KPC models demonstrate a pronounced susceptibility to outliers, as they presuppose that the projection distance between data points and the plane normal vector adheres to the $L_{2}$ distance. Meanwhile, the assumption of infinitely extending clusters adversely affects clustering performance. To solve these problems, this paper proposed a new robust fuzzy local k-plane clustering (RFLkPC) method that combines the mixture distance of hinge loss and $L_{1}$ norm. The RFLkPC model assumes that each plane cluster is bounded to a finite area, which can flexibly and robustly handle plane clustering tasks with outliers or not. The corresponding model and optimization algorithms of RFLkPC were provided. Compared to other related models on this topic, a large number of experiments verify the efficiency of RFLkPC on simulated data and real data.},
  archive      = {J_TKDE},
  author       = {Junjun Huang and Xiliang Lu and Xuelin Xie and Jerry Zhijian Yang},
  doi          = {10.1109/TKDE.2025.3582849},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5584-5597},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust fuzzy local K-plane clustering with mixture distance of hinge loss and $L_{1}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math> norm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provable higher-order graph clustering: The power of peeling-based approaches. <em>TKDE</em>, <em>37</em>(9), 5568-5583. (<a href='https://doi.org/10.1109/TKDE.2025.3579811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Higher-order graph clustering partitions graphs use frequently occurring subgraphs instead of edges, proving effective in community detection and knowledge discovery. Motif conductance, known for its strong interpretability, is a leading model. However, existing motif conductance algorithms are hindered by a two-stage reweighting framework that requires enumerating motif instances to generate an edge-weighted graph for partitioning. This framework has two major drawbacks: (1) It provides only a quadratic bound for three-vertex motifs, with no provable approximation guarantees for other motifs. (2) Enumerating motif instances is computationally prohibitive for large motifs or dense graphs due to combinatorial explosions. Besides, costly spectral clustering or local graph diffusion on the edge-weighted graph limits their scalability. In this paper, we propose a novel peeling-based clustering framework, PSMC, offering a motif-independent approximation ratio for any motif. Specifically, PSMC first defines a new locally computable vertex metric Motif Resident based on the given motif. Then, it iteratively deletes vertices with the smallest motif resident using efficient dynamic update techniques, outputting a locally optimal result with approximation guarantees. Besides, we introduce several powerful optimization techniques to further reduce computational costs. Empirical results on real-world and synthetic datasets showcase our proposed solutions’ superiority over ten competitors.},
  archive      = {J_TKDE},
  author       = {Longlong Lin and Zeli Wang and Rong-Hua Li and Qiyu Liu and Hongchao Qin and Jin Zhao},
  doi          = {10.1109/TKDE.2025.3579811},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5568-5583},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Provable higher-order graph clustering: The power of peeling-based approaches},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized news recommendation towards the era of LLMs: Review and prospect. <em>TKDE</em>, <em>37</em>(9), 5551-5567. (<a href='https://doi.org/10.1109/TKDE.2025.3581806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of online news services, personalized news recommendation (PNR) has played an indispensable role in meeting users’ needs and mitigating information overload, with the aim of providing news articles that cater to user preferences. Despite significant progress made in the field of PNR over the past few decades, their performances are still hindered by some limitations, such as insufficient news modeling, difficulties in effectively modeling diverse user interests, and ignorance of fine-grained matching signals. It is fortunate that the emergence of large language models (LLMs) provides a promising insight into empowering the capabilities of news recommendation. Known for their impressive capabilities of natural language understanding and generation, LLMs have achieved disruptive achievements in various natural language processing (NLP) tasks, which motivates us to integrate LLMs into news recommendation and benefits from them to make up existing deficiencies. In this paper, we conduct a comprehensive review of current efforts made towards utilizing LLMs for PNR, with a focus on three core modules involved in the news recommendation process, i.e., news modeling, user modeling, and accurate matching. We systematically discuss and analyze relevant works under each focus. In addition, we point out several potential research directions to provide more inspiration for future investigation in this thriving field.},
  archive      = {J_TKDE},
  author       = {Jie Li and Zeyi Liu and Linmei Hu and Yunbo Rao and Bo Liu and Bo Fang and Liqiang Nie},
  doi          = {10.1109/TKDE.2025.3581806},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5551-5567},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized news recommendation towards the era of LLMs: Review and prospect},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-adaptive border peeling clustering algorithm. <em>TKDE</em>, <em>37</em>(9), 5538-5550. (<a href='https://doi.org/10.1109/TKDE.2025.3579367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most clustering algorithms require setting one or more parameters, which rely on prior knowledge or are constantly adjusted based on external indicators. To address the issues of requiring external index guidance, blindness, and time-consuming parameter setting for clustering algorithms on complex data, we propose a novel Parameter-Adaptive Border Peeling clustering algorithm (PABP). The PABP algorithm initially employs the maximum number of neighbors identified through natural neighbor search to automatically ascertain the number of local neighborhoods. At the same time, the Gaussian kernel bandwidth can be adaptively obtained in density measurement, which can highlight high-density areas. Secondly, the number of peels is adaptively determined by the coefficient of variation of density during the iterative border peeling process. Lastly, labels are assigned to core points based on graph connections, while the clustering of border points is accomplished via label propagation. PABP does not require users to adjust parameters based on prior knowledge or external indicators throughout the entire process. In the experiment, PABP was compared with seven other advanced clustering algorithms on 13 synthetic datasets, 10 UCI datasets, and Olivetti Face and MNIST datasets. The results indicate that the clustering performance of PABP is superior to the compared algorithms.},
  archive      = {J_TKDE},
  author       = {Hui Tu and Shifei Ding and Xiao Xu and Lili Guo and Ling Ding and Xindong Wu},
  doi          = {10.1109/TKDE.2025.3579367},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5538-5550},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Parameter-adaptive border peeling clustering algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-step pairwise constrained multi-view clustering in linear time. <em>TKDE</em>, <em>37</em>(9), 5523-5537. (<a href='https://doi.org/10.1109/TKDE.2025.3579388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise constrained clustering, which employs the pairwise constraints to boost clustering performance, has been widely used in many applications such as face clustering and image retrieval. Due to the prevalence of multi-view data, pairwise constrained multi-view clustering has attracted increasing attention. Nevertheless, existing methods suffer from at least one of the three issues, i.e., expensive time consumption, two-stage clustering and inadequate use of pairwise constraints. To address the above issues, this paper proposes a Pairwise Constrained Bipartite Graph (PCBG) learning method for efficient one-step pairwise constrained multi-view clustering. Concretely, to encode must-link constraints, a novel comprehensive bipartite graph is elegantly designed. Meanwhile, a cannot-link regularization is derived and imposed on the comprehensive bipartite graph, which enforces cannot-link constraints to be realized with theoretically provable guarantees. Moreover, the comprehensive bipartite graph is constrained to exhibit explicit clustering partition by its connected components. Then, an efficient and convergent algorithm with theoretically proved accelerating techniques is derived for optimization, which has linear time complexity to the sample size. Extensive experimental results demonstrate the advantages of PCBG in both clustering performance and time complexity compared with state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Wenjun Yu and Hong Tao and Chenping Hou},
  doi          = {10.1109/TKDE.2025.3579388},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5523-5537},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {One-step pairwise constrained multi-view clustering in linear time},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODMixer: Fine-grained spatial-temporal MLP for metro origin-destination prediction. <em>TKDE</em>, <em>37</em>(9), 5508-5522. (<a href='https://doi.org/10.1109/TKDE.2025.3579370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metro Origin-Destination (OD) prediction is a crucial yet challenging spatial-temporal prediction task in urban computing, which aims to accurately forecast cross-station ridership for optimizing metro scheduling and enhancing overall transport efficiency. Analyzing fine-grained and comprehensive relations among stations effectively is imperative for metro OD prediction. However, existing metro OD models either mix information from multiple OD pairs from the station’s perspective or exclusively focus on a subset of OD pairs. These approaches may overlook fine-grained relations among OD pairs, leading to difficulties in predicting potential anomalous conditions. To address these challenges, we learn traffic evolution from the perspective of all OD pairs and propose a fine-grained spatial-temporal MLP architecture for metro OD prediction, namely ODMixer. Specifically, our ODMixer has double-branch structure and involves the Channel Mixer, the Multi-view Mixer, and the Bidirectional Trend Learner. The Channel Mixer aims to capture short-term temporal relations among OD pairs, the Multi-view Mixer concentrates on capturing spatial relations from both origin and destination perspectives. To model long-term temporal relations, we introduce the Bidirectional Trend Learner. Extensive experiments on two large-scale metro OD prediction datasets HZMOD and SHMO demonstrate the advantages of our ODMixer.},
  archive      = {J_TKDE},
  author       = {Yang Liu and Binglin Chen and Yongsen Zheng and Lechao Cheng and Guanbin Li and Liang Lin},
  doi          = {10.1109/TKDE.2025.3579370},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5508-5522},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ODMixer: Fine-grained spatial-temporal MLP for metro origin-destination prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuro-ins: A learning-based one-shot node insertion for dynamic routing problems. <em>TKDE</em>, <em>37</em>(9), 5495-5507. (<a href='https://doi.org/10.1109/TKDE.2025.3580640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise in instant delivery services necessitates efficient route planning in last-mile delivery scenarios, where new orders arrive dynamically and need to be integrated into existing routes. In such contexts, complete re-optimization of routes are not permitted, and node insertion to existing route sequences is the only viable option. However, many existing heuristics for node insertion, such as the Cheapest Insertion (CI) method, are myopic and often result in suboptimal solutions retrospectively. This paper presents Neuro-Ins, an initial yet novel attempt at harnessing a learning-based framework to handle the insertion of new orders for the Pickup and Delivery Problem (PDP). In contrast to CI, which considers only one node at a time for insertion, Neuro-Ins leverages an Attention-Mechanism (AM) based encoder-decoder structure to collectively consider all nodes to be inserted, thereby enhancing the quality of the eventual solution. To further improve the model’s representation of the current route, we introduce a position embedding to enrich the node feature embedding with positional information of the route. Experiments on synthetic and real-world datasets demonstrate that Neuro-Ins, trained by PPO, consistently outperforms CI without compromising computational speed, and it also surpasses the performance of state-of-the-art solution methods implemented in the industry. Our findings emphasize the importance of explicitly considering all nodes to be inserted along with the en-route nodes and their positions in the route, showcasing the efficacy of the proposed AM-based framework in optimizing the instant delivery routes.},
  archive      = {J_TKDE},
  author       = {Zhiqin Zhang and Jingfeng Yang and Zhiguang Cao and Hoong Chuin Lau},
  doi          = {10.1109/TKDE.2025.3580640},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5495-5507},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Neuro-ins: A learning-based one-shot node insertion for dynamic routing problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple change point detection method of profile data with false discovery rate control. <em>TKDE</em>, <em>37</em>(9), 5481-5494. (<a href='https://doi.org/10.1109/TKDE.2025.3584034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple change point detection seeks to identify potential shifts in the data properties. While existing detection methods primarily focus on univariate and multivariate data, they often fall short in detecting variations in profile data, which represent the functional relationships between explanatory and response variables. This paper introduces a novel change point detection method tailored for profile data, employing a smooth profile decomposition (SPD) strategy that accommodates arbitrary designs and heteroscedasticity. This approach facilitates a comprehensive representation of both overall trends and fluctuations within the profiles. Furthermore, we propose an order-splitting screening estimator (OSE) to construct a detection statistic, allowing for precise estimation of change points while ensuring a significant theoretical guarantee regarding the false discovery rate (FDR). We validate the performance and robustness of the proposed method through numerical experiments and a real case study involving wind turbines.},
  archive      = {J_TKDE},
  author       = {Zhenyu Wu and Yanting Li and Nan Chen and Zhijun Wang and Chaoxu Mu},
  doi          = {10.1109/TKDE.2025.3584034},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5481-5494},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multiple change point detection method of profile data with false discovery rate control},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal entity linking with dynamic modality selection and interactive prompt learning. <em>TKDE</em>, <em>37</em>(9), 5467-5480. (<a href='https://doi.org/10.1109/TKDE.2025.3580754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Multimodal Entity Linking leverage multimodal information to link target mentions to corresponding entities. However, existing methods uniformly adopt a “one-size-fits-all” approach, which overlooks the unique requirements of individual samples and fails to adequately balance modality-assisted disambiguation and modality-induced noise. Also, the commonly used separate large-scale visual and text pre-trained models for feature extraction do not address inter-modal heterogeneity and the high computational cost of fine-tuning. To resolve these two issues, we introduce a novel approach named Multimodal Entity Linking with Dynamic Modality Selection and Interactive Prompt Learning (DSMIP). First, we design three expert networks that utilize different subsets of modalities tailored to the task and train them individually. Specifically, for the multimodal expert network, we enhance entity and mention feature extraction by updating multimodal prompts and setting up a coupling function to realize the interaction of prompts between modalities. Subsequently, to select the best-suited expert network for each specific sample, we devise a Modality Selection Gating Network to gain the optimal one-hot selection vector by applying a specialized reparameterization technique and a two-stage training process. Experimental results on three public benchmark datasets demonstrate that the proposed DSMIP outperforms all state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Yingyao Ma and Yifan Xue and Jiasong Wu and Lotfi Senhadji and Huazhong Shu and Jian Yang},
  doi          = {10.1109/TKDE.2025.3580754},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5467-5480},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multimodal entity linking with dynamic modality selection and interactive prompt learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDIPN: Multi-scale deep interval prediction network for multivariate time series. <em>TKDE</em>, <em>37</em>(9), 5452-5466. (<a href='https://doi.org/10.1109/TKDE.2025.3579406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval prediction is crucial in decision-making processes across many domains. Although significant progress has been made in existing interval prediction methods, they still face several challenges, such as assumptions about data distribution, fixed interval widths, limitations of gradient-based optimization algorithm, crossing of upper and lower bounds, and insufficient consideration of multi-scale spatial-temporal patterns. To address these issues, we propose a Multi-Scale Deep Interval Prediction Network (MSDIPN). Specifically, a Multi-Scale Spatio-Temporal Self-Attention Mechanism is introduced to capture spatio-temporal dependencies across different spatial scales. Additionally, a Temporal Self-Attention Mechanism module is constructed to extract temporal dependencies of historical variables across varying lag phases. Then a Global Self-Attention Mechanism module is designed to address representation degradation using residual connections and self-attention mechanisms. To overcome limitations related to distributional assumptions, fixed interval widths, and crossing problems, an Improved LUBE module is developed as the output module for generating prediction intervals (PIs) of time series data. Furthermore, a gradient-based PIs loss function is designed to address the optimization issue of MSDIPN by integrating a smooth approximation function with a pinball loss function. We validate the effectiveness of the proposed algorithm using five real-world datasets, demonstrating its superiority over traditional models.},
  archive      = {J_TKDE},
  author       = {Feng Jiang and Bo Wu and Shiping Wen and Tianhai Tian},
  doi          = {10.1109/TKDE.2025.3579406},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5452-5466},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MSDIPN: Multi-scale deep interval prediction network for multivariate time series},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On your mark, get set, predict! modeling continuous-time dynamics of cascades for information popularity prediction. <em>TKDE</em>, <em>37</em>(9), 5436-5451. (<a href='https://doi.org/10.1109/TKDE.2025.3583129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information popularity prediction is important yet challenging in various domains, including viral marketing and news recommendations. The key to accurately predicting information popularity lies in subtly modeling the underlying temporal information diffusion process behind observed events of an information cascade, such as the retweets of a tweet. To this end, most existing methods either adopt recurrent networks to capture the temporal dynamics from the first to the last observed event or develop a statistical model based on self-exciting point processes to make predictions. However, information diffusion is intrinsically a complex continuous-time process with irregularly observed discrete events, which is oversimplified using recurrent networks as they fail to capture the irregular time intervals between events, or using self-exciting point processes as they lack flexibility to capture the complex diffusion process. Against this background, we propose ConCat, modeling the Continuous-time dynamics of Cascades for information popularity prediction. On the one hand, it leverages neural Ordinary Differential Equations (ODEs) to model irregular events of a cascade in continuous time based on the cascade graph and sequential event information. On the other hand, it considers cascade events as neural temporal point processes (TPPs) parameterized by a conditional intensity function which can also benefit the popularity prediction task. We conduct extensive experiments to evaluate ConCat on three real-world datasets. Results show that ConCat achieves superior performance compared to state-of-the-art baselines, yielding 2.3%-33.2% improvement over the best-performing baselines across the three datasets.},
  archive      = {J_TKDE},
  author       = {Xin Jing and Yichen Jing and Yuhuan Lu and Bangchao Deng and Sikun Yang and Dingqi Yang},
  doi          = {10.1109/TKDE.2025.3583129},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5436-5451},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {On your mark, get set, predict! modeling continuous-time dynamics of cascades for information popularity prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining cross-level high utility itemsets in unstable and negative profit databases. <em>TKDE</em>, <em>37</em>(9), 5420-5435. (<a href='https://doi.org/10.1109/TKDE.2025.3579746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High utility itemset mining (HUIM) is one of the most compelling problems in data mining, extending frequent itemset mining (FIM) and serving as a crucial method for analyzing customer behavior. Many HUIM algorithms have been proposed to improve execution time and memory consumption. However, most assume that the profit is fixed for each item in a database, which is unrealistic. Some algorithms address products with unstable transaction profits but still need to run faster due to ineffective pruning strategies. Additionally, generalizing items into categories is often neglected. To address these issues, this paper considers a more practical database type that integrates unstable profits with a taxonomy of items. The proposed algorithm, CLHUN (Cross-level High Utility Itemset Mining in a Database with Unstable and Negative Profits), combines efficient techniques such as item sorting and tighter upper bounds to prune the search space. Furthermore, it introduces strategies to eliminate unpromising items during mining and reduce the number of transaction scans. Several experiments were conducted to evaluate the algorithm’s performance. Results demonstrate that CLHUN is efficient with these techniques and strategies.},
  archive      = {J_TKDE},
  author       = {N. T. Tung and Trinh D. D. Nguyen and Loan T. T. Nguyen and Duc-Lung Vu and Philippe Fournier-Viger and Bay Vo},
  doi          = {10.1109/TKDE.2025.3579746},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5420-5435},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Mining cross-level high utility itemsets in unstable and negative profit databases},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mask diffusion-based contrastive learning for knowledge-aware recommendation. <em>TKDE</em>, <em>37</em>(9), 5407-5419. (<a href='https://doi.org/10.1109/TKDE.2025.3582767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-aware recommendations improve performance by using knowledge graphs as auxiliary information. Recently, researchers have introduced the contrastive learning paradigm in knowledge-aware recommendations to enhance representation learning. However, most contrastive learning methods rely on manually or randomly generated knowledge views, making it challenging to generalize to different data distributions and alleviate knowledge noise effects. To solve these issues, we propose a mask diffusion-based contrastive learning method for knowledge-aware recommendation. Specifically, we apply local masked input to the diffusion model, using a mask prediction paradigm to adaptively generate views from both global and local perspectives, thereby enhancing the model’s generalization capability across different data distributions. Additionally, we propose a conditional inference process, leveraging user intentions to provide reasonable denoising guidance. At the same time, we design a collaborative knowledge diffusion loss aimed at improving the consistency between generated data and user behavior patterns. In this way, we combine the diffusion model with contrastive learning for the knowledge-aware recommendation, which can improve the generalization ability of the model. Our experimental results on four datasets show the effectiveness of our model.},
  archive      = {J_TKDE},
  author       = {Kaibei Li and Yihao Zhang and Xiaokang Li and Meng Yuan and Wei Zhou},
  doi          = {10.1109/TKDE.2025.3582767},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5407-5419},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Mask diffusion-based contrastive learning for knowledge-aware recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-QL: A LLM-enhanced Q-learning approach for scheduling multiple parallel drones. <em>TKDE</em>, <em>37</em>(9), 5393-5406. (<a href='https://doi.org/10.1109/TKDE.2025.3579386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the Multiple Flying Sidekicks Traveling Salesman Problem (mFSTSP), where parallel Unmanned Aerial Vehicles (UAVs), or Drones, work alongside truck to enhance delivery efficiency. Existing scheduling approaches face challenges in high computational costs and the risk of converging to local optima due to excessive exploration in unknown environments, especially in large-scale mFSTSP. This study proposed a Large Language Model Enhanced Q-Learning Approach (LLM-QL) to solve mFSTSP, which combines the local exploration advantages of Q-Learning with the global understanding of unknown environments provided by LLMs, thus improving the efficiency of path planning. A novel prompt strategy is also provided, transforming the problem modeling into a format easily understood by LLMs, guiding the algorithm’s exploration and significantly improving convergence. We also provide a proof of the convergence of LLM-QL. Experimental results demonstrate that LLM-QL achieves up to a 1.35 x improvement in key performance metrics such as total completion time, algorithm runtime, and UAV utilization, compared to existing state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Qian Zhou and Jiayang Wu and Mengyue Zhu and Yuhang Zhou and Fu Xiao and Yanchun Zhang},
  doi          = {10.1109/TKDE.2025.3579386},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5393-5406},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LLM-QL: A LLM-enhanced Q-learning approach for scheduling multiple parallel drones},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to maintain: Towards human-machine collaborative spatial task assignment. <em>TKDE</em>, <em>37</em>(9), 5378-5392. (<a href='https://doi.org/10.1109/TKDE.2025.3583407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of mobile internet and GPS-enabled smartphones, spatial crowdsourcing has emerged as a prevalent computing paradigm. In this paradigm, the human-machine collaborative task assignment mode, which empowers workers to select tasks based on their preferences, has become a preferred approach for various applications such as ridesharing and takeaways. Generally, the platform continuously presents a set of top-$k$ tasks to individual workers by taking into account factors like travel distance, and allows workers to select tasks from this set. This decision approach is beneficial to both platform and workers. However, it still faces significant challenges in large-scale dynamic results maintenance, which incurs considerable computational costs. In this paper, we propose a novel solution framework with an adaptive two-layer cache structure to efficiently address the problem of updating dynamic top-$k$ results. Additionally, we propose two effective learning-based methods which greatly improve the efficiency of result maintenance. Furthermore, we present a novel approach to identify and process caches that trigger intensive updates within a tight time limit, greatly reducing the peak demand for updating caches. Finally, extensive experimental results on real datasets demonstrate that our proposed algorithms exhibit strong performance across various parameter configurations.},
  archive      = {J_TKDE},
  author       = {Baolong Mei and Yafei Li and Yuanyuan Jin and Yun Peng and Mingliang Xu and Jianliang Xu},
  doi          = {10.1109/TKDE.2025.3583407},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5378-5392},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning to maintain: Towards human-machine collaborative spatial task assignment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning multi-granularity and adaptive representation for knowledge graph reasoning. <em>TKDE</em>, <em>37</em>(9), 5360-5377. (<a href='https://doi.org/10.1109/TKDE.2025.3579774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph reasoning (KGR) seeks to infer new factual triples from existing knowledge graphs (KGs). Recent methods have unified transductive and inductive reasoning by learning entity-independent representations through local neighboring structures. Nevertheless, these methods often encounter inefficiencies and rely on elaborate local structures without directly modeling the correlations between queries and various structures within KGs. In this paper, we propose a novel framework MulGA, which is designed to learn multi-granularity and adaptive embeddings for KGR. MulGA first employs connectivity subgraphs to uniformly and hierarchically represent query-related structures within KGs, such as triples, relation paths, and subgraphs, establishing the hierarchical relationship between structures at different granularities. Subsequently, we design a graph neural network-based multi-granularity embedding propagation module that unifies the message-passing process with the connectivity subgraph construction. This module obtains the query-related structural representations by all entities at multiple granularities, eliminating the need to explicitly extract any graph elements, thus addressing inefficiency issues. Moreover, we develop a structure-aware adaptive merging mechanism that assigns weights to different granularities and integrates them into cohesive subgraph-granularity representations for reasoning. The systematic experiments have been conducted on 15 benchmarks and MulGA achieves a significant improvement in MRR by an average of 0.5% -1.1% on transductive tasks and 0.2% -7.3% on inductive tasks than existing state-of-the-art methods. Moreover, MulGA exhibits faster convergence speed, smaller number of parameters, competitive inference time, and alleviates the over-smoothing prevalent in graph neural networks.},
  archive      = {J_TKDE},
  author       = {Ziyu Shang and Peng Wang and Jianghan Liu and Jiajun Liu and Guozheng Li and Zijie Xu and Zhizhao Luo and Xiye Chen and Wenjun Ke},
  doi          = {10.1109/TKDE.2025.3579774},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5360-5377},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning multi-granularity and adaptive representation for knowledge graph reasoning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JetBGC: Joint robust embedding and structural fusion bipartite graph clustering. <em>TKDE</em>, <em>37</em>(9), 5346-5359. (<a href='https://doi.org/10.1109/TKDE.2025.3583718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graph clustering (BGC) has emerged as a fast-growing research in the clustering community. Despite BGC has achieved promising scalability, most variants still suffer from the following concerns: a) Susceptibility to noisy features. They construct bipartite graphs in the raw feature space, inducing poor robustness to noisy features. b) Inflexible anchor selection strategies. They usually select anchors through heuristic sampling or constrained learning methods, degrading flexibility. c) Partial structure mining. Existing methods are mainly built upon Linear Reconstruction Paradigm (LRP) from subspace clustering or Locally Linear Paradigm (LLP) from manifold learning, which partially exploit linear or locally linear structures, lacking a unified perspective to integrate global complementary structures. To this end, we propose a novel model, termed J oint Robust Emb e dding and Struc t ural Fusion B ipartite G raph C lustering (JetBGC), which focuses on three aspects, namely robustness, flexibility, and complementarity. Concretely, we first introduce a robust embedding learning module to extract latent representation that can reduce the impact of noisy features. Then, we optimize anchors via a constraint-free strategy that can flexibly capture data distribution. Furthermore, we revisit the consistency and specificity of LRP and LLP, and design a new unified structural fusion strategy to integrate both linear and locally linear structures from a global perspective. Therefore, JetBGC unifies robust representation learning, flexible anchor optimization, and structural bipartite graph fusion in a framework. Extensive experiments on synthetic and real-world datasets validate our effectiveness against existing baselines.},
  archive      = {J_TKDE},
  author       = {Liang Li and Yuangang Pan and Junpu Zhang and Pei Zhang and Jie Liu and Xinwang Liu and Kenli Li and Ivor W. Tsang and Keqin Li},
  doi          = {10.1109/TKDE.2025.3583718},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5346-5359},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {JetBGC: Joint robust embedding and structural fusion bipartite graph clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intra-trajectory error balancing and inter-trajectory feature point clustering for trajectory compression. <em>TKDE</em>, <em>37</em>(9), 5330-5345. (<a href='https://doi.org/10.1109/TKDE.2025.3579434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of locatable devices leads to a sharp increase in the storage of trajectory data, and redundant storage of similar trajectories wastes a large amount of storage resources. The state-of-the-art multiple trajectory compression algorithms are developed to strip the partial information of trajectory; however, these algorithms have low compression efficiency because they do not eliminate the redundancy within a single trajectory as much as possible, as well as high time overhead due to matching of reference sub-trajectories. In this study, we propose a new spatio-temporal trajectory compression technique, consisting of intra-trajectory error balancing and inter-trajectory feature point clustering. Intra-trajectory error balancing is achieved through retaining high score (an aggregated metric) trajectory points (i.e., feature points). Furthermore, inter-trajectory feature point clustering realizes the fusion of similar trajectories and extracts the commonality between trajectories. Experiments are performed on five real trajectory datasets, including two road datasets, one airline dataset, and one walking dataset. Compared with the state-of-the-art methods, our compression technique improves the compression ratio by an average of 24.9% under the same error, and reduces the time overhead by at least an order of magnitude.},
  archive      = {J_TKDE},
  author       = {Lei Yang and Xin Cheng and Yuwei Liao and Rui Li and Guoqi Xie},
  doi          = {10.1109/TKDE.2025.3579434},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5330-5345},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Intra-trajectory error balancing and inter-trajectory feature point clustering for trajectory compression},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to bridge the gap between modalities: Survey on multimodal large language model. <em>TKDE</em>, <em>37</em>(9), 5311-5329. (<a href='https://doi.org/10.1109/TKDE.2025.3527978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image-based questions, bridging the gap towards real-world human-computer interactions and hinting at a potential pathway to artificial general intelligence. However, MLLMs still face challenges in addressing the semantic gap in multimodal data, which may lead to erroneous outputs, posing potential risks to society. Selecting the appropriate modality alignment method is crucial, as improper methods might require more parameters without significant performance improvements. This paper aims to explore modality alignment methods for LLMs and their current capabilities. Implementing effective modality alignment can help LLMs address environmental issues and enhance accessibility. The study surveys existing modality alignment methods for MLLMs, categorizing them into four groups: (1) Multimodal Converter, which transforms data into a format that LLMs can understand; (2) Multimodal Perceiver, which improves how LLMs percieve different types of data; (3) Tool Learning, which leverages external tools to convert data into a common format, usually text; and (4) Data-Driven Method, which teaches LLMs to understand specific data types within datasets.},
  archive      = {J_TKDE},
  author       = {Shezheng Song and Xiaopeng Li and Shasha Li and Shan Zhao and Jie Yu and Jun Ma and Xiaoguang Mao and Weimin Zhang and Meng Wang},
  doi          = {10.1109/TKDE.2025.3527978},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5311-5329},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {How to bridge the gap between modalities: Survey on multimodal large language model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-aware neural subgraph matching with enhanced similarity measure. <em>TKDE</em>, <em>37</em>(9), 5298-5310. (<a href='https://doi.org/10.1109/TKDE.2025.3583003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph matching is challenging as it necessitates time-consuming combinatorial searches. Recent Graph Neural Network (GNN)-based approaches address this issue by employing GNN encoders to extract graph information and hinge distance measures to ensure containment constraints in the embedding space. These methods significantly shorten the response time, making them promising solutions for subgraph retrieval. However, they suffer from scale differences between graph pairs during encoding, as they focus on feature counts but overlook the relative positions of features within node-rooted subtrees, leading to disturbed containment constraints and false predictions. Additionally, their hinge distance measures lack discriminative power for matched graph pairs, hindering ranking applications. We propose NC-Iso, a novel GNN architecture for neural subgraph matching. NC-Iso preserves the relative positions of features by building the hierarchical dependencies between adjacent echelons within node-rooted subtrees, ensuring matched graph pairs maintain consistent hierarchies while complying with containment constraints in feature counts. To enhance the ranking ability for matched pairs, we introduce a novel similarity dominance ratio-enhanced measure, which quantifies the dominance of similarity over dissimilarity between graph pairs. Empirical results on nine datasets validate the effectiveness, generalization ability, scalability, and transferability of NC-Iso while maintaining time efficiency, offering a more discriminative neural subgraph matching solution for subgraph retrieval.},
  archive      = {J_TKDE},
  author       = {Zhouyang Liu and Ning Liu and Yixin Chen and Jiezhong He and Menghan Jia and Dongsheng Li},
  doi          = {10.1109/TKDE.2025.3583003},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5298-5310},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchy-aware neural subgraph matching with enhanced similarity measure},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical text classification optimization via structural entropy and singular smoothing. <em>TKDE</em>, <em>37</em>(9), 5283-5297. (<a href='https://doi.org/10.1109/TKDE.2025.3579810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With long-tailed data and complex label hierarchy, hierarchical text classification (HTC) is a challenging multi-label text classification task. Applying prompts to pre-trained language models (PLMs) has recently become a mainstream approach in HTC. However, existing prompt-based models experience a significant drop in classification performance on tail labels. Due to the imbalanced data, HTC models still face two challenges. First, text embeddings, learned for classification, often lack distinctiveness for tail categories. Second, label embeddings suffer from significant degeneration, especially for tail labels. To address these issues, in this paper, we propose a novel Hierarchical Text Classification Optimization method via Structural Entropy and SIngular Spectrum Smoothing, namely SIHTC. SIHTC contains two parts: text embedding optimization and label embedding optimization. First, based on the structural information theory, we design a tree aggregation network and construct encoding trees to minimize the structural entropy of texts under the hierarchical labels. In this manner, SIHTC injects label structural information into text embeddings, hierarchically optimizing the embedding space by enclosing the text embeddings within related ground truth labels while separating them from unrelated ground truth labels. Second, we propose a global and local singular spectrum smoothing regularization method to maximize the area under the singular value curve. In this way, SIHTC decreases representation degeneration and learns label embeddings with improved label generalization capability. Extensive experiments are conducted on three popular HTC datasets. The results show that SIHTC outperforms all baseline methods, especially with an advantage in handling tail labels, indicating the effectiveness of the above two optimizations.},
  archive      = {J_TKDE},
  author       = {Qitong Liu and Hao Peng and Xiang Huang and Zhifeng Hao and Qingyun Sun and Zhengtao Yu and Philip S. Yu},
  doi          = {10.1109/TKDE.2025.3579810},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5283-5297},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical text classification optimization via structural entropy and singular smoothing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical intent-based interest disentanglement for personalized recommendation. <em>TKDE</em>, <em>37</em>(9), 5271-5282. (<a href='https://doi.org/10.1109/TKDE.2025.3569097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the data sparsity issue, conventional graph-based models leverage structural signals from the interaction graph to embed users’ interests. However, these models learn a uniform representation for interest modeling, which blends users’ diverse intents and inevitably biases interest learning, hindering recommendations. Although the fine-grained paradigm can learn the intents of interactions separately to alleviate learning bias, the relationships among intents and the disentangled manner require elaborate design. Existing fine-grained models emphasize intent diversity and employ additional data splitting for disentanglement, which ignores the hierarchical relationship, exacerbates data sparsity, and increases the computational burden. To address these issues, we explore hierarchical intents and adaptive intent learning, proposing a hierarchical intent-based interest disentanglement (HIID) model for personalized recommendation. HIID introduces learnable intent queries to guide interest disentanglement from global interactions in a split-free manner. It raises a hierarchical intent hypothesis to involve hierarchical CF signals for interest modeling, where intents within the same level appear relatively diverse, and the in-depth intents are abstracted from the superficial ones. Both adaptive intent learning and hierarchical hypothesis help extract significant CF signals to promote personalized recommendation. Extensive experiments on public datasets show that the proposed HIID outperforms the state-of-the-art CF models for recommendation. Furthermore, HIID implements adaptive interest disentanglement in a split-free manner, improving the training efficiency of the recommender model compared to the existing fine-grained interest models.},
  archive      = {J_TKDE},
  author       = {Tuo Wang and Meng Jian and Xinyi Xu and Lifang Wu},
  doi          = {10.1109/TKDE.2025.3569097},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5271-5282},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical intent-based interest disentanglement for personalized recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling new class in online label shift. <em>TKDE</em>, <em>37</em>(9), 5257-5270. (<a href='https://doi.org/10.1109/TKDE.2025.3583138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, data are continuously accumulated in open environments, and new classes may emerge over time. For instance, in disease diagnosis, the prevalence of a certain disease may vary seasonally, and new diseases can also emerge. This paper investigates the problem of learning from unlabeled data stream where the label distribution evolves over time, and meanwhile, previously unseen new classes may appear. To handle the emerging new classes in online label shift, we first design a novel risk estimator by unbiased risk rewriting and mixture proportion estimation, which enables the identification of new class data. Subsequently, we employ the online ensemble paradigm for model updating to handle unknown distribution shifts. Moreover, we introduce the sketching and ensemble pruning mechanisms to improve the efficiency of the algorithm, making it more lightweight and practical. The proposed approach enjoys a theoretical guarantee of dynamic regret, ensuring its effectiveness in adapting to the unknown distribution shifts and the emergence of new classes in streaming data. Experiments on diverse benchmark datasets and two real-world applications demonstrate the effectiveness of the algorithm.},
  archive      = {J_TKDE},
  author       = {Yu-Yang Qian and Yong Bai and Zhen-Yu Zhang and Peng Zhao and Zhi-Hua Zhou},
  doi          = {10.1109/TKDE.2025.3583138},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5257-5270},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Handling new class in online label shift},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCPA: GAN-based collusive poisoning attack in federated recommender systems. <em>TKDE</em>, <em>37</em>(9), 5243-5256. (<a href='https://doi.org/10.1109/TKDE.2025.3579807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Recommender Systems (FedRecs) have evolved as a privacy-preserving paradigm that facilitates distributed training of personalized recommenders without sharing user data. However, FedRecs are known to be susceptible to poisoning attacks by malicious users, who aim at promoting or demoting the exposure of target items through sending malicious updates to the central server. Meanwhile, the distribution of recommendation performance among users, called as performance fairness, could be exacerbated, which is one of the major concerns of trustworthy FedRecs. This paper proposes a novel attack method, Generative Adversarial Network (GAN)-Based Collusive Poisoning Attack (GCPA). To implement GCPA, we create a GAN-based fake user synthesis strategy that mimics behaviors and preferences of real users to generate fake users. Furthermore, we design a collusion-based fairness attack strategy that changes the exposure of items to undermine fairness. To maximize the impact on the distribution of recommendation performance, we develop an adaptive clustering algorithm to identify a subset of items that significantly contribute to the uneven distribution of recommendation performance through collusion. Extensive experiments on two datasets show that GCPA effectively increase the exposure of target items while undermining the performance fairness of FedRecs. In addition, GCPA also has strong resistance to four defense methods. Meanwhile, we provide a heuristic defense method based on gradient direction and similarity against collusive poisoning attack on FedRecs.},
  archive      = {J_TKDE},
  author       = {Tianlong Gu and Shouhong Tan and Fengrui Hao and Xiaoli Liu and Liang Chang and Yuanfeng Liu},
  doi          = {10.1109/TKDE.2025.3579807},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5243-5256},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GCPA: GAN-based collusive poisoning attack in federated recommender systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairDgcl: Fairness-aware recommendation with dynamic graph contrastive learning. <em>TKDE</em>, <em>37</em>(9), 5230-5242. (<a href='https://doi.org/10.1109/TKDE.2025.3580087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As trustworthy AI continues to advance, the fairness issue in recommendations has received increasing attention. A recommender system is considered unfair when it produces unequal outcomes for different user groups based on user-sensitive attributes (e.g., age, gender). Some researchers have proposed data augmentation-based methods aiming at alleviating user-level unfairness by altering the skewed distribution of training data among various user groups. Despite yielding promising results, they often rely on fairness-related assumptions that may not align with reality, potentially reducing the data quality and negatively affecting model effectiveness. To tackle this issue, in this paper, we study how to implement high-quality data augmentation to improve recommendation fairness. Specifically, we propose FairDgcl, a dynamic graph adversarial contrastive learning framework aiming at improving fairness in recommender system. First, FairDgcl develops an adversarial contrastive network with a view generator and a view discriminator to learn generating fair augmentation strategies in an adversarial style. Then, we propose two dynamic, learnable models to generate contrastive views within contrastive learning framework, which automatically fine-tune the augmentation strategies. Meanwhile, we theoretically show that FairDgcl can simultaneously generate enhanced representations that possess both fairness and accuracy. Lastly, comprehensive experiments conducted on four datasets demonstrate the effectiveness of the proposed FairDgcl.},
  archive      = {J_TKDE},
  author       = {Wei Chen and Meng Yuan and Zhao Zhang and Ruobing Xie and Fuzhen Zhuang and Deqing Wang and Rui Liu},
  doi          = {10.1109/TKDE.2025.3580087},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5230-5242},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FairDgcl: Fairness-aware recommendation with dynamic graph contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairCDSR: Fairness-aware cross-domain sequential recommendation via multi-interest transfer and contrastive learning. <em>TKDE</em>, <em>37</em>(9), 5214-5229. (<a href='https://doi.org/10.1109/TKDE.2025.3582297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sequential recommendation (CDSR) tackles data sparsity and cold-start issues by leveraging information from the source domain to enhance prediction accuracy in the target domain. However, the recommendation fairness issue may further deteriorate dramatically with the biased knowledge transfer of overlapped users. This paper is the first study to address and improve fairness measurement between different demographic groups in CDSR. The proposed FairCDSR employs sequence augmentation techniques to enrich the interaction histories of disadvantaged user groups, which typically have less training data. These augmented sequences are further represented by a contrastive learning method with hard negative sampling to mitigate the unfairness in recommendations. Then, to more precisely capture cross-domain preferences, a multi-interest learning approach is applied to each group across the domains. Finally, an interest-level knowledge transfer algorithm with fixed bandwidth limitations for each group is developed to extract fair and semantic cross-domain information. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of FairCDSR. Compared to existing cross-domain or fair recommendation systems, FairCDSR significantly reduces recommendation disparity between advantaged and disadvantaged groups. Benefiting from a significant improvement in the recommendation accuracy of the disadvantaged group, the overall system performance can also be effectively enhanced by 5-10% .},
  archive      = {J_TKDE},
  author       = {De-Ren Toh and Szu-Hao Huang and Chiao-Ting Chen},
  doi          = {10.1109/TKDE.2025.3582297},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5214-5229},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FairCDSR: Fairness-aware cross-domain sequential recommendation via multi-interest transfer and contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>AT: Feature-focusing adversarial training via disentanglement of natural and perturbed patterns. <em>TKDE</em>, <em>37</em>(9), 5201-5213. (<a href='https://doi.org/10.1109/TKDE.2025.3580116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to adversarial examples crafted by well-designed perturbations. This could lead to disastrous results on critical applications such as self-driving cars, surveillance security, and medical diagnosis. At present, adversarial training is one of the most effective defenses against adversarial examples. However, in traditional adversarial training, it is still difficult to achieve a good trade-off between clean accuracy and robustness since DNNs still learn spurious features. The intrinsic reason is that traditional adversarial training makes it difficult to fully learn core features from adversarial examples when noise and examples cannot be disentangled. In this paper, we disentangle the adversarial examples into natural and perturbed patterns by bit-plane slicing. We assume the higher bit-planes represent natural patterns and the lower bit-planes represent perturbed patterns, respectively. We propose Feature-Focusing Adversarial Training (F$^{2}$AT), which differs from previous work in that it enforces the model to focus on the core features from natural patterns and reduce the impact of spurious features from perturbed patterns. The experimental results demonstrated that the clean accuracy and adversarial robustness with our F$^{2}$AT can be significantly improved.},
  archive      = {J_TKDE},
  author       = {Yaguan Qian and Chenyu Zhao and Zhaoquan Gu and Bin Wang and Shouling Ji and Wei Wang and Yanchun Zhang},
  doi          = {10.1109/TKDE.2025.3580116},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5201-5213},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {F$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>AT: Feature-focusing adversarial training via disentanglement of natural and perturbed patterns},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing collaborative semantics of language model-driven recommendations via graph-aware learning. <em>TKDE</em>, <em>37</em>(9), 5188-5200. (<a href='https://doi.org/10.1109/TKDE.2025.3581606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are increasingly prominent in the recommendation systems domain. Existing studies usually utilize in-context learning or supervised fine-tuning on task-specific data to align LLMs into recommendations. However, the substantial bias in semantic spaces between language processing tasks and recommendation tasks poses a nonnegligible challenge. Specifically, without the adequate capturing ability of collaborative information, existing modeling paradigms struggle to capture behavior patterns within community groups, leading to LLMs’ ineffectiveness in discerning implicit interaction semantic in recommendation scenarios. To address this, we consider enhancing the learning capability of language model-driven recommendation models for structured data, specifically by utilizing interaction graphs rich in collaborative semantics. We propose a Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec). GAL-Rec enhances the understanding of user-item collaborative semantics by imitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop information, thereby fully exploiting the substantial learning capacity of LLMs to independently address the complex graphs in the recommendation system. Sufficient experimental results on three real-world datasets demonstrate that GAL-Rec significantly enhances the comprehension of collaborative semantics, and improves recommendation performance.},
  archive      = {J_TKDE},
  author       = {Zhong Guan and Likang Wu and Hongke Zhao and Ming He and Jianpin Fan},
  doi          = {10.1109/TKDE.2025.3581606},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5188-5200},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing collaborative semantics of language model-driven recommendations via graph-aware learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECStore: Achieving efficient and compressible indexing on outsourced encrypted databases. <em>TKDE</em>, <em>37</em>(9), 5171-5187. (<a href='https://doi.org/10.1109/TKDE.2025.3583470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encrypted Databases (EDBs) are essential for protecting sensitive data outsourced to public clouds, enabling diverse index-based queries over encrypted data. However, existing EDB indexes often incur high storage overhead and performance degradation, primarily due to the poor compressibility of pseudorandom encrypted values, which leads to frequent accesses to slower persistent storage as indexes outgrow main memory. We introduce ECStore, the first EDB that supports compressible and efficient indexing. Observing that EDB indexes are used solely for lookups and never decrypted, we design ECTree, a cryptographic hash-based index structure in which each node is a compressible bit-string identifier that conceals plaintext keys. ECTree enables logarithmic-time encrypted search via a novel membership testing mechanism. To address false positives arising in dynamic workloads, we introduce Directed View Check (DVC), which detects inaccuracies and avoids redundant traversals. Additionally, ECTree’s Merkle-tree-like structure supports encrypted query authentication, resisting server compromise. Extensive evaluations show that ECStore can achieve up to 94.7% lower latency and 10.5x higher throughput on popular benchmarks compared to notable EDBs.},
  archive      = {J_TKDE},
  author       = {Tianxiang Shen and Ji Qi and Ning Jia and Haoze Song and Xiapu Luo and Sen Wang and Heming Cui},
  doi          = {10.1109/TKDE.2025.3583470},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5171-5187},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ECStore: Achieving efficient and compressible indexing on outsourced encrypted databases},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSHCL: Dual-state hypergraph contrastive learning for information diffusion prediction. <em>TKDE</em>, <em>37</em>(9), 5158-5170. (<a href='https://doi.org/10.1109/TKDE.2025.3581419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion prediction is a crucial task for comprehending the dissemination process of information. Although this problem has received significant attention recently, most of the state-of-the-arts primarily focus on the modelling of information cascades, while neglecting the implicit social relations between users in the social network and failing to adequately model the interrelations between the user social network and information cascades. To tackle the aforementioned issues, in this work, we propose a Dual-State Hypergraph Contrastive Learning model (${\sf DSHCL}$). Specifically, we first propose to construct a social hypergraph based on the social network to capture the implicit social relations. Then, for capturing the cascade level correlations among users, we generate the dual-state (i.e., static and dynamic) user representations from the user social hypergraph and information cascades. Finally, we exploit contrastive learning to model the interplay between the social network and information cascades by discriminating the dual-state representations generated from them. We conduct an empirical assessment of DSHCL across four publicly available datasets, and the findings underscore the DSHCL’s superiority and the efficacy of its components.},
  archive      = {J_TKDE},
  author       = {Tianyang Shao and Weixin Zeng and Xiang Zhao},
  doi          = {10.1109/TKDE.2025.3581419},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5158-5170},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DSHCL: Dual-state hypergraph contrastive learning for information diffusion prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepNM: Incremental graph matching based on sinkhorn similarity. <em>TKDE</em>, <em>37</em>(9), 5141-5157. (<a href='https://doi.org/10.1109/TKDE.2025.3583059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph matching is a critical task with diverse real-world applications. Current cutting-edge methodologies incorporate GNN (Graph Neural Network) combined with incremental anchor refinement, calculating the matching similarity directly via node embeddings. However, the direct similarity computation based on aggregated embeddings from GNN may obscure the distinctiveness of nodes within a localized region. In addition, the possible wrongly added anchor pairs in the iterations and the lack of capturing the relationships to anchors may further affect the performance. In order to tackle these challenges, this paper proposes a method named DeepNM, which attempts to find node matching based on their neighbors’ similarities. Specifically, DeepNM introduces a Sinkhorn-based similarity on a node’s neighborhood’s embeddings, which serves as both a training loss and a matching metric tailored to the graph matching problem. Additionally, we demonstrate that the Sinkhorn-based similarity, which relies on common neighbor statistics, is highly resilient to inaccurately identified anchor pairs within the context of incremental graph matching. Our comprehensive experiments on synthetic and real-world datasets demonstrate that DeepNM, compatible with the incremental graph matching paradigm, excels particularly well at matching graphs where common neighbors provide good matches. Applying the DeepNM pipeline to real social networks results in a 6% improvement, and applying the Sinkhorn similarity on knowledge graphs results in an average improvement of 1.7% over the best baseline.},
  archive      = {J_TKDE},
  author       = {Yikuan Xia and Jiazun Chen and Xinchi Li and Jun Gao},
  doi          = {10.1109/TKDE.2025.3583059},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5141-5157},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DeepNM: Incremental graph matching based on sinkhorn similarity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep probabilistic graph matching. <em>TKDE</em>, <em>37</em>(9), 5127-5140. (<a href='https://doi.org/10.1109/TKDE.2025.3578989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous learning-based graph matching algorithms solve the quadratic assignment problem (QAP) by dropping one or more of the matching constraints and adopting a relaxed assignment solver to obtain sub-optimal correspondences. Such relaxation may actually weaken the original graph matching problem, and in turn hurt the matching performance. In this paper, we propose a deep learning-based graph matching framework that works for the original QAP without compromising on the matching constraints. In particular, we design an affinity-assignment prediction network to jointly learn the pairwise affinity and estimate the node assignments, and we then develop a differentiable solver inspired by the probabilistic perspective of the pairwise affinities. Aiming to obtain better matching results, the probabilistic solver refines the estimated assignments in an iterative manner to impose both discrete and one-to-one matching constraints. The proposed method is trained in a supervised manner, evaluated on several benchmarks related to semantic keypoint corresponding, matching of social networks and pure QAP instances. In all experiment, it exhibits state-of-the-art matching performance on all benchmarks.},
  archive      = {J_TKDE},
  author       = {He Liu and Tao Wang and Congyan Lang and Yidong Li and Haibin Ling},
  doi          = {10.1109/TKDE.2025.3578989},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5127-5140},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep probabilistic graph matching},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep graph anomaly detection: A survey and new perspectives. <em>TKDE</em>, <em>37</em>(9), 5106-5126. (<a href='https://doi.org/10.1109/TKDE.2025.3581578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD), which aims to identify unusual graph instances (e.g., nodes, edges, subgraphs, or graphs), has attracted increasing attention in recent years due to its significance in a wide range of applications. Deep learning approaches, graph neural networks (GNNs) in particular, have been emerging as a promising paradigm for GAD, owing to its strong capability in capturing complex structure and/or node attributes in graph data. Considering the large number of methods proposed for GNN-based GAD, it is of paramount importance to summarize the methodologies and findings in the existing GAD studies, so that we can pinpoint effective model designs for tackling open GAD problems. To this end, in this work we aim to present a comprehensive review of deep learning approaches for GAD. Existing GAD surveys are focused on task-specific discussions, making it difficult to understand the technical insights of existing methods and their limitations in addressing some unique challenges in GAD. To fill this gap, we first discuss the problem complexities and their resulting challenges in GAD, and then provide a systematic review of current deep GAD methods from three novel perspectives of methodology, including GNN backbone design, proxy task design for GAD, and graph anomaly measures. To deepen the discussions, we further propose a taxonomy of 13 fine-grained method categories under these three perspectives to provide more in-depth insights into the model designs and their capabilities. To facilitate the experiments and validation of the GAD methods, we also summarize a collection of widely-used datasets for GAD and empirical performance comparison on these datasets. We further discuss multiple important open research problems in GAD to inspire more future high-quality research in this area.},
  archive      = {J_TKDE},
  author       = {Hezhe Qiao and Hanghang Tong and Bo An and Irwin King and Charu Aggarwal and Guansong Pang},
  doi          = {10.1109/TKDE.2025.3581578},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5106-5126},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep graph anomaly detection: A survey and new perspectives},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>AE: Data-decoupled active experts promote one-class anomaly discovery. <em>TKDE</em>, <em>37</em>(9), 5093-5105. (<a href='https://doi.org/10.1109/TKDE.2025.3582848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) suffers from severe performance decrease when dealing with corrupted datasets. By querying limited annotations from an oracle, active learning is prevalent in mitigating this problem. However, previous work ignores the particularity of the AD task on the one-class setting, where wrong pseudo-annotations of anomaly noise will mislead the active inference results. To address this challenge, we propose D$^{2}$AE, a novel active AD framework through Decoupling Data pools between training and inference process for Active Experts. Specifically, we design a data-splitting module named as DSS to obtain diverse subsets and weaken the mutual interference of similar anomalies. To decouple the data, we propose an Independent Active Experts (IAE) module formed by multiple expert replications, on which each data subset is trained by one separate expert (squad) and inferred by the other non-training ones. To further improve the efficiency of data utilization, we propose Active Expert Squad (AES) beyond IAE by introducing Mixture-of-Experts. The commonality and specificity between expert squads promote model training and active query, respectively. We conduct extensive experiments on various image, tabular, and NLP datasets. Experimental results show the superiority of our solution compared with existing methods.},
  archive      = {J_TKDE},
  author       = {Chao Feng and Ziyi Zhao and Hongxing Wang},
  doi          = {10.1109/TKDE.2025.3582848},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5093-5105},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {D$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>AE: Data-decoupled active experts promote one-class anomaly discovery},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic data distillation semi-supervised learning for multi-modal emotion recognition. <em>TKDE</em>, <em>37</em>(9), 5078-5092. (<a href='https://doi.org/10.1109/TKDE.2025.3581786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal emotion recognition (MER) integrates multi-modal signals to help computers comprehensively understand human emotions, which is a crucial technology in human-computer interactions. However, the amount of labeled multi-modal emotion data is small and limits MER performance due to its expensive manual annotations. Meanwhile, semi-supervised learning (SSL) methods improving MER models with enormous unlabeled data suffer from confirmation bias, resulting in biased data distribution. To tackle these challenges, this paper proposes a cyclic data distillation semi-supervised learning (CDD-SSL) for MER tasks. CDD-SSL leverages multiple pre-trained unimodal teacher models and confidence-boosting pseudo-labelling (CBPL) to boost the confidence of multi-modal ensemble outputs and distill reliable and class-representative data from numerous unlabeled data. It then utilizes reliable and less-biased data to train a multi-modal student model and provides feedback to update all unimodal teacher models. CDD-SSL is a cyclic teacher-student framework with a feedback mechanism that gradually mitigates confirmation bias and obtains an effective MER model. Experimental results on four benchmark datasets demonstrate that CDD-SSL achieves superior performance over both the semi-supervised methods and the state-of-the-art fully-supervised models in MER tasks.},
  archive      = {J_TKDE},
  author       = {Shuzhen Li and Tong Zhang and C. L. Philip Chen},
  doi          = {10.1109/TKDE.2025.3581786},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5078-5092},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cyclic data distillation semi-supervised learning for multi-modal emotion recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRATE: Privacy-preserving travel time estimation. <em>TKDE</em>, <em>37</em>(9), 5063-5077. (<a href='https://doi.org/10.1109/TKDE.2025.3583004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel Time Estimation (TTE) stands as a cornerstone of efficient transportation systems. However, the critical imperative of privacy preservation within the TTE context remains notably underexplored. This gap underscores the pressing necessity for innovative solutions that prioritize the safeguarding of users’ geo-privacy, particularly in light of the expanding prevalence of data-driven TTE algorithms. In this paper, a novel privacy-preserving TTE framework, CRATE, is proposed to ensure comprehensive privacy preservation for TTE without compromising service quality. CRATE achieves this objective by identifying random routes within a transportation network that yield identical travel times to the actual, privacy-rich route. This is accomplished through exploiting the embedding representations for road segments and routes, followed by the development of a highly efficient heuristic for random route generation. Furthermore, a travel time aggregation and calibration model is devised to enhance estimation accuracy while upholding user privacy. Case studies conducted on three real-world vehicular trajectory datasets demonstrate that CRATE attains comparable estimation accuracy to state-of-the-art non-privacy-preserving TTE algorithms while maintaining strict privacy protection. Additionally, CRATE’s efficiency is showcased through deployment on both high- and low-end mobile handsets spanning the past decade.},
  archive      = {J_TKDE},
  author       = {James Jianqiao Yu},
  doi          = {10.1109/TKDE.2025.3583004},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5063-5077},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CRATE: Privacy-preserving travel time estimation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConvD: Attention enhanced dynamic convolutional embeddings for knowledge graph completion. <em>TKDE</em>, <em>37</em>(9), 5049-5062. (<a href='https://doi.org/10.1109/TKDE.2025.3582243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs often suffer from incompleteness issues, which can be alleviated through information completion. However, current state-of-the-art deep knowledge convolutional embedding models rely on external convolution kernels and conventional convolution processes, which limits the feature interaction capability of the model. This paper introduces a novel dynamic convolutional embedding model, named ConvD, which directly reshapes relation embeddings into multiple internal convolution kernels. This approach effectively enhances the feature interactions between relation embeddings and entity embeddings. Simultaneously, we incorporate a priori knowledge-optimized attention mechanism that assigns distinct contribution weights to multiple relational convolution kernels during dynamic convolution, further boosting the expressive power of the model. Extensive experiments on various datasets show that our proposed model consistently outperforms the state-of-the-art baseline methods, with average improvements ranging from 3.28% to 14.69% across all the evaluation metrics, while the number of parameters is reduced by 50.66% to 85.40% compared to other state-of-the-art models.},
  archive      = {J_TKDE},
  author       = {Wenbin Guo and Zhao Li and Xin Wang and Zirui Chen and Jun Zhao and Jianxin Li and Ye Yuan},
  doi          = {10.1109/TKDE.2025.3582243},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5049-5062},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ConvD: Attention enhanced dynamic convolutional embeddings for knowledge graph completion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive variational group recommendation with data-agnostic augmentation. <em>TKDE</em>, <em>37</em>(9), 5034-5048. (<a href='https://doi.org/10.1109/TKDE.2025.3581571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group recommendation aims to recommend desired items for a group of users. Existing methods mainly adopt deterministic networks to represent groups as fixed-point vectors, assuming their preferences be highly close to these vectors in interest space. However, each group tends to have various interests, which cannot be fully captured by fixed-point vectors and thus calls for probabilistic modeling of interests as density instead. Although this can be supported by Variational AutoEncoder (VAE), interaction data in group recommendation are highly sparse and insufficient for VAE model training, resulting in high risks of posterior collapse and deficiency in personalization. To this end, this paper proposes a contrastive variational learning model boosted by variational model augmentation and an easy-to-hard paradigm. Specifically, VAE with tailored attention is first employed to represent group preferences as variational vectors for probabilistic preference modeling. Additionally, we conduct data-agnostic augmentation via learnable variational dropout, which removes redundant or irrelevant neurons in VAE to generate meaningful augmented views adequately for contrastive learning in spite of data sparsity. Difficulty-aware negative sampling is further applied to generate high-quality negative samples adapting to varying requirements of task difficulty according to the training process. Finally, we utilize density-based variational alignment to guide the optimization process of contrastive learning. Experiments on four real-world datasets are conducted to demonstrate the significant performance improvements of our model compared with SOTA methods for group recommendation.},
  archive      = {J_TKDE},
  author       = {Wen Yang and Jiajie Xu and Rui Zhou and Lu Chen and Jianxin Li and Pengpeng Zhao and Chengfei Liu},
  doi          = {10.1109/TKDE.2025.3581571},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5034-5048},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Contrastive variational group recommendation with data-agnostic augmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative knowledge fusion: A novel method for multi-task recommender systems via LLMs. <em>TKDE</em>, <em>37</em>(9), 5017-5033. (<a href='https://doi.org/10.1109/TKDE.2025.3581706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the impressive general intelligence of large language models (LLMs), there has been a growing trend to integrate them into recommender systems to gain a more profound insight into human interests and intentions. Existing LLMs-based recommender systems primarily leverage item attributes and user interaction histories in textual format, improving the single task like rating prediction or explainable recommendation. Nevertheless, these approaches underestimate the crucial contribution of traditional collaborative signals in discerning users’ profound intentions and disregard the interrelatedness among tasks. To address these limitations, we introduce a novel framework known as CKF, specifically developed to boost multi-task recommendations via personalized collaborative knowledge fusion into LLMs. Specifically, to enhance collaborative signal integration, we develop a meta-network that creates personalized mapping bridges for each user. This enables the seamless incorporation of trained collaborative filtering embeddings into structured prompt templates, significantly boosting the LLM’s understanding of user interests. To investigate the intrinsic relationship among diverse recommendation tasks, we develop Multi-LoRA, a new parameter-efficient approach for multi-task optimization, adept at distinctly segregating task-shared and task-specific knowledge. This semantic approach forges a connection between LLMs and recommendation scenarios, while simultaneously enriching the supervisory signal through mutual knowledge transfer among various tasks. Extensive experiments and in-depth robustness analyses across four common recommendation tasks on four large public data sets substantiate our effectiveness.},
  archive      = {J_TKDE},
  author       = {Chuang Zhao and Xing Su and Ming He and Hongke Zhao and Jianping Fan and Xiaomeng Li},
  doi          = {10.1109/TKDE.2025.3581706},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5017-5033},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Collaborative knowledge fusion: A novel method for multi-task recommender systems via LLMs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond accuracy: Decision transformers for reward-driven multi-objective recommendations. <em>TKDE</em>, <em>37</em>(9), 5004-5016. (<a href='https://doi.org/10.1109/TKDE.2025.3582506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accuracy has been the primary benchmark for assessing recommenders learned from sequential interactions. To improve user experience by diverse and novel recommendation, our paper focuses on Multi-objective Sequential Recommendation (MOSR) to balance these conflicting objectives. Although a few studies leveraged reinforcement learning (RL) to solve MOSR, these methods can lead to sub-optimal results. First, traditional offline RL approach typically optimizes various objectives independently via multiple RL heads, accumulating prediction errors and leading to unstable performance. Furthermore, the offline policy cannot dynamically adjust objective weights during the inference stage, limiting adaptability to varying contexts. To this end, we introduce Multi-objective Decision Transformer for Reward-driven Recommendation (MODT4R), a novel framework that addresses MOSR as sequence modeling problem. First, we propose a user trajectory to capture user state transitions along with their multi-objective interests, represented by sequential expected cumulative rewards (returns). Moreover, the supervised learning paradigm makes the training process more stable while naturally integrating multi-objective optimization into sequence modeling by using multiple returns as conditional inputs. During inference, a score function is used to adjust the weights of diversity and novelty. Experimental evaluations on real-world datasets demonstrate that MODT4R significantly enhances diversity and novelty while maintaining accuracy compared to existing state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Jie Wang and Alexandros Karatzoglou and Ioannis Arapakis and Joemon M. Jose and Xuri Ge},
  doi          = {10.1109/TKDE.2025.3582506},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {5004-5016},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Beyond accuracy: Decision transformers for reward-driven multi-objective recommendations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated prompting for non-overlapping cross-domain sequential recommendation. <em>TKDE</em>, <em>37</em>(9), 4990-5003. (<a href='https://doi.org/10.1109/TKDE.2025.3589721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain Recommendation (CR) has been extensively studied in recent years to alleviate the data sparsity issue in recommender systems by utilizing different domain information. In this work, we focus on the more general Non-overlapping Cross-domain Sequential Recommendation (NCSR) scenario. Non-overlapping Cross-domain Sequential Recommendation (NCSR) is challenging because there are no overlapped entities (e.g., users and items) between domains, and there is only users’ implicit feedback and no content information. Previous Cross-domain Recommendation (CR) methods cannot solve NCSR well, since (1) they either need extra content to align domains or need explicit domain alignment constraints to reduce the domain discrepancy from domain-invariant features, (2) they pay more attention to users’ explicit feedback (i.e., users’ rating data) and cannot well capture their sequential interaction patterns, (3) they usually do a single-target cross-domain recommendation task and seldom investigate the dual-target ones. Considering the above challenges, we propose Prompt Learning-based Cross-domain Recommender (PLCR), an automated prompting-based recommendation framework for the NCSR task. Specifically, to address the challenge (1), Prompt Learning-based Cross-domain Recommender (PLCR) resorts to learning domain-invariant and domain-specific representations via its prompt learning component, where the domain alignment constraint is discarded. For challenges (2) and (3), PLCR introduces a pre-trained sequence encoder to learn users’ sequential interaction patterns, and conducts a dual-learning target with a separation constraint to enhance recommendations in both domains. Our empirical study on two sub-collections of Amazon demonstrates the advance of PLCR compared with some related SOTA methods.},
  archive      = {J_TKDE},
  author       = {Lei Guo and Chunxiao Wang and Xinhua Wang and Lei Zhu and Hongzhi Yin},
  doi          = {10.1109/TKDE.2025.3589721},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4990-5003},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Automated prompting for non-overlapping cross-domain sequential recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced marked cuckoo filter for multi-set multi-membership querying in distributed system. <em>TKDE</em>, <em>37</em>(9), 4977-4989. (<a href='https://doi.org/10.1109/TKDE.2025.3579571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of multi-set membership query is a fundamental task in the fields of distributed systems and computer networks. It entails identifying which sets, out of n sets $S_{0}, S_{1},{\ldots }, S_{n-1}$, in a Multi Set Multi-Membership Querying (MS-MMQ) contain a given element q. To address this problem while minimizing space usage, probabilistic data structures, such as cuckoo filters, are commonly employed. However, existing sketch data structures struggle to effectively balance scalability and query efficiency. To address this challenge, we introduce an enhanced marked cuckoo filter (EMCF), which enhances support for MS-MMQ scenarios by incorporating set markers after the fingerprint field. Additionally, it grants horizontal scalability and collaborative search capabilities at the filter level through the inclusion of global markers. Furthermore, we have developed an optimized variant of the enhanced marked cuckoo filter (EMCF-V) for multi-set scenarios to achieve space optimization. Experimental results using real-world datasets demonstrate that EMCF exceeds CSC-CF by more than 10 times in terms of speed, and EMCF-V exhibits a 33.3% higher query efficiency than CSC-CF methods, particularly in multiset scenarios.},
  archive      = {J_TKDE},
  author       = {Zhaolin Ma and Jiali You and Haojiang Deng},
  doi          = {10.1109/TKDE.2025.3579571},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4977-4989},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An enhanced marked cuckoo filter for multi-set multi-membership querying in distributed system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient fuzzy system for complex query answering on knowledge graphs. <em>TKDE</em>, <em>37</em>(9), 4962-4976. (<a href='https://doi.org/10.1109/TKDE.2025.3581959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex Query Answering (CQA) on knowledge graphs is a fundamental yet challenging task, which can be formalized as answering a subset of first-order logic queries containing logical conjunction, disjunction, negation, and existential quantifiers. Recent research reveals that Link Predictors (LPs) trained on 1-hop queries can generalize to various types of complex queries. However, existing methods neglect crucial characteristics of LPs’ outputs, including the effects of highly relevant entities and uncertainty. What’s worse, as they model logical operations by fuzzy set operations, these methods suffer from problems like inflexibility, sensitivity to noise, and inconsistency with priority in human cognition, which limits their performance, especially on queries with negation. To address these challenges, we propose an efficient fuzzy system for CQA that requires no extra training overhead and is plug-and-play with existing LP-based methods. First, we expand the output of LPs by two complementary membership functions of weak and strong relevance, which help to distinguish the target entities from highly relevant and irrelevant entities. Subsequently, we model logical operations through fuzzy rule bases and infer the final predictions via defuzzification, providing a flexible and tractable scheme for modeling logical operations. Finally, the effectiveness of the proposed fuzzy system is validated by its outstanding performance on benchmark datasets when compared to state-of-the-art methods. The source code of our proposed method is available at https://github.com/luyy9apples/FuzzSys-CQA.},
  archive      = {J_TKDE},
  author       = {Yuyin Lu and Hegang Chen and Yanghui Rao and Jianxing Yu and Wen Hua and Qing Li},
  doi          = {10.1109/TKDE.2025.3581959},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4962-4976},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An efficient fuzzy system for complex query answering on knowledge graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADEdgeDrop: Adversarial edge dropping for robust graph neural networks. <em>TKDE</em>, <em>37</em>(9), 4948-4961. (<a href='https://doi.org/10.1109/TKDE.2025.3586369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Graph Neural Networks (GNNs) have exhibited the powerful ability to gather graph-structured information from neighborhood nodes via various message-passing mechanisms, the performance of GNNs is limited by poor generalization and fragile robustness caused by noisy and redundant graph data. As a prominent solution, Graph Augmentation Learning (GAL) has recently received increasing attention in the literature. Among the existing GAL approaches, edge-dropping methods that randomly remove edges from a graph during training are effective techniques to improve the robustness of GNNs. However, randomly dropping edges often results in bypassing critical edges. Consequently, the effectiveness of message passing is weakened. In this paper, we propose a novel adversarial edge-dropping method (ADEdgeDrop) that leverages an adversarial edge predictor guiding the removal of edges, which can be flexibly incorporated into diverse GNN backbones. Employing an adversarial training framework, the edge predictor utilizes the line graph transformed from the original graph to estimate the edges to be dropped, which improves the interpretability of the edge-dropping method. The proposed ADEdgeDrop is optimized alternately by stochastic gradient descent and projected gradient descent. Comprehensive experiments on eight graph benchmark datasets demonstrate that the proposed ADEdgeDrop outperforms state-of-the-art baselines across various GNN backbones, demonstrating improved generalization and robustness.},
  archive      = {J_TKDE},
  author       = {Zhaoliang Chen and Zhihao Wu and Ylli Sadikaj and Claudia Plant and Hong-Ning Dai and Shiping Wang and Yiu-Ming Cheung and Wenzhong Guo},
  doi          = {10.1109/TKDE.2025.3586369},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4948-4961},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ADEdgeDrop: Adversarial edge dropping for robust graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A universal subhypergraph-assisted embedding framework for both homogeneous and heterogeneous networks. <em>TKDE</em>, <em>37</em>(9), 4935-4947. (<a href='https://doi.org/10.1109/TKDE.2025.3581963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, most complex systems can be generally modelled as homogenous or heterogenous networks. Therefore, downstream tasks (e.g., node/graph classification, node clustering) based on these two types of graphs become ubiquitous and have drawn considerable attention in recent years. Existing literatures on node classification mainly focus on either homogeneous or heterogeneous graphs, while research on effectively carrying out node classification tasks on both types of graphs simultaneously is still under-exploited. To fill this gap, we propose a universal Graph Neural Network architecture based on Subgraph and Subhypergraph (SS-GNN) with feature-enhanced strategy for node embedding on both homogeneous and heterogeneous graphs. Through construction of subgraph and subhypergraph with same-class nodes, our model can simultaneously deal with homogeneous and heterogeneous graphs. Graph attention modules are especially designed to embed subgraphs of same-class nodes to learn the internal topological structure and local community structure within the original graph. Additionally, to capture high-order features of graph and enhance the embedding representations of nodes, we also utilize hypergraph attention modules to embed subhypergraphs of same-class nodes. Unlike other approaches that rely on pre-defined meta-paths, our model can be readily applied to most real-world applications without requiring any domain knowledge. Finally, we conduct extensive experiments on three homogeneous and three heterogeneous real-world graphs to demonstrate the effectiveness of SS-GNN. The experimental results for node classification and clustering tasks not only show the superior performance of our proposed model compared to state-of-the-art baselines, but also demonstrate its potentially good interpretability for graph analysis. This work may provide some enlightening insights to the study on universality of graph foundation model.},
  archive      = {J_TKDE},
  author       = {Shibing Mo and Xiangyi Teng and Kai Wu and Jing Liu and Kaixin Yuan},
  doi          = {10.1109/TKDE.2025.3581963},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4935-4947},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A universal subhypergraph-assisted embedding framework for both homogeneous and heterogeneous networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A linguistic Z-number rule-based modeling framework considering knowledge reliability based on evidential reasoning rule. <em>TKDE</em>, <em>37</em>(9), 4920-4934. (<a href='https://doi.org/10.1109/TKDE.2025.3579716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expert knowledge holds a pivotal role in artificial intelligence models. Constrained by the subjectivity and ignorance of human cognition, it is imperfectly reliable. Modeling and decision-making driven by such knowledge may generate large risks. To this end, it is necessary to investigate a mechanism for handling such imperfectly reliable knowledge. In this paper, the reliability of knowledge is described as expert reliability. A novel rule-based modeling framework with expert reliability is proposed correspondingly, including the following four parts: modeling, reasoning, optimization and robustness analysis. The main works are: (1) Based on the transparent knowledge representation of belief rule base (BRB), a linguistic Z-number BRB (LZ-BRB) is proposed, where the linguistic Z-number quantitatively represents expert reliability. (2) An improved evidential reasoning (ER) rule is developed to obtain the inference result of the LZ-BRB model. (3) A data-driven parameter optimization model is designed to reduce modeling errors caused by imperfectly reliable knowledge. (4) The robustness analysis of expert reliability is performed to further analyze its influence on the inference result. Finally, a fiber optic gyro (FOG) health evaluation case verifies the proposed method.},
  archive      = {J_TKDE},
  author       = {Zheng Lian and Zhijie Zhou and Changhua Hu and Pengyun Ning and Zhichao Ming and Xiaoqin Liu},
  doi          = {10.1109/TKDE.2025.3579716},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4920-4934},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A linguistic Z-number rule-based modeling framework considering knowledge reliability based on evidential reasoning rule},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hidden key user discovery model for guided public opinion based on behavioral intentions and implicit relationships. <em>TKDE</em>, <em>37</em>(9), 4908-4919. (<a href='https://doi.org/10.1109/TKDE.2025.3589675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering hidden key users of leading topics plays an important role in opinion control and risk prevention. Aiming at the dynamic nature of key users’ intentions and other problems, a key user discovery model based on behavioral intentions and implicit relationships is proposed. First, to address the dynamic nature of key users’ intentions, the dynamic latent Dirichlet allocation method is introduced. This approach effectively mines topic evolution in text data, uncovering dynamic behavioral themes of key users and analyzing evolutionary relationships between topics. Meanwhile, incremental learning is introduced to quantify the dynamic behavioral intentions of key users more precisely. Second, a random wandering strategy based on user interaction degree and propagation depth is designed to address the hidden nature of user relationships. The strategy introduces the user interaction degree designed by the social cognition theory and the propagation depth designed by the propagation chain theory to better explore the hidden user interaction relationships. Finally, for the timeliness of key user identification, considering the advantage of dynamic evolution for real-time interaction, dynamic evolution is introduced to effectively analyze the dynamic structure of topic networks, and attention mechanism is introduced to improve the adaptivity of the model. The experiments show that this paper verifies the factuality of the existence of hidden key users dominating the promotion behind the guiding public opinion, and is more effective in tracing the hidden key users in the topics.},
  archive      = {J_TKDE},
  author       = {Rong Wang and Haichuan Zhou and Tun Li and Qian Li and Yunpeng Xiao},
  doi          = {10.1109/TKDE.2025.3589675},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {9},
  number       = {9},
  pages        = {4908-4919},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A hidden key user discovery model for guided public opinion based on behavioral intentions and implicit relationships},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UVTM: Universal vehicle trajectory modeling with ST feature domain generation. <em>TKDE</em>, <em>37</em>(8), 4894-4907. (<a href='https://doi.org/10.1109/TKDE.2025.3570428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle movement is frequently captured in the form of GPS trajectories, i.e., sequences of timestamped GPS locations. Such data is widely used for various tasks such as travel-time estimation, trajectory recovery, and trajectory prediction. A universal vehicle trajectory model could be applied to different tasks, removing the need to maintain multiple specialized models, thereby reducing computational and storage costs. However, creating such a model is challenging when the integrity of trajectory features is compromised, i.e., in scenarios where only partial features are available or the trajectories are sparse. To address these challenges, we propose the Universal Vehicle Trajectory Model (UVTM), which can effectively adapt to different tasks without excessive retraining. UVTM incorporates two specialized designs. First, it divides trajectory features into three distinct domains. Each domain can be masked and generated independently to accommodate tasks with only partially available features. Second, UVTM is pre-trained by reconstructing dense, feature-complete trajectories from sparse, feature-incomplete counterparts, enabling strong performance even when the integrity of trajectory features is compromised. Experiments involving four representative trajectory-related tasks on three real-world vehicle trajectory datasets provide insight into the performance of UVTM and offer evidence that it is capable of meeting its objectives.},
  archive      = {J_TKDE},
  author       = {Yan Lin and Jilin Hu and Shengnan Guo and Bin Yang and Christian S. Jensen and Youfang Lin and Huaiyu Wan},
  doi          = {10.1109/TKDE.2025.3570428},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4894-4907},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {UVTM: Universal vehicle trajectory modeling with ST feature domain generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards DS-NER: Unveiling and addressing latent noise in distant annotations. <em>TKDE</em>, <em>37</em>(8), 4880-4893. (<a href='https://doi.org/10.1109/TKDE.2025.3567204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distantly supervised named entity recognition (DS-NER) has emerged as a cheap and convenient alternative to traditional human annotation methods, enabling the automatic generation of training data by aligning text with external resources. Despite the many efforts in noise measurement methods, few works focus on the latent noise distribution between different distant annotation methods. In this work, we explore the effectiveness and robustness of DS-NER by two aspects: (1) distant annotation techniques, which encompasses both traditional rule-based methods and the innovative large language model supervision approach, and (2) noise assessment, for which we introduce a novel framework. This framework addresses the challenges by distinctly categorizing them into the unlabeled-entity problem (UEP) and the noisy-entity problem (NEP), subsequently providing specialized solutions for each. Our proposed method achieves significant improvements on eight real-world distant supervision datasets originating from three different data sources and involving four distinct annotation techniques, confirming its superiority over current state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Yuyang Ding and Dan Qiao and Juntao Li and Jiajie Xu and Pingfu Chao and Xiaofang Zhou and Min Zhang},
  doi          = {10.1109/TKDE.2025.3567204},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4880-4893},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards DS-NER: Unveiling and addressing latent noise in distant annotations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Top-K representative search for comparative tree summarization. <em>TKDE</em>, <em>37</em>(8), 4873-4879. (<a href='https://doi.org/10.1109/TKDE.2025.3565845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data summarization aims at utilizing a small-scale summary to represent massive datasets as a whole, which is useful for visualization and information sipped generation. However, most existing studies of hierarchical summarization only work on one single tree by selecting $k$ representative nodes, which neglects an important problem of comparative summarization on two trees. In this paper, given two trees with the same topology structure and different node weights, we aim at finding $k$ representative nodes, where $k_{1}$ nodes summarize the common relationship between them and $k_{2}$ nodes highlight significantly different subtrees meanwhile satisfying $k_{1}+k_{2}=k$. To optimize summarization results, we introduce a scaling coefficient for balancing the summary view between two subtrees in terms of similarity and difference. Additionally, we propose a novel definition based on the Hellinger distance to quantify the node distribution difference between two subtrees. We present a greedy algorithm SVDT to find high-quality results with approximation guaranteed in an efficient way. Furthermore, we explore an extension of our comparative summarization to handle two trees with different structures. Extensive experiments demonstrate the effectiveness and efficiency of our SVDT algorithm against existing summarization competitors.},
  archive      = {J_TKDE},
  author       = {Yuqi Chen and Xin Huang and Bilian Chen},
  doi          = {10.1109/TKDE.2025.3565845},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4873-4879},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Top-K representative search for comparative tree summarization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal and spatial analysis in early sepsis prediction via causal disentanglements. <em>TKDE</em>, <em>37</em>(8), 4860-4872. (<a href='https://doi.org/10.1109/TKDE.2025.3569584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is one of the main causes of death in ICU patients, and accurate and stable early prediction is essential for clinical intervention. Existing methods mostly rely on traditional time series models (e.g., LSTM, Transformer) or clinical scoring criteria (e.g., SOFA, qSOFA), but face two major challenges: 1) spurious correlations in the data affect the robustness of the model; 2) Lack of modeling the underlying causal relationships in the data space. We propose a Serialized Causal Disentanglement Model (SCDM) that decouples latent variables into sepsis-related factors ($u$), other disease-related factors ($v$), and irrelevant confounders ($s$ ). Based on the MIMIC-IV v2.2 dataset (3,511 positive samples and 17,538 negative samples), SCDM took patient clinical indicators, personal information, and clinical notes as input, and achieved an AUC of 0.765-0.928in the prediction task 48 to 0 hours before the onset of sepsis. The performance is significantly better than the baseline models (e.g., Transformer's 0.662-0.910, MGP-AttTCN's 0.692-0.913). Experiments show that optimizing the time window (5 hours of continuous observation) and variable selection (45 key indicators) can improve the performance of the model. The effectiveness of causal unwinding is verified by the visualization of Grad CAM and t-SNE, key clinical indicators such as platelet count, lactic acid, and respiratory rate are further identified to provide interpretable decision support for doctors. Our study provides a high-precision and interpretable causal disentanglement framework for early prediction of sepsis, which is expected to promote the development of intelligent diagnosis and treatment in the ICU.},
  archive      = {J_TKDE},
  author       = {Qiang Li and Dongchen Li and Weizhi Nie and He Jiao and Zhenhua Wu and Anan Liu},
  doi          = {10.1109/TKDE.2025.3569584},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4860-4872},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Temporal and spatial analysis in early sepsis prediction via causal disentanglements},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-LLM+: Graph enhanced spatio-temporal large language models for traffic prediction. <em>TKDE</em>, <em>37</em>(8), 4846-4859. (<a href='https://doi.org/10.1109/TKDE.2025.3570705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a crucial component of data management systems, leveraging historical data to learn spatio-temporal dynamics for forecasting future traffic and enabling efficient decision-making and resource allocation. Despite efforts to develop increasingly complex architectures, existing traffic prediction models often struggle to generalize across diverse datasets and contexts, limiting their adaptability in real-world applications. In contrast to existing traffic prediction models, large language models (LLMs) progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose ST-LLM+, the graph enhanced spatio-temporal large language models for traffic prediction. Through incorporating a proximity-based adjacency matrix derived from the traffic network into the calibrated LLMs, ST-LLM+ captures complex spatio-temporal dependencies within the traffic network. The Partially Frozen Graph Attention (PFGA) module is designed to retain global dependencies learned during LLMs pre-training while modeling localized dependencies specific to the traffic domain. To reduce computational overhead, ST-LLM+ adopts the LoRA-augmented training strategy, allowing attention layers to be fine-tuned with fewer learnable parameters. Comprehensive experiments on real-world traffic datasets demonstrate that ST-LLM+ outperforms state-of-the-art models. In particular, ST-LLM+ also exhibits robust performance in both few-shot and zero-shot prediction scenarios. Additionally, our case study demonstrates that ST-LLM+ captures global and localized dependencies between stations, verifying its effectiveness for traffic prediction tasks.},
  archive      = {J_TKDE},
  author       = {Chenxi Liu and Kethmi Hirushini Hettige and Qianxiong Xu and Cheng Long and Shili Xiang and Gao Cong and Ziyue Li and Rui Zhao},
  doi          = {10.1109/TKDE.2025.3570705},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4846-4859},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ST-LLM+: Graph enhanced spatio-temporal large language models for traffic prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STDA: Spatio-temporal deviation alignment learning for cross-city fine-grained urban flow inference. <em>TKDE</em>, <em>37</em>(8), 4833-4845. (<a href='https://doi.org/10.1109/TKDE.2025.3565504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained urban flow inference (FUFI) is crucial for traffic management, as it infers high-resolution urban flow maps from coarse-grained observations. Existing FUFI methods typically focus on a single city and rely on comprehensive training with large-scale datasets to achieve precise inferences. However, data availability in developing cities may be limited, posing challenges to the development of well-performing models. To address this issue, we propose cross-city fine-grained urban flow inference, which aims to transfer spatio-temporal knowledge from data-rich cities to data-scarce areas using meta-transfer learning. This paper devises a Spatio-Temporal Deviation Alignment (STDA) framework to mitigate spatio-temporal distribution deviations and urban structural deviations between multiple source cities and the target city. Furthermore, STDA presents a cross-city normalization method that adaptively combines batch and instance normalization to maintain consistency between city-variant and city-invariant features. Besides, we design an urban structure alignment module to align spatial topological differences across cities. STDA effectively reduces distribution and structural deviations among different datasets while avoiding negative transfer. Extensive experiments conducted on three real-world datasets demonstrate that STDA consistently outperforms state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Min Yang and Xiaoyu Li and Bin Xu and Xiushan Nie and Muming Zhao and Chengqi Zhang and Yu Zheng and Yongshun Gong},
  doi          = {10.1109/TKDE.2025.3565504},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4833-4845},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {STDA: Spatio-temporal deviation alignment learning for cross-city fine-grained urban flow inference},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAGoG: Similarity-aware graph of graphs neural networks for multivariate time series classification. <em>TKDE</em>, <em>37</em>(8), 4820-4832. (<a href='https://doi.org/10.1109/TKDE.2025.3572216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series Classification (MTSC) has important research significance and practical value. Deep learning models have achieved considerable success in addressing MTSC problems. However, a key challenge faced by existing classification models is how to effectively consider the correlations between time series instances and across channels simultaneously, as well as how to capture the dynamic of these inter-channel correlations over time. Current methods often fall short in these aspects: on one hand, they fail to fully account for the combined effects of inter-instance and inter-channel correlations; on the other hand, they largely overlook the dynamic nature of how inter-channel correlations change over time. To address these issues, we propose a novel graph neural network model, called Similarity-Aware Graph of Graphs neural networks (SAGoG), for multivariate time series classification. This model can comprehensively consider the dependencies between channel-level and instance-level time series, it dynamically learns dependency features through graph structure evolution and graph pooling layers. We conduct experiments on the UEA dataset to validate the SAGoG model, and the results demonstrate its outstanding performance in multivariate time series classification tasks.},
  archive      = {J_TKDE},
  author       = {Shun Wang and Yong Zhang and Xuanqi Lin and Yongli Hu and Qingming Huang and Baocai Yin},
  doi          = {10.1109/TKDE.2025.3572216},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4820-4832},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SAGoG: Similarity-aware graph of graphs neural networks for multivariate time series classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust tensor completion with side information. <em>TKDE</em>, <em>37</em>(8), 4805-4819. (<a href='https://doi.org/10.1109/TKDE.2025.3566441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although robust tensor completion has been extensively studied, the effect of incorporating side information has not been explored. In this article, we fill this gap by developing a novel high-order robust tensor completion model that incorporates both latent and explicit side information. We base our model on the transformed t-product because the corresponding tensor tubal rank can characterize the inherent low-rank structure of a tensor. We study the effect of side information on sample complexity and prove that our model needs fewer observations than other tensor recovery methods when side information is perfect. This theoretically shows that informative side information is beneficial for learning. Extensive experimental results on synthetic and real data further demonstrate the superiority of the proposed method over several popular alternatives. In particular, we evaluate the performance of our solution based on two important applications, namely, link prediction in signed networks and rating prediction in recommender systems. We show that the proposed model, which manages to exploit side information in learning, outperforms other methods in the learning of such low-rank tensor data. Furthermore, when dealing with varying dimensions, we also design an online robust tensor completion with side information algorithm and validate its effectiveness using a real-world traffic dataset in the supplementary material.},
  archive      = {J_TKDE},
  author       = {Yao Wang and Qianxin Yi and Yiyang Yang and Shanxing Gao and Shaojie Tang and Di Wang},
  doi          = {10.1109/TKDE.2025.3566441},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4805-4819},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust tensor completion with side information},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RobGC: Towards robust graph condensation. <em>TKDE</em>, <em>37</em>(8), 4791-4804. (<a href='https://doi.org/10.1109/TKDE.2025.3569629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing prevalence of large-scale graphs presents a significant challenge for Graph neural networks (GNNs) training due to their computational demands, limiting the applicability of GNNs in various scenarios. In response to this challenge, graph condensation (GC) is proposed as a promising acceleration solution, focusing on generating an informative compact graph that enables efficient training of GNNs while retaining performance. Despite the potential to accelerate GNN training, existing GC methods overlook the quality of large training graphs during both the training and inference stages. They indiscriminately emulate the training graph distributions, making the condensed graphs susceptible to noises within the training graph and significantly impeding the application of GC in intricate real-world scenarios. To address this issue, we propose robust graph condensation (RobGC), a plug-and-play approach for GC to extend the robustness and applicability of condensed graphs in noisy graph structure environments. Specifically, RobGC leverages the condensed graph as a feedback signal to guide the denoising process on the original training graph. A label propagation-based alternating optimization strategy is in place for the condensation and denoising processes, contributing to the mutual purification of the condensed graph and training graph. Additionally, as a GC method designed for inductive graph inference, RobGC facilitates test-time graph denoising by leveraging the noise-free condensed graph to calibrate the structure of the test graph. Extensive experiments show that RobGC is compatible with various GC methods, significantly boosting their robustness.},
  archive      = {J_TKDE},
  author       = {Xinyi Gao and Hongzhi Yin and Tong Chen and Guanhua Ye and Wentao Zhang and Bin Cui},
  doi          = {10.1109/TKDE.2025.3569629},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4791-4804},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RobGC: Towards robust graph condensation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QSTGNN: Quaternion spatio-temporal graph neural networks. <em>TKDE</em>, <em>37</em>(8), 4776-4790. (<a href='https://doi.org/10.1109/TKDE.2025.3571983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal time series forecasting has attracted great attentions in various fields, including climate, power, and traffic forecasting. Recently, Spatio-temporal Graph Neural Networks (STGNNs) have shown promising performances in modeling spatial dependencies based on graph neural networks (GNNs) and temporal dependencies based on temporal learning modules. However, most STGNNs do not effectively integrate explicit and implicit relationships between nodes, nor do they adequately capture long and short-term time dependencies. To address these challenges, this paper presents a Quaternion Spatio-temporal Graph Neural Network (QSTGNN). Specifically, the quaternion spatio-temporal graph is constructed firstly, such that the information of both short and long-term time steps are preserved in quaternion feature tensor, and information of multiple explicit graphs and implicit graph are integrated in quaternion graph adjacency matrix. Then, two modules are designed: a 1D quaternion convolution module and a quaternion graph convolution module. In the 1D quaternion convolution module, complex temporal correlations among short and long-term time steps can be well exploited by 1D quaternion convolution operator based on the quaternion Hamilton product. In the quaternion graph convolution module, quaternion graph convolution is designed to characterize nonlinear dependencies among multiple spatial graphs, including explicit and implicit graphs. Extensive experiments are conducted on six datasets, and the results show that QSTGNN achieves state-of-the-art performances over the existing ten methods. Explainable analysis presents that multiple spatial correlations can accurately illustrate the traffic flow and road functional information in real traffic roads.},
  archive      = {J_TKDE},
  author       = {Ye Liu and Chaoxiong Lin and Yuchen Mou and Huaiguang Jiang and Hongmin Cai},
  doi          = {10.1109/TKDE.2025.3571983},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4776-4790},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {QSTGNN: Quaternion spatio-temporal graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Per-flow quantile estimation using m4 framework. <em>TKDE</em>, <em>37</em>(8), 4758-4775. (<a href='https://doi.org/10.1109/TKDE.2025.3573812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel framework, M4, designed to estimate per-flow quantiles in data streams accurately. M4 is a versatile framework that can be integrated with a wide array of single-flow quantile estimation algorithms, thereby enabling them to perform per-flow estimation. The framework employs a sketch-based approach to provide a space-efficient method for recording and extracting distribution information. M4 incorporates two techniques: MINIMUM and SUM. The MINIMUM technique minimizes the noise on a flow from other flows caused by hash collisions, while the SUM technique efficiently categorizes flows based on their sizes and customizes treatment strategies accordingly. We demonstrate the application of M4 on three single-flow quantile estimation algorithms (DDSketch, $t$-digest, and ReqSketch), detailing the specific implementation of the MINIMUM and SUM techniques. We provide theoretical proof that M4 delivers high accuracy while utilizing limited memory. Additionally, we conduct extensive experiments to evaluate the performance of M4 regarding accuracy and speed. The experimental results indicate that across all three example algorithms, M4 significantly outperforms two comparison frameworks in terms of accuracy for per-flow quantile estimation while maintaining comparable speed.},
  archive      = {J_TKDE},
  author       = {Zhuochen Fan and Yalun Cai and Siyuan Dong and Qiuheng Yin and Tianyu Bai and Hanyu Xue and Peiqing Chen and Yuhan Wu and Tong Yang and Bin Cui},
  doi          = {10.1109/TKDE.2025.3573812},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4758-4775},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Per-flow quantile estimation using m4 framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On searching and querying maximum directed $(k,\ell )$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>-plex. <em>TKDE</em>, <em>37</em>(8), 4743-4757. (<a href='https://doi.org/10.1109/TKDE.2025.3569755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding cohesive subgraphs from a directed graph is a fundamental approach to analyze directed graph data. We consider a new model called directed $(k,\ell )$-plex for a cohesive directed subgraph, which is generalized from the concept of $k$-plex that is only applicable to undirected graphs. Directed $(k,\ell )$-plex (or DPlex) has the connection requirements on both inbound and outbound directions of each vertex inside, i.e., each vertex disconnects at most $k$ vertices and is meanwhile not pointed to by at most $\ell$ vertices. In this paper, we study the maximum DPlex search problem which finds a DPlex with the most vertices. We formally prove the NP-hardness of the problem. We then design a heuristic algorithm called DPHeuris, which finds a DPlex with the size close to the maximum one and runs practically fast in polynomial time. Furthermore, we propose a branch-and-bound algorithm called DPBB to find the exact maximum DPlex and develop effective graph reduction strategies for boosting the empirical performance. We also consider the problem of querying personalized maximum DPlex, and design a new method called DPBBQ for the problem. Finally, we conduct extensive experiments on real directed graphs. The experimental results show that (1) our heuristic method can quickly find a near-optimal solution and (2) our branch-and-bound method runs up to six orders of magnitude faster than other baselines.},
  archive      = {J_TKDE},
  author       = {Shuohao Gao and Kaiqiang Yu and Shengxin Liu and Cheng Long and Xun Zhou},
  doi          = {10.1109/TKDE.2025.3569755},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4743-4757},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {On searching and querying maximum directed $(k,\ell )$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>ℓ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>-plex},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGB: Language model and graph neural network-driven social bot detection. <em>TKDE</em>, <em>37</em>(8), 4728-4742. (<a href='https://doi.org/10.1109/TKDE.2025.3573748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious social bots achieve their malicious purposes by spreading misinformation and inciting social public opinion, seriously endangering social security, making their detection a critical concern. Recently, graph-based bot detection methods have achieved state-of-the-art (SOTA) performance. However, our research finds many isolated and poorly linked nodes in social networks, which graph-based methods cannot effectively detect. To address this problem, our research focuses on effectively utilizing node semantics and network structure to jointly detect sparsely linked nodes. Given the excellent performance of language models (LMs) in natural language understanding (NLU), we propose a novel social bot detection framework LGB, which consists of two main components: language model (LM) and graph neural network (GNN). Specifically, the social account information is first extracted into unified user textual sequences, which is then used to perform supervised fine-tuning (SFT) of the language model to improve its ability to understand social account semantics. Next, the semantically enriched node representation is fed into the pre-trained GNN to further enhance the node representation by aggregating information from neighbors. Finally, LGB fuses the information from both modalities to improve the detection performance of sparsely linked nodes. Extensive experiments on two real-world datasets demonstrate that LGB consistently outperforms state-of-the-art baseline models by up to 10.95%. LGB is already online: https://botdetection.aminer.cn/robotmain.},
  archive      = {J_TKDE},
  author       = {Ming Zhou and Dan Zhang and Yuandong Wang and Yangli-ao Geng and Yuxiao Dong and Jie Tang},
  doi          = {10.1109/TKDE.2025.3573748},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4728-4742},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LGB: Language model and graph neural network-driven social bot detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete multi-view clustering via multi-level contrastive learning. <em>TKDE</em>, <em>37</em>(8), 4716-4727. (<a href='https://doi.org/10.1109/TKDE.2025.3568795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant progress has been made in multi-view learning over the past few decades, it remains challenging, especially in the context of incomplete multi-view clustering, where modeling complex correlations among different views and handling missing data are key difficulties. In this paper, we propose a novel incomplete multi-view clustering network to address the aforementioned issue, named Incomplete Multi-view Clustering via Multi-level Contrastive Learning (IMC-MCL). Specifically, the proposed model aims to minimize the conditional entropy between views to recover missing data by dual prediction strategy. Moreover, the approach learns multi-level features, including latent, high-level and semantic features, with the goal of satisfying both reconstruction and consistency objectives in distinct feature spaces. Specifically, latent features are utilized to accomplish the reconstruction objective, while high-level features and semantic labels are employed to achieve the two consistency goals through contrastive learning. This framework enables the exploration of shared semantics within high-level features and achieves clustering assignment using semantic features. Extensive experiments have shown that the proposed approach outperforms other state-of-the-art incomplete multi-view clustering methods on seven challenging datasets.},
  archive      = {J_TKDE},
  author       = {Jun Yin and Pei Wang and Shiliang Sun and Zhonglong Zheng},
  doi          = {10.1109/TKDE.2025.3568795},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4716-4727},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Incomplete multi-view clustering via multi-level contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implicit multi-behavior generative recommendation with mixture of quantization. <em>TKDE</em>, <em>37</em>(8), 4704-4715. (<a href='https://doi.org/10.1109/TKDE.2025.3572014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative recommendation systems have recently seen a surge in interest, largely due to the promising advancements in generative AI. As a competitive solution for multi-behavior sequence recommendations, much of the recent research has concentrated on predicting the next item a user will likely interact with using a generative approach. However, these methods often 1). assign multiple residual quantization layers to obtain item codes, which leads to extra storage costs of more codebooks. And 2). explicitly utilize behavior sequences leading to longer sequences, potentially increasing the training time as well as inference time compared with original sequences. In response to these challenges, we introduce the Implicit Multi-Behavior Generative recommendation with a mixture of quantization (IMBGen) approach in this paper. Specifically, we have devised a Mixture of Quantization (MoQ) that combines the merits of both residual and parallel quantization for a more effective tokenization process. Additionally, we propose an Implicit Behavior Modeling (IBM) framework, allowing for more efficient integration of users’ behaviors into the interacted items. Finally, we conducted extensive experiments on two widely used benchmark datasets and further confirmed our findings with an online A/B test. The results consistently demonstrate the advantages of our approach over other baseline methods.},
  archive      = {J_TKDE},
  author       = {Yuze Tan and Yanjie Gou and Kouying Xue and Shudong Huang and Yi Hu and Ivor W. Tsang and Jiancheng Lv},
  doi          = {10.1109/TKDE.2025.3572014},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4704-4715},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Implicit multi-behavior generative recommendation with mixture of quantization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph convolutional networks for course recommendation in MOOCs. <em>TKDE</em>, <em>37</em>(8), 4691-4703. (<a href='https://doi.org/10.1109/TKDE.2025.3568709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining learner preferences and needs from individual learning behavior data is a critical task in course recommendation systems. While graph-based models have shown efficacy in capturing pairwise relationships between learners and courses, they often overlook the complex higher-order interactions involving learners, courses and teachers that are essential for accurate recommendations. To address this limitation, we propose a novel Hypergraph Convolutional Network for Course Recommendation (HCNCR) framework, designed to model these higher-order interactions effectively. Our approach constructs course and learner hypergraphs based on course attributes and learner similarity relations, respectively. By employing hypergraph convolution, we capture the intrinsic higher-order relationships within these hypergraphs. Additionally, we utilize graph convolutional layers on the learner-course bipartite graph to integrate embeddings derived from hypergraphs, achieving comprehensive representations of both learners and courses. Extensive experiments conducted on real-world datasets demonstrate that HCNCR significantly outperforms existing state-of-the-art methods in course recommendation tasks.},
  archive      = {J_TKDE},
  author       = {Zhu Su and Yafeng Li and Qing Li and Zhonghua Yan and Longfeng Zhao and Zhi Liu and Jianwen Sun and Sannyuya Liu},
  doi          = {10.1109/TKDE.2025.3568709},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4691-4703},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hypergraph convolutional networks for course recommendation in MOOCs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic hypergraph transformer with knowledge state disentanglement for knowledge tracing. <em>TKDE</em>, <em>37</em>(8), 4677-4690. (<a href='https://doi.org/10.1109/TKDE.2025.3570098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) refers to inferring the students’ knowledge mastery and predicting their future performance. KT serves as the foundation for personalized learning and enhances the effectiveness of educational interventions, becoming a crucial technology in intelligent tutoring systems. Recent approaches have demonstrated notable success by harnessing the potent representational capacities of deep learning. However, complex neural networks lead to entangled knowledge state embeddings, where the embedding dimensions are coupled, limiting their expressiveness and interpretability. In addition, the limitations of existing methods in euclidean space result in distortions when capturing complex relationships among knowledge states. This distortion is reflected in the alteration of distances and geometric structures among knowledge states during the embedding process. To address the challenges, in this paper, we propose a hyperbolic hypergraph transformer with knowledge state Disentanglement for Knowledge Tracing, named DisenKT. We construct the students’ response sequences into the hypergraph, projected into the hyperbolic space to alleviate the representation distortion problem of questions and knowledge states. The embeddings of hierarchical knowledge states are refined through message passing between questions and students based on the proposed hyperbolic hypergraph transformer. Moreover, we are the first to disentangle knowledge states via a contrastive clustering auxiliary task, which enhances the expressiveness and interpretability of knowledge state embeddings. Extensive experimental results on three public datasets demonstrate that DisenKT outperforms state-of-the-art methods on student performance prediction and interpretability.},
  archive      = {J_TKDE},
  author       = {Jiawei Li and Shun Mao and Yixiu Qin and Feng Wang and Yuncheng Jiang},
  doi          = {10.1109/TKDE.2025.3570098},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4677-4690},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hyperbolic hypergraph transformer with knowledge state disentanglement for knowledge tracing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph-based multimodal brain network learning. <em>TKDE</em>, <em>37</em>(8), 4664-4676. (<a href='https://doi.org/10.1109/TKDE.2025.3569648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) provide powerful insights into brain neuroimaging technology from the view of graphical networks. However, most existing GNN-based models treat the brain connectome, derived from neuroimaging, as a homogeneous graph characterized by uniform node and edge types. In fact, emerging studies have reported and emphasized the significance of heterogeneity among human brain activities, especially between the two cerebral hemispheres. Thus, homogeneous-structured brain network-based graph methods are insufficient for modeling complicated cerebral activity states. To overcome this problem, we introduce a novel heterogeneous graph neural network (HeBrainGNN) for multimodal brain neuroimaging fusion learning. HeBrainGNN first conceptualizes the brain network as a heterogeneous graph with multiple types of nodes (representing the left and right hemispheres) and edges (categorizing intra- and interhemispheric interactions). We further develop a self-supervised pretraining strategy for this heterogeneous network to address the potential overfitting problem caused by the conflict between a large parameter size and a small medical data sample size. Empirical results show the superiority of the proposed model over other existing methods in brain-related disease prediction tasks. Ablation experiments show that our heterogeneous graph-based model attaches more importance to hemispheric connections that may be neglected due to their low strength by previous homogeneous graph models. Additional experiments reveal that our pretraining strategy not only addresses the challenge of limited labeled data but also significantly enhances accuracy, affirming the potential of our approach in advancing neuroimaging analysis.},
  archive      = {J_TKDE},
  author       = {Gen Shi and Yifan Zhu and Wenjin Liu and Quanming Yao and Xuesong Li},
  doi          = {10.1109/TKDE.2025.3569648},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4664-4676},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Heterogeneous graph-based multimodal brain network learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based clustering: High-order bipartite graph for proximity learning. <em>TKDE</em>, <em>37</em>(8), 4649-4663. (<a href='https://doi.org/10.1109/TKDE.2025.3569681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured proximity matrix learning, one of the mainstream directions in clustering research, refers to learning a proximity matrix with an explicit clustering structure from the original first-order proximity matrix. Due to the complexity of the data structure, the original first-order proximity matrix always lacks some must-links compared to the groundtruth proximity matrix. It is worth noting that high-order proximity matrices can provide missed must-link information. However, the computation of high-order proximity matrices and clustering based on them are expensive. To solve the above problem, inspired by the anchor bipartite graph, we present a novel high-order bipartite graph proximity matrix and a fast method to compute it. This proposed high-order bipartite graph proximity matrix contains high-order proximity information and can significantly reduce the computational complexity of the whole clustering process. Furthermore, we introduce an efficient and simple high-order bipartite graph fusion framework that can adaptively assign weights to each order of the high-order bipartite graph matrices. Finally, under the Laplace rank constraint, a consensus structured bipartite graph proximity matrix is obtained. At the same time, an efficient solution algorithm is proposed for this model. The model's efficacy is underscored through rigorous experiments, highlighting its superior clustering performance and time efficiency.},
  archive      = {J_TKDE},
  author       = {Zihua Zhao and Danyang Wu and Rong Wang and Zheng Wang and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3569681},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4649-4663},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph-based clustering: High-order bipartite graph for proximity learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GinAR+: A robust end-to-end framework for multivariate time series forecasting with missing values. <em>TKDE</em>, <em>37</em>(8), 4635-4648. (<a href='https://doi.org/10.1109/TKDE.2025.3569649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial-Temporal Graph Neural Networks (STGNNs) have been widely utilized in multivariate time series forecasting (MTSF), but they rely on the assumption of data completeness. In practice, due to factors such as natural disaster, STGNNs frequently encounter the challenge of missing data resulting from numerous malfunctioning data collectors. In this case, on the one hand, due to the presence of missing values, STGNNs easily generate incorrect spatial correlations, leading to the performance degradation. On the other hand, STGNNs require separate training of models for different missing rates, limiting their robustness. To address these challenges, we first propose two important components (interpolation attention and adaptive graph convolution), which utilize normal values to recover missing values into reliable representations and reconstruct spatial correlations. Then, we replace the fully connected layers in simple recursive units with these two components and propose Graph Interpolation Attention Recursive Network (GinAR), aiming to recursively correct spatial correlations and achieve end-to-end MTSF with missing values. Finally, we use data with different missing rates as positive and negative data pairs. By employing contrastive learning to train GinAR, we propose GinAR+ and enhance its robustness to data with different missing rates. Experiments validate the superiority of GinAR+ and our motivation.},
  archive      = {J_TKDE},
  author       = {Chengqing Yu and Fei Wang and Zezhi Shao and Tangwen Qian and Zhao Zhang and Wei Wei and Zhulin An and Qi Wang and Yongjun Xu},
  doi          = {10.1109/TKDE.2025.3569649},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4635-4648},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GinAR+: A robust end-to-end framework for multivariate time series forecasting with missing values},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized local prominence for source detection in real-world rumor networks. <em>TKDE</em>, <em>37</em>(8), 4620-4634. (<a href='https://doi.org/10.1109/TKDE.2025.3567282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of infection source detection deals with localizing the infection source in a given network. While the problem has been extensively studied in the past, researchers have mainly focused on simulated infection networks which may not be the correct reflection of the dynamics of real-world infections. More significantly, the existing methods assume that a rumor source lies at the center of an infection network (source-centrality), which is not always true in sparse real-world rumor networks. Due to the randomness of infection flow in such networks, the source may lie away from the center (source-skewness). There is also a lack of real-world infection network datasets to provide a true real-world perspective. Therefore, we revisit the source detection problem and contemplate a shift from mainstream simulations to a real-world paradigm. To this end, we generate two novel rumor network datasets, ${\mathsf {Cov19-RN}}$ and ${\mathsf {Use20-RN}}$, based on COVID-19 and US Elections 2020 misinformation trends on Twitter (currently $\mathbb {X}$). Besides, inspired by the technicalities inherent to real-world rumor networks, we propose a real-world oriented algorithm called Generalized Exoneration and Prominence based Age, ${\mathsf {GEPA}}$, for rumor source detection. ${\mathsf {GEPA}}$ addresses the problem of source-skewness to detect rumor sources using the concept of generalized local prominence, which we introduce in this study. Our experiments show that ${\mathsf {GEPA}}$ significantly outperforms the state-of-the-art methods, producing detection rates of 73.6% against 61.5% of the closest competing method on ${\mathsf {Cov19-RN}}$, and 61.5% against 52.6% of the closest competing method on ${\mathsf {Use20-RN}}$. To the best of our knowledge, this study is the first such work to deal with source detection in real-world rumor networks and address the problem of source-skewness.},
  archive      = {J_TKDE},
  author       = {Syed Shafat Ali and Ajay Rastogi and Tarique Anwar and Syed Afzal Murtaza Rizvi and Jian Yang and Jia Wu and Quan Z. Sheng},
  doi          = {10.1109/TKDE.2025.3567282},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4620-4634},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Generalized local prominence for source detection in real-world rumor networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process latent variable modeling for few-shot time series forecasting. <em>TKDE</em>, <em>37</em>(8), 4604-4619. (<a href='https://doi.org/10.1109/TKDE.2025.3573673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate time series forecasting is crucial for optimizing resource allocation, industrial production, and urban management, particularly with the growth of cyber-physical and IoT systems. However, limited training sample availability in fields like physics and biology poses significant challenges. Existing models struggle to capture long-term dependencies and to model diverse meta-knowledge explicitly in few-shot scenarios. To address these issues, we propose MetaGP, a meta-learning-based Gaussian process latent variable model that uses a Gaussian process kernel function to capture long-term dependencies and to maintain strong correlations in time series. We also introduce Kernel Association Search (KAS) as a novel meta-learning component to explicitly model meta-knowledge, thereby enhancing both interpretability and prediction accuracy. We study MetaGP on simulated and real-world few-shot datasets, showing that it is capable of state-of-the-art prediction accuracy. We also find that MetaGP can capture long-term dependencies and can model meta-knowledge, thereby providing valuable insights into complex time series patterns.},
  archive      = {J_TKDE},
  author       = {Yunyao Cheng and Chenjuan Guo and Kaixuan Chen and Kai Zhao and Bin Yang and Jiandong Xie and Christian S. Jensen and Feiteng Huang and Kai Zheng},
  doi          = {10.1109/TKDE.2025.3573673},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4604-4619},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Gaussian process latent variable modeling for few-shot time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast anchor graph clustering via maximizing within-cluster similarity. <em>TKDE</em>, <em>37</em>(8), 4591-4603. (<a href='https://doi.org/10.1109/TKDE.2025.3569777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based clustering methods have attracted increasing attention due to their ability to provide efficient and scalable solutions in clustering tasks, such as subspace, multi-view and ensemble clustering. Nevertheless, the majority of anchor-based methods view anchors merely as tools, concentrating on diminishing computational complexity within original data space. However, in fact, clustering can be directly performed on anchors and then the anchor clustering results could be propagated to original data. Due to the much smaller volume of anchors, this could significantly reduce the computational complexity of clustering algorithms. Building upon this idea, in this paper, we propose a fast anchor graph clustering method (FAGC) via maximizing within-cluster similarity. Inspired by the relaxation and discretization model in spectral clustering, we also propose two corresponding models, namely FAGC-R and FAGC-D. FAGC-R first obtains spectral embedding of anchors and then discretizes the embedding to obtain anchor indicator matrix. While FAGC-D directly solves the discrete anchor membership matrix. Once anchor clustering results are obtained, original data labels can be obtained through anchor label transmission. Extensive experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed methods.},
  archive      = {J_TKDE},
  author       = {Fangyuan Xie and Jingjing Xue and Feiping Nie and Weizhong Yu and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3569777},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4591-4603},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast anchor graph clustering via maximizing within-cluster similarity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient bitruss decomposition on GPU. <em>TKDE</em>, <em>37</em>(8), 4578-4590. (<a href='https://doi.org/10.1109/TKDE.2025.3569804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cohesive subgraph computation on bipartite graphs has drawn significant research interest recently. As a popular cohesive subgraph model, $k$-bitruss is defined as the maximal subgraph where each edge is contained in at least $k$ butterflies (i.e., a (2, 2)-biclique). The bitruss decomposition problem is widely studied, which aims to compute all $k$-bitrusses for $k \geq 0$. The state-of-the-art CPU-based solutions require extensive costs to construct an index structure for grouping butterflies, leading to scalability challenges on large bipartite graphs. In this paper, we explore bitruss decomposition with GPU by leveraging the parallel computing capabilities of GPU architectures. As the index-based approach requires extensive space and the memory resources of GPUs are limited, we propose GBiD, which is a peeling-based algorithm on GPUs that utilizes a block-centric computation scheme to enable space-efficient bitruss decomposition without any indexing structure. In addition, cost-aware common neighbor exploration and neighbor list accessing optimizations are proposed to enhance GBiD by reducing the cost of enumerating butterflies and accessing the graph structure during the peeling process. Extensive experiments conducted on 10 real-world datasets demonstrate that our proposed techniques significantly surpass existing CPU-based solutions in terms of both space and time efficiency.},
  archive      = {J_TKDE},
  author       = {Shunyang Li and Kai Wang and Wenjie Zhang and Xuemin Lin and Yizhang He},
  doi          = {10.1109/TKDE.2025.3569804},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4578-4590},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient bitruss decomposition on GPU},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Educating language models as promoters: Multi-aspect instruction alignment with self-augmentation. <em>TKDE</em>, <em>37</em>(8), 4564-4577. (<a href='https://doi.org/10.1109/TKDE.2025.3569585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce content generation necessitates creating engaging and customer-centric material to endorse products and enhance user satisfaction. Existing methods depend on task-specific feature design, which requires a fine-tailored model for each task with complex data collection and pre-processing, and their generation capabilities are limited. Meanwhile, large language models have demonstrated their capabilities in diverse natural language processing tasks, solving multiple tasks in a unified process. To address the concerns in e-commerce content generation, we leverage the impressive generation performance of large language models and propose a framework to educate them as proficient promoters in various e-commerce-related tasks. Our framework involves two modules: self-educating proliferates task instructions and data by instructing the unaligned model, and multi-aspect instruction alignment educates the language model by embedding all e-commerce tasks in a unified framework. The proposed model, Promoter, can perform a batch of prediction and generation tasks, working as a smart and creative promoter that only requires a quick view of the customer profile. Extensive experiments from automatic and human perspectives indicate that Promoter achieves state-of-the-art performances in various generation tasks, bringing the productivity of large language models to e-commerce in an integrated pipeline.},
  archive      = {J_TKDE},
  author       = {Xueyao Sun and Kaize Shi and Haoran Tang and Dingxian Wang and Guandong Xu and Qing Li},
  doi          = {10.1109/TKDE.2025.3569585},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4564-4577},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Educating language models as promoters: Multi-aspect instruction alignment with self-augmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangling inter- and intra-cascades dynamics for information diffusion prediction. <em>TKDE</em>, <em>37</em>(8), 4548-4563. (<a href='https://doi.org/10.1109/TKDE.2025.3568289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion prediction is a vital component for a wide range of social applications, including viral marketing identification and precise recommendation. Prior methods focus on modeling contextual information from a single cascade, ignoring rich collaborative information behind historical interactions across various cascades and future data within the cascade. Leveraging such interactions can substantially enhance diffusion prediction performance but presents two major challenges: (1) user intents are usually entangled behind historical interactions; and (2) utilizing future data may introduce severe training-inference discrepancies. We present MIM, a novel information diffusion model merging multi-scale interactions for improving user intent learning and behavior retrieval. Specifically, we convert cascades and social relations into multi-channel hypergraphs, where each channel depicts a common fine-grained user intent behind historical interactions across cascades. By aggregating embeddings learned through multiple channels, we obtain comprehensive intent representations. Second, we decouple past- and future-level temporal influences within a cascade via a dual temporal network. Then we implement past-future knowledge transferring to enhance the knowledge learned from the dual network via hierarchical knowledge distillation. Extensive experiments conducted on four datasets demonstrate that MIM significantly outperforms various benchmarks.},
  archive      = {J_TKDE},
  author       = {Zhangtao Cheng and Yang Liu and Ting Zhong and Kunpeng Zhang and Fan Zhou and Philip S. Yu},
  doi          = {10.1109/TKDE.2025.3568289},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4548-4563},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Disentangling inter- and intra-cascades dynamics for information diffusion prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFL-net: Disentangled feature learning network for multi-view clustering. <em>TKDE</em>, <em>37</em>(8), 4537-4547. (<a href='https://doi.org/10.1109/TKDE.2025.3574150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims at partitioning data into their underlying categories by mining shared and complementary information conveyed by different views. Although the integration of deep learning and disentanglement learning has markedly improved clustering performance, our analysis reveals two fundamental limitations in existing approaches: inadequate separation between view-shared and view-exclusive features; and the negative effects of clustering-irrelevant information on feature decoupling. To tackle these issues, we present a novel Disentangled Feature Learning Network (DFL-Net), which utilizes a progressive learning framework to systematically disentangle features. DFL-Net initially establishes view-shared representations through semantic disparity minimization, followed by the construction of orthogonal feature subspaces using cross-view and intra-view independence constraints to isolate view-specific features. Subsequently, DFL-Net enforces clustering consistency across views to adaptively eliminate irrelevant information, thus enhancing the overall effectiveness of disentanglement learning. The framework introduces two significant innovations: a comprehensive feature independence criterion that concurrently reduces intra-view and cross-view feature dependencies, and an irrelevance filtering mechanism that ensures cross-view clustering consistency. Extensive experiments on benchmark datasets demonstrate the superior performance of DFL-Net compared to state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Zhe Chen and Xiao-Jun Wu and Tianyang Xu and Josef Kittler},
  doi          = {10.1109/TKDE.2025.3574150},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4537-4547},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DFL-net: Disentangled feature learning network for multi-view clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning based knowledge tracing: A review, a tool and empirical studies. <em>TKDE</em>, <em>37</em>(8), 4512-4536. (<a href='https://doi.org/10.1109/TKDE.2025.3552759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) involves utilizing historical data from students’ learning interactions to model their mastery of knowledge over time, with the aim of predicting their future performance in interactions. Recently, significant advancements have been achieved through the application of various deep learning methodologies to address the KT challenge. However, a considerable proportion of deep learning-based knowledge tracing (DLKT) approaches exhibit striking similarities in their methodologies, and model designs, and even the outcomes demonstrate minimal divergence. In addition, the evaluation procedures employed in current DLKT studies are not standardized, resulting in substantial inconsistencies in the reported area under the curve (AUC) outcomes, despite analyzing the same model on identical datasets. To address the two aforementioned problems, this paper proposes a generalized DLKT framework and represents the existing DLKT models with five components, i.e., multimodal data encoder, student knowledge memory, auxiliary knowledge base, learning outcome objective, and computational efficiency and scalability. Furthermore, we develop and open source a standardized DLKT benchmark platform named pyKT,1 that consists of a standardized set of integrated data preprocessing procedures on 9 popular datasets across different domains, and 21 frequently compared DLKT model implementations. With pyKT, we conduct empirical and reproducible research to assess the performance of prevalent DLKT algorithms in an unbiased and clear setting over multiple data sources. Finally, we discuss the applications of KT techniques in the educational sector and their future development directions.},
  archive      = {J_TKDE},
  author       = {Zitao Liu and Teng Guo and Qianru Liang and Mingliang Hou and Bojun Zhan and Jiliang Tang and Weiqi Luo and Jian Weng},
  doi          = {10.1109/TKDE.2025.3552759},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4512-4536},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep learning based knowledge tracing: A review, a tool and empirical studies},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DASCE: Long-tailed data augmentation based sparse class-correlation exploitation. <em>TKDE</em>, <em>37</em>(8), 4497-4511. (<a href='https://doi.org/10.1109/TKDE.2025.3573899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-tailed data distribution frequently occurs in the real-world scenarios, whereas deep learning is not effective enough for such distribution. In order to improve the effectiveness for the long-tailed data, data augmentation is widely used to balance the distribution of classes by generating new samples. However, most existing studies are designed from the perspective of the class-independence assumption by default, ignoring the effect of interrelation among classes for data augmentation, which causes that some generated samples may be unrepresentative and useless for balancing the class-distribution. Inspired by this, we propose a new data augmentation method based the sparse class-correlation exploitation in this paper, which can generate more representative samples by utilizing the class-correlation, to effectively balance the class-distribution for the long-tailed data. In the proposed method, a sparse class-correlation exploration module is first proposed to explore the potential correlations among multiple classes for boosting the classification performance. Based on the class-correlations, the pivotal seed-samples are generated by maximizing the sparse representation of challenging samples. Meanwhile, an ambiguity-filtered translation module is designed to generate more representative new samples for the target classes based the obtained seed-samples by enhancing the class-consistency and suppressing the deviation from the target classes. In addition, we introduce the self-supervised feature and fuse it with the discriminative feature to explore more accurate class-correlations. Experimental results illustrate that the proposed method obtains better performance only with a small number of generated samples than the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Mengnan Qi and Shasha Mao and Yimeng Zhang and Jing Gu and Shuiping Gou and Licheng Jiao and Yuming Zhang},
  doi          = {10.1109/TKDE.2025.3573899},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4497-4511},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DASCE: Long-tailed data augmentation based sparse class-correlation exploitation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DACAD: Domain adaptation contrastive learning for anomaly detection in multivariate time series. <em>TKDE</em>, <em>37</em>(8), 4485-4496. (<a href='https://doi.org/10.1109/TKDE.2025.3569909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In time series anomaly detection (TSAD), the scarcity of labeled data poses a challenge to the development of accurate models. Unsupervised domain adaptation (UDA) offers a solution by leveraging labeled data from a related domain to detect anomalies in an unlabeled target domain. However, existing UDA methods assume consistent anomalous classes across domains. To address this limitation, we propose a novel Domain Adaptation Contrastive learning model for Anomaly Detection in multivariate time series (DACAD), combining UDA with contrastive learning. DACAD utilizes an anomaly injection mechanism that enhances generalization across unseen anomalous classes, improving adaptability and robustness. Additionally, our model employs supervised contrastive loss for the source domain and self-supervised contrastive triplet loss for the target domain, ensuring comprehensive feature representation learning and domain-invariant feature extraction. Finally, an effective Center-based Entropy Classifier (CEC) accurately learns normal boundaries in the source domain. Extensive evaluations on multiple real-world datasets and a synthetic dataset highlight DACAD’s superior performance in transferring knowledge across domains and mitigating the challenge of limited labeled data in TSAD.},
  archive      = {J_TKDE},
  author       = {Zahra Zamanzadeh Darban and Yiyuan Yang and Geoffrey I. Webb and Charu C. Aggarwal and Qingsong Wen and Shirui Pan and Mahsa Salehi},
  doi          = {10.1109/TKDE.2025.3569909},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4485-4496},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DACAD: Domain adaptation contrastive learning for anomaly detection in multivariate time series},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost-sensitive neighborhood granularity selection for hierarchical classification. <em>TKDE</em>, <em>37</em>(8), 4471-4484. (<a href='https://doi.org/10.1109/TKDE.2025.3566038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification represented by hierarchical classification (HC) plays an important role in current large-scale problems, which can acquire a more accurate expression of data that conforms to the human multi-granularity cognitive process. To compress the original dataset and simultaneously enhance the expressive force of models, selecting an appropriate granularity for approximately describing the classification is the main task in the rough set theory. Nevertheless, the current rough set theory merely concerns flat classification and encounters new problems when approximately describing HC. 1) There lacks a measure to correctly reflect misclassification in accordance with the hierarchical accuracy of HC on the training set. 2) There lacks a measure relying on the distribution of the dataset to reflect the difference between two distinct feature sets describing HC in generalization ability. To address the mentioned issues, this paper utilizes the knowledge distance to characterize HC and proposes a cost-sensitive granularity selection for HC. First, HC and features are respectively granulated according to hierarchical quotient space and neighborhood granular structures. Then, knowledge distance and its extended form are employed to formulate misclassification and test costs. On this basis, a cost-sensitive neighborhood granularity selection is presented for HC. Finally, we experimentally demonstrate the excellent performance of the proposed method in terms of efficiency and HC accuracy both in synthetic and real datasets.},
  archive      = {J_TKDE},
  author       = {Shuai Li and Jie Yang and Huanan Bao and Deyou Xia and Qinghua Zhang and Guoyin Wang},
  doi          = {10.1109/TKDE.2025.3566038},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4471-4484},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cost-sensitive neighborhood granularity selection for hierarchical classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-around neural collapse for imbalanced classification. <em>TKDE</em>, <em>37</em>(8), 4460-4470. (<a href='https://doi.org/10.1109/TKDE.2025.3569563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Collapse (NC) presents an elegant geometric structure that enables individual activations (features), class means and classifier (weights) vectors to reach optimal inter-class separability during the terminal phase of training on a balanced dataset. Once shifted to imbalanced classification, such an optimal structure of NC can be readily destroyed by the notorious minority collapse, where the classifier vectors corresponding to the minority classes are squeezed. In response, existing works mainly optimize classifiers in an effort to recover NC. However, we discover that this squeezing phenomenon is not only confined to classifier vectors but also occurs with class means. Consequently, reconstructing NC solely at the classifier aspect may be futile, as the class means remain compressed, leading to the violation of inherent self-duality in NC (i.e., class means and classifier vectors converge mutually) and incidentally, an unsatisfactory collapse of individual activations towards the corresponding class means. To shake off these dilemmas, we present a unified All-around Neural Collapse framework (AllNC), aiming to comprehensively restore NC across multiple aspects including individual activations, class means and classifier vectors. We thoroughly analyze its effectiveness and verify its performance on multiple benchmark datasets as state-of-the-art in both balanced and imbalanced settings.},
  archive      = {J_TKDE},
  author       = {Enhao Zhang and Chaohua Li and Chuanxing Geng and Songcan Chen},
  doi          = {10.1109/TKDE.2025.3569563},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4460-4470},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {All-around neural collapse for imbalanced classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive traffic forecasting on daily basis: A spatio-temporal context learning approach. <em>TKDE</em>, <em>37</em>(8), 4446-4459. (<a href='https://doi.org/10.1109/TKDE.2025.3570484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting plays a crucial role in establishing an Intelligent Transportation System (ITS) by providing essential insights. Existing traffic forecasting relies on the assumption that there is a hidden invariant spatial-temporal pattern in the large-scale dataset. However, the traffic patterns are easily influenced by many unpredictable external factors, such as policy interventions and climate changes. Due to the dynamic nature of these exogenous factors, the traffic network’s spatial-temporal patterns are also changed, thus impacting the performance of traffic forecasting models. Thus, there is an urgent need to rethink the traffic forecasting model in a fast-adaptive manner. To solve this challenge, this paper proposes an Adaptive Spatio-Temporal Context Learning framework named ASTCL, which achieves desired forecasting accuracy using daily basis traffic data collected from dozens of sensors. ASTCL constructs adaptive spatio-temporal contexts for target locations in the traffic network and generates dynamic sequence graphs based on semantic similarities. The adaptive contexts aggregate valuable information from available data, while the graphs reveal dynamic trends in traffic properties. Further, ASTCL introduces a joint convolution and attention mechanism to model intricate spatio-temporal relationships from multiple perspectives. Extensive experiments conducted on four real-world datasets demonstrate that ASTCL achieves remarkable fast adaptability and outperforms other state-of-the-art methods by a significant margin.},
  archive      = {J_TKDE},
  author       = {Xiaoyu Li and Yitian Zhang and Guodong Long and Yupeng Hu and Wenpeng Lu and Meng Chen and Chengqi Zhang and Yongshun Gong},
  doi          = {10.1109/TKDE.2025.3570484},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4446-4459},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive traffic forecasting on daily basis: A spatio-temporal context learning approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaE: Knowledge graph embedding with adaptive embedding sizes. <em>TKDE</em>, <em>37</em>(8), 4432-4445. (<a href='https://doi.org/10.1109/TKDE.2025.3566270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Embedding (KGE) aims to learn dense embeddings as the representations for entities and relations in KGs. Indeed, the entities in existing KGs suffer from the data imbalance issue, i.e., there exists a substantial disparity in the occurrence frequencies among various entities. Existing KGE models pre-define a unified and fixed dimension size for all entity embeddings. However, embedding sizes of entities are highly desired for their frequencies, while a uniform embedding size may result in inadequate expression of entities, i.e., leading to overfitting for low-frequency entities and underfitting for high-frequency ones. A straight-forward idea is to set the embedding sizes for each entity before KGE training. However, manually selecting different embedding sizes is labor-intensive and time-consuming, posing challenges in real-world applications. To tackle this problem, we propose AdaE, which adaptively learns KG embeddings with different embedding sizes during training. In particular, AdaE is capable of selecting appropriate dimension sizes for each entity from a continuous integer space. To this end, we specially tailor bilevel optimization for the KGE task, which alternately learns representations and embedding sizes of entities. Our framework is general and flexible, fitting various existing KGE models. Extensive experiments demonstrate the effectiveness and compatibility of AdaE.},
  archive      = {J_TKDE},
  author       = {Zhanpeng Guan and Fuwei Zhang and Zhao Zhang and Fuzhen Zhuang and Fei Wang and Zhulin An and Yongjun Xu},
  doi          = {10.1109/TKDE.2025.3566270},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4432-4445},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AdaE: Knowledge graph embedding with adaptive embedding sizes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on side information-driven session-based recommendation: From a data-centric perspective. <em>TKDE</em>, <em>37</em>(8), 4411-4431. (<a href='https://doi.org/10.1109/TKDE.2025.3569549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation is gaining increasing attention due to its practical value in predicting the intents of anonymous users based on limited behaviors. Emerging efforts incorporate various side information to alleviate inherent data scarcity issues in this task, leading to impressive performance improvements. The core of side information-driven session-based recommendation is the discovery and utilization of diverse data. In this survey, we provide a comprehensive review of this task from a data-centric perspective. Specifically, this survey commences with a clear formulation of the task. This is followed by a detailed exploration of various benchmarks rich in side information that are pivotal for advancing research in this field. Afterwards, we delve into how different types of side information enhance the task, underscoring data characteristics and utility. Moreover, we discuss the usage of various side information, including data encoding, data injection, and involved techniques. A systematic review of research progress is then presented, with the taxonomy by the types of side information. Finally, we summarize the current limitations and present the future prospects of this vibrant topic.},
  archive      = {J_TKDE},
  author       = {Xiaokun Zhang and Bo Xu and Chenliang Li and Bowei He and Hongfei Lin and Chen Ma and Fenglong Ma},
  doi          = {10.1109/TKDE.2025.3569549},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4411-4431},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on side information-driven session-based recommendation: From a data-centric perspective},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on self-supervised graph foundation models: Knowledge-based perspective. <em>TKDE</em>, <em>37</em>(8), 4389-4410. (<a href='https://doi.org/10.1109/TKDE.2025.3568147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of graph foundation models (GFMs) has seen a dramatic rise in interest in recent years. Their powerful generalization ability is believed to be endowed by self-supervised pre-training and downstream tuning techniques. There is a wide variety of knowledge patterns embedded in the graph data, such as node properties and clusters, which are crucial for learning generalized representations for GFMs. We present a comprehensive survey of self-supervised GFMs from a novel knowledge-based perspective. Our main contribution is a knowledge-based taxonomy that categorizes self-supervised graph models by the specific graph knowledge utilized: microscopic (nodes, links, etc.), mesoscopic (context, clusters, etc.), and macroscopic (global structure, manifolds, etc.). It covers a total of 9 knowledge categories and 300 references for self-supervised pre-training as well as various downstream tuning strategies. Such a knowledge-based taxonomy allows us to more clearly re-examine potential GFM architectures, including large language models (LLMs), as well as provide deeper insights for constructing future GFMs.},
  archive      = {J_TKDE},
  author       = {Ziwen Zhao and Yixin Su and Yuhua Li and Yixiong Zou and Ruixuan Li and Rui Zhang},
  doi          = {10.1109/TKDE.2025.3568147},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {8},
  number       = {8},
  pages        = {4389-4410},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on self-supervised graph foundation models: Knowledge-based perspective},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniDyG: A unified and effective representation learning approach for large dynamic graphs. <em>TKDE</em>, <em>37</em>(7), 4373-4388. (<a href='https://doi.org/10.1109/TKDE.2025.3566064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graphs, which capture time-evolving edges between nodes, are formulated in continuous-time or discrete-time dynamic graphs. They differ in temporal granularity: Continuous-Time Dynamic Graphs (CTDGs) exhibit rapid, localized changes, while Discrete-Time Dynamic Graphs (DTDGs) show gradual, global updates. This difference leads to isolated developments in representation learning for each type. To advance dynamic graph representation learning, recent research attempts to design a unified model capable of handling both CTDGs and DTDGs, achieving promising results. However, it typically focuses on local dynamic propagation for temporal structure learning in the time domain, failing to accurately capture the underlying structural evolution associated with each temporal granularity and thus compromising model effectiveness. In addition, existing works-whether specific or unified-often overlook the issue of temporal noise, compromising the model’s robustness. To better model both types of dynamic graphs, we propose UniDyG, a unified and effective representation learning approach, which can scale to large dynamic graphs. Specifically, we first propose a novel Fourier Graph Attention (FGAT) mechanism that can model local and global structural correlations based on recent neighbors and complex-number selective aggregation, while theoretically ensuring consistent representations of dynamic graphs over time. Based on approximation theory, we demonstrate that FGAT is well-suited to capture the underlying structures in both CTDGs and DTDGs. We further enhance FGAT to resist temporal noise by designing an energy-gated unit, which adaptively filters out high-frequency noise according to the energy. Last, we leverage our proposed FGAT mechanisms for temporal structure learning and employ the frequency-enhanced linear function for node-level dynamic updates, facilitating the generation of high-quality temporal embeddings. Extensive experiments show that our UniDyG achieves an average improvement of 14.4% over sixteen baselines across nine dynamic graphs while exhibiting superior robustness in noisy scenarios.},
  archive      = {J_TKDE},
  author       = {Yuanyuan Xu and Wenjie Zhang and Xuemin Lin and Ying Zhang},
  doi          = {10.1109/TKDE.2025.3566064},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4373-4388},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {UniDyG: A unified and effective representation learning approach for large dynamic graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Turn waste into wealth: On efficient clustering and cleaning over dirty data. <em>TKDE</em>, <em>37</em>(7), 4361-4372. (<a href='https://doi.org/10.1109/TKDE.2025.3564313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dirty data commonly exist. Simply discarding a large number of inaccurate points (as noises) could greatly affect clustering results. We argue that dirty data can be repaired and utilized as strong supports in clustering. To this end, we study a novel problem of clustering and repairing over dirty data at the same time. Referring to the minimum change principle in data repairing, the objective is to find a minimum modification of inaccurate points such that the large amount of dirty data can enhance clustering. We show that the problem is np-hard and can be formulated as an integer linear programming (ilp) problem. A constant factor approximation algorithm gdorc is devised based on grid, with high efficiency. In experiments, gdorc has great repairing and clustering results with low time consumption. Empirical results demonstrate that both the clustering and cleaning accuracies can be improved by our approach of repairing and utilizing the dirty data in clustering.},
  archive      = {J_TKDE},
  author       = {Kenny Ye Liang and Yunxiang Su and Shaoxu Song and Chunping Li},
  doi          = {10.1109/TKDE.2025.3564313},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4361-4372},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Turn waste into wealth: On efficient clustering and cleaning over dirty data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tricolore: Multi-behavior user profiling for enhanced candidate generation in recommender systems. <em>TKDE</em>, <em>37</em>(7), 4349-4360. (<a href='https://doi.org/10.1109/TKDE.2025.3558503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online platforms aggregate extensive user feedback across diverse behaviors, providing a rich source for enhancing user engagement. Traditional recommender systems, however, typically optimize for a single target behavior and represent user preferences with a single vector, limiting their ability to handle multiple important behaviors or optimization objectives. This conventional approach also struggles to capture the full spectrum of user interests, resulting in a narrow item pool during candidate generation. To address these limitations, we present Tricolore, a versatile multi-vector learning framework that uncovers connections between different behavior types for more robust candidate generation. Tricolore's adaptive multi-task structure is also customizable to specific platform needs. To manage the variability in sparsity across behavior types, we incorporate a behavior-wise multi-view fusion module that dynamically enhances learning. Moreover, a popularity-balanced strategy ensures the recommendation list balances accuracy with item popularity, fostering diversity and improving overall performance. Extensive experiments on public datasets demonstrate Tricolore's effectiveness across various recommendation scenarios, from short video platforms to e-commerce. By leveraging a shared base embedding strategy, Tricolore also significantly improves the performance for cold-start users.},
  archive      = {J_TKDE},
  author       = {Xiao Zhou and Zhongxiang Zhao and Hanze Guo},
  doi          = {10.1109/TKDE.2025.3558503},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4349-4360},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Tricolore: Multi-behavior user profiling for enhanced candidate generation in recommender systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triangle topology enhancement for multi-view graph clustering. <em>TKDE</em>, <em>37</em>(7), 4338-4348. (<a href='https://doi.org/10.1109/TKDE.2025.3566387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing multi-view graph clustering models focus on integrating the topological structure of different views directly, which cannot efficiently stimulate the collaboration between multiple views. To alleviate this problem, this paper proposes a Triangle Topology Enhancement (T$^{2}$E) module, which expands two topological structures based on the raw topology of each view, including the self-triangle enhanced topology that highlights the local view information and the cross-view triangle enhanced topology containing the global-local view information. Afterward, this paper designs a novel multi-view graph clustering model, named MGC-T$^{2}$E, to integrate both the raw and derived topological structures and directly induce consistent clustering indicators based on a self-supervised clustering module. In the simulation, the experimental results demonstrate that MGC-T$^{2}$E achieves state-of-the-art performances compared with a mass of current competitors.},
  archive      = {J_TKDE},
  author       = {Danyang Wu and Penglei Wang and Jitao Lu and Zhanxuan Hu and Hongming Zhang and Feiping Nie},
  doi          = {10.1109/TKDE.2025.3566387},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4338-4348},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Triangle topology enhancement for multi-view graph clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ten challenging problems in federated foundation models. <em>TKDE</em>, <em>37</em>(7), 4314-4337. (<a href='https://doi.org/10.1109/TKDE.2025.3555328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Foundation Models (FedFMs) represent a distributed learning paradigm that fuses general competences of foundation models as well as privacy-preserving capabilities of federated learning. This combination allows the large foundation models and the small local domain models at the remote clients to learn from each other in a teacher-student learning setting. This paper provides a comprehensive summary of the ten challenging problems inherent in FedFMs, encompassing foundational theory, utilization of private data, continual learning, unlearning, Non-IID and graph data, bidirectional knowledge transfer, incentive mechanism design, game mechanism design, model watermarking, and efficiency. The ten challenging problems manifest in five pivotal aspects: “Foundational Theory,” which aims to establish a coherent and unifying theoretical framework for FedFMs. “Data,” addressing the difficulties in leveraging domain-specific knowledge from private data while maintaining privacy; “Heterogeneity,” examining variations in data, model, and computational resources across clients; “Security and Privacy,” focusing on defenses against malicious attacks and model theft; and “Efficiency,” highlighting the need for improvements in training, communication, and parameter efficiency. For each problem, we offer a clear mathematical definition on the objective function, analyze existing methods, and discuss the key challenges and potential solutions. This in-depth exploration aims to advance the theoretical foundations of FedFMs, guide practical implementations, and inspire future research to overcome these obstacles, thereby enabling the robust, efficient, and privacy-preserving FedFMs in various real-world applications.},
  archive      = {J_TKDE},
  author       = {Tao Fan and Hanlin Gu and Xuemei Cao and Chee Seng Chan and Qian Chen and Yiqiang Chen and Yihui Feng and Yang Gu and Jiaxiang Geng and Bing Luo and Shuoling Liu and Win Kent Ong and Chao Ren and Jiaqi Shao and Chuan Sun and Xiaoli Tang and Hong Xi Tae and Yongxin Tong and Shuyue Wei and Fan Wu and Wei Xi and Mingcong Xu and He Yang and Xin Yang and Jiangpeng Yan and Hao Yu and Han Yu and Teng Zhang and Yifei Zhang and Xiaojin Zhang and Zhenzhe Zheng and Lixin Fan and Qiang Yang},
  doi          = {10.1109/TKDE.2025.3555328},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4314-4337},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Ten challenging problems in federated foundation models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TELEX: Two-level learned index for rich queries on enclave-based blockchain systems. <em>TKDE</em>, <em>37</em>(7), 4299-4313. (<a href='https://doi.org/10.1109/TKDE.2025.3564905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain has become a popular paradigm for secure and immutable data storage. Despite its numerous applications across various fields, concerns regarding the user privacy and result integrity during data queries persist. Additionally, the need for rich query functionalities to harness the full potential of blockchain data remains an area ripe for exploration. In order to address these challenges, our paper first utilizes a framework based on the Trusted Execution Environment (TEE) and oblivious RAM technique to achieve both privacy and data integrity. To enhance the query efficiency over the entire blockchain, we then devise a two-level learned indexing methodology named TELEX within the TEE for both integer and string keys. We also propose different query processing algorithms for versatile query types, including exact queries, aggregate queries, Boolean queries, and range queries. By implementing the prototype and conducting extensive evaluation, we demonstrate the feasibility and remarkable improvement in efficiency compared to existing solutions.},
  archive      = {J_TKDE},
  author       = {Haotian Wu and Yuzhe Tang and Zhaoyan Shen and Jun Tao and Chenhao Lin and Zhe Peng},
  doi          = {10.1109/TKDE.2025.3564905},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4299-4313},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TELEX: Two-level learned index for rich queries on enclave-based blockchain systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S-MGHSTN: Towards an effective streaming traffic accident risk prediction framework. <em>TKDE</em>, <em>37</em>(7), 4285-4298. (<a href='https://doi.org/10.1109/TKDE.2025.3557864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents pose a significant risk to human health and property safety. To address this issue, predicting their risks has garnered growing interest. We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents. In particular, it should adequately consider the streaming nature of data and key related aspects, such as regional background, accurately capture both proximity and similarity while bridging the disparities, and effectively address the sparsity. However, these factors are often overlooked or difficult to incorporate. In this paper, we propose a novel streaming multi-granularity hierarchical spatio-temporal network. Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background. We construct multiple high-level risk prediction tasks to enhance model’s ability to cope with sparsity. Subsequently, to capture and bridge spatial proximity and semantic similarity, region features and multi-view graph undergo encoding processes to distill effective representations, followed by a graph-enhanced representation alignment module that reconciles their disparities. At last, an alternating experience replay with a dual-memory buffer is employed to accommodate streaming data scenarios. Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Minxiao Chen and Haitao Yuan and Nan Jiang and Zhihan Zheng and Zhifeng Bao and Ao Zhou and Jiaxin Jiang and Shangguang Wang},
  doi          = {10.1109/TKDE.2025.3557864},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4285-4298},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {S-MGHSTN: Towards an effective streaming traffic accident risk prediction framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-labeling and self-knowledge distillation unsupervised feature selection. <em>TKDE</em>, <em>37</em>(7), 4270-4284. (<a href='https://doi.org/10.1109/TKDE.2025.3561046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a deep pseudo-label method for unsupervised feature selection, which learns non-linear representations to generate pseudo-labels and trains a Neural Network (NN) to select informative features via self-Knowledge Distillation (KD). Specifically, the proposed method divides a standard NN into two sub-components: an encoder and a predictor, and introduces a dependency subnet. It works by self-supervised pre-training the encoder to produce informative representations and then alternating between two steps: (1) learning pseudo-labels by combining the clustering results of the encoder's outputs with the NN's prediction outputs, and (2) updating the NN's parameters by globally selecting a subset of features to predict the pseudo-labels while updating the subnet's parameters through self-KD. Self-KD is achieved by encouraging the subnet to locally capture a subset of the NN features to produce class probabilities that match those produced by the NN. This allows the model to self-absorb the learned inter-class knowledge and evaluate feature diversity, removing redundant features without sacrificing performance. Meanwhile, the potential discriminative capability of a NN can also be self-excavated without the assistance of other NNs. The two alternate steps reinforce each other: in step (2), by predicting the learned pseudo-labels and conducting self-KD, the discrimination of the outputs of both the NN and the encoder is gradually enhanced, while the self-labeling method in step (1) leverages these two improvements to further refine the pseudo-labels for step (2), resulting in the superior performance. Extensive experiments show the proposed method significantly outperforms state-of-the-art methods across various datasets.},
  archive      = {J_TKDE},
  author       = {Yunzhi Ling and Feiping Nie and Weizhong Yu and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3561046},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4270-4284},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Self-labeling and self-knowledge distillation unsupervised feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable transactional stream processing on multicore processors. <em>TKDE</em>, <em>37</em>(7), 4254-4269. (<a href='https://doi.org/10.1109/TKDE.2025.3556741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transactional stream processing engines (TSPEs) are central to modern stream applications handling shared mutable states. However, their full potential, particularly in adaptive scheduling, remains largely unexplored. We present MorphStream, a TSPE designed to optimize parallelism and performance for transactional stream processing on multicores. Through a unique three-stage execution paradigm (i.e., planning, scheduling, and execution), MorphStream enables adaptive scheduling under varying workload characteristics. Building on this foundation, MorphStream is further enhanced with support for non-deterministic state access, employing a stateful task precedence graph to handle undefined read/write sets at runtime while guaranteeing transaction semantics. Additionally, MorphStream incorporates a generalized framework for managing window-based operations, enabling efficient tracking and maintenance of overlapping windows using multi-versioned state management. These extensions enhance the system’s ability to process dynamic and irregular workloads. Experimental results demonstrate up to 3.4 times higher throughput and 69.1% lower latency compared to state-of-the-art TSPEs, validating its scalability and adaptability in real-world streaming scenarios.},
  archive      = {J_TKDE},
  author       = {Jianjun Zhao and Yancan Mao and Zhonghao Yang and Haikun Liu and Shuhao Zhang},
  doi          = {10.1109/TKDE.2025.3556741},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4254-4269},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable transactional stream processing on multicore processors},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable and load-balanced full-graph GNN training on multiple GPUs. <em>TKDE</em>, <em>37</em>(7), 4239-4253. (<a href='https://doi.org/10.1109/TKDE.2025.3558641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While full-graph training is effective for graph learning, it typically demands substantial memory resources. Existing multi-GPU training frameworks struggle with scalability because they require retaining data for each layer within GPU memory. In this work, we present $\mathsf {HongTu }$, a memory-efficient system that supports out-of-memory full-graph GNN training on GPUs. $\mathsf {HongTu }$ offloads vertex data to CPU memory and employs partition parallelism training that splits and assigns large graphs to multiple GPUs. To reduce runtime memory consumption with optimal performance, $\mathsf {HongTu }$ utilizes a hybrid solution combining recomputation, caching, and computation-reordering, enabling efficient layer-wise intermediate data management. To address the increased communication caused by duplicated neighbor access among partitions, $\mathsf {HongTu }$ employs a deduplicated communication framework that converts host-GPU transfers into more efficient inter/intra-GPU data access. Additionally, $\mathsf {HongTu }$ tackles the load-imbalance issues in out-of-memory full-graph training, featuring a multi-objective graph partition algorithm that balances memory consumption and data transfer and maximizes the effectiveness of communication deduplication. Experiments on a 4× A100 GPU server show that $\mathsf {HongTu }$ can effectively train graphs with billion edges while reducing host-GPU data communication by 25% to 71% . Compared to the full-graph GNN system running on 16 CPU nodes, $\mathsf {HongTu }$ achieves speedups ranging from 11.4× to 21.3×.},
  archive      = {J_TKDE},
  author       = {Qiange Wang and Yao Chen and Weng-Fai Wong and Bingsheng He},
  doi          = {10.1109/TKDE.2025.3558641},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4239-4253},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable and load-balanced full-graph GNN training on multiple GPUs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting edge perturbation for graph neural network in graph data augmentation and attack. <em>TKDE</em>, <em>37</em>(7), 4225-4238. (<a href='https://doi.org/10.1109/TKDE.2025.3565306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge perturbation is a basic method to modify graph structures. It can be categorized into two veins based on their effects on the performance of graph neural networks (GNNs), i.e., graph data augmentation and attack. Surprisingly, both veins of edge perturbation methods employ the same operations, yet yield opposite effects on GNNs’ accuracy. A distinct boundary between these methods in using edge perturbation has never been clearly defined. Consequently, inappropriate perturbations may lead to undesirable outcomes, necessitating precise adjustments to achieve desired effects. Therefore, questions of “why edge perturbation has a two-faced effect?” and “what makes edge perturbation flexible and effective?” still remain unanswered. In this paper, we will answer these questions by proposing a unified formulation and establishing a quantizable boundary between two categories of edge perturbation methods. Specifically, we conduct experiments to elucidate the differences and similarities between these methods and theoretically unify the workflow of these methods by casting it to one optimization problem. Then, we devise Edge Priority Detector (EPD) to generate a novel priority metric, bridging these methods up in the workflow. Experiments show that EPD can make augmentation or attack flexibly and achieve comparable or superior performance to other counterparts with less time overhead.},
  archive      = {J_TKDE},
  author       = {Xin Liu and Yuxiang Zhang and Meng Wu and Mingyu Yan and Kun He and Wei Yan and Shirui Pan and Xiaochun Ye and Dongrui Fan},
  doi          = {10.1109/TKDE.2025.3565306},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4225-4238},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Revisiting edge perturbation for graph neural network in graph data augmentation and attack},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-label guided bidirectional discriminative deep multi-view subspace clustering. <em>TKDE</em>, <em>37</em>(7), 4213-4224. (<a href='https://doi.org/10.1109/TKDE.2025.3562723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, multi-view subspace clustering is hindered by data noise that disrupts the ideal block-diagonal structure of self-representation matrices, thereby degrading performance. Moreover, many existing methods rely solely on sample features, overlooking the valuable structural information in affinity matrices (e.g., pairwise relationships). While conventional contrastive learning strategies often introduce false negative pairs due to noise and unreliable sample selection. To address these challenges, we propose a pseudo-label guided bidirectional discriminative deep multi-view subspace clustering method (PBDMSC). Our approach first employs pseudo-label guided contrastive learning, using previous cluster assignments to select reliable positive and negative samples, which mitigates incorrect pairings and enhances low-dimensional representations. Then, a discriminative self-representation learning method is introduced that leverages pseudo-labels to enforce homogeneous expression constraints and incorporates a bidirectional attention mechanism to preserve the structured information from affinity matrices, thereby enhancing robustness. Experimental results on six real-world datasets demonstrate that our proposed method achieves state-of-the-art clustering performance.},
  archive      = {J_TKDE},
  author       = {Yongbo Yu and Zhoumin Lu and Feiping Nie and Weizhong Yu and Zongcheng Miao and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3562723},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4213-4224},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pseudo-label guided bidirectional discriminative deep multi-view subspace clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontology embedding: A survey of methods, applications and resources. <em>TKDE</em>, <em>37</em>(7), 4193-4212. (<a href='https://doi.org/10.1109/TKDE.2025.3559023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies are widely used for representing domain knowledge and meta data, playing an increasingly important role in Information Systems, the Semantic Web, Bioinformatics and many other domains. However, logical reasoning that ontologies can directly support are quite limited in learning, approximation and prediction. One straightforward solution is to integrate statistical analysis and machine learning. To this end, automatically learning vector representation for knowledge of an ontology i.e., ontology embedding has been widely investigated. Numerous papers have been published on ontology embedding, but a lack of systematic reviews hinders researchers from gaining a comprehensive understanding of this field. To bridge this gap, we write this survey paper, which first introduces different kinds of semantics of ontologies and formally defines ontology embedding as well as its property of faithfulness. Based on this, it systematically categorizes and analyses a relatively complete set of over 80 papers, according to the ontologies they aim at and their technical solutions including geometric modeling, sequence modeling and graph propagation. This survey also introduces the applications of ontology embedding in ontology engineering, machine learning augmentation and life sciences, presents a new library mOWL and discusses the challenges and future directions.},
  archive      = {J_TKDE},
  author       = {Jiaoyan Chen and Olga Mashkova and Fernando Zhapa-Camacho and Robert Hoehndorf and Yuan He and Ian Horrocks},
  doi          = {10.1109/TKDE.2025.3559023},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4193-4212},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Ontology embedding: A survey of methods, applications and resources},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuralLoss: A learnable pretrained surrogate loss for learning to rank. <em>TKDE</em>, <em>37</em>(7), 4179-4192. (<a href='https://doi.org/10.1109/TKDE.2025.3562450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to Rank (LTR) aims to develop a ranking model from supervised data to rank a set of items using machine learning techniques. However, since the losses and ranking metrics involved in LTR are both based on ranking, they are neither continuous nor differentiable, making it challenging to optimize them using gradient descent algorithms. Various surrogate losses have been proposed to address this issue, yet their connection with ranking metrics is often loose, leading to inconsistencies between optimization objectives and evaluation metrics. In this study, we introduce NeuralLoss, a learnable and pretrained surrogate loss. By undergoing training on data structured around ranking metrics, NeuralLoss approximates these ranking metrics, aligning its optimization objectives with evaluation metrics. We employ Transformer to construct the surrogate model and ensure permutation invariance. The pretrained surrogate loss facilitates end-to-end training of ranking models using gradient descent algorithms and can approximate various ranking metrics by adjusting the training data. In this paper, we employ NeuralLoss to approximate NDCG and Recall, demonstrating its performance in both document retrieval and cross-modal retrieval tasks. Experimental results indicate that our approach achieves excellent performance and exhibits strong competitiveness across these tasks.},
  archive      = {J_TKDE},
  author       = {Chen Liu and Cailan Jiang and Lixin Zhou},
  doi          = {10.1109/TKDE.2025.3562450},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4179-4192},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {NeuralLoss: A learnable pretrained surrogate loss for learning to rank},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional causality fairness learning. <em>TKDE</em>, <em>37</em>(7), 4166-4178. (<a href='https://doi.org/10.1109/TKDE.2025.3566011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal learning is a recent and widely adopted paradigm to handle algorithmic discrimination. Contemporary causality-based studies on fairness only capture the unfair causal effect of a single-dimensional sensitive attribute (i.e., individual-dimension, like gender) on the decision. They neglect the socially constructed nature of individual attributes, such as macro-dimensional factors. However, social science research shows that discrimination against an individual may be related to disadvantaged treatments, which operate at the macro-dimension (e.g., neighborhood economic level). This multi-dimensional conceptualization is pertinent to matters of fairness, and it is crucial to be fair for individuals across multiple dimensions. The hidden confounder is another bottleneck for addressing fairness concerns based on causal techniques. To tackle these issues, we present an approach, called MultiCFL, which accounts for multi-dimensional sources of discrimination and unifies them via causal tools. To handle hidden confounders, MultiCFL first trains a causal effect variational autoencoder as the causal estimator to learn the causal mechanisms behind observational data. Subsequently, it makes selective use of estimated causal relationships to construct a predictive model with multi-dimensional fairness. Experimental results confirm the effectiveness of MultiCFL, and prove the necessity of considering multiple dimensional properties to mitigate unfairness.},
  archive      = {J_TKDE},
  author       = {Cong Su and Guoxian Yu and Jun Wang and Wei Guo and Yongqing Zheng and Carlotta Domeniconi},
  doi          = {10.1109/TKDE.2025.3566011},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4166-4178},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-dimensional causality fairness learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimum $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-vertex connected graph search. <em>TKDE</em>, <em>37</em>(7), 4159-4165. (<a href='https://doi.org/10.1109/TKDE.2025.3565844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $k$-vertex connected ($k$-VC) subgraph, which remains connected with fewer than $k$ vertices being removed, is an essential structure in graph mining. It has found many applications, such as survivable network design and web search optimization. However, existing studies focus on mining maximal $k$-VCs, which are excessively large yet less cohesive in real applications. In this paper, we study the minimum $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-VC search (MinVC) problem, seeking to find a $k$-VC with the minimum number of vertices. We formally prove that this problem is NP-hard and then propose two algorithms to obtain the exact solution. The basic method, called Enum, follows a branch-and-bound framework with some pruning rules, which directly enumerates all possible vertex sets. Nonetheless, it suffers from the efficiency issues due to the non-hereditary property of the $k$-VC model. To address this challenge, we propose an advanced method, called VCtoB, which divides the MinVC problem into several new sub-problems, called the fixed-size $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-VC problems. Each of them can be solved efficiently by exploiting the hereditary property of the $s$-bundle model. Finally, our empirical experiments on 139 real-world networks demonstrate that VCtoB achieves performance improvement of up to six orders of magnitude over the baseline.},
  archive      = {J_TKDE},
  author       = {Yang Liu and Hejiao Huang and Kaiqiang Yu and Shengxin Liu and Cheng Long},
  doi          = {10.1109/TKDE.2025.3565844},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4159-4165},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Minimum $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-vertex connected graph search},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale clustering with anchor-based constrained laplacian rank. <em>TKDE</em>, <em>37</em>(7), 4144-4158. (<a href='https://doi.org/10.1109/TKDE.2025.3557718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering technique has garnered significant attention due to precise information characterization by pairwise graph similarity. Nevertheless, the post-processing step in traditional methods often limits clustering effects because of crucial information loss. Therefore, the Constrained Laplacian Rank (CLR) theory emerges to directly obtain discrete labels from optimally structural graph, achieving desirable outcomes. However, CLR suffers from substantial time overhead, making it infeasible for large-scale data analysis. To overcome this issue, we propose Anchor-based CLR (ACLR), a simple yet effective method for efficient large-scale clustering. The ACLR method comprises four stages: (1) anchors that roughly cover original data are opted to prepare bipartite graph construction; (2) a novel two-step probability transition (TSPT) strategy initializes a small-scale graph with random walk probability among anchors; (3) the main ACLR model alternately optimizes the graph connected structure and directly produces discrete anchor labels, achieving a time complexity independent of the number of samples due to dramatically reduced graph scale; and (4) labels are propagated from anchors to samples using $K$-NN algorithm. Extensive experiments demonstrate that ACLR yields superior accuracy and efficiency, particularly when applied to large-scale data.},
  archive      = {J_TKDE},
  author       = {Zhenyu Ma and Jingyu Wang and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3557718},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4144-4158},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large-scale clustering with anchor-based constrained laplacian rank},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models are in-context molecule learners. <em>TKDE</em>, <em>37</em>(7), 4131-4143. (<a href='https://doi.org/10.1109/TKDE.2025.3557697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated exceptional performance in biochemical tasks, especially the molecule caption translation task, which aims to bridge the gap between molecules and natural language texts. However, previous methods in adapting LLMs to the molecule-caption translation task required extra domain-specific pre-training stages, suffered weak alignment between molecular and textual spaces, or imposed stringent demands on the scale of LLMs. To resolve the challenges, we propose In-Context Molecule Adaptation (ICMA), as a new paradigm allowing LLMs to learn the molecule-text alignment from context examples via In-Context Molecule Tuning. Specifically, ICMA incorporates the following three stages: Hybrid Context Retrieval, Post-retrieval Re-ranking, and In-context Molecule Tuning. Initially, Hybrid Context Retrieval utilizes BM25 Caption Retrieval and Molecule Graph Retrieval to retrieve similar informative context examples. Additionally, Post-retrieval Re-ranking is composed of Sequence Reversal and Random Walk selection to further improve the quality of retrieval results. Finally, In-Context Molecule Tuning unlocks the in-context learning and reasoning capability of LLMs with the retrieved examples and adapts the parameters of LLMs for better alignment between molecules and texts. Experimental results demonstrate that ICMA can empower LLMs to achieve state-of-the-art or comparable performance without extra training corpora and intricate structures, showing that LLMs are inherently in-context molecule learners.},
  archive      = {J_TKDE},
  author       = {Jiatong Li and Wei Liu and Zhihao Ding and Wenqi Fan and Yuqiang Li and Qing Li},
  doi          = {10.1109/TKDE.2025.3557697},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4131-4143},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large language models are in-context molecule learners},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inconsistent multivariate time series forecasting. <em>TKDE</em>, <em>37</em>(7), 4117-4130. (<a href='https://doi.org/10.1109/TKDE.2025.3556940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional statistical time series forecasting models rely on model identification methods to identify the worthiest model variants to investigate; therefore, the model parameters change with the statistical features of rolling windows to reach optimality. Currently, although deep-learning-based methods achieve promising multivariate forecasting performance, their representations of variable correlations are consistent regardless of the observed local time series properties and dynamic cross-variable relations, rendering them prone to overfitting. To bridge this gap, we propose FPPformer-MD, a novel inconsistent time series forecasting transformer. FPPformer-MD leverages multiresolution analysis to transform each univariate series into multiple frequency scales and evaluate the local variable correlations via their variances. Thus, FPPformer-MD receives richer input features, and its inner inconsistent cross-variable attention mechanism enables the adaptive extraction of cross-variable features. To further alleviate the overfitting problem, we apply dynamic mode decomposition to perform cross-variable data augmentation, which reconstructs the sequence outliers with other correlated sequences during the model training process. Extensive experiments conducted on thirteen real-world benchmarks demonstrate the state-of-the-art performance of FPPformer-MD.},
  archive      = {J_TKDE},
  author       = {Li Shen and Yangzhu Wang and Xuyi Fan and Xu Yang and Huaxin Qiu},
  doi          = {10.1109/TKDE.2025.3556940},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4117-4130},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Inconsistent multivariate time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph portfolio: High-frequency factor predictors via heterogeneous continual GNNs. <em>TKDE</em>, <em>37</em>(7), 4104-4116. (<a href='https://doi.org/10.1109/TKDE.2025.3566111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to address the challenges of financial price prediction in high-frequency trading (HFT) by introducing a novel continual learning framework based on factor predictors via graph neural networks. The model integrates multi-factor pricing theory with real-time market dynamics, effectively bypassing the limitations of conventional time series forecasting methods, which often lack financial theory guidance and ignore market correlations. We propose three heterogeneous tasks, including price gap regression, changepoint detection, and price moving average regression to trace the short-, intermediate-, and long-term trend factors present in the data. We also account for the cross-sectional correlations inherent in the financial market, where prices of different assets show strong dynamic correlations. To accurately capture these dynamic relationships, we resort to spatio-temporal graph neural network (STGNN) to enhance the predictive power of the model. Our model allows a continual learning strategy to simultaneously consider these tasks (factors). To tackle the catastrophic forgetting in continual learning while considering the heterogeneity of tasks, we propose to calculate parameter importance with mutual information between original observations and the extracted features. Empirical studies on the Chinese futures data and U.S. equity data demonstrate the superior performance of the proposed model compared to other state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Min Hu and Zhizhong Tan and Bin Liu and Guosheng Yin},
  doi          = {10.1109/TKDE.2025.3566111},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4104-4116},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph portfolio: High-frequency factor predictors via heterogeneous continual GNNs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genie: A lightweight serverless infrastructure for in-memory key-value caching with fine-grained and prompt elasticity. <em>TKDE</em>, <em>37</em>(7), 4089-4103. (<a href='https://doi.org/10.1109/TKDE.2025.3556427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasing number of web applications require cloud in-memory key-value stores to minimize latency and achieve higher throughput. They generally have diverse characteristics and constantly changing traffic volumes, which require different computational and memory resources. A serverless in-memory key-value store characterized by elastic resource allocation and pay-as-you-go billing could satisfy the requirements of diverse and dynamic workloads. However, we find current serverless IMKVs fail to achieve fine-grained and prompt resource elasticity due to the limitations of their infrastructures. This paper proposes Genie, a lightweight serverless infrastructure for in-memory key-value caching with fine-grained and immediate elasticity. In Genie, a novel approach is adopted to enable dynamic and independent resource allocation to multiple tenants. It processes all arrived requests and estimates the vCPU consumption with a lightweight machine-learning approach for fine-grained billing. Moreover, Genie estimates the working set and dynamically resizes the allocated memory for hit ratio requirements. Evaluation results show that CPU estimation could be achieved every 100 microseconds without impacting system performance, and memory capacity could be adjusted by megabytes within seconds. The holistic design incurs 1% -2% performance degradation compared to our baseline. Moreover, Genie achieves an average of 58.3% CPU and 49.9% memory savings compared to AsparaDB for Memcache.},
  archive      = {J_TKDE},
  author       = {Huijuan Xiao and Shixi Yang and Kai Zhang and Yinan Jing and Zhenying He and X. Sean Wang},
  doi          = {10.1109/TKDE.2025.3556427},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4089-4103},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Genie: A lightweight serverless infrastructure for in-memory key-value caching with fine-grained and prompt elasticity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCTN: Graph competitive transfer network for cross-domain multi-behavior prediction. <em>TKDE</em>, <em>37</em>(7), 4075-4088. (<a href='https://doi.org/10.1109/TKDE.2025.3554610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the multi-behavior information on a specific domain has been successfully exploited by aggregating diverse user behaviors to solve the problems of cold start and data sparsity in recommendations. However, the user behavior information captured from multiple behaviors in a single domain is insufficient. Our study seeks to enhance user behavior prediction by leveraging both multi-behavior information and cross-domain information in a more effective manner. In order to explore the correlations and differences between different behaviors and different domains, we propose a novel competition framework consists of intra-domain competition and inter-domain competition for knowledge learning. Specifically, for intra-domain, a behavior competition mechanism is designed to enable the model to mine users’ interests and behavior patterns effectively. For inter-domain, a domain competition mechanism is designed to perform knowledge transfer and knowledge fusion for overlapping users in different domains. Through the competition mechanisms, our proposed Graph Competitive Transfer Network (GCTN) achieves knowledge transfer between different domains and captures users’ behavior patterns in different contexts. The effectiveness of the GCTN and its competition mechanisms has been validated through sufficient experimental trials on Douban and Amazon datasets. Compared to baseline methods, GCTN has demonstrated a marked improvement in both $AUC$ and $F1$ scores.},
  archive      = {J_TKDE},
  author       = {Lei Zhang and Wuji Zhang and Likang Wu and Hongke Zhao},
  doi          = {10.1109/TKDE.2025.3554610},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4075-4088},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GCTN: Graph competitive transfer network for cross-domain multi-behavior prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FeBT: A feature balancing transformer for corporate ESG forecasting. <em>TKDE</em>, <em>37</em>(7), 4063-4074. (<a href='https://doi.org/10.1109/TKDE.2025.3560137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental, social, and governance (ESG) serves as a crucial indicator for evaluating firms in terms of sustainable development. However, the existing ESG evaluation systems suffer from limitations, such as narrow coverage, subjective bias, and lack of timeliness. Therefore, there is a pressing need to leverage machine learning methods to predict the ESG performance of firms using their publicly available data. Traditional machine learning models encounter the feature imbalance problem due to the heterogeneity in ESG-related features. Common approaches typically involve unfolding all features, thereby granting high-dimensional folding features greater exposure and accessibility to downstream models, which results in the neglect of low-dimensional features. To fill the research gap regarding fully using the heterogeneous features of enterprises to enhance AI-based ESG prediction performance, we propose the Feature Balancing Transformer (FeBT), a model based on autoencoders and Transformer blocks. FeBT incorporates a novel feature balancing technique that compresses and enhances high-dimensional features from imbalanced data into low-dimensional representations, thereby ensuring a more balanced impact of high-dimensional and low-dimensional features on the model’s performance in the downstream ESG forecasting module. Extensive experiments verified the superior performance of FeBT compared with state-of-the-art methods in real-world ESG-related datasets and evidenced that our feature balancing module provides significant insights from high-dimensional folding features.},
  archive      = {J_TKDE},
  author       = {Yawen Li and Mengyu Zhuang and Guanhua Ye and Yan Li and Junheng Wang and Jinyi Zhou and Pengfei Zhang},
  doi          = {10.1109/TKDE.2025.3560137},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4063-4074},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FeBT: A feature balancing transformer for corporate ESG forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairCoRe: Fairness-aware recommendation through counterfactual representation learning. <em>TKDE</em>, <em>37</em>(7), 4049-4062. (<a href='https://doi.org/10.1109/TKDE.2025.3557501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eliminating bias from data representations is crucial to ensure fairness in recommendation. Existing studies primarily focus on weakening the correlation between data representations and sensitive attributes, yet may inadvertently steer the user representations toward another potential bias direction of the target attribute. Furthermore, they often overlook the impact of user preferences on capturing sensitive information, incurring inadequate bias elimination. In this paper, we propose a Fair Counterfactual Representations (FairCoRe) learning framework, which aims to ensure the neutrality of representations among all bias directions. First, we intervene on sensitive attributes to construct a counterfactual scenario. Then, two opposing attribute prediction tasks are respectively performed in ground-truth and counterfactual scenarios to encode sensitive information along different bias directions. Second, we design a bias-aware enhancement learning method that quantifies the respective correlation of user preferences and sensitive attributes to enhance sensitive information encoding. Finally, we introduce two mutual information optimization methods that optimize the representations to capture users’ interests and disentangle sensitive factors. Moreover, we propose an attribute neutralization strategy that refines the learned representations, ensuring sensitive attribute neutrality. Extensive experiments demonstrate that our method achieves the optimal fairness and competitive accuracy compared to state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Chenzhong Bin and Wenqiang Liu and Feng Zhang and Liang Chang and Tianlong Gu},
  doi          = {10.1109/TKDE.2025.3557501},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4049-4062},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FairCoRe: Fairness-aware recommendation through counterfactual representation learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EPM: Evolutionary perception method for anomaly detection in noisy dynamic graphs. <em>TKDE</em>, <em>37</em>(7), 4035-4048. (<a href='https://doi.org/10.1109/TKDE.2025.3561191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion of interactions across various domains such as social networks, transaction networks, and IP-IP networks, anomaly detection in dynamic graphs has become increasingly critical for mitigating potential risks. However, existing anomaly detection methods often assume noise-free dynamic graphs, overlooking the prevalence of noisy dynamic graphs in real-world applications. Specifically, noisy dynamic graphs affected by structural noises—such as spurious and missing nodes and edges—struggle to consistently provide reliable structural evidence for anomaly detection. To tackle this challenge, we propose an Evolutionary Perception Method (EPM) for identifying anomalous nodes in noisy dynamic graphs by resisting the interference of structural noises. EPM primarily consists of two components: a dynamic fitter and a filtering reviser. The dynamic fitter characterizes the interaction dynamics of nodes that removes and generates links at each period as a multiple superposition state, utilizing various link prediction algorithms to fit evolutionary mechanisms. Additionally, the filtering reviser designs evolutional entropies to quantify the evolutional uncertainty in multiple superposition states, further reconstructing the Kalman filter to optimize these entropies. Extensive experiments have proved that our proposed EPM outperforms state-of-the-art methods in discovering anomalous nodes in noisy dynamic graphs.},
  archive      = {J_TKDE},
  author       = {Huan Wang and Junyang Chen and Yirui Wu and Victor C. M. Leung and Di Wang},
  doi          = {10.1109/TKDE.2025.3561191},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4035-4048},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {EPM: Evolutionary perception method for anomaly detection in noisy dynamic graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation via learning using statistical invariant. <em>TKDE</em>, <em>37</em>(7), 4023-4034. (<a href='https://doi.org/10.1109/TKDE.2025.3565780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation has found widespread applications in real-life scenarios, especially when the target domain has limited labeled samples. However, most of the domain adaptation models only utilize one type of knowledge from the source domain, which is usually achieved by strong mode of convergence. To fully incorporate multiple knowledge from the source domain, for binary classification, this paper studies a novel learning paradigm for Domain Adaptation via Learning Using Statistical Invariant by simultaneously combining the strong and weak modes of convergence in a Hilbert space. The strong mode of convergence undertakes the mission of learning a least squares probability output binary classification task in a general hypothesis space, while the weak mode of convergence integrates diverse knowledge by constructing meaningful statistical invariants that embody the concept of intelligence. The utilization of weak convergence shrinks the admissible set of approximation functions, and subsequently accelerates the learning process. In this paper, several statistical invariants that represent sample, feature and parameter information from the source domain are constructed. By taking an appropriate statistical invariant, DLUSI realizes some existing methods. Experimental results on synthetic data as well as the widely used Amazon Reviews and 20 News data demonstrate the superiority of the proposed method.},
  archive      = {J_TKDE},
  author       = {Chunna Li and Yiwei Song and Yuan-Hai Shao},
  doi          = {10.1109/TKDE.2025.3565780},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4023-4034},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Domain adaptation via learning using statistical invariant},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangling dynamics: Advanced, scalable and explainable imputation for multivariate time series. <em>TKDE</em>, <em>37</em>(7), 4010-4022. (<a href='https://doi.org/10.1109/TKDE.2025.3558405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values pose a formidable obstacle in multivariate time series analysis. Existing imputation methods rely on entangled representations that struggle to simultaneously capture multiple orthogonal time-series patterns, leading to suboptimal performance and limited interpretability. Meanwhile, requiring the entire data span as input renders these models impractical for long time series. To address these issues, we propose $\mathsf {TIDER}$ and its enhanced version, $\mathsf {AdaTIDER}$. $\mathsf {TIDER}$ employs low-rank matrix factorization and disentangled temporal representations to model intricate dynamics like trend, seasonality, and local bias. However, $\mathsf {TIDER}$ is limited to single-period modeling and does not explicitly capture dependencies between channels. To overcome these limitations, $\mathsf {AdaTIDER}$ incorporates adaptive cross-channel dependency modeling and multi-period seasonality representations. These advancements enable it to dynamically capture variable relationships and complex multi-period patterns, significantly enhancing imputation accuracy and interpretability, while maintaining $\mathsf {TIDER}$’s scalability. Extensive experiments on real-world datasets validate the superiority of our models in imputation accuracy, scalability, interpretability, and robustness.},
  archive      = {J_TKDE},
  author       = {Shuai Liu and Xiucheng Li and Yile Chen and Yue Jiang and Gao Cong},
  doi          = {10.1109/TKDE.2025.3558405},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4010-4022},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Disentangling dynamics: Advanced, scalable and explainable imputation for multivariate time series},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering cliques in attribute graphs based on proportional fairness. <em>TKDE</em>, <em>37</em>(7), 4003-4009. (<a href='https://doi.org/10.1109/TKDE.2025.3559994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a fundamental problem and has been extensively studied. With the abundance of information in real-world networks, the discovery of communities in attribute graphs is increasingly valuable. However, numerous previous models in attribute graphs neglect the fairness concept, which plays an important role in ensuring that graph analysis is not biased toward specific groups. In this paper, we propose a novel model, named proportional fair clique (PFC). Specifically, given an attribute graph $G=(V,E,A)$, an integer $k$ and a threshold $\lambda \in [0,1/|A|]$, a subgraph $S$ of $G$ is a PFC if $(i)$ $S$ is a clique with size at least $k$ and $(ii)$ $|S_{a_{i}}|/|S| \geq \lambda$ for each attribute $a_{i}$ in $G$, where $S_{a_{i}}$ is the node set in $S$ associated with attribute $a_{i}$. We show that the problem of enumerating all the maximal proportional fair cliques (MPFC) is NP-hard. A reasonable baseline algorithm is first presented by extending the Bron-Kerbosch framework. To scale for large networks, we propose several optimization strategies to accelerate the computation. Finally, comprehensive experiments are conducted over 6 graphs to demonstrate the efficiency and effectiveness of the proposed techniques and model.},
  archive      = {J_TKDE},
  author       = {Yongye Li and Renjie Sun and Chen Chen and Xiaoyang Wang and Ying Zhang and Wenjie Zhang},
  doi          = {10.1109/TKDE.2025.3559994},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {4003-4009},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discovering cliques in attribute graphs based on proportional fairness},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct spectral clustering with new graph learning for better fitting. <em>TKDE</em>, <em>37</em>(7), 3991-4002. (<a href='https://doi.org/10.1109/TKDE.2025.3533040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional spectral clustering methods struggle with scalability and robustness in large datasets due to their reliance on similarity matrices and EigenValue Decomposition. We introduce two innovative models: Rcut-based Coordinate Descent Clustering (R-CDC) and Ncut-based Doubly Stochastic Clustering (N-DSC). These models integrate graph construction and segmentation into a unified process optimized through the coordinate descent method, significantly enhancing clustering efficacy. A novel graph structure enhances robustness against noise and outliers, simplifying the clustering process and improving outcomes across diverse datasets. Our extensive experiments show that these models surpass existing spectral clustering techniques in managing large-scale data and complex structures.},
  archive      = {J_TKDE},
  author       = {Lingyi Kong and Jingjing Xue and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3533040},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3991-4002},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Direct spectral clustering with new graph learning for better fitting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decider: A dual-system rule-controllable decoding framework for language generation. <em>TKDE</em>, <em>37</em>(7), 3976-3990. (<a href='https://doi.org/10.1109/TKDE.2025.3554819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained decoding approaches aim to control the meaning or style of text generated by a Pre-trained Language Model (PLM) for various task-specific objectives at inference time. However, these methods often guide plausible continuations by greedily and explicitly selecting targets, which, while fulfilling the task requirements, may overlook the natural patterns of human language generation. In this work, we propose a novel decoding framework, Decider, which enables us to program high-level rules on how we might effectively complete tasks to control a PLM. Differing from previous works, our framework transforms the encouragement of concrete target words into the encouragement of all words that satisfy the high-level rules. Specifically, Decider is a dual system in which a PLM is equipped and controlled by a First-Order Logic (FOL) reasoner to express and evaluate the rules, along with a decision function that merges the outputs from both systems to guide the generation. Experiments on CommonGen and PersonaChat demonstrate that Decider can effectively follow given rules to guide a PLM in achieving generation tasks in a more human-like manner.},
  archive      = {J_TKDE},
  author       = {Chen Xu and Tian Lan and Yu Ji and Changlong Yu and Wei Wang and Jun Gao and Qunxi Dong and Kun Qian and Piji Li and Wei Bi and Bin Hu},
  doi          = {10.1109/TKDE.2025.3554819},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3976-3990},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Decider: A dual-system rule-controllable decoding framework for language generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data synthesis reinvented: Preserving missing patterns for enhanced analysis. <em>TKDE</em>, <em>37</em>(7), 3962-3975. (<a href='https://doi.org/10.1109/TKDE.2025.3563319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data is being widely used as a replacement or enhancement for real data in fields as diverse as healthcare, telecommunications, and finance. Unlike real data, which represents actual people and objects, synthetic data is generated from an estimated distribution that retains key statistical properties of the real data. This makes synthetic data attractive for sharing while addressing privacy, confidentiality, and autonomy concerns. Real data often contains missing values that hold important information about individual, system, or organizational behavior. Standard synthetic data generation methods eliminate missing values as part of their pre-processing steps and thus completely ignore this valuable source of information. Instead, we propose methods to generate synthetic data that preserve both the observable and missing data distributions; consequently, retaining the valuable information encoded in the missing patterns of the real data. Our approach handles various missing data scenarios and can easily integrate with existing data generation methods. Extensive empirical evaluations on diverse datasets demonstrate the effectiveness of our approach as well as the value of preserving missing data distribution in synthetic data.},
  archive      = {J_TKDE},
  author       = {Xinyue Wang and Hafiz Asif and Shashank Gupta and Jaideep Vaidya},
  doi          = {10.1109/TKDE.2025.3563319},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3962-3975},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Data synthesis reinvented: Preserving missing patterns for enhanced analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Charging-aware task assignment for urban logistics with electric vehicles. <em>TKDE</em>, <em>37</em>(7), 3947-3961. (<a href='https://doi.org/10.1109/TKDE.2025.3565858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of e-commerce has intensified the demand for efficient urban logistics. Electric Vehicles (EVs), with their eco-friendly and high-efficiency features, have emerged as a promising solution for improving urban logistics efficiency. However, due to their limited battery capacity, EVs often require recharging during operations, and improper charging decisions may lead to delivery delays, resulting in a loss of platform revenue. In this paper, we explore a novel EV Charging-Aware Task Assignment (ECTA) problem in urban logistics scenarios, where the objective is to maximize platform revenue by ensuring timely task completion while meeting the charging needs of EVs. To address this challenge, we present e-Charge, an efficient two-stage framework that enables real-time optimization of two continuous processes: task assignment and charging decision. For task assignment, which focuses on matching tasks to suitable EVs, we construct a hybrid weight model that incorporates charging penalties to calculate matching weights for EVs in both active and charging states, thus improving task assignment quality. Additionally, we implement an effective vehicle selection strategy to expedite the matching process, ensuring the efficiency of task assignment. For charging decision, which focuses on determining when and where EVs should be charged, we propose a multi-agent reinforcement learning (MARL) approach to dynamically select the charging timing for EVs. To further enhance decision-making quality, we devise a hierarchical communication graph that enables better collaboration between EVs and facilitates adaptive charging decisions. Finally, extensive experiments demonstrate that e-Charge significantly outperforms compared methods, achieving higher revenue and task completion ratio across a wide range of parameter settings.},
  archive      = {J_TKDE},
  author       = {Yafei Li and Yuke Pan and Guanglei Zhu and Shuo He and Mingliang Xu and Jianliang Xu},
  doi          = {10.1109/TKDE.2025.3565858},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3947-3961},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Charging-aware task assignment for urban logistics with electric vehicles},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal label enhancement. <em>TKDE</em>, <em>37</em>(7), 3933-3946. (<a href='https://doi.org/10.1109/TKDE.2024.3512938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label enhancement (LE) is still a challenging task to mitigate the dilemma of the lack of label distribution. Existing LE work typically focuses on primarily formulating a projection between feature space and label distribution space from discriminative model perspective, which preserves the relevance consistency that the sign of recovered label distribution should be consistent with the logical label. Different from previous algorithms, we formulate this problem from a causal perspective and present a novel LE method via the structured causal model (LESCM). Specifically, the proposed LESCM deliberates establishing the causal graph with assuming that label distribution is a cause of feature and logical label, which naturally satisfies the definition of label distribution learning (LDL). With capturing the underlying causal relationships, we can significantly boost the interpretability and identifiability of label enhancement. Meanwhile, except for the relevance consistency, LESCM are encouraged to sustain the order consistency that assigns higher description degree of the recovered label distribution to the positive labels, as compared with the negative labels. Empirically, sufficient experiments on several label distribution learning data sets validate the effectiveness of LESCM.},
  archive      = {J_TKDE},
  author       = {Xinyuan Liu and Jihua Zhu and Qinghai Zheng and Zhongyu Li and Zhiqiang Tian and Mingchen Zhu},
  doi          = {10.1109/TKDE.2024.3512938},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3933-3946},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Causal label enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camouflaged variational graph AutoEncoder against attribute inference attacks for cross-domain recommendation. <em>TKDE</em>, <em>37</em>(7), 3916-3932. (<a href='https://doi.org/10.1109/TKDE.2025.3565793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation (CDR) aims to alleviate the data sparsity problem by leveraging the benefits of modeling two domains. However, existing research often focuses on the recommendation performance while ignores the privacy leakage issue. We find that an attacker can infer user attribute information from the knowledge (e.g., user preferences) transferred between the source and target domains. For example, in our experiments, the average inference accuracies of attack models on gender and age attributes are 0.8323 and 0.3897. The best-performing attack model achieves accuracies of 0.8847 and 0.4634, exceeding a random inference by 25.10% and 64.04%. We can see that the leakage of user attribute information may significantly exceed what would be expected from random inference. In this paper, we propose a novel recommendation framework named CVGAE (short for camouflaged variational graph autoencoder), which effectively models user behaviors and mitigates the risk of user attribute information leakage at the same time. Specifically, our CVGAE combines the strengths of VAEs in capturing latent features and variability with the ability of GCNs in exploiting high-order relational information. Moreover, to ensure against attribute inference attacks without sacrificing the recommendation performance, we design a user attribute protection module that fuses user attribute-camouflaged information with knowledge transfer during cross-domain processes. We then conduct extensive experiments on three real-world datasets, and find our CVGAE is able to achieve strong privacy protection while making little sacrifices in recommendation accuracy.},
  archive      = {J_TKDE},
  author       = {Yudi Xiong and Yongxin Guo and Weike Pan and Qiang Yang and Zhong Ming and Xiaojin Zhang and Han Yu and Tao Lin and Xiaoying Tang},
  doi          = {10.1109/TKDE.2025.3565793},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3916-3932},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Camouflaged variational graph AutoEncoder against attribute inference attacks for cross-domain recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on mixture of experts in large language models. <em>TKDE</em>, <em>37</em>(7), 3896-3915. (<a href='https://doi.org/10.1109/TKDE.2025.3554028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have garnered unprecedented advancements across diverse fields, ranging from natural language processing to computer vision and beyond. The prowess of LLMs is underpinned by their substantial model size, extensive and diverse datasets, and the vast computational power harnessed during training, all of which contribute to the emergent abilities of LLMs (e.g., in-context learning) that are not present in small models. Within this context, the mixture of experts (MoE) has emerged as an effective method for substantially scaling up model capacity with minimal computation overhead, gaining significant attention from academia and industry. Despite its growing prevalence, there lacks a systematic and comprehensive review of the literature on MoE. This survey seeks to bridge that gap, serving as an essential resource for researchers delving into the intricacies of MoE. We first briefly introduce the structure of the MoE layer, followed by proposing a new taxonomy of MoE. Next, we overview the core designs for various MoE models including both algorithmic and systemic aspects, alongside collections of available open-source implementations, hyperparameter configurations and empirical evaluations. Furthermore, we delineate the multifaceted applications of MoE in practice, and outline some potential directions for future research.},
  archive      = {J_TKDE},
  author       = {Weilin Cai and Juyong Jiang and Fan Wang and Jing Tang and Sunghun Kim and Jiayi Huang},
  doi          = {10.1109/TKDE.2025.3554028},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3896-3915},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on mixture of experts in large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable algorithm for fair influence maximization with unbiased estimator. <em>TKDE</em>, <em>37</em>(7), 3881-3895. (<a href='https://doi.org/10.1109/TKDE.2025.3564283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fair influence maximization problem with efficient algorithms. In particular, given a graph $G$, a community structure ${\mathcal {C}}$ consisting of disjoint communities, and a budget $k$, the problem asks to select a seed set $S$ ($|S|=k$) that maximizes the influence spread while narrowing the influence gap between different communities. This problem derives from some significant social scenarios, such as health interventions (e.g. suicide/HIV prevention) where individuals from underrepresented groups or LGBTQ communities may be disproportionately excluded from the benefits of the intervention. To depict the concept of fairness in the context of influence maximization, researchers have proposed various notions of fairness, where the welfare fairness notion that better balances fairness level and influence spread has shown promising effectiveness. However, the lack of efficient algorithms for optimizing the objective function under welfare fairness restricts its application to networks of only a few hundred nodes. In this paper, we modify the objective function of welfare fairness to maximize the exponentially weighted sum and the logarithmically weighted sum over all communities’ influenced fractions (utility). To achieve efficient algorithms with theoretical guarantees, we first introduce two unbiased estimators: one for the fractional power of the arithmetic mean and the other for the logarithm of the arithmetic mean. Then, by adapting the Reverse Influence Sampling (RIS) approach, we convert the optimization problem to a weighted maximum coverage problem. We also analyze the number of reverse reachable sets needed to approximate the fair influence at a high probability. Finally, we present an efficient algorithm that guarantees $1-1/e - \varepsilon$ (positive objective function) or $1+1/e + \varepsilon$ (negative objective function) approximation for any small $\varepsilon &gt; 0$. Experiments demonstrate that our proposed algorithm could efficiently handle large-scale networks with good performance.},
  archive      = {J_TKDE},
  author       = {Xiaobin Rui and Zhixiao Wang and Hao Peng and Wei Chen and Philip S. Yu},
  doi          = {10.1109/TKDE.2025.3564283},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3881-3895},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A scalable algorithm for fair influence maximization with unbiased estimator},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A local community detection method based on folded subgraph. <em>TKDE</em>, <em>37</em>(7), 3869-3880. (<a href='https://doi.org/10.1109/TKDE.2025.3563100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure refers to the “small groups” in the network. Detecting community structure in networks has significant application value. With the continuous expansion and complexity of the network, the global information of the network is often difficult to obtain. On the other hand, in some cases, we pay more attention to the local community where the given node is located. Local community detection methods detect local community structure by using local information from a given node. However, many local community detection methods encounter the problem of precision limitation. Therefore, in order to alleviate such problems, we propose the FG-based method in this paper. Based on the characteristics of complex networks, a folded subgraph method is designed to consider some similar nodes as single nodes, reducing the impact of noise in the network. Furthermore, based on the folded subgraph, FG-based method designs a three-stage local expansion strategy, in which nodes with different characteristics are added to the local community in each stage. We conduct experiments on datasets and find that the FG-based method can improve the recall and precision of local community structures.},
  archive      = {J_TKDE},
  author       = {Mengting Zhang and Weihong Bi},
  doi          = {10.1109/TKDE.2025.3563100},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3869-3880},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A local community detection method based on folded subgraph},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-level augmentation framework for time series forecasting with ambiguously related source data. <em>TKDE</em>, <em>37</em>(7), 3855-3868. (<a href='https://doi.org/10.1109/TKDE.2025.3555530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical time series forecasting (TSF) tasks are plagued by data limitations. To alleviate this challenge, we design a data-level augmentation framework. It involves a time series generation (TSG) module and a source data selection (Sel-src) module. TSG aims to achieve better generation results by considering both the global profile and temporal dynamics of series. However, when only few target data is available, TSG module may tend to simulate the limited target samples, leading to poor generalization performance. A natural idea for this problem is to seek help from related source domain, which can provide additional useful information for TSG module. Here we consider a more complex situation, where the relevance between source and target domains is ambiguous. That is, irrelevant samples may exist in the source domain. Blindly using all the source data may lead to counterproductive results. To meet this challenge, Sel-src module is designed to select effective source samples by Inter-Representation Learning (Inter-RL) and Intra-Representation Learning (Intra-RL). Effectiveness of this algorithm is underpinned from two aspects: the quality of the augmented data and the accuracy improvement upon the augmentation.},
  archive      = {J_TKDE},
  author       = {Rui Ye and Qun Dai},
  doi          = {10.1109/TKDE.2025.3555530},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {7},
  number       = {7},
  pages        = {3855-3868},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A data-level augmentation framework for time series forecasting with ambiguously related source data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zkfhed: A verifiable and scalable blockchain-enhanced federated learning system. <em>TKDE</em>, <em>37</em>(6), 3841-3854. (<a href='https://doi.org/10.1109/TKDE.2025.3550546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging paradigm that enables multiple clients to collaboratively train a machine learning (ML) model without the need to exchange their raw data. However, it relies on a centralized authority to coordinate participants’ activities. This not only interrupts the entire training task in case of a single point of failure, but also lacks an effective regulatory mechanism to prevent malicious behavior. Although blockchain, with its decentralized architecture and data immutability, has significantly advanced the development of FL, it still struggles to withstand poisoning attacks and faces limitations in computational scalability. We propose Zkfhed, a verifiable and scalable FL system that overcomes the limitations of blockchain-based FL in poison attacks and computational scalability. First, we propose a two-stage audit scheme based on zero-knowledge proofs (ZKPs), which verifies that the training data are extracted from trusted organizations and that computations on the data exactly follow the specified training protocols. Second, we propose a homomorphic encryption delegation learning (HEDL), based on fully homomorphic encryption (FHE). It is capable of outsourcing complex computing to external computing resources without sacrificing the client's data privacy. Final, extensive experiments on real-world datasets demonstrate that Zkfhed can effectively identify malicious clients and is highly efficient and scalable in terms of online time and communication efficiency.},
  archive      = {J_TKDE},
  author       = {Bingxue Zhang and Guangguang Lu and Yuncheng Wu and Kunpeng Ren and Feida Zhu},
  doi          = {10.1109/TKDE.2025.3550546},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3841-3854},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Zkfhed: A verifiable and scalable blockchain-enhanced federated learning system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Valuing training data via causal inference for in-context learning. <em>TKDE</em>, <em>37</em>(6), 3824-3840. (<a href='https://doi.org/10.1109/TKDE.2025.3546761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-context learning (ICL) empowers large pre-trained language models (PLMs) to predict outcomes for unseen inputs without parameter updates. However, the efficacy of ICL heavily relies on the choice of demonstration examples. Randomly selecting from the training set frequently leads to inconsistent performance. Addressing this challenge, this study takes a novel approach by focusing on training data valuation through causal inference. Specifically, we introduce the concept of average marginal effect (AME) to quantify the contribution of individual training samples to ICL performance, encompassing both its generalization and robustness. Drawing inspiration from multiple treatment effects and randomized experiments, we initially sample diverse training subsets to construct prompts and evaluate the ICL performance based on these prompts. Subsequently, we employ Elastic Net regression to collectively estimate the AME values for all training data, considering subset compositions and inference performance. Ultimately, we prioritize samples with the highest values to prompt the inference of the test data. Across various tasks and with seven PLMs ranging in size from 0.8B to 33B, our approach consistently achieves state-of-the-art performance. Particularly, it outperforms Vanilla ICL and the best-performing baseline by an average of 14.1% and 5.2%, respectively. Moreover, prioritizing the most valuable samples for prompting leads to a significant enhancement in performance stability and robustness across various learning scenarios. Impressively, the valuable samples exhibit transferability across diverse PLMs and generalize well to out-of-distribution tasks.},
  archive      = {J_TKDE},
  author       = {Xiaoling Zhou and Wei Ye and Zhemg Lee and Lei Zou and Shikun Zhang},
  doi          = {10.1109/TKDE.2025.3546761},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3824-3840},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Valuing training data via causal inference for in-context learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Valid coverage oriented item perspective recommendation. <em>TKDE</em>, <em>37</em>(6), 3810-3823. (<a href='https://doi.org/10.1109/TKDE.2025.3547968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, mainstream recommendation systems have achieved remarkable success in recommending items that align with user interests. However, limited attention has been paid to the perspective of item providers. Content providers often desire that all their offerings, including unpopular or cold items, are displayed and appreciated by users. To tackle the challenges of unfair exhibition and limited item acceptance coverage, we introduce a novel recommendation perspective that enables items to “select” their most relevant users. We further introduce ItemRec, a straightforward plug-and-play approach that leverages mutual scores calculated by any model. The goal is to maximize the recommendation and acceptance of items by users. Through extensive experiments on three real-world datasets, we demonstrate that ItemRec can enhance valid coverage by up to 38.5% while maintaining comparable or superior recommendation quality. This improvement comes with only a minor increase in model inference time, ranging from 1.5% to 5%. Furthermore, when compared to thirteen state-of-the-art recommendation methods across accuracy, fairness, and diversity, ItemRec exhibits significant advantages as well. Specifically, ItemRec achieves an optimal balance between precision and valid coverage, showcasing an efficiency gain ranging from 1.8 to 45 times compared to other fairness-oriented methodologies.},
  archive      = {J_TKDE},
  author       = {Ruijia Ma and Yahong Lian and Rongbo Qi and Chunyao Song and Tingjian Ge},
  doi          = {10.1109/TKDE.2025.3547968},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3810-3823},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Valid coverage oriented item perspective recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-friendly and expressive forward-secure attribute-based signature with server-aided signature and outsourced verification. <em>TKDE</em>, <em>37</em>(6), 3794-3809. (<a href='https://doi.org/10.1109/TKDE.2025.3554973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute-based signature (ABS) is an attractive variation of digital signature that enables signers to sign messages with fine-grained signature predicates. In ABS, a signer is able to perform signing operations without revealing personal attributes, and verifiers can only confirm that the signature was created by someone with attributes satisfying a specific signature predicate. However, traditional ABS suffers from key exposure, and the compromise of a signer’s signature key results in invalidating all signatures from him/her. To address this problem, forward-secure ABS (FS-ABS) was introduced. Nevertheless, existing FS-ABS schemes have the shortcomings of low policy expressiveness and high computation costs, and thus are not suitable to be employed on mobile devices with limited resources. In this paper, we propose a user-friendly and expressive FS-ABS (UEFS-ABS) scheme that is proven secure in the standard model. The proposed scheme not only supports expressive signature predicates based on the linear secret sharing scheme, but also provides server-aided signature and outsourced verification functions, significantly reducing the workload of user terminals at both signature generation and verification stages. The experiments indicate that compared with the up-to-date FS-ABS scheme, our scheme reduces the computation costs for signature generation (on signers’ devices) and verification (on verifiers’ devices) by about 85% and 68%, respectively. This makes our scheme more suitable for user terminals in mobile computing scenarios.},
  archive      = {J_TKDE},
  author       = {Chao Guo and Yang Lu and Nian Xia and Jiguo Li},
  doi          = {10.1109/TKDE.2025.3554973},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3794-3809},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {User-friendly and expressive forward-secure attribute-based signature with server-aided signature and outsourced verification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty calibration for counterfactual propensity estimation in recommendation. <em>TKDE</em>, <em>37</em>(6), 3781-3793. (<a href='https://doi.org/10.1109/TKDE.2025.3552658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-click conversion rate (CVR) is a reliable indicator of online customers’ preferences, making it crucial for developing recommender systems. A major challenge in predicting CVR is severe selection bias, arising from users’ inherent self-selection behavior and the system’s item selection process. To mitigate this issue, the inverse propensity score (IPS) is employed to weight the prediction error of each observed instance. However, current propensity score estimations are unreliable due to the lack of a quality measure. To address this, we evaluate the quality of propensity scores from the perspective of uncertainty calibration, proposing the use of Expected Calibration Error (ECE) as a measure of propensity-score quality, which quantifies the extent to which predicted probabilities are overconfident by assessing the difference between predicted probabilities and actual observed frequencies. Miscalibrated propensity scores can lead to distorted IPS weights, thereby compromising the debiasing process in CVR prediction. In this paper, we introduce a model-agnostic calibration framework for propensity-based debiasing of CVR predictions. Theoretical analysis on bias and generalization bounds demonstrates the superiority of calibrated propensity estimates over uncalibrated ones. Experiments conducted on the Coat, Yahoo and KuaiRand datasets show improved uncertainty calibration, as evidenced by lower ECE values, leading to enhanced CVR prediction outcomes.},
  archive      = {J_TKDE},
  author       = {Wenbo Hu and Xin Sun and Qiang Liu and Le Wu and Liang Wang},
  doi          = {10.1109/TKDE.2025.3552658},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3781-3793},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Uncertainty calibration for counterfactual propensity estimation in recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards target sequential rules. <em>TKDE</em>, <em>37</em>(6), 3766-3780. (<a href='https://doi.org/10.1109/TKDE.2025.3547394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, sequential rule mining (SRM) can offer prediction and recommendation functions for a variety of services. It is an important technique of pattern mining to discover all valuable rules that can reveal the temporal relationship between objects. Although several algorithms of SRM are proposed to solve various practical problems, there are no studies on the problem of targeted mining. Targeted sequential rule mining aims to obtain those interesting sequential rules that users focus on, thus avoiding the generation of other invalid and unnecessary rules. It can further improve the efficiency of users in analyzing rules and reduce the consumption of computing resources. In this paper, we first present the relevant definitions of target sequential rules and formulate the problem of targeted sequential rule mining. Then, we propose an efficient algorithm called TaSRM. Several pruning strategies and an optimization are introduced to improve the efficiency of TaSRM. Finally, a large number of experiments are conducted on different benchmarks, and we analyze the results in terms of running time, memory consumption, and scalability, as well as query cases with different query rules. It is shown that the novel algorithm TaSRM and its variants can achieve better experimental performance compared to the baseline algorithm.},
  archive      = {J_TKDE},
  author       = {Wensheng Gan and Gengsen Huang and Jian Weng and Tianlong Gu and Philip S. Yu},
  doi          = {10.1109/TKDE.2025.3547394},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3766-3780},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards target sequential rules},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topic videolization: A rumor detection method inspired by video forgery detection technology. <em>TKDE</em>, <em>37</em>(6), 3753-3765. (<a href='https://doi.org/10.1109/TKDE.2025.3543852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study was inspired by video forgery detection techniques. If the topic space at a certain time is considered as a frame image, the consecutive frame images over time could be viewed as a video. Then the rumor topic detection problem is transformed into a topic video forgery detection problem. Thus, a novel rumor detection method was proposed. First, a Topic2RGB algorithm was proposed to convert comment users into pixel points. The algorithm views commenting users as pixel points while using game theory to mine user pro-opposition emotions as RGB information. Secondly, a Topic2Video algorithm was proposed to convert the topic space into video. The algorithm converts the topic space into frame images. Meanwhile, the topic space is time-sliced, then the topic space is transformed into a video. Finally, the volatility of user emotional confrontation during a long time in the topic space is like the change of characteristics of frame images in forgeries videos. Then, a topic video rumor detection method (TVRD) was proposed. The experiments indicate that the method successfully verifies the viability of the topic videolization for rumor detection. Additionally, the method also demonstrates the effectiveness of user emotion confrontation of topic space on detection performance.},
  archive      = {J_TKDE},
  author       = {Yucai Pang and Zhou Yang and Qian Li and Shihong Wei and Yunpeng Xiao},
  doi          = {10.1109/TKDE.2025.3543852},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3753-3765},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Topic videolization: A rumor detection method inspired by video forgery detection technology},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Summary graph induced invariant learning for generalizable graph learning. <em>TKDE</em>, <em>37</em>(6), 3739-3752. (<a href='https://doi.org/10.1109/TKDE.2025.3547226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a promising strategy to achieve generalizable graph learning tasks, graph invariant learning emphasizes identifying invariant subgraphs for stable predictions on biased unknown distribution by selecting the important edges/nodes based on their contributions to the predictive tasks (i.e., subgraph predictivity). However, the existing approaches solely relying on subgraph predictivity face a challenge: the learned invariant subgraph often contains numerous spurious nodes and shows poor connectivity, undermining the generalization power of Graph Neural Networks (GNNs). To tackle this issue, we propose a summary graph-induced Invariant Learning (SIL) model that innovatively adopts a summary graph to leverage both the subgraph connectivity and predictivity for learning strong connected and accurate invariant subgraphs. Specifically, SIL first learns a summary graph containing multiple strongly connected supernodes while maintaining structure consistency with the original graph. Second, the learned summary graph is disentangled into an invariant supernode and spurious counterparts to eliminate the interference of highly predictive edges and nodes. Finally, SIL identifies a potential invariant subgraph from the invariant supernode to accomplish generalization tasks. Additionally, we provide a theoretical analysis of the summary graph learning mechanism, guaranteeing that the learned summary graph is consistent with the original graph. Experimental results validate the effectiveness of the SIL model.},
  archive      = {J_TKDE},
  author       = {Xuecheng Ning and Yujie Wang and Kui Yu and Jiali Miao and Fuyuan Cao and Jiye Liang},
  doi          = {10.1109/TKDE.2025.3547226},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3739-3752},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Summary graph induced invariant learning for generalizable graph learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structured graph-based ensemble clustering. <em>TKDE</em>, <em>37</em>(6), 3728-3738. (<a href='https://doi.org/10.1109/TKDE.2025.3546502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble clustering can utilize the complementary information among multiple base clusterings, and obtain a clustering model with better performance and more robustness. Despite its great success, there are still two problems in the current ensemble clustering methods. First, most ensemble clustering methods often treat all base clusterings equally. Second, the final ensemble clustering result often relies on $k$-means or other discretization procedures to uncover the clustering indicators, thus obtaining unsatisfactory results. To address these issues, we proposed a novel ensemble clustering method based on structured graph learning, which can directly extract clustering indicators from the obtained similarity matrix. Moreover, our methods take sufficient consideration of correlation among the base clusterings and can effectively reduce the redundancy among them. Extensive experiments on artificial and real-world datasets demonstrate the efficiency and effectiveness of our methods.},
  archive      = {J_TKDE},
  author       = {Xuan Zheng and Yihang Lu and Rong Wang and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2025.3546502},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3728-3738},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Structured graph-based ensemble clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPIN: Sparse portfolio strategy with irregular news in fluctuating markets. <em>TKDE</em>, <em>37</em>(6), 3714-3727. (<a href='https://doi.org/10.1109/TKDE.2025.3545115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse portfolio optimization (SPO) problem is increasingly crucial in portfolio management, focusing on selecting a few stocks with the potential for strong market performance. However, sparse portfolio strategies often face significant short-term drawdowns during periods of market volatility. To this end, a news-driven portfolio strategy offers valuable insights to capture sudden market changes. Nevertheless, it encounters two main challenges: how to reasonably map the relationships between news and stocks and how to effectively utilize the irregular timing of news releases. To tackle the SPO problem in fluctuating markets while addressing these challenges, we propose a novel news-driven sparse portfolio strategy, named SPIN. Specifically, SPIN not only leverages industry-specific group structures existing among stocks for a more reasonable news-stock mapping and models news sequential patterns based on our devised novel news-driven forecaster to handle the irregularity of news releases. We rigorously prove that SPIN achieves a sub-linear regret. Extensive experiments on three real-world datasets demonstrate SPIN's superiority over state-of-the-art portfolio strategies in terms of cumulative wealth and short-term drawdowns.},
  archive      = {J_TKDE},
  author       = {Mengying Zhu and Mengyuan Yang and Yan Wang and Fei Wu and Qianqiao Liang and Chaochao Chen and Hua Wei and Xiaolin Zheng},
  doi          = {10.1109/TKDE.2025.3545115},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3714-3727},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SPIN: Sparse portfolio strategy with irregular news in fluctuating markets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE-GNN: Seed expanded-aware graph neural network with iterative optimization for semi-supervised entity alignment. <em>TKDE</em>, <em>37</em>(6), 3700-3713. (<a href='https://doi.org/10.1109/TKDE.2025.3555586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment aims to use pre-aligned seed pairs to find other equivalent entities from different knowledge graphs and is widely used in graph fusion-related fields. However, as the scale of knowledge graphs increases, manually annotating pre-aligned seed pairs becomes difficult. Existing research utilizes entity embeddings obtained by aggregating single structural information to identify potential seed pairs, thus reducing the reliance on pre-aligned seed pairs. However, due to the structural heterogeneity of KG, the quality of potential seed pairs obtained using only a single structural information is not ideal. In addition, although existing research improves the quality of potential seed pairs through semi-supervised iteration, they underestimate the impact of embedding distortion produced by noisy seed pairs on the alignment effect. In order to solve the above problems, we propose a seed expanded-aware graph neural network with iterative optimization for semi-supervised entity alignment, named SE-GNN. First, we utilize the semantic attributes and structural features of entities, combined with a conditional filtering mechanism, to obtain high-quality initial potential seed pairs. Next, we designed a local and global awareness mechanism. It introduces initial potential seed pairs and combines local and global information to obtain a more comprehensive entity embedding representation, which alleviates the impact of KG structural heterogeneity and lays the foundation for the optimization of initial potential seed pairs. Then, we designed the threshold nearest neighbor embedding correction strategy. It combines the similarity threshold and the bidirectional nearest neighbor method as a filtering mechanism to select iterative potential seed pairs and also uses an embedding correction strategy to eliminate the embedding distortion. Finally, we will reach the optimized potential seeds after iterative rounds to input local and global sensing mechanisms, obtain the final entity embedding, and perform entity alignment. Experimental results on public datasets demonstrate the excellent performance of our SE-GNN, showcasing the effectiveness of the model. Our code is publicly available at https://github.com/ShuoShan1/SE-GNN.},
  archive      = {J_TKDE},
  author       = {Tao Meng and Shuo Shan and Hongen Shao and Yuntao Shou and Wei Ai and Keqin Li},
  doi          = {10.1109/TKDE.2025.3555586},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3700-3713},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SE-GNN: Seed expanded-aware graph neural network with iterative optimization for semi-supervised entity alignment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RayE-sub: Countering subgraph degradation via perfect reconstruction. <em>TKDE</em>, <em>37</em>(6), 3684-3699. (<a href='https://doi.org/10.1109/TKDE.2025.3544696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph learning has dominated most practices of improving the expressive power of Message Passing Neural Networks (MPNNs). Existing subgraph discovery policies can be classified into node-based and partition-based, which both achieve impressive performance in most scenarios. However, both mainstream solutions still face a subgraph degradation trap. Subgraph degradation is reflected in the phenomenon that the subgraph-level methods fail to offer any benefits over node-level MPNNs. In this work, we empirically investigate the existence of the subgraph degradation issue and introduce a unified perspective, perfect reconstruction, to provide insights for improving two lines of methods. We further propose a subgraph learning strategy guided by the principle of perfect reconstruction. To achieve this, two major issues should be well-addressed, i.e., (i) how to ensure the subgraphs to possess with ‘perfect’ information? (ii) how to guarantee the ‘reconstruction’ power of obtained subgraphs? First, we propose a subgraph partition strategy Rayleigh-resistance to extract non-overlap subgraphs by leveraging the graph spectral theory. Second, we put forward a Query mechanism to achieve subgraph-level equivariant learning, which guarantees subgraph reconstruction ability. These two parts, perfect subgraph partition and equivariant subgraph learning are seamlessly unified as a novel Rayleigh-resistance Equivariant Subgraph learning architecture (RayE-Sub). Comprehensive experiments on both synthetic and real datasets demonstrate that our approach can consistently outperform previous subgraph learning architectures.},
  archive      = {J_TKDE},
  author       = {Kuo Yang and Zhengyang Zhou and Xu Wang and Pengkun Wang and Limin Li and Yang Wang},
  doi          = {10.1109/TKDE.2025.3544696},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3684-3699},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RayE-sub: Countering subgraph degradation via perfect reconstruction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QAEA-DR: A unified text augmentation framework for dense retrieval. <em>TKDE</em>, <em>37</em>(6), 3669-3683. (<a href='https://doi.org/10.1109/TKDE.2025.3543203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dense retrieval, embedding long texts into dense vectors can result in information loss, leading to inaccurate query-text matching. Additionally, low-quality texts with excessive noise or sparse key information are unlikely to align well with relevant queries. Recent studies mainly focus on improving the sentence embedding model or retrieval process. In this work, we introduce a novel text augmentation framework for dense retrieval. This framework transforms raw documents into information-dense text formats, which supplement the original texts to effectively address the aforementioned issues without modifying embedding or retrieval methodologies. Two text representations are generated via large language models (LLMs) zero-shot prompting: question-answer pairs and element-driven events. We term this approach QAEA-DR: unifying question-answer generation and event extraction in a text augmentation framework for dense retrieval. To further enhance the quality of generated texts, a scoring-based evaluation and regeneration mechanism is introduced in LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval, supported by both theoretical analysis and empirical experiments.},
  archive      = {J_TKDE},
  author       = {Hongming Tan and Shaoxiong Zhan and Hai Lin and Hai-Tao Zheng and Wai Kin Chan},
  doi          = {10.1109/TKDE.2025.3543203},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3669-3683},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {QAEA-DR: A unified text augmentation framework for dense retrieval},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provenance graph kernel. <em>TKDE</em>, <em>37</em>(6), 3653-3668. (<a href='https://doi.org/10.1109/TKDE.2025.3543097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provenance is a standardised record that describes how entities, activities, and agents have influenced a piece of data; it is commonly represented as graphs with relevant labels on both their nodes and edges. With the growing adoption of provenance in a wide range of application domains, users are increasingly confronted with an abundance of graph data, which may prove challenging to process. Graph kernels, on the other hand, have been successfully used to efficiently analyse graphs. In this paper, we introduce a novel graph kernel called provenance kernel, which is inspired by and tailored for provenance data. We employ provenance kernels to classify provenance graphs from three application domains. Our evaluation shows that they perform well in terms of classification accuracy and yield competitive results when compared against existing graph kernel methods and the provenance network analytics method while more efficient in computing time. Moreover, the provenance types used by provenance kernels are a symbolic representation of a tree pattern which can, in turn, be described using the domain-agnostic vocabulary of provenance. Therefore, provenance types thus allow for the creation of explanations of predictive models built on them.},
  archive      = {J_TKDE},
  author       = {David Kohan Marzagão and Trung Dong Huynh and Ayah Helal and Sean Baccas and Luc Moreau},
  doi          = {10.1109/TKDE.2025.3543097},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3653-3668},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Provenance graph kernel},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing for data assets based on data quality, quantity and utility on the perspective of consumer heterogeneity. <em>TKDE</em>, <em>37</em>(6), 3641-3652. (<a href='https://doi.org/10.1109/TKDE.2025.3551401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is an inevitable trend for the development of global digital economy to transform data into data assets and realize their transaction circulation. Aiming at the release of data value and the development of its transaction process, the concept of integrated score of data is proposed by combining integrated quality index containing four dimensions with data quantity. On this basis, data assets are priced according to the principle of profit maximization by constructing a nonlinear programming model. Among them, three types of pricing models are divided according to the heterogeneity of consumers’ utility sensitivity, and the consumers’ wiilingness to pay are adjusted based on business parameters using FAHP system. The proposed model is verified with the data of China's carbon emissions as the original data, combined with the KNN machine learning algorithm and a series of simulation analyses. In addition, multiple sets of heterogeneous data are tested. The results show that the quality, quantity and utility of data have an important impact on the pricing of data assets, and it is necessary to divide the utility sensitivity of consumers as well as take business parameters into consideration. The model proposed can also provide decision-making reference for data platforms.},
  archive      = {J_TKDE},
  author       = {Juanjuan Lin and Zhigang Huang and Yong Tang},
  doi          = {10.1109/TKDE.2025.3551401},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3641-3652},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pricing for data assets based on data quality, quantity and utility on the perspective of consumer heterogeneity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern-wise transparent sequential recommendation. <em>TKDE</em>, <em>37</em>(6), 3627-3640. (<a href='https://doi.org/10.1109/TKDE.2025.3549032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A transparent decision-making process is essential for developing reliable and trustworthy recommender systems. For sequential recommendation, it means that the model can identify key items that account for its recommendation results. However, achieving both interpretability and recommendation performance simultaneously is challenging, especially for models that take the entire sequence of items as input without screening. In this paper, we propose an interpretable framework (named PTSR) that enables a pattern-wise transparent decision-making process without extra features. It breaks the sequence of items into multi-level patterns that serve as atomic units throughout the recommendation process. The contribution of each pattern to the outcome is quantified in the probability space. With a carefully designed score correction mechanism, the pattern contribution can be implicitly learned in the absence of ground-truth key patterns. The final recommended items are those that most key patterns strongly endorse. Extensive experiments on five public datasets demonstrate remarkable recommendation performance, while statistical analysis and case studies validate the model interpretability.},
  archive      = {J_TKDE},
  author       = {Kun Ma and Cong Xu and Zeyuan Chen and Wei Zhang},
  doi          = {10.1109/TKDE.2025.3549032},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3627-3640},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pattern-wise transparent sequential recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OpDiag: Unveiling database performance anomalies through query operator attribution. <em>TKDE</em>, <em>37</em>(6), 3613-3626. (<a href='https://doi.org/10.1109/TKDE.2025.3557049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively diagnose and mitigate database performance anomalies remains a significant concern for modern database systems. Manually identifying the root causes of the anomalies is a labor-intensive process and significantly relies on professional experience. Meanwhile, existing work on automatic database diagnosis mainly focuses on detecting anomalous performance metrics or system log. These solutions lack the power to pinpoint detailed issues such as bad queries or problematic operators, which are indispensable for most database troubleshooting processes. In this paper, we propose OpDiag, a diagnosis framework that attributes database performance anomalies to query operators. In this framework, we first construct models offline to represent the relationship between query operators, performance metrics, and anomalies. These models can capture query plan features and support ad-hoc queries and schemas. Then, through feature attribution on these models during online diagnosis, OpDiag can effectively identify critical anomalous metrics and further trace back to suspicious queries and operators. This can provide concrete guidance for subsequent steps in anomaly mitigation. We applied OpDiag to both synthetic benchmark and real industry cases from ZTE Corporation. Empirical studies prove that OpDiag can accurately localize anomalous queries and operators, thus reducing human efforts in diagnosing and mitigating database performance anomalies.},
  archive      = {J_TKDE},
  author       = {Shiyue Huang and Ziwei Wang and Yinjun Wu and Yaofeng Tu and Jiankai Wang and Bin Cui},
  doi          = {10.1109/TKDE.2025.3557049},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3613-3626},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {OpDiag: Unveiling database performance anomalies through query operator attribution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On efficient single-source personalized PageRank computation in online social networks. <em>TKDE</em>, <em>37</em>(6), 3598-3612. (<a href='https://doi.org/10.1109/TKDE.2025.3551751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Single-Source Personalized PageRank (SSPPR) problem is widely used in information retrieval and recommendation systems. Traditional algorithms assume full knowledge of the network, making them inapplicable to online social networks (OSNs), where the topology is unknown, and users can only explore the network step by step via APIs. The only feasible approach for SSPPR in OSNs is Monte Carlo (MC) simulation, but traditional MC methods rely on static sampling, which lacks flexibility, delays feedback, and overestimates the number of required random walks. To address these limitations, we propose PANDA (Single-Source Personalized PageRank on OSNs with Rademacher Average), a progressive sampling algorithm. PANDA iteratively samples random walks in batches, estimating accuracy dynamically using Rademacher Average from statistical learning theory. This data-dependent approach allows for early termination once the desired accuracy is met. Additionally, PANDA features a dynamic sampling schedule to optimize efficiency. Empirical studies show that PANDA significantly outperforms existing methods, achieving the same accuracy with far greater efficiency.},
  archive      = {J_TKDE},
  author       = {Victor Junqiu Wei and Di Jiang and Jason Chen Zhang},
  doi          = {10.1109/TKDE.2025.3551751},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3598-3612},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {On efficient single-source personalized PageRank computation in online social networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonconvex low-rank tensor representation for multi-view subspace clustering with insufficient observed samples. <em>TKDE</em>, <em>37</em>(6), 3583-3597. (<a href='https://doi.org/10.1109/TKDE.2025.3555043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) separates the data with multiple views into multiple clusters, and each cluster corresponds to one certain subspace. Existing tensor-based MVSC methods construct self-representation subspace coefficient matrices of all views as a tensor, and introduce the tensor nuclear norm (TNN) to capture the complementary information hidden in different views. The key assumption is that the data samples of each subspace must be sufficient for subspace representation. This work proposes a nonconvex latent transformed low-rank tensor representation framework for MVSC. To deal with the insufficient sample problem, we study the latent low-rank representation in the multi-view case to supplement underlying observed samples. Moreover, we propose to use data-driven transformed TNN (TTNN), resulting from the intrinsic structure of multi-view samples, to preserve the consensus and complementary information in the transformed domain. Meanwhile, the proposed unified nonconvex low-rank tensor representation framework can better learn the high correlation among different views. To resolve the proposed nonconvex optimization model, we propose an effective algorithm under the framework of the alternating direction method of multipliers and theoretically prove that the iteration sequences converge to the critical point. Experiments on various datasets showcase outstanding performance.},
  archive      = {J_TKDE},
  author       = {Meng Ding and Jing-Hua Yang and Xi-Le Zhao and Jie Zhang and Michael K. Ng},
  doi          = {10.1109/TKDE.2025.3555043},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3583-3597},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Nonconvex low-rank tensor representation for multi-view subspace clustering with insufficient observed samples},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next-POI recommendation via spatial-temporal knowledge graph contrastive learning and trajectory prompt. <em>TKDE</em>, <em>37</em>(6), 3570-3582. (<a href='https://doi.org/10.1109/TKDE.2025.3545958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next POI (Point-of-Interest) recommendation aims to forecast users’ future movements based on their historical check-in trajectories, holding significant value in location-based services. Existing methods address trajectory data sparsity by integrating rich auxiliary information or using spatial-temporal knowledge graphs (STKGs), showing promising results. Yet, they face two main challenges: i) Due to the difficulty of transforming structured trajectory data into trajectory text describing users’ spatial-temporal mobility, the powerful reasoning ability of pre-trained language models is rarely explored to enhance recommendation performance. ii) Methods based on STKG can introduce external knowledge inconsistent with user preferences, leading to the knowledge noise generated hampering the accuracy of recommendations. To this end, we propose a novel approach called STKG-PLM that integrates STKG contrastive learning and prompt pre-trained language model (PLM) to enhance the next POI recommendation. Specifically, we design a spatial-temporal trajectory prompt template that transforms structured trajectories into text corpus based on STKG, serving as the input of PLM to understand the movement pattern of users from coarse-grained and fine-grained perspectives. Additionally, we propose an STKG contrastive learning framework to mitigate the introduced knowledge noise. Extensive experiments on three real-world datasets demonstrate that STKG-PLM exhibits notable performance improvements over the state-of-the-art baseline methods.},
  archive      = {J_TKDE},
  author       = {Wei Chen and Haoyu Huang and Zhiyu Zhang and Tianyi Wang and Youfang Lin and Liang Chang and Huaiyu Wan},
  doi          = {10.1109/TKDE.2025.3545958},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3570-3582},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Next-POI recommendation via spatial-temporal knowledge graph contrastive learning and trajectory prompt},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale weisfeiler-leman directed graph neural networks for prerequisite-link prediction. <em>TKDE</em>, <em>37</em>(6), 3556-3569. (<a href='https://doi.org/10.1109/TKDE.2025.3552045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prerequisite-link Prediction (PLP) aims to discover the condition relations of a specific event or a concerned variable, which is a fundamental problem in a large number of fields, such as educational data mining. Current studies on PLP usually developed graph neural networks (GNNs) to learn the representations of pairs of nodes. However, these models fail to distinguish non-isomorphic graphs and integrate multiscale structures, leading to the insufficient expressive capability of GNNs. To this end, we in this paper proposed k-dimensional Weisferiler-Leman directed GNNs, dubbed k-WediGNNs, to recognize non-isomorphic graphs via the Weisferiler-Leman algorithm. Furthermore, we integrated the multiscale structures of a directed graph into k-WediGNNs, dubbed multiscale k-WediGNNs, from the bidirected views of in-degree and out-degree. With the Siamese network, the proposed models are extended to address the problem of PLP. Besides, the expressive power is then interpreted via theoretical proofs. The experiments were conducted on four publicly available datasets for concept prerequisite relation prediction (CPRP). The results show that the proposed models achieve better performance than the state-of-the-art approaches, where our multiscale k-WediGNN achieves a new benchmark in the task of CPRP.},
  archive      = {J_TKDE},
  author       = {Yupei Zhang and Xiran Qu and Shuhui Liu and Yan Pang and Xuequn Shang},
  doi          = {10.1109/TKDE.2025.3552045},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3556-3569},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multiscale weisfeiler-leman directed graph neural networks for prerequisite-link prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale temporal dynamic learning for time series classification. <em>TKDE</em>, <em>37</em>(6), 3543-3555. (<a href='https://doi.org/10.1109/TKDE.2025.3542799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) is crucial in many applications, yet accurately modeling complex time series patterns remains challenging. Model-based TSC strives to aptly model time series by capturing their intrinsic temporal dynamics, deriving effective dynamic representations for classification. Despite significant progress in this domain, existing works are still constrained by a singular and overly simplistic modeling paradigm, which proves inadequate to handle the multiscale hierarchies inherent in time series. Additionally, the prevailing reliance on manual model configuration fails to address the diverse dynamic characteristics across varying data scenarios. In this paper, we amalgamate multiple recurrent reservoirs to devise a model-based Multiscale Temporal Dynamic Learning (MsDL) approach. These reservoirs are endowed with varied recurrent connection skips, ensuring a comprehensive capture of temporal dynamics across different timescales. We also present a multi-objective optimization algorithm, which adaptively configures the memory length of each reservoir, allowing for more accurate time series modeling. This optimization further encourages time series from the same class to look closer, while separating those from different classes, thereby enhancing the category-discriminability. Extensive experiments on public datasets demonstrate that MsDL outperforms the state-of-the-art methods. Additionally, ablation studies confirm that our multiscale design and optimization algorithm effectively enhance classification accuracy.},
  archive      = {J_TKDE},
  author       = {Shikang Liu and Xiren Zhou and Huanhuan Chen},
  doi          = {10.1109/TKDE.2025.3542799},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3543-3555},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multiscale temporal dynamic learning for time series classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOFTune: A low-overhead and flexible approach for spark SQL configuration tuning. <em>TKDE</em>, <em>37</em>(6), 3528-3542. (<a href='https://doi.org/10.1109/TKDE.2025.3549232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The query efficiency of Spark SQL is significantly impacted by its configurations. Therefore, configuration tuning has drawn great attention, and various automatic configuration tuning methods have been proposed. However, existing methods suffer from two issues: (1) high tuning overhead: they need to repeatedly execute the workloads several times to obtain the training samples, which is time-consuming; and (2) low throughput: they need to occupy resources like CPU cores and memory for a long time, causing other Spark SQL workloads to wait, thereby reducing the overall system throughput. These issues impede the use of automatic configuration tuning methods in practical systems which have limited tuning budget and many concurrent workloads. To address these issues, this paper proposes a Low-Overhead and Flexible approach for Spark SQL configuration Tuning, dubbed LOFTune. LOFTune reduces the tuning overhead via a sample-efficient optimization framework, which is proposed based on multi-task SQL representation learning and multi-armed bandit. Furthermore, LOFTune solves the low throughput issue with a recommendation-sampling-decoupled tuning framework. Extensive experiments validate the effectiveness of LOFTune. In the sampling-allowed case, LOFTune can save up to 90% of the workload runs comparing with the state-of-the-art methods. Besides, in the zero-sampling case, LOFTune can reduce up to 41.26% of latency.},
  archive      = {J_TKDE},
  author       = {Jiahui Li and Junhao Ye and Yuren Mao and Yunjun Gao and Lu Chen},
  doi          = {10.1109/TKDE.2025.3549232},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3528-3542},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LOFTune: A low-overhead and flexible approach for spark SQL configuration tuning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local community detection in multi-attributed road-social networks. <em>TKDE</em>, <em>37</em>(6), 3514-3527. (<a href='https://doi.org/10.1109/TKDE.2025.3550476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The information available in multi-attributed road-social networks includes network structure, location information, and numerical attributes. Most studies mainly focus on mining communities by combining structure with attributes or structure with location, which do not consider structure, attributes, and location simultaneously. Therefore, we propose a parameter-free algorithm, called LCDMRS, to mine local communities in multi-attributed road-social networks. LCDMRS extracts a sub-network surrounding the given node and embeds it to generate the vector representations of nodes, which incorporates both structural and attributed information. Based on the vector representations of nodes, the average cosine similarity between nodes is designed to ensure both the structural and attributed cohesiveness of the community, while the community node density is designed to ensure the spatial cohesiveness of the community. Targeting the community node density and cosine similarity of nodes, LCDMRS takes the given node as the starting node and employs the community dominance relation to expand the community outward. Experimental results on multiple real-world datasets demonstrate LCDMRS outperforms comparison algorithms.},
  archive      = {J_TKDE},
  author       = {Li Ni and Qiuyu Li and Yiwen Zhang and Wenjian Luo and Victor S. Sheng},
  doi          = {10.1109/TKDE.2025.3550476},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3514-3527},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Local community detection in multi-attributed road-social networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LIOF: Make the learned index learn faster with higher accuracy. <em>TKDE</em>, <em>37</em>(6), 3499-3513. (<a href='https://doi.org/10.1109/TKDE.2025.3548298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learned indexes, emerging as a promising alternative to traditional indexes like B+Tree, utilize machine learning models to enhance query performance and reduce memory usage. However, the widespread adoption of learned indexes is limited by their expensive training cost and the need for high accuracy of internal models. Although some studies attempt to optimize the building process of these learned indexes, existing methods are restrictive in scope and applicability. They are usually tailored to specific index types and heavily rely on pre-trained model knowledge, making deployment a challenging task. In this work, we introduce the Learned Index Optimization Framework (LIOF), a general and easily integrated solution aimed at expediting the training process and improving the accuracy of index model for one-dimensional and multi-dimensional learned indexes. The optimization of LIOF for the learned indexes is intuitive, directly providing optimized parameters for index models based on the distribution of node data. By leveraging the correlation between key distribution and node model parameters, LIOF significantly reduces the training epochs required for each node model. Initially, we introduce an optimization strategy inspired by optimization-based meta-learning to train the LIOF to generate optimized initial parameters for index node models. Subsequently, we present a data-driven encoder and a parameter-centric decoder network, which adaptively translate key distribution into a latent variable representation and decode it into optimized node model initialization. Additionally, to further utilize characteristics of key distribution, we propose a monotonic regularizer and focal loss, guiding LIOF training towards efficiency and precision. Through extensive experimentation on real-world and synthetic datasets, we demonstrate that LIOF provides substantial enhancements in both training efficiency and the predictive accuracy for learned indexes.},
  archive      = {J_TKDE},
  author       = {Tao Ji and Kai Zhong and Luming Sun and Yiyan Li and Cuiping Li and Hong Chen},
  doi          = {10.1109/TKDE.2025.3548298},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3499-3513},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LIOF: Make the learned index learn faster with higher accuracy},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning temporal event knowledge for continual social event classification. <em>TKDE</em>, <em>37</em>(6), 3485-3498. (<a href='https://doi.org/10.1109/TKDE.2025.3553162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet and the burgeoning scale of social media, Social Event Classification (SEC) has garnered increasing attention. The existing study of SEC focuses on recognizing a fixed set of social events. However, in real-world scenarios, new social events continually emerge on social media, which suggests the necessity for a practical SEC model that can swiftly adapt to the evolving environment with incremental social events. Therefore, in this paper, we study a new yet crucial problem defined as Continual Social Event Classification (C-SEC), where new events continually emerge in the sequentially collected social data. Accordingly, we propose a novel Temporal Event Knowledge Network (TEKNet) to continually learn temporal event knowledge for C-SEC with temporally incremental events. First, we conduct present event knowledge learning to learn the classification of newly emerging events in the presently incoming data. Second, we design past event knowledge replay with self-knowledge distillation to consolidate the learned knowledge of past events and prevent catastrophic forgetting. Finally, we propose future event knowledge pretraining with a modality mixture mechanism to pretrain the classifiers for events that occur in the future. Comprehensive experiments on real-world social event datasets demonstrate the superiority of our proposed TEKNet for C-SEC.},
  archive      = {J_TKDE},
  author       = {Shengsheng Qian and Shengjie Zhang and Dizhan Xue and Huaiwen Zhang and Changsheng Xu},
  doi          = {10.1109/TKDE.2025.3553162},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3485-3498},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning temporal event knowledge for continual social event classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning causal representations based on a GAE embedded autoencoder. <em>TKDE</em>, <em>37</em>(6), 3472-3484. (<a href='https://doi.org/10.1109/TKDE.2025.3546607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine-learning approaches face limitations when confronted with insufficient data. Transfer learning addresses this by leveraging knowledge from closely related domains. The key in transfer learning is to find a transferable feature representation to enhance cross-domain classification models. However, in some scenarios, some features correlated with samples in the source domain may not be relevant to those in the target. Causal inference enables us to uncover the underlying patterns and mechanisms within the data, mitigating the impact of confounding factors. Nevertheless, most existing causal inference algorithms have limitations when applied to high-dimensional datasets with nonlinear causal relationships. In this work, a new causal representation method based on a Graph autoencoder embedded AutoEncoder, named GeAE, is introduced to learn invariant representations across domains. The proposed approach employs a causal structure learning module, similar to a graph autoencoder, to account for nonlinear causal relationships present in the data. Moreover, the cross-entropy loss as well as the causal structure learning loss and the reconstruction loss are incorporated in the objective function designed in a united autoencoder. This method allows for the handling of high-dimensional data and can provide effective representations for cross-domain classification tasks. Experimental results on generated and real-world datasets demonstrate the effectiveness of GeAE compared with the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Kuang Zhou and Ming Jiang and Bogdan Gabrys and Yong Xu},
  doi          = {10.1109/TKDE.2025.3546607},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3472-3484},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning causal representations based on a GAE embedded autoencoder},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-centered dual-process reasoning for math word problems with large language models. <em>TKDE</em>, <em>37</em>(6), 3457-3471. (<a href='https://doi.org/10.1109/TKDE.2025.3556367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Math word problem (MWP) serves as a critical milestone for assessing the text mining ability and knowledge mastery level of models. Recent advancements have witnessed large language models (LLMs) showcasing remarkable performance on MWP. However, current LLMs still frequently exhibit logical errors, which highlights their inability to fully grasp the knowledge required for genuine step-by-step mathematical reasoning. To this end, in this paper, we propose a novel Knowledge-guided Solver (KNOS) framework that empowers LLMs to simulate human mathematical reasoning, whose core idea is to Invoke-Verify-Inject necessary knowledge to solve MWP. We draw inspiration from the dual-process theory to construct two cooperative systems: a Knowledge System and an Inference System. Specifically, the Knowledge System employs LLMs as the knowledge base and develops a novel knowledge invoker that can elicit their relevant knowledge to support the strict step-level mathematical reasoning. In the Inference System, we propose a knowledge verifier and a knowledge injector to evaluate the knowledge rationality and further guide the step-wise symbolic deduction in an interpretable manner based on human cognitive mechanism, respectively. Moreover, to tackle the potential scarcity issue of mathematics-specific knowledge in LLMs, we consider an open-book exam scenario and propose an improved version of KNOS called EKNOS. In EKNOS, we meticulously design knowledge selectors to extract the most relevant commonsense and math formulas from external knowledge sources for each reasoning step. This knowledge is utilized to assist the knowledge invoker in better stimulating LLMs’ reasoning abilities. Both KNOS and EKNOS are flexible to empower different LLMs. Our experiments with GPT3, ChatGPT, and GPT4 not only demonstrate their reasoning accuracy improvement but also show how they bring the strict step-wise interpretability of mathematical thinking.},
  archive      = {J_TKDE},
  author       = {Jiayu Liu and Zhenya Huang and Qi Liu and Zhiyuan Ma and Chengxiang Zhai and Enhong Chen},
  doi          = {10.1109/TKDE.2025.3556367},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3457-3471},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Knowledge-centered dual-process reasoning for math word problems with large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard or false: Keep the balance for negative sampling in knowledge graphs. <em>TKDE</em>, <em>37</em>(6), 3445-3456. (<a href='https://doi.org/10.1109/TKDE.2025.3550545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negative sampling is an essential part in knowledge graph embedding, which offers significant advantages to numerous downstream related tasks. There are two kinds of important negatives: hard and false negatives. Hard negatives are the negatives which are difficult to distinguish from positive samples, while false negatives are positive samples which are mistakenly identified as negatives. Harnessing hard negatives effectively can make the model more discriminative, and reducing false negatives can avoid misleading the model during training. Therefore, the two kinds of negatives are essential in high-quality negative sampling. However, the present negative sampling methods face two shortcomings: 1.judging one negative is hard or false mainly relies on score functions; 2. difficulty in balancing the impact of hard and false negatives. In this paper, we absorb bigram language model and propose a novel criterion to help verify the negatives are hard or false, and discuss how to keep the balance between hard and false negatives. Experiments on four representative score functions and two public datasets demonstrate the effects of the proposed negative sampling method.},
  archive      = {J_TKDE},
  author       = {Feihu Che and Jianhua Tao and Qionghai Dai},
  doi          = {10.1109/TKDE.2025.3550545},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3445-3456},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hard or false: Keep the balance for negative sampling in knowledge graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G-thinkerq: A general subgraph querying system with a unified task-based programming model. <em>TKDE</em>, <em>37</em>(6), 3429-3444. (<a href='https://doi.org/10.1109/TKDE.2025.3537964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a large graph $G$, a subgraph query $Q$ finds the set of all subgraphs of $G$ that satisfy certain conditions specified by $Q$. Examples of subgraph queries including finding a community containing designated members to organize an event, and subgraph matching. To overcome the weakness of existing graph-parallel systems that underutilize CPU cores when finding subgraphs, our prior system, G-thinker, was proposed that adopts a novel think-like-a-task (TLAT) parallel programming model. However, G-thinker targets offline analytics and cannot support interactive online querying where users continually submit subgraph queries with different query contents. The challenges here are (i) how to maintain fairness that queries are answered in the order that they are received: a later query is processed only if earlier queries cannot saturate the available computation resources; (ii) how to track the progress of active queries (each with many tasks under computation) so that users can be timely notified as soon as a query completes; and (iii) how to maintain memory boundedness and high task concurrency as in G-thinker. In this article, we propose a novel TLAT programming framework, called G-thinkerQ, for answering online subgraph queries. G-thinkerQ inherits the memory boundedness and high task concurrency of G-thinker by organizing the tasks of each query using a “task capsule” structure, and designs a novel task-capsule list is to ensure fairness among queries. A novel lineage-based mechanism is also designed to keep track of when the last task of a query is completed. Parallel counterparts of the state-of-the-art algorithms for 4 recent advanced subgraph queries are implemented on G-thinkerQ to demonstrate its CPU-scalability.},
  archive      = {J_TKDE},
  author       = {Lyuheng Yuan and Guimu Guo and Da Yan and Saugat Adhikari and Jalal Khalil and Cheng Long and Lei Zou},
  doi          = {10.1109/TKDE.2025.3537964},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3429-3444},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {G-thinkerq: A general subgraph querying system with a unified task-based programming model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPU-accelerated structural diversity search in graphs. <em>TKDE</em>, <em>37</em>(6), 3413-3428. (<a href='https://doi.org/10.1109/TKDE.2025.3547443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of structural diversity search has been widely studied recently, which aims to find out the users with the highest structural diversity in social networks. The structural diversity of a user is depicted by the number of social contexts inside his/her contact neighborhood. Three structural diversity models based on cohesive subgraph models (e.g., k-sized component, k-core, and k-truss), have been proposed. Previous solutions only focus on CPU-based sequential solutions, suffering from several key steps of that cannot be highly parallelized. GPUs enjoy high-efficiency performance in parallel computing for solving many complex graph problems such as triangle counting, subgraph pattern matching, and graph decomposition. In this paper, we provide a unified framework to utilize multiple GPUs to accelerate the computation of structural diversity search under the mentioned three structural diversity models. We first propose a GPU-based lock-free method to efficiently extract ego-networks in CSR format in parallel. Second, we design detailed GPU-based solutions for computing k-sized component-based, k-core-based, and also k-truss-based structural diversity scores by dynamically grouping GPU resources. To effectively optimize the workload balance among multiple GPUs, we propose a greedy work-packing scheme and a dynamic work-stealing strategy to fulfill usage. Extensive experiments on real-world datasets validate the superiority of our GPU-based structural diversity search solutions in terms of efficiency and effectiveness.},
  archive      = {J_TKDE},
  author       = {Jinbin Huang and Xin Huang and Jianliang Xu and Byron Choi and Yun Peng},
  doi          = {10.1109/TKDE.2025.3547443},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3413-3428},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GPU-accelerated structural diversity search in graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlexIM: Efficient and verifiable index management in blockchain. <em>TKDE</em>, <em>37</em>(6), 3399-3412. (<a href='https://doi.org/10.1109/TKDE.2025.3546997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based query with its traceability and data provenance has become increasingly popular and widely adopted in numerous applications. Yet existing index-based query approaches are only efficient under static blockchain query workloads where the query attribute or type must be fixed. It turns out to be particularly challenging to construct an efficient index for dynamic workloads due to prohibitively long construction time and excessive storage consumption. In this paper, we present FlexIM, the first efficient and verifiable index management system for blockchain dynamic queries. The key innovation in FlexIM is to uncover the inherent characteristics of blockchain, i.e., data distribution and block access frequency, and then to optimally choose the index by utilizing reinforcement learning technique under varying workloads. In addition, we enhance and facilitate verifiability with low storage overhead by leveraging Root Merkle Tree (RMT) and Bloom Filter Merkle Tree (BMT). Our comprehensive evaluations demonstrate that FlexIM outperforms the state-of-the-art blockchain query mechanism, vChain+, by achieving a 26.5% speedup while consuming 94.2% less storage, on average, over real-world Bitcoin datasets.},
  archive      = {J_TKDE},
  author       = {Binhong Li and Licheng Lin and Shijie Zhang and Jianliang Xu and Jiang Xiao and Bo Li and Hai Jin},
  doi          = {10.1109/TKDE.2025.3546997},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3399-3412},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FlexIM: Efficient and verifiable index management in blockchain},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast counting and utilizing induced 6-cycles in bipartite networks. <em>TKDE</em>, <em>37</em>(6), 3386-3398. (<a href='https://doi.org/10.1109/TKDE.2025.3546516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graphs are a powerful tool for modeling the interactions between two distinct groups. These bipartite relationships often feature small, recurring structural patterns called motifs which are building blocks for community structure. One promising structure is the induced 6-cycle which consists of three nodes on each node set forming a cycle where each node has exactly two edges. In this paper, we study the problem of counting and utilizing induced 6-cycles in large bipartite networks. We first consider two adaptations inspired by previous works for cycle counting in bipartite networks. Then, we introduce a new approach for node triplets which offer a systematic way to count the induced 6-cycles, used in BatchTripletJoin. Our experimental evaluation shows that BatchTripletJoin is significantly faster than the other algorithms while being scalable to large graph sizes and number of cores. On a network with $ 112M$ edges, BatchTripletJoin is able to finish the computation in 78 mins by using 52 threads. In addition, we provide a new way to identify anomalous node triplets by comparing and contrasting the butterfly and induced 6-cycle counts of the nodes. We showcase several case studies on real-world networks from Amazon Kindle ratings, Steam game reviews, and Yelp ratings.},
  archive      = {J_TKDE},
  author       = {Jason Niu and Jaroslaw Zola and Ahmet Erdem Sarıyüce},
  doi          = {10.1109/TKDE.2025.3546516},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3386-3398},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast counting and utilizing induced 6-cycles in bipartite networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing security and privacy in federated learning using low-dimensional update representation and proximity-based defense. <em>TKDE</em>, <em>37</em>(6), 3372-3385. (<a href='https://doi.org/10.1109/TKDE.2025.3539717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a promising privacy-preserving machine learning paradigm that allows data owners to collaboratively train models while keeping their data localized. Despite its potential, FL faces challenges related to the trustworthiness of both clients and servers, particularly against curious or malicious adversaries. In this paper, we introduce a novel framework named Federated Learning with Low-Dimensional Update Representation and Proximity-Based defense (FLURP), designed to address privacy preservation and resistance to Byzantine attacks in distributed learning environments. FLURP employs $\mathsf {LinfSample}$ method, enabling clients to compute the $l_{\infty }$ norm across sliding windows of updates, resulting in a Low-Dimensional Update Representation (LUR). Calculating the shared distance matrix among LURs, rather than updates, significantly reduces the overhead of Secure Multi-Party Computation (SMPC) by three orders of magnitude while effectively distinguishing between benign and poisoned updates. Additionally, FLURP integrates a privacy-preserving proximity-based defense mechanism utilizing optimized SMPC protocols to minimize communication rounds. Our experiments demonstrate FLURP's effectiveness in countering Byzantine adversaries with low communication and runtime overhead. FLURP offers a scalable framework for secure and reliable FL in distributed environments, facilitating its application in scenarios requiring robust data management and security.},
  archive      = {J_TKDE},
  author       = {Wenjie Li and Kai Fan and Jingyuan Zhang and Hui Li and Wei Yang Bryan Lim and Qiang Yang},
  doi          = {10.1109/TKDE.2025.3539717},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3372-3385},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing security and privacy in federated learning using low-dimensional update representation and proximity-based defense},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elevating knowledge-enhanced entity and relationship understanding for sarcasm detection. <em>TKDE</em>, <em>37</em>(6), 3356-3371. (<a href='https://doi.org/10.1109/TKDE.2025.3547055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm thrives on popular social media platforms such as Twitter and Reddit, where users frequently employ it to convey emotions in an ironic or satirical manner. The ability to detect sarcasm plays a pivotal role in comprehending individuals’ true sentiments. To achieve a comprehensive grasp of sentence semantics, it is crucial to integrate external knowledge that can aid in deciphering entities and their intricate relationships within a sentence. Although some efforts have been made in this regard, their use of external knowledge is still relatively superficial. Specifically, Knowledge-enhanced entity and relationship understanding still face significant challenges. In this paper, we propose the Knowledge Enhanced Sentiment Dependency Graph Convolutional Network (KSDGCN) framework, which constructs a commonsense-augmented sentiment graph and a commonsense-replaced dependency graph for each text to explicitly capture the role of external knowledge for sarcasm detection. Furthermore, we validate the irrational relationships between co-occurring entity pairs within sentences and background knowledge by a signed attention mechanism. We conduct experiments on four benchmark datasets, and the results show that KSDGCN outperforms existing state-of-the-art methods and is highly interpretable.},
  archive      = {J_TKDE},
  author       = {Xiaobao Wang and Yujing Wang and Dongxiao He and Zhe Yu and Yawen Li and Longbiao Wang and Jianwu Dang and Di Jin},
  doi          = {10.1109/TKDE.2025.3547055},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3356-3371},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Elevating knowledge-enhanced entity and relationship understanding for sarcasm detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient algorithms for minimizing the kirchhoff index via adding edges. <em>TKDE</em>, <em>37</em>(6), 3342-3355. (<a href='https://doi.org/10.1109/TKDE.2025.3552644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kirchhoff index, which is the sum of the resistance distance between every pair of nodes in a network, is a key metric for gauging network performance, where lower values signify enhanced performance. In this paper, we study the problem of minimizing the Kirchhoff index by adding edges. We first provide a greedy algorithm for solving this problem and give an analysis of its quality based on the bounds of the submodularity ratio and the curvature. Then, we introduce a gradient-based greedy algorithm as a new paradigm to solve this problem. To accelerate the computation cost, we leverage geometric properties, convex hull approximation, and approximation of the projected coordinate of each point. To further improve this algorithm, we use pre-pruning and fast update techniques, making it particularly suitable for large networks. Our proposed algorithms have nearly-linear time complexity. We provide extensive experiments on ten real networks to evaluate the quality of our algorithms. The results demonstrate that our proposed algorithms outperform the state-of-the-art methods in terms of efficiency and effectiveness. Moreover, our algorithms are scalable to large graphs with over 5 million nodes and 12 million edges.},
  archive      = {J_TKDE},
  author       = {Xiaotian Zhou and Ahad N. Zehmakan and Zhongzhi Zhang},
  doi          = {10.1109/TKDE.2025.3552644},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3342-3355},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient algorithms for minimizing the kirchhoff index via adding edges},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-channel multiplex graph neural networks for recommendation. <em>TKDE</em>, <em>37</em>(6), 3327-3341. (<a href='https://doi.org/10.1109/TKDE.2025.3544081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective recommender systems play a crucial role in accurately capturing user and item attributes that mirror individual preferences. Some existing recommendation techniques have started to shift their focus towards modeling various types of interactive relations between users and items in real-world recommendation scenarios, such as clicks, marking favorites, and purchases on online shopping platforms. Nevertheless, these approaches still grapple with two significant challenges: (1) Insufficient modeling and exploitation of the impact of various behavior patterns formed by multiplex relations between users and items on representation learning, and (2) ignoring the effect of different relations within behavior patterns on the target relation in recommender system scenarios. In this work, we introduce a novel recommendation framework, Dual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the aforementioned challenges. It incorporates an explicit behavior pattern representation learner to capture the behavior patterns composed of multiplex user-item interactive relations, and includes a relation chain representation learner and a relation chain-aware encoder to discover the impact of various auxiliary relations on the target relation, the dependencies between different relations, and mine the appropriate order of relations in a behavior pattern. Extensive experiments on three real-world datasets demonstrate that our DCMGNN surpasses various state-of-the-art recommendation methods. It outperforms the best baselines by 10.06% and 12.15% on average across all datasets in terms of Recall@10 and NDCG@10 respectively. The source code of our paper is available at https://github.com/lx970414/TKDE-DCMGNN.},
  archive      = {J_TKDE},
  author       = {Xiang Li and Chaofan Fu and Zhongying Zhao and Guangjie Zheng and Chao Huang and Yanwei Yu and Junyu Dong},
  doi          = {10.1109/TKDE.2025.3544081},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3327-3341},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dual-channel multiplex graph neural networks for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual test-time training for out-of-distribution recommender system. <em>TKDE</em>, <em>37</em>(6), 3312-3326. (<a href='https://doi.org/10.1109/TKDE.2025.3548160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely applied in recommender systems, which has recently achieved revolutionary progress. However, most existing learning-based methods assume that the user and item distributions remain unchanged between the training phase and the test phase. However, the distribution of user and item features can naturally shift in real-world scenarios, potentially resulting in a substantial decrease in recommendation performance. This phenomenon can be formulated as an Out-Of-Distribution (OOD) recommendation problem. To address this challenge, we propose a novel Dual Test-Time-Training framework for OOD Recommendation, termed DT3OR. In DT3OR, we incorporate a model adaptation mechanism during the test-time phase to carefully update the recommendation model, allowing the model to adapt specially to the shifting user and item features. To be specific, we propose a self-distillation task and a contrastive task to assist the model learning both the user’s invariant interest preferences and the variant user/item characteristics during the test-time phase, thus facilitating a smooth adaptation to the shifting features. Furthermore, we provide theoretical analysis to support the rationale behind our dual test-time training framework. To the best of our knowledge, this paper is the first work to address OOD recommendation via a test-time-training strategy. We conduct experiments on five datasets with various backbones. Comprehensive experimental results have demonstrated the effectiveness of DT3OR compared to other state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Xihong Yang and Yiqi Wang and Jin Chen and Wenqi Fan and Xiangyu Zhao and En Zhu and Xinwang Liu and Defu Lian},
  doi          = {10.1109/TKDE.2025.3548160},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3312-3326},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dual test-time training for out-of-distribution recommender system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRLPG: Reinforced opponent-aware order pricing for hub mobility services. <em>TKDE</em>, <em>37</em>(6), 3298-3311. (<a href='https://doi.org/10.1109/TKDE.2025.3551147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A modern service model known as the “hub-oriented” model has emerged with the development of mobility services. This model allows users to request vehicles from multiple companies (agents) simultaneously through a unified entry (a ‘hub’). In contrast to conventional services, the “hub-oriented” model emphasizes pricing competition. To address this scenario, an agent should consider its competitors when developing its pricing strategy. In this paper, we introduce DRLPG, a mixed opponent-aware pricing method, which consists of two main components: the two-stage guarantor and the end-to-end deep reinforcement learning (DRL) module, as well as interaction mechanisms. In the guarantor, we design a prediction-decision framework. Specifically, we propose a new objective function for the spatiotemporal neural network in the prediction stage and utilize a traditional reinforcement learning method in the decision stage, respectively. In the end-to-end DRL framework, we explore the adoption of conventional DRL in the “hub-oriented” scenario. Finally, a meta-decider and an experience-sharing mechanism are proposed to combine both methods and leverage their advantages. We conduct extensive experiments on real data, and DRLPG achieves an average improvement of 99.9% and 61.1% in the peak and low peak periods, respectively. Our results demonstrate the effectiveness of our approach compared to the baseline.},
  archive      = {J_TKDE},
  author       = {Zuohan Wu and Chen Jason Zhang and Han Yin and Rui Meng and Libin Zheng and Huaijie Zhu and Wei Liu},
  doi          = {10.1109/TKDE.2025.3551147},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3298-3311},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DRLPG: Reinforced opponent-aware order pricing for hub mobility services},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distill & contrast: A new graph self-supervised method with approximating nature data relationships. <em>TKDE</em>, <em>37</em>(6), 3284-3297. (<a href='https://doi.org/10.1109/TKDE.2025.3554524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive Learning (CL) has emerged as a popular self-supervised representation learning paradigm that has been shown in many applications to perform similarly to traditional supervised learning methods. A key component of CL is mining the latent discriminative relationships between positive and negative samples and using them as self-supervised labels. We argue that this discriminative contrastive task is, in essence, similar to a classification task, and the “either positive or negative” hard label sampling strategies are arbitrary. To solve this problem, we explore ideas from data distillation, which considers probabilistic logit vectors as soft labels to transfer model knowledge. We attempt to abandon the classical hard sampling labels in CL and instead explore self-supervised soft labels. We adopt soft sampling labels that are extracted, without supervision, from the inherent relationships in data pairs to retain more information. We propose a new self-supervised graph learning method, Distill and Contrast (D&C), for learning representations that closely approximate natural data relationships. D&C extracts node similarities from the features and structures to derive soft sampling labels, which also eliminate noise in the data to increase robustness. Extensive experimental results on real-world datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Dongxiao He and Jitao Zhao and Rui Guo and Zhiyong Feng and Cuiying Huo and Di Jin and Witold Pedrycz and Weixiong Zhang},
  doi          = {10.1109/TKDE.2025.3554524},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3284-3297},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distill & contrast: A new graph self-supervised method with approximating nature data relationships},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlating time series with interpretable convolutional kernels. <em>TKDE</em>, <em>37</em>(6), 3272-3283. (<a href='https://doi.org/10.1109/TKDE.2025.3550877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of convolutional kernel learning in univariate, multivariate, and multidimensional time series data, which is crucial for interpreting temporal patterns in time series and supporting downstream machine learning tasks. First, we propose formulating convolutional kernel learning for univariate time series as a sparse regression problem with a non-negative constraint, leveraging the properties of circular convolution and circulant matrices. Second, to generalize this approach to multivariate and multidimensional time series data, we use tensor computations, reformulating the convolutional kernel learning problem in the form of tensors. This is further converted into a standard sparse regression problem through vectorization and tensor unfolding operations. In the proposed methodology, the optimization problem is addressed using the existing non-negative subspace pursuit method, enabling the convolutional kernel to capture temporal correlations and patterns. To evaluate the proposed model, we apply it to several real-world time series datasets. On the multidimensional ridesharing and taxi trip data from New York City and Chicago, the convolutional kernels reveal interpretable local correlations and cyclical patterns, such as weekly seasonality. For the monthly temperature time series data in North America, the proposed model can quantify the yearly seasonality and make it comparable across different decades. In the context of multidimensional fluid flow data, both local and nonlocal correlations captured by the convolutional kernels can reinforce tensor factorization, leading to performance improvements in fluid flow reconstruction tasks. Thus, this study lays an insightful foundation for automatically learning convolutional kernels from time series data, with an emphasis on interpretability through sparsity and non-negativity constraints.},
  archive      = {J_TKDE},
  author       = {Xinyu Chen and HanQin Cai and Fuqiang Liu and Jinhua Zhao},
  doi          = {10.1109/TKDE.2025.3550877},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3272-3283},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Correlating time series with interpretable convolutional kernels},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing shapley values for dynamic data. <em>TKDE</em>, <em>37</em>(6), 3253-3271. (<a href='https://doi.org/10.1109/TKDE.2025.3527380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data valuation is a core function in data markets and cooperative data sharing. Shapley value is a widely used approach to fairly measure the contribution of data points towards a collective utility (e.g., a machine learning model trained from the data). However, computing Shapley values is known to be in general #P-hard due to the exponential utility evaluation. Furthermore, the presence of dynamic data poses additional challenges due to the prohibitively expensive cost of recomputing from scratch. In this paper, we study the problem of Dynamic Shapley Value Computation, which focuses on updating Shapley values when dynamically adding or deleting data points. For adding, to prune redundant computation of overlapping model utilities, we propose the pivot-based algorithm that can reduce half the computation time in expectation. We also propose delta-based algorithms to capture Shapley value changes, which require only a smaller sample size to converge. For deleting, we present the YN-NN algorithm that derives the new Shapley values from precomputed utilities efficiently. Based on Shapley value changes, we give another version of the delta-based algorithm for deleting data points. Besides, we propose heuristic algorithms that draw on experimental observations for addition, deletion, and hybrid scenarios. Extensive experimental results demonstrate the efficiency and effectiveness of our proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Haocheng Xia and Jiayao Zhang and Qiheng Sun and Jinfei Liu and Kui Ren and Li Xiong and Jian Pei},
  doi          = {10.1109/TKDE.2025.3527380},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3253-3271},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Computing shapley values for dynamic data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complementary learning subnetworks towards parameter-efficient class-incremental learning. <em>TKDE</em>, <em>37</em>(6), 3240-3252. (<a href='https://doi.org/10.1109/TKDE.2025.3550809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scenario of class-incremental learning (CIL), deep neural networks have to adapt their model parameters to non-stationary data distributions, e.g., the emergence of new classes over time. To mitigate the catastrophic forgetting phenomenon, typical CIL methods either cumulatively store exemplars of old classes for retraining model parameters from scratch or progressively expand model size as new classes arrive, which, however, compromises their practical value due to little attention paid to parameter efficiency. In this paper, we contribute a novel solution, effective control of the parameters of a well-trained model, by the synergy between two complementary learning subnetworks. Specifically, we integrate one plastic feature extractor and one analytical feed-forward classifier into a unified framework amenable to streaming data. In each CIL session, it achieves non-overwritten parameter updates in a cost-effective manner, neither revisiting old task data nor extending previously learned networks; Instead, it accommodates new tasks by attaching a tiny set of declarative parameters to its backbone, in which only one matrix per task or one vector per class is kept for knowledge retention. Experimental results on a variety of task sequences demonstrate that our method achieves competitive results against state-of-the-art CIL approaches, especially in accuracy gain, knowledge transfer, training efficiency, and task-order robustness. Furthermore, a graceful forgetting implementation on previously learned trivial tasks is empirically investigated to make its non-growing backbone (i.e., a model with limited network capacity) suffice to train on more incoming tasks.},
  archive      = {J_TKDE},
  author       = {Depeng Li and Zhigang Zeng and Wei Dai and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1109/TKDE.2025.3550809},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3240-3252},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Complementary learning subnetworks towards parameter-efficient class-incremental learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CogLign: Interpretable text sentiment determination by aligning cognition between EEG-derived brain graph and text-derived knowledge graph. <em>TKDE</em>, <em>37</em>(6), 3220-3239. (<a href='https://doi.org/10.1109/TKDE.2025.3538618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, detecting sentiment or emotion from user generated texts has been intensively studied in natural language understanding, especially via neural-based models based on text representation. However, the interpretability on how could the final text sentiment be determined by neural-based text representation has not been thoroughly unfolded yet. Consequently, in this paper, we propose CogLign which injects the neural-cognition derived from Electroencephalogram (EEG)-signal into the neural-based text sentiment analysis model, aimed at learning the activation of brain regions stimulated by different sentiments, so as to guide our proposed CogLign to make proper determination on text sentiment in brain-like way. Specifically, on the one hand, the given videos in different sentiments have been watched by subjects, during which the EEG-signals are monitored to construct brain connectivity pattern as brain graph (BG), attaining more obvious sentiment response on brain region activation for neural-cognition. On the other hand, we interpret the video-plots (or video-semantics) along timeline into text, where the entire video-interpreted-text will be strictly bound with the whole EEG-signal-sequence by segment via the fixed size of time-window. Then, entities and relations are extracted from the video-interpreted-text to construct knowledge graph (KG), depicting text semantics. Next, mapping from entities (or nodes) in KG to EEG-Electrodes (or nodes) in BG, further dated back to different brain regions, has been learned via cognition alignment between the EEG-derived BG and text-derived KG. In this way, by aligning neural cognition from brain graph with the semantic cognition from knowledge graph, our proposed framework CogLign can not only achieve the overall best sentiment analysis performance on the video-interpreted-text, but can also detect brain connectivity patterns in different sentiments more consistent with the prior conclusion of brain region sentiment preference, revealing competitive interpretability on text sentiment determination.},
  archive      = {J_TKDE},
  author       = {Huan Rong and Wenxuan Ji and Tinghuai Ma and Weiyi Ding and Victor S. Sheng},
  doi          = {10.1109/TKDE.2025.3538618},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3220-3239},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CogLign: Interpretable text sentiment determination by aligning cognition between EEG-derived brain graph and text-derived knowledge graph},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal-TSF: A causal intervention approach to mitigate confounding bias in time series forecasting. <em>TKDE</em>, <em>37</em>(6), 3205-3219. (<a href='https://doi.org/10.1109/TKDE.2025.3536107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting, aiming to learn models from historical data and predict future values in time series, is a fundamental research topic in machine learning. However, few efforts have been devoted to addressing the confounding effects in time series data, e.g., the historical data are affected by some hidden surrounding factors (i.e., confounders), leading to biased forecasting models for future data. This paper presents a causal intervention approach to eliminate the bias that is raised by some hidden confounders. By using a causal graph, we illustrate why hidden confounders can bring bias in time series forecasting and how to tackle it. We implement causal intervention by a deep architecture that consists of two modules, a Confounders Estimation module to estimate the hidden confounders and a Debiasing module to eliminate the confounding bias in the forecasting model via sampling on confounders. We conduct comprehensive evaluations on various time series datasets. The experiment results indicate that the proposed method can reduce the negative confounding effects in time series data, and it achieves superior gains over state-of-the-art baselines for time series forecasting.},
  archive      = {J_TKDE},
  author       = {Qinkang Gong and Yan Pan and Hanjiang Lai and Rongbang Qiu and Jian Yin},
  doi          = {10.1109/TKDE.2025.3536107},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3205-3219},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Causal-TSF: A causal intervention approach to mitigate confounding bias in time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive graph convolution neural differential equation for spatio-temporal time series prediction. <em>TKDE</em>, <em>37</em>(6), 3193-3204. (<a href='https://doi.org/10.1109/TKDE.2024.3383895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series prediction has aroused widely research interests during decades. However, the spatial heterogeneity and temporal evolution characteristics bring much challenges for high-dimensional time series prediction. In this paper, a novel adaptive graph convolution module is introduced to automatically learn the spatial correlation of multivariate time series and a Koopman-based neural differential equation is proposed to simulate the nonlinear system state evolution. In detail, the correlation between multivariate time series is revealed by the consine similarity of node embedding to infer the potential relationship between nodes and the spatio-temporal feature fusion module is utilized. The LSTM-based network is adopted as Koopman operator to reveal the latent states of spatio-temporal time series and the reversible assumption is imposed on the Koopman operator. Furthermore, the Euler-trapezoidal integration are utilized to simulate the temporal dynamics and multiple-step prediction is carried out in the latent space from the perspective of dynamical differential equation. The proposed model could explicitly discover the spatial correlation by adaptive graph convolution and reveal the temporal dynamics by neural differential equation, which make the modeling more interpretable. Simulation results show the effectiveness on spatio-temporal dynamic discovery and prediction performance.},
  archive      = {J_TKDE},
  author       = {Min Han and Qipeng Wang},
  doi          = {10.1109/TKDE.2024.3383895},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3193-3204},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive graph convolution neural differential equation for spatio-temporal time series prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acceleration algorithms in GNNs: A survey. <em>TKDE</em>, <em>37</em>(6), 3173-3192. (<a href='https://doi.org/10.1109/TKDE.2025.3540787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks have demonstrated remarkable effectiveness in various graph-based tasks, but their inefficiency in training and inference poses significant challenges for scaling to real-world, large-scale applications. To address these challenges, a plethora of algorithms have been developed to accelerate GNN training and inference, garnering substantial interest from the research community. This paper presents a systematic review of these acceleration algorithms, categorizing them into three main topics: training acceleration, inference acceleration, and execution acceleration. For training acceleration, we discuss techniques like graph sampling and GNN simplification. In inference acceleration, we focus on knowledge distillation, GNN quantization, and GNN pruning. For execution acceleration, we explore GNN binarization and graph condensation. Additionally, we review several libraries related to GNN acceleration, including our Scalable Graph Learning library, and propose future research directions.},
  archive      = {J_TKDE},
  author       = {Lu Ma and Zeang Sheng and Xunkai Li and Xinyi Gao and Zhezheng Hao and Ling Yang and Xiaonan Nie and Jiawei Jiang and Wentao Zhang and Bin Cui},
  doi          = {10.1109/TKDE.2025.3540787},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3173-3192},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Acceleration algorithms in GNNs: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on point-of-interest recommendation: Models, architectures, and security. <em>TKDE</em>, <em>37</em>(6), 3153-3172. (<a href='https://doi.org/10.1109/TKDE.2025.3551292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.},
  archive      = {J_TKDE},
  author       = {Qianru Zhang and Peng Yang and Junliang Yu and Haixin Wang and Xingwei He and Siu-Ming Yiu and Hongzhi Yin},
  doi          = {10.1109/TKDE.2025.3551292},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3153-3172},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on point-of-interest recommendation: Models, architectures, and security},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of imbalanced learning on graphs: Problems, techniques, and future directions. <em>TKDE</em>, <em>37</em>(6), 3132-3152. (<a href='https://doi.org/10.1109/TKDE.2025.3549299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs represent interconnected structures prevalent in a myriad of real-world scenarios. Effective graph analytics, such as graph learning methods, enables users to gain profound insights from graph data, underpinning various tasks including node classification and link prediction. However, these methods often suffer from data imbalance, a common issue in graph data where certain segments possess abundant data while others are scarce, thereby leading to biased learning outcomes. This necessitates the emerging field of imbalanced learning on graphs, which aims to correct these data distribution skews for more accurate and representative learning outcomes. In this survey, we embark on a comprehensive review of the literature on imbalanced learning on graphs. We begin by providing a definitive understanding of the concept and related terminologies, establishing a strong foundational understanding for readers. Following this, we propose two comprehensive taxonomies: (1) the problem taxonomy, which describes the forms of imbalance we consider, the associated tasks, and potential solutions and (2) the technique taxonomy, which details key strategies for addressing these imbalances, and aids readers in their method selection process. Finally, we suggest prospective future directions for both problems and techniques within the sphere of imbalanced learning on graphs, fostering further innovation in this critical area.},
  archive      = {J_TKDE},
  author       = {Zemin Liu and Yuan Li and Nan Chen and Qian Wang and Bryan Hooi and Bingsheng He},
  doi          = {10.1109/TKDE.2025.3549299},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3132-3152},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of imbalanced learning on graphs: Problems, techniques, and future directions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible diffusion convolution for graph neural networks. <em>TKDE</em>, <em>37</em>(6), 3118-3131. (<a href='https://doi.org/10.1109/TKDE.2025.3547817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been gaining more attention due to their excellent performance in modeling various graph-structured data. However, most of the current GNNs only consider fixed-neighbor discrete message-passing, disregarding the importance of the local structure of different nodes and the implicit information between nodes for smoothing features. Previous approaches either focus on adaptive selection for aggregation structures or treat discrete graph convolution as a continuous diffusion process, but none of them comprehensively considered the above issues, significantly limiting the model's performance. To this end, we present a novel approach called Flexible Diffusion Convolution (Flexi-DC), which exploits the neighborhood information of nodes to set a particular continuous diffusion for each node to smooth features. Specifically, Flexi-DC first extracts the local structure knowledge based on the degrees of nodes in the graph data and then injects it into the diffusion convolution module to smooth features. Additionally, we utilize the extracted knowledge to smooth labels. Flexi-DC is an efficient framework that can significantly improve the performance of most GNN architectures. Experimental results demonstrate that Flexi-DC outperforms their vanilla implementations by an average accuracy of 13.24% (GCN), 16.37% (JKNet), and 11.98% (ARMA) on nine graph datasets with different homophily ratios.},
  archive      = {J_TKDE},
  author       = {Songwei Zhao and Bo Yu and Kang Yang and Sinuo Zhang and Jifeng Hu and Yuan Jiang and Philip S. Yu and Hechang Chen},
  doi          = {10.1109/TKDE.2025.3547817},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3118-3131},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A flexible diffusion convolution for graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Final: Combining first-order logic with natural logic for question answering. <em>TKDE</em>, <em>37</em>(6), 3103-3117. (<a href='https://doi.org/10.1109/TKDE.2025.3551231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many question-answering problems can be approached as textual entailment tasks, where the hypotheses are formed by the question and candidate answers, and the premises are derived from an external knowledge base. However, current neural methods often lack transparency in their decision-making processes. Moreover, first-order logic methods, while systematic, struggle to integrate unstructured external knowledge. To address these limitations, we propose a neuro-symbolic reasoning framework called Final, which combines FIrst-order logic with NAtural Logic for question answering. Our framework utilizes first-order logic to systematically decompose hypotheses and natural logic to construct reasoning paths from premises to hypotheses, employing bidirectional reasoning to establish links along the reasoning path. This approach not only enhances interpretability but also effectively integrates unstructured knowledge. Our experiments on three benchmark datasets, namely QASC, WorldTree, and WikiHop, demonstrate that Final outperforms existing methods in commonsense reasoning and reading comprehension tasks, achieving state-of-the-art results. Additionally, our framework also provides transparent reasoning paths that elucidate the rationale behind the correct decisions.},
  archive      = {J_TKDE},
  author       = {Jihao Shi and Xiao Ding and Siu Cheung Hui and Yuxiong Yan and Hengwei Zhao and Ting Liu and Bing Qin},
  doi          = {10.1109/TKDE.2025.3551231},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3103-3117},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Final: Combining first-order logic with natural logic for question answering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ${\sf CHASe}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi mathvariant="sans-serif">CHASe</mml:mi></mml:math>: Client heterogeneity-aware data selection for effective federated active learning. <em>TKDE</em>, <em>37</em>(6), 3088-3102. (<a href='https://doi.org/10.1109/TKDE.2025.3547423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) reduces human annotation costs for machine learning systems by strategically selecting the most informative unlabeled data for annotation, but performing it individually may still be insufficient due to restricted data diversity and annotation budget. Federated Active Learning (FAL) addresses this by facilitating collaborative data selection and model training, while preserving the confidentiality of raw data samples. Yet, existing FAL methods fail to account for the heterogeneity of data distribution across clients and the associated fluctuations in global and local model parameters, adversely affecting model accuracy. To overcome these challenges, we propose ${\sf CHASe}$ (Client Heterogeneity-Aware Data Selection), specifically designed for FAL. ${\sf CHASe}$ focuses on identifying those unlabeled samples with high epistemic variations (EVs), which notably oscillate around the decision boundaries during training. To achieve both effectiveness and efficiency, ${\sf CHASe}$ encompasses techniques for 1) tracking EVs by analyzing inference inconsistencies across training epochs, 2) calibrating decision boundaries of inaccurate models with a new alignment loss, and 3) enhancing data selection efficiency via a data freeze and awaken mechanism with subset sampling. Experiments show that ${\sf CHASe}$ surpasses various established baselines in terms of effectiveness and efficiency, validated across diverse datasets, model complexities, and heterogeneous federation settings.},
  archive      = {J_TKDE},
  author       = {Jun Zhang and Jue Wang and Huan Li and Zhongle Xie and Ke Chen and Lidan Shou},
  doi          = {10.1109/TKDE.2025.3547423},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3088-3102},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {${\sf CHASe}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi mathvariant="sans-serif">CHASe</mml:mi></mml:math>: Client heterogeneity-aware data selection for effective federated active learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). #REval: A semantic evaluation framework for hashtag recommendation. <em>TKDE</em>, <em>37</em>(6), 3075-3087. (<a href='https://doi.org/10.1109/TKDE.2025.3553683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic evaluation of hashtag recommendation models is a fundamental task in Twitter. In the traditional evaluation methods, the recommended hashtags from an algorithm are first compared with the ground truth hashtags for exact correspondences. The number of exact matches is then used to calculate the hit rate, hit ratio, precision, recall, or F1-score. This way of evaluating hashtag similarities is inadequate as it ignores the semantic correlation between the recommended and ground truth hashtags. To tackle this problem, we propose a novel semantic evaluation framework for hashtag recommendation, called #REval. This framework includes an internal module referred to as BERTag, which automatically learns the hashtag embeddings. We investigate on how the #REval framework performs under different word embedding methods and different numbers of synonyms and hashtags in the recommendation using our proposed #REval-hit-ratio measure. Our experiments of the proposed framework on three large datasets show that #REval gave more meaningful hashtag synonyms for hashtag recommendation evaluation. Our analysis also highlights the sensitivity of the framework to the word embedding technique, with #REval based on BERTag more superior over #REval based on Word2Vec, FastText, and GloVe.},
  archive      = {J_TKDE},
  author       = {Areej Alsini and Du Q. Huynh and Amitava Datta},
  doi          = {10.1109/TKDE.2025.3553683},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {6},
  number       = {6},
  pages        = {3075-3087},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {#REval: A semantic evaluation framework for hashtag recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer-and-fusion: Integrated link prediction across knowledge graphs. <em>TKDE</em>, <em>37</em>(5), 3062-3074. (<a href='https://doi.org/10.1109/TKDE.2025.3544255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing work on knowledge graph (KG) link prediction has primarily focused on a single KG. However, a single KG is often limited by its incompleteness, encompassing missing facts, entities, and relations. This limitation subsequently restricts the practicality, as it cannot handle the queries that involve missing entities or relations within the single KG. In this article, we explore an extended link prediction task, cross-KG link prediction, which answers queries using entities or relations integrated from other KGs. The crux of this problem is transferring knowledge across KGs and fusing their embedding spaces, which possess varying schemata. We develop a relation prototype graph to model the interactions among relations from different KGs. Based on this graph, we first propose a dual-view embedding learning module to fuse embedding spaces by training with instance facts and relation prototype edges. We then introduce an attention mechanism to highlight pivotal information for specific queries, recognizing that different KGs often emphasize various domains. Moreover, we devise an augmentation strategy to generate pseudo-cross-KG facts, facilitating knowledge transfer across KGs. Using four widely-used KGs, we construct two cross-KG link prediction datasets. Extensive experimental results demonstrate the superiority of our model and the unique contributions of each module.},
  archive      = {J_TKDE},
  author       = {Yuanning Cui and Zequn Sun and Wei Hu},
  doi          = {10.1109/TKDE.2025.3544255},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {3062-3074},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Transfer-and-fusion: Integrated link prediction across knowledge graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards stable and explainable attention mechanisms. <em>TKDE</em>, <em>37</em>(5), 3047-3061. (<a href='https://doi.org/10.1109/TKDE.2025.3538583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, attention mechanism has become a standard fixture in most state-of-the-art natural language processing (NLP) models, not only due to the outstanding performance it could gain but also due to plausible innate explanations for the behaviors of neural architectures it provides, which is notoriously difficult to analyze. However, recent studies show that attention is unstable against randomness and perturbations during training or testing, such as random seeds and slight perturbation of embedding vectors, which impedes it from becoming a faithful explanation tool. Thus, a natural question is whether we can find some substitute for the current attention that is more stable and could keep the most important characteristics of explanation and prediction of attention. In this paper, to resolve the problem, we provide a rigorous definition of such alternate namely SEAT (Stable and Explainable Attention). Specifically, a SEAT should have the following three properties: (1) Its prediction distribution is enforced to be close to the distribution based on the vanilla attention; (2) Its top-$k$ indices have large overlaps with those of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any slight perturbation on SEAT will not change the prediction distribution too much, which implicitly indicates that it is stable to randomness and perturbations. To further improve the interpretability stability against perturbations, based on SEAT we provide another definition called SEAT++. Then we propose a method to get a SEAT++, which could be considered an ad hoc modification for canonical attention. Finally, through intensive experiments on various datasets, we compare our SEAT and SEAT++ with other baseline methods using RNN, BiLSTM, and BERT architectures via six different evaluation metrics for model interpretation, stability, and accuracy. Results show that SEAT and SEAT++ are more stable against different perturbations and randomness while also keeping the explainability of attention, which indicates they provide more faithful explanations. Moreover, compared with vanilla attention, there is almost no utility (accuracy) degradation for SEAT and SEAT++.},
  archive      = {J_TKDE},
  author       = {Lijie Hu and Xinhai Wang and Yixin Liu and Ninghao Liu and Mengdi Huai and Lichao Sun and Di Wang},
  doi          = {10.1109/TKDE.2025.3538583},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {3047-3061},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards stable and explainable attention mechanisms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TaylorS: A multi-order expansion structure for urban spatio-temporal forecasting. <em>TKDE</em>, <em>37</em>(5), 3030-3046. (<a href='https://doi.org/10.1109/TKDE.2025.3538857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a variety of models have been proposed for urban spatio-temporal forecasting, most existing forecasting models are developed manually for specific tasks. By investigating the correlation between multi-order derivative and spatio-temporal data, we propose a generic yet simple plug-in structure, named TaylorS, to improve the performance and generalization of existing forecasting models. The TaylorS converts the non-linear regression problem into a multi-order non-linear approximation problem by plugging a Taylor expansion into the forecasting task. To achieve this, we design a two-step training framework, including a training step and an adjusting step. During training, we train a given forecasting model as a base model to be equipped with prior knowledge. During adjusting, we fine-tune the base model while plugging an adjustment model into the base model. The adjustment model, as a multi-order expansion, takes the multi-order derivative of data to evaluate data uncertainty for further forecasting approximation and adjustment. Extensive experimental results demonstrate that the proposed TaylorS framework can consistently improve the performance of existing state-of-the-art methods and generalize these methods to different forecasting tasks.},
  archive      = {J_TKDE},
  author       = {Jianyang Qin and Yan Jia and Binxing Fang and Qing Liao},
  doi          = {10.1109/TKDE.2025.3538857},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {3030-3046},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TaylorS: A multi-order expansion structure for urban spatio-temporal forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TagRec: Temporal-aware graph contrastive learning with theoretical augmentation for sequential recommendation. <em>TKDE</em>, <em>37</em>(5), 3015-3029. (<a href='https://doi.org/10.1109/TKDE.2025.3538706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation systems aim to predict the future behaviors of users based on their historical interactions. Despite the success of neural architectures like Transformer and Graph Neural Networks, these models often struggle with the inherent challenge of sparse data in accurately predicting future user behaviors. To alleviate the data sparsity problem, some methods leverage the contrastive learning to generate contrastive views, assuming the items appear discretely at the same time intervals and focusing on the sequence order. However, these approaches neglect the crucial temporal-aware collaborative patterns hidden within the user-item interactions, leading to a limited variety of contrastive pairs and less informative embeddings. The proposed framework, Temporal-aware graph contrastive learning with theoretical guarantees for sequential Recommendation (TagRec), integrates temporal-aware collaborative patterns with adaptive data augmentation to generate more informative user and item representations. TagRec employs a temporal-aware graph neural network to embed the original graph, then generates augmented graphs through the addition of interactions via latent user interest mining, the dropping of redundant interaction edges, and the perturbation of temporal information. Theoretical guarantees are provided that these augmentations enhance the graph’s utility. Extensive experiments on real-world datasets demonstrate the superiority of the proposed approach over the state-of-the-art recommendation methods.},
  archive      = {J_TKDE},
  author       = {Tianhao Peng and Haitao Yuan and Yongqi Zhang and Yuchen Li and Peihong Dai and Qunbo Wang and Senzhang Wang and Wenjun Wu},
  doi          = {10.1109/TKDE.2025.3538706},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {3015-3029},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TagRec: Temporal-aware graph contrastive learning with theoretical augmentation for sequential recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style feature extraction using contrastive conditioned variational autoencoders with mutual information constraints. <em>TKDE</em>, <em>37</em>(5), 3001-3014. (<a href='https://doi.org/10.1109/TKDE.2025.3543383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting fine-grained features such as styles from unlabeled data is crucial for data analysis. Unsupervised methods such as variational autoencoders (VAEs) can extract styles that are usually mixed with other features. Conditional VAEs (CVAEs) can isolate styles using class labels; however, there are no established methods to extract only styles using unlabeled data. In this paper, we propose a CVAE-based method that extracts style features using only unlabeled data. The proposed model consists of a contrastive learning (CL) part that extracts style-independent features and a CVAE part that extracts style features. The CL model learns representations independent of data augmentation, which can be viewed as a perturbation in styles, in a self-supervised manner. Considering the style-independent features from the pretrained CL model as a condition, the CVAE learns to extract only styles. Additionally, we introduce a constraint based on mutual information between the CL and VAE features to prevent the CVAE from ignoring the condition. Experiments conducted using two simple datasets, MNIST and an original dataset based on Google Fonts, demonstrate that the proposed method can efficiently extract style features. Further experiments using real-world natural image datasets were also conducted to illustrate the method’s extendability.},
  archive      = {J_TKDE},
  author       = {Suguru Yasutomi and Toshihisa Tanaka},
  doi          = {10.1109/TKDE.2025.3543383},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {3001-3014},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Style feature extraction using contrastive conditioned variational autoencoders with mutual information constraints},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal multivariate probabilistic modeling for traffic prediction. <em>TKDE</em>, <em>37</em>(5), 2986-3000. (<a href='https://doi.org/10.1109/TKDE.2025.3539680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is an essential task in intelligent transportation systems dealing with complex and dynamic spatio-temporal correlations. To date, most work is focused on point estimation models, which only output a single value w.r.t an attribute of traffic data at a time, falling short of depicting diverse situations and uncertainty in future. Besides, most methods are not flexible enough to handle real complex traffic scenarios, involving missing values and non-uniformly sampled data. The interactions among different attributes of traffic data are also rarely explored explicitly. In this paper, we focus on probabilistic estimation in traffic prediction tasks, proposing a spatio-temporal multivariate probabilistic predictive model to estimate the distributions of traffic data. Specifically, we devise a multivariate spatio-temporal fusion graph block to extract spatio-temporal correlations of multiple traffic attributes at different locations. A multi-graph fusion module is designed to capture time-varying spatial relationships. We estimate the joint distributions of missing traffic data using copulas. The proposed model can simultaneously perform traffic forecasting and interpolation tasks with non-uniformly sampled data. Our experiments on two real-world traffic datasets demonstrate the advantages of our model over the state-of-the-art1.},
  archive      = {J_TKDE},
  author       = {Yang An and Zhibin Li and Xiaoyu Li and Wei Liu and Xinghao Yang and Haoliang Sun and Meng Chen and Yu Zheng and Yongshun Gong},
  doi          = {10.1109/TKDE.2025.3539680},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2986-3000},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatio-temporal multivariate probabilistic modeling for traffic prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Snoopy: Effective and efficient semantic join discovery via proxy columns. <em>TKDE</em>, <em>37</em>(5), 2971-2985. (<a href='https://doi.org/10.1109/TKDE.2025.3545176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic join discovery, which aims to find columns in a table repository with high semantic joinabilities to a query column, is crucial for dataset discovery. Existing methods can be divided into two categories: cell-level methods and column-level methods. However, neither of them ensures both effectiveness and efficiency simultaneously. Cell-level methods, which compute the joinability by counting cell matches between columns, enjoy ideal effectiveness but suffer poor efficiency. In contrast, column-level methods, which determine joinability only by computing the similarity of column embeddings, enjoy proper efficiency but suffer poor effectiveness due to the issues occurring in their column embeddings: (i) semantics-joinability-gap, (ii) size limit, and (iii) permutation sensitivity. To address these issues, this paper proposes to compute column embeddings via proxy columns; furthermore, a novel column-level semantic join discovery framework, ${\sf Snoopy}$, is presented, leveraging proxy-column-based embeddings to bridge effectiveness and efficiency. Specifically, the proposed column embeddings are derived from the implicit column-to-proxy-column relationships, which are captured by the lightweight approximate-graph-matching-based column projection. To acquire good proxy columns for guiding the column projection, we introduce a rank-aware contrastive learning paradigm. Extensive experiments on four real-world datasets demonstrate that ${\sf Snoopy}$ outperforms SOTA column-level methods by 16% in Recall@25 and 10% in NDCG@25, and achieves superior efficiency—being at least 5 orders of magnitude faster than cell-level solutions, and 3.5× faster than existing column-level methods.},
  archive      = {J_TKDE},
  author       = {Yuxiang Guo and Yuren Mao and Zhonghao Hu and Lu Chen and Yunjun Gao},
  doi          = {10.1109/TKDE.2025.3545176},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2971-2985},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Snoopy: Effective and efficient semantic join discovery via proxy columns},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SemSI-GAT: Semantic similarity-based interaction graph attention network for knowledge graph completion. <em>TKDE</em>, <em>37</em>(5), 2958-2970. (<a href='https://doi.org/10.1109/TKDE.2025.3528496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) show great power in Knowledge Graph Completion (KGC) as they can handle non-Euclidean graph structures and do not depend on the specific shape or topology of the graph. However, many current GNN-based KGC models have difficulty in effectively capturing and utilizing the substantial structure and global semantic information in Knowledge Graphs (KGs). For more effective use of GNN for KGC, we innovatively propose the Semantic Similarity-based Interaction Graph Attention Network (SemSI-GAT) for the KGC task. In SemSI-GAT, we utilize BERT, a pre-trained language model, to learn the global semantic information and obtain semantic similarity between entities and their neighbors. Furthermore, we creatively design a novel encoder network called the interaction graph attention network and introduce a semantic similarity sampling mechanism to optimize the aggregation of interaction information between neighbors. By aggregating local features with interaction features, this network can generate more expressive structural embeddings. This network generates more expressive embeddings by fusing global semantic information, local structure features, and interaction features. The experimental evaluations demonstrate that the proposed SemSI-GAT outperforms existing state-of-the-art KGC methods on four benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Xingfei Wang and Ke Zhang and Muyuan Niu and Xiaofen Wang},
  doi          = {10.1109/TKDE.2025.3528496},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2958-2970},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SemSI-GAT: Semantic similarity-based interaction graph attention network for knowledge graph completion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCHENO: Measuring schema vs. noise in graphs. <em>TKDE</em>, <em>37</em>(5), 2946-2957. (<a href='https://doi.org/10.1109/TKDE.2025.3543032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data is typically a noisy manifestation of a core pattern (schema), and the purpose of data mining algorithms is to uncover that pattern, thereby splitting (i.e. decomposing) the data into schema and noise. We introduce SCHENO, a principled evaluation metric for the goodness of a schema-noise decomposition of a graph. SCHENO captures how schematic the schema is, how noisy the noise is, and how well the combination of the two represent the original graph data. We visually demonstrate what this metric prioritizes in small graphs, then show that if SCHENO is used as the fitness function for a simple optimization strategy, we can uncover a wide variety of patterns. Finally, we evaluate several well-known graph mining algorithms with this metric; we find that although they produce patterns, those patterns are not always the best representation of the input data.},
  archive      = {J_TKDE},
  author       = {Justus Isaiah Hibshman and Adnan Hoq and Tim Weninger},
  doi          = {10.1109/TKDE.2025.3543032},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2946-2957},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SCHENO: Measuring schema vs. noise in graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multi-view graph clustering with cross-view corresponding anchor alignment. <em>TKDE</em>, <em>37</em>(5), 2932-2945. (<a href='https://doi.org/10.1109/TKDE.2025.3538852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering (MVGC) explores pairwise correlations of entire instances and comprehensively aggregates diverse source information with optimal graph structure. One major issue of practical MVGC is the high time and space complexities prohibiting being applied on large-scale applications. As a promising solution of addressing large-scale problems, anchor-based strategy identifies small portion and key landmarks to serve as replacements for the entire dataset. Despite of its efficiency, anchors chosen across views may be semantically unaligned contrasting to naturally-aligned full sample setting, which may lead to the latter inappropriate graph fusion. Limited attention has been focused on the mentioned Multi-View Anchor-Unaligned Problem (MV-AUP) in the existing literature. In this paper, we first revisit existing multi-view anchor graph clustering frameworks and present the MV-AUP phenomenon. Then, we propose a novel Multi-view Corresponding Anchor Graph Alignment Fusion framework (MV-CAGAF), which elegantly solves MV-AUP with structural representation matching in multi-dimensional spaces. Further, we theoretically prove our proposed structural matching approach can be regarded as minimizing the EMD distance of the two relative anchor distributions. Based on this, we design the innovative multi-view anchor graph fusion paradigm with correspondence alignment, which inherits the linear sample complexity for scalable cross-view clustering. Our proposed MV-CAGAF achieves significant improvements with the help of the novel fusion framework on comprehensive benchmark datasets. Most importantly, the experimental results on both of the simulated and real-world datasets significantly prove the importance of cross-view alignment for large-scale multi-view clustering.},
  archive      = {J_TKDE},
  author       = {Siwei Wang and Xinwang Liu and Qing Liao and Yi Wen and En Zhu and Kunlun He},
  doi          = {10.1109/TKDE.2025.3538852},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2932-2945},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable multi-view graph clustering with cross-view corresponding anchor alignment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable min-max multi-view spectral clustering. <em>TKDE</em>, <em>37</em>(5), 2918-2931. (<a href='https://doi.org/10.1109/TKDE.2025.3543817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering has attracted considerable attention since it can explore common geometric structures from diverse views. Nevertheless, existing min-min framework-based models adopt internal minimization to find the view combination with the minimized within-cluster variance, which will lead to effectiveness loss since the real clusters often exhibit high within-cluster variance. To address this issue, we provide a novel scalable min-max multi-view spectral clustering (SMMSC) model to improve clustering performance. Besides, anchor graphs, rather than full sample graphs, are utilized to reduce the computational complexity of graph construction and singular value decomposition, thereby enhancing the applicability of SMMSC to large-scale applications. Then, we rewrite the min-max model as a minimized optimal value function, demonstrate its differentiability, and develop an efficient gradient descent-based algorithm to optimize it with linear computational complexity. Moreover, we demonstrate that the resultant solution of the proposed algorithm is the global optimum. Numerous experiments on different real-world datasets, including some large-scale datasets, demonstrate that SMMSC outperforms existing state-of-the-art multi-view clustering methods regarding clustering performance.},
  archive      = {J_TKDE},
  author       = {Ben Yang and Xuetao Zhang and Jinghan Wu and Feiping Nie and Fei Wang and Badong Chen},
  doi          = {10.1109/TKDE.2025.3543817},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2918-2931},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable min-max multi-view spectral clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking variational bayes in community detection from graph signal perspective. <em>TKDE</em>, <em>37</em>(5), 2903-2917. (<a href='https://doi.org/10.1109/TKDE.2025.3543378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods based on variational bayes theorytare widely used to detect community structures in networks. In recent years, many related methods have emerged that provide valuable insights into variational bayes theory. Remarkably, a fundamental assumption remains incomprehensible. Variational bayes-based methods typically employ a posterior distribution that follows a gaussian distribution to approximate the unknown prior distribution. However, the complexity and irregularity of node distributions in real-world networks prompt us to consider what characteristics of network information are suitable for the posterior distribution. Mathematically, inappropriate low- and high-frequency signals in expectation inference and variance inference can intensify the adverse effects of community distortion and ambiguity. To analysis these two phenomena and propose reasonable countermeasures, we conduct an empirical study. It is found that appropriately compressing low-frequency signals during expectation inference and amplifying high-frequency signals during variance inference are effective strategies. Based on these two strategies, this paper proposes a novel variational bayes plug-in, namely VBPG, to boost the performance of existing variational bayes-based community detection methods. Specifically, we modulate the frequency signals during expectation and variance inference to generate a new gaussian distribution. This strategy improves the fitting accuracy between the posterior distribution and the unknown true distribution without altering the modules of existing methods. The comprehensive experimental results validate that methods using VBPG achieve competitive performance improvements in most cases.},
  archive      = {J_TKDE},
  author       = {Junwei Cheng and Yong Tang and Chaobo He and Pengxing Feng and Kunlin Han and Quanlong Guan},
  doi          = {10.1109/TKDE.2025.3543378},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2903-2917},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Rethinking variational bayes in community detection from graph signal perspective},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REP: An interpretable robustness enhanced plugin for differentiable neural architecture search. <em>TKDE</em>, <em>37</em>(5), 2888-2902. (<a href='https://doi.org/10.1109/TKDE.2025.3543503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is widely used to automate the design of high-accuracy deep architectures, which are often vulnerable to adversarial attacks in practice due to the lack of adversarial robustness. Existing methods focus on the direct utilization of regularized optimization process to address this critical issue, which causes the lack of interpretability for the end users to learn how the robust architecture is constructed. In this paper, we introduce a robust enhanced plugin (REP) method for differentiable NAS to search for robust neural architectures. Different from existing peer methods, REP focuses on the robust search primitives in the search space of NAS methods, and naturally has the merit of contributing to understanding how the robust architectures are progressively constructed. Specifically, we first propose an effective sampling strategy to sample robust search primitives in the search space. In addition, we also propose a probabilistic enhancement method to guarantee natural accuracy and adversarial robustness simultaneously during the search process. We conduct experiments on both convolutional neural networks and graph neural networks with widely used benchmarks against state of the arts. The results reveal that REP can achieve superiority in terms of both the adversarial robustness to popular adversarial attacks and the natural accuracy of original data. REP is flexible and can be easily used by any existing differentiable NAS methods to enhance their robustness without much additional effort.},
  archive      = {J_TKDE},
  author       = {Yuqi Feng and Yanan Sun and Gary G. Yen and Kay Chen Tan},
  doi          = {10.1109/TKDE.2025.3543503},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2888-2902},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {REP: An interpretable robustness enhanced plugin for differentiable neural architecture search},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic learning of multivariate time series with temporal irregularity. <em>TKDE</em>, <em>37</em>(5), 2874-2887. (<a href='https://doi.org/10.1109/TKDE.2025.3544348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic forecasting of multivariate time series is essential for various downstream tasks. Most existing approaches rely on the sequences being uniformly spaced and aligned across all variables. However, real-world multivariate time series often suffer from temporal irregularities, including nonuniform intervals and misaligned variables, which pose significant challenges for accurate forecasting. To address these challenges, we propose an end-to-end framework that models temporal irregularities while capturing the joint distribution of variables at arbitrary continuous-time points. Specifically, we introduce a dynamic conditional continuous normalizing flow to model data distributions in a non-parametric manner, accommodating the complex, non-Gaussian characteristics commonly found in real-world datasets. Then, by leveraging a carefully factorized log-likelihood objective, our approach captures both temporal and cross-sectional dependencies efficiently. Extensive experiments on a range of real-world datasets demonstrate the superiority and adaptability of our method compared to existing approaches.},
  archive      = {J_TKDE},
  author       = {Yijun Li and Cheuk Hang Leung and Qi Wu},
  doi          = {10.1109/TKDE.2025.3544348},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2874-2887},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Probabilistic learning of multivariate time series with temporal irregularity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRADA: Pre-train ranking models with diverse relevance signals mined from search logs. <em>TKDE</em>, <em>37</em>(5), 2861-2873. (<a href='https://doi.org/10.1109/TKDE.2024.3515800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing studies have proven that pre-trained ranking models outperform pre-trained language models when it comes to ranking tasks. To pre-train such models, researchers have utilized large-scale search logs and clicks as weak-supervised signals of query-document relevance. However, search logs are incomplete and sparse. Different users with the same intent tend to use various forms of queries. It is hard for recorded clicks to sufficiently cover diverse relevance patterns between queries and documents. Moreover, the diverse intentions of a large user base lead to long-tail distributions of search intents. Deriving sufficient relevance signals from sparse clicks of these long-tail intents poses another challenge. Therefore, there is significant potential for exploring richer relevance signals beyond direct clicks to pre-train high-quality ranking models. To tackle this problem, we develop two exploratory data augmentation strategies that consider the diversity of query forms from local and global perspectives, hence mining potential and diverse relevance signals from search logs. A generative augmentation strategy is also devised to create supplementary positive samples, to enhance the ranking ability for long-tail query intents. We leverage a multi-level pairwise ranking objective and a contrastive learning approach to enable our model to capture fine-grained relevance patterns and be robust for noisy training samples. Experimental results on a large-scale public dataset and a commercial dataset confirm that our model, namely PRADA, can yield better ranking effectiveness over existing pre-trained ranking models.},
  archive      = {J_TKDE},
  author       = {Shuting Wang and Zhicheng Dou and Kexiang Wang and Dehong Ma and Jun Fan and Daiting Shi and Zhicong Cheng and Simiu Gu and Dawei Yin and Ji-Rong Wen},
  doi          = {10.1109/TKDE.2024.3515800},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2861-2873},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PRADA: Pre-train ranking models with diverse relevance signals mined from search logs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical equi-join over encrypted database with reduced leakage. <em>TKDE</em>, <em>37</em>(5), 2846-2860. (<a href='https://doi.org/10.1109/TKDE.2025.3543168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure join schemes, an important class of queries over encrypted databases, have attracted increasing attention. While efficient querying is paramount, data owners also emphasize the significance of privacy preservation. The state-of-the-art JXT (Jutla and Patranabis ASIACRYPT 2022) enables efficient join queries over encrypted tables with a symmetric-key solution. However, we observe that JXT inadvertently leaks undesirable query results as the number of queries increases. In this paper, we propose a novel equi-join scheme, One-Time Join Cross-Tags (OTJXT), which can avoid additional result leakage in multiple queries and extend to equi-join as opposed to natural join in JXT. Specifically, we design a new data encoding method using nonlinear transformations that reveals only the union of results for each query without extra leakage observed in JXT. Moreover, OTJXT addresses the linear search complexity issue (Shafieinejad et al. ICDE 2022) while preventing multiple query leakage. Finally, we implement OTJXT and compare its performance with JXT and Shafieinejad et al.'s scheme on the TPC-H dataset. The results show that OTJXT outperforms in search and storage efficiency, achieving a $\mathbf {98.5\times }$ (resp., $\mathbf {10^{6}\times }$) speedup in search latency and reducing storage cost by 62.5% (resp., 78.5%), compared to JXT (resp., Shafieinejad et al.'s scheme). Using OTJXT, a TPC-H query on a 40 MB database only takes 21 ms.},
  archive      = {J_TKDE},
  author       = {Qiaoer Xu and Jianfeng Wang and Shi-Feng Sun and Zhipeng Liu and Xiaofeng Chen},
  doi          = {10.1109/TKDE.2025.3543168},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2846-2860},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Practical equi-join over encrypted database with reduced leakage},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PipeOptim: Ensuring effective 1F1B schedule with optimizer-dependent weight prediction. <em>TKDE</em>, <em>37</em>(5), 2831-2845. (<a href='https://doi.org/10.1109/TKDE.2025.3543225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asynchronous pipeline model parallelism with a “1F1B” (one forward, one backward) schedule generates little bubble overhead and always provides quite a high throughput. However, the “1F1B” schedule inevitably leads to weight inconsistency and weight staleness issues due to the cross-training of different mini-batches across GPUs. To simultaneously address these two problems, in this paper, we propose an optimizer-dependent weight prediction strategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight of our proposal is that we employ a weight prediction strategy in the forward pass to approximately ensure that each mini-batch uses consistent and staleness-free weights to compute the forward pass of the “1F1B” schedule. To be concrete, we first construct the weight prediction scheme based on the update rule of the used optimizer when training the deep neural network models. Then throughout the “1F1B” pipeline training, each mini-batch is mandated to execute weight prediction, subsequently employing the predicted weights to perform the forward pass. As a result, PipeOptim 1) inherits the advantage of the “1F1B” schedule and generates high throughput, and 2) can ensure effective parameter learning regardless of the type of the used optimizer. We conducted extensive experimental evaluations using nine different deep-learning models to verify the effectiveness of our proposal. The experiment results demonstrate that PipeOptim outperforms the other five popular pipeline approaches including GPipe, PipeDream, PipeDream-2BW, SpecTrain, and XPipe.},
  archive      = {J_TKDE},
  author       = {Lei Guan and Dongsheng Li and Yongle Chen and Jiye Liang and Wenjian Wang and Xicheng Lu},
  doi          = {10.1109/TKDE.2025.3543225},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2831-2845},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PipeOptim: Ensuring effective 1F1B schedule with optimizer-dependent weight prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PipeFilter: Parallelizable and space-efficient filter for approximate membership query. <em>TKDE</em>, <em>37</em>(5), 2816-2830. (<a href='https://doi.org/10.1109/TKDE.2025.3543881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate membership query data structures (i.e., filters) have ubiquitous applications in database and data mining. Cuckoo filters are emerging as the alternative to Bloom filters because they support deletions and usually have higher operation throughput and space efficiency. However, their designs are confined to a single-threaded execution paradigm and consequently cannot fully exploit the parallel processing capabilities of modern hardware. This paper presents PipeFilter, a faster and more space-efficient filter that harnesses pipeline parallelism for superior performance. PipeFilter re-architects the Cuckoo filter by partitioning its data structure into several sub-filters, each providing a candidate position for every item. This allows the filter operations, including insertion, lookup, and deletion, to be naturally distributed across several pipeline stages, each overseeing one of the sub-filters, which can further be implemented through multi-threaded execution or pipeline stages of programmable hardware to achieve significantly higher throughput. Meanwhile, PipeFilter excels for single-threaded execution thanks to a combination of unique design features, including block design, path prophet, round robin, and SIMD optimization, such that it achieves superior performance than the SOTAs even when running with a single core. PipeFilter also has a competitive advantage in space utilization because it permits each item to explore more candidate positions. We implement and optimize PipeFilter on four platforms (single-core CPU, multi-core CPU, FPGA, and P4 ASIC). Experimental results demonstrate that PipeFilter surpasses all baseline methods on four platforms. When running with a single core, it showcases a notable 15%$\sim$57% improvement in operation throughput and a high load factor exceeding 99%. When parallel processing on other platforms, PipeFilter achieves 7$\times \sim 800\times$ higher throughput than single-threaded execution.},
  archive      = {J_TKDE},
  author       = {Shankui Ji and Yang Du and He Huang and Yu-E Sun and Jia Liu and Yapeng Shu},
  doi          = {10.1109/TKDE.2025.3543881},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2816-2830},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PipeFilter: Parallelizable and space-efficient filter for approximate membership query},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern hiding and authorized searchable encryption for data sharing in cloud storage. <em>TKDE</em>, <em>37</em>(5), 2802-2815. (<a href='https://doi.org/10.1109/TKDE.2025.3537613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure cloud storage is a prevalent way to provide data retrieval services, where users’ data are encrypted before uploading to the cloud. To effectively perform keyword searches over the encrypted data, the approach of searchable encryption (SE) was introduced. However, the leakage of the keyword-pair result pattern to the cloud could be exploited to reconstruct the queried keywords. To mitigate such information leakages, numerous result pattern-hiding SE systems were proposed but rarely supported data sharing with expressive queries and even owner-enforced authorization. Therefore, we present a result pattern hiding and authorized SE system (AXT) supporting conjunctive queries for cloud-based data sharing. Technically, we construct an authorized label private set intersection protocol from a refined authorized public key encryption with an equality test and then combine it with an introduced asymmetric variant of oblivious cross-tag protocol. Moreover, we introduce the system and security model of AXT along with rigorous security proof. Furthermore, we conduct comparative experiments between state-of-the-art solutions with AXT on HUAWEI Cloud platform under the widely recognized Enron dataset, which reveal that AXT achieves practical performance with retaining authorized data sharing and result pattern hiding, specifically, the time overhead for conjunctive queries with 10 keywords is reduced by 20$\%$.},
  archive      = {J_TKDE},
  author       = {Kai Zhang and Boli Hu and Jianting Ning and Junqing Gong and Haifeng Qian},
  doi          = {10.1109/TKDE.2025.3537613},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2802-2815},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pattern hiding and authorized searchable encryption for data sharing in cloud storage},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partitioned dynamic hub labeling for large road networks. <em>TKDE</em>, <em>37</em>(5), 2784-2801. (<a href='https://doi.org/10.1109/TKDE.2025.3538694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shortest path computation is ubiquitous in various applications in road networks and the index-based algorithms, especially hub labeling, can boost the query performance dramatically. However, traffic conditions keep changing in real life, making the precomputed index unable to answer the query correctly. In this work, we adopt the state-of-the-art tree decomposition-based hub labeling (TDHL) as the underlying index and design efficient algorithms to incrementally maintain the index. Specifically, we first analyze the structural stability of the index in dynamic road networks which enables us to concentrate on label value maintenance. We then introduce the minimum weight property and minimum distance property to guarantee index correctness without graph traversal. Moreover, we propose the star-centric paradigm for tracing index change and design various pruning techniques to further accelerate index maintenance. We also extend our algorithms to batch mode for shared computation, to structural maintenance for full types of updates, and generalize to all kinds of TDHL. Finally, we further improve the index maintenance efficiency and scalability of our algorithms by leveraging graph partition. Our experimental results validate the superiority of our proposals over existing solutions on both index maintenance and query processing.},
  archive      = {J_TKDE},
  author       = {Mengxuan Zhang and Xinjie Zhou and Lei Li and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2025.3538694},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2784-2801},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Partitioned dynamic hub labeling for large road networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-step adaptive graph learning for incomplete multiview subspace clustering. <em>TKDE</em>, <em>37</em>(5), 2771-2783. (<a href='https://doi.org/10.1109/TKDE.2025.3543696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multiview clustering (IMVC) optimally integrates complementary information within incomplete multiview data to improve clustering performance. Several one-step graph-based methods show great potential for IMVC. However, the low-rank structures of similarity graphs are neglected at the initialization stage of similarity graph construction. Moreover, further investigation into complementary information integration across incomplete multiple views is needed, particularly when considering the low-rank structures implied in high-dimensional multiview data. In this paper, we present one-step adaptive graph learning (OAGL) that adaptively performs spectral embedding fusion to achieve clustering assignments at the clustering indicator level. We first initiate affinity matrices corresponding to incomplete multiple views using spare representation under two constraints, i.e., the sparsity constraint on each affinity matrix corresponding to an incomplete view and the degree matrix of the affinity matrix approximating an identity matrix. This approach promotes exploring complementary information across incomplete multiple views. Subsequently, we perform an alignment of the spectral block-diagonal matrices among incomplete multiple views using low-rank tensor learning theory. This facilitates consistency information exploration across incomplete multiple views. Furthermore, we present an effective alternating iterative algorithm to solve the resulting optimization problem. Extensive experiments on benchmark datasets demonstrate that the proposed OAGL method outperforms several state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Jie Chen and Hua Mao and Wai Lok Woo and Chuanbin Liu and Zhu Wang and Xi Peng},
  doi          = {10.1109/TKDE.2025.3543696},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2771-2783},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {One-step adaptive graph learning for incomplete multiview subspace clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view riemannian manifolds fusion enhancement for knowledge graph completion. <em>TKDE</em>, <em>37</em>(5), 2756-2770. (<a href='https://doi.org/10.1109/TKDE.2025.3538110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of knowledge graphs becomes increasingly widespread, the issue of knowledge graph incompleteness has garnered significant attention. As a classical type of non-euclidean spatial data, knowledge graphs possess various complex structural types. However, most current knowledge graph completion models are developed within a single space, which makes it challenging to capture the inherent knowledge information embedded in the entire knowledge graph. This limitation hinders the representation learning capability of the models. To address this issue, this paper focuses on how to better extend the representation learning from a single space to Riemannian manifolds, which are capable of representing more complex structures. We propose a new knowledge graph completion model called MRME-KGC, based on multi-view Riemannian Manifolds fusion to achieve this. Specifically, MRME-KGC simultaneously considers the fusion of four views: two hyperbolic Riemannian spaces with negative curvature, a Euclidean Riemannian space with zero curvature, and a spherical Riemannian space with positive curvature to enhance knowledge graph modeling. Additionally, this paper proposes a contrastive learning method for Riemannian spaces to mitigate the noise and representation issues arising from Multi-view Riemannian Manifolds Fusion. This paper presents extensive experiments on MRME-KGC across multiple datasets. The results consistently demonstrate that MRME-KGC significantly outperforms current state-of-the-art models, achieving highly competitive performance even with low-dimensional embeddings.},
  archive      = {J_TKDE},
  author       = {Linyu Li and Zhi Jin and Xuan Zhang and Haoran Duan and Jishu Wang and Zhengwei Tao and Haiyan Zhao and Xiaofeng Zhu},
  doi          = {10.1109/TKDE.2025.3538110},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2756-2770},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view riemannian manifolds fusion enhancement for knowledge graph completion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTD-DS: An SLA-aware decision support benchmark for multi-tenant parallel DBMSs. <em>TKDE</em>, <em>37</em>(5), 2743-2755. (<a href='https://doi.org/10.1109/TKDE.2025.3543727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-tenant DBMSs are used by cloud providers for their Database-as-a-Service products. They could be single-node DBMSs installed in virtual machines, SQL-on-Hadoop systems or classic parallel relational DBMSs running on top of a shared-nothing or shared-disk architecture. For a cloud provider, it is interesting to measure these systems’ capability of dealing with multi-tenant workloads, i.e., taking advantage of the statistical multiplexing to obtain economic gain while being attractive by providing a good quality of service and a low bill to the tenants. In this paper, we present MTD-DS benchmark (with MTD for Multi-Tenant parallel DBMSs and DS for Decision Support). MTD-DS extends TPC-DS by adding a multi-tenant query workload generator, a performance Service Level Objectives generator, configurable Database-as-a-Service pricing models, and new metrics to measure the potential capability of a multi-tenant parallel DBMS in obtaining the best trade-off between the provider's benefit and the tenants’ satisfaction. Example experimental results have been produced to show the relevance and the feasibility of the MTD-DS benchmark.},
  archive      = {J_TKDE},
  author       = {Shaoyi Yin and Franck Morvan and Jorge Martinez-Gil and Abdelkader Hameurlain},
  doi          = {10.1109/TKDE.2025.3543727},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2743-2755},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MTD-DS: An SLA-aware decision support benchmark for multi-tenant parallel DBMSs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-agnostic dual-side online fairness learning for dynamic recommendation. <em>TKDE</em>, <em>37</em>(5), 2727-2742. (<a href='https://doi.org/10.1109/TKDE.2025.3544510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness in recommendation has drawn much attention since it significantly affects how users access information and how information is exposed to users. However, most fairness-aware methods are designed offline with the entire stationary interaction data to handle the global unfairness issue and evaluate their performance in a one-time paradigm. In real-world scenarios, users tend to interact with items continuously over time, leading to a dynamic recommendation environment where unfairness is evolving online. Moreover, previous methods that focus on mitigating the unfairness can hardly bring significant improvements to the recommendation task. Hence, in this paper, we propose a Model-agnostic Dual-side Online Fairness Learning method (MDOFair) for the dynamic recommendation. First, we carefully design dynamic dual-side fairness learning to trace the rapid evolution of unfairness from both the user and item sides. Second, we leverage the fairness and recommendation tasks in one utilized framework to pursue the double-win success. Last, we present an efficient model-agnostic post-ranking method for the dynamic recommendation scenario to mitigate the dynamic unfairness while improving the recommendation performance significantly. Extensive experiments demonstrate the superiority and effectiveness of our proposed MDOFair by incorporating it into existing dynamic models as a post-ranking stage.},
  archive      = {J_TKDE},
  author       = {Haoran Tang and Shiqing Wu and Zhihong Cui and Yicong Li and Guandong Xu and Qing Li},
  doi          = {10.1109/TKDE.2025.3544510},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2727-2742},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Model-agnostic dual-side online fairness learning for dynamic recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning location-guided time-series shapelets. <em>TKDE</em>, <em>37</em>(5), 2712-2726. (<a href='https://doi.org/10.1109/TKDE.2025.3536462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shapelets are interclass discriminative subsequences that can be used to characterize target classes. Learning shapelets by continuous optimization has recently been studied to improve classification accuracy. However, there are two issues in previous studies. First, since the locations where shapelets appear in the time series are determined by only their shapes, shapelets may appear at incorrect and non-discriminative locations in the time series, degrading the accuracy and interpretability. Second, the theoretical interpretation of learned shapelets has been limited to binary classification. To tackle the first issue, we propose a continuous optimization that learns not only shapelets but also their probable locations in a time series, and we show theoretically that this enhances feature discriminability. To tackle the second issue, we provide a theoretical interpretation of shapelet closeness to the time series for target / off-target classes when learning with softmax loss, which allows for multi-class classification. We demonstrate the effectiveness of the proposed method in terms of accuracy, runtime, and interpretability on the UCR archive.},
  archive      = {J_TKDE},
  author       = {Akihiro Yamaguchi and Ken Ueno and Hisashi Kashima},
  doi          = {10.1109/TKDE.2025.3536462},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2712-2726},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning location-guided time-series shapelets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale hierarchical causal discovery via weak prior knowledge. <em>TKDE</em>, <em>37</em>(5), 2695-2711. (<a href='https://doi.org/10.1109/TKDE.2025.3537832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery faces significant challenges as the number of hypotheses grows exponentially with the number of variables. This complexity becomes particularly daunting when dealing with large sets of variables. We introduce a novel divide-and-conquer method that uniquely handles this challenge. The existing division strategies often rely on conditional independency (CI) tests or data-driven clustering to split variables, which can suffer from the typical data scarcity in large-scale settings, thus leading to inaccurate division results. The proposed method overcomes this by implementing a data-independent division strategy, which constructs a prior structure, informed by potential causal relationships identified using a Large Language Model (LLM), to guide recursively dividing variables into sub-sets. This approach avoids the impact of data insufficiency and is robust against potential incompleteness in the prior structure. In the merging phase, we adopt a score-based refinement strategy to address fake causal links caused by hidden variables in sub-sets, which eliminates edges in the intersected parts of sub-sets to optimize the score of local structures. While maintaining both correctness and completeness under the faithfulness assumption, this novel merging approach demonstrates enhanced performance than the conventional CI-test based merging strategy in practical scenarios. Empirical evaluations on various large-scale datasets demonstrate the proposed approach's superior accuracy and efficiency compared to existing causal discovery methods.},
  archive      = {J_TKDE},
  author       = {Xiangyu Wang and Taiyu Ban and Lyuzhou Chen and Derui Lyu and Qinrui Zhu and Huanhuan Chen},
  doi          = {10.1109/TKDE.2025.3537832},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2695-2711},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large-scale hierarchical causal discovery via weak prior knowledge},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). -graph: A graph embedding for interpretable time series clustering. <em>TKDE</em>, <em>37</em>(5), 2680-2694. (<a href='https://doi.org/10.1109/TKDE.2025.3543946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series clustering poses a significant challenge with diverse applications across domains. A prominent drawback of existing solutions lies in their limited interpretability, often confined to presenting users with centroids. In addressing this gap, our work presents $k$-Graph, an unsupervised method explicitly crafted to augment interpretability in time series clustering. Leveraging a graph representation of time series subsequences, $k$-Graph constructs multiple graph representations based on different subsequence lengths. This feature accommodates variable-length time series without requiring users to predetermine subsequence lengths. Our experimental results reveal that $k$-Graph outperforms current state-of-the-art time series clustering algorithms in accuracy, while providing users with meaningful explanations and interpretations of the clustering outcomes.},
  archive      = {J_TKDE},
  author       = {Paul Boniol and Donato Tiano and Angela Bonifati and Themis Palpanas},
  doi          = {10.1109/TKDE.2025.3543946},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2680-2694},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {-graph: A graph embedding for interpretable time series clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intent propagation contrastive collaborative filtering. <em>TKDE</em>, <em>37</em>(5), 2665-2679. (<a href='https://doi.org/10.1109/TKDE.2025.3543241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disentanglement techniques used in collaborative filtering uncover interaction intents between nodes, improving the interpretability of node representations and enhancing recommendation performance. However, existing disentanglement methods still face the following two problems. 1) They focus on local structural features derived from direct node interactions, overlooking the comprehensive graph structure, which limits disentanglement accuracy. 2) The disentanglement process depends on backpropagation signals derived from recommendation tasks, lacking direct supervision, which may lead to biases and overfitting. To address the issues, we propose the Intent Propagation Contrastive Collaborative Filtering (IPCCF) algorithm. Specifically, we design a double helix message propagation framework to more effectively extract the deep semantic information of nodes, thereby improving the model's understanding of interactions between nodes. An intent message propagation method is also developed that incorporates graph structure information into the disentanglement process, thereby expanding the consideration scope of disentanglement. In addition, contrastive learning techniques are employed to align node representations derived from the structure and intents, providing direct supervision for the disentanglement process, mitigating biases, and enhancing the model's robustness to overfitting. The experiments on three real data graphs illustrate the superiority of the proposed approach.},
  archive      = {J_TKDE},
  author       = {Haojie Li and Junwei Du and Guanfeng Liu and Feng Jiang and Yan Wang and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2025.3543241},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2665-2679},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Intent propagation contrastive collaborative filtering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving sequential recommendations via bidirectional temporal data augmentation with pre-training. <em>TKDE</em>, <em>37</em>(5), 2652-2664. (<a href='https://doi.org/10.1109/TKDE.2025.3546035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation systems are integral to discerning temporal user preferences. Yet, the task of learning from abbreviated user interaction sequences poses a notable challenge. Data augmentation has been identified as a potent strategy to enhance the informational richness of these sequences. Traditional augmentation techniques, such as item randomization, may disrupt the inherent temporal dynamics. Although recent advancements in reverse chronological pseudo-item generation have shown promise, they can introduce temporal discrepancies when assessed in a natural chronological context. In response, we introduce a sophisticated approach, Bidirectional temporal data Augmentation with pre-training (BARec). Our approach leverages bidirectional temporal augmentation and knowledge-enhanced fine-tuning to synthesize authentic pseudo-prior items that retain user preferences and capture deeper item semantic correlations, thus boosting the model’s expressive power. Our comprehensive experimental analysis on five benchmark datasets confirms the superiority of BARec across both short and elongated sequence contexts. Moreover, theoretical examination and case study offer further insight into the model’s logical processes and interpretability.},
  archive      = {J_TKDE},
  author       = {Juyong Jiang and Peiyan Zhang and Yingtao Luo and Chaozhuo Li and Jae Boum Kim and Kai Zhang and Senzhang Wang and Sunghun Kim and Philip S. Yu},
  doi          = {10.1109/TKDE.2025.3546035},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2652-2664},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Improving sequential recommendations via bidirectional temporal data augmentation with pre-training},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph collaborative filtering with adaptive augmentation of graph data for recommendation. <em>TKDE</em>, <em>37</em>(5), 2640-2651. (<a href='https://doi.org/10.1109/TKDE.2025.3539769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised tasks show significant advantages for node representation learning in recommender systems. This core idea of self-supervised task-based recommender systems depends on data augmentation to generate multi-view representations. However, there are two key challenges that are not well explored in existing self-supervised tasks: i) Restricted by the structure of the graph-based CF paradigm itself, the classical graph comparison learning architecture ignores the global structural information on the user-item interaction graph. ii) In a key part of existing contrast learning-random graph data enhancement schemes can significantly deteriorate model performance. To address these challenges, we propose a new hypergraph collaborative filtering with adaptive augmentation framework(HCFAA). It captures both local and global collaborative relationships on the user-item graph through a hypergraph-enhanced joint learning architecture. In particular, the designed adaptive structure-guided model ignores the noise introduced on unimportant edges, and thus learns the critical node information on the user-item graph. Comprehensive experimental studies on the Amazon dataset show that the method is effective, which provides an optimization scheme with a new perspective for the problems of key node loss in graph data enhancement and loss of higher-order structural information in GNN. The source code of our model can be available on https://github.com/RSnewbie/RS/tree/master/HCFAA.},
  archive      = {J_TKDE},
  author       = {Jian Wang and Jianrong Wang and Di Jin and Xinglong Chang},
  doi          = {10.1109/TKDE.2025.3539769},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2640-2651},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hypergraph collaborative filtering with adaptive augmentation of graph data for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical causal discovery from large-scale observed variables. <em>TKDE</em>, <em>37</em>(5), 2626-2639. (<a href='https://doi.org/10.1109/TKDE.2025.3539788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a long-standing question to discover causal relations from observed variables in many empirical sciences. However, current causal discovery methods are inefficient when dealing with large-scale observed variables due to challenges in conditional independence (CI) tests or complex computations of acyclicity, and may even fail altogether. To address the efficiency issue in causal discovery from large-scale observed variables, we propose a Hierarchical Causal Discovery (HCD) framework with a bilevel policy that handles this issue by boosting existing models. Specifically, the high-level policy first finds a causal cut set to partition observed variables into several causal clusters and releases the clusters to the low-level policy. The low-level policy applies any causal discovery method to process these causal clusters in parallel and obtain intra-cluster structures for subsequently inter-cluster structure merging in the high-level policy. To avoid missing inter-cluster edges, we theoretically demonstrate the feasibility of causal cluster cut and inter-cluster structure merging. We also prove the completeness and correctness of HCD for causal discovery. Experiments on both synthetic and real-world datasets demonstrate that HCD consistently and significantly enhances the efficiency and effectiveness of existing advanced methods.},
  archive      = {J_TKDE},
  author       = {Rujia Shen and Muhan Li and Chao Zhao and Boran Wang and Yi Guan and Jie Liu and Jingchi Jiang},
  doi          = {10.1109/TKDE.2025.3539788},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2626-2639},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical causal discovery from large-scale observed variables},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group-aware dynamic graph representation learning for next POI recommendation. <em>TKDE</em>, <em>37</em>(5), 2614-2625. (<a href='https://doi.org/10.1109/TKDE.2025.3538005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Next POI recommendation, which has attracted many attentions recently, is a complex study due to the sparsity of check-in data and numerous sequential patterns. The recent methods based on sequential modeling have shown promising applicability for this task. However, most of existing next POI recommendation researches only model users’ preferences based on their own sequences and ignore the influence of partners who visit POI with the target user and may change with time. Inspired by dynamic Graph neural networks, we propose a Group-aware Dynamic Graph Representation Learning (GDGRL) method for next POI recommendation. GDGRL connects different user sequences and specific partners via dynamic graph structure, which contains interactions between users and POIs as well as influence of partners. The users’ dynamic preferences are learned from group-aware dynamic graph and context-aware dynamic graph through dynamic graph neural networks. Finally, the next POI recommendation task is transformed into a link prediction between user node and POI node in the dynamic graph. Extensive experiments on two real-world datasets show that GDGRL outperforms several state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Ruichang Li and Xiangwu Meng and Yujie Zhang},
  doi          = {10.1109/TKDE.2025.3538005},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2614-2625},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Group-aware dynamic graph representation learning for next POI recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph clustering with harmonic-maxmin cut guidance. <em>TKDE</em>, <em>37</em>(5), 2600-2613. (<a href='https://doi.org/10.1109/TKDE.2025.3542839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering has become a crucial technique for uncovering community structures in complex network data. However, existing approaches often introduce cumbersome regularization or constraints (hyperparameter tuning burden) to obtain balanced clustering results, thereby increasing hyperparameter tuning requirements and intermediate variables. These limitations can lead to suboptimal performance, particularly in scenarios involving imbalanced clusters or large-scale datasets. Besides, most graph cut clustering methods solve two separate discrete problems, resulting in information loss and relying on time-consuming eigen-decomposition. To address these challenges, this paper propose an effective graph cut framework, termed Harmonic MaxMin Cut (HMMC), inspired by worst-case objective optimization and the harmonic mean. Unlike traditional spectral clustering, HMMC produces all cluster assignments in a single step, eliminating the need for additional discretization and notably enhancing robustness to “worst-case cluster” boundaries. this paper further devise a fast coordinate descent (CD) solver that scales linearly complexity with the graph size, offering a computationally efficient alternative to eigen decomposition. Extensive experiments on real-world datasets demonstrate that HMMC is comparable to, or even surpasses, state-of-the-art methods, while also finding more favorable local solutions than non-negative matrix factorization techniques.},
  archive      = {J_TKDE},
  author       = {Jingwei Chen and Zihan Wu and Jingqing Cheng and Xiaohua Xu and Feiping Nie},
  doi          = {10.1109/TKDE.2025.3542839},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2600-2613},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph clustering with harmonic-maxmin cut guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-hop-constrained $s$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math>-$t$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math> path graphs. <em>TKDE</em>, <em>37</em>(5), 2584-2599. (<a href='https://doi.org/10.1109/TKDE.2025.3532318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study two different problems that investigate relations between given vertices $s$ and $t$. The first problem is to generate the $k$-hop-constrained $s$-$t$ path graph, i.e., the subgraph consisting of all paths from $s$ to $t$, where each path is not longer than $k$ s.t. $s$ and $t$ appear only once. To solve the first problem, we propose the A-BiBFS$^{++}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math> method enhanced with the reduced neighbor index and an approximate vertex grouping strategy. The second problem is to generate the $k$-hop-constrained $s$-$t$ simple path graph, i.e., the subgraph consisting of all $k$-hop-constrained simple paths from $s$ to $t$, which is proved to be NP-hard on directed graphs. Based on A-BiBFS$^{++}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math>, we propose the EVE method to tackle the second problem, which exploits the paradigm of edge-wise examination rather than exhaustively enumerating all simple paths. Extensive experiments show that both A-BiBFS$^{++}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math> and EVE significantly outperform all baselines. Moreover, by taking EVE as a built-in block, state-of-the-art for hop-constrained simple path enumeration can be accelerated by up to an order of magnitude.},
  archive      = {J_TKDE},
  author       = {Yuzheng Cai and Siyuan Liu and Weiguo Zheng and Xuemin Lin and Chengbo Zhang and Xuecang Zhang},
  doi          = {10.1109/TKDE.2025.3532318},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2584-2599},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Generating $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-hop-constrained $s$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>s</mml:mi></mml:math>-$t$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math> path graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAFExplainer: Global view explanation of graph neural networks through attribute augmentation and fusion embedding. <em>TKDE</em>, <em>37</em>(5), 2569-2583. (<a href='https://doi.org/10.1109/TKDE.2025.3539989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The excellent performance of graph neural networks (GNNs), which learn node representations by aggregating their neighborhood information, led to their use in various graph tasks. However, GNNs are black box models, the prediction results of which are difficult to understand directly. Although node attributes are vital for making predictions, previous studies have ignored their importance for explanation. This study presents GAFExplainer, a novel GNN explainer that emphasizes node attributes via attribute augmentation and fusion embedding. The former enhances node attribute encoding for more expressive masks, while the latter preserves the discrimination of node representations across different layers. Together, these modules significantly improve explanation performance. By training the explanatory network, a global view explanation of GNN models is obtained, and reasonably explainable subgraphs are available for new graphs, thus rendering the model well-generalizable. Multiple sets of experimental results on real and synthetic datasets demonstrate that the proposed model provides valid and accurate explanations. In the visual analysis, the explanations obtained by the proposed model are more comprehensible than those in existing work. Further, the fidelity evaluation and efficiency comparison reveal that with an average performance improvement of 8.9$\% $ compared with representative baselines, GAFExplainer achieves the best fidelity metrics while maintaining computational efficiency.},
  archive      = {J_TKDE},
  author       = {Wenya Hu and Jia Wu and Quan Qian},
  doi          = {10.1109/TKDE.2025.3539989},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2569-2583},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GAFExplainer: Global view explanation of graph neural networks through attribute augmentation and fusion embedding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From pixels to insights: A survey on automatic chart understanding in the era of large foundation models. <em>TKDE</em>, <em>37</em>(5), 2550-2568. (<a href='https://doi.org/10.1109/TKDE.2024.3513320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data visualization in the form of charts plays a pivotal role in data analysis, offering critical insights and aiding in informed decision-making. Automatic chart understanding has witnessed significant advancements with the rise of large foundation models in recent years. Foundation models, such as large language models, have revolutionized various natural language processing tasks and are increasingly being applied to chart understanding tasks. This survey paper provides a comprehensive overview of the recent developments, challenges, and future directions in chart understanding within the context of these foundation models. We review fundamental building blocks crucial for studying chart understanding tasks. Additionally, we explore various tasks and their evaluation metrics and sources of both charts and textual inputs. Various modeling strategies are then examined, encompassing both classification-based and generation-based approaches, along with tool augmentation techniques that enhance chart understanding performance. Furthermore, we discuss the state-of-the-art performance of each task and discuss how we can improve the performance. Challenges and future directions are addressed, highlighting the importance of several topics, such as domain-specific charts, lack of efforts in developing evaluation metrics, and agent-oriented settings. This survey paper aims to provide valuable insights and directions for future research in chart understanding leveraging large foundation models.},
  archive      = {J_TKDE},
  author       = {Kung-Hsiang Huang and Hou Pong Chan and May Fung and Haoyi Qiu and Mingyang Zhou and Shafiq Joty and Shih-Fu Chang and Heng Ji},
  doi          = {10.1109/TKDE.2024.3513320},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2550-2568},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {From pixels to insights: A survey on automatic chart understanding in the era of large foundation models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding rule-interpretable non-negative data representation. <em>TKDE</em>, <em>37</em>(5), 2538-2549. (<a href='https://doi.org/10.1109/TKDE.2025.3538327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative Matrix Factorization (NMF) is an intensively used technique for obtaining parts-based, lower dimensional and non-negative representation. Researchers in biology, medicine, pharmacy and other fields often prefer NMF over other dimensionality reduction approaches (such as PCA) because the non-negativity of the approach naturally fits the characteristics of the domain problem and its results are easier to analyze and understand. Despite these advantages, obtaining exact characterization and interpretation of the NMF’s latent factors can still be difficult due to their numerical nature. Rule-based approaches, such as rule mining, conceptual clustering, subgroup discovery and redescription mining, are often considered more interpretable but lack lower-dimensional representation of the data. We present a version of the NMF approach that merges rule-based descriptions with advantages of part-based representation offered by the NMF. Given the numerical input data with non-negative entries and a set of rules with high entity coverage, the approach creates the lower-dimensional non-negative representation of the input data in such a way that its factors are described by the appropriate subset of the input rules. In addition to revealing important attributes for latent factors, their interaction and value ranges, this approach allows performing focused embedding potentially using multiple overlapping target labels.},
  archive      = {J_TKDE},
  author       = {Matej Mihelčić and Pauli Miettinen},
  doi          = {10.1109/TKDE.2025.3538327},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2538-2549},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Finding rule-interpretable non-negative data representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot knowledge graph completion with star and ring topology information aggregation. <em>TKDE</em>, <em>37</em>(5), 2525-2537. (<a href='https://doi.org/10.1109/TKDE.2025.3544202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot knowledge graph completion (FKGC) addresses the long-tail problem of relations by leveraging a few observed support entity pairs to infer unknown facts for tail-located relations. Learning the relation representation of entity pairs and evaluating the match of query and support entity pairs are the two key steps of FKGC. Existing methods learn the representation of entity pairs by either aggregating neighbors of entities or integrating relation representations in the connected paths from head to tail. However, in few-shot scenarios, the limited number of support entity pairs and insufficient structural information with a single neighborhood topology will lead to matching failure. To this end, we consider the star and ring topological information for a given entity pair: (1) Entity neighborhood, which captures multi-hop neighbors of entities; (2) Relational path, which characterizes compound relation forms. Furthermore, to effectively fuse the two kinds of heterogeneous topological information, we design the multi-aggregator and the fine-grained path correlation matching algorithm to obtain more delicate and balanced matching. Based on the proposed relational path correlation matching module, we propose the relation adaptive network to solve the few-shot temporal knowledge graph completion problem. The experimental results show that our method continuously outperforms the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Jing Zhao and Xinzhu Zhang and Yujia Li and Shiliang Sun},
  doi          = {10.1109/TKDE.2025.3544202},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2525-2537},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Few-shot knowledge graph completion with star and ring topology information aggregation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating multi-label expected accuracy using labelset distributions. <em>TKDE</em>, <em>37</em>(5), 2513-2524. (<a href='https://doi.org/10.1109/TKDE.2025.3545972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-label classifier estimates the binary label state (relevant/irrelevant) for each of a set of concept labels, for a given instance. Probabilistic multi-label classifiers provide a distribution over all possible labelset combinations of such label states (the powerset of labels), from which we can provide the best estimate by selecting the labelset corresponding to the largest expected accuracy. Providing confidence for predictions is important for real-world application of multi-label models, which provides the practitioner with a sense of the correctness of the prediction. It has been thought that the probability of the chosen labelset is a good measure of the confidence of the prediction, but multi-label accuracy can be measured in many ways and so confidence should align with the expected accuracy of the evaluation method. In this article, we investigate the effectiveness of seven candidate functions for estimating multi-label expected accuracy conditioned on the labelset distribution and the evaluation method. We found most correlate to expected accuracy and have varying levels of robustness. Further, we found that the candidate functions provide high expected accuracy estimates for Hamming similarity, but a combination of the candidates provided an accurate estimate of expected accuracy for Jaccard index and Exact match.},
  archive      = {J_TKDE},
  author       = {Laurence A. F. Park and Jesse Read},
  doi          = {10.1109/TKDE.2025.3545972},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2513-2524},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Estimating multi-label expected accuracy using labelset distributions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing attribute-driven fraud detection with risk-aware graph representation. <em>TKDE</em>, <em>37</em>(5), 2501-2512. (<a href='https://doi.org/10.1109/TKDE.2025.3543887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud is a severe issue that causes significant losses for both cardholders and issuing banks. Existing methods utilize machine learning-based classifiers to identify fraudulent transactions from labeled transaction records. However, labeled data are often scarce compared to the billions of real transactions due to the high cost of annotation, which means that previous methods do not fully utilize the rich features of unlabeled data. What’s more, contemporary methods succumb to a fallacy of unawareness of the local risk structure and the inability to capture certain risk patterns. Therefore, we propose the Risk-aware Gated Temporal Attention Network (RGTAN) for fraud detection in this work. Specifically, we first build a temporal transaction graph based on the transaction records, which consists of temporal transactions (nodes) and their interactions (edges). Then we leverage a Gated Temporal Graph Attention (GTGA) Mechanism to propagate messages among the nodes and learn adaptive representations of transactions. We also model the fraud patterns through risk propagation, taking advantage of the relations among transactions. More importantly, we devise a neighbor risk-aware representation learning layer to enhance our method’s perception of multi-hop risk structures. We conduct extensive experiments on a real-world credit card transaction dataset and two public fraud detection datasets. The results show that our proposed method, RGTAN, outperforms other state-of-the-art methods on three fraud detection datasets. The risk-aware semi-supervised experiments also demonstrate the excellent performance of our model with only a small fraction of manually labeled data. Moreover, RGTAN has been deployed in a world-leading credit card issuer for credit card fraud detection, and the case study results show the effectiveness of our method in uncovering real-world fraud patterns.},
  archive      = {J_TKDE},
  author       = {Sheng Xiang and Guibin Zhang and Dawei Cheng and Ying Zhang},
  doi          = {10.1109/TKDE.2025.3543887},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2501-2512},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing attribute-driven fraud detection with risk-aware graph representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient PMU data compression using enhanced graph filtering enabled principal component analysis. <em>TKDE</em>, <em>37</em>(5), 2488-2500. (<a href='https://doi.org/10.1109/TKDE.2025.3544768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phasor Measurement Units (PMUs) are state-of-the-art measuring devices that capture high-resolution time-synchronized voltage and current phasor measurements in wide area monitoring systems (WAMS). Their usage for various real-time applications demands a huge amount of data collected from multiple PMUs to be transmitted from the local phasor data concentrator (PDC) to the control centre. To optimize the requirements of bandwidth to transmit the data as well as to store the data, an efficient synchrophasor data compression technique is desired. To this end, this paper presents a 3-stage data compression scheme in which Stage-1 performs the accumulation of the data matrix from the optimally placed PMUs in WAMS into the local PDC. The data is then passed through a novel Ramanujan's sum-based fault window detection algorithm to identify the fault within the PMU data matrix in Stage-2. Finally, Stage-3 proposes an enhanced graph filtering-enabled principal component analysis scheme which expands the notion of conventional PCA techniques into the graph domain to compress the data. The performance of the proposed scheme is verified on the IEEE 14-bus system and New England 39-bus system. Further, practical applicability of the proposed method is validated on field PMU data collected from EPFL campus in Switzerland.},
  archive      = {J_TKDE},
  author       = {Manish Pandit and Ranjana Sodhi},
  doi          = {10.1109/TKDE.2025.3544768},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2488-2500},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient PMU data compression using enhanced graph filtering enabled principal component analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and accurate spatial queries using lossy compressed 3D geometry data. <em>TKDE</em>, <em>37</em>(5), 2472-2487. (<a href='https://doi.org/10.1109/TKDE.2025.3539729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D spatial data management is increasingly vital across various application scenarios, such as GIS, digital twins, human atlases, and tissue imaging. However, the inherent complexity of 3D spatial data, primarily represented by 3D geometries in real-world applications, hinders the efficient evaluation of spatial relationships through resource-intensive geometric computations. Geometric simplification algorithms have been developed to reduce the complexity of 3D representations, albeit at the cost of querying accuracy. Previous work has aimed to address precision loss by leveraging the spatial relationship between the simplified and original 3D object representations. However, this approach relied on specialized geometric simplification algorithms tailored to regions with specific criteria. In this paper, we introduce a novel approach to achieve highly efficient and accurate 3D spatial queries, incorporating geometric computation and simplification. We present a generalized progressive refinement methodology applicable to general geometric simplification algorithms, involving accurate querying of 3D geometry data using low-resolution representations and simplification extents quantified using Hausdorff distances at the facet level. Additionally, we propose techniques for calculating and storing Hausdorff distances efficiently. Extensive experimental evaluations validate the effectiveness of the proposed method which outperforms state-of-the-art systems by a factor of 4 while minimizing computational and storage overhead.},
  archive      = {J_TKDE},
  author       = {Dejun Teng and Zhaochuan Li and Zhaohui Peng and Shuai Ma and Fusheng Wang},
  doi          = {10.1109/TKDE.2025.3539729},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2472-2487},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient and accurate spatial queries using lossy compressed 3D geometry data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic ensemble framework for imbalanced data classification. <em>TKDE</em>, <em>37</em>(5), 2456-2471. (<a href='https://doi.org/10.1109/TKDE.2025.3528719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic ensemble has significantly greater potential space to improve the classification of imbalanced data compared to static ensemble. However, dynamic ensemble schemes are far less successful than static ensemble methods in the imbalanced learning field. Through an in-depth analysis on the behavior characteristics of dynamic ensemble, we find that there are some important problems that need to be addressed to release the full potential of dynamic ensemble, including but not limited to, correcting the component classifiers’ bias towards the majority classes, increasing the proportions of the positive classifiers (i.e., the component classifiers making correct prediction) for difficult samples, and providing the accurate competence estimations on the hard-to-classify samples w.r.t the classifier pool. Inspired by these, we propose a Dynamic Ensemble Framework for imbalanced data classification (imDEF). imDEF first uses the data generation method OREM$\mathrm{_{G}}$ to generate multiple artificial synthetic datasets, which have diverse class distributions by rebalancing the original imbalanced data. Based on each of such synthetic datasets, imDEF then utilizes a Classification Error-aware Self-Paced Sampling Ensemble (SPSE$\mathrm{_{CE}}$) method to gradually focus more on difficult samples, to create a low-biased classifier pool and increase the proportions of the positive classifiers for the difficult samples. Finally, imDEF constructs a referee system to achieve the competence estimations by leveraging an Ensemble Margin-aware Self-Paced Sampling Ensemble (SPSE$\mathrm{_{EM}}$) method. SPSE$\mathrm{_{EM}}$ incrementally strengthens the learning of the hard-to-classify samples, so that the competent levels of component classifiers could be estimated accurately. Extensive experiments demonstrate the effectiveness of imDEF. The source codes have been made publicly available on GitHub.},
  archive      = {J_TKDE},
  author       = {Tuanfei Zhu and Xingchen Hu and Xinwang Liu and En Zhu and Xinzhong Zhu and Huiying Xu},
  doi          = {10.1109/TKDE.2025.3528719},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2456-2471},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dynamic ensemble framework for imbalanced data classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-state personalized knowledge tracing with emotional incorporation. <em>TKDE</em>, <em>37</em>(5), 2440-2455. (<a href='https://doi.org/10.1109/TKDE.2025.3538121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing has been widely used in online learning systems to guide the students’ future learning. However, most existing KT models primarily focus on extracting abundant information from the question sets and explore the relationships between them, but ignore the personalized student behavioral information in the learning process. This will limit the model’s ability to accurately capture the personalized knowledge states of students and reasonably predict their performances. To alleviate this limitation, we explicitly models the personalized learning process by incorporating the emotions, a representative personalized behavior in the learning process, into KT framework. Specifically, we present a novel Dual-State Personalized Knowledge Tracing with Emotional Incorporation model to achieve this goal: First, we incorporate emotional information into the modeling process of knowledge state, resulting in the Knowledge State Boosting Module. Second, we design an Emotional State Tracing Module to monitor students’ personalized emotional states, and propose an emotion prediction method based on personalized emotional states. Finally, we apply the predicted emotions to enhance students’ response prediction. Furthermore, to extend the generalization capability of our model across different datasets, we design a transferred version of DEKT, named Transfer Learning-based Self-loop model (T-DEKT). Extensive experiments show our method achieves the state-of-the-art performance.},
  archive      = {J_TKDE},
  author       = {Shanshan Wang and Fangzheng Yuan and Keyang Wang and Xun Yang and Xingyi Zhang and Meng Wang},
  doi          = {10.1109/TKDE.2025.3538121},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2440-2455},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dual-state personalized knowledge tracing with emotional incorporation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Doing more with less: A survey of data selection methods for mathematical modeling. <em>TKDE</em>, <em>37</em>(5), 2420-2439. (<a href='https://doi.org/10.1109/TKDE.2025.3545965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data applications such as Artificial Intelligence (AI) and Internet of Things (IoT) have in recent years been leading to many technological breakthroughs in system modeling. However, these applications are typically data intensive, thus requiring an increasing cost of resources. In this paper, a first-of-its-kind comprehensive review of data selection methods across different engineering disciplines is given in order to analyze the effectiveness of these methods in improving the data efficiency of mathematical modeling algorithms. Eight distinct selection methods have been identified and subsequently analyzed and discussed on the basis of the relevant literature. In addition, the selection methods have been classified according to three dichotomies established by the survey. A comparative analysis of these methods was conducted along with a discussion of potentials, challenges, and future research directions for the research area. Data selection was found to be widely used in many engineering applications and has the potential to play an important role in making more sustainable Big Data applications, especially those in which transmission of data across large distances is required. Furthermore, making resource-aware decisions about the use of data has been shown to be highly effective in reducing energy costs while ensuring high performance of the model.},
  archive      = {J_TKDE},
  author       = {Nicolai A. Weinreich and Arman Oshnoei and Remus Teodorescu and Kim G. Larsen},
  doi          = {10.1109/TKDE.2025.3545965},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2420-2439},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Doing more with less: A survey of data selection methods for mathematical modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do as i can, not as i get: Topology-aware multi-hop reasoning on multi-modal knowledge graphs. <em>TKDE</em>, <em>37</em>(5), 2405-2419. (<a href='https://doi.org/10.1109/TKDE.2025.3546686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-modal knowledge graph (MKG) includes triplets that consist of entities and relations and multi-modal auxiliary data. In recent years, multi-hop multi-modal knowledge graph reasoning (MMKGR) based on reinforcement learning (RL) has received extensive attention because it addresses the intrinsic incompleteness of MKG in an interpretable manner. However, its performance is limited by empirically designed rewards and sparse relations. In addition, this method has been designed for the transductive setting where test entities have been seen during training, and it works poorly in the inductive setting where test entities do not appear in the training set. To overcome these issues, we propose TMR (Topology-aware Multi-hop Reasoning), which can conduct MKG reasoning under inductive and transductive settings. Specifically, TMR mainly consists of two components. (1) The topology-aware inductive representation captures information from the directed relations of unseen entities, and aggregates query-related topology features in an attentive manner to generate the fine-grained entity-independent features. (2) After completing multi-modal feature fusion, the relation-augmented adaptive RL conducts multi-hop reasoning by eliminating manual rewards and dynamically adding actions. Finally, we construct new MKG datasets with different scales for inductive reasoning evaluation. Experimental results demonstrate that TMP outperforms state-of-the-art MKGR methods under both inductive and transductive settings.},
  archive      = {J_TKDE},
  author       = {Shangfei Zheng and Hongzhi Yin and Tong Chen and Quoc Viet Hung Nguyen and Wei Chen and Lei Zhao},
  doi          = {10.1109/TKDE.2025.3546686},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2405-2419},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Do as i can, not as i get: Topology-aware multi-hop reasoning on multi-modal knowledge graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-promoting recommendation with dual-objective optimization and dual consideration. <em>TKDE</em>, <em>37</em>(5), 2391-2404. (<a href='https://doi.org/10.1109/TKDE.2025.3543285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diversifying recommendations to broaden user horizons and explore potential interests has become a prominent research area in recommender systems. Although numerous efforts have been made to enhance diverse recommendations, the trade-off between diversity and accuracy remains a significant challenge. The primary causes lie in the following two aspects: (i) the inherent goals of diversity-promoting recommendation, which are to simultaneously deliver accurate recommendations and cater to a broader spectrum of users’ interests, have not been adequately explored; and (ii) considering diversity only in the model training procedure cannot guarantee the provision of diversification services in recommender systems. In this work, we directly formulate the inherent goals of diversity-promoting recommendation as a dual-objective optimization problem by simultaneously minimizing the recommendation error and maximizing diversity. These proposed objectives are integrated into Generative Adversarial Nets (GANs) to guide the training process toward the orientation of boosting both diversification and accuracy. Additionally, we propose considering diversity in both training and serving phases. Experimental results demonstrate that our model outperforms others in both diversity and relevance. We extend DDPR to state-of-the-art CTR and re-ranking models, which also result in improved performance on these tasks, further demonstrating the applicability of our model in real-world scenarios.},
  archive      = {J_TKDE},
  author       = {Yuli Liu and Yuan Zhang},
  doi          = {10.1109/TKDE.2025.3543285},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2391-2404},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Diversity-promoting recommendation with dual-objective optimization and dual consideration},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovery of temporal network motifs. <em>TKDE</em>, <em>37</em>(5), 2376-2390. (<a href='https://doi.org/10.1109/TKDE.2025.3538514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network motifs provide a deep insight into the network functional abilities, and have proven useful in various practical applications. Existing studies reveal that different definitions of motifs may be needed for different temporal networks. In this study, we focus on a class of temporal networks such that the nodes and edges keep fixed, but the edge labels vary regularly with timestamps. First, we propose a proper definition of temporal motifs, which appear continuously within sufficiently large time intervals, to properly reinterpret the recurrent and statistically significant nature of motifs in temporal networks. Second, we develop a low polynomial time solution to find temporal motifs for all possible time intervals with the top to bottom and right to left scheme, based on the analyses of the properties for temporal motifs. Third, we develop a theoretically faster incremental solution to efficiently find temporal motifs to support continuously updates of temporal networks, by identifying unaffected time intervals and unnecessary edges. Finally, we have conducted extensive experiments to verify the efficiency and usefulness of our static and incremental solutions.},
  archive      = {J_TKDE},
  author       = {Hanqing Chen and Shuai Ma and Junfeng Liu and Lizhen Cui},
  doi          = {10.1109/TKDE.2025.3538514},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2376-2390},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discovery of temporal network motifs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data optimization in deep learning: A survey. <em>TKDE</em>, <em>37</em>(5), 2356-2375. (<a href='https://doi.org/10.1109/TKDE.2025.3530916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale, high-quality data are considered an essential factor for the successful application of many deep learning techniques. Meanwhile, numerous real-world deep learning tasks still have to contend with the lack of sufficient amounts of high-quality data. Additionally, issues such as model robustness, fairness, and trustworthiness are also closely related to training data. Consequently, a huge number of studies in the existing literature have focused on the data aspect in deep learning tasks. Some typical data optimization techniques include data augmentation, logit perturbation, sample weighting, and data condensation. These techniques usually come from different deep learning divisions and their theoretical inspirations or heuristic motivations may seem unrelated to each other. This study aims to organize a wide range of existing data optimization methodologies for deep learning from the previous literature, and makes the effort to construct a comprehensive taxonomy for them. The constructed taxonomy considers the diversity of split dimensions, and deep sub-taxonomies are constructed for each dimension. On the basis of the taxonomy, connections among the extensive data optimization methods for deep learning are built in terms of five aspects. We probe into rendering several promising and interesting future directions. The constructed taxonomy and the revealed connections will enlighten the better understanding of existing methods and the design of novel data optimization techniques. Furthermore, our aspiration for this survey is to promote data optimization as an independent subdivision of deep learning.},
  archive      = {J_TKDE},
  author       = {Ou Wu and Rujing Yao},
  doi          = {10.1109/TKDE.2025.3530916},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2356-2375},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Data optimization in deep learning: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-graph interaction networks. <em>TKDE</em>, <em>37</em>(5), 2341-2355. (<a href='https://doi.org/10.1109/TKDE.2025.3543377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are recognized as a significant methodology for handling graph-structure data. However, with the increasing prevalence of learning scenarios involving multiple graphs, traditional GNNs mostly overlook the relationships between nodes across different graphs, mainly due to their limitation of traditional message passing within each graph. In this paper, we propose a novel GNN architecture called cross-graph interaction networks (GInterNet) to enable inter-graph message passing. Specifically, we develop a cross-graph topology construction module to uncover and learn the potential topologies between nodes across different graphs. Furthermore, we establish inter-graph message passing based on the learned cross-graph topologies, achieving cross-graph interaction by aggregating information from different graphs. Finally, we employ cross-graph construction functions involving the relationships between contextual information and cross-graph topology structure to iteratively update the cross-graph topologies. Different to existing related approaches, GInterNet is designed as a cross-graph interaction paradigm for inter-graph message passing. It enables multi-graph interaction during the message passing process. Additionally, it is a plug-and-play framework that can be easily embedded into other models. We evaluate its performance in semi-supervised and unsupervised learning scenarios involving multiple graphs. A detailed theoretical analysis and extensive experiment results have shown that GInterNet improves the performance and robustness of the base models.},
  archive      = {J_TKDE},
  author       = {Qihang Guo and Xibei Yang and Weiping Ding and Yuhua Qian},
  doi          = {10.1109/TKDE.2025.3543377},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2341-2355},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cross-graph interaction networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoLLM: Integrating collaborative embeddings into large language models for recommendation. <em>TKDE</em>, <em>37</em>(5), 2329-2340. (<a href='https://doi.org/10.1109/TKDE.2025.3540912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging Large Language Models as recommenders, referred to as LLMRec, is gaining traction and brings novel dynamics for modeling user preferences, particularly for cold-start users. However, existing LLMRec approaches primarily focus on text semantics and overlook the crucial aspect of incorporating collaborative information from user-item interactions, leading to potentially sub-optimal performance in warm-start scenarios. To ensure superior recommendations across both warm and cold scenarios, we introduce CoLLM, an innovative LLMRec approach that explicitly integrates collaborative information for recommendations. CoLLM treats collaborative information as a distinct modality, directly encoding it from well-established traditional collaborative models, and then tunes a mapping module to align this collaborative information with the LLM's input text token space for recommendations. By externally integrating traditional models, CoLLM ensures effective collaborative information modeling without modifying the LLM itself, providing the flexibility to adopt diverse collaborative information modeling mechanisms. Extensive experimentation validates that CoLLM adeptly integrates collaborative information into LLMs, resulting in enhanced recommendation performance.},
  archive      = {J_TKDE},
  author       = {Yang Zhang and Fuli Feng and Jizhi Zhang and Keqin Bao and Qifan Wang and Xiangnan He},
  doi          = {10.1109/TKDE.2025.3540912},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2329-2340},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CoLLM: Integrating collaborative embeddings into large language models for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaboratively semantic alignment and metric learning for cross-modal hashing. <em>TKDE</em>, <em>37</em>(5), 2311-2328. (<a href='https://doi.org/10.1109/TKDE.2025.3537704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval is a promising technique nowadays to find semantically similar instances in other modalities while a query instance is given from one modality. However, there still exists many challenges for reducing heterogeneous modality gap by embedding label information to discrete hash codes effectively, solving the binary optimization when generating unified hash codes and reducing the discrepancy of data distribution efficiently during common space learning. In order to overcome the above-mentioned challenges, we propose a Collaboratively Semantic alignment and Metric learning for cross-modal Hashing (CSMH) in this paper. Specifically, by a kernelization operation, CSMH first extracts the non-linear data features for each modality, which are projected into a latent subspace to align both marginal and conditional distributions simultaneously. Then, a maximum mean discrepancy-based metric strategy is customized to mitigate the distribution discrepancies among features from different modalities. Finally, semantic information obtained from the label similarity matrix, is further incorporated to embed the latent semantic structure into the discriminant subspace. Experimental results of CSMH and baseline methods on four widely-used datasets show that CSMH outperforms some state-of-the-art hashing baseline methods for cross-modal retrieval on efficiency and precision.},
  archive      = {J_TKDE},
  author       = {Jiaxing Li and Wai Keung Wong and Lin Jiang and Kaihang Jiang and Xiaozhao Fang and Shengli Xie and Jie Wen},
  doi          = {10.1109/TKDE.2025.3537704},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2311-2328},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Collaboratively semantic alignment and metric learning for cross-modal hashing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMVC+: A multi-view clustering framework for open knowledge base canonicalization via contrastive learning. <em>TKDE</em>, <em>37</em>(5), 2296-2310. (<a href='https://doi.org/10.1109/TKDE.2025.3543423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open information extraction (OIE) methods extract plenty of OIE triples $&lt; $<mml:math><mml:mo>&lt;</mml:mo></mml:math>noun phrase, relation phrase, noun phrase$&gt; $<mml:math><mml:mo>&gt;</mml:mo></mml:math> from unstructured text, which compose large open knowledge bases (OKBs). Noun phrases and relation phrases in such OKBs are not canonicalized, which leads to scattered and redundant facts. It is found that two views of knowledge (i.e., a fact view based on the fact triple and a context view based on the fact triple's source context) provide complementary information that is vital to the task of OKB canonicalization, which clusters synonymous noun phrases and relation phrases into the same group and assigns them unique identifiers. In order to leverage these two views of knowledge jointly, we propose CMVC+, a novel unsupervised framework for canonicalizing OKBs without the need for manually annotated labels. Specifically, we propose a multi-view CHF K-Means clustering algorithm to mutually reinforce the clustering of view-specific embeddings learned from each view by considering the clustering quality in a fine-grained manner. Furthermore, we propose a novel contrastive learning module to refine the learned view-specific embeddings and further enhance the canonicalization performance. We demonstrate the superiority of our framework through extensive experiments on multiple real-world OKB data sets against state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Yang Yang and Wei Shen and Junfeng Shu and Yinan Liu and Edward Curry and Guoliang Li},
  doi          = {10.1109/TKDE.2025.3543423},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2296-2310},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CMVC+: A multi-view clustering framework for open knowledge base canonicalization via contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CGoFed: Constrained gradient optimization strategy for federated class incremental learning. <em>TKDE</em>, <em>37</em>(5), 2282-2295. (<a href='https://doi.org/10.1109/TKDE.2025.3544605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Class Incremental Learning (FCIL) has emerged as a new paradigm due to its applicability in real-world scenarios. In FCIL, clients continuously generate new data with unseen class labels and do not share local data due to privacy restrictions, and each client’s class distribution evolves dynamically and independently. However, existing work still faces two significant challenges. Firstly, current methods lack a better balance between maintaining sound anti-forgetting effects over old data (stability) and ensuring good adaptability for new tasks (plasticity). Secondly, some FCIL methods overlook that the incremental data will also have a non-identical label distribution, leading to poor performance. This paper proposes CGoFed, which includes relax-constrained gradient update and cross-task gradient regularization modules. The relax-constrained gradient update prevents forgetting the knowledge about old data while quickly adapting to the new data by constraining the gradient update direction to a gradient space that minimizes interference with historical tasks. The cross-task gradient regularization also finds applicable historical models from other clients and trains a personalized global model to address the non-identical label distribution problem. The results demonstrate that the CGoFed performs well in alleviating catastrophic forgetting and improves model performance by 8% -23% compared with the SOTA comparison method.},
  archive      = {J_TKDE},
  author       = {Jiyuan Feng and Xu Yang and Liwen Liang and Weihong Han and Binxing Fang and Qing Liao},
  doi          = {10.1109/TKDE.2025.3544605},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2282-2295},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CGoFed: Constrained gradient optimization strategy for federated class incremental learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cafe: Improved federated data imputation by leveraging missing data heterogeneity. <em>TKDE</em>, <em>37</em>(5), 2266-2281. (<a href='https://doi.org/10.1109/TKDE.2025.3537403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), a decentralized machine learning approach, offers great performance while alleviating autonomy and confidentiality concerns. Despite FL’s popularity, how to deal with missing values in a federated manner is not well understood. In this work, we initiate a study of federated imputation of missing values, particularly in complex scenarios, where missing data heterogeneity exists and the state-of-the-art (SOTA) approaches for federated imputation suffer from significant loss in imputation quality. We propose Cafe, a personalized FL approach for missing data imputation. Cafe is inspired from the observation that heterogeneity can induce differences in observable and missing data distribution across clients, and that these differences can be leveraged to improve the imputation quality. Cafe computes personalized weights that are automatically calibrated for the level of heterogeneity, which can remain unknown, to develop personalized imputation models for each client. An extensive empirical evaluation over a variety of settings demonstrates that Cafe matches the performance of SOTA baselines in homogeneous settings while significantly outperforming the baselines in heterogeneous settings.},
  archive      = {J_TKDE},
  author       = {Sitao Min and Hafiz Asif and Xinyue Wang and Jaideep Vaidya},
  doi          = {10.1109/TKDE.2025.3537403},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2266-2281},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cafe: Improved federated data imputation by leveraging missing data heterogeneity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Build a good human-free prompt tuning: Jointly pre-trained template and verbalizer for few-shot classification. <em>TKDE</em>, <em>37</em>(5), 2253-2265. (<a href='https://doi.org/10.1109/TKDE.2025.3543422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt tuning for pre-trained language models (PLMs) has been an effective approach for few-shot text classification. To make a prediction, a typical prompt tuning method employs a template wrapping the input text into a cloze question, and a verbalizer mapping the output embedding to labels. However, current methods typically depend on handcrafted templates and verbalizers, which require much domain-specific prior knowledge by human efforts. In this work, we investigate how to build a good human-free prompt tuning using soft prompt templates and soft verbalizers, which can be learned directly from data. To address the challenge of data scarcity, we integrate a set of trainable bases for sentence representation to transfer the contextual information into a low-dimensional space. By jointly pre-training the soft prompts and the bases using contrastive learning, the projection space can catch critical semantics at the sentence level, which could be transferred to various downstream tasks. To better bridge the gap between downstream tasks and the pre-training procedure, we formulate the few-shot classification tasks as another contrastive learning problem. We name this Jointly Pretrained Template and Verbalizer (JPTV). Extensive experiments show that this human-free prompt tuning can achieve comparable or even better performance than manual prompt tuning.},
  archive      = {J_TKDE},
  author       = {Mouxiang Chen and Han Fu and Chenghao Liu and Xiaoyun Joy Wang and Zhuo Li and Jianling Sun},
  doi          = {10.1109/TKDE.2025.3543422},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2253-2265},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Build a good human-free prompt tuning: Jointly pre-trained template and verbalizer for few-shot classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An amortized o(1) lower bound for dynamic time warping in motif discovery. <em>TKDE</em>, <em>37</em>(5), 2239-2252. (<a href='https://doi.org/10.1109/TKDE.2025.3544751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motif discovery is a critical operation for analyzing series data in many applications. Recent works demonstrate the importance of finding motifs with Dynamic Time Warping. However, existing algorithms spend most of their time in computing lower bounds of Dynamic Time Warping to filter out the unpromising candidates. Specifically, the time complexity for computing these lower bounds is $O(L)$ for each pair of subsequences, where $L$ is the length of the motif (subsequences). This paper proposes two new lower bounds, called $LB_{f}$ and $LB_{M}$, both of them only cost amortized $O(1)$ time for each pair of subsequences. On real datasets, the proposed lower bounds are at least one magnitude faster than the state-of-the-art lower bounds used in motif discovery while still keeping satisfying effectiveness. Based on these faster lower bounds, this paper designs an efficient motif discovery algorithm that significantly reduces the cost of lower bounds. The experiments conducted on real datasets show the proposed algorithm is 5.6 times faster than the state-of-the-art algorithms on average.},
  archive      = {J_TKDE},
  author       = {Zemin Chao and Hong Gao and Dongjing Miao and Jianzhong Li and Hongzhi Wang},
  doi          = {10.1109/TKDE.2025.3544751},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2239-2252},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An amortized o(1) lower bound for dynamic time warping in motif discovery},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive reliable defense graph for multi-channel robust GCN. <em>TKDE</em>, <em>37</em>(5), 2226-2238. (<a href='https://doi.org/10.1109/TKDE.2025.3538645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have demonstrated remarkable success in various graph-related tasks. However, recent studies show that GCNs are vulnerable to adversarial attacks on graph structures. Therefore, how to defend against such attacks has become a popular research topic. The current common defense methods face two main limitations: (1) From the data perspective, it may lead to suboptimal results since the structural information is ignored when distinguishing the perturbed edges. (2) From the model perspective, the defenders rely on the low-pass filter of the GCN, which is vulnerable during message passing. To overcome these limitations, this paper analyzes the characteristics of perturbed edges, and based on this we propose a robust defense framework, REDE, to generate the adaptive Reliable Defense graph for multi-channel robust GCN. REDE first uses feature similarity and structure difference to discriminate perturbed edges and generates the defense graph by pruning them. Then REDE designs a multi-channel GCN, which can separately capture the information of different edges and high-order neighbors utilizing different frequency components. Leveraging this capability, the defense graph is adaptively updated at each layer, enhancing its reliability and improving prediction accuracy. Extensive experiments on four benchmark datasets demonstrate the enhanced performance and robustness of our proposed REDE over the state-of-the-art defense methods.},
  archive      = {J_TKDE},
  author       = {Xiao Zhang and Peng Bao},
  doi          = {10.1109/TKDE.2025.3538645},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2226-2238},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive reliable defense graph for multi-channel robust GCN},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A universal pre-training and prompting framework for general urban spatio-temporal prediction. <em>TKDE</em>, <em>37</em>(5), 2212-2225. (<a href='https://doi.org/10.1109/TKDE.2025.3545948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban spatio-temporal prediction is crucial for informed decision-making, such as traffic management, resource optimization, and emergency response. Despite remarkable breakthroughs in pretrained natural language models that enable one model to handle diverse tasks, a universal solution for spatio-temporal prediction remains challenging. Existing prediction approaches are typically tailored for specific spatio-temporal scenarios, requiring task-specific model designs and extensive domain-specific training data. In this study, we introduce UniST, a universal model designed for general urban spatio-temporal prediction across a wide range of scenarios. Inspired by large language models, UniST achieves success through: (i) utilizing diverse spatio-temporal data from different scenarios, (ii) effective pre-training to capture complex spatio-temporal dynamics, (iii) knowledge-guided prompts to enhance generalization capabilities. These designs together unlock the potential of building a universal model for various scenarios. Extensive experiments on more than 20 spatio-temporal scenarios, including grid-based data and graph-based data, demonstrate UniST’s efficacy in advancing state-of-the-art performance, especially in few-shot and zero-shot prediction.},
  archive      = {J_TKDE},
  author       = {Yuan Yuan and Jingtao Ding and Jie Feng and Depeng Jin and Yong Li},
  doi          = {10.1109/TKDE.2025.3545948},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2212-2225},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A universal pre-training and prompting framework for general urban spatio-temporal prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for bandit online multiclass prediction. <em>TKDE</em>, <em>37</em>(5), 2200-2211. (<a href='https://doi.org/10.1109/TKDE.2024.3458419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bandit online multiclass prediction plays an important role in many real-world applications. In this paper, we propose a unified Bandit Online Multiclass Prediction (BOMP) framework. This framework is based on our proposed margin-based gradient descent approach. Its update step provides an unbiased estimate of the surrogate loss gradient and has a lower variance than existing methods. It also enables our algorithms to update even for incorrect predictions by penalizing the wrong classes. The link function of the framework can evolve over time, gradually incorporating online data information including second-order information into the potential functions. Based on the proposed framework, we investigate first-order and second-order bandit online multiclass prediction algorithms. Theoretical analysis demonstrates the superiority of our proposed update rule and bandit online multiclass prediction framework. Finally, we compare our proposed first-order and second-order bandit online multiclass prediction algorithms with several state-of-the-art methods on two synthetic and four real-world datasets. The encouraging results show that our proposed algorithms significantly outperform state-of-the-art techniques.},
  archive      = {J_TKDE},
  author       = {Wanjin Feng and Xingyu Gao and Peilin Zhao and Steven C.H. Hoi},
  doi          = {10.1109/TKDE.2024.3458419},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2200-2211},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A unified framework for bandit online multiclass prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel expandable borderline smote over-sampling method for class imbalance problem. <em>TKDE</em>, <em>37</em>(5), 2183-2199. (<a href='https://doi.org/10.1109/TKDE.2025.3544284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem can cause classifiers to be biased toward the majority class and inclined to generate incorrect predictions. While existing studies have proposed numerous oversampling methods to alleviate class imbalance by generating extra minority class samples, these methods still have some inherent weaknesses and make the generated samples less informative. This study proposes a novel over-sampling method named the Expandable Borderline Smote (EB-Smote), which can address the weaknesses of existing over-sampling methods and generate more informative synthetic samples. In EB-Smote, not only minority class but also majority class is oversampled, and the synthetic samples are generated in the area between the selected minority and majority samples, which are close to the borderlines of their respective classes. EB-Smote can generate more informative samples by expanding the borderlines of minority and majority classes toward the actual decision boundary. Based on 27 imbalanced datasets and commonly used machine learning models, the experimental results demonstrate that EB-Smote significantly outperforms the other 8 existing oversampling methods. This study can provide theoretical guidance and practical recommendations to solve the crucial class imbalance problem in classification tasks.},
  archive      = {J_TKDE},
  author       = {Hao Sun and Jianping Li and Xiaoqian Zhu},
  doi          = {10.1109/TKDE.2025.3544284},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2183-2199},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel expandable borderline smote over-sampling method for class imbalance problem},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A causal-based attribute selection strategy for conversational recommender systems. <em>TKDE</em>, <em>37</em>(5), 2169-2182. (<a href='https://doi.org/10.1109/TKDE.2025.3543112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational recommender systems (CRSs) provide personalised recommendations by strategically querying attributes matching users’ preferences. However, this process suffers from confounding effects of time and user attributes, as users’ preferences naturally evolve over time and differ among similar users due to their unique attributes. These confounding effects distort user behaviors’ causal drivers, challenging CRSs in learning users’ true preferences and generalizable patterns. Recently, causal inference provides principled tools to clarify cause-effect relations in data, offering a promising way to address such confounding effects. In this context, we introduce Causal Conversational Recommender (CCR), which applies causal inference to model the causality between user behaviors and time/user attribute, enabling deeper understanding of user behaviors’ causal drivers. First, CCR employs stratification and matching to ensure attribute asked per round is independent from time and user attributes, mitigating their confounding effects. Following that, we apply the Average Treatment Effect (ATE) to quantify the unbiased causal impact of each unasked attribute on user preferences, identifying the attribute with the highest ATE per round as the causal-based attribute, i.e., causal driver of user behaviour. Finally, CCR iteratively refines user preferences through feedback on causal-based attributes. Extensive experiments verified CCR's robustness and personalization.},
  archive      = {J_TKDE},
  author       = {Dianer Yu and Qian Li and Xiangmeng Wang and Guandong Xu},
  doi          = {10.1109/TKDE.2025.3543112},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {5},
  number       = {5},
  pages        = {2169-2182},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A causal-based attribute selection strategy for conversational recommender systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards accurate truth discovery with privacy-preserving over crowdsourced data streams. <em>TKDE</em>, <em>37</em>(4), 2155-2168. (<a href='https://doi.org/10.1109/TKDE.2025.3536180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truth discovery endeavors to extract valuable information from multi-source data through weighted aggregation. Some studies have integrated differential privacy techniques into traditional truth discovery algorithms to protect data privacy. However, due to the neglect of outliers and limitations in budget allocation, these schemes still need improvement in the accuracy of discovery results. To solve these challenges, we propose a privacy-preserving scheme called PriPTD to achieve secure and accurate truth discovery services over crowdsourced data streams. Instead of assuming that worker weights are always stable between two neighboring timestamps, we delve deeper to consider outliers where worker weights change rapidly. Accordingly, we develop an outlier-aware weight estimation method with a time series model to capture and handle these outliers. Furthermore, to ensure data utility under a limited budget, we devise a weight-aware budget allocation algorithm. Its core idea is that timestamps with higher importance consume a larger proportion of the remaining budget. Additionally, we design a noise-aware error adjustment approach to mitigate the adverse effects of introduced noise on accuracy. Theoretical analysis and extensive experiments validate our scheme. Final comparative experiments against existing works confirm that our scheme achieves more accurate truth discovery while preserving privacy.},
  archive      = {J_TKDE},
  author       = {Zhimao Gong and Zhibang Yang and Shenghong Yang and Siyang Yu and Kenli Li and Mingxing Duan},
  doi          = {10.1109/TKDE.2025.3536180},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2155-2168},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards accurate truth discovery with privacy-preserving over crowdsourced data streams},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STCDM: Spatio-temporal contrastive diffusion model for check-in sequence generation. <em>TKDE</em>, <em>37</em>(4), 2141-2154. (<a href='https://doi.org/10.1109/TKDE.2025.3525718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and comprehending check-in sequences is crucial for various applications in smart cities. However, publicly available check-in datasets are often limited in scale due to privacy concerns. This poses a significant obstacle to academic research and downstream applications. Thus, it is urgent to generate realistic check-in datasets. The denoising diffusion probabilistic model (DDPM) as one of the most capable generation methods is a good choice to achieve this goal. However, generating check-in sequences using DDPM is not an easy feat. The difficulties lie in handling check-in sequences of variable lengths and capturing the correlation from check-in sequences’ distinct characteristics. This paper addresses the challenges by proposing a Spatio-Temporal Contrastive Diffusion Model (STCDM). This model introduces a novel spatio-temporal lossless encoding method that effectively encodes check-in sequences into a suitable format with equal length. Furthermore, we capture the spatio-temporal correlations with two disentangled diffusion modules to reduce the impact of the difference between spatial and temporal characteristics. Finally, we incorporate contrastive learning to enhance the relationship between diffusion modules. We generate four realistic datasets in different scenarios using STCDM and design four metrics for comparison. Experiments demonstrate that our generated datasets are more realistic and free of privacy leakage.},
  archive      = {J_TKDE},
  author       = {Letian Gong and Shengnan Guo and Yan Lin and Yichen Liu and Erwen Zheng and Yiwei Shuang and Youfang Lin and Jilin Hu and Huaiyu Wan},
  doi          = {10.1109/TKDE.2025.3525718},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2141-2154},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {STCDM: Spatio-temporal contrastive diffusion model for check-in sequence generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal prediction on streaming data: A unified federated continuous learning framework. <em>TKDE</em>, <em>37</em>(4), 2126-2140. (<a href='https://doi.org/10.1109/TKDE.2025.3528876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread deployment of wireless and mobile devices results in a proliferation of decentralized spatio-temporal data. Many recent proposals that target deep learning for spatio-temporal prediction assume that all data is available at a central location and suffers from so-called catastrophic forgetting, where previously learned knowledge is entirely forgotten when new data arrives. Such proposals may face data privacy concerns and may experience deteriorating prediction performance when applied in decentralized settings where data streams into the system. To bridge the gap between decentralized training and spatio-temporal prediction on streaming data, we propose a unified federated continuous learning framework, which uses a horizontal federated learning mechanism for protecting data privacy and includes a global replay buffer with synthetic spatio-temporal data generated by the previously learned global model. For each client, we fuse the current training data with synthetic spatio-temporal data using a spatio-temporal mixup mechanism to preserve historical knowledge effectively, thus avoiding catastrophic forgetting. To enable holistic representation preservation, the local models at clients each integrates a general spatio-temporal autoencoder with a spatio-temporal simple siamese network that aims to ensure prediction accuracy and avoid holistic feature loss. Extensive experiments on real data offer insight into the effectiveness of the proposed framework.},
  archive      = {J_TKDE},
  author       = {Hao Miao and Yan Zhao and Chenjuan Guo and Bin Yang and Kai Zheng and Christian S. Jensen},
  doi          = {10.1109/TKDE.2025.3528876},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2126-2140},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatio-temporal prediction on streaming data: A unified federated continuous learning framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMPCache: Towards more efficient SQL queries in multi-party collaborative data analysis. <em>TKDE</em>, <em>37</em>(4), 2111-2125. (<a href='https://doi.org/10.1109/TKDE.2025.3535944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving collaborative data analysis is a popular research direction in recent years. Among all such analysis tasks, privacy-preserving SQL queries on multi-party databases are of particular industrial interest. Although the privacy concern can be addressed by many cryptographic tools, such as secure multi-party computation (MPC), the efficiency of executing such SQL queries is far from satisfactory, especially for high-volume databases. In particular, existing MPC-based solutions treat each SQL query as an isolated task and launch it from scratch, in spite of the nature that many SQL queries are done regularly and somewhat overlap in their functionalities. In this work, we are motivated to exploit this nature to improve the efficiency of MPC-based, privacy-preserving SQL queries. We introduce a cache-like optimization mechanism. To ensure a higher cache hit rate and reduce redundant MPC operators, we present a cache structure different from that of plain databases and design a set of cache strategies. Our optimization mechanism, SMPCache, can be built upon secret-sharing-based MPC frameworks, which attract much attention from the industry. To demonstrate the utility of SMPCache, we implement it on Rosetta, an open-source MPC library, and use real-world datasets to launch extensive experiments on some basic SQL operators (e.g., Filter, Order-by, Aggregation, and Inner-Join) and some representative composite SQL queries. To give a data point, we note that SMPCache can achieve most up to 3536× efficiency improvement on the TPC-DS dataset and 562× on the TPC-H dataset at a moderate storage cost. We also apply SMPCache to the basic SQL operators (Filter, Order-by, Group-by, Aggregation, and Inner-join) of the Secrecy framework, achieving up to 127.3× efficiency improvement.},
  archive      = {J_TKDE},
  author       = {Junjian Shi and Ye Han and Xiaojie Guo and Zekun Fei and Zheli Liu and Siyi Lv and Tong Li and Xiaotao Liu},
  doi          = {10.1109/TKDE.2025.3535944},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2111-2125},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SMPCache: Towards more efficient SQL queries in multi-party collaborative data analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-learning symmetric multi-view probabilistic clustering. <em>TKDE</em>, <em>37</em>(4), 2097-2110. (<a href='https://doi.org/10.1109/TKDE.2024.3440352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view Clustering (MVC) has achieved significant progress, with many efforts dedicated to learn knowledge from multiple views. However, most existing methods are either not applicable or require additional steps for incomplete MVC. Such a limitation results in poor-quality clustering performance and poor missing view adaptation. Besides, noise or outliers might significantly degrade the overall clustering performance, which are not handled well by most existing methods. In this paper, we propose a novel unified framework for incomplete and complete MVC named self-learning symmetric multi-view probabilistic clustering (SLS-MPC). SLS-MPC proposes a novel symmetric multi-view probability estimation and equivalently transforms multi-view pairwise posterior matching probability into composition of each view's individual distribution, which tolerates data missing and might extend to any number of views. Then, SLS-MPC proposes a novel self-learning probability function without any prior knowledge and hyper-parameters to learn each view's individual distribution. Next, graph-context-aware refinement with path propagation and co-neighbor propagation is used to refine pairwise probability, which alleviates the impact of noise and outliers. Finally, SLS-MPC proposes a probabilistic clustering algorithm to adjust clustering assignments by maximizing the joint probability iteratively without category information. Extensive experiments on multiple benchmarks show that SLS-MPC outperforms previous state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Junjie Liu and Junlong Liu and Rongxin Jiang and Yaowu Chen and Chen Shen and Jieping Ye},
  doi          = {10.1109/TKDE.2024.3440352},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2097-2110},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Self-learning symmetric multi-view probabilistic clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAGIC: Risk-aware generative framework for stock interval construction. <em>TKDE</em>, <em>37</em>(4), 2085-2096. (<a href='https://doi.org/10.1109/TKDE.2025.3533492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efforts to predict stock market outcomes have yielded limited success due to the inherently stochastic nature of the market, influenced by numerous unpredictable factors. Many existing prediction approaches focus on single-point predictions, lacking the depth needed for effective decision-making and often overlooking market risk. To bridge this gap, we propose RAGIC, a novel risk-aware framework for stock interval prediction to quantify uncertainty. Our approach leverages a Generative Adversarial Network (GAN) to produce future price sequences infused with randomness inherent in financial markets. RAGIC’s generator detects the risk perception of informed investors and captures historical price trends globally and locally. Then the risk-sensitive intervals is built upon the simulated future prices from sequence generation through statistical inference, incorporating horizon-wise insights. The interval’s width is adaptively adjusted to reflect market volatility. Importantly, our approach relies solely on publicly available data and incurs only low computational overhead. RAGIC’s evaluation across globally recognized broad-based indices demonstrates its balanced performance, offering both accuracy and informativeness. Achieving a consistent 95% coverage, RAGIC maintains a narrow interval width. This promising outcome suggests that our approach effectively addresses the challenges of stock market prediction while incorporating vital risk considerations.},
  archive      = {J_TKDE},
  author       = {Jingyi Gu and Wenlu Du and Guiling Wang},
  doi          = {10.1109/TKDE.2025.3533492},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2085-2096},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RAGIC: Risk-aware generative framework for stock interval construction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preference-consistent knowledge distillation for recommender system. <em>TKDE</em>, <em>37</em>(4), 2071-2084. (<a href='https://doi.org/10.1109/TKDE.2025.3526420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based knowledge distillation has been applied to compress modern recommendation models, usually with projectors that align student (small) recommendation models’ dimensions with teacher dimensions. However, existing studies have only focused on making the projected features (i.e., student features after projectors) similar to teacher features, overlooking investigating whether the user preference can be transferred to student features (i.e., student features before projectors) in this manner. In this paper, we find that due to the lack of restrictions on projectors, the process of transferring user preferences will likely be interfered with. We refer to this phenomenon as preference inconsistency. It greatly wastes the power of feature-based knowledge distillation. To mitigate preference inconsistency, we propose PCKD, which consists of two regularization terms for projectors. We also propose a hybrid method that combines the two regularization terms. We focus on items with high preference scores and significantly mitigate preference inconsistency, improving the performance of feature-based knowledge distillation. Extensive experiments on three public datasets and three backbones demonstrate the effectiveness of PCKD.},
  archive      = {J_TKDE},
  author       = {Zhangchi Zhu and Wei Zhang},
  doi          = {10.1109/TKDE.2025.3526420},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2071-2084},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Preference-consistent knowledge distillation for recommender system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NALSpatial: A natural language interface for spatial databases. <em>TKDE</em>, <em>37</em>(4), 2056-2070. (<a href='https://doi.org/10.1109/TKDE.2025.3525587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial databases play a vital role in a number of applications ranging from geographic information systems to location-based services. Application tasks typically access underlying spatial data to answer queries. However, non-experts lack the expertise necessary for formulating spatial queries. To fill in this gap, we propose an effective framework that translates natural language queries over spatial data into executable database queries, called NALSpatial. The framework consists of two core phases: (i) natural language understanding and (ii) natural language translation. Phase (i) extracts key entity information, comprehends the query intent and determines the query type by employing natural language processing techniques and deep learning algorithms. The key entities and query type are passed to phase (ii), which makes use of entity mapping rules and structured language models to construct executable database queries. NALSpatial supports dealing with five types of queries including (i) basic queries (e.g. distance and area), (ii) range queries, (iii) nearest neighbor queries, (iv) spatial join queries and (v) aggregation queries. We develop NALSpatial in an open-source extensible database system SECONDO. Extensive experiments show that NALSpatial on average achieves response time of about 2.5 seconds, translatability of 95% and translation precision of 92%, outperforming three state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Mengyi Liu and Xieyang Wang and Jianqiu Xu and Hua Lu and Yongxin Tong},
  doi          = {10.1109/TKDE.2025.3525587},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2056-2070},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {NALSpatial: A natural language interface for spatial databases},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection with missing features via implicit label replenishment and positive correlation feature recovery. <em>TKDE</em>, <em>37</em>(4), 2042-2055. (<a href='https://doi.org/10.1109/TKDE.2025.3536080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection can effectively solve the curse of dimensionality problem in multi-label learning. Existing multi-label feature selection methods mostly handle multi-label data without missing features. However, in practical applications, multi-label data with missing features exist widely, and most existing multi-label feature selection methods are not directly applicable. Therefore, we propose a feature selection method for multi-label data with missing features. First, we propose a method to extract implicit label information from the feature space to replenish the binary label information. Second, we learn the positive correlation between features to construct a feature correlation recovery matrix to recover missing features. Finally, we design a sparse model-based multi-label feature selection method for processing multi-label data with missing features and prove the convergence of this method. Comparative experiments with existing feature selection methods demonstrate the effectiveness of our method.},
  archive      = {J_TKDE},
  author       = {Jianhua Dai and Wenxiang Chen and Yuhua Qian},
  doi          = {10.1109/TKDE.2025.3536080},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2042-2055},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-label feature selection with missing features via implicit label replenishment and positive correlation feature recovery},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating the tail effect in fraud detection by community enhanced multi-relation graph neural networks. <em>TKDE</em>, <em>37</em>(4), 2029-2041. (<a href='https://doi.org/10.1109/TKDE.2025.3530467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection, a classical data mining problem in finance applications, has risen in significance amid the intensifying confrontation between fraudsters and anti-fraud forces. Recently, an increasing number of criminals are constantly expanding the scope of fraud activities to covet the property of innocent victims. However, most existing approaches require abundant historical records to mine fraud patterns from financial transaction behaviors, thereby leading to significant challenges to protect minority groups, who are less involved in the modern financial market but also under the threat of fraudsters nowadays. Therefore, in this paper, we propose a novel community-enhanced multi-relation graph neural network-based model, named CMR-GNN, to address the important defects of existing fraud detection models in the tail effect situation. In particular, we first construct multiple types of relation graphs from historical transactions and then devise a clustering-based neural network module to capture diverse patterns from transaction communities. To mitigate information lacking tailed nodes, we proposed tailed-groups learning modules to aggregate features from similarly clustered subgraphs by graph convolution networks. Extensive experiments on both the real-world and public datasets demonstrate that our method not only surpasses the state-of-the-art baselines but also could effectively harness information within transaction communities while mitigating the impact of tail effects.},
  archive      = {J_TKDE},
  author       = {Li Han and Longxun Wang and Ziyang Cheng and Bo Wang and Guang Yang and Dawei Cheng and Xuemin Lin},
  doi          = {10.1109/TKDE.2025.3530467},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2029-2041},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Mitigating the tail effect in fraud detection by community enhanced multi-relation graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHR: A multi-modal hyperbolic representation framework for fake news detection. <em>TKDE</em>, <em>37</em>(4), 2015-2028. (<a href='https://doi.org/10.1109/TKDE.2025.3528951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the internet has led to an alarming increase in the dissemination of fake news, which has had many negative effects on society. Various methods have been proposed for detecting fake news. However, these approaches suffer from several limitations. First, most existing works only consider news as separate entities and do not consider the correlations between fake news and real news. Moreover, these works are usually conducted in the Euclidean space, which is unable to capture complex relationships between news, in particular the hierarchical relationships. To tackle these issues, we introduce a novel Multi-modal Hyperbolic Representation framework (MHR) for fake news detection. Specifically, we capture the correlations between news for graph construction to arrange and analyze different news. To fully utilize the multi-modal characteristics, we first extract the textual and visual information, and then design a Lorentzian multi-modal fusion module to fuse them as the node information in the graph. By utilizing the fully hyperbolic graph neural networks, we learn the graph’s representation in hyperbolic space, followed by a detector for detecting fake news. The experimental results on three real-world datasets demonstrate that our proposed MHR model achieves state-of-the-art performance, indicating the benefits of hyperbolic representation.},
  archive      = {J_TKDE},
  author       = {Shanshan Feng and Guoxin Yu and Dawei Liu and Han Hu and Yong Luo and Hui Lin and Yew-Soon Ong},
  doi          = {10.1109/TKDE.2025.3528951},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2015-2028},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MHR: A multi-modal hyperbolic representation framework for fake news detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Making non-overlapping matters: An unsupervised alignment enhanced cross-domain cold-start recommendation. <em>TKDE</em>, <em>37</em>(4), 2001-2014. (<a href='https://doi.org/10.1109/TKDE.2024.3511602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold-start recommendation is a long-standing challenge when presenting potential preferred items to new users. Most empirical studies leverage side information to promote cold-start recommendation. In this work, we focus on cross-domain cold-start recommendation, which aims to provide suggestions to those non-overlapping users who have only interacted in the source domain and are viewed as new users in the target domain. Pre-training and then mapping is the common solution for the cross-domain cold-start recommendation. The former learns domain-specific user preference, and the latter transfers preference knowledge from the source to the target domain. Despite the effectiveness, we argue that current mapping-based methods still have the following limitations. First, current mapping functions fail to fully consider the similarity of user behavioral patterns, either common transfer or personalized transfer mappings. Second, sparse supervision signals from the limited overlapping users, lead to insufficient mapping function learning for recommendation. To tackle the above limitations, we propose a novel MACDR model for cross-domain cold-start recommendation. Specifically, MACDR consists of two elaborate modules: a Prototype enhanced Mixture-Of-Experts (PMOE) based mapping function and a Preference Distribution Alignment (PDA) enhanced optimization. PMOE is designed to balance the transfer patterns of common and personalized preferences, following the basis that similar users share similar preference transfer. Furthermore, to alleviate the sparse supervision issue, PDA is designed to explore the utilization of non-overlapping users in an unsupervised manner based on the prototype distribution alignment technique. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Zihan Wang and Yonghui Yang and Le Wu and Richang Hong and Meng Wang},
  doi          = {10.1109/TKDE.2024.3511602},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {2001-2014},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Making non-overlapping matters: An unsupervised alignment enhanced cross-domain cold-start recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagicNet: Memory-aware graph interactive causal network for multivariate stock price movement prediction. <em>TKDE</em>, <em>37</em>(4), 1989-2000. (<a href='https://doi.org/10.1109/TKDE.2025.3527480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative trading is a prominent field that employs time series analysis today, attracting researchers who apply machine intelligence to real-world issues like stock price movement prediction. In recent literature, various types of auxiliary data have been integrated alongside stock prices to improve prediction accuracy, such as textual news and correlational information. However, they typically rely on directly related documents or symmetric price correlations to make predictions for a particular stock (we refer to as “self-influence”). In this paper, we propose a Memory-Aware Graph Interactive Causal Network (MagicNet) that considers both temporal and spatial dependencies in financial documents and introduces causality-based correlations between multivariate stocks in a hierarchical fashion. MagicNet involves a text memory slot for each stock to retain the most influential texts over time and contains a dynamic interaction graph based on causal relationships to aggregate interactive influences asymmetrically. We believe that MagicNet leverages influential texts across stocks and explores their interrelationships through a logical structure, improving predictions on multiple stocks (we refer to as “interactive-influence”). The effectiveness of MagicNet is demonstrated through experiments on three real-world datasets, where MagicNet outperforms existing state-of-the-art models, offering an intuitive framework for understanding how texts and correlations affect future stock prices.},
  archive      = {J_TKDE},
  author       = {Di Luo and Shuqi Li and Weiheng Liao and Rui Yan},
  doi          = {10.1109/TKDE.2025.3527480},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1989-2000},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MagicNet: Memory-aware graph interactive causal network for multivariate stock price movement prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine unlearning through fine-grained model parameters perturbation. <em>TKDE</em>, <em>37</em>(4), 1975-1988. (<a href='https://doi.org/10.1109/TKDE.2025.3528551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning involves retracting data records and reducing their influence on trained models, aiding user privacy protection, at a significant computational cost potentially. Weight perturbation-based unlearning is common but typically modifies parameters globally. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning that address the privacy needs while keeping the computational costs tractable. However, commonly used training data are independent and identically distributed, for inexact machine unlearning, current metrics are inadequate in quantifying unlearning degree that occurs after unlearning. To address this quantification issue, we introduce SPD-GAN, which subtly perturbs data distribution targeted for unlearning. Then, we evaluate unlearning degree by measuring the performance difference of the models on the perturbed unlearning data before and after unlearning. Furthermore, to demonstrate efficacy, we tackle the challenge of evaluating machine unlearning by assessing model generalization across unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. By implementing these innovative techniques and metrics, we achieve computationally efficacious privacy protection in machine learning applications without significant sacrifice of model performance. A by-product of our work is a novel method for evaluating and quantifying unlearning degree.},
  archive      = {J_TKDE},
  author       = {Zhiwei Zuo and Zhuo Tang and Kenli Li and Anwitaman Datta},
  doi          = {10.1109/TKDE.2025.3528551},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1975-1988},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Machine unlearning through fine-grained model parameters perturbation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LUNA: Efficient backward-private dynamic symmetric searchable encryption scheme with secure deletion in encrypted database. <em>TKDE</em>, <em>37</em>(4), 1961-1974. (<a href='https://doi.org/10.1109/TKDE.2023.3329234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic symmetric searchable encryption (SSE) enables clients to perform searches and updates on an encrypted database outsourced to an untrusted server while preserving the privacy of data and queries. For restricting information leakage, it is very important to limit what the server can learn about the deleted data during searches after the deletion, i.e., to satisfy backward privacy. However, previous backward privacy definitions only considered the logical deletion of keywords in documents while ignoring security risks caused by the actual deletion of documents. Moreover, existing SSE schemes often depend on heavy cryptographic primitives for achieving high-level backward privacy, which greatly degrades the end-to-end performance. To this end, we define a new backward privacy notion named BP-DEL, which restricts the information leakage of the actual deletion. Moreover, we design a hybrid index structure that provides BP-DEL for SSE schemes such that they support deletions securely. Based on the hybrid index, we propose a BP-DEL construction named LUNA and design its protocols with a trusted execution environment (TEE) to maintain the index efficiently. Finally, we implement LUNA in the MySQL database by encapsulating it in UDFs. The experimental results show that LUNA has a performance much better than previous works satisfying BP-DEL.},
  archive      = {J_TKDE},
  author       = {Siyi Lv and Yanyu Huang and Xinhao Li and Tong Li and Liang Guo and Xiaofeng Chen and Zheli Liu},
  doi          = {10.1109/TKDE.2023.3329234},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1961-1974},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LUNA: Efficient backward-private dynamic symmetric searchable encryption scheme with secure deletion in encrypted database},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-driven causal discovery via harmonized prior. <em>TKDE</em>, <em>37</em>(4), 1943-1960. (<a href='https://doi.org/10.1109/TKDE.2025.3528461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional domain-specific causal discovery relies on expert knowledge to guide the data-based structure learning process, thereby improving the reliability of recovered causality. Recent studies have shown promise in using the Large Language Model (LLM) as causal experts to construct autonomous expert-guided causal discovery systems through causal reasoning between pairwise variables. However, their performance is hampered by inaccuracies in aligning LLM-derived causal knowledge with the actual causal structure. To address this issue, this paper proposes a novel LLM-driven causal discovery framework that limits LLM’s prior within a reliable range. Instead of pairwise causal reasoning that requires both precise and comprehensive output results, the LLM is directed to focus on each single aspect separately. By combining these distinct causal insights, a unified set of structural constraints is created, termed a harmonized prior, which draws on their respective strengths to ensure prior accuracy. On this basis, we introduce plug-and-play integrations of the harmonized prior into mainstream categories of structure learning methods, thereby enhancing their applicability in practical scenarios. Evaluations on real-world data demonstrate the effectiveness of our approach.},
  archive      = {J_TKDE},
  author       = {Taiyu Ban and Lyuzhou Chen and Derui Lyu and Xiangyu Wang and Qinrui Zhu and Huanhuan Chen},
  doi          = {10.1109/TKDE.2025.3528461},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1943-1960},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LLM-driven causal discovery via harmonized prior},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning latent and changing dynamics in real non-stationary environments. <em>TKDE</em>, <em>37</em>(4), 1930-1942. (<a href='https://doi.org/10.1109/TKDE.2025.3535961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning (RL) aims to learn the underlying dynamics of a given environment. The success of most existing works is built on the critical assumption that the dynamic is fixed, which is unrealistic in many open-world scenarios, such as drone delivery and online chatting, where agents may need to deal with environments with unpredictable changing dynamics (hereafter, real non-stationary environment). Therefore, learning changing dynamics in a real non-stationary environment offers both significant benefits and challenges. This paper proposes a new model-based reinforcement learning algorithm that proactively and dynamically detects possible changes and Learns these Latent and Changing Dynamics (LLCD) in a latent Markovian space for real non-stationary environments. To ensure the Markovian property of the RL model and improve computational efficiency, we employ a latent space model to learn the environment’s transition dynamics. Furthermore, we perform online change detection in the latent space to promptly identify change points in non-stationary environments. Then, we utilize the detected information to help the agent adapt to new conditions. Experiments indicate that the rewards of the proposed algorithm accumulate for the most rapid adaptions to environmental change, among other benefits. This work has a strong potential to enhance environmentally suitable model-based reinforcement learning capabilities.},
  archive      = {J_TKDE},
  author       = {Zihe Liu and Jie Lu and Junyu Xuan and Guangquan Zhang},
  doi          = {10.1109/TKDE.2025.3535961},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1930-1942},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning latent and changing dynamics in real non-stationary environments},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intent-guided heterogeneous graph contrastive learning for recommendation. <em>TKDE</em>, <em>37</em>(4), 1915-1929. (<a href='https://doi.org/10.1109/TKDE.2025.3536096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive Learning (CL)-based recommender systems have gained prominence in the context of Heterogeneous Graph (HG) due to their capacity to enhance the consistency of representations across different views. However, existing frameworks often neglect the fact that user-item interactions within HG are governed by diverse latent intents (e.g., brand preferences or demographic characteristics of item audiences), which are pivotal in capturing fine-grained relations. The exploration of these underlying intents, particularly through the lens of meta-paths in HGs, presents us with two principal challenges: i) How to integrate CL with intents; ii) How to mitigate noise from meta-path-driven intents. To address these challenges, we propose an innovative framework termed Intent-guided Heterogeneous Graph Contrastive Learning (IHGCL), which designed to enhance CL-based recommendation by capturing the intents contained within meta-paths. Specifically, the IHGCL framework includes: i) a meta-path-based Dual Contrastive Learning (DCL) approach to effectively integrate intents into the recommendation, constructing intent-intent contrast and intent-interaction contrast; ii) a Bottlenecked AutoEncoder (BAE) that combines mask propagation with the information bottleneck principle to significantly reduce noise perturbations introduced by meta-paths. Empirical evaluations conducted across six distinct datasets demonstrate the superior performance of our IHGCL framework relative to conventional baseline methods.},
  archive      = {J_TKDE},
  author       = {Lei Sang and Yu Wang and Yi Zhang and Yiwen Zhang and Xindong Wu},
  doi          = {10.1109/TKDE.2025.3536096},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1915-1929},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Intent-guided heterogeneous graph contrastive learning for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HyCubE: Efficient knowledge hypergraph 3D circular convolutional embedding. <em>TKDE</em>, <em>37</em>(4), 1902-1914. (<a href='https://doi.org/10.1109/TKDE.2025.3531372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge hypergraph embedding models are usually computationally expensive due to the inherent complex semantic information. However, existing works mainly focus on improving the effectiveness of knowledge hypergraph embedding, making the model architecture more complex and redundant. It is desirable and challenging for knowledge hypergraph embedding to reach a trade-off between model effectiveness and efficiency. In this paper, we propose an end-to-end efficient knowledge hypergraph embedding model, HyCubE, which designs a novel 3D circular convolutional neural network and the alternate mask stack strategy to enhance the interaction and extraction of feature information comprehensively. Furthermore, our proposed model achieves a better trade-off between effectiveness and efficiency by adaptively adjusting the 3D circular convolutional layer structure to handle $n$-ary knowledge tuples of different arities with fewer parameters. In addition, we use a knowledge hypergraph 1-N multilinear scoring way to accelerate the model training efficiency further. Finally, extensive experimental results on all datasets demonstrate that our proposed model consistently outperforms state-of-the-art baselines, with an average improvement of 8.22% and a maximum improvement of 33.82% across all metrics. Meanwhile, HyCubE is 6.12x faster, GPU memory usage is 52.67% lower, and the number of parameters is reduced by 85.21% compared with the average metric of the latest state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Zhao Li and Xin Wang and Jun Zhao and Wenbin Guo and Jianxin Li},
  doi          = {10.1109/TKDE.2025.3531372},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1902-1914},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HyCubE: Efficient knowledge hypergraph 3D circular convolutional embedding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HPST-GT: Full-link delivery time estimation via heterogeneous periodic spatial-temporal graph transformer. <em>TKDE</em>, <em>37</em>(4), 1885-1901. (<a href='https://doi.org/10.1109/TKDE.2025.3533610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A warehouse-distribution integration (WDI) e-commerce platform is an approach that combines warehousing and distribution processes, which is increasingly adopted in industry to enhance business efficiency. In the WDI e-commerce, one of the most important problems is to estimate the full-link delivery time for decision-making. Traditional methods designed for separate warehouse-distribution models struggle to address challenges in integrated systems. The difficulties stem from two main factors: (i) the contextual influence exerted by neighboring units within heterogeneous delivery networks, and (ii) the uncertainty in delivery times caused by dynamic and periodic temporal factors such as fluctuations in online sales volumes and the varying characteristics of different delivery units (e.g., warehouses and sorting centers). To address these challenges, we propose a novel full-link delivery time estimation framework called Heterogeneous Periodic Spatial-Temporal Graph Transformer (HPST-GT). First, we develop heterogeneous graph transformers to capture the hierarchical and diverse information of the warehouse-distribution network. Next, we design spatial-temporal transformers based on heterogeneous features to analyze the correlation between spatial and temporal information. Finally, we create a heterogeneous spatial-temporal graph prediction module to estimate full-link delivery time. Our method, evaluated on a one-month dataset from a leading e-commerce platform, surpasses current benchmarks across multiple performance metrics.},
  archive      = {J_TKDE},
  author       = {Shuai Wang and Hai Wang and Li Lin and Xiaohui Zhao and Tian He and Dian Shen and Wei Xi},
  doi          = {10.1109/TKDE.2025.3533610},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1885-1901},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HPST-GT: Full-link delivery time estimation via heterogeneous periodic spatial-temporal graph transformer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HG-SCC: A subgraph-aware convolutional few-shot classification method on heterogeneous graphs. <em>TKDE</em>, <em>37</em>(4), 1871-1884. (<a href='https://doi.org/10.1109/TKDE.2024.3523573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot classification is increasingly relevant in emerging applications, such as university course classification in intelligent education systems. University course classification helps students acquire specific skills, comprehend course purposes, and assists departments in defining training goals. However, classifying frontier courses presents challenges due to the absence of labels and descriptions. Few-shot learning addresses this by acquiring meta-knowledge. Heterogeneous graphs (HGs), rich in semantic information, introduce complexities that make few-shot particularly challenging. Addressing this problem, we propose a subgraph-aware convolutional few-shot classification method on HGs (HG-SCC). We first formalize the subgraph sampling strategy for HGs and different views under meta-paths. Then, the layer number adaptive spectral-based graph convolution is designed for personalized node embedding. Furthermore, a high-order convolution operation with classes as nodes is designed to increase the class representation coverage. Modeling subgraph centrality, combined with node features, captures structural information, improving awareness of each sampled subgraph, thus alleviating sparsity in new class labels and enhancing classification accuracy. Euclidean distance-based and task-affected cosine similarity-based classifiers under different meta-paths are proposed, with stacking introduced to blend multiple classifiers based on subgraph features. Experimental results show that our method has high performance in course classification and also outperforms state-of-the-art methods on benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Minghe Yu and Yun Zhang and Jintong Sun and Min Huang and Tiancheng Zhang and Ge Yu},
  doi          = {10.1109/TKDE.2024.3523573},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1871-1884},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HG-SCC: A subgraph-aware convolutional few-shot classification method on heterogeneous graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heavy nodes in a small neighborhood: Exact and peeling algorithms with applications. <em>TKDE</em>, <em>37</em>(4), 1853-1870. (<a href='https://doi.org/10.1109/TKDE.2024.3515875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a weighted and unconstrained variant of the well-known minimum $k$ union problem: Given a bipartite graph $\mathcal {G}(U,V,E)$ with weights for all nodes in $V$, find a set $S\subseteq V$ such that the ratio between the total weight of the nodes in $S$ and the number of their distinct adjacent nodes in $U$ is maximized. Our problem, which we term Heavy Nodes in a Small Neighborhood (HNSN), finds applications in marketing, team formation, and money laundering detection. For example, in the latter application, $S$ represents bank account holders who obtain illicit money from some peers of a criminal and route it through their accounts to a target account belonging to the criminal. We prove that HNSN can be solved exactly in polynomial time via linear programming. We also develop several algorithms offering different effectiveness/efficiency trade-offs: an exact algorithm, based on node contraction, graph decomposition, and linear programming, as well as three peeling algorithms. The first peeling algorithm is a near-linear time approximation algorithm with a tight approximation ratio, the second is an iterative algorithm that converges to an optimal solution in a very small number of iterations in practice, and the third is a near-linear time greedy heuristic. In addition, we formalize a money laundering scenario involving multiple target accounts and show how our algorithms can be extended to deal with it. Our experiments on real and synthetic datasets show that our algorithms find (near-)optimal solutions, outperforming a natural baseline, and that they can detect money laundering more effectively and efficiently than two state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Ling Li and Hilde Verbeek and Huiping Chen and Grigorios Loukides and Robert Gwadera and Leen Stougie and Solon P. Pissis},
  doi          = {10.1109/TKDE.2024.3515875},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1853-1870},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Heavy nodes in a small neighborhood: Exact and peeling algorithms with applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph linear convolution pooling for learning in incomplete high-dimensional data. <em>TKDE</em>, <em>37</em>(4), 1838-1852. (<a href='https://doi.org/10.1109/TKDE.2024.3524627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional and incomplete (HDI) data are frequently encountered in diverse real-world applications involving complex interactions among numerous nodes. Approaches based on latent feature analysis (LFA) have proven effective in performing representation learning in HDI data. Nevertheless, they cannot handle the high-order connectivity among nodes in HDI data well, resulting in severe accuracy loss. To address the previously mentioned issue, we present a novel model in this paper, namely Graph Linear Convolution Pooling Network (GLCPN). The proposed GLCPN adopts the three-fold ideas. First, it leverages simplified graph convolutions to efficiently capture high-order connectivity among nodes for learning representations of matrix factorization. Second, a simple yet effective priori convolution operator is adopted by each graph neural layer to capture node-node collaboration for aggregation. Third, a locality-enhanced pooling scheme is designed to holistically utilize multi-layer representations of the neighborhood. Therefore, GLCPN can effectively acquire the hidden information in HDI data with high efficiency. In addition, we have conducted a theoretical analysis demonstrating that the proposed GLCPN is more expressive compared with existing graph neural networks for HDI data. Extensive experiments have been further conducted on ten well-established HDI datasets from various applications. The experimental results demonstrate that the proposed GLCPN significantly outperforms state-of-the-art models for learning representations in HDI data evaluated by accuracy and efficiency metrics.},
  archive      = {J_TKDE},
  author       = {Fanghui Bi and Tiantian He and Yew-Soon Ong and Xin Luo},
  doi          = {10.1109/TKDE.2024.3524627},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1838-1852},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph linear convolution pooling for learning in incomplete high-dimensional data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph condensation: A survey. <em>TKDE</em>, <em>37</em>(4), 1819-1837. (<a href='https://doi.org/10.1109/TKDE.2025.3535877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of graph data poses significant challenges in storage, transmission, and particularly the training of graph neural networks (GNNs). To address these challenges, graph condensation (GC) has emerged as an innovative solution. GC focuses on synthesizing a compact yet highly representative graph, enabling GNNs trained on it to achieve performance comparable to those trained on the original large graph. The notable efficacy of GC and its broad prospects have garnered significant attention and spurred extensive research. This survey paper provides an up-to-date and systematic overview of GC, organizing existing research into five categories aligned with critical GC evaluation criteria: effectiveness, generalization, efficiency, fairness, and robustness. To facilitate an in-depth and comprehensive understanding of GC, this paper examines various methods under each category and thoroughly discusses two essential components within GC: optimization strategies and condensed graph generation. We also empirically compare and analyze representative GC methods with diverse optimization strategies based on the five proposed GC evaluation criteria. Finally, we explore the applications of GC in various fields, outline the related open-source libraries, and highlight the present challenges and novel insights, with the aim of promoting advancements in future research.},
  archive      = {J_TKDE},
  author       = {Xinyi Gao and Junliang Yu and Tong Chen and Guanhua Ye and Wentao Zhang and Hongzhi Yin},
  doi          = {10.1109/TKDE.2025.3535877},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1819-1837},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph condensation: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot causal representation learning for out-of-distribution generalization on heterogeneous graphs. <em>TKDE</em>, <em>37</em>(4), 1804-1818. (<a href='https://doi.org/10.1109/TKDE.2025.3531469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of label sparsity in heterogeneous graphs (HGs), heterogeneous graph few-shot learning (HGFL) has recently emerged. HGFL aims to extract meta-knowledge from source HGs with rich-labeled data and transfers it to a target HG, facilitating learning new classes with few-labeled training data and improving predictions on unlabeled testing data. Existing methods typically assume the same distribution across the source HG, training data, and testing data. However, in practice, distribution shifts in HGFL are inevitable due to (1) the scarcity of source HGs that match the target HG's distribution, and (2) the unpredictable data generation mechanism of the target HG. Such distribution shifts can degrade the performance of existing methods, leading to a novel problem of out-of-distribution (OOD) generalization in HGFL. To address this challenging problem, we propose COHF, a Causal OOD Heterogeneous graph Few-shot learning model. In COHF, we first adopt a bottom-up data generative perspective to identify the invariance principle for OOD generalization. Then, based on this principle, we design a novel variational autoencoder-based heterogeneous graph neural network (VAE-HGNN) to mitigate the impact of distribution shifts. Finally, we propose a novel meta-learning framework that incorporates VAE-HGNN to effectively transfer meta-knowledge in OOD environments. Extensive experiments on seven real-world datasets have demonstrated the superior performance of COHF over the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Pengfei Ding and Yan Wang and Guanfeng Liu and Nan Wang and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2025.3531469},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1804-1818},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Few-shot causal representation learning for out-of-distribution generalization on heterogeneous graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDict: Towards practical federated dictionary-based time series classification. <em>TKDE</em>, <em>37</em>(4), 1785-1803. (<a href='https://doi.org/10.1109/TKDE.2025.3528023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dictionary-based approach is one of the most representative types of time series classification (TSC) algorithm due to its high accuracy, efficiency, and good interpretability. However, existing studies focus on the centralized scenario where data from multiple sources are gathered. Considering that in many practical applications, data owners are reluctant to share their data due to privacy concerns, we study an unexplored problem involving collaboratively building the dictionary-based model over the data owners without disclosing their private data (i.e., in the federated scenario). We propose FedDict, a novel dictionary-based TSC approach customized for the federated setting to benefit from the advantages of the centralized algorithms. To further improve the performance and practicality, we propose a novel federated optimization algorithm for training logistic regression classifiers using dictionary features. The algorithm does not rely on any secure broker and is more accurate and efficient than existing solutions without hyper-parameter tuning. We also propose two contract algorithms for federated dictionary building, such that the user can flexibly balance the running time and the TSC performance through a pre-defined time limit. Extensive experiments on a total of 117 highly heterogeneous datasets validate the effectiveness of our methods and the superiority over existing solutions.},
  archive      = {J_TKDE},
  author       = {Zhiyu Liang and Zheng Liang and Hongzhi Wang and Bo Zheng},
  doi          = {10.1109/TKDE.2025.3528023},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1785-1803},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FedDict: Towards practical federated dictionary-based time series classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing hyperedge prediction with context-aware self-supervised learning. <em>TKDE</em>, <em>37</em>(4), 1772-1784. (<a href='https://doi.org/10.1109/TKDE.2025.3532263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs can naturally model group-wise relations (e.g., a group of users who co-purchase an item) as hyperedges. Hyperedge prediction is to predict future or unobserved hyperedges, which is a fundamental task in many real-world applications (e.g., group recommendation). Despite the recent breakthrough of hyperedge prediction methods, the following challenges have been rarely studied: (C1) How to aggregate the nodes in each hyperedge candidate for accurate hyperedge prediction? and (C2) How to mitigate the inherent data sparsity problem in hyperedge prediction? To tackle both challenges together, in this paper, we propose a novel hyperedge prediction framework ($\mathsf{CASH}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi mathvariant="sans-serif">CASH</mml:mi></mml:math>) that employs (1) context-aware node aggregation to precisely capture complex relations among nodes in each hyperedge for (C1) and (2) self-supervised contrastive learning in the context of hyperedge prediction to enhance hypergraph representations for (C2). Furthermore, as for (C2), we propose a hyperedge-aware augmentation method to fully exploit the latent semantics behind the original hypergraph and consider both node-level and group-level contrasts (i.e., dual contrasts) for better node and hyperedge representations. Extensive experiments on six real-world hypergraphs reveal that $\mathsf{CASH}$ consistently outperforms all competing methods in terms of the accuracy in hyperedge prediction and each of the proposed strategies is effective in improving the model accuracy of $\mathsf{CASH}$.},
  archive      = {J_TKDE},
  author       = {Yunyong Ko and Hanghang Tong and Sang-Wook Kim},
  doi          = {10.1109/TKDE.2025.3532263},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1772-1784},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing hyperedge prediction with context-aware self-supervised learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient generalized temporal pattern mining in time series using mutual information. <em>TKDE</em>, <em>37</em>(4), 1753-1771. (<a href='https://doi.org/10.1109/TKDE.2025.3526800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big time series are increasingly available from an ever wider range of IoT-enabled sensors deployed in various environments. Significant insights can be gained by mining temporal patterns from these time series. Temporal pattern mining (TPM) extends traditional pattern mining by adding event time intervals into extracted patterns, making them more expressive at the expense of increased time and space complexities. Besides frequent temporal patterns (FTPs), which occur frequently in the entire dataset, another useful type of temporal patterns are so-called rare temporal patterns (RTPs), which appear rarely but with high confidence. Mining rare temporal patterns yields additional challenges. For FTP mining, the temporal information and complex relations between events already create an exponential search space. For RTP mining, the support measure is set very low, leading to a further combinatorial explosion and potentially producing too many uninteresting patterns. Thus, there is a need for a better approach to mine frequent and rare temporal patterns. This paper presents our Generalized Temporal Pattern Mining from Time Series (GTPMfTS) approach that can mine both types of patterns, with the following specific contributions: (1) The end-to-end GTPMfTS process taking time series as input and producing frequent/rare temporal patterns as output. (2) The efficient Generalized Temporal Pattern Mining (GTPM) algorithm mines frequent and rare temporal patterns using efficient data structures for fast retrieval of events and patterns during the mining process, and employs effective pruning techniques for significantly faster mining. (3) An approximate version of GTPM that uses mutual information, a measure of data correlation, to prune unpromising time series from the search space. (4) An extensive experimental evaluation of GTPM for rare temporal pattern mining (RTPM) and frequent temporal pattern mining (FTPM), showing that RTPM and FTPM significantly outperform the baselines on runtime and memory consumption, and can scale to big datasets. The approximate RTPM is up to one order of magnitude, and the approximate FTPM is up to two orders of magnitude, faster than the baselines, while retaining high accuracy.},
  archive      = {J_TKDE},
  author       = {Van Long Ho and Nguyen Ho and Torben Bach Pedersen and Panagiotis Papapetrou},
  doi          = {10.1109/TKDE.2025.3526800},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1753-1771},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient generalized temporal pattern mining in time series using mutual information},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EA2N: Evidence-based AMR attention network for fake news detection. <em>TKDE</em>, <em>37</em>(4), 1742-1752. (<a href='https://doi.org/10.1109/TKDE.2025.3529707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proliferation of fake news has become a critical issue in today's information-driven society. Our study includes external knowledge from Wikidata which allows the model to cross-reference factual claims with established knowledge. This approach deviates from the reliance on social information to detect fake news that many state-of-the-art (SOTA) fact-checking models adopt. This paper introduces EA$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>N, an Evidence-based AMR (abstract meaning representation) Attention Network for Fake News Detection. EA$^{2}$N utilizes the proposed Evidence based Abstract Meaning Representation (WikiAMR) which incorporates knowledge using a proposed evidence-linking algorithm, pushing the boundaries of fake news detection. The proposed framework encompasses a combination of a novel language encoder and a graph encoder to detect fake news. While the language encoder effectively combines transformer-encoded textual features with affective lexical features, the graph encoder encodes semantic relations with evidence through external knowledge, referred to as WikiAMR graph. A path-aware graph learning module is designed to capture crucial semantic relationships among entities over evidence. Extensive experiments support our model's superior performance, surpassing SOTA methodologies with a difference of 2-3% in F1-score and accuracy for Politifact and Gossipcop datasets. The improvement due to the introduction of WikiAMR is found to be statistically significant with t-value less than 0.01.},
  archive      = {J_TKDE},
  author       = {Shubham Gupta and Abhishek Rajora and Suman Kundu},
  doi          = {10.1109/TKDE.2025.3529707},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1742-1752},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {EA2N: Evidence-based AMR attention network for fake news detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual enhanced meta-learning with adaptive task scheduler for cold-start recommendation. <em>TKDE</em>, <em>37</em>(4), 1728-1741. (<a href='https://doi.org/10.1109/TKDE.2025.3529525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems typically rely on users’ historical behavior to infer their preferences. However, when new entries emerge, the system cannot make accurate prediction due to the lack of historical data. This is known as the “cold-start” problem, which not only limits the exposure of new items but also impacts the first experience of new users severely. Meta-learning has emerged as a promising approach to address this issue, but existing methods have limitations in dealing with the differences in user preferences and sparse monitoring data. To overcome these limitations, Dual enhanced Meta-learning with Adaptive Task Sampling is proposed. First, we propose an embedding enhancement strategy for cold nodes. Specifically, we map the cold-start embeddings into the warm space based on the common features shared across all nodes, and then add uniform noise to create the contrastive views. This strategy injects warm co-occurrence signals into the content of cold nodes, effectively enriching the feature space of cold nodes. Second, we introduce an adaptive task scheduler to measure the effectiveness of different meta-tasks and filter out the noise from invalid tasks. We assign different sampling probabilities to the tasks based on the learning process (gradient similarity) and the learning result (loss) of the meta-tasks. Finally, we consider the above two modules as auxiliary tasks for the main meta-model. Then, joint optimization is carried out through a multi-task learning framework. Experiments in three cold-start scenarios show that our approach outperforms the most advanced baselines, including traditional methods, HIN-based methods, and meta-learning-based methods.},
  archive      = {J_TKDE},
  author       = {Dongxiao He and Jiaqi Cui and Xiaobao Wang and Guojie Song and Yuxiao Huang and Lingfei Wu},
  doi          = {10.1109/TKDE.2025.3529525},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1728-1741},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dual enhanced meta-learning with adaptive task scheduler for cold-start recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DASKT: A dynamic affect simulation method for knowledge tracing. <em>TKDE</em>, <em>37</em>(4), 1714-1727. (<a href='https://doi.org/10.1109/TKDE.2025.3526584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) predicts future performance by modeling students’ historical interactions, and understanding students’ affective states can enhance the effectiveness of KT, thereby improving the quality of education. Although traditional KT values students’ cognition and learning behaviors, efficient evaluation of students’ affective states and their application in KT still require further exploration due to the non-affect-oriented nature of the data and budget constraints. To address this issue, we propose a computation-driven approach, Dynamic Affect Simulation Knowledge Tracing (DASKT), to explore the impact of various student affective states (such as frustration, concentration, boredom, and confusion) on their knowledge states. In this model, we first extract affective factors from students’ non-affect-oriented behavioral data, then use clustering and spatiotemporal sequence modeling to accurately simulate students’ dynamic affect changes when dealing with different problems. Subsequently, we incorporate affect with time-series analysis to improve the model's ability to infer knowledge states over time and space. Extensive experimental results on two public real-world educational datasets show that DASKT can achieve more reasonable knowledge states under the effect of students’ affective states. Moreover, DASKT outperforms the most advanced KT methods in predicting student performance. Our research highlights a promising avenue for future KT studies, focusing on achieving high interpretability and accuracy.},
  archive      = {J_TKDE},
  author       = {Xinjie Sun and Kai Zhang and Qi Liu and Shuanghong Shen and Fei Wang and Yuxiang Guo and Enhong Chen},
  doi          = {10.1109/TKDE.2025.3526584},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1714-1727},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DASKT: A dynamic affect simulation method for knowledge tracing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoreSense: Social commonsense knowledge-aware context refinement for conversational recommender system. <em>TKDE</em>, <em>37</em>(4), 1702-1713. (<a href='https://doi.org/10.1109/TKDE.2025.3536464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the traditional recommender systems that rely on historical data such as clicks or purchases, a conversational recommender system (CRS) aims to provide a personalized recommendation through a natural conversation. The conversational interaction facilitates capturing not only explicit preference from mentioned items but also implicit states, such as a user’s current situation and emotional states from a dialogue context. Nevertheless, existing CRSs fall short of fully exploiting a dialogue context since they primarily derive explicit user preferences from the items and item-attributes mentioned in a conversation. To address this limitation and attain a comprehensive understanding of a dialogue context, we propose CoreSense, a conversational recommender system enhanced with social commonsense knowledge. In other words, CoreSense exploits the social commonsense knowledge graph ATOMIC to capture the user’s implicit states, such as a user’s current situation and emotional states, from a dialogue context. Thus, the social commonsense knowledge-augmented CRS can provide a more appropriate recommendation from a given dialogue context. Furthermore, we enhance the collaborative filtering effect by utilizing the user’s states inferred from commonsense knowledge as an improved criterion for retrieving other dialogues of similar interests. Extensive experiments on CRS benchmark datasets show that CoreSense provides human-like recommendations and responses based on inferred user states, achieving significant performance improvements.},
  archive      = {J_TKDE},
  author       = {Hyeongjun Yang and Donghyun Kim and Gayeon Park and KyuHwan Yeom and Kyong-Ho Lee},
  doi          = {10.1109/TKDE.2025.3536464},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1702-1713},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CoreSense: Social commonsense knowledge-aware context refinement for conversational recommender system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CloudRGK: Towards private similarity measurement between graphs on the cloud. <em>TKDE</em>, <em>37</em>(4), 1688-1701. (<a href='https://doi.org/10.1109/TKDE.2025.3529949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph kernels are a significant class of tools for measuring the similarity of graph data, which is the basis of a wide range of graph learning methods. However, graph kernels often suffer from high computing overhead. With the shining of cloud computing, it is desirable to transfer the computing burden to the server with abundant computing resources to reduce the cost of local machines. Nonetheless, under the honest-but-curious cloud assumption, the server may peek at the data, raising privacy concerns. To eliminate the risk of data privacy leakage, we propose CloudRGK to securely perform Random walk Graph Kernel(RGK), one of the most well-known graph kernels, on the cloud. We first prove that the edge- and vertex-labeled graphs could be transformed into an equivalent matrix representation. Afterward, we prove that the cloud could perform the core operations in RGK on the encrypted graphs without feature information loss. Evaluations of the real-world graph data demonstrate that our strategy significantly reduces the overhead of the local party to perform RGK without performance degradation. Meanwhile, it introduces only a small amount of extra computation cost. To the best of our knowledge, it is the first work towards private graph kernel computation on the cloud.},
  archive      = {J_TKDE},
  author       = {Linxiao Yu and Jun Tao and Yifan Xu and Haotian Wang},
  doi          = {10.1109/TKDE.2025.3529949},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1688-1701},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CloudRGK: Towards private similarity measurement between graphs on the cloud},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLEAR: Spatial-temporal traffic data representation learning for traffic prediction. <em>TKDE</em>, <em>37</em>(4), 1672-1687. (<a href='https://doi.org/10.1109/TKDE.2025.3536009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving field of urban development, precise traffic prediction is essential for optimizing traffic and mitigating congestion. While traditional graph learning-based models effectively exploit complex spatial-temporal correlations, their reliance on trivially generated graph structures or deeply intertwined adjacency learning without supervised loss significantly impedes their efficiency. This paper presents Contrastive Learning of spatial-tEmporal trAffic data Representations (CLEAR) framework, a comprehensive approach to spatial-temporal traffic data representation learning aimed at enhancing the accuracy of traffic predictions. Employing self-supervised contrastive learning, CLEAR strategically extracts discriminative embeddings from both traffic time-series and graph-structured data. The framework applies weak and strong data augmentations to facilitate subsequent exploitations of intrinsic spatial-temporal correlations that are critical for accurate prediction. Additionally, CLEAR incorporates advanced representation learning models that transmute these dynamics into compact, semantic-rich embeddings, thereby elevating downstream models’ prediction accuracy. By integrating with existing traffic predictors, CLEAR boosts predicting performance and accelerates the training process by effectively decoupling adjacency learning from correlation learning. Comprehensive experiments validate that CLEAR can robustly enhance the capabilities of existing graph learning-based traffic predictors and provide superior traffic predictions with a straightforward representation decoder. This investigation highlights the potential of contrastive representation learning in developing robust traffic data representations for traffic prediction.},
  archive      = {J_TKDE},
  author       = {James Jianqiao Yu and Xinwei Fang and Shiyao Zhang and Yuxin Ma},
  doi          = {10.1109/TKDE.2025.3536009},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1672-1687},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CLEAR: Spatial-temporal traffic data representation learning for traffic prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain and cognitive science inspired deep learning: A comprehensive survey. <em>TKDE</em>, <em>37</em>(4), 1650-1671. (<a href='https://doi.org/10.1109/TKDE.2025.3527551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) is increasingly viewed as a foundational methodology for advancing Artificial Intelligence (AI). However, its interpretability remains limited, and it often underperforms in certain fields due to its lack of human-like characteristics. Consequently, leveraging insights from Brain and Cognitive Science (BCS) to understand and advance DL has become a focal point for researchers in the DL community. However, BCS is a diverse discipline where existing studies often concentrate on cognitive theories within their respective domains. These theories are typically grounded in certain assumptions, complicating comparisons between different approaches. Therefore, this review is intended to provide a comprehensive landscape of more than 300 papers on the intersection of DL and BCS grounded in DL community. Unlike previous reviews that based on sub-disciplines of Cognitive Science, this article aims to establish a unified framework encompassing all aspects of DL inspired by BCS, offering insights into the symbiotic relationship between DL and BCS. Additionally, we present a forward-looking perspective on future research directions, with the intention of inspiring further advancements in AI research.},
  archive      = {J_TKDE},
  author       = {Zihan Zhang and Xiao Ding and Xia Liang and Yusheng Zhou and Bing Qin and Ting Liu},
  doi          = {10.1109/TKDE.2025.3527551},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1650-1671},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Brain and cognitive science inspired deep learning: A comprehensive survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting GNN-based link prediction via PU-AUC optimization. <em>TKDE</em>, <em>37</em>(4), 1635-1649. (<a href='https://doi.org/10.1109/TKDE.2025.3525490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction, which aims to predict the existence of a link between two nodes in a network, has various applications ranging from friend recommendation to protein interaction prediction. Recently, Graph Neural Network (GNN)-based link prediction has demonstrated its advantages and achieved the state-of-the-art performance. Typically, GNN-based link prediction can be formulated as a binary classification problem. However, in link prediction, we only have positive data (observed links) and unlabeled data (unobserved links), but no negative data. Therefore, Positive Unlabeled (PU) learning naturally fits the link prediction scenario. Unfortunately, the unknown class prior and data imbalance of networks impede the use of PU learning in link prediction. To deal with these issues, this paper proposes a novel model-agnostic PU learning algorithm for GNN-based link prediction by means of Positive-Unlabeled Area Under the Receiver Operating Characteristic Curve (PU-AUC) optimization. The proposed method is free of class prior estimation and able to handle the data imbalance. Moreover, we propose an accelerated method to reduce the operational complexity of PU-AUC optimization from quadratic to approximately linear. Extensive experiments back up our theoretical analysis and validate that the proposed method is capable of boosting the performance of the state-of-the-art GNN-based link prediction models.},
  archive      = {J_TKDE},
  author       = {Yuren Mao and Yu Hao and Xin Cao and Yunjun Gao and Chang Yao and Xuemin Lin},
  doi          = {10.1109/TKDE.2025.3525490},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1635-1649},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Boosting GNN-based link prediction via PU-AUC optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are large language models really good logical reasoners? a comprehensive evaluation and beyond. <em>TKDE</em>, <em>37</em>(4), 1620-1634. (<a href='https://doi.org/10.1109/TKDE.2025.3536008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical reasoning consistently plays a fundamental and significant role in the domains of knowledge engineering and artificial intelligence. Recently, Large Language Models (LLMs) have emerged as a noteworthy innovation in natural language processing (NLP). However, the question of whether LLMs can effectively address the task of logical reasoning, which requires gradual cognitive inference similar to human intelligence, remains unanswered. To this end, we aim to bridge this gap and provide comprehensive evaluations in this paper. First, to offer systematic evaluations, we select fifteen typical logical reasoning datasets and organize them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include 3 early-era representative LLMs and 4 trending LLMs. Second, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations in objective and subjective manners, covering both answers and explanations, including answer correctness, explain correctness, explain completeness and explain redundancy. Additionally, to uncover the logical flaws of LLMs, problematic cases will be attributed to five error types from two dimensions, i.e., evidence selection process and reasoning process. Third, to avoid the influences of knowledge bias and concentrate purely on benchmarking the logical reasoning capability of LLMs, we propose a new dataset with neutral content. Based on the in-depth evaluations, this paper finally forms a general evaluation scheme of logical reasoning capability from six dimensions (i.e., Correct, Rigorous, Self-aware, Active, Oriented and No hallucination). It reflects the pros and cons of LLMs and gives guiding directions for future works.},
  archive      = {J_TKDE},
  author       = {Fangzhi Xu and Qika Lin and Jiawei Han and Tianzhe Zhao and Jun Liu and Erik Cambria},
  doi          = {10.1109/TKDE.2025.3536008},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1620-1634},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Are large language models really good logical reasoners? a comprehensive evaluation and beyond},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive survey with empirical studies on deep temporal point process. <em>TKDE</em>, <em>37</em>(4), 1599-1619. (<a href='https://doi.org/10.1109/TKDE.2024.3522114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal point process as the stochastic process on a continuous domain of time is commonly used to model the asynchronous event sequence featuring occurrence timestamps. Thanks to the strong expressivity of deep neural networks, they are emerging as a promising choice for capturing the patterns in asynchronous sequences, in the context of temporal point process. In this paper, we first review recent research emphasis and difficulties in modeling asynchronous event sequences with deep temporal point process, which can be concluded into four fields: encoding of history sequence, formulation of conditional intensity function, relational discovery of events, and learning approaches for optimization. We introduce most of the recently proposed models by dismantling them into four parts and conduct experiments by re-modularizing the first three parts with the same learning strategy for a fair empirical evaluation. Besides, we extend the history encoders and conditional intensity function family and propose a Granger causality discovery framework for exploiting the relations among multi-types of events. Because the Granger causality can be represented by the Granger causality graph, discrete graph structure learning in the framework of Variational Inference is employed to reveal latent structures of the graph. Further experiments show that the proposed framework with latent graph discovery can both capture the relations and achieve an improved fitting and predicting performance.},
  archive      = {J_TKDE},
  author       = {Haitao Lin and Cheng Tan and Lirong Wu and Zicheng Liu and Zhangyang Gao and Stan Z. Li},
  doi          = {10.1109/TKDE.2024.3522114},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1599-1619},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An extensive survey with empirical studies on deep temporal point process},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive entire-space multi-scenario multi-task transfer learning model for recommendations. <em>TKDE</em>, <em>37</em>(4), 1585-1598. (<a href='https://doi.org/10.1109/TKDE.2025.3536334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scenario and multi-task recommendation systems efficiently facilitate knowledge transfer across different scenarios and tasks. However, many existing approaches inadequately incorporate personalized information across users and scenarios. Moreover, the conversion rate (CVR) task in multi-task learning often encounters challenges like sample selection bias, resulting from systematic differences between the training and inference sample spaces, and data sparsity due to infrequent clicks. To address these issues, we propose Adaptive Entire-space Multi-scenario Multi-task Transfer Learning model (AEM$^{2}$TL) with four key modules: 1) Scenario-CGC (Scenario-Customized Gate Control), 2) Task-CGC (Task-Customized Gate Control), 3) Personalized Gating Network, and 4) Entire-space Supervised Multi-Task Module. AEM$^{2}$TL employs a multi-gate mechanism to effectively integrate shared and specific information across scenarios and tasks, enhancing prediction adaptability. To further improve task-specific personalization, it incorporates personalized prior features and applies a gating mechanism that dynamically scales the top-layer neural units. A novel post-impression behavior decomposition technique is designed to leverage all impression samples across the entire space, mitigating sample selection bias and data sparsity. Furthermore, an adaptive weighting mechanism dynamically allocates attention to tasks based on their relative importance, ensuring optimal task prioritization. Extensive experiments on one industrial and two real-world public datasets indicate the superiority of AEM$^{2}$TL over state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Qingqing Yi and Jingjing Tang and Xiangyu Zhao and Yujian Zeng and Zengchun Song and Jia Wu},
  doi          = {10.1109/TKDE.2025.3536334},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1585-1598},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An adaptive entire-space multi-scenario multi-task transfer learning model for recommendations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AISFuser: Encoding maritime graphical representations with temporal attribute modeling for vessel trajectory prediction. <em>TKDE</em>, <em>37</em>(4), 1571-1584. (<a href='https://doi.org/10.1109/TKDE.2025.3531770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime transportation, vital for nearly 90% of global trade, necessitates precise vessel trajectory prediction for safety and efficiency. Although the Automatic Identification System (AIS) provides a comprehensive data source, how to model these multi-modal and heterogeneous time-varying sequences (such as vessels’ kinetic information and ocean weather factors) poses a formidable challenge. Moreover, most existing approaches are limited by the confined scope of vessel trajectory modeling, making it impossible to consider the unique characteristics of maritime transportation system. To tackle these challenges, we propose a novel framework called AISFuser to i) encode unique maritime traffic network into graphical representations, and ii) introduce the heterogeneity into multi-modal temporal embeddings through Self-Supervised Learning (SSL). Specifically, our AISFuser is constructed by combining an attention-based graph block with a transformer network to encode information across space and time, respectively. In terms of temporal dimension, one SSL auxiliary task is also designed to enhance the heterogeneity of temporal representations and supplement the main vessel prediction task. We validate the effectiveness of the proposed AISFuser on a real-world AIS dataset. Extensive experimental results demonstrate that our method can forecast multiple attributes of vessel trajectory for over 10 hours into the future, outperforming competitive baselines.},
  archive      = {J_TKDE},
  author       = {Zhiwen Zhang and Wei Yuan and Zipei Fan and Xuan Song and Ryosuke Shibasaki},
  doi          = {10.1109/TKDE.2025.3531770},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1571-1584},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AISFuser: Encoding maritime graphical representations with temporal attribute modeling for vessel trajectory prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized $f$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math>-divergence with applications in pattern classification. <em>TKDE</em>, <em>37</em>(4), 1556-1570. (<a href='https://doi.org/10.1109/TKDE.2025.3530524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multisource information fusion (MSIF), Dempster–Shafer evidence (DSE) theory offers a useful framework for reasoning under uncertainty. However, measuring the divergence between belief functions within this theory remains an unresolved challenge, particularly in managing conflicts in MSIF, which is crucial for enhancing decision-making level. In this paper, several divergence and distance functions are proposed to quantitatively measure discrimination between belief functions in DSE theory, including the reverse evidential KullbackLeibler (REKL) divergence, evidential Jeffrey’s (EJ) divergence, evidential JensenShannon (EJS) divergence, evidential $\chi ^{2}$ (E$\chi ^{2}$) divergence, evidential symmetric $\chi ^{2}$ (ES$\chi ^{2}$) divergence, evidential triangular (ET) discrimination, evidential Hellinger (EH) distance, and evidential total variation (ETV) distance. On this basis, a generalized $f$-divergence, also called the evidential $f$-divergence (Ef divergence), is proposed. Depending on different kernel functions, the Ef divergence degrades into several specific classes: EKL, REKL, EJ, EJS, E$\chi ^{2}$ and ES$\chi ^{2}$ divergences, ET discrimination, and EH and ETV distances. Notably, when basic belief assignments (BBAs) are transformed into probability distributions, these classes of Ef divergence revert to their classical counterparts in statistics and information theory. In addition, several Ef-MSIF algorithms are proposed for pattern classification based on the classes of Ef divergence. These Ef-MSIF algorithms are evaluated on real-world datasets to demonstrate their practical effectiveness in solving classification problems. In summary, this work represents the first attempt to extend classical $f$-divergence within the DSE framework, capitalizing on the distinct properties of BBA functions. Experimental results show that the proposed Ef-MSIF algorithms improve classification accuracy, with the best-performing Ef-MSIF algorithm achieving an overall performance difference approximately 1.22 times smaller than the suboptimal method and 14.12 times smaller than the worst-performing method.},
  archive      = {J_TKDE},
  author       = {Fuyuan Xiao and Weiping Ding and Witold Pedrycz},
  doi          = {10.1109/TKDE.2025.3530524},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1556-1570},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A generalized $f$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math>-divergence with applications in pattern classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial conservative alternating Q-learning for credit card debt collection. <em>TKDE</em>, <em>37</em>(4), 1542-1555. (<a href='https://doi.org/10.1109/TKDE.2025.3528219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Debt collection is utilized for risk control after credit card delinquency. The existing rule-based method tends to be myopic and non-adaptive due to the delayed feedback. Reinforcement learning (RL) has an inherent advantage in dealing with such task and can learn policies end-to-end. However, employing RL here remains difficult because of different interaction processes from standard RL and the notorious problem of optimistic estimations in the offline setting. To tackle these challenges, we first propose an Alternating Q-Learning (AQL) framework to adapt debt collection processes to comparable procedures in RL. Based on AQL, we further develop an Adversarial Conservative Alternating Q-Learning (ACAQL) to address the issue of overoptimistic estimations. Specifically, adversarial conservative value regularization is proposed to balance optimism and conservatism on Q-values of out-of-distribution actions. Furthermore, ACAQL utilizes the counterfactual action stitching to mitigate the overestimation by enhancing behavior data. Finally, we evaluate ACAQL on a real-world dataset created from Bank of Shanghai. Offline experimental results show that our approach outperforms state-of-the-art methods and effectively alleviates the optimistic estimation issue. Moreover, we conduct online A/B tests on the bank, and ACAQL achieves at least a 6% improvement of the debt recovery rate, which yields tangible economic benefits.},
  archive      = {J_TKDE},
  author       = {Wenhui Liu and Jiapeng Zhu and Lyu Ni and Jingyu Bi and Zhijian Wu and Jiajie Long and Mengyao Gao and Dingjiang Huang and Shuigeng Zhou},
  doi          = {10.1109/TKDE.2025.3528219},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1542-1555},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adversarial conservative alternating Q-learning for credit card debt collection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning in imbalanced data streams with unpredictable feature evolution. <em>TKDE</em>, <em>37</em>(4), 1527-1541. (<a href='https://doi.org/10.1109/TKDE.2025.3531431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from data streams collected sequentially over time are widely spread in real-world applications. Previous methods typically assume that the data stream has a feature space with a fixed or clearly defined evolution pattern, as well as a balanced class distribution. However, in many practical scenarios, such as environmental monitoring systems, the frequency of anomalous events is significantly imbalanced compared to normal ones and the feature space dynamically changes due to ecological evolution and sensor lifespan. To alleviate this important but rarely studied problem, we propose the Adaptive Learning in Imbalace data streams with Unpredictable feature evolution (ALIU) algorithm. As data streams with imbalanced class distribution arrive, ALIU first mitigates the model's bias for the majority class by reweighting the adaptive gradient descent magnitudes between different classes. Then, a new loss function is proposed that simultaneously focuses on misclassifications and maintains model robustness. Further, when imbalanced data streams arrive with feature evolutions, we reuse the previously learned model and update the incomplete and augmented features by adopting the adaptive gradient strategy and ensemble method, respectively. Finally, we utilize the projected technique to build a sparse yet efficient model. Based on a few common and mild assumptions, we theoretically analyze that the ALIU satisfies a sub-linear regret bound under both convex and strong convex loss functions and the performance of model can be improved with the assistance of old features. Besides, extensive experimental results further demonstrate the effectiveness of our proposed algorithm.},
  archive      = {J_TKDE},
  author       = {Jiahang Tu and Xijia Tang and Shilin Gu and Yucong Dai and Ruidong Fan and Chenping Hou},
  doi          = {10.1109/TKDE.2025.3531431},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1527-1541},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive learning in imbalanced data streams with unpredictable feature evolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving top-$K$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math>-fairness for finding global top-$K$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math> frequent items. <em>TKDE</em>, <em>37</em>(4), 1508-1526. (<a href='https://doi.org/10.1109/TKDE.2024.3523033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding top-$K$ frequent items has been a hot topic in data stream processing with wide-ranging applications. However, most existing sketch algorithms focus on finding local top-$K$ in a single data stream. In this paper, we tackle finding global top-$K$ across multiple data streams. We find that using prior sketch algorithms directly is often unfair in global scenarios, degrading global top-$K$ accuracy. We define top-$K$-fairness and show its importance for finding global top-$K$. To achieve this, we propose the Double-Anonymous (DA) sketch, where double-anonymity ensures fairness. We also propose two techniques, hot-filtering and early-freezing, to improve accuracy further. We theoretically prove that the DA sketch achieves top-$K$-fairness while maintaining high accuracy. Extensive experiments verify top-$K$-fairness in disjoint data streams, showing that the DA sketch's error is up to 129 times (60 times on average) smaller than the state-of-the-art. To enhance the applicability and technical depth, we also investigate how to extend the DA sketch to general distributed data stream scenarios and how to provide a fairer and more accurate global ranking for top-$K$ items. The experimental results show that the extended version of the DA sketch can indeed compute better rankings and still has significant advantages in general data streams.},
  archive      = {J_TKDE},
  author       = {Yikai Zhao and Wei Zhou and Wenchen Han and Zheng Zhong and Yinda Zhang and Xiuqi Zheng and Tong Yang and Bin Cui},
  doi          = {10.1109/TKDE.2024.3523033},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {4},
  number       = {4},
  pages        = {1508-1526},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Achieving top-$K$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math>-fairness for finding global top-$K$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math> frequent items},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Web-FTP: A feature transferring-based pre-trained model for web attack detection. <em>TKDE</em>, <em>37</em>(3), 1495-1507. (<a href='https://doi.org/10.1109/TKDE.2024.3512793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web attack is a major threat to cyberspace security, so web attack detection models have become a critical task. Traditional supervised learning methods learn features of web attacks with large amounts of high-confidence labeled data, which are extremely expensive in the real world. Pre-trained models offer a novel solution with their ability to learn generic features on large unlabeled datasets. However, designing and deploying a pre-trained model for real-world web attack detection remains challenges. In this paper, we present a pre-trained model for web attack detection, including a pre-processing module, a pre-training module, and a deployment scheme. Our model significantly improves classification performance on several web attack detection datasets. Moreover, we deploy the model in real-world systems and show its potential for industrial applications.},
  archive      = {J_TKDE},
  author       = {Zhenyu Guo and Qinghua Shang and Xin Li and Chengyi Li and Zijian Zhang and Zhuo Zhang and Jingjing Hu and Jincheng An and Chuanming Huang and Yang Chen and Yuguang Cai},
  doi          = {10.1109/TKDE.2024.3512793},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1495-1507},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Web-FTP: A feature transferring-based pre-trained model for web attack detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniTE: A survey and unified pipeline for pre-training spatiotemporal trajectory embeddings. <em>TKDE</em>, <em>37</em>(3), 1475-1494. (<a href='https://doi.org/10.1109/TKDE.2024.3523996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal trajectories are sequences of timestamped locations, which enable a variety of analyses that in turn enable important real-world applications. It is common to map trajectories to vectors, called embeddings, before subsequent analyses. Thus, the qualities of embeddings are very important. Methods for pre-training embeddings, which leverage unlabeled trajectories for training universal embeddings, have shown promising applicability across different tasks, thus attracting considerable interest. However, research progress on this topic faces two key challenges: a lack of a comprehensive overview of existing methods, resulting in several related methods not being well-recognized, and the absence of a unified pipeline, complicating the development of new methods and the analysis of methods. We present UniTE, a survey and a unified pipeline for this domain. In doing so, we present a comprehensive list of existing methods for pre-training trajectory embeddings, which includes methods that either explicitly or implicitly employ pre-training techniques. Further, we present a unified and modular pipeline with publicly available underlying code, simplifying the process of constructing and evaluating methods for pre-training trajectory embeddings. Additionally, we contribute a selection of experimental results using the proposed pipeline on real-world datasets.},
  archive      = {J_TKDE},
  author       = {Yan Lin and Zeyu Zhou and Yicheng Liu and Haochen Lv and Haomin Wen and Tianyi Li and Yushuai Li and Christian S. Jensen and Shengnan Guo and Youfang Lin and Huaiyu Wan},
  doi          = {10.1109/TKDE.2024.3523996},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1475-1494},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {UniTE: A survey and unified pipeline for pre-training spatiotemporal trajectory embeddings},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The expressive power of graph neural networks: A survey. <em>TKDE</em>, <em>37</em>(3), 1455-1474. (<a href='https://doi.org/10.1109/TKDE.2024.3523700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are effective machine learning models for many graph-related applications. Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., Graph feature enhancement, Graph topology enhancement, and GNNs architecture enhancement.},
  archive      = {J_TKDE},
  author       = {Bingxu Zhang and Changjun Fan and Shixuan Liu and Kuihua Huang and Xiang Zhao and Jincai Huang and Zhong Liu},
  doi          = {10.1109/TKDE.2024.3523700},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1455-1474},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {The expressive power of graph neural networks: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-correcting clustering. <em>TKDE</em>, <em>37</em>(3), 1439-1454. (<a href='https://doi.org/10.1109/TKDE.2024.3523021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of target distribution significantly enhances the success of deep clustering. However, most of the related deep clustering methods suffer from two drawbacks: (1) manually-designed target distribution functions with uncertain performance and (2) cluster misassignment accumulation. To address these issues, a Self-Correcting Clustering (Self-CC) framework is proposed. In Self-CC, a robust target distribution solver (RTDS) is designed to automatically predict the target distribution and alleviate the adverse influence of misassignments. Specifically, RTDS divides the high confidence samples selected according to the cluster assignments predicted by a clustering module into labeled samples with correct pseudo labels and unlabeled samples of possible misassignments by modeling its training loss distribution. With the divided data, RTDS can be trained in a semi-supervised way. The critical hyperparameter which controls the semi-supervised training process can be set adaptively by estimating the distribution property of misassignments in the pseudo-label space with the support of a theoretical analysis. The target distribution can be predicted by the well-trained RTDS automatically, optimizing the clustering module and correcting misassignments in the cluster assignments. The clustering module and RTDS mutually promote each other forming a positive feedback loop. Extensive experiments on four benchmark datasets demonstrate the effectiveness of the proposed Self-CC.},
  archive      = {J_TKDE},
  author       = {Hanxuan Wang and Na Lu and Zixuan Wang and Yuxuan Yan and Gustavo Carneiro and Zhen Wang},
  doi          = {10.1109/TKDE.2024.3523021},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1439-1454},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Self-correcting clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmented sequence prediction using variable-order markov model ensemble. <em>TKDE</em>, <em>37</em>(3), 1425-1438. (<a href='https://doi.org/10.1109/TKDE.2024.3522975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, sequence prediction, particularly in natural language processing tasks, has made significant progress due to advanced neural network architectures like Transformer and enhanced computing power. However, challenges persist in modeling and analyzing certain types of sequence data, such as human daily activities and competitive ball games. These segmented sequence data are characterized by short length, varying local dependencies, and coarse-grained unit states. These characteristics limit the effectiveness of conventional probabilistic graphical models and attention-based or recurrent neural networks in modeling and analyzing segmented sequence data. To address this gap, we introduce a novel generative model for segmented sequences, employing an ensemble of multiple variable-order Markov models (VOMMs) to flexibly represent state transition dependencies. Our approach integrates probabilistic graphical models with neural networks, surpassing the representation capabilities of single high-order or variable-order Markov models. Compared to end-to-end deep learning models, our method offers improved interpretability and reduces overfitting in short segments. We demonstrate the efficacy of our proposed method in two tasks: predicting tennis shot types and forecasting daily action sequences. These applications highlight the broad applicability of our segmented sequence modeling approach across diverse domains.},
  archive      = {J_TKDE},
  author       = {Weichao Yan and Hao Ma and Zaiyue Yang},
  doi          = {10.1109/TKDE.2024.3522975},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1425-1438},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Segmented sequence prediction using variable-order markov model ensemble},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust and communication-efficient federated domain adaptation via random features. <em>TKDE</em>, <em>37</em>(3), 1411-1424. (<a href='https://doi.org/10.1109/TKDE.2024.3510296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning (ML) models have grown to a scale where training them on a single machine becomes impractical. As a result, there is a growing trend to leverage federated learning (FL) techniques to train large ML models in a distributed and collaborative manner. These models, however, when deployed on new devices, might struggle to generalize well due to domain shifts. In this context, federated domain adaptation (FDA) emerges as a powerful approach to address this challenge. Most existing FDA approaches typically focus on aligning the distributions between source and target domains by minimizing their (e.g., MMD) distance. Such strategies, however, inevitably introduce high communication overheads and can be highly sensitive to network reliability. In this paper, we introduce RF-TCA, an enhancement to the standard Transfer Component Analysis approach that significantly accelerates computation without compromising theoretical and empirical performance. Leveraging the computational advantage of RF-TCA, we further extend it to FDA setting with FedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that is independent of the sample size, while maintaining performance that is either comparable to or even surpasses state-of-the-art FDA methods. We present extensive experiments to showcase the superior performance and robustness (to network condition) of FedRF-TCA.},
  archive      = {J_TKDE},
  author       = {Zhanbo Feng and Yuanjie Wang and Jie Li and Fan Yang and Jiong Lou and Tiebin Mi and Robert Caiming Qiu and Zhenyu Liao},
  doi          = {10.1109/TKDE.2024.3510296},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1411-1424},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust and communication-efficient federated domain adaptation via random features},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RMD-graph: Adversarial attacks resisting malicious domain detection based on dual denoising. <em>TKDE</em>, <em>37</em>(3), 1394-1410. (<a href='https://doi.org/10.1109/TKDE.2024.3520798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Domain Name System (DNS) is a critical Internet service that translates domain names into IPs, but it is often targeted by attackers, posing a serious security risk. Graph-based models for detecting malicious domains have shown high performance but are vulnerable to adversarial attacks. To address this issue, we propose RMD-Graph, which is characterized by its ability to resist adversarial attacks and its low dependency on labeled data. A dual denoising module is specifically designed based on two autoencoders to generate the reconstructed graph, where SVD, TOP-k and reconstruction loss are introduced to enhance the denoising capability of autoencoders. Subsequently, residual connections are employed to generate an optimized graph that retains essential information from the original graph. The reconstructed graph and the optimized graph are then utilized as two views for graph contrastive learning, thereby achieving an self-supervised representation learning task without labels. In the downstream malicious domain detection, the denoised node representations are employed for machine learning classification. Extensive experiments are conducted on publicly available DNS datasets, and the results demonstrate that RMD-Graph significantly outperforms known baseline methods, especially in adversarial scenarios.},
  archive      = {J_TKDE},
  author       = {Sanfeng Zhang and Luyao Huang and Zheng Zhang and Wenduan Xu and Wang Yang and Linfeng Liu},
  doi          = {10.1109/TKDE.2024.3520798},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1394-1410},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RMD-graph: Adversarial attacks resisting malicious domain detection based on dual denoising},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nowhere to H2IDE: Fraud detection from multi-relation graphs via disentangled homophily and heterophily identification. <em>TKDE</em>, <em>37</em>(3), 1380-1393. (<a href='https://doi.org/10.1109/TKDE.2024.3523107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection has always been one of the primary concerns in social and economic activities and is becoming a decisive force in the booming digital economy. Graph structures formed by rich user interactions naturally serve as important clues for identifying fraudsters. While numerous graph neural network-based methods have been proposed, the diverse interactive connections within graphs and the heterophilic connections deliberately established by fraudsters to normal users as camouflage pose new research challenges. In this light, we propose H2IDE (Homophily and Heterophily Identification with Disentangled Embeddings) for accurate fraud detection in multi-relation graphs. H2IDE features in an independence-constrained disentangled representation learning scheme to capture various latent behavioral patterns in graphs, along with a supervised identification task to specifically model the factor-wise heterophilic connections, both of which are proven crucial to fraud detection. We also design a relation-aware attention mechanism for hierarchical and adaptive neighborhood aggregation in H2IDE. Extensive comparative experiments with state-of-the-art baseline methods on two real-world multi-relation graphs and two large-scale homogeneous graphs demonstrate the superiority and scalability of our proposed method and highlight the key role of disentangled representation learning with homophily and heterophily identification.},
  archive      = {J_TKDE},
  author       = {Chao Fu and Guannan Liu and Kun Yuan and Junjie Wu},
  doi          = {10.1109/TKDE.2024.3523107},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1380-1393},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Nowhere to H2IDE: Fraud detection from multi-relation graphs via disentangled homophily and heterophily identification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next point-of-interest recommendation with adaptive graph contrastive learning. <em>TKDE</em>, <em>37</em>(3), 1366-1379. (<a href='https://doi.org/10.1109/TKDE.2024.3509480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next point-of-interest (POI) recommendation predicts user’s next movement and facilitates location-based applications such as destination suggestion and travel planning. State-of-the-art (SOTA) methods learn an adaptive graph from user trajectories and compute POI representations using graph neural networks (GNNs). However, a single graph cannot capture the diverse dependencies among the POIs (e.g., geographical proximity and transition frequency). To tackle this limitation, we propose the Adaptive Graph Contrastive Learning (AGCL) framework. AGCL constructs multiple adaptive graphs, each modeling a kind of POI dependency and producing one POI representation; and the POI representations from different graphs are merged into a multi-facet representation that encodes comprehensive information. To train the POI representations, we tailor a graph-based contrastive learning, which encourages the representations of similar POIs to align and dissimilar POIs to differentiate. Moreover, to learn the sequential regularities of user trajectories, we design an attention mechanism to integrate spatial-temporal information into the POI representations. An explicit spatial-temporal bias is also employed to adjust the predictions for enhanced accuracy. We compare AGCL with 10 state-of-the-art baselines on 3 datasets. The results show that AGCL outperforms all baselines and achieves an improvement of 10.14% over the best performing baseline in average accuracy.},
  archive      = {J_TKDE},
  author       = {Xuan Rao and Renhe Jiang and Shuo Shang and Lisi Chen and Peng Han and Bin Yao and Panos Kalnis},
  doi          = {10.1109/TKDE.2024.3509480},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1366-1379},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Next point-of-interest recommendation with adaptive graph contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network-to-network: Self-supervised network representation learning via position prediction. <em>TKDE</em>, <em>37</em>(3), 1354-1365. (<a href='https://doi.org/10.1109/TKDE.2024.3493391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Representation Learning (NRL) has achieved remarkable success in learning low-dimensional representations for network nodes. However, most NRL methods, including Graph Neural Networks (GNNs) and their variants, face critical challenges. First, labeled network data, which are required for training most GNNs, are expensive to obtain. Second, existing methods are sub-optimal in preserving comprehensive topological information, including structural and positional information. Finally, most GNN approaches ignore the rich node content information. To address these challenges, we propose a self-supervised Network-to-Network framework (Net2Net) to learn semantically meaningful node representations. Our framework employs a pretext task of node position prediction (PosPredict) to effectively fuse the topological and content knowledge into low-dimensional embeddings for every node in a semi-supervised manner. Specifically, we regard a network as node content and position networks, where Net2Net aims to learn the mapping between them. We utilize a multi-layer recursively composable encoder to integrate the content and topological knowledge into the egocentric network node embeddings. Furthermore, we design a cross-modal decoder to map the egocentric node embeddings into their node position identities (PosIDs) in the node position network. Extensive experiments on eight diverse networks demonstrate the superiority of Net2Net over comparable methods.},
  archive      = {J_TKDE},
  author       = {Jie Liu and Chunhai Zhang and Zhicheng He and Wenzheng Zhang and Na Li},
  doi          = {10.1109/TKDE.2024.3493391},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1354-1365},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Network-to-network: Self-supervised network representation learning via position prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-grade revenue maximization for promotional and competitive viral marketing in social networks. <em>TKDE</em>, <em>37</em>(3), 1339-1353. (<a href='https://doi.org/10.1109/TKDE.2024.3518359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of revenue maximization (RM) for multi-grade products in social networks by considering pricing, seed selection, and coupon distribution. Previous works on RM often focus on a single product and neglect the use of coupons for promotion. We propose a new optimization problem, Revenue Maximization of Multi-Grade Product(RMMGP), to simultaneously determine pricing, seed selection, and coupon distribution for multi-grade products with both promotional and competitive relationships between grades in order to maximize revenue through viral marketing. We prove the hardness and inapproximability of RMMGP and show that the revenue function is not monotone or submodular. To solve RMMGP, we design an approximation algorithm, namely Data-Dependent Revenue Maximization (DDRM), and propose the Pricing-Seeding-Coupon allocation (PriSCa) algorithm, which uses the concepts of Worth Receiving Probability, Pricing-Promotion Alternating Framework, and Independent/Holistic Customer-Grade Determinant sets. Our experiments on real social networks, using valuation distributions from Amazon.com, demonstrate that PriSCa and DDRM achieve on average 1.5 times higher revenue than state-of-the-art approaches. Additionally, PriSCa is efficient and scalable on large datasets.},
  archive      = {J_TKDE},
  author       = {Ya-Wen Teng and Yishuo Shi and De-Nian Yang and Chih-Hua Tai and Philip S. Yu and Ming-Syan Chen},
  doi          = {10.1109/TKDE.2024.3518359},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1339-1353},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-grade revenue maximization for promotional and competitive viral marketing in social networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-behavior hypergraph contrastive learning for session-based recommendation. <em>TKDE</em>, <em>37</em>(3), 1325-1338. (<a href='https://doi.org/10.1109/TKDE.2024.3523383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current session-based recommendations model session sequences solely based on the user's target behavior, ignoring the user's hidden preferences in auxiliary behaviors. Additionally, they use ordinary graphs to model one-to-one item correlations in the current session and fail to leverage other sessions to learn richer higher-order item correlations. To address these issues, a multi-behavior hypergraph contrastive learning model for session-based recommendations is proposed. This model represents all the sessions as global hypergraphs according to two types of behavior sequences. It employs contrastive learning to obtain global item embeddings, which are further aggregated to generate a global session representation that captures higher-order correlations of items from all session perspectives. A novel local heterogeneous hypergraph is designed for the current session to capture higher-order correlations between items with different behaviors in the current session, thus enhancing the local session representation. Additionally, a novel self-supervised signal is created by constructing a multi-behavior line graph, enhancing the global session representation. Finally, the local session representation, global session representation, and global item embedding are used to learn the predicted interaction probability of each item. Extensive experiments are conducted on three real datasets, and the results demonstrate that the proposed model significantly improves recommendation accuracy.},
  archive      = {J_TKDE},
  author       = {Liangmin Guo and Shiming Zhou and Haiyue Tang and Xiaoyao Zheng and Yonglong Luo},
  doi          = {10.1109/TKDE.2024.3523383},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1325-1338},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-behavior hypergraph contrastive learning for session-based recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MimoSketch: A framework for frequency-based mining tasks on multiple nodes with sketches. <em>TKDE</em>, <em>37</em>(3), 1311-1324. (<a href='https://doi.org/10.1109/TKDE.2024.3523034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In distributed data stream mining, we abstract a MIMO scenario where a stream of multiple items is mined by multiple nodes. We design a framework named MimoSketch for the MIMO-specific scenario, which improves the fundamental mining tasks of item frequency estimation, item size distribution estimation, heavy hitter detection, heavy change detection, and entropy estimation. MimoSketch consists of an algorithm design and a policy to schedule items to nodes. MimoSketch's algorithm applies random counting to preserve a mathematically proven unbiasedness property, which makes it friendly to the aggregate query on multiple nodes; its memory layout is dynamically adaptive to the runtime item size distribution, which maximizes the estimation accuracy by storing more items. MimoSketch's scheduling policy balances items among nodes, avoiding nodes being overloaded or underloaded, which improves the overall mining accuracy. Our prototype and evaluation show that our algorithm can improve the accuracy of five typical mining tasks by an order of magnitude compared with the state-of-the-art solutions, and the scheduling policy further promotes the performance in MIMO scenarios.},
  archive      = {J_TKDE},
  author       = {Wenfei Wu and Yuchen Xu},
  doi          = {10.1109/TKDE.2024.3523034},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1311-1324},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MimoSketch: A framework for frequency-based mining tasks on multiple nodes with sketches},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing influence query over indoor trajectories. <em>TKDE</em>, <em>37</em>(3), 1294-1310. (<a href='https://doi.org/10.1109/TKDE.2024.3514323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing Influence (Max-Inf) query is a fundamental operation in spatial data management. This query returns an optimal site from a candidate set to maximize its influence. Existing work commonly focuses on outdoor spaces. In practice, however, people spend up to 87% of their daily life inside indoor spaces. The outdoor techniques fall short in indoor spaces due to the complicated topology of indoor spaces. In this paper, we formulate two indoor Max-Inf queries: Top-$k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math> Probabilistic Influence Query (T$k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>PI) and Collective-$k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math> Probabilistic Influence Query (C$k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>PI) taking probability and mobility factors into consideration. We propose a novel spatial index, IT-tree, which utilizes the properties of indoor venues to facilitate the indoor distance computation, and then applies a trie to further organize the trajectories with similar check-in partitions together, based on their sketch information. This structure is simple but highly effective in pruning the trajectory search space. To process T$k$PI efficiently, we devise subtree pruning and progressive pruning techniques to delicately filter out unnecessary trajectories based on probability bounds and the monotonicity of influence probability. For C$k$PI queries, which is a submodular NP-hard problem, three approximation algorithms are provided with different strategies of computing marginal influence value during the search. Through extensive experiments on several real indoor venues, we demonstrate the efficiency and effectiveness of our proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Jian Chen and Hong Gao and Yuhong Shi and Junle Chen and Donghua Yang and Jianzhong Li},
  doi          = {10.1109/TKDE.2024.3514323},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1294-1310},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Maximizing influence query over indoor trajectories},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LDGI: Location-discriminative geo-indistinguishability for location privacy. <em>TKDE</em>, <em>37</em>(3), 1282-1293. (<a href='https://doi.org/10.1109/TKDE.2024.3522320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geo-Indistinguishability (GI) is a powerful privacy model that can effectively protect location information by limiting the ability of an attacker to infer a user's true location. In real life, locations usually have different sensitive levels in terms of privacy; for example, shopping malls might be low-sensitive while home addresses might be high-sensitive for users. But the GI model does not consider the various sensitive levels of locations, and implements the same perturbation on all locations to meet the highest privacy requirement. This would cause overprotection of low-sensitive locations and reduce data utility. To strike a good balance between privacy and utility, in this paper, we propose a novel privacy notion, termed Location-Discriminative Geo-Indistinguishability (LDGI), which takes into account different sensitive levels of location privacy. With LDGI model, we then develop a perturbation scheme called EM-LDGI based on the exponential mechanism, and an advance scheme MinQL to further enhance data utility. To improve the efficiency of the proposed schemes, we design a scheme MinQL-S with the assistance of the spanner graph, at the cost of a slight utility degradation. We theoretically analyze that the proposed schemes satisfy LDGI and evaluate their performance by extensive experiments on both synthetic and real datasets. The comparison with GI mechanisms demonstrates the advantages of the LDGI model.},
  archive      = {J_TKDE},
  author       = {Youwen Zhu and Yuanyuan Hong and Qiao Xue and Xiao Lan and Yushu Zhang and Yong Xiang},
  doi          = {10.1109/TKDE.2024.3522320},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1282-1293},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LDGI: Location-discriminative geo-indistinguishability for location privacy},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-aware causal feature selection. <em>TKDE</em>, <em>37</em>(3), 1268-1281. (<a href='https://doi.org/10.1109/TKDE.2024.3522580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal feature selection has recently received increasing attention in machine learning and data mining, especially in the era of Big Data. Existing causal feature selection algorithms select unique causal features of the single class label as the optimal feature subset. However, a single class label usually has multiple classes, and it is unreasonable to select the same causal features for different classes of a single class label. To address this problem, we employ the class-specific mutual information to evaluate the causal information carried by each class of the single class label, and theoretically analyze the unique relationship between each class and the causal features. Based on this, a Label-aware Causal Feature Selection algorithm (LaCFS) is proposed to identifies the causal features for each class of the class label. Specifically, LaCFS uses the pairwise comparisons of class-specific mutual information and the size of class-specific mutual information values from the perspective of each class, and follows a divide-and-conquer framework to find causal features. The correctness and application condition of LaCFS are theoretically proved, and extensive experiments are conducted to demonstrate the efficiency and superiority of LaCFS compared to the state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Zhaolong Ling and Jingxuan Wu and Yiwen Zhang and Peng Zhou and Xingyu Wu and Kui Yu and Xindong Wu},
  doi          = {10.1109/TKDE.2024.3522580},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1268-1281},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Label-aware causal feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic graph contrastive learning for collaborative filtering. <em>TKDE</em>, <em>37</em>(3), 1255-1267. (<a href='https://doi.org/10.1109/TKDE.2024.3522960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperbolic space based collaborative filtering has emerged as a popular topic in recommender systems. Compared to the euclidean space, hyperbolic space is more suitable to the tree-like structures in the user-item interactions and can achieve better recommender performance. Although some works have been devoted to this popular topic and made some progresses, they use tangent space as an approximation of hyperbolic space to implement model. Despite the effectiveness, such methods fail to fully exploit the advantages of hyperbolic space and still suffer from the data sparsity issue, which severely limits the recommender performance. To tackle these problems, we refer to the self-supervised learning technique and novelly propose a Hyperbolic Graph Contrastive Learning (HyperCL) framework. Specifically, our framework encodes the augmentation views from both the tangent space and the hyperbolic space, and construct the contrast pairs based on their corresponding learned node representations. Our model not only leverages the geometric advantages of both sides but also achieves seamless information transmission between the two spaces. Extensive experimental results on public benchmark datasets demonstrate that our model is highly competitive and outperforms leading baselines by considerable margins. Further experiments validate the robustness and the superiority of contrastive learning paradigm.},
  archive      = {J_TKDE},
  author       = {Zhida Qin and Wentao Cheng and Wenxing Ding and Gangyi Ding},
  doi          = {10.1109/TKDE.2024.3522960},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1255-1267},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hyperbolic graph contrastive learning for collaborative filtering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-agent meta-reinforcement learning for cross-channel bidding. <em>TKDE</em>, <em>37</em>(3), 1241-1254. (<a href='https://doi.org/10.1109/TKDE.2024.3523472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time bidding (RTB) plays a pivotal role in online advertising ecosystems. Advertisers employ strategic bidding to optimize their advertising impact while adhering to various financial constraints, such as the return-on-investment (ROI) and cost-per-click (CPC). Primarily focusing on bidding with fixed budget constraints, traditional approaches cannot effectively manage the dynamic budget allocation problem where the goal is to achieve global optimization of bidding performance across multiple channels with a shared budget. In this paper, we propose a hierarchical multi-agent reinforcement learning framework for multi-channel bidding optimization. In this framework, the top-level strategy applies a CPC constrained diffusion model to dynamically allocate budgets among the channels according to their distinct features and complex interdependencies, while the bottom-level strategy adopts a state-action decoupled actor-critic method to address the problem of extrapolation errors in offline learning caused by out-of-distribution actions and a context-based meta-channel knowledge learning method to improve the state representation capability of the policy based on the shared knowledge among different channels. Comprehensive experiments conducted on a large scale real-world industrial dataset from the Meituan ad bidding platform demonstrate that our method achieves a state-of-the-art performance.},
  archive      = {J_TKDE},
  author       = {Shenghong He and Chao Yu and Qian Lin and Shangqin Mao and Bo Tang and Qianlong Xie and Xingxing Wang},
  doi          = {10.1109/TKDE.2024.3523472},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1241-1254},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical multi-agent meta-reinforcement learning for cross-channel bidding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HidAttack: An effective and undetectable model poisoning attack to federated recommenders. <em>TKDE</em>, <em>37</em>(3), 1227-1240. (<a href='https://doi.org/10.1109/TKDE.2024.3522763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy concerns in recommender systems are potentially addressed due to constitutional and commercial requirements. Centralized recommendation models are susceptible to poisoning attacks, which threaten their integrity. In this context, federated learning has emerged as an optimal solution to privacy concerns. However, recent investigations proved that Federated Recommender Systems (FedRS) are also vulnerable to model poisoning attacks. Existing attack possibilities highlighted in academic literature require a large fraction of Byzantine clients to effectively influence the training process, which is unrealistic for practical systems with millions of users. Additionally, most attack models neglected the role of the defense mechanism running at the aggregation server. To this end, we propose a novel undetectable hidden attack strategy (HidAttack) for FedRS, aiming to raise the exposure ratio of targeted items with minimum Byzantine clients. To achieve this goal, we construct a cluster of baseline attacks, on top of which a bandit model is designed that intelligently infers effective poisoned gradients. It ensures a diverse pattern of poisoned gradients and therefore, Byzantine clients cannot be distinguished from benign clients by the defense mechanism. Extensive experiments demonstrate that: 1) our attack model significantly increases the target item's exposure rate covertly without compromising the recommendation accuracy and 2) the current defenses are insufficient, emphasizing the need for better security improvements against our model poisoning attack to FedRS.},
  archive      = {J_TKDE},
  author       = {Waqar Ali and Khalid Umer and Xiangmin Zhou and Jie Shao},
  doi          = {10.1109/TKDE.2024.3522763},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1227-1240},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HidAttack: An effective and undetectable model poisoning attack to federated recommenders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSM-EL: A generalizable symbol-manipulation approach for entity linking. <em>TKDE</em>, <em>37</em>(3), 1213-1226. (<a href='https://doi.org/10.1109/TKDE.2024.3523399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking (EL) is a challenging task as it typically requires matching an ambiguous entity mention with its corresponding entity in a knowledge base (KB). The mainstream studies focus on learning and evaluating linking models on the same corpus and obtained significant performance achievement, however, they often overlook the generalization ability to out-of-domain corpus, which is more realistic yet much more challenging. To address this issue, we introduce a novel neural-symbolic model for entity linking, which is inspired by the symbol-manipulation mechanism in human brains. Specifically, we abstract diverse features into unified variables, then combine them using neural operators to capture diverse relevance requirements, and finally aggregate relevance scores through voting. We conduct experiments on eleven benchmark datasets with different types of text, and the results show that our method outperforms nearly all baselines. Notably, the best performance of our method on seven out-of-domain datasets highlights its generalization ability.},
  archive      = {J_TKDE},
  author       = {Xueqi Cheng and Yuanzheng Wang and Yixing Fan and Jiafeng Guo and Ruqing Zhang and Keping Bi},
  doi          = {10.1109/TKDE.2024.3523399},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1213-1226},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GSM-EL: A generalizable symbol-manipulation approach for entity linking},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph percolation embeddings for efficient knowledge graph inductive reasoning. <em>TKDE</em>, <em>37</em>(3), 1198-1212. (<a href='https://doi.org/10.1109/TKDE.2024.3508064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Graph Neural Networks (GNNs)-based embedding techniques for knowledge graph (KG) reasoning. For the first time, we link the path redundancy issue in the state-of-the-art path encoding-based models to the transformation error in model training, which brings us new theoretical insights into KG reasoning, as well as high efficacy in practice. On the theoretical side, we analyze the entropy of transformation error in KG paths and point out query-specific redundant paths causing entropy increases. These findings guide us to maintain the shortest paths and remove redundant paths for minimized-entropy message passing. To achieve this goal, on the practical side, we propose an efficient Graph Percolation process motivated by the percolation phenomenon in Fluid Mechanics, and design a lightweight GNN-based KG reasoning framework called Graph Percolation Embeddings (GraPE)1. GraPE outperforms state-of-the-art methods in both transductive and inductive reasoning tasks, while requiring fewer training parameters and less inference time.},
  archive      = {J_TKDE},
  author       = {Kai Wang and Dan Lin and Siqiang Luo},
  doi          = {10.1109/TKDE.2024.3508064},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1198-1212},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph percolation embeddings for efficient knowledge graph inductive reasoning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy granule density-based outlier detection with multi-scale granular balls. <em>TKDE</em>, <em>37</em>(3), 1182-1197. (<a href='https://doi.org/10.1109/TKDE.2024.3525003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index.},
  archive      = {J_TKDE},
  author       = {Can Gao and Xiaofeng Tan and Jie Zhou and Weiping Ding and Witold Pedrycz},
  doi          = {10.1109/TKDE.2024.3525003},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1182-1197},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fuzzy granule density-based outlier detection with multi-scale granular balls},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRAME: Feature rectification for class imbalance learning. <em>TKDE</em>, <em>37</em>(3), 1167-1181. (<a href='https://doi.org/10.1109/TKDE.2024.3523043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance learning is a challenging task in machine learning applications. To balance training data, traditional class imbalance learning approaches, such as class resampling or reweighting, are commonly applied in the literature. However, these methods can have significant limitations, particularly in the presence of noisy data, missing values, or when applied to advanced learning paradigms like semi-supervised or federated learning. To address these limitations, this paper proposes a novel and theoretically-ensured latent Feature Rectification method for clAss iMbalance lEarning (FRAME). The proposed FRAME can automatically learn multiple centroids for each class in the latent space and then perform class balancing. Unlike data-level methods, FRAME balances feature in the latent space rather than the original space. Compared to algorithm-level methods, FRAME can distinguish different classes based on distance without the need to adjust the learning algorithms. Through latent feature rectification, FRAME can effectively mitigate contaminated noises/missing values without worrying about structural variations in the data. In order to accommodate a wider range of applications, this paper extends FRAME to the following three main learning paradigms: fully-supervised learning, semi-supervised learning, and federated learning. Extensive experiments on 10 binary-class datasets demonstrate that our FRAME can achieve competitive performance than the state-of-the-art methods and its robustness to noises/missing values.},
  archive      = {J_TKDE},
  author       = {Xu Cheng and Fan Shi and Yao Zhang and Huan Li and Xiufeng Liu and Shengyong Chen},
  doi          = {10.1109/TKDE.2024.3523043},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1167-1181},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FRAME: Feature rectification for class imbalance learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early detection of malicious crypto addresses with asset path tracing and selection. <em>TKDE</em>, <em>37</em>(3), 1154-1166. (<a href='https://doi.org/10.1109/TKDE.2024.3522772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the burgeoning cryptocurrency sector and its associated financial risks, there is a growing focus on detecting fraudulent activities and malicious addresses. Traditional studies are limited by their reliance on comprehensive historical data and address-wise manipulation, which are not available for early malice detection and fail to identify addresses controlled by the same fraudulent entity. We thus introduce Evolve Path Tracer, a novel solution designed for early malice detection in cryptocurrency. This system innovatively incorporates Asset Transfer Paths and corresponding path graphs in an evolve model, which effectively characterize rapidly evolving transaction patterns. First, for the target address, the Clustering-based Path Selector weight each Asset Transfer Path by finding sibling addresses along the Asset Transfer Paths. Evolve Path Encoder LSTM and Evolve Path Graph GCN then encode the asset transfer path and path graph within a dynamic structure. Additionally, our Hierarchical Survival Predictor efficiently scales to predict the address labels, demonstrating high scalability and efficiency. We rigorously tested Evolve Path Tracer on three real-world datasets of malicious addresses, where it consistently outperformed existing state-of-the-art methods. Our extensive scalability tests further confirmed the model's robust adaptability in dynamic prediction environments, highlighting its potential as a significant tool in the realm of cryptocurrency security.},
  archive      = {J_TKDE},
  author       = {Ling Cheng and Feida Zhu and Qian Shao and Jiashu Pu and Fengzhu Zeng},
  doi          = {10.1109/TKDE.2024.3522772},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1154-1166},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Early detection of malicious crypto addresses with asset path tracing and selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Delayed bottlenecking: Alleviating forgetting in pre-trained graph neural networks. <em>TKDE</em>, <em>37</em>(3), 1140-1153. (<a href='https://doi.org/10.1109/TKDE.2024.3516192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training GNNs to extract transferable knowledge and apply it to downstream tasks has become the de facto standard of graph representation learning. Recent works focused on designing self-supervised pre-training tasks to extract useful and universal transferable knowledge from large-scale unlabeled data. However, they have to face an inevitable question: traditional pre-training strategies that aim at extracting useful information about pre-training tasks, may not extract all useful information about the downstream task. In this paper, we reexamine the pre-training process within traditional pre-training and fine-tuning frameworks from the perspective of Information Bottleneck (IB) and confirm that the forgetting phenomenon in pre-training phase may cause detrimental effects on downstream tasks. Therefore, we propose a novel Delayed Bottlenecking Pre-training (DBP) framework which maintains as much as possible mutual information between latent representations and training data during pre-training phase by suppressing the compression operation and delays the compression operation to fine-tuning phase to make sure the compression can be guided with labeled fine-tuning data and downstream tasks. To achieve this, we design two information control objectives that can be directly optimized and further integrate them into the actual model design. Extensive experiments on both chemistry and biology domains demonstrate the effectiveness of DBP.},
  archive      = {J_TKDE},
  author       = {Zhe Zhao and Pengkun Wang and Xu Wang and Haibin Wen and Xiaolong Xie and Zhengyang Zhou and Qingfu Zhang and Yang Wang},
  doi          = {10.1109/TKDE.2024.3516192},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1140-1153},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Delayed bottlenecking: Alleviating forgetting in pre-trained graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conversational recommendations with user entity focus and multi-granularity latent variable enhancement. <em>TKDE</em>, <em>37</em>(3), 1126-1139. (<a href='https://doi.org/10.1109/TKDE.2024.3523283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational recommendation is one system that can extract the user's preferences and recommend suitable items in a similar way to human-like responses. Existing methods often use the feature extraction combined with the Transformer model to extract user preferences and make recommendations. However, these methods have two limitations. First, they do not consider the order in which entities appear, thus affecting the extraction of user preferences. Second, the generated responses lack diversity that affects the users’ experience to the system. To this end, we propose a conversational recommendation model with User Entity focus and Multi-Granularity latent variable enhancement (UEMG). In UEMG, we design a novel neural network that utilizes Bi-GRU to capture the appearing orders of entities in dialogues, and leverages Transformer to capture the global dependencies of entities, and then combines them to extract user preferences. For the second issue, to improve the diversity of dialogue generation, we propose a multi-granularity latent variable mechanism, which can extract more entities from the context information and the knowledge graphs, respectively. We conducted extensive experiments on publicly available dialogue generation datasets. Experimental results demonstrate that compared to current state-of-the-art methods, UEMG achieves 9.7% improvements in recommendation performance and 23% improvements in dialogue generation.},
  archive      = {J_TKDE},
  author       = {Yunfei Yin and Yiming Pan and Xianjian Bao and Faliang Huang},
  doi          = {10.1109/TKDE.2024.3523283},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1126-1139},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Conversational recommendations with user entity focus and multi-granularity latent variable enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Colorful star motif counting: Concepts, algorithms and applications. <em>TKDE</em>, <em>37</em>(3), 1105-1125. (<a href='https://doi.org/10.1109/TKDE.2024.3514997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A colorful star motif is a star-shaped graph where any two nodes have different colors. Counting the colorful star motif can help to analyze the structural properties of real-life colorful graphs, model higher-order clustering, and accelerate the mining of the densest subgraph exhibiting $h$-clique characteristics in graphs. In this manuscript, we introduce the concept of colorful $h$-star in a colored graph and proposes two higher-order cohesive subgraph models, namely colorful $h$-star core and colorful $h$-star truss. We show that the colorful $h$-stars can be counted and updated very efficiently using a novel dynamic programming (DP) algorithm. Based on the proposed DP algorithm, we develop a colorful $h$-star core decomposition algorithm which takes $O(h m)$ time, $O(h n+m)$ space; and a colorful $h$-star truss decomposition algorithm which takes $O(h m^{1.5})$ time, $O(hm)$ space, where $m$ and $n$ denote the number of edges and nodes of the graph respectively. Moreover, we also propose a graph reduction technique based on our colorful $h$-star core model to accelerate the computation of the approximation algorithm for $ h$-clique densest subgraph mining. The results of comprehensive experiments on 11 large real-world datasets demonstrate the efficiency, scalability and effectiveness of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Hongchao Qin and Gao Sen and Rong-Hua Li and Hongzhi Chen and Ye Yuan and Guoren Wang},
  doi          = {10.1109/TKDE.2024.3514997},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1105-1125},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Colorful star motif counting: Concepts, algorithms and applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ATPF: An adaptive temporal perturbation framework for adversarial attacks on temporal knowledge graph. <em>TKDE</em>, <em>37</em>(3), 1091-1104. (<a href='https://doi.org/10.1109/TKDE.2024.3510689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness is paramount for ensuring the reliability of knowledge graph models in safety-sensitive applications. While recent research has delved into adversarial attacks on static knowledge graph models, the exploration of more practical temporal knowledge graphs has been largely overlooked. To fill this gap, we present the Adaptive Temporal Perturbation Framework (ATPF), a novel adversarial attack framework aimed at probing the robustness of temporal knowledge graph (TKG) models. The general idea of ATPF is to inject perturbations into the victim model input to undermine the prediction. First, we propose the Temporal Perturbation Prioritization (TPP) algorithm, which identifies the optimal time sequence for perturbation injection before initiating attacks. Subsequently, we design the Rank-Based Edge Manipulation (RBEM) algorithm, enabling the generation of both edge addition and removal perturbations under black-box setting. With ATPF, we present two adversarial attack methods: the stringent ATPF-hard and the more lenient ATPF-soft, each imposing different perturbation constraints. Our experimental evaluations on the link prediction task for TKGs demonstrate the superior attack performance of our methods compared to baseline methods. Furthermore, we find that strategically placing a single perturbation often suffices to successfully compromise a target link.},
  archive      = {J_TKDE},
  author       = {Longquan Liao and Linjiang Zheng and Jiaxing Shang and Xu Li and Fengwen Chen},
  doi          = {10.1109/TKDE.2024.3510689},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1091-1104},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ATPF: An adaptive temporal perturbation framework for adversarial attacks on temporal knowledge graph},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor guided unsupervised domain adaptation. <em>TKDE</em>, <em>37</em>(3), 1079-1090. (<a href='https://doi.org/10.1109/TKDE.2024.3511714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation aims to classify unlabeled data points in the target domain using labeled data points from the source domain, while the distributions of data points in two domains are different. To address this issue, we propose a novel method called the anchor guided unsupervised domain adaptation method (AGDA). We minimize distribution divergence in a latent feature subspace using the Maximum Mean Discrepancy (MMD) criterion. Unlike existing unsupervised domain adaptation methods, we introduce anchor points in the original space and impose domains data to the same anchor points rather than center points to further reduce the domain difference. We optimize the anchor-based graph in the subspace to obtain discriminative transformation matrices. This enables our model to perform better on non-Gaussian distribution than methods focusing on global structure. Furthermore, the sparse anchor-based graph reduces time complexity compared to the fully connected graph, enabling exploration of local structure. Experimental results demonstrate that our algorithm outperforms several state-of-the-art methods on various benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Canyu Zhang and Feiping Nie and Rong Wang},
  doi          = {10.1109/TKDE.2024.3511714},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1079-1090},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Anchor guided unsupervised domain adaptation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AEGK: Aligned entropic graph kernels through continuous-time quantum walks. <em>TKDE</em>, <em>37</em>(3), 1064-1078. (<a href='https://doi.org/10.1109/TKDE.2024.3512181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a family of Aligned Entropic Graph Kernels (AEGK) for graph classification. We commence by performing the Continuous-time Quantum Walk (CTQW) on each graph structure, and compute the Averaged Mixing Matrix (AMM) to describe how the CTQW visits all vertices from a starting vertex. More specifically, we show how this AMM matrix allows us to compute a quantum Shannon entropy of each vertex for either un-attributed or attributed graphs. For pairwise graphs, the proposed AEGK kernels are defined by computing the kernel-based similarity between the quantum Shannon entropies of their pairwise aligned vertices. The analysis of theoretical properties reveals that the proposed AEGK kernels cannot only address the shortcoming of neglecting the structural correspondence information between graphs arising in most existing R-convolution graph kernels, but also overcome the problems of neglecting the structural differences and vertex-attributed information arising in existing vertex-based matching kernels. Moreover, unlike most existing classical graph kernels that only focus on the global or local structural information of graphs, the proposed AEGK kernels can simultaneously capture both global and local structural characteristics through the quantum Shannon entropies, reflecting more precise kernel-based similarity measures between pairwise graphs. The above theoretical properties explain the effectiveness of the proposed AEGK kernels. Experimental evaluations demonstrate that the proposed kernels can outperform state-of-the-art graph kernels and deep learning models for graph classification.},
  archive      = {J_TKDE},
  author       = {Lu Bai and Lixin Cui and Ming Li and Peng Ren and Yue Wang and Lichi Zhang and Philip S. Yu and Edwin R. Hancock},
  doi          = {10.1109/TKDE.2024.3512181},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1064-1078},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AEGK: Aligned entropic graph kernels through continuous-time quantum walks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADMH-ER: Adaptive denoising multi-modal hybrid for entity resolution. <em>TKDE</em>, <em>37</em>(3), 1049-1063. (<a href='https://doi.org/10.1109/TKDE.2025.3526623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Modal Knowledge Graphs (MMKGs), comprising relational triples and related multi-modal data (e.g., text and images), usually suffer from the problems of low coverage and incompleteness. To mitigate this, existing studies introduce a fundamental MMKG fusion task, i.e., Multi-Modal Entity Alignment (MMEA) that identifies equivalent entities across multiple MMKGs. Despite MMEA’s significant advancements, effectively integrating MMKGs remains challenging, mainly stemming from two core limitations: 1) entity ambiguity, where real-world entities across different MMKGs may possess multiple corresponding counterparts or alternative identities; and 2) severe noise within multi-modal data. To tackle these limitations, a new task MMER (Multi-Modal Entity Resolution), which expands the scope of MMEA to encompass entity ambiguity, is introduced. To tackle this task effectively, we develop a novel model ADMH-ER (Adaptive Denoising Multi-modal Hybrid for Entity Resolution) that incorporates several crucial modules: 1) multi-modal knowledge encoders, which are crafted to obtain entity representations based on multi-modal data sources; 2) an adaptive denoising multi-modal hybrid module that is designed to tackle challenges including noise interference, multi-modal heterogeneity, and semantic irrelevance across modalities; and 3) a hierarchical multi-objective learning strategy, which is proposed to ensure diverse convergence capabilities among different learning objectives. Experimental results demonstrate that ADMH-ER outperforms state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Qian Zhou and Wei Chen and Li Zhang and An Liu and Junhua Fang and Lei Zhao},
  doi          = {10.1109/TKDE.2025.3526623},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1049-1063},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ADMH-ER: Adaptive denoising multi-modal hybrid for entity resolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of change point detection in dynamic graphs. <em>TKDE</em>, <em>37</em>(3), 1030-1048. (<a href='https://doi.org/10.1109/TKDE.2024.3523857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change point detection is crucial for identifying state transitions and anomalies in dynamic systems, with applications in network security, health care, and social network analysis. Dynamic systems are represented by dynamic graphs with spatial and temporal dimensions. As objects and their relations in a dynamic graph change over time, detecting these changes is essential. Numerous methods for change point detection in dynamic graphs have been developed, but no systematic review exists. This paper addresses this gap by introducing change point detection tasks in dynamic graphs, discussing two tasks based on input data types: detection in graph snapshot series (focusing on graph topology changes) and time series on graphs (focusing on changes in graph entities with temporal dynamics). We then present related challenges and applications, provide a comprehensive taxonomy of surveyed methods, including datasets and evaluation metrics, and discuss promising research directions.},
  archive      = {J_TKDE},
  author       = {Yuxuan Zhou and Shang Gao and Dandan Guo and Xiaohui Wei and Jon Rokne and Hui Wang},
  doi          = {10.1109/TKDE.2024.3523857},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1030-1048},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of change point detection in dynamic graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vertical federated density peaks clustering under nonlinear mapping. <em>TKDE</em>, <em>37</em>(2), 1004-1017. (<a href='https://doi.org/10.1109/TKDE.2024.3487534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the representative density-based clustering algorithm, density peaks clustering (DPC) has wide recognition, and many improved algorithms and applications have been extended from it. However, the DPC involving privacy protection has not been deeply studied. In addition, there is still room for improvement in the selection of centers and allocation methods of DPC. To address these issues, vertical federated density peaks clustering under nonlinear mapping (VFDPC) is proposed to address privacy protection issues in vertically partitioned data. Firstly, a hybrid encryption privacy protection mechanism is proposed to protect the merging process of distance matrices generated by client data. Secondly, according to the merged distance matrix, a more effective cluster merging under nonlinear mapping is proposed to ameliorate the process of DPC. Results on man-made, real, and multi-view data fully prove the improvement of VFDPC on clustering accuracy.},
  archive      = {J_TKDE},
  author       = {Chao Li and Shifei Ding and Xiao Xu and Lili Guo and Ling Ding and Xindong Wu},
  doi          = {10.1109/TKDE.2024.3487534},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {1004-1017},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Vertical federated density peaks clustering under nonlinear mapping},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified multi-scenario summarization evaluation and explanation. <em>TKDE</em>, <em>37</em>(2), 991-1003. (<a href='https://doi.org/10.1109/TKDE.2024.3509715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Summarization quality evaluation is a non-trivial task in text summarization. Contemporary methods can be mainly categorized into two scenarios: (1) reference-based: evaluating with human-labeled reference summary; (2) reference-free: evaluating the summary consistency of the document. Recent studies mainly focus on one of these scenarios and explore training neural models to align with human criteria and finally give a numeric score. However, the models from different scenarios are optimized individually, which may result in sub-optimal performance since they neglect the shared knowledge across different scenarios. Besides, designing individual models for each scenario caused inconvenience to the user. Moreover, only providing the numeric quality evaluation score for users cannot help users to improve the summarization model, since they do not know why the score is low. Inspired by this, we propose Unified Multi-scenario Summarization Evaluator (UMSE) and Multi-Agent Summarization Evaluation Explainer (MASEE). More specifically, we propose a perturbed prefix tuning method to share cross-scenario knowledge between scenarios and use a self-supervised training paradigm to optimize the model without extra human labeling. Our UMSE is the first unified summarization evaluation framework engaged with the ability to be used in three evaluation scenarios. We propose a multi-agent summary evaluation explanation method MASEE, which employs several LLM-based agents to generate detailed natural language explanations in four different aspects. Experimental results across three typical scenarios on the benchmark dataset SummEval indicate that our UMSE can achieve comparable performance with several existing strong methods that are specifically designed for each scenario. And intensive quantitative and qualitative experiments also demonstrate the effectiveness of our proposed explanation method, which can generate consistent and accurate explanations.},
  archive      = {J_TKDE},
  author       = {Shuo Shang and Zhitao Yao and Hao Fu and Chongyang Tao and Xiuying Chen and Feng Wang and Yongbo Wang and Zhaochun Ren and Shen Gao},
  doi          = {10.1109/TKDE.2024.3509715},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {991-1003},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unified multi-scenario summarization evaluation and explanation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unconstrained fuzzy C-means based on entropy regularization: An equivalent model. <em>TKDE</em>, <em>37</em>(2), 979-990. (<a href='https://doi.org/10.1109/TKDE.2024.3516085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy c-means based on entropy regularization (FCER) is a commonly used machine learning algorithm that uses maximum entropy as the regularization term to realize fuzzy clustering. However, this model has many constraints and is challenging to optimize directly. During the solution process, the membership matrix and cluster centers are alternately optimized, easily converging to poor local solutions, limiting the clustering performance. In this paper, we start with the optimization model and propose an unconstrained fuzzy clustering model (UFCER) equivalent to FCER, which reduces the size of optimization variables from $(n+d)\times c$ to $d\times c$. More importantly, there is no need to calculate the membership matrix during the optimization process iteratively. The time complexity is only linear, and the convergence speed is fast. We conduct extensive experiments on real datasets. The comparison of objective function value and clustering performance fully demonstrates that under the same initialization, our proposed algorithm can converge to smaller local minimums and get better clustering performance.},
  archive      = {J_TKDE},
  author       = {Feiping Nie and Runxin Zhang and Yu Duan and Rong Wang},
  doi          = {10.1109/TKDE.2024.3516085},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {979-990},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unconstrained fuzzy C-means based on entropy regularization: An equivalent model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time- and space-efficiently sketching billion-scale attributed networks. <em>TKDE</em>, <em>37</em>(2), 966-978. (<a href='https://doi.org/10.1109/TKDE.2024.3508256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed network embedding seeks to depict each network node via a compact, low-dimensional vector while effectively preserving the similarity between node pairs, which lays a strong foundation for a great many high-level network mining tasks. With the advent of the era of Big Data, the number of nodes and edges has reached billions in many real-world networks, which poses great computational and storage challenges to the existing methods. Although some algorithms have been developed to handle billion-scale networks, they often undergo accuracy degradation or tempo-spatial inefficiency owing to attribute information loss or substantial parameter learning. To this end, we propose a simple, time- and space-efficient billion-scale attributed network embedding algorithm called SketchBANE in this paper, which strikes an excellent balance between accuracy and efficiency by adopting sparse random projection with 1-bit quantization to sketch the iterative closed neighborhood and maintain the similarity among high-order nodes in a non-learning manner. The extensive experimental results indicate that our proposed SketchBANE algorithm competes favorably with the state-of-the-art approaches, while remarkably reducing runtime and space consumption. Also, the proposed SketchBANE algorithm exhibits good scalability and parallelization.},
  archive      = {J_TKDE},
  author       = {Wei Wu and Shiqi Li and Mi Jiang and Chuan Luo and Fangfang Li},
  doi          = {10.1109/TKDE.2024.3508256},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {966-978},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Time- and space-efficiently sketching billion-scale attributed networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal insights for group-based fraud detection on e-commerce platforms. <em>TKDE</em>, <em>37</em>(2), 951-965. (<a href='https://doi.org/10.1109/TKDE.2024.3485127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the rapid technological and commercial innovation on e-commerce platforms, an increasing number of frauds cause great harm to these platforms. Many frauds are conducted by organized groups of fraudsters for higher efficiency and lower costs, also known as group-based frauds. Despite the high concealment and strong destructiveness of group-based fraud, no existing research can thoroughly exploit the information within the transaction networks of e-commerce platforms for group-based fraud detection. In this work, we analyze and summarize the characteristics of group-based frauds. Based on this, we propose a novel end-to-end semi-supervised Group-based Fraud Detection Network (GFDN) to support such fraud detection in real-world applications. In addition, we introduce a module named Temporal Group Dynamics Analyzer (TGDA) that strengthens the ability to analyze temporal information on group fraudulent activity. Based on this, we built an enhanced model named TGFDN. Experimental results on large-scale e-commerce datasets from Taobao and Bitcoin trading datasets show our proposed model's superior effectiveness and efficiency for group-based fraud detection on bipartite graphs.},
  archive      = {J_TKDE},
  author       = {Jianke Yu and Hanchen Wang and Xiaoyang Wang and Zhao Li and Lu Qin and Wenjie Zhang and Jian Liao and Ying Zhang and Bailin Yang},
  doi          = {10.1109/TKDE.2024.3485127},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {951-965},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Temporal insights for group-based fraud detection on e-commerce platforms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial meta learning with comprehensive prior knowledge injection for service time prediction. <em>TKDE</em>, <em>37</em>(2), 936-950. (<a href='https://doi.org/10.1109/TKDE.2024.3512582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent logistics relies on accurately predicting the service time, which is a part of time cost in the last-mile delivery. However, service time prediction (STP) is non-trivial given complex delivery circumstances, location heterogeneity, and skewed observations in space, which are not well-handled by existing solutions. In our prior work, we treat STP at each location as a learning task to keep the location heterogeneity, propose a prior knowledge-enhanced meta-learning to tackle skewed observations, and introduce a Transformer-based representation module to encode complex delivery circumstances. Maintaining the design principles of prior work, in this extended paper, we propose MetaSTP+. In addition to fusing the prior knowledge after the meta-learning process, MetaSTP+ also injects the prior knowledge before and during the meta-learning process to better tackle skewed observations. More specifically, MetaSTP+ completes the support set of tasks with scarce samples from other tasks based on prior knowledge and is equipped with a prior knowledge-aware historical observation encoding module to achieve those purposes accordingly. Experiments show MetaSTP+ outperforms the best baseline by 11.2% and 8.4% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP+ is deployed in JD Logistics.},
  archive      = {J_TKDE},
  author       = {Shuliang Wang and Qianyu Yang and Sijie Ruan and Cheng Long and Ye Yuan and Qi Li and Ziqiang Yuan and Jie Bao and Yu Zheng},
  doi          = {10.1109/TKDE.2024.3512582},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {936-950},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatial meta learning with comprehensive prior knowledge injection for service time prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Session-oriented fairness-aware recommendation via dual temporal convolutional networks. <em>TKDE</em>, <em>37</em>(2), 923-935. (<a href='https://doi.org/10.1109/TKDE.2024.3509454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based Recommender Systems (SBRSs) aim at timely predicting the next likely item by capturing users’ current preferences in sessions. Existing SBRSs research only focuses on maximizing session utilities, and little has been done on the fairness issue in SBRSs, which is vital but different from the same issue in traditional Recommender Systems (RSs). To fill in this gap, we define a novel concept of session-oriented fairness to enforce individual items to have the same exposure accumulated within each single session, which is flexible enough to provide opportunities to achieve different fairness goals. Then, we devise a Session-Oriented Fairness-Aware algorithm (SOFA) with a dual Temporal Convolutional Networks (TCN) architecture: one is SOUP (Session-Oriented Utility Promoter) and the other is SODA (Session-Oriented Disparity Alleviator). Benefit from the collaborative learning of SOUP and SODA for the evolution of accumulated exposure in sessions, SOFA is effective to maximize session-oriented fairness while maintaining high session utilities. To the best of our knowledge, this research is the first to solve fairness issues in SBRSs. Extensive experiments on real-world datasets demonstrate that SOFA outperforms the state-of-the-art approaches in terms of both utility and fairness.},
  archive      = {J_TKDE},
  author       = {Jie Li and Ke Deng and Jianxin Li and Yongli Ren},
  doi          = {10.1109/TKDE.2024.3509454},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {923-935},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Session-oriented fairness-aware recommendation via dual temporal convolutional networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential causal effect estimation by jointly modeling the unmeasured confounders and instrumental variables. <em>TKDE</em>, <em>37</em>(2), 910-922. (<a href='https://doi.org/10.1109/TKDE.2024.3510734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential causal effect estimation has recently attracted increasing attention from research and industry. While the existing models have achieved many successes, there are still many limitations. Existing models usually assume the causal graphs to be sufficient, i.e., there are no latent factors, such as the unmeasured confounders and instrumental variables. However, in real-world scenarios, it is hard to record all of the factors in the observational data, which makes the causally sufficient assumptions not hold. Moreover, existing models mainly focus on discrete treatments rather than continuous ones. To alleviate the above problems, in this paper, we propose a novel Continous Causal Model by explicitly capturing the Latent Factors (called C$^{2}$<mml:math><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>M-LF for short). Specifically, we define a sequential causal graph by simultaneously considering the unmeasured confounders and instrumental variables. Second, we describe the independence that should be satisfied among different variables from the mutual information perspective and further propose our learning objective. Then, we reweight different samples in the continuous treatment space to optimize our model unbiasedly. Beyond the above designs, we also theoretically analyze our model’s causal identifiability and unbiasedness. Finally, we conduct extensive experiments on both simulation and real-world datasets to demonstrate the effectiveness of our proposed model.},
  archive      = {J_TKDE},
  author       = {Zexu Sun and Bowei He and Shiqi Shen and Zhipeng Wang and Zhi Gong and Chen Ma and Qi Qi and Xu Chen},
  doi          = {10.1109/TKDE.2024.3510734},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {910-922},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Sequential causal effect estimation by jointly modeling the unmeasured confounders and instrumental variables},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable and effective graph neural networks via trainable random walk sampling. <em>TKDE</em>, <em>37</em>(2), 896-909. (<a href='https://doi.org/10.1109/TKDE.2024.3513533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have aroused increasing research attention for their effectiveness on graph mining tasks. However, full-batch training methods based on stochastic gradient descent (SGD) require substantial resources since all gradient-required computational processes are stored in the acceleration device. The bottleneck of storage challenges the training of classic GNNs on large-scale datasets within one acceleration device. Meanwhile, message-passing based (spatial) GNN designs usually necessitate the homophily hypothesis of the graph, which easily fails on heterophilous graphs. In this paper, we propose the random walk extension for those message-passing based GNNs, enriching them with spectral powers. We prove that our random walk sampling with appropriate correction coefficients generates an unbiased approximation of the $K$-order polynomial filter matrix, thus promoting the neighborhood aggregation of the central nodes. Node-wise sampling strategy and historical embedding allow the classic models to be trained with mini-batches, which extends the scalability of the basic models. To show the effectiveness of our method, we conduct a thorough experimental analysis on some frequently-used benchmarks with diverse homophily and scale. The empirical results show that our model achieves significant performance improvements in comparison with the corresponding base GNNs and some state-of-the-art baselines in node classification tasks.},
  archive      = {J_TKDE},
  author       = {Haipeng Ding and Zhewei Wei and Yuhang Ye},
  doi          = {10.1109/TKDE.2024.3513533},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {896-909},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable and effective graph neural networks via trainable random walk sampling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking unsupervised graph anomaly detection with deep learning: Residuals and objectives. <em>TKDE</em>, <em>37</em>(2), 881-895. (<a href='https://doi.org/10.1109/TKDE.2024.3501307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalies often occur in real-world information networks/graphs, such as malevolent users in online review networks and fake news in social media. When representing such structured network data as graphs, anomalies usually appear as anomalous nodes that exhibit significantly deviated structure patterns, or different attributes, or the both. To date, numerous unsupervised methods have been developed to detect anomalies based on residual analysis, which assumes that anomalies will introduce larger residual errors (i.e., graph reconstruction loss). While these existing works achieved encouraging performance, in this paper, we formally prove that their employed learning objectives, i.e., MSE and cross-entropy losses, encounter significant limitations in learning the major data distributions, particularly for anomaly detection, and through our preliminary study, we reveal that the vanilla residual analysis-based methods cannot effectively investigate the rich graph structure. Upon these discoveries, we propose a novel structure-biased graph anomaly detection framework (SALAD) to attain anomalies’ divergent patterns with the assistance of a specially designed node representation augmentation approach. We further present two effective training objectives to empower SALAD to effectively capture the major structure and attribute distributions by emphasizing less on anomalies that introduce higher reconstruction errors under the encoder-decoder framework. The detection performance on eight widely-used datasets demonstrates SALAD's superiority over twelve state-of-the-art baselines. Additional ablation and case studies validate that our data augmentation method and training objectives result in the impressive performance.},
  archive      = {J_TKDE},
  author       = {Xiaoxiao Ma and Fanzhen Liu and Jia Wu and Jian Yang and Shan Xue and Quan Z. Sheng},
  doi          = {10.1109/TKDE.2024.3501307},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {881-895},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Rethinking unsupervised graph anomaly detection with deep learning: Residuals and objectives},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational stock selection via probabilistic state space learning. <em>TKDE</em>, <em>37</em>(2), 865-880. (<a href='https://doi.org/10.1109/TKDE.2024.3509267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing stock selection through stock ranking is one of the critical but intricate tasks in quantitative trading areas because of the non-stationary dynamics and complicated interdependencies behind stock markets. Recent studies have made efforts to model historical market movements to enhance stock selection. However, they primarily borrowed the spirit of time series modeling and sought to build a deterministic paradigm without considering the uncertain fluctuations. In addition, some of these studies tailor to explore stock correlations from a predefined (e.g., binary) graph structure and use explicitly simple relations (such as first-order relations) to guide evolving interactions. Nevertheless, aggregating predefined but shallow relationships to collaborate with stock movements may affect selection generalizability and increase the risk of portfolio failure. This study introduces a novel Relational stock selection framework via probabilistic State Space Learning (or RSSL) for stock selection. Specifically, RSSL first attempts to build a tree-based structure to explicitly expose higher-order relations in the stock market, primarily by discovering a hierarchical delineation of ties between stocks. Whereafter, it couples with time-varying movements via an attention mechanism to smoothly explore the interactive correlations among different stocks. Inspired by recent state space models (SSM) in probabilistic Bayesian learning, we devise a Probabilistic Kalman Network (PKNet) with uncertainty estimates to recursively simulate ever-changing stock volatility, enabling more promising return-risk trade-offs. The experimental results on several real-world stock market datasets demonstrate that RSSL outperforms several representative baseline methods by a significant margin.},
  archive      = {J_TKDE},
  author       = {Qiang Gao and Zhengxiang Liu and Li Huang and Kunpeng Zhang and Jun Wang and Guisong Liu},
  doi          = {10.1109/TKDE.2024.3509267},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {865-880},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Relational stock selection via probabilistic state space learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting individual irregular mobility via web search-driven bipartite graph neural networks. <em>TKDE</em>, <em>37</em>(2), 851-864. (<a href='https://doi.org/10.1109/TKDE.2024.3487549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual mobility prediction holds significant importance in urban computing, supporting various applications such as place recommendations. Current studies primarily focus on frequent mobility patterns including commuting trips to residential and workplaces. However, such studies do not accurately forecast irregular trips, which incorporate journeys that end at locations other than residences and workplaces. Despite their usefulness in recommendations and advertising, the stochastic, infrequent, and spontaneous nature of irregular trips makes them challenging to predict. To address the difficulty, this study proposes a web search-driven bipartite graph neural network, namely WS-BiGNN, for the individual irregular mobility prediction (IIMP) problem. Specifically, we construct bipartite graphs to represent mobility and web search records, formulating the IIMP problem as a link prediction task. First, WS-BiGNN employs user-user edges and POI-POI edges (POI: point-of-interest) to bolster information propagation within sparse bipartite graphs. Second, the temporal weighting module is created to discern the influence of past mobility and web searches on future mobility. Lastly, WS-BiGNN incorporates the search-mobility memory module, which classifies four interpretable web search-mobility patterns and harnesses them to improve prediction accuracy. We perform experiments utilizing real-world data in Tokyo from October 2019 to March 2020. The results showcase the superior performance of WS-BiGNN compared to baseline models, as supported by higher scores in Recall and NDCG. The exceptional performance and additional analysis reveal that infrequent behavior may be effectively predicted by learning search-mobility patterns at the individual level.},
  archive      = {J_TKDE},
  author       = {Jiawei Xue and Takahiro Yabe and Kota Tsubouchi and Jianzhu Ma and Satish V. Ukkusuri},
  doi          = {10.1109/TKDE.2024.3487549},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {851-864},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Predicting individual irregular mobility via web search-driven bipartite graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Order-2 probabilistic information fusion on random permutation set. <em>TKDE</em>, <em>37</em>(2), 837-850. (<a href='https://doi.org/10.1109/TKDE.2024.3484009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi-object recognition scenario is considered to extend the random finite set into random permutation set. Probabilistic information on random permutation set can be viewed as an distribution determined by three random variables. We use another emerging uncertainty representation, order-2 information granule, to realize the probabilistic information fusion on random permutation sets. First, the probabilistic information on random permutation sets is viewed as an order-2 probability distribution. Second, corresponding information fusion approach is proposed. Finally, the proposed approach is applied to random permutation sets, resolving the decision-making issue under the multi-object recognition scenario. This paper pioneers the connection of order-2 information processing logic to a multi-object recognition task and develops order-2 probability distribution and its combination rules. Compared to the traditional probabilistic information fusion approaches, the proposed approach takes into account not only the propositions’ beliefs provided by the sources, but the structural dependency among propositions as well.},
  archive      = {J_TKDE},
  author       = {Qianli Zhou and Witold Pedrycz and Yong Deng},
  doi          = {10.1109/TKDE.2024.3484009},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {837-850},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Order-2 probabilistic information fusion on random permutation set},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Networked instrumental variable for treatment effect estimation with unobserved confounders. <em>TKDE</em>, <em>37</em>(2), 823-836. (<a href='https://doi.org/10.1109/TKDE.2024.3491776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment effect estimation from observational data is a fundamental problem in causal inference, and its critical challenge is to address the confounding bias arising from the confounders. The effectiveness of the conventional methods proposed to solve this problem depends on the unconfoundedness assumption. In practice, however, the unconfoundedness assumption is frequently violated since we cannot guarantee that all the confounders are measured. To this end, recent studies suggest using auxiliary network architectures to mine information about unmeasured confounders in the data to relax this assumption. However, these methods cannot address the confounding bias from unmeasured confounders unrelated to the network information. Inspired by the insight that some neighboring features that influence one's treatment choice (e.g., which movie to watch) but do not affect the outcome (e.g., assessment of the movie) can be treated as instrumental variables (IVs), we propose a novel Network Instrumental Variable Regression (NetIV) framework exploits IV information from neighborhoods to perform a two-stage regression for treatment effect estimation. Extensive experiments demonstrate that our NetIV method outperforms the state-of-the-art methods for treatment effect estimation in the presence of unmeasured confounders.},
  archive      = {J_TKDE},
  author       = {Ziyu Zhao and Anpeng Wu and Kun Kuang and Ruoxuan Xiong and Bo Li and Zhihua Wang and Fei Wu},
  doi          = {10.1109/TKDE.2024.3491776},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {823-836},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Networked instrumental variable for treatment effect estimation with unobserved confounders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal correction network for recommendation. <em>TKDE</em>, <em>37</em>(2), 810-822. (<a href='https://doi.org/10.1109/TKDE.2024.3493374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal contents have proven to be the powerful knowledge for recommendation tasks. Most state-of-the-art multi-modal recommendation methods mainly focus on aligning the semantic spaces of different modalities to enhance the item representations and do not pay much attention on the relevant knowledge in the multi-modalities for recommendation, resulting in that the positive effects of the relevant knowledge is reduced and the improvement of recommendation performance is limited. In this paper, we propose a multi-modal correction network termed MMCN to enhance the item representation with the important semantic knowledge in each modality by a residual structure with attention mechanisms and a hierarchical contrastive learning framework. The residual information is obtained through self-attention and cross-attention, which can learn the relevant knowledge across different modalities effectively. While hierarchical contrastive learning further captures the relevant knowledge not only at the feature level but also at the element-wise level with a matrix. Extensive experiments on three large-scale real-world datasets show the superiority of MMCN over state-of-the-art multi-modal recommendation methods.},
  archive      = {J_TKDE},
  author       = {Zengmao Wang and Yunzhen Feng and Xin Zhang and Renjie Yang and Bo Du},
  doi          = {10.1109/TKDE.2024.3493374},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {810-822},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-modal correction network for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and monitoring of indoor populations using sparse positioning data. <em>TKDE</em>, <em>37</em>(2), 794-809. (<a href='https://doi.org/10.1109/TKDE.2024.3489796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large venues like shopping malls and airports, knowledge on the indoor populations fuels applications such as business analytics, venue management, and safety control. In this work, we provide means of modeling populations in partitions of indoor space offline and of monitoring indoor populations continuously, by using indoor positioning data. However, the low-sampling rates of indoor positioning render the data temporally and spatially sparse, which in turn renders the offline capture of indoor populations challenging. It is even more challenging to continuously monitor indoor populations, as positioning data may be missing or not ready yet at the current moment. To address these challenges, we first enable probabilistic modeling of populations in indoor space partitions as Normal distributions. Based on that, we propose two learning-based estimators for on-the-fly prediction of population distributions. Leveraging the prediction-based schemes, we provide a unified continuous query processing framework for a type of query that enables continuous monitoring of populated partitions. The framework encompasses caching and result validity mechanisms to reduce cost and maintain monitoring effectiveness. Extensive experiments on two real data sets show that the proposed estimators are able to outperform the state-of-the-art alternatives and that the query processing framework is effective and efficient.},
  archive      = {J_TKDE},
  author       = {Xiao Li and Huan Li and Hua Lu and Christian S. Jensen},
  doi          = {10.1109/TKDE.2024.3489796},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {794-809},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling and monitoring of indoor populations using sparse positioning data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta recommendation with robustness improvement. <em>TKDE</em>, <em>37</em>(2), 781-793. (<a href='https://doi.org/10.1109/TKDE.2024.3509416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta learning has been recognized as an effective remedy for solving the cold-start problem in the recommendation domain. Existing models aim to learn how to generalize from the user behaviors in the training set to testing set. However, in the cold start settings, with only a small number of training samples, the testing distribution may easily deviate from the training one, which may invalidate the learned generalization patterns, and lower the recommendation performance. For alleviating this problem, in this paper, we propose a robust meta recommender framework to address the distribution shift problem. In specific, we argue that the distribution shift may exist on both the user- and interaction-levels, and in order to mitigate them simultaneously, we design a novel distributionally robust model by hierarchically reweighing the training samples. Different sample weights correspond to different training distributions, and we minimize the largest loss induced by the sample weights in a simplex, which essentially optimizes the upper bound of the testing loss. In addition, we analyze our framework on the convergence rates and generalization error bound to provide more theoretical insights. Empirically, we conduct extensive experiments based on different meta recommender models and real-world datasets to verify the generality and effectiveness of our framework.},
  archive      = {J_TKDE},
  author       = {Zeyu Zhang and Chaozhuo Li and Xu Chen and Xing Xie and Philip S. Yu},
  doi          = {10.1109/TKDE.2024.3509416},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {781-793},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Meta recommendation with robustness improvement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MC$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>LS: Towards efficient collective location selection in competition. <em>TKDE</em>, <em>37</em>(2), 766-780. (<a href='https://doi.org/10.1109/TKDE.2024.3510100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective Location Selection (CLS) has received significant research attention in the spatial database community due to its wide range of applications. The CLS problem selects a group of k preferred locations among candidate sites to establish facilities, aimed at collectively attracting the maximum number of users. Existing studies commonly assume every user is located in a fixed position, without considering the competition between peer facilities. Unfortunately, in real markets, users are mobile and choose to patronize from a host of competitors, making traditional techniques unavailable. To this end, this paper presents the first effort on a CLS problem in competition scenarios, called mc$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>ls, taking into account the mobility factor. Solving mc$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>ls is a non-trivial task due to its NP-hardness. To overcome the challenge of pruning multi-point users with highly overlapped minimum boundary rectangles (MBRs), we exploit a position count threshold and design two square-based pruning rules. We introduce IQuad-tree, a user-MBR-free index, to benefit the hierarchical and batch-wise properties of the pruning rules. We propose an $(1-\frac{1}{e})$-approximate greedy solution to mc$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>ls and incorporate a candidate-pruning strategy to further accelerate the computation for handling skewed datasets. Extensive experiments are conducted on real datasets, demonstrating the superiority of our proposed pruning rules and solution compared to the state-of-the-art techniques.},
  archive      = {J_TKDE},
  author       = {Meng Wang and Mengfei Zhao and Hui Li and Jiangtao Cui and Bo Yang and Tao Xue},
  doi          = {10.1109/TKDE.2024.3510100},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {766-780},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MC$^{2}$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mrow/><mml:mn>2</mml:mn></mml:msup></mml:math>LS: Towards efficient collective location selection in competition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning without missing-at-random prior propensity-A generative approach for recommender systems. <em>TKDE</em>, <em>37</em>(2), 754-765. (<a href='https://doi.org/10.1109/TKDE.2024.3490593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, it is frequently presumed that missing ratings adhere to a missing at random (MAR) mechanism, implying the absence of ratings is independent of their potential values. However, this assumption fails to hold in real-world scenarios, where users are inclined to rate items they either strongly favor or disfavor, introducing a missing not at random (MNAR) scenario. To tackle this issue, prior researchers have utilized explicit MAR feedbacks to infer the propensities of unobserved, implicit MNAR feedbacks. Nonetheless, acquiring explicit MAR feedbacks is resource-intensive and time-consuming and may not reflect users’ true preferences. Furthermore, most methods have only been tested on synthetic or small-scale datasets, thus their applicability and effectiveness in real-world settings without MAR feedbacks remain unclear. Along these lines, we aim to predict MNAR ratings without MAR prior propensities by exploring the consistency between MAR and MNAR feedbacks and narrowing the gap between them. From the empirical study and preliminary experiment, we hypothesize that user preferences can be treated as the common prior propensity for both MAR and MNAR generative processes. In this way, we extend this hypothesis to a more general MNAR scenario: user preferences learned from MNAR can partially substitute for the prior propensities derived from MAR feedbacks for MNAR recommendation tasks. To validate our hypothesis and approach, we develop a lightweight iterative probabilistic matrix factorization framework (lightIPMF) as a practical method of our methodology, utilizing user preferences extracted from MNAR, not MAR, to estimate MNAR feedbacks. Finally, the experimental results show that modeling user preferences can effectively improve MNAR feedback estimation without MAR feedback, and our proposed lightIPMF outperforms the state-of-the-art MNAR methods in predicting MNAR feedbacks.},
  archive      = {J_TKDE},
  author       = {Yuanbo Xu and Fuzhen Zhuang and En Wang and Chaozhuo Li and Jie Wu},
  doi          = {10.1109/TKDE.2024.3490593},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {754-765},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning without missing-at-random prior propensity-A generative approach for recommender systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical denoising for robust social recommendation. <em>TKDE</em>, <em>37</em>(2), 739-753. (<a href='https://doi.org/10.1109/TKDE.2024.3508778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendations leverage social networks to augment the performance of recommender systems. However, the critical task of denoising social information has not been thoroughly investigated in prior research. In this study, we introduce a hierarchical denoising robust social recommendation model to tackle noise at two levels: 1) intra-domain noise, resulting from user multi-faceted social trust relationships, and 2) inter-domain noise, stemming from the entanglement of the latent factors over heterogeneous relations (e.g., user-item interactions, user-user trust relationships). Specifically, our model advances a preference and social psychology-aware methodology for the fine-grained and multi-perspective estimation of tie strength within social networks. This serves as a precursor to an edge weight-guided edge pruning strategy that refines the model's diversity and robustness by dynamically filtering social ties. Additionally, we propose a user interest-aware cross-domain denoising gate, which not only filters noise during the knowledge transfer process but also captures the high-dimensional, nonlinear information prevalent in social domains. We conduct extensive experiments on three real-world datasets to validate the effectiveness of our proposed model against state-of-the-art baselines. We perform empirical studies on synthetic datasets to validate the strong robustness of our proposed model.},
  archive      = {J_TKDE},
  author       = {Zheng Hu and Satoshi Nakagawa and Yan Zhuang and Jiawen Deng and Shimin Cai and Tao Zhou and Fuji Ren},
  doi          = {10.1109/TKDE.2024.3508778},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {739-753},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical denoising for robust social recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical abstracting graph kernel. <em>TKDE</em>, <em>37</em>(2), 724-738. (<a href='https://doi.org/10.1109/TKDE.2024.3509028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph kernels have been regarded as a successful tool for handling a variety of graph applications since they were proposed. However, most of the proposed graph kernels are based on the R-convolution framework, which decomposes graphs into a set of substructures at the same abstraction level and compares all substructure pairs equally; these methods inherently overlook the utility of the hierarchical structural information embedded in graphs. In this paper, we propose Hierarchical Abstracting Graph Kernels (HAGK), a novel set of graph kernels that compare graphs’ hierarchical substructures to capture and utilize the latent hierarchical structural information fully. Instead of generating non-structural substructures, we reveal each graph’s hierarchical substructures by constructing its hierarchical abstracting, specifically, the hierarchically organized nested node sets adhering to the principle of structural entropy minimization. To compare a pair of hierarchical abstractings, we propose two novel substructure matching approaches, Local Optimal Matching (LOM) and Priority Ordering Matching (POM), to find appropriate matching between the substructures by different strategies recursively. Extensive experiments demonstrate that the proposed kernels are highly competitive with the existing state-of-the-art graph kernels, and verify that the hierarchical abstracting plays a significant role in the improvement of the kernel performance.},
  archive      = {J_TKDE},
  author       = {Runze Yang and Hao Peng and Angsheng Li and Peng Li and Chunyang Liu and Philip S. Yu},
  doi          = {10.1109/TKDE.2024.3509028},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {724-738},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical abstracting graph kernel},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph cross-correlated network for recommendation. <em>TKDE</em>, <em>37</em>(2), 710-723. (<a href='https://doi.org/10.1109/TKDE.2024.3491778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) models have demonstrated remarkable performance in recommender systems, which represent users and items as embedding vectors. Recently, due to the powerful modeling capability of graph neural networks for user-item interaction graphs, graph-based CF models have gained increasing attention. They encode each user/item and its subgraph into a single super vector by combining graph embeddings after each graph convolution. However, each hop of the neighbor in the user-item subgraphs carries a specific semantic meaning. Encoding all subgraph information into single vectors and inferring user-item relations with dot products can weaken the semantic information between user and item subgraphs, thus leaving untapped potential. Exploiting this untapped potential provides insight into improving performance for existing recommendation models. To this end, we propose the Graph Cross-correlated Network for Recommendation (GCR), which serves as a general recommendation paradigm that explicitly considers correlations between user/item subgraphs. GCR first introduces the Plain Graph Representation (PGR) to extract information directly from each hop of neighbors into corresponding PGR vectors. Then, GCR develops Cross-Correlated Aggregation (CCA) to construct possible cross-correlated terms between PGR vectors of user/item subgraphs. Finally, GCR comprehensively incorporates the cross-correlated terms for recommendations. Experimental results show that GCR outperforms state-of-the-art models on both interaction prediction and click-through rate prediction tasks.},
  archive      = {J_TKDE},
  author       = {Hao Chen and Yuanchen Bei and Wenbing Huang and Shengyuan Chen and Feiran Huang and Xiao Huang},
  doi          = {10.1109/TKDE.2024.3491778},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {710-723},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph cross-correlated network for recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gecko: Efficient sliding window aggregation with granular-based bulk eviction over big data streams. <em>TKDE</em>, <em>37</em>(2), 698-709. (<a href='https://doi.org/10.1109/TKDE.2024.3511334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sliding window aggregation, which extracts summaries from data streams, is a core operation in streaming analysis. Though existing sliding window algorithms that perform single eviction and insertion operations can achieve a worst-case time complexity of $O(1)$ for in-order streams, real-world data streams often involve out-of-order data and exhibit burst data characteristics, which pose performance challenges to these sliding window algorithms. To address this challenging issue, we propose Gecko - a novel sliding window aggregation algorithm that supports bulk eviction. Gecko leverages a granular-based eviction strategy for various bulk sizes, enabling efficient bulk eviction while maintaining the performance close to that of in-order stream algorithms for single evictions. For large data bulks, Gecko performs coarse-grained eviction at the chunk level, followed by fine-grained eviction using leftward binary tree aggregation (LTA) as a complementary method. Moreover, Gecko partitions data based on chunks to prevent the impacts of out-of-order data on other chunks, thereby enabling efficient handling of out-of-order data streams. We conduct extensive experiments to evaluate the performance of Gecko. Experimental results demonstrate that Gecko exhibits superior performance over other solutions, which is consistent with theoretical expectations. In real-world data scenarios, Gecko improves the average throughput of the state-of-the-art algorithm b_FiBA by 1.7 times, with a maximum improvement of up to 3.5 times. Gecko also demonstrates the best latency performance among all compared schemes.},
  archive      = {J_TKDE},
  author       = {Jianjun Li and Yuhui Deng and Jiande Huang and Yi Zhou and Qifen Yang and Geyong Min},
  doi          = {10.1109/TKDE.2024.3511334},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {698-709},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Gecko: Efficient sliding window aggregation with granular-based bulk eviction over big data streams},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FWCEC: An enhanced feature weighting method via causal effect for clustering. <em>TKDE</em>, <em>37</em>(2), 685-697. (<a href='https://doi.org/10.1109/TKDE.2024.3508057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature weighting aims to assign different weights to features based on their importance in machine learning tasks. In clustering tasks, the existing methods learn feature importance based on the clustering results derived from the collaborative contribution of all features, which overlooks the independent effect of each feature. In fact, there are underlying causal relationships between features and the clustering results, and the features with high causal effects are always more crucial for clustering. Therefore, we propose an enhanced Feature Weighting method via Causal Effect for Clustering, calculating the causal effect of each feature on the clustering results for obtaining the independent contribution of each feature. Specifically, we start by identifying the causal relationships among the features and utilizing the causal relationships to generate a reasonable treatment group. Next, we compare the changes in the data distribution between the treatment and control groups to determine the causal effect of each feature. Finally, the causal effects of features are used for enhancing the clustering-driven weight learning. Moreover, we present a theory of relative order consistency in causal effect. Experimental results demonstrate that utilizing causal effect in weight learning facilitates efficient convergence and achieves superior accuracy compared to state-of-the-art clustering algorithms.},
  archive      = {J_TKDE},
  author       = {Fuyuan Cao and Xuechun Jing and Kui Yu and Jiye Liang},
  doi          = {10.1109/TKDE.2024.3508057},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {685-697},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FWCEC: An enhanced feature weighting method via causal effect for clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing monotonic decision tree based on related family. <em>TKDE</em>, <em>37</em>(2), 670-684. (<a href='https://doi.org/10.1109/TKDE.2024.3487641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monotonic classification is a special ordinal classification task that involves monotonicity constraints between features and the decision. Monotonic feature selection can reduce dimensionality while preserving the monotonicity constraints, ultimately improving the efficiency and performance of monotonic classifiers. However, existing feature selection algorithms cannot handle large-scale monotonic data sets due to their lack of consideration for monotonic constraints or their high computational complexities. To address these issues, building on our team's previous research, we define the monotonic related family method with lower time complexity to select informative features and obtain multi-reducts carrying complementary information from multi-view for raw feature space. Using bi-directional rank mutual information, we build two trees for each feature subset and fuse all trees using the corresponding decision support level (BFMDT). Compared with six representative algorithms for monotonic feature selection, BFMDT's average classification accuracy increased by 4.06% (FFREMT), 6.77% (FCMT), 5.61% (FPRS_up), 6.05% (FPRS_down), 5.86%(FPRS_global), 4.41% (Bagging), 7.65% (REMT) and 21.89% (FMKNN), the average execution time compared to tree-based algorithms decreased by 83.41% (FFREMT), 96.96% (FCMT), 75.64% (FPRS_up), 59.43% (FPRS_down), 84.65%(FPRS_global), 81.50% (Bagging) and 63.41% (REMT), while most of comparing algorithms were unable to complete computation on six high-dimensional datasets.},
  archive      = {J_TKDE},
  author       = {Tian Yang and Fansong Yan and Fengcai Qiao and Jieting Wang and Yuhua Qian},
  doi          = {10.1109/TKDE.2024.3487641},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {670-684},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fusing monotonic decision tree based on related family},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding antagonistic communities in signed uncertain graphs. <em>TKDE</em>, <em>37</em>(2), 655-669. (<a href='https://doi.org/10.1109/TKDE.2024.3496586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world networks are signed networks with positive and negative edge weights, such as social networks with positive (friend) or negative (foe) relationships between users, and gene interaction networks with positive (stimulatory) or negative (inhibitory) interactions between genes. A well-known data mining task in signed networks is to find groups of antagonistic communities, where the vertices in the same community have a strong positive relationship and the vertices in different communities have a strong negative relationship. Most existing methods find antagonistic communities by modelling a signed network as a static graph with constant positive and negative edge weights. However, since the relationship between vertices is often uncertain in many real-world networks, it is more practical and accurate to capture the uncertainty of the relationship in the network by a signed uncertain graph (SUG), where each edge is independently associated with a discrete probability distribution of signed edge weights. How to find groups of antagonistic communities in a SUG is a challenging data mining task that has not been systematically tackled before. In this paper, we propose a novel method to tackle this task. We first model a group of antagonistic communities by a set of subgraphs, where the vertices in the same subgraph have a large expectation of positive edge weights and the vertices in different subgraphs have a large expectation of negative edge weights. Then, we propose a method to efficiently find significant groups of antagonistic communities by restricting all the computations on small local subgraphs of the SUG. Extensive experiments on seven real-world datasets and a synthetic dataset demonstrate the outstanding effectiveness and efficiency of the proposed method.},
  archive      = {J_TKDE},
  author       = {Qiqi Zhang and Lingyang Chu and Zijin Zhao and Jian Pei},
  doi          = {10.1109/TKDE.2024.3496586},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {655-669},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Finding antagonistic communities in signed uncertain graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FairSort: Learning to fair rank for personalized recommendations in two-sided platforms. <em>TKDE</em>, <em>37</em>(2), 641-654. (<a href='https://doi.org/10.1109/TKDE.2024.3509912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation systems focus on maximizing user satisfaction by suggesting their favorite items. This user-centric approach may lead to unfair exposure distribution among the providers. On the contrary, a provider-centric design might become unfair to the users. Therefore, this paper proposes a re-ranking model FairSort1 to find a trade-off solution among user-side fairness, provider-side fairness, and personalized recommendations utility. Previous works habitually treat this issue as a knapsack problem, incorporating both-side fairness as constraints. In this paper, we adopt a novel perspective, treating each recommendation list as a runway rather than a knapsack. In this perspective, each item on the runway gains a velocity and runs within a specific time, achieving re-ranking for both-side fairness. Meanwhile, we ensure the Minimum Utility Guarantee for personalized recommendations by designing a Binary Search approach. This can provide more reliable recommendations compared to the conventional greedy strategy based on the knapsack problem. We further broaden the applicability of FairSort, designing two versions for online and offline recommendation scenarios. Theoretical analysis and extensive experiments on real-world datasets indicate that FairSort can ensure more reliable personalized recommendations while considering fairness for both the provider and user.},
  archive      = {J_TKDE},
  author       = {Guoli Wu and Zhiyong Feng and Shizhan Chen and Hongyue Wu and Xiao Xue and Jianmao Xiao and Guodong Fan and Hongqi Chen and Jingyu Li},
  doi          = {10.1109/TKDE.2024.3509912},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {641-654},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FairSort: Learning to fair rank for personalized recommendations in two-sided platforms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient projection-based algorithms for tip decomposition on dynamic bipartite graphs. <em>TKDE</em>, <em>37</em>(2), 626-640. (<a href='https://doi.org/10.1109/TKDE.2024.3486310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the pressing need for effective k-tips decomposition in dynamic bipartite graphs, a crucial aspect of real-time applications that analyze and mine binary relationship patterns. Recognizing the dynamic nature of these graphs, our study is the first to provide a solution for k-tips decomposition in such evolving environments. We introduce a pioneering projection-based algorithm, coupled with advanced incremental maintenance strategies for edge modifications, tailored specifically for dynamic graphs. This novel approach not only fills a significant gap in the analysis of dynamic bipartite graphs but also substantially enhances the accuracy and timeliness of data-driven decisions in critical areas like public health. Our contributions set a new benchmark in the field, paving the way for more nuanced and responsive analyses in various domains reliant on dynamic data interpretation.},
  archive      = {J_TKDE},
  author       = {Tongfeng Weng and Yumeng Liu and Mo Sha and Xinyuan Chen and Xu Zhou and Kenli Li and Kian-Lee Tan},
  doi          = {10.1109/TKDE.2024.3486310},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {626-640},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient projection-based algorithms for tip decomposition on dynamic bipartite graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early detection of multimodal fake news via reinforced propagation path generation. <em>TKDE</em>, <em>37</em>(2), 613-625. (<a href='https://doi.org/10.1109/TKDE.2024.3496701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amidst the rapid propagation of multimodal fake news across social media platforms, the detection of fake news has emerged as a prime research pursuit. To detect heightened level of meticulous fabrications, propagation paths are introduced to provide nuanced social context that enhances the basic semantic analysis of the news content. However, existing propagation-enhanced models encounter a dilemma between detection efficacy and social hazard. In this paper, we explore the innovative problem of early fake news detection through the generation of propagation paths, capable of benefiting from the extensive social context within propagation paths while mitigating potential social hazards. To address these challenges, we propose a novel Reinforced Propagation Path Generation Fake News Detection model, RPPG-Fake. Departing from conventional discriminative approaches, RPPG-Fake captures the propagation topology pattern from a heterogeneous social graph and generates the propagation paths to detect fake news effectively under a reinforcement learning paradigm. Our proposal is extensively evaluated over three popular datasets, and experimental results demonstrate the superiority of our proposal.},
  archive      = {J_TKDE},
  author       = {Litian Zhang and Xiaoming Zhang and Ziyi Zhou and Xi Zhang and Senzhang Wang and Philip S. Yu and Chaozhuo Li},
  doi          = {10.1109/TKDE.2024.3496701},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {613-625},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Early detection of multimodal fake news via reinforced propagation path generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view desynchronization hypergraph learning for dynamic hyperedge prediction. <em>TKDE</em>, <em>37</em>(2), 597-612. (<a href='https://doi.org/10.1109/TKDE.2024.3509024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperedges, as extensions of pairwise edges, can characterize higher-order relations among multiple individuals. Due to the necessity of hypergraph detection in practical systems, hyperedge prediction has become a frontier problem in complex networks. However, previous hyperedge prediction models encounter three challenges: (i) failing to predict dynamic and arbitrary-order hyperedges simultaneously, (ii) confusing higher-order and lower-order features together to propagate neighborhood information, and (iii) lacking the capability to learn physical evolution laws, which lead to poor performance of the models. To tackle these challenges, we propose D$^{3}$HP, a Dual-view Desynchronization hypergraph learning for arbitrary-order Dynamic Hyperedge Prediction. Specifically, D$^{3}$HP extracts the dynamic higher-order and lower-order features of hyperedges separately through an elastic hypergraph neural network (EHGNN) and an alternate desynchronization graph convolutional network (ADGCN) at each time snapshot. EHGNN is designed to incrementally mine the implicit higher-order relations and propagate neighborhood information. Moreover, ADGCN aims to combine GCN with desynchronization learining to learn the physical evolution of lower-order relations and alleviate the over-smoothing problem. Further, we improve the prediction performance of the model by rationally fusing the features learned from the dual views. Extensive experiments on 8 dynamic higher-order networks demonstrate that D$^{3}$HP outperforms 14 state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Zhihui Wang and Jianrui Chen and Zhongshi Shao and Zhen Wang},
  doi          = {10.1109/TKDE.2024.3509024},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {597-612},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dual-view desynchronization hypergraph learning for dynamic hyperedge prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting and analyzing motifs in large-scale online transaction networks. <em>TKDE</em>, <em>37</em>(2), 584-596. (<a href='https://doi.org/10.1109/TKDE.2024.3511136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motif detection is a graph algorithm that detects certain local structures in a graph. Although network motif has been studied in graph analytics, e.g., social network and biological network, it is yet unclear whether network motif is useful for analyzing online transaction network that is generated in applications such as instant messaging and e-commerce. In an online transaction network, each vertex represents a user’s account and each edge represents a money transaction between two users. In this work, we try to analyze online transaction networks with network motifs. We design motif-based vertex embedding that integrates motif counts and centrality measurements. Furthermore, we design a distributed framework to detect motifs in large-scale online transaction networks. Our framework obtains the edge directions using a bi-directional tagging method and avoids redundant detection with a reduced view of neighboring vertices. We implement the proposed framework under the parameter server architecture. In the evaluation, we analyze different kinds of online transaction networks w.r.t the distribution of motifs and evaluate the effectiveness of motif-based embedding in downstream graph analytical tasks. The experimental results also show that our proposed motif detection framework can efficiently handle large-scale graphs.},
  archive      = {J_TKDE},
  author       = {Jiawei Jiang and Hao Huang and Zhigao Zheng and Yi Wei and Fangcheng Fu and Xiaosen Li and Bin Cui},
  doi          = {10.1109/TKDE.2024.3511136},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {584-596},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Detecting and analyzing motifs in large-scale online transaction networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual inference from sparse shopping transactions based on motif patterns. <em>TKDE</em>, <em>37</em>(2), 572-583. (<a href='https://doi.org/10.1109/TKDE.2024.3452638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring contextual information such as demographics from historical transactions is valuable to public agencies and businesses. Existing methods are data-hungry and do not work well when the available records of transactions are sparse. We consider here specifically inference of demographic information using limited historical grocery transactions from a few random trips that a typical business or public service organization may see. We propose a novel method called DemoMotif to build a network model from heterogeneous data and identify subgraph patterns (i.e., motifs) that enable us to infer demographic attributes. We then design a novel motif context selection algorithm to find specific node combinations significant to certain demographic groups. Finally, we learn representations of households using these selected motif instances as context, and employ a standard classifier (e.g., SVM) for inference. For evaluation purposes, we use three real-world consumer datasets, spanning different regions and time periods in the U.S. We evaluate the framework for predicting three attributes: ethnicity, seniority of household heads, and presence of children. Extensive experiments and case studies demonstrate that DemoMotif is capable of inferring household demographics using only a small number (e.g., fewer than 10) of random grocery trips, significantly outperforming the state-of-the-art.},
  archive      = {J_TKDE},
  author       = {Jiayun Zhang and Xinyang Zhang and Dezhi Hong and Rajesh K. Gupta and Jingbo Shang},
  doi          = {10.1109/TKDE.2024.3452638},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {572-583},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Contextual inference from sparse shopping transactions based on motif patterns},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficiently updatable path oracle for terrain surfaces. <em>TKDE</em>, <em>37</em>(2), 557-571. (<a href='https://doi.org/10.1109/TKDE.2024.3484434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The booming of computer graphics technology facilitates the growing use of terrain data. Notably, shortest path querying on a terrain surface is central in a range of applications and has received substantial attention from the database community. Despite this, computing the shortest paths on-the-fly on a terrain surface remains very expensive, and all existing oracle-based algorithms are only efficient when the terrain surface is fixed. They rely on large data structures that must be re-constructed from scratch when updates to the terrain surface occur, which is very time-consuming. To advance the state-of-the-art, we propose an efficiently updatable $(1+\epsilon )$-approximate shortest path oracle for a set of Points-Of-Interests (POIs) on an updated terrain surface, and it can be easily adapted to the case if POIs are not given as input. Our experiments show that when POIs are given (resp. not given), our oracle is up to 88 times, 12 times, and 3 times (resp. 15 times, 50 times, and 100 times) better than the best-known oracle on terrain surfaces in terms of the oracle update time, output size, and shortest path query.},
  archive      = {J_TKDE},
  author       = {Yinzhao Yan and Raymond Chi-Wing Wong and Christian S. Jensen},
  doi          = {10.1109/TKDE.2024.3484434},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {2},
  number       = {2},
  pages        = {557-571},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An efficiently updatable path oracle for terrain surfaces},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Y-graph: A max-ascent-angle graph for detecting clusters. <em>TKDE</em>, <em>37</em>(1), 542-556. (<a href='https://doi.org/10.1109/TKDE.2024.3486221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering technique is highly effective in detecting complex-shaped clusters, in which graph building is a crucial step. Nevertheless, building a reasonable graph that can exhibit high connectivity within clusters and low connectivity across clusters is challenging. Herein, we design a max-ascent-angle graph called the “Y-graph”, a high-sparse graph that automatically allocates dense edges within clusters and sparse edges across clusters, regardless of their shapes or dimensionality. In the graph, every point $x$ is allowed to connect its nearest higher-density neighbor $\delta$, and another higher-density neighbor $\gamma$, satisfying that the angle $\angle \delta x\gamma$ is the largest, called “max-ascent-angle”. By seeking the max-ascent-angle, points are automatically connected as the Y-graph, which is a reasonable graph that can effectively balance inter-cluster connectivity and intra-cluster non-connectivity. Besides, an edge weight function is designed to capture the similarity of the neighbor probability distribution, which effectively represents the density connectivity between points. By employing the Normalized-Cut (Ncut) technique, a Ncut-Y algorithm is proposed. Benefiting from the excellent performance of Y-graph, Ncut-Y can fast seek and cut the edges located in the low-density boundaries between clusters, thereby, capturing clusters effectively. Experimental results on both synthetic and real datasets demonstrate the effectiveness of Y-graph and Ncut-Y.},
  archive      = {J_TKDE},
  author       = {Junyi Guan and Sheng Li and Xiongxiong He and Jiajia Chen and Yangyang Zhao and Yuxuan Zhang},
  doi          = {10.1109/TKDE.2024.3486221},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {542-556},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Y-graph: A max-ascent-angle graph for detecting clusters},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TGformer: A graph transformer framework for knowledge graph embedding. <em>TKDE</em>, <em>37</em>(1), 526-541. (<a href='https://doi.org/10.1109/TKDE.2024.3486747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is efficient method for reasoning over known facts and inferring missing links. Existing methods are mainly triplet-based or graph-based. Triplet-based approaches learn the embedding of missing entities by a single triple only. They ignore the fact that the knowledge graph is essentially a graph structure. Graph-based methods consider graph structure information but ignore the contextual information of nodes in the knowledge graph, making them unable to discern valuable entity (relation) information. In response to the above limitations, we propose a general graph transformer framework for knowledge graph embedding (TGformer). It is the first to use a graph transformer to build knowledge embeddings with triplet-level and graph-level structural features in the static and temporal knowledge graph. Specifically, a context-level subgraph is constructed for each predicted triplet, which models the relation between triplets with the same entity. Afterward, we design a knowledge graph transformer network (KGTN) to fully explore multi-structural features in knowledge graphs, including triplet-level and graph-level, boosting the model to understand entities (relations) in different contexts. Finally, semantic matching is adopted to select the entity with the highest score. Experimental results on several public knowledge graph datasets show that our method can achieve state-of-the-art performance in link prediction.},
  archive      = {J_TKDE},
  author       = {Fobo Shi and Duantengchuan Li and Xiaoguang Wang and Bing Li and Xindong Wu},
  doi          = {10.1109/TKDE.2024.3486747},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {526-541},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TGformer: A graph transformer framework for knowledge graph embedding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-aware data selectivity in pervasive edge computing environments. <em>TKDE</em>, <em>37</em>(1), 513-525. (<a href='https://doi.org/10.1109/TKDE.2024.3485531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-aware data selectivity in Edge Computing (EC) requires nodes to efficiently manage the data collected from Internet of Things (IoT) devices, e.g., sensors, for supporting real-time and data-driven pervasive analytics. Data selectivity at the network edge copes with the challenge of deciding which data should be kept at the edge for future analytics tasks under limited computational and storage resources. Our challenge is to efficiently learn the access patterns of data-driven tasks (analytics) and predict which data are relevant, thus, being stored in nodes’ local datasets. Task patterns directly indicate which data need to be accessed and processed to support end-users’ applications. We introduce a task workload-aware mechanism which adopts one-class classification to learn and predict the relevant data requested by past tasks. The inherent uncertainty in learning task patterns, identifying inliers and eliminating outliers is handled by introducing a lightweight fuzzy inference estimator that dynamically adapts nodes’ local data filters ensuring accurate data relevance prediction. We analytically describe our mechanism and comprehensively evaluate and compare against baselines and approaches found in the literature showcasing its applicability in pervasive EC.},
  archive      = {J_TKDE},
  author       = {Athanasios Koukosias and Christos Anagnostopoulos and Kostas Kolomvatsos},
  doi          = {10.1109/TKDE.2024.3485531},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {513-525},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Task-aware data selectivity in pervasive edge computing environments},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey and benchmark of anomaly detection in business processes. <em>TKDE</em>, <em>37</em>(1), 493-512. (<a href='https://doi.org/10.1109/TKDE.2024.3484159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective management of business processes is crucial for organizational success. However, despite meticulous design and implementation, anomalies are inevitable and can result in inefficiencies, delays, or even significant financial losses. Numerous methods for detecting anomalies in business processes have been proposed recently. However, there is no comprehensive benchmark to evaluate these methods. Consequently, the relative merits of each method remain unclear due to differences in their experimental setup, choice of datasets and evaluation measures. In this paper, we present a systematic literature review and taxonomy of business process anomaly detection methods. Additionally, we select at least one method from each category, resulting in 16 methods that are cross-benchmarked against 32 synthetic logs and 19 real-life logs from different industry domains. Our analysis provides insights into the strengths and weaknesses of different anomaly detection methods. Ultimately, our findings can help researchers and practitioners in the field of process mining make informed decisions when selecting and applying anomaly detection methods to real-life business scenarios. Finally, some future directions are discussed in order to promote the evolution of business process anomaly detection.},
  archive      = {J_TKDE},
  author       = {Wei Guan and Jian Cao and Haiyan Zhao and Yang Gu and Shiyou Qian},
  doi          = {10.1109/TKDE.2024.3484159},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {493-512},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Survey and benchmark of anomaly detection in business processes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable semi-supervised clustering via structural entropy with different constraints. <em>TKDE</em>, <em>37</em>(1), 478-492. (<a href='https://doi.org/10.1109/TKDE.2024.3486530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information in the form of constraints to achieve higher-quality clustering outcomes. However, most existing methods struggle with large-scale datasets owing to their high time and space complexity. Moreover, they encounter the challenge of seamlessly integrating various constraints, thereby limiting their applicability. In this paper, we present Scalable Semi-supervised clustering via Structural Entropy (SSSE), a novel method that tackles scalable datasets with different types of constraints from diverse sources to perform both semi-supervised partitioning and hierarchical clustering, which is fully explainable compared to deep learning-based methods. Specifically, we design objectives based on structural entropy, integrating constraints for semi-supervised partitioning and hierarchical clustering. To achieve scalability on data size, we develop efficient algorithms based on graph sampling to reduce the time and space complexity. To achieve generalization on constraint types, we formulate a uniform view for widely used pairwise and label constraints. Extensive experiments on real-world clustering datasets at different scales demonstrate the superiority of SSSE in clustering accuracy and scalability with different constraints. Additionally, Cell clustering experiments on single-cell RNA-seq datasets demonstrate the functionality of SSSE for biological data analysis.},
  archive      = {J_TKDE},
  author       = {Guangjie Zeng and Hao Peng and Angsheng Li and Jia Wu and Chunyang Liu and Philip S. Yu},
  doi          = {10.1109/TKDE.2024.3486530},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {478-492},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable semi-supervised clustering via structural entropy with different constraints},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PURE: Personality-coupled multi-task learning framework for aspect-based multimodal sentiment analysis. <em>TKDE</em>, <em>37</em>(1), 462-477. (<a href='https://doi.org/10.1109/TKDE.2024.3485108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Multimodal Sentiment Analysis (ABMSA) aims to infer the users’ sentiment polarities over individual aspects using visual, textual, and acoustic signals. Although psychological studies have shown that personality has a direct impact on people's sentiment orientations, most existing methods disregard the potential personality character while executing ABMSA tasks. To tackle this issue, a novel psychological perspective, the people's personalities are introduced. To the best of our knowledge, this paper is the very first study in this field. Different from current pipelined multi-task sentiment analysis methods, an end-to-end ABMSA method called Personality-coupled mUlti-task leaRning framEwork (PURE) is proposed, which strongly couples personality mining and ABMSA tasks in a unified architecture to avoid error propagation and enhance the overall system robustness. Specifically, an adaptive personality feature extraction method is designed to accurately model the first impression of different people's personalities. Then, a multi-task ABMSA framework is designed to strongly couple the multimodal features of aspects extracted by the interactive attention fusion network with people's personalities. Subsequently, the proposed framework optimizes them parallel via extended Bayesian meta-learning. Finally, compared to the current optimal model, the classification accuracy and macro F1 score of the proposed model have both shown significant improvements on public datasets. In addition, PURE is transferable and can effectively couple personality modeling tasks with any other sentiment analysis methods.},
  archive      = {J_TKDE},
  author       = {Puning Zhang and Miao Fu and Rongjian Zhao and Hongbin Zhang and Changchun Luo},
  doi          = {10.1109/TKDE.2024.3485108},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {462-477},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PURE: Personality-coupled multi-task learning framework for aspect-based multimodal sentiment analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PUMA: Efficient continual graph learning for node classification with graph condensation. <em>TKDE</em>, <em>37</em>(1), 449-461. (<a href='https://doi.org/10.1109/TKDE.2024.3485691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When handling streaming graphs, existing graph representation learning models encounter a catastrophic forgetting problem, where previously learned knowledge of these models is easily overwritten when learning with newly incoming graphs. In response, Continual Graph Learning (CGL) emerges as a novel paradigm enabling graph representation learning from static to streaming graphs. Our prior work, Condense and Train (CaT) (Liu et al. 2023) is a replay-based CGL framework with a balanced continual learning procedure, which designs a small yet effective memory bank for replaying data by condensing incoming graphs. Although the CaT alleviates the catastrophic forgetting problem, there exist three issues: (1) The graph condensation algorithm derived in CaT only focuses on labelled nodes while neglecting abundant information carried by unlabelled nodes; (2) The continual training scheme of the CaT overemphasises on the previously learned knowledge, limiting the model capacity to learn from newly added memories; (3) Both the condensation process and replaying process of the CaT are time-consuming. In this paper, we propose a PsUdo-label guided Memory bAnk (PUMA) CGL framework, extending from the CaT to enhance its efficiency and effectiveness by overcoming the above-mentioned weaknesses and limits. To fully exploit the information in a graph, PUMA expands the coverage of nodes during graph condensation with both labelled and unlabelled nodes. Furthermore, a training-from-scratch strategy is proposed to upgrade the previous continual learning scheme for a balanced training between the historical and the new graphs. Besides, PUMA uses a one-time prorogation and wide graph encoders to accelerate the graph condensation and the graph encoding process in the training stage to improve the efficiency of the whole framework. Extensive experiments on seven datasets for the node classification task demonstrate the state-of-the-art performance and efficiency over existing methods.},
  archive      = {J_TKDE},
  author       = {Yilun Liu and Ruihong Qiu and Yanran Tang and Hongzhi Yin and Zi Huang},
  doi          = {10.1109/TKDE.2024.3485691},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {449-461},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PUMA: Efficient continual graph learning for node classification with graph condensation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPM: Multi patterns memory model for short-term time series forecasting. <em>TKDE</em>, <em>37</em>(1), 438-448. (<a href='https://doi.org/10.1109/TKDE.2024.3490843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term time series forecasting is pivotal in various scientific and industrial fields. Recent advancements in deep learning-based technologies have significantly improved the efficiency and accuracy of short-term time series modeling. Despite advancements, current time short-term series forecasting methods typically emphasize modeling dependencies across time stamps but frequently overlook inter-variable dependencies, which is crucial for multivariate forecasting. We propose a multi patterns memory model discovering various dependency patterns for short-term multivariate time series forecasting to fill the gap. The proposed model is structured around two key components: the short-term memory block and the long-term memory block. These networks are distinctively characterized by their use of asymmetric convolution, each tailored to process the various spatial-temporal dependencies among data. Experimental results show that the proposed model demonstrates competitive performance over the other time series forecasting methods across five benchmark datasets, likely thanks to the asymmetric structure, which can effectively extract the underlying various spatial-temporal dependencies among data.},
  archive      = {J_TKDE},
  author       = {Dezheng Wang and Rongjie Liu and Congyan Chen and Shihua Li},
  doi          = {10.1109/TKDE.2024.3490843},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {438-448},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MPM: Multi patterns memory model for short-term time series forecasting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning road network index structure for efficient map matching. <em>TKDE</em>, <em>37</em>(1), 423-437. (<a href='https://doi.org/10.1109/TKDE.2024.3485195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Map matching aims to align GPS trajectories to their actual travel routes on a road network, which is an essential pre-processing task for most of trajectory-based applications. Many map matching approaches utilize Hidden Markov Model (HMM) as their backbones. Typically, HMM treats GPS samples of a trajectory as observations and nearby road segments as hidden states. During map matching, HMM determines candidate states for each observation with a fixed searching range, and computes the most likely travel route using the Viterbi algorithm. Although HMM-based approaches can derive high matching accuracy, they still suffer from high computation overheads. By inspecting the HMM process, we find that the computation bottleneck mainly comes from improper candidate sets, which contain many irrelevant candidates and incur unnecessary computations. In this paper, we present $\mathtt {LiMM}$ – a learned road network index structure for efficient map matching. $\mathtt {LiMM}$ improves existing HMM-based approaches from two aspects. First, we propose a novel learned index for road networks, which considers the characteristics of road data. Second, we devise an adaptive searching range mechanism to dynamically adjust the searching range for GPS samples based on their locations. As a result, $\mathtt {LiMM}$ can provide refined candidate sets for GPS samples and thus accelerate the map matching process. Extensive experiments are conducted with three large real-world GPS trajectory datasets. The results demonstrate that $\mathtt {LiMM}$ significantly reduces computation overheads by achieving an average speedup of $11.7\times$ than baseline methods, merely with a subtle accuracy loss of 1.8%.},
  archive      = {J_TKDE},
  author       = {Zhidan Liu and Yingqian Zhou and Xiaosi Liu and Haodi Zhang and Yabo Dong and Dongming Lu and Kaishun Wu},
  doi          = {10.1109/TKDE.2024.3485195},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {423-437},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning road network index structure for efficient map matching},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-oriented random walks and pipeline optimization for distributed graph embedding. <em>TKDE</em>, <em>37</em>(1), 408-422. (<a href='https://doi.org/10.1109/TKDE.2024.3424333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding maps graph nodes to low-dimensional vectors and is widely used in machine learning tasks. The increasing availability of billion-edge graphs underscores the importance of learning efficient and effective embeddings on large graphs, such as link prediction on Twitter with over one billion edges. Most existing graph embedding methods fall short of reaching high data scalability. In this paper, we present a general-purpose, distributed, information-centric random walk-based, and pipeline-optimized graph embedding framework, $\sf{DistGER-Pipe}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">e</mml:mi></mml:mrow></mml:math>, which scales to embed billion-edge graphs. $\sf{DistGER-Pipe}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">e</mml:mi></mml:mrow></mml:math> incrementally computes information-centric random walks to reduce redundant computations for more effective and efficient graph embedding. It further leverages a multi-proximity-aware, streaming, parallel graph partitioning strategy, simultaneously achieving high local partition quality and excellent workload balancing across machines. $\sf{DistGER-Pipe}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">e</mml:mi></mml:mrow></mml:math> also improves the distributed $\sf{Skip-Gram}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">S</mml:mi><mml:mi mathvariant="sans-serif">k</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">r</mml:mi><mml:mi mathvariant="sans-serif">a</mml:mi><mml:mi mathvariant="sans-serif">m</mml:mi></mml:mrow></mml:math> learning model to generate node embeddings by optimizing access locality, CPU throughput, and synchronization efficiency. Finally, $\sf{DistGER-Pipe}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">e</mml:mi></mml:mrow></mml:math> designs pipelined execution that decouples the operators in sampling and training procedures with an inter-round serial and intra-round parallel processing, attaining optimal utilization of computing resources. Experiments on real-world graphs demonstrate that compared to state-of-the-art distributed graph embedding frameworks, including $\sf{KnightKing}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">K</mml:mi><mml:mi mathvariant="sans-serif">n</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">g</mml:mi><mml:mi mathvariant="sans-serif">h</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">K</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">n</mml:mi><mml:mi mathvariant="sans-serif">g</mml:mi></mml:mrow></mml:math>, $\sf{DistDGL}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">L</mml:mi></mml:mrow></mml:math>, $\sf{Pytorch-BigGraph}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">y</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">o</mml:mi><mml:mi mathvariant="sans-serif">r</mml:mi><mml:mi mathvariant="sans-serif">c</mml:mi><mml:mi mathvariant="sans-serif">h</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">B</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">g</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">r</mml:mi><mml:mi mathvariant="sans-serif">a</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">h</mml:mi></mml:mrow></mml:math>, and $\sf{DistGER}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi></mml:mrow></mml:math>, $\sf{DistGER-Pipe}$<mml:math><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="sans-serif">D</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">s</mml:mi><mml:mi mathvariant="sans-serif">t</mml:mi><mml:mi mathvariant="sans-serif">G</mml:mi><mml:mi mathvariant="sans-serif">E</mml:mi><mml:mi mathvariant="sans-serif">R</mml:mi><mml:mo mathvariant="sans-serif">−</mml:mo><mml:mi mathvariant="sans-serif">P</mml:mi><mml:mi mathvariant="sans-serif">i</mml:mi><mml:mi mathvariant="sans-serif">p</mml:mi><mml:mi mathvariant="sans-serif">e</mml:mi></mml:mrow></mml:math> exhibits 3.15×–1053× acceleration, 45% reduction in cross-machines communication, >10% effectiveness improvement in downstream tasks, and 38% enhancement in CPU utilization.},
  archive      = {J_TKDE},
  author       = {Peng Fang and Zhenli Li and Arijit Khan and Siqiang Luo and Fang Wang and Zhan Shi and Dan Feng},
  doi          = {10.1109/TKDE.2024.3424333},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {408-422},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Information-oriented random walks and pipeline optimization for distributed graph embedding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In search of a memory-efficient framework for online cardinality estimation. <em>TKDE</em>, <em>37</em>(1), 392-407. (<a href='https://doi.org/10.1109/TKDE.2024.3486571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating per-flow cardinality from high-speed data streams has many applications such as anomaly detection and resource allocation. Yet despite tracking single flow cardinality with approximation algorithms offered, there remain algorithmical challenges for monitoring multi-flows especially under unbalanced cardinality distribution: existing methods adopt a uniform sketch layout and incur a large memory footprint to achieve high accuracy. Furthermore, they are hard to implement in the compact hardware used for line-rate processing. In this paper, we propose Couper, a memory-efficient measurement framework that can estimate cardinality for multi-flows under unbalanced cardinality distribution. We propose a two-layer structure based on a classic coupon collector's principle, where numerous mice flows are confined to the first layer and only the potential elephant flows are allowed to enter the second layer. Our two-layer structure can better fit the unbalanced cardinality distribution in practice and achieve much higher memory efficiency. We implement Couper in both software and hardware. Extensive evaluation under real-world and synthetic data traces show more than 20× improvements in terms of memory-efficiency compared to state-of-the-art.},
  archive      = {J_TKDE},
  author       = {Xun Song and Jiaqi Zheng and Hao Qian and Shiju Zhao and Hongxuan Zhang and Xuntao Pan and Guihai Chen},
  doi          = {10.1109/TKDE.2024.3486571},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {392-407},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {In search of a memory-efficient framework for online cardinality estimation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid cost modeling for reducing query performance regression in index tuning. <em>TKDE</em>, <em>37</em>(1), 379-391. (<a href='https://doi.org/10.1109/TKDE.2024.3484954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous index tuning (“auto-indexing” for short) has recently started being supported by cloud database service providers. Index tuners rely on query optimizer's cost estimates to recommend indexes that can minimize the execution cost of an input workload. Such cost estimates can often be erroneous that lead to significant query performance regression. To reduce the chance of regression, existing work primarily uses machine learning (ML) technologies to build prediction models to improve query execution cost estimation using actual query execution telemetry as training data. However, training data collection is typically an expensive process, especially for index tuning due to the significant overhead of creating/dropping indexes. As a result, the amount of training data can be limited in auto-indexing for cloud databases. In this paper, we propose a new approach named “hybrid cost modeling” to address this challenge. The key idea is to limit the ML-based modeling effort to the leaf operators such as table scans, index scans, and index seeks, and then combine the ML-model predicted costs of the leaf operators with optimizer's estimated costs of the other operators in the query plan. We conduct theoretical study as well as empirical evaluation to demonstrate the efficacy of applying hybrid cost modeling to index tuning, using both industrial benchmarks and real workloads.},
  archive      = {J_TKDE},
  author       = {Wentao Wu},
  doi          = {10.1109/TKDE.2024.3484954},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {379-391},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hybrid cost modeling for reducing query performance regression in index tuning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-aware adaptive graph neural network. <em>TKDE</em>, <em>37</em>(1), 365-378. (<a href='https://doi.org/10.1109/TKDE.2024.3485736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have gained attention for their ability in capturing node interactions to generate node representations. However, their performances are frequently restricted in real-world directed networks with natural hierarchical structures. Most current GNNs incorporate information from immediate neighbors or within predefined receptive fields, potentially overlooking long-range dependencies inherent in hierarchical structures. They also tend to neglect node adaptability, which varies based on their positions. To address these limitations, we propose a new model called Hierarchy-Aware Adaptive Graph Neural Network (HAGNN) to adaptively capture hierarchical long-range dependencies. Technically, HAGNN creates a hierarchical structure based on directional pair-wise node interactions, revealing underlying hierarchical relationships among nodes. The inferred hierarchy helps to identify certain key nodes, named Source Hubs in our research, which serve as hierarchical contexts for individual nodes. Shortcuts adaptively connect these Source Hubs with distant nodes, enabling efficient message passing for informative long-range interactions. Through comprehensive experiments across multiple datasets, our proposed model outperforms several baseline methods, thus establishing a new state-of-the-art in performance. Further analysis demonstrates the effectiveness of our approach in capturing relevant adaptive hierarchical contexts, leading to improved and explainable node representation.},
  archive      = {J_TKDE},
  author       = {Dengsheng Wu and Huidong Wu and Jianping Li},
  doi          = {10.1109/TKDE.2024.3485736},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {365-378},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchy-aware adaptive graph neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical deep document model. <em>TKDE</em>, <em>37</em>(1), 351-364. (<a href='https://doi.org/10.1109/TKDE.2024.3487523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic modeling is a commonly used text analysis tool for discovering latent topics in a text corpus. However, while topics in a text corpus often exhibit a hierarchical structure (e.g., cellphone is a sub-topic of electronics), most topic modeling methods assume a flat topic structure that ignores the hierarchical dependency among topics, or utilize a predefined topic hierarchy. In this work, we present a novel Hierarchical Deep Document Model (HDDM) to learn topic hierarchies using a variational autoencoder framework. We propose a novel objective function, sum of log likelihood, instead of the widely used evidence lower bound, to facilitate the learning of hierarchical latent topic structure. The proposed objective function can directly model and optimize the hierarchical topic-word distributions at all topic levels. We conduct experiments on four real-world text datasets to evaluate the topic modeling capability of the proposed HDDM method compared to state-of-the-art hierarchical topic modeling benchmarks. Experimental results show that HDDM achieves considerable improvement over benchmarks and is capable of learning meaningful topics and topic hierarchies. To further demonstrate the practical utility of HDDM, we apply it to a real-world medical notes dataset for clinical prediction. Experimental results show that HDDM can better summarize topics in medical notes, resulting in more accurate clinical predictions.},
  archive      = {J_TKDE},
  author       = {Yi Yang and John P. Lalor and Ahmed Abbasi and Daniel Dajun Zeng},
  doi          = {10.1109/TKDE.2024.3487523},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {351-364},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical deep document model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling low homophily in recommender systems with partitioned graph transformer. <em>TKDE</em>, <em>37</em>(1), 334-350. (<a href='https://doi.org/10.1109/TKDE.2024.3485880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern recommender systems derive predictions from an interaction graph that links users and items. To this end, many of today's state-of-the-art systems use graph neural networks (GNNs) to learn effective representations of these graphs under the assumption of homophily, i.e., the idea that similar users will sit close to each other in the graph. However, recent studies have revealed that real-world recommendation graphs are often heterophilous, i.e., dissimilar users will also often sit close to each other. One of the reasons for this heterophilia is shilling attacks that obscure the inherent characteristics of the graph and make the derived recommendations less accurate as a consequence. Hence, to cope with low homophily in recommender systems, we propose a recommendation model called PGT4Rec that is based on a Partitioned Graph Transformer. The model integrates label information into the learning process, which allows discriminative neighbourhoods of users to be generated. As such, the framework can both detect shilling attacks and predict user ratings for items. Extensive experiments on real and synthetic datasets show PGT4Rec as not only providing superior performance in these two tasks but also significant robustness to a range of adversarial conditions.},
  archive      = {J_TKDE},
  author       = {Thanh Tam Nguyen and Thanh Toan Nguyen and Matthias Weidlich and Jun Jo and Quoc Viet Hung Nguyen and Hongzhi Yin and Alan Wee-Chung Liew},
  doi          = {10.1109/TKDE.2024.3485880},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {334-350},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Handling low homophily in recommender systems with partitioned graph transformer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GZOO: Black-box node injection attack on graph neural networks via zeroth-order optimization. <em>TKDE</em>, <em>37</em>(1), 319-333. (<a href='https://doi.org/10.1109/TKDE.2024.3483274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of Graph Neural Networks (GNNs) emphasizes the imperative to assess their resilience against node injection attacks, a type of evasion attacks that impact victim models by injecting nodes with fabricated attributes and structures. However, prevailing attacks face two primary limitations: (1) Sequential construction of attributes and structures results in suboptimal outcomes as structure information is overlooked during attribute construction and vice versa. (2) In black-box scenarios, where attackers lack access to victim model architecture and parameters, reliance on surrogate models degrades performance due to architectural discrepancies. To overcome these limitations, we introduce GZOO, a black-box node injection attack that leverages an adversarial graph generator, compromising both attribute and structure sub-generators. This integration crafts optimal attributes and structures by considering their mutual information, enhancing their influence when aggregating information from injected nodes. Furthermore, GZOO proposes a zeroth-order optimization algorithm leveraging prediction results from victim models to estimate gradients for updating generator parameters, eliminating the necessity to train surrogate models. Across sixteen datasets, GZOO significantly outperforms state-of-the-art attacks, achieving remarkable effectiveness and robustness. Notably, on the Cora dataset with the GCN model, GZOO achieves an impressive 95.69% success rate, surpassing the maximum 66.01% achieved by baselines.},
  archive      = {J_TKDE},
  author       = {Hao Yu and Ke Liang and Dayu Hu and Wenxuan Tu and Chuan Ma and Sihang Zhou and Xinwang Liu},
  doi          = {10.1109/TKDE.2024.3483274},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {319-333},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GZOO: Black-box node injection attack on graph neural networks via zeroth-order optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expressiveness analysis and enhancing framework for geometric knowledge graph embedding models. <em>TKDE</em>, <em>37</em>(1), 306-318. (<a href='https://doi.org/10.1109/TKDE.2024.3486915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing geometric knowledge graph embedding methods employ various relational transformations, such as translation, rotation, and projection, to model different relation patterns, which aims to enhance the expressiveness of models. In contrast to current approaches that treat the expressiveness of the model as a binary issue, we aim to delve deeper into analyzing the level of difficulty in which geometric knowledge graph embedding models can represent relation patterns. In this paper, we provide a theoretical analysis framework that measures the expressiveness of the model in relation patterns by quantifying the size of the solution space of linear equation systems. Additionally, we propose a mechanism for imposing relational constraints on geometric knowledge graph embedding models by setting “traps” near relational optimal solutions, which enables the model to better converge to the optimal solution. Empirically, we analyze and compare several typical knowledge graph embedding models with different geometric algebras, revealing that some models have insufficient solution space due to their design, which leads to performance weaknesses. We also demonstrate that the proposed relational constraint operations can improve the performance of certain relation patterns. The experimental results on public benchmarks and relation pattern specified dataset are consistent with our theoretical analysis.},
  archive      = {J_TKDE},
  author       = {Tengwei Song and Long Yin and Yang Liu and Long Liao and Jie Luo and Zhiqiang Xu},
  doi          = {10.1109/TKDE.2024.3486915},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {306-318},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Expressiveness analysis and enhancing framework for geometric knowledge graph embedding models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring progress in multivariate time series forecasting: Comprehensive benchmarking and heterogeneity analysis. <em>TKDE</em>, <em>37</em>(1), 291-305. (<a href='https://doi.org/10.1109/TKDE.2024.3484454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series (MTS) analysis is crucial to understanding and managing complex systems, such as traffic and energy systems, and a variety of approaches to MTS forecasting have been proposed recently. However, we often observe inconsistent or seemingly contradictory performance findings across different studies. This hinders our understanding of the merits of different approaches and slows down progress. We address the need for means of assessing MTS forecasting proposals reliably and fairly, in turn enabling better exploitation of MTS as seen in different applications. Specifically, we first propose BasicTS+, a benchmark designed to enable fair, comprehensive, and reproducible comparison of MTS forecasting solutions. BasicTS+ establishes a unified training pipeline and reasonable settings, enabling an unbiased evaluation. Second, we identify the heterogeneity across different MTS as an important consideration and enable classification of MTS based on their temporal and spatial characteristics. Disregarding this heterogeneity is a prime reason for difficulties in selecting the most promising technical directions. Third, we apply BasicTS+ along with rich datasets to assess the capabilities of more than 30 MTS forecasting solutions. This provides readers with an overall picture of the cutting-edge research on MTS forecasting.},
  archive      = {J_TKDE},
  author       = {Zezhi Shao and Fei Wang and Yongjun Xu and Wei Wei and Chengqing Yu and Zhao Zhang and Di Yao and Tao Sun and Guangyin Jin and Xin Cao and Gao Cong and Christian S. Jensen and Xueqi Cheng},
  doi          = {10.1109/TKDE.2024.3484454},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {291-305},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exploring progress in multivariate time series forecasting: Comprehensive benchmarking and heterogeneity analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable session-based recommendation via path reasoning. <em>TKDE</em>, <em>37</em>(1), 278-290. (<a href='https://doi.org/10.1109/TKDE.2024.3486326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores explaining session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting nodes for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR and introduce path midpoint reward to enhance the exploration efficiency and accuracy in knowledge graphs. To improve the knowledge graph’s completeness and diversify the paths of explanation, we incorporate extracted feature information from images into the knowledge graph. We instantiate PR4SR in five state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and compare it with other explainable SR frameworks to demonstrate the effectiveness of PR4SR for recommendation and explanation tasks through extensive experiments with these approaches on four datasets.},
  archive      = {J_TKDE},
  author       = {Yang Cao and Shuo Shang and Jun Wang and Wei Zhang},
  doi          = {10.1109/TKDE.2024.3486326},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {278-290},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Explainable session-based recommendation via path reasoning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ENCODE: Breaking the trade-off between performance and efficiency in long-term user behavior modeling. <em>TKDE</em>, <em>37</em>(1), 265-277. (<a href='https://doi.org/10.1109/TKDE.2024.3486445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term user behavior sequences are a goldmine for businesses to explore users’ interests to improve Click-Through Rate (CTR). However, it is very challenging to accurately capture users’ long-term interests from their long-term behavior sequences and give quick responses from the online serving systems. To meet such requirements, existing methods “inadvertently” destroy two basic requirements in long-term sequence modeling: R1) make full use of the entire sequence to keep the information as much as possible; R2) extract information from the most relevant behaviors to keep high relevance between learned interests and current target items. The performance of online serving systems is significantly affected by incomplete and inaccurate user interest information obtained by existing methods. To this end, we propose an efficient two-stage long-term sequence modeling approach, named as EfficieNt Clustering based twO-stage interest moDEling (ENCODE), consisting of offline extraction stage and online inference stage. It not only meets the aforementioned two basic requirements but also achieves a desirable balance between online service efficiency and precision. Specifically, in the offline extraction stage, ENCODE clusters the entire behavior sequence and extracts accurate interests. To reduce the overhead of the clustering process, we design a metric learning-based dimension reduction algorithm that preserves the relative pairwise distances of behaviors in the new feature space. While in the online inference stage, ENCODE takes the off-the-shelf user interests to predict the associations with target items. Besides, to further ensure the relevance between user interests and target items, we adopt the same relevance metric throughout the whole pipeline of ENCODE. The extensive experiment and comparison with SOTA on both industrial and public datasets have demonstrated the effectiveness and efficiency of our proposed ENCODE.},
  archive      = {J_TKDE},
  author       = {Wen-Ji Zhou and Yuhang Zheng and Yinfu Feng and Yunan Ye and Rong Xiao and Long Chen and Xiaosong Yang and Jun Xiao},
  doi          = {10.1109/TKDE.2024.3486445},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {265-277},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ENCODE: Breaking the trade-off between performance and efficiency in long-term user behavior modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient link prediction via GNN layers induced by negative sampling. <em>TKDE</em>, <em>37</em>(1), 253-264. (<a href='https://doi.org/10.1109/TKDE.2024.3481015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, node-wise architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time, model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, edge-wise methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the forward pass explicitly depends on both positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet still cheap node-wise embeddings. This is achieved by recasting the embeddings themselves as minimizers of a forward-pass-specific energy function that favors separation of positive and negative samples. Notably, this energy is distinct from the actual training loss shared by most existing link prediction models, where contrastive pairs only influence the backward pass. As demonstrated by extensive empirical evaluations, the resulting architecture retains the inference speed of node-wise models, while producing competitive accuracy with edge-wise alternatives.},
  archive      = {J_TKDE},
  author       = {Yuxin Wang and Xiannian Hu and Quan Gan and Xuanjing Huang and Xipeng Qiu and David Wipf},
  doi          = {10.1109/TKDE.2024.3481015},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {253-264},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient link prediction via GNN layers induced by negative sampling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DynImpt: A dynamic data selection method for improving model training efficiency. <em>TKDE</em>, <em>37</em>(1), 239-252. (<a href='https://doi.org/10.1109/TKDE.2024.3482466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting key data subsets for model training is an effective way to improve training efficiency. Existing methods generally utilize a well-trained model to evaluate samples and select crucial subsets, ignoring the fact that the sample importance changes dynamically during model training, resulting in the selected subset only being critical in a specific training epoch rather than a changing training phase. To address this issue, we attempt to evaluate the significant changes in sample importance during dynamic training and propose a novel data selection method to improve model training efficiency. Specifically, the temporal changes in sample importance are considered from three perspectives: (i) loss, the difference between the predicted labels and the true labels of samples in the current training epoch; (ii) instability, the dispersion of sample importance in the recent training phase; and (iii) inconsistency, the comparison of the changing trend in the importance of an individual sample relative to the average importance of all samples in the recent training phase. Extensive experiments demonstrate that dynamic data selection can reduce computational costs and improve model training efficiency. Additionally, we find that the difficulty level of the training task influences the data selection strategy.},
  archive      = {J_TKDE},
  author       = {Wei Huang and Yunxiao Zhang and Shangmin Guo and Yu-Ming Shang and Xiangling Fu},
  doi          = {10.1109/TKDE.2024.3482466},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {239-252},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DynImpt: A dynamic data selection method for improving model training efficiency},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adversarial active learning for domain generalization classification. <em>TKDE</em>, <em>37</em>(1), 226-238. (<a href='https://doi.org/10.1109/TKDE.2024.3486204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization (DG) tasks aim to learn cross-domain models from source domains and apply them to unknown target domains. Recent research has demonstrated that diverse and rich source domain samples can enhance domain generalization capability. This work argues that the impact of each sample on the model's generalization ability varies. Even a small-scale but high-quality dataset can achieve a notable level of generalization. Motivated by this, we propose a domain-adversarial active learning (DAAL) algorithm for classification tasks in DG. First, we analyze that the objective of DG tasks is to maximize the inter-class distance within the same domain and minimize the intra-class distance across different domains. We design a domain adversarial selection method that prioritizes challenging samples in an active learning (AL) framework. Second, we hypothesize that even in a converged model, some feature subsets lack discriminatory power within each domain. We develop a method to identify and optimize these feature subsets, thereby maximizing inter-class distance of features. Lastly, We experimentally compare our DAAL algorithm with various DG and AL algorithms across four datasets. The results demonstrate that the DAAL algorithm can achieve strong generalization ability with fewer data resources, thereby significantly reducing data annotation costs in DG tasks.},
  archive      = {J_TKDE},
  author       = {Jianting Chen and Ling Ding and Yunxiao Yang and Zaiyuan Di and Yang Xiang},
  doi          = {10.1109/TKDE.2024.3486204},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {226-238},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Domain adversarial active learning for domain generalization classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIMS: Distributed index for similarity search in metric spaces. <em>TKDE</em>, <em>37</em>(1), 210-225. (<a href='https://doi.org/10.1109/TKDE.2024.3487759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity search finds objects that are similar to a given query object based on a similarity metric. As the amount and variety of data continue to grow, similarity search in metric spaces has gained significant attention. Metric spaces can accommodate any type of data and support flexible distance metrics, making similarity search in metric spaces beneficial for many real-world applications, such as multimedia retrieval, personalized recommendation, trajectory analytics, data mining, decision planning, and distributed servers. However, existing studies mostly focus on indexing metric spaces on a single machine, which faces efficiency and scalability limitations with increasing data volume and query amount. Recent advancements in similarity search turn towards distributed methods, while they face challenges including inefficient local data management, unbalanced workload, and low concurrent search efficiency. To this end, we propose DIMS, an efficient Distributed Index for similarity search in Metric Spaces. First, we design a novel three-stage heterogeneous partition to achieve workload balance. Then, we present an effective three-stage indexing structure to efficiently manage objects. We also develop concurrent search methods with filtering and validation techniques that support efficient distributed similarity search. Additionally, we devise a cost-based optimization model to balance communication and computation cost. Extensive experiments demonstrate that DIMS significantly outperforms existing distributed similarity search approaches.},
  archive      = {J_TKDE},
  author       = {Yifan Zhu and Chengyang Luo and Tang Qian and Lu Chen and Yunjun Gao and Baihua Zheng},
  doi          = {10.1109/TKDE.2024.3487759},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {210-225},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DIMS: Distributed index for similarity search in metric spaces},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFNO: Detecting fuzzy neighborhood outliers. <em>TKDE</em>, <em>37</em>(1), 200-209. (<a href='https://doi.org/10.1109/TKDE.2024.3484448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier Detection (OD) has attracted extensive research due to its application in many fields. The idea of neighborhood computing is one of the widely used methods in outlier analysis. Nevertheless, these methods mainly use certainty strategies to model outlier detection, so they cannot effectively handle the fuzzy information in the dataset. Moreover, they mainly focus on dealing with outlier detection in numerical data and cannot effectively find outliers in mixed-attribute data. Fuzzy information granulation theory is an effective granular computing model that allows objects to belong to a set to a certain extent (i.e., membership degree), which makes it possible to better handle uncertainty problems such as fuzziness. In this work, we propose an outlier detection model based on fuzzy neighborhoods. First, a hybrid fuzzy similarity is constructed to granulate the set of objects to form fuzzy information granules. Second, the fuzzy $k$-nearest neighbor is defined to describe the fuzzy local information. Then, the fuzzy neighborhood density is defined to indicate the degree of aggregation of each object. The smaller the fuzzy neighborhood density of an object, the more likely it is to be an outlier. Based on this idea, the fuzzy neighborhood deviation degree is defined to quantify the degree of outliers of objects. Finally, the fuzzy deviation degree on the set of conditional attributes is constructed to indicate the outlier scores of objects. Experimental comparisons with state-of-the-art methods show that the proposed method has a significant improvement on the AUC index and applies to three types of data.},
  archive      = {J_TKDE},
  author       = {Zhong Yuan and Peng Hu and Hongmei Chen and Yingke Chen and Qilin Li},
  doi          = {10.1109/TKDE.2024.3484448},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {200-209},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DFNO: Detecting fuzzy neighborhood outliers},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep contrastive multi-view subspace clustering with representation and cluster interactive learning. <em>TKDE</em>, <em>37</em>(1), 188-199. (<a href='https://doi.org/10.1109/TKDE.2024.3484161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is an important approach to mining the valuable information within multi-view data. In this paper, we propose a novel multi-view deep subspace clustering method based on contrastive learning and Cauchy-Schwarz (CS) divergence. Our method not only uses contrastive learning techniques and block diagonalization constraints to guide representation matrix learning, but also combines representation learning and clustering processes to achieve the interaction of representation and clustering. First, we introduce a novel loss function based on CS divergence in the clustering module to achieve the interaction of representation and clustering. Second, we propose an extension of the multiple positive and negative pair diffusion method to enhance contrastive learning. Finally, we establish the equivalence between contrastive clustering and spectral clustering with orthogonal constraints, leading to a comprehensive model optimization. We evaluate our method on six publicly available datasets and compare its performance with eight competing methods. The results demonstrate the superiority of our method over the compared multi-view clustering methods.},
  archive      = {J_TKDE},
  author       = {Xuejiao Yu and Yi Jiang and Guoqing Chao and Dianhui Chu},
  doi          = {10.1109/TKDE.2024.3484161},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {188-199},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep contrastive multi-view subspace clustering with representation and cluster interactive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context correlation discrepancy analysis for graph anomaly detection. <em>TKDE</em>, <em>37</em>(1), 174-187. (<a href='https://doi.org/10.1109/TKDE.2024.3488375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised graph anomaly detection, existing methods usually focus on detecting outliers by learning local context information of nodes, while often ignoring the importance of global context. However, global context information can provide more comprehensive relationship information between nodes in the network. By considering the structure of the entire network, detection methods are able to identify potential dependencies and interaction patterns between nodes, which is crucial for anomaly detection. Therefore, we propose an innovative graph anomaly detection framework, termed CoCo (Context Correlation Discrepancy Analysis), which detects anomalies by meticulously evaluating variances in correlations. Specifically, CoCo leverages the strengths of Transformers in sequence processing to effectively capture both global and local contextual features of nodes by aggregating neighbor features at various hops. Subsequently, a correlation analysis module is employed to maximize the correlation between local and global contexts of each normal node. Unseen anomalies are ultimately detected by measuring the discrepancy in the correlation of nodes’ contextual features. Extensive experiments conducted on six datasets with synthetic outliers and five datasets with organic outliers have demonstrated the significant effectiveness of CoCo compared to existing methods.},
  archive      = {J_TKDE},
  author       = {Ruidong Wang and Liang Xi and Fengbin Zhang and Haoyi Fan and Xu Yu and Lei Liu and Shui Yu and Victor C. M. Leung},
  doi          = {10.1109/TKDE.2024.3488375},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {174-187},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Context correlation discrepancy analysis for graph anomaly detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Condensing pre-augmented recommendation data via lightweight policy gradient estimation. <em>TKDE</em>, <em>37</em>(1), 162-173. (<a href='https://doi.org/10.1109/TKDE.2024.3484249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training recommendation models on large datasets requires significant time and resources. It is desired to construct concise yet informative datasets for efficient training. Recent advances in dataset condensation show promise in addressing this problem by synthesizing small datasets. However, applying existing methods of dataset condensation to recommendation has limitations: (1) they fail to generate discrete user-item interactions, and (2) they could not preserve users’ potential preferences. To address the limitations, we propose a lightweight condensation framework tailored for recommendation (DConRec), focusing on condensing user-item historical interaction sets. Specifically, we model the discrete user-item interactions via a probabilistic approach and design a pre-augmentation module to incorporate the potential preferences of users into the condensed datasets. While the substantial size of datasets leads to costly optimization, we propose a lightweight policy gradient estimation to accelerate the data synthesis. Experimental results on multiple real-world datasets have demonstrated the effectiveness and efficiency of our framework. Besides, we provide a theoretical analysis of the provable convergence of DConRec.},
  archive      = {J_TKDE},
  author       = {Jiahao Wu and Wenqi Fan and Jingfan Chen and Shengcai Liu and Qijiong Liu and Rui He and Qing Li and Ke Tang},
  doi          = {10.1109/TKDE.2024.3484249},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {162-173},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Condensing pre-augmented recommendation data via lightweight policy gradient estimation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering ensemble based on fuzzy matrix self-enhancement. <em>TKDE</em>, <em>37</em>(1), 148-161. (<a href='https://doi.org/10.1109/TKDE.2024.3489553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy clustering ensemble techniques have been proven to yield more accurate and robust clustering results, with the mainstream methods relying on the fuzzy co-association (FCA) matrix. However, the inherent issues of low-value density and uniform dispersion in the FCA matrix significantly affect the performance of fuzzy clustering ensembles, an aspect that has been overlooked. To address this issue, we propose a novel framework for fuzzy clustering ensemble based on fuzzy matrix self-enhancement (FMSE). Specifically, we initially employ singular value decomposition to extract the principal components of the FCA matrix, thereby alleviating its low-value density. Second, on the basis of the criterion of fuzzy entropy, we measure the fuzziness of samples, design a metric for the fuzzy representativeness of samples, and incorporate it into a fusion-weighted structure for the reconstruction of the FCA matrix, mitigating uniform dispersion. Subsequently, on the basis of the self-enhanced fuzzy matrix model, we utilize a prototype diffusion approach to identify core samples and gradually allocate remaining samples to obtain a consensus clustering solution. Extensive comparative experiments on benchmark datasets against state-of-the-art clustering ensemble methods demonstrate the effectiveness and superiority of the proposed approach.},
  archive      = {J_TKDE},
  author       = {Xia Ji and Jiawei Sun and Jianhua Peng and Yue Pang and Peng Zhou},
  doi          = {10.1109/TKDE.2024.3489553},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {148-161},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Clustering ensemble based on fuzzy matrix self-enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing submanifold region for out-of-distribution detection. <em>TKDE</em>, <em>37</em>(1), 130-147. (<a href='https://doi.org/10.1109/TKDE.2024.3468629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting out-of-distribution (OOD) samples poses a significant safety challenge when deploying models in open-world scenarios. Advanced works assume that OOD and in-distributional (ID) samples exhibit a distribution discrepancy, showing an encouraging direction in estimating the uncertainty with embedding features or predicting outputs. Besides incorporating auxiliary outlier as decision boundary, quantifying a “meaningful distance” in embedding space as uncertainty measurement is a promising strategy. However, these distances-based approaches overlook the data structure and heavily rely on the high-dimension features learned by deep neural networks, causing unreliable distances due to the “curse of dimensionality”. In this work, we propose a data structure-aware approach to mitigate the sensitivity of distances to the “curse of dimensionality”, where high-dimensional features are mapped to the manifold of ID samples, leveraging the well-known manifold assumption. Specifically, we present a novel distance termed as tangent distance, which tackles the issue of generalizing the meaningfulness of distances on testing samples to detect OOD inputs. Inspired by manifold learning for adversarial examples, where adversarial region probability density is close to the orthogonal direction of the manifold, and both OOD and adversarial samples have common characteristic $-$ imperceptible perturbations with shift distribution, we propose that OOD samples are relatively far away from the ID manifold, where tangent distance directly computes the Euclidean distance between samples and the nearest submanifold space $-$ instantiated as the linear approximation of local region on the manifold. We provide empirical and theoretical insights to demonstrate the effectiveness of OOD uncertainty measurements on the low-dimensional subspace. Extensive experiments show that the tangent distance performs competitively with other post hoc OOD detection baselines on common and large-scale benchmarks, and the theoretical analysis supports our claim that ID samples are likely to reside in high-density regions, explaining the effectiveness of internal connections among ID data.},
  archive      = {J_TKDE},
  author       = {Xuhui Li and Zhen Fang and Yonggang Zhang and Ning Ma and Jiajun Bu and Bo Han and Haishuai Wang},
  doi          = {10.1109/TKDE.2024.3468629},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {130-147},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Characterizing submanifold region for out-of-distribution detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CauseRuDi: Explaining behavior sequence models by causal statistics generation and rule distillation. <em>TKDE</em>, <em>37</em>(1), 116-129. (<a href='https://doi.org/10.1109/TKDE.2024.3487625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk scoring systems have been widely deployed in many applications, which assign risk scores to users according to their behavior sequences. Though many deep learning methods with sophisticated designs have achieved promising results, the black-box nature hinders their applications due to fairness, explainability, and compliance consideration. Rule-based systems are considered reliable in these sensitive scenarios. However, building a rule system is labor-intensive. Experts need to find informative statistics from user behavior sequences, design rules based on statistics and assign weights to each rule. In this paper, we bridge the gap between effective but black-box models and transparent rule models. We propose a two-stage framework, CauseRuDi, that distills the knowledge of black-box teacher models into rule-based student models. We design a Monte Carlo tree search-based statistics generation method that maximizes the correlation or dependence between the generated statistics and the teacher model's outputs. We formulate a sequential move game and a simultaneous move coalitional game to generate multiple statistics. Then statistics are composed into logical rules with our proposed neural logical networks by mimicking the outputs of teacher models. We evaluate CauseRuDi on three real-world public datasets and an industrial dataset to demonstrate its effectiveness.},
  archive      = {J_TKDE},
  author       = {Yao Zhang and Yun Xiong and Yiheng Sun and Yucheng Jin and Caihua Shan and Tian Lu and Hui Song and Shengli Sun},
  doi          = {10.1109/TKDE.2024.3487625},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {116-129},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CauseRuDi: Explaining behavior sequence models by causal statistics generation and rule distillation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalFormer: An interpretable transformer for temporal causal discovery. <em>TKDE</em>, <em>37</em>(1), 102-115. (<a href='https://doi.org/10.1109/TKDE.2024.3484461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal causal discovery is a crucial task aimed at uncovering the causal relations within time series data. The latest temporal causal discovery methods usually train deep learning models on prediction tasks to uncover the causality between time series. They capture causal relations by analyzing the parameters of some components of the trained models, e.g., attention weights and convolution weights. However, this is an incomplete mapping process from the model parameters to the causality and fails to investigate the other components, e.g., fully connected layers and activation functions, that are also significant for causal discovery. To facilitate the utilization of the whole deep learning models in temporal causal discovery, we proposed an interpretable transformer-based causal discovery model termed CausalFormer, which consists of the causality-aware transformer and the decomposition-based causality detector. The causality-aware transformer learns the causal representation of time series data using a prediction task with the designed multi-kernel causal convolution which aggregates each input time series along the temporal dimension under the temporal priority constraint. Then, the decomposition-based causality detector interprets the global structure of the trained causality-aware transformer with the proposed regression relevance propagation to identify potential causal relations and finally construct the causal graph. Experiments on synthetic, simulated, and real datasets demonstrate the state-of-the-art performance of CausalFormer on discovering temporal causality.},
  archive      = {J_TKDE},
  author       = {Lingbai Kong and Wengen Li and Hanchen Yang and Yichao Zhang and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1109/TKDE.2024.3484461},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {102-115},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CausalFormer: An interpretable transformer for temporal causal discovery},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAGS: Context-aware document ranking with contrastive graph sampling. <em>TKDE</em>, <em>37</em>(1), 89-101. (<a href='https://doi.org/10.1109/TKDE.2024.3491996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In search sessions, a series of interactions in the context has been proven to be advantageous in capturing users’ search intents. Existing studies show that designing pre-training tasks and data augmentation strategies for session search improves the robustness and generalizability of the model. However, such data augmentation strategies only focus on changing the original session structure to learn a better representation. Ignoring information from outside the session, users’ diverse and complex intents cannot be learned well by simply reordering and deleting historical behaviors, proving that such strategies are limited and inadequate. In order to solve the problem of insufficient modeling under complex user intents, we propose exploiting information outside the original session. More specifically, in this paper, we sample queries and documents from the global click-on and follow-up session graph, alter an original session with these samples, and construct a new session that shares a similar user intent with the original one. Specifically, we design four data augmentation strategies based on session graphs in view of both one-hop and multi-hop structures to sample intent-associated query/document nodes. Experiments conducted on three large-scale public datasets demonstrate that our model outperforms the existing ad-hoc and context-aware document ranking models.},
  archive      = {J_TKDE},
  author       = {Zhaoheng Huang and Yutao Zhu and Zhicheng Dou and Ji-Rong Wen},
  doi          = {10.1109/TKDE.2024.3491996},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {89-101},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CAGS: Context-aware document ranking with contrastive graph sampling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). B-CAVE: A robust online time series change point detection algorithm based on the between-class average and variance evaluation approach. <em>TKDE</em>, <em>37</em>(1), 75-88. (<a href='https://doi.org/10.1109/TKDE.2024.3492339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change point detection (CPD) is a valuable technique in time series (TS) analysis, which allows for the automatic detection of abrupt variations within the TS. It is often useful in applications such as fault, anomaly, and intrusion detection systems. However, the inherent unpredictability and fluctuations in many real-time data sources pose a challenge for existing contemporary CPD techniques, leading to inconsistent performance across diverse real-time TS with varying characteristics. To address this challenge, we have developed a novel and robust online CPD algorithm constructed from the principle of discriminant analysis and based upon a newly proposed between-class average and variance evaluation approach, termed B-CAVE. Our B-CAVE algorithm features a unique change point measure, which has only one tunable parameter (i.e. the window size) in its computational process. We have also proposed a new evaluation metric that integrates time delay and the false alarm error towards effectively comparing the performance of different CPD methods in the literature. To validate the effectiveness of our method, we conducted experiments using both synthetic and real datasets, demonstrating the superior performance of the B-CAVE algorithm over other prominent existing techniques.},
  archive      = {J_TKDE},
  author       = {Aditi Gupta and Adeiza James Onumanyi and Satyadev Ahlawat and Yamuna Prasad and Virendra Singh},
  doi          = {10.1109/TKDE.2024.3492339},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {75-88},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {B-CAVE: A robust online time series change point detection algorithm based on the between-class average and variance evaluation approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Answering min-max resource-constrained shortest path queries over large graphs. <em>TKDE</em>, <em>37</em>(1), 60-74. (<a href='https://doi.org/10.1109/TKDE.2024.3488095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constrained shortest path problem is a fundamental and challenging task in applications built on graphs. In this paper, we formalize and study the $Min$-$Max$ resource-constrained shortest path ($Min$-$Max$ RCSP) problem, which generalizes the well-studied $Max$ RCSP problem. The objective is to find a simple path of minimum cost between two query nodes, subject to resource constraints between minimum and maximum limits. This problem has wide applications in fields such as delay networks and transportation. However, we theoretically prove that computing the optimal solution is NP-hard. We propose a two-stage approach that involves resource-based graph reduction followed by cost-guided path generation. To reduce the cost of expensive acyclicity checking, we introduce the technique of ancestor checking based on the shortest path tree. Furthermore, we present an even faster incremental search approach that considers both the path cost and resource constraints while avoiding acyclicity checking. Extensive experiments on twenty real graphs consistently demonstrate the superiority of our proposed methods, achieving up to two orders of magnitude improvement in time efficiency over the baseline algorithms while producing high-quality solutions.},
  archive      = {J_TKDE},
  author       = {Haoran Qian and Weiguo Zheng and Zhijie Zhang and Bo Fu},
  doi          = {10.1109/TKDE.2024.3488095},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {60-74},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Answering min-max resource-constrained shortest path queries over large graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Angular reconstructive discrete embedding with fusion similarity for multi-view clustering. <em>TKDE</em>, <em>37</em>(1), 45-59. (<a href='https://doi.org/10.1109/TKDE.2024.3487907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively and efficiently mining valuable clustering patterns is a challenging problem when handling large-scale data from diverse sources. Existing approaches adopt anchor graph learning or binary representation embedding to reduce computational complexity. Normally, anchor graph learning can not directly obtain the clustering assignment except adopt the post-processing stage, such as graph cut or k-means clustering. The binary representation embedding neglects the structure information in Hamming space. In order to overcome these limitations, this paper proposes a novel, effective, and efficient angular reconstructive discrete embedding method with fusion similarity for a multi-view clustering (AFMC) that can jointly learn the global and local structure preserving binary representation and clustering assignment. Specifically, we propose to use angular reconstructive error minimization to maintain the global similarity correlation of binary representations of heterogeneous features in a common Hamming space. Moreover, we design a multi-view discrete ridge regression with fusion similarity term to handle the out-of-sample problem and preserve the local manifold structure. In addition, we propose an efficient optimization algorithm with linear computational complexity to solve the non-convex and non-smooth objective function. The experimental results demonstrate that AFMC outperforms several state-of-the-art large-scale multi-view clustering methods.},
  archive      = {J_TKDE},
  author       = {Jintang Bian and Xiaohua Xie and Chang-Dong Wang and Lingxiao Yang and Jian-Huang Lai and Feiping Nie},
  doi          = {10.1109/TKDE.2024.3487907},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {45-59},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Angular reconstructive discrete embedding with fusion similarity for multi-view clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving efficient and privacy-preserving reverse skyline query over single cloud. <em>TKDE</em>, <em>37</em>(1), 29-44. (<a href='https://doi.org/10.1109/TKDE.2024.3487646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reverse skyline query (RSQ) has been widely used in practice since it can pick out the data of interest to the query vector. To save storage resources and facilitate service provision, data owners usually outsource data to the cloud for RSQ services, which poses huge challenges to data security and privacy protection. Existing privacy-preserving RSQ schemes are either based on a two-cloud model or cannot fully protect privacy. To this end, we propose an efficient privacy-preserving reverse skyline query scheme over a single cloud (ePRSQ). Specifically, we first design a privacy-preserving inner product's sign determination scheme (PIPSD), which can determine whether the inner product of two vectors satisfies a specific relation with 0 without leaking the vectors’ information. Next, we propose a privacy-preserving reverse dominance checking scheme (PRDC) based on symmetric homomorphic encryption. Finally, we achieve ePRSQ based on PIPSD and PRDC. Security analysis shows that PIPSD and PRDC are both secure in the real/ideal world model, and ePRSQ can protect the security of the dataset, the privacy of query requests and query results. Extensive experiments show that ePRSQ is efficient. Specifically, for a 3-dimensional dataset of size 1000, the computational and communication overheads of ePRSQ for a query are 79.47 s and 0.0021 MB, respectively. The efficiency is improved by $3.78\times$ (300.58 s) and $928.57\times$ (1.95 MB) respectively compared with PPARS, and by $61.31\times$ (4872.55 s) and $407309\times$ (855.35 MB) respectively compared with OPPRS.},
  archive      = {J_TKDE},
  author       = {Yubo Peng and Xiong Li and Ke Gu and Jinjun Chen and Sajal K. Das and Xiaosong Zhang},
  doi          = {10.1109/TKDE.2024.3487646},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {29-44},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Achieving efficient and privacy-preserving reverse skyline query over single cloud},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel key point based MLCS algorithm for big sequences mining. <em>TKDE</em>, <em>37</em>(1), 15-28. (<a href='https://doi.org/10.1109/TKDE.2024.3485234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining multiple longest common subsequences (MLCS) from a set of sequences of length three or more over a finite alphabet (a classical NP-hard problem) is an important task in many fields, e.g., bioinformatics, computational genomics, pattern recognition, information extraction, etc. Applications in these fields often involve generating very long sequences (length $\geqslant$ 10,000), referred to as big sequences. Despite efforts in improving the time and space complexities of MLCS mining algorithms, both existing exact and approximate algorithms face challenges in handling big sequences due to the overwhelming size of their problem-solving graph model MLCS-DAG (Directed Acyclic Graph), leading to the issue of memory explosion or extremely high time complexity. To bridge the gap, this paper first proposes a new identification and deletion strategy for different classes of non-critical points in the mining of MLCS, which are the points that do not contribute to their MLCSs mining in the MLCS-DAG. It then proposes a new MLCS problem-solving graph model, namely $DAG_{KP}$ (a new MLCS-DAG containing only Key Points). A novel parallel MLCS algorithm, called KP-MLCS (Key Point based MLCS), is also presented, which can mine and compress all MLCSs of big sequences effectively and efficiently. Extensive experiments on both synthetic and real-world biological sequences show that the proposed algorithm KP-MLCS drastically outperforms the existing state-of-the-art MLCS algorithms in terms of both efficiency and effectiveness.},
  archive      = {J_TKDE},
  author       = {Yanni Li and Bing Liu and Tihua Duan and Zhi Wang and Hui Li and Jiangtao Cui},
  doi          = {10.1109/TKDE.2024.3485234},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {15-28},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel key point based MLCS algorithm for big sequences mining},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fine-grained network for joint multimodal entity-relation extraction. <em>TKDE</em>, <em>37</em>(1), 1-14. (<a href='https://doi.org/10.1109/TKDE.2024.3485107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint multimodal entity-relation extraction (JMERE) is a challenging task that involves two joint subtasks, i.e., named entity recognition and relation extraction, from multimodal data such as text sentences with associated images. Previous JMERE methods have primarily employed 1) pipeline models, which apply pre-trained unimodal models separately and ignore the interaction between tasks, or 2) word-pair relation tagging methods, which neglect neighboring word pairs. To address these limitations, we propose a fine-grained network for JMERE. Specifically, we introduce a fine-grained alignment module that utilizes a phrase-patch to establish connections between text phrases and visual objects. This module can learn consistent multimodal representations from multimodal data. Furthermore, we address the task-irrelevant image information issue by proposing a gate fusion module, which mitigates the impact of image noise and ensures a balanced representation between image objects and text representations. Furthermore, we design a multi-word decoder that enables ensemble prediction of tags for each word pair. This approach leverages the predicted results of neighboring word pairs, improving the ability to extract multi-word entities. Evaluation results from a series of experiments demonstrate the superiority of our proposed model over state-of-the-art models in JMERE.},
  archive      = {J_TKDE},
  author       = {Li Yuan and Yi Cai and Jingyu Xu and Qing Li and Tao Wang},
  doi          = {10.1109/TKDE.2024.3485107},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A fine-grained network for joint multimodal entity-relation extraction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
