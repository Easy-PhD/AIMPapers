<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MRA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mra">MRA - 64</h2>
<ul>
<li><details>
<summary>
(2025). Call for IEEE robotics and automation society sustainability grant applications [Society news]. <em>MRA</em>, <em>32</em>(3), 219. (<a href='https://doi.org/10.1109/MRA.2025.3589833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589833},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {219},
  title    = {Call for IEEE robotics and automation society sustainability grant applications [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAS recognizes 2025 award recipients at IEEE international conference on robotics and automation [Society news]. <em>MRA</em>, <em>32</em>(3), 216-218. (<a href='https://doi.org/10.1109/MRA.2025.3589831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589831},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {216-218},
  title    = {RAS recognizes 2025 award recipients at IEEE international conference on robotics and automation [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The IEEE robotics and automation society congratulates our elevated senior members of 2025 [Society news]. <em>MRA</em>, <em>32</em>(3), 214-216. (<a href='https://doi.org/10.1109/MRA.2025.3589832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589832},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {214-216},
  title    = {The IEEE robotics and automation society congratulates our elevated senior members of 2025 [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mastering Research—Part 1/3: Choose smart, read smarter! [Student’s corner]. <em>MRA</em>, <em>32</em>(3), 210-212. (<a href='https://doi.org/10.1109/MRA.2025.3586428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Dipam Patel},
  doi     = {10.1109/MRA.2025.3586428},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {210-212},
  title   = {Mastering Research—Part 1/3: Choose smart, read smarter! [Student’s corner]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Women in robotics: Insights into the first international conference on intelligent robots and systems in the middle east [Women in engineering]. <em>MRA</em>, <em>32</em>(3), 205-209. (<a href='https://doi.org/10.1109/MRA.2025.3587857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), held for the first time in the Middle East, featured two key events dedicated to Women in Engineering (WIE): the Empowering Diverse Voices in Robotics (EDVR) Forum and the 2024 IEEE Robotics and Automation Society (RAS) Women in Robotics Luncheon Panel. These events underscored the limited but growing number of women in robotics in the region [1], [2], prompting the development of a comprehensive survey to explore their experiences. This increased representation is particularly valuable given that diverse teams enhance collaboration, improve decision making, and foster greater creativity and performance [3].},
  archive  = {J},
  author   = {Reem Ashour and Sara Aldhaheri and J. Stephany Berrio Perez and Giulia De Masi},
  doi      = {10.1109/MRA.2025.3587857},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {205-209},
  title    = {Women in robotics: Insights into the first international conference on intelligent robots and systems in the middle east [Women in engineering]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CASE 2024: Pioneering innovations in automation and systems engineering [Conference highlights]. <em>MRA</em>, <em>32</em>(3), 201-220. (<a href='https://doi.org/10.1109/MRA.2025.3586662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Mariagrazia Dotoli and Yu Sun and Carla Seatzu and Paolo Scarabaggio},
  doi     = {10.1109/MRA.2025.3586662},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {201-220},
  title   = {CASE 2024: Pioneering innovations in automation and systems engineering [Conference highlights]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABET’s new accreditation criteria for robotics and mechatronics engineering: A summary [Industry activities]. <em>MRA</em>, <em>32</em>(3), 198-212. (<a href='https://doi.org/10.1109/MRA.2025.3584823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Joel M. Esposito},
  doi     = {10.1109/MRA.2025.3584823},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {198-212},
  title   = {ABET’s new accreditation criteria for robotics and mechatronics engineering: A summary [Industry activities]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fostering innovation in robotics through open environments and standards [Standards]. <em>MRA</em>, <em>32</em>(3), 196-197. (<a href='https://doi.org/10.1109/MRA.2025.3586427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Nico Peper},
  doi     = {10.1109/MRA.2025.3586427},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {196-197},
  title   = {Fostering innovation in robotics through open environments and standards [Standards]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE SA launched new working group p1955: Shaping the future of robotics with 6G [Standards]. <em>MRA</em>, <em>32</em>(3), 195-196. (<a href='https://doi.org/10.1109/MRA.2025.3586425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Mona Ghassemian and Periklis Chatzimisios and Howard Li and Sharief Oteafy and Edson Prestes},
  doi     = {10.1109/MRA.2025.3586425},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {195-196},
  title   = {IEEE SA launched new working group p1955: Shaping the future of robotics with 6G [Standards]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAFRO: Geometric algebra for robotics [Tutorial]. <em>MRA</em>, <em>32</em>(3), 184-194. (<a href='https://doi.org/10.1109/MRA.2024.3433109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Geometry is a fundamental part of robotics and there have been various frameworks of representation over the years. Recently, geometric algebra has gained attention for its property of unifying many of those previous ideas into one algebra. While there are already efficient open-source implementations of geometric algebra available, none of them is targeted at robotics applications. We want to address this shortcoming with our library gafro. This article presents an overview of the implementation details as well as a tutorial of gafro, an efficient C++ library targeting robotics applications using geometric algebra. The library focuses on using conformal geometric algebra. Hence, various geometric primitives are available for computation as well as rigid body transformations. The modeling of robotic systems is also an important aspect of the library. It implements various algorithms for calculating the kinematics and dynamics of such systems as well as objectives for optimization problems. The software stack is completed by Python bindings in pygafro and a ROS interface in gafro_ros.},
  archive  = {J},
  author   = {Tobias Löw and Philip Abbet and Sylvain Calinon},
  doi      = {10.1109/MRA.2024.3433109},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {184-194},
  title    = {GAFRO: Geometric algebra for robotics [Tutorial]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automation and artificial intelligence technology in surface mining: A brief introduction to open-pit operations in the pilbara [Survey]. <em>MRA</em>, <em>32</em>(3), 164-183. (<a href='https://doi.org/10.1109/MRA.2023.3328457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This survey article provides a synopsis on some of the engineering problems, technological innovations, robotic development and automation efforts encountered in the mining industry—particularly in the Pilbara iron-ore region of Western Australia. The goal is to paint the technology landscape and highlight issues relevant to an engineering audience to raise awareness of AI and automation trends in mining. It assumes the reader has no prior knowledge of mining and builds context gradually through focused discussion and short summaries of common open-pit mining operations. The principal activities that take place may be categorized in terms of resource development, mine-, rail- and port operations. From mineral exploration to ore shipment, there are roughly nine steps in between. These include: geological assessment, mine planning and development, production drilling and assaying, blasting and excavation, transportation of ore and waste, crush and screen, stockpile and load-out, rail network distribution, and ore-car dumping. The objective is to describe these processes and provide insights on some of the challenges / opportunities from the perspective of a decade-long industry-university R&D partnership.},
  archive  = {J},
  author   = {Raymond Leung and Andrew J. Hill and Arman Melkumyan},
  doi      = {10.1109/MRA.2023.3328457},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {164-183},
  title    = {Automation and artificial intelligence technology in surface mining: A brief introduction to open-pit operations in the pilbara [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on small-scale testbeds for connected and automated vehicles and robot swarms: A guide for creating a new testbed [Survey]. <em>MRA</em>, <em>32</em>(3), 146-163. (<a href='https://doi.org/10.1109/MRA.2024.3505772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Connected and automated vehicles (CAVs) and robot swarms (RSs) hold transformative potential for enhancing safety, efficiency, and sustainability in the transportation and manufacturing sectors. Extensive testing and validation of these technologies are crucial for their deployment in the real world. While simulations are essential for initial testing, they often have limitations in capturing the complex dynamics of real-world interactions. This limitation underscores the importance of small-scale testbeds. These testbeds provide a realistic, cost-effective, and controlled environment for testing and validating algorithms, acting as an essential intermediary between simulation and full-scale experiments. This work serves to facilitate researchers’ efforts in identifying existing small-scale testbeds suitable for their experiments and provide insights for those who want to build their own. In addition, it delivers a comprehensive survey of the current landscape of these testbeds. We derive 62 characteristics of testbeds based on the well-known sense–plan–act paradigm and offer an online table comparing 23 small-scale testbeds based on these characteristics. The online table is hosted on our designated public webpage, https://bassamlab.github.io/testbeds-survey, and we invite testbed creators and developers to contribute to it. We closely examine nine testbeds in this article, demonstrating how the derived characteristics can be used to present testbeds. Furthermore, we discuss three ongoing challenges concerning small-scale testbeds that we identified, i.e., small-scale to full-scale transition, sustainability, and power and resource management.},
  archive  = {J},
  author   = {Armin Mokhtarian and Jianye Xu and Patrick Scheffe and Maximilian Kloock and Simon Schäfer and Heeseung Bang and Viet-Anh Le and Sangeet Ulhas and Johannes Betz and Sean Wilson and Spring Berman and Liam Paull and Amanda Prorok and Bassam Alrifaee},
  doi      = {10.1109/MRA.2024.3505772},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {146-163},
  title    = {A survey on small-scale testbeds for connected and automated vehicles and robot swarms: A guide for creating a new testbed [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic importance-weighted fusion network based on dynamic convolutions for hand posture recognition: A technique based on red, green, blue plus depth cameras. <em>MRA</em>, <em>32</em>(3), 134-145. (<a href='https://doi.org/10.1109/MRA.2024.3415004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Hand posture recognition technology makes humancomputer interaction more natural and efficient. Existing hand posture recognition algorithms are mainly based on RGB images or depth data, each of which has its limitations: the former is susceptible to the interference of lighting and background color, while the latter is difficult to capture details and affects accuracy. To overcome these problems, fusion of RGB images and depth data has become a research trend. However, traditional static fusion methods use fixed modal weights, which are difficult to adapt to the complex relationships between modalities and lead to performance degradation. To cope with this problem, this paper proposes a Fusion module, including Multi-Scale Gated Extraction modules (MSGE) for multi-scale feature extraction and gating mechanism, Context Sensitive Dynamic Filtering modules (CSDF) for dynamically adjusting the weights according to the modal importance, and Importance Weighted Fusion modules (IWF) for adaptive weighting. Based on this, this paper proposes a network that fuses RGB information and depth data, named Dynamic Importance-Weighted Fusion Network (DIWFNet). This network utilizes a dual-branch YOLOv5 framework integrated with four Fusion modules, fully leveraging the complementary nature of RGB images and depth data. Through dynamic weight distribution and adaptive feature convolution, it precisely captures and models the complex interactions between different modalities, enhancing the accuracy and robustness of hand posture recognition. Our method has shown excellent performance on the CUG dataset, NTU dataset, and self-built dataset, and has been successfully applied to robots in real operational environments.},
  archive  = {J},
  author   = {Jing Qi and Li Ma and Yushu Yu},
  doi      = {10.1109/MRA.2024.3415004},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {134-145},
  title    = {Dynamic importance-weighted fusion network based on dynamic convolutions for hand posture recognition: A technique based on red, green, blue plus depth cameras},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interactive augmented reality interface for personalized proxemics modeling: Comfort and Human–Robot interactions. <em>MRA</em>, <em>32</em>(3), 125-133. (<a href='https://doi.org/10.1109/MRA.2024.3415108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Understanding and respecting personal space preferences is essential for socially assistive robots designed for older adult users. This work introduces and evaluates a novel personalized context-aware method for modeling users’ proxemics preferences during human-robot interactions. Using an interactive augmented reality interface, we collected a set of user-preferred distances from the robot and employed an active transfer learning approach to fine-tune a specialized deep learning model. We evaluated this approach through two user studies: 1) a convenience population study (N = 24) to validate the efficacy of the active transfer learning approach; and 2) a user study involving older adults (N = 15) to assess the system’s usability. We compared the data collected with the augmented reality interface and with the physical robot to examine the relationship between proxemics preferences for a virtual robot versus a physically embodied robot. We found that fine-tuning significantly improved model performance: on average, the error in testing decreased by 26.97% after fine-tuning. The system was well-received by older adult participants, who provided valuable feedback and suggestions for future work.},
  archive  = {J},
  author   = {Massimiliano Nigro and Amy O’Connell and Thomas Groechel and Anna-Maria Velentza and Maja Matarić},
  doi      = {10.1109/MRA.2024.3415108},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {125-133},
  title    = {An interactive augmented reality interface for personalized proxemics modeling: Comfort and Human–Robot interactions},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HuBotVerse: Toward internet of human and intelligent robotic things with a digital twin-based mixed reality framework. <em>MRA</em>, <em>32</em>(3), 114-124. (<a href='https://doi.org/10.1109/MRA.2024.3417090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Although the Internet of Robotic Things (IoRT) has enhanced the productivity of robotic systems in conjunction with the Internet of Things (IoT), it does not inherently support seamless human-robot collaboration. This paper presents HuBotVerse, a unified framework designed to foster the evolution of the Internet of Human and Intelligent Robotic Things (IoHIRT). HuBotVerse is advantageous due to its unique features, including security, user-friendliness, manageability, and its open-source nature. Moreover, this framework can seamlessly integrate various Human-Robot Interaction (HRI) interfaces to facilitate collaborative control between humans and robots. Here, we emphasize a Digital Twin-Based Mixed Reality (MR) interface, which enhances teleoperation efficiency by offering users an intuitive and immersive way to interact. To evaluate the effectiveness of HuBotVerse, we conducted user studies based on a pick-and-place task. Feedback was gathered through questionnaires, complemented by a quantitative analysis of key performance metrics, user experience, and the NASA Task Load Index (NASA-TLX). Results indicate that the fusion of MR and HuBotVerse within a comprehensive framework significantly improves the efficiency and user experience of teleoperation. Moreover, the follow-up questionnaires reflect the advantages of the HuBotVerse framework in terms of evident user-friendliness, manageability, and usability in homecare or healthcare applications. For codes, project videos, tutorials, technical details, case studies, and Q&A, please check our website (https://sites.google.com/view/iohirtplusmr/home).},
  archive  = {J},
  author   = {Dandan Zhang and Ziniu Wu and Jin Zheng and Yifan Li and Zheng Dong and Jialin Lin},
  doi      = {10.1109/MRA.2024.3417090},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {114-124},
  title    = {HuBotVerse: Toward internet of human and intelligent robotic things with a digital twin-based mixed reality framework},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward industry 5.0: A neuroergonomic workstation for a human-centered, collaborative robot-supported manual assembly process. <em>MRA</em>, <em>32</em>(3), 103-113. (<a href='https://doi.org/10.1109/MRA.2024.3487323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article brings the concept of neuroergonomic workcell with its essential components (psychological and physical assessment, nonphysical, physical, and strategic support) for improving the well-being and productivity of workers at their workplaces. A proof-of-concept neuroergonomic human-centered workstation is demonstrated in a real factory environment for a typical industrial laborious task: assembly. The pilot workstation introduces a fully portable, noninvasive electroencephalogram (EEG)-based users’ mental workload assessment, a nonobtrusive human–machine interface, illustrative graphical assembly guidelines, a collaborative robot assistant, and an intelligent task scheduler. The subjects’ performance and workload were assessed using a NASA Task Load Index questionnaire, three EEG workload indices, hand gesture detection accuracy, the number of errors, and task duration. We identified a notable correlation between multiple EEG indices of workload and NASA score results. The new workstation boosts productivity with better performance and fewer errors on the assembly line while reducing mental demand. Its modular design ensures easy integration and adaptation into factory settings, optimizing manual assembly processes.},
  archive  = {J},
  author   = {Nikola Knežević and Andrej Savić and Zaviša Gordić and Arash Ajoudani and Kosta Jovanović},
  doi      = {10.1109/MRA.2024.3487323},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {103-113},
  title    = {Toward industry 5.0: A neuroergonomic workstation for a human-centered, collaborative robot-supported manual assembly process},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards fully integrated autonomous excavation: Autonomous excavator for precise earth cutting and onboard landscape inspection. <em>MRA</em>, <em>32</em>(3), 88-102. (<a href='https://doi.org/10.1109/MRA.2024.3400772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Autonomous excavator systems can alleviate the issues caused by the shortage of skilled labor forces and increasing labor costs. For autonomous excavation, real-time landscape estimation, excavation path generation, control, and precise landscape inspection are all essential. In this article, we propose and experimentally validate an integrated autonomous excavator system incorporating all these elements. Specifically, unlike previous research, we introduce a sensor arrangement capable of sufficiently covering the regions of interest regardless of the inclination of the target landscape, a motion planning method that satisfies geometric and physical constraints, and a precise postexcavation inspection module using only onboard sensors. The proposed methodology was experimentally validated using a real 30-ton hydraulic excavator. It successfully performed a cutting task on an upward slope with 45° inclination and achieved a centimeter-level accuracy through autonomous repetitive excavation; also, the proposed postexcavation inspection method demonstrated subcentimeter precision within seconds using onboard sensors only.},
  archive  = {J},
  author   = {Inkyu Jang and Junha Kim and Dongjae Lee and Changhyeon Kim and Changsuk Oh and Youngbum Kim and Sangwook Woo and Heejee Sung and H. Jin Kim},
  doi      = {10.1109/MRA.2024.3400772},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {88-102},
  title    = {Towards fully integrated autonomous excavation: Autonomous excavator for precise earth cutting and onboard landscape inspection},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Int-ball2: On-orbit demonstration of autonomous intravehicular flight and docking for image capturing and recharging. <em>MRA</em>, <em>32</em>(3), 76-87. (<a href='https://doi.org/10.1109/MRA.2024.3505776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents the system architecture and the orbital demonstration results of the Int-Ball2, a free-flying camera robot developed by the Japan Aerospace Exploration Agency (JAXA). The purpose of the Int-Ball2 project is to assist astronauts and reduce their workload in the International Space Station (ISS). This robot is an upgrade from the first Int-Ball, enhancing the propulsion subsystem for greater maneuverability and adding a new docking station (DS) for autonomous battery recharging. This study performed comprehensive ground tests for autonomous maneuvering and docking, employing a combination of a fully software-based simulator, a hardware-in-the-loop (HIL) simulator, and a planar air-bearing facility. After a successful launch to the ISS, the Int-Ball2 demonstrated its ability to work in microgravity without relying on astronaut support. The results obtained from ground and orbital tests underscored the effectiveness of our system design and ground verification approach. Further, we present key technologies essential for the Int-Ball2’s successful implementation on board the ISS. We expect the insights from this project to be invaluable to future missions involving free-flying robots in microgravity.},
  archive  = {J},
  author   = {Daichi Hirano and Shinji Mitani and Keisuke Watanabe and Taisei Nishishita and Tatsuya Yamamoto and Seiko P. Yamaguchi},
  doi      = {10.1109/MRA.2024.3505776},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {76-87},
  title    = {Int-ball2: On-orbit demonstration of autonomous intravehicular flight and docking for image capturing and recharging},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale vine robots for industrial inspection: Developing a new framework to overcome limitations with existing inspection methods. <em>MRA</em>, <em>32</em>(3), 64-75. (<a href='https://doi.org/10.1109/MRA.2024.3487326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Industrial facilities such as chemical factories, gas terminals, and power plants can contain kilometers of piping that require meticulous inspection for leaks and defects prior to operation. This is a costly and time-consuming process that sometimes requires dismantling sections of pipe. While current internal inspection devices such as borescopes, “pipe inspection gadgets,” rovers, and drones serve specific purposes, none can effectively maneuver through multiple bends with large diameter changes while pulling a tethered sensor. As a first step in addressing this need, we tackled the mobility challenge without a sensor, developing a 33-m-long, 1-m-wide, soft, inflatable vine robot for accessing hard-to-reach spaces in dangerous industrial facilities. We also investigated ways to mount sensors to large-scale vine robots, identified key challenges in doing so, and provide the framework for a potential solution. Our work addresses many modeling, design, and scaling challenges, including frictional properties, gravitational effects, pneumatic control, and portability. To validate the device’s capabilities, we conducted testing at a Bechtel facility in Houston, TX, USA. Our portable device successfully navigated a 24-m-long section of oil and gas piping, negotiating a 90° bend, a vertical section, a blockage, and an open chamber. Our work not only represents a substantial advancement in addressing current pipe navigation challenges but also establishes a new benchmark as the world’s largest soft robot, showcasing the effectiveness of pneumatic principles at large scales.},
  archive  = {J},
  author   = {William E. Heap and Steven Man and Vedad Bassari and Steven Nguyen and Elvy B. Yao and Neel A. Tripathi and Nicholas D. Naclerio and Elliot W. Hawkes},
  doi      = {10.1109/MRA.2024.3487326},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {64-75},
  title    = {Large-scale vine robots for industrial inspection: Developing a new framework to overcome limitations with existing inspection methods},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic grape inspection and selective harvesting in vineyards: A multisensory robotic system with advanced cognitive capabilities. <em>MRA</em>, <em>32</em>(3), 51-63. (<a href='https://doi.org/10.1109/MRA.2024.3487324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Driven by the increasing food demand and the need for higher-quality cultivation, precision agriculture grows steadily during the last decade. It involves the application of mobile robots and intelligent robotic technologies in various agricultural field tasks, concerning a variety of crop types. Aiming at compensating for the lack of selective robotic harvesting solutions regarding the high-value crop of grapes, the EU-funded project BACCHUS (https://cordis.europa.eu/project/id/871704 and https://bacchus-project.eu/) develops an intelligent mobile robotic system, comprising two independent and cooperative robots: one for the grape inspection and collection of valuable data regarding their maturity level, and one for the bimanual harvesting of grapes in a human-inspired manner. Validated via real-field trials, the proposed autonomous system pushes forward the precision agriculture application for a particularly sensitive crop type in the challenging and heavily cluttered environment of vineyards, facilitating the selective harvesting of high-quality grapes.},
  archive  = {J},
  author   = {Sotiris Stavridis and Leonidas Droukas and Zoe Doulgeri and Dimitrios Papageorgiou and Fotios Dimeas and Ángel Soriano and Sergi Molina and Sami Ahmed Deiri and Michael Hutchinson and Jaime Pulido-Fentanes and Ibrahim Hroob and Riccardo Polvara and Marc Hanheide and Grzegorz Cielniak and Nikiforos Samarinas and Dimitrios Kateris and Dionysis Bochtis and Georgia Peleka and Stefanos Papadam and Dimitra Triantafyllou and Alexios Papadimitriou and Christos Papadopoulos and Ioannis Mariolis and Dimitrios Giakoumis and Dimitrios Tzovaras},
  doi      = {10.1109/MRA.2024.3487324},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {51-63},
  title    = {Robotic grape inspection and selective harvesting in vineyards: A multisensory robotic system with advanced cognitive capabilities},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing campus mobility: Achievements and challenges of the snow lion autonomous shuttle. <em>MRA</em>, <em>32</em>(3), 40-50. (<a href='https://doi.org/10.1109/MRA.2024.3433168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, the rapid evolution of autonomous vehicles (AVs) has reshaped global transportation systems, leading to an increase in autonomous shuttle applications in people’s daily lives. Leveraging the accomplishments of our earlier endeavor, particularly Hercules (Liu et al., 2021), an autonomous logistics vehicle for transporting goods, we introduce Snow Lion, an autonomous shuttle vehicle specifically designed to transform on-campus transportation, providing a safe and efficient mobility solution for students, faculty, and visitors.},
  archive  = {J},
  author   = {Yingbing Chen and Jie Cheng and Sheng Wang and Hongji Liu and Xiaodong Mei and Xiaoyang Yan and Mingkai Tang and Ge Sun and Ya Wen and Junwei Cai and Xupeng Xie and Lu Gan and Mandan Chao and Ren Xin and Lujia Wang and Ming Liu and Jianhao Jiao},
  doi      = {10.1109/MRA.2024.3433168},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {40-50},
  title    = {Enhancing campus mobility: Achievements and challenges of the snow lion autonomous shuttle},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward the deployment of an autonomous last-mile delivery robot in urban areas: The ona prototype platform. <em>MRA</em>, <em>32</em>(3), 26-39. (<a href='https://doi.org/10.1109/MRA.2024.3487321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Nowadays, the skyrocketing last-mile freight transportation in urban areas is leading to very negative effects (e.g., pollution, noise, or traffic congestion), which could be minimized by using autonomous electric vehicles. In this sense, this article presents the first prototype of Ona, an autonomous last-mile delivery robot that, in contrast to existing platforms, has a medium-sized storage capacity with the capability of navigating in both street and pedestrian areas. Herein we describe the platform and position it with respect to other existing prototypes, providing its main software modules and the first validation experiments, carried out in the Barcelona Robot Lab (Universitat Politècnica de Catalunya); Esplugues de Llobregat (next to Barcelona); and Debrecen (Hungary), which are representative urban scenarios. In such validations, we focus our analysis on the key localization module, whose errors could cascade down the rest of the navigation pipeline (e.g., planning or control). Aside from robotic technical details, we also include the results of the technology acceptance by the public present in the Esplugues de Llobregat test, collected in situ through a survey.},
  archive  = {J},
  author   = {Angel Santamaria-Navarro and Sergi Hernández and Fernando Herrero and Alejandro López and Iván del Pino and Nicolás Rodríguez-Linares and Carlos Fernández and Albert Baldó and Clément Lemardelé and Anaís Garrell and Joan Vallvé and Hafsa Taher and Ana M. Puig-Pey and Laia Pagès and Alberto Sanfeliu},
  doi      = {10.1109/MRA.2024.3487321},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {26-39},
  title    = {Toward the deployment of an autonomous last-mile delivery robot in urban areas: The ona prototype platform},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Door-to-door parcel delivery from supply point to user’s home with heterogeneous robot team: The euROBIN first-year robotics hackathon. <em>MRA</em>, <em>32</em>(3), 8-25. (<a href='https://doi.org/10.1109/MRA.2024.3501954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Logistics and service operations involving parcel preparation, delivery, and unpacking from a supply point to a user’s home could be carried out completely by robots in the near future, taking advantage of the capabilities of the different robot morphologies for the logistics, outdoor, and domestic environments. The use of robots for parcel delivery can contribute to the goals of sustainability and reduced emissions by exploiting their different locomotion modalities (wheeled, legged, and aerial). This article reports the development and results obtained from the first robotics hackathon celebrated as part of the European Robotics and Artificial Intelligence Network involving eight robotic platforms in three domains: 1) an industrial robotic arm for parcel preparation at the supply point, 2) a Centauro robot, a dual-arm aerial manipulator, and a wheeled-legged quadruped for parcel transportation, and 3) two humanoid robots and two commercial mobile manipulators for parcel delivery and unpacking in domestic scenarios. The article describes the joint operation and the evaluation scenario, the features and capabilities of the robots, particularly those involved in the realization of the tasks, and the lessons learned.},
  archive  = {J},
  author   = {Alejandro Suarez and Rainer Kartmann and Daniel Leidner and Luca Rossini and Johann Huber and Carlos Azevedo and Quentin Rouxel and Marko Bjelonic and Antonio Gonzalez-Morgado and Christian Dreher and Peter Schmaus and Arturo Laurenzi and François Hélénon and Rodrigo Serra and Jean-Baptiste Mouret and Lorenz Wellhausen and Vicente Perez-Sanchez and Jianfeng Gao and Adrian Simon Bauer and Alessio De Luca and Mouad Abrini and Rui Bettencourt and Olivier Rochel and Joonho Lee and Pablo Viana and Christoph Pohl and Nesrine Batti and Diego Vedelago and Vamsi Krishna Guda and Alexander Reske and Carlos Alvarez and Fabian Reister and Werner Friedl and Corrado Burchielli and Aline Baudry and Fabian Peller-Konrad and Thomas Gumpert and Luca Muratore and Philippe Gauthier and Franziska Krebs and Sebastian Jung and Lorenzo Baccelliere and Hippolyte Watrelot and Andre Meixner and Anne Köpken and Mohamed Chetouani and Pascal Weiner and Florian Lay and Felix Hundhausen and Anne Reichert and Noémie Jaquier and Florian Schmidt and Marco Sewtz and Freek Stulp and Lioba Suchenwirth and Rudolph Triebel and Xuwei Wu and Begoña Arrue and Rebecca Schedl-Warpup and Marco Hutter and Serena Ivaldi and Pedro U. Lima and Stéphane Doncieux and Nikos Tsagarakis and Tamim Asfour and Anibal Ollero and Alin Albu-Schäffer},
  doi      = {10.1109/MRA.2024.3501954},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {8-25},
  title    = {Door-to-door parcel delivery from supply point to user’s home with heterogeneous robot team: The euROBIN first-year robotics hackathon},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Humanoids and robot learning [President’s message]. <em>MRA</em>, <em>32</em>(3), 5-6. (<a href='https://doi.org/10.1109/MRA.2025.3588643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Aude Billard},
  doi     = {10.1109/MRA.2025.3588643},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {5-6},
  title   = {Humanoids and robot learning [President’s message]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New impact factor, new promises: Never a better time for robotics and automation [From the editor’s desk]. <em>MRA</em>, <em>32</em>(3), 4. (<a href='https://doi.org/10.1109/MRA.2025.3588644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Yi Guo},
  doi     = {10.1109/MRA.2025.3588644},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {4},
  title   = {New impact factor, new promises: Never a better time for robotics and automation [From the editor’s desk]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Important updates to journal review process guidelines. <em>MRA</em>, <em>32</em>(2), 211. (<a href='https://doi.org/10.1109/MRA.2025.3561636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3561636},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {211},
  title    = {Important updates to journal review process guidelines},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2025 RAS AdCom election results. <em>MRA</em>, <em>32</em>(2), 210. (<a href='https://doi.org/10.1109/MRA.2025.3561613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3561613},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {210},
  title    = {2025 RAS AdCom election results},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE transactions on field robotics: A dedicated venue for high-impact field robotics research [Society news]. <em>MRA</em>, <em>32</em>(2), 206-207. (<a href='https://doi.org/10.1109/MRA.2025.3561611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  author   = {Sanjiv Singh},
  doi      = {10.1109/MRA.2025.3561611},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {206-207},
  title    = {IEEE transactions on field robotics: A dedicated venue for high-impact field robotics research [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strengthening robotics and automation in africa: Highlights of ICRA@40–Africa [Education]. <em>MRA</em>, <em>32</em>(2), 202-216. (<a href='https://doi.org/10.1109/MRA.2025.3560463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Ndivhuwo Makondo and Paul Amayo and Jenalea Rajab and Lifhasi Ramulondi and Steven James and Alexandra Barry and Adam Mukuddem and Thabisa Maweni and Tamlin Love and Geraud Nangue Tasse and Zimkhitha Sijovu and Belinda Matebese and Benjamin Rosman},
  doi     = {10.1109/MRA.2025.3560463},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {202-216},
  title   = {Strengthening robotics and automation in africa: Highlights of ICRA@40–Africa [Education]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building fire-resilient forests: Robotic innovations for wildfire risk mitigation [Industry activities]. <em>MRA</em>, <em>32</em>(2), 200-216. (<a href='https://doi.org/10.1109/MRA.2025.3560464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Micael S. Couceiro and Paulo Peixoto and A. Paulo Coimbra and Aníbal T. de Almeida},
  doi     = {10.1109/MRA.2025.3560464},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {200-216},
  title   = {Building fire-resilient forests: Robotic innovations for wildfire risk mitigation [Industry activities]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot control [TC spotlight]. <em>MRA</em>, <em>32</em>(2), 197-198. (<a href='https://doi.org/10.1109/MRA.2025.3560465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Cosimo Della Santina and Sylvia Herbert and Manuel Keppler and Kaoru Yamamoto},
  doi     = {10.1109/MRA.2025.3560465},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {197-198},
  title   = {Robot control [TC spotlight]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous mario kart in the wild: Lessons learned from the earth rover challenge at IROS 2024 [Competitions]. <em>MRA</em>, <em>32</em>(2), 189-196. (<a href='https://doi.org/10.1109/MRA.2025.3565211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Xuesu Xiao and Jie Tan and Michael Cho and David Hsu and Dhruv Shah and Joanne Truong and Ted Xiao and Naoki Yokoyama and Wenhao Yu and Tingnan Zhang and Zhuo Xu and Santiago Pravisani and Niresh Dravin and Mohammad Alshamsi},
  doi     = {10.1109/MRA.2025.3565211},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {189-196},
  title   = {Autonomous mario kart in the wild: Lessons learned from the earth rover challenge at IROS 2024 [Competitions]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable transmission mechanisms for robotic applications: A review [Survey]. <em>MRA</em>, <em>32</em>(2), 167-188. (<a href='https://doi.org/10.1109/MRA.2024.3451795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Actuators play a crucial role in robotics, determining the force and speed capabilities necessary for varied tasks, directly affecting the performance of the robotic system. With the growing reliance on robotics in both industrial applications and daily life, innovative actuator research has expanded significantly. Despite advances, traditional actuators encounter limitations in performance and operational range due to inherent physical constraints. To address these challenges, variable transmission mechanisms (VTMs) have emerged over the past decade as one of the alternative solutions, enhancing the adaptability and efficiency of robotic systems. However, there is currently a lack of survey articles that comprehensively cover the mechanisms and working principles of VTMs in robotics. This review article fills this gap by offering an extensive analysis of VTM applications in robotics. It categorizes VTMs based on their mechanisms and principles, presents case studies on both commercial and experimental VTMs, and provides insights into future prospects.},
  archive  = {J},
  author   = {Jihyuk Park and Joon Lee and Hyung-Tae Seo and Seokhwan Jeong},
  doi      = {10.1109/MRA.2024.3451795},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {167-188},
  title    = {Variable transmission mechanisms for robotic applications: A review [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey of simulators for aerial robots: An overview and in-depth systematic comparisons [Survey]. <em>MRA</em>, <em>32</em>(2), 153-166. (<a href='https://doi.org/10.1109/MRA.2024.3433171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Uncrewed Aerial Vehicle (UAV) research faces challenges with safety, scalability, costs, and ecological impact when conducting hardware testing. High-fidelity simulators offer a vital solution by replicating real-world conditions to enable the development and evaluation of novel perception and control algorithms. However, the large number of available simulators poses a significant challenge for researchers to determine which simulator best suits their specific use-case, based on each simulator’s limitations and customization readiness. In this paper we present an overview of 43 UAV simulators, including in-depth, systematic comparisons for 17 of the simulators. Additionally, we present a set of decision factors for selection of simulators, aiming to enhance the efficiency and safety of research endeavors.},
  archive  = {J},
  author   = {Cora A. Dimmig and Giuseppe Silano and Kimberly McGuire and Chiara Gabellieri and Wolfgang Hönig and Joseph Moore and Marin Kobilarov},
  doi      = {10.1109/MRA.2024.3433171},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {153-166},
  title    = {Survey of simulators for aerial robots: An overview and in-depth systematic comparisons [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Magnetic resonance imaging-guided needle insertion robots: A review of systems for liver and kidney interventions [Survey]. <em>MRA</em>, <em>32</em>(2), 129-152. (<a href='https://doi.org/10.1109/MRA.2024.3409788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {MRI-guided intervention for the liver and kidney has achieved considerable progress in tumour diagnosis and treatment over the past two decades. However, due to the space constraints associated with the narrow and deep bore of the MRI machines, it is still extremely challenging for clinicians to position and drive the needle-shaped probes used for delivering the treatment where the targeted tumoral mass is located. MRIcompatible robotic systems have been investigated by several research teams worldwide, both in academia and industry. These endeavours aim to address challenges related to the confined workspace within MRI machine bores. The goal is to facilitate the shift from CT-guided to MRI-guided interventions, leveraging the advantages of MRI, including its exceptional soft tissue contrast, non-ionizing radiation, and versatile multi-angle imaging capabilities. In this article, we systematically review the state-of-the-art MRI-guided needle insertion robots for the treatment of the liver and kidney in order to identify challenges, trends and potential research gaps in this field. Furthermore, this review encompasses robotic systems designed for anatomically similar regions or exhibiting comparable structures to those intended for interventions in the liver and kidney. These systems, which have shown potential for application in this field, are discussed to explore possibilities within this domain. The review concludes by proposing future research directions in this area.},
  archive  = {J},
  author   = {Ziting Liang and Lukas Lindenroth and Ryman Hashem and Steve Bandula and Danail Stoyanov and Agostino Stilli},
  doi      = {10.1109/MRA.2024.3409788},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {129-152},
  title    = {Magnetic resonance imaging-guided needle insertion robots: A review of systems for liver and kidney interventions [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Caveats on the first-generation da vinci research kit: Latent technical constraints and essential calibrations [Survey]. <em>MRA</em>, <em>32</em>(2), 113-128. (<a href='https://doi.org/10.1109/MRA.2023.3310863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Telesurgical robotic systems provide a well established form of assistance in the operating theater, with evidence of growing uptake in recent years. Until now, the da Vinci surgical system (Intuitive Surgical Inc, Sunnyvale, California) has been the most widely adopted robot of this kind, with more than 6,700 systems in current clinical use worldwide [1]. To accelerate research on robotic-assisted surgery, the retired first-generation da Vinci robots have been redeployed for research use as “da Vinci Research Kits” (dVRKs), which have been distributed to research institutions around the world to support both training and research in the sector. In the past ten years, a great amount of research on the dVRK has been carried out across a vast range of research topics. During this extensive and distributed process, common technical issues have been identified that are buried deep within the dVRK research and development architecture, and were found to be common among dVRK user feedback, regardless of the breadth and disparity of research directions identified. This paper gathers and analyzes the most significant of these, with a focus on the technical constraints of the first-generation dVRK, which both existing and prospective users should be aware of before embarking onto dVRK-related research. The hope is that this review will aid users in identifying and addressing common limitations of the systems promptly, thus helping to accelerate progress in the field.},
  archive  = {J},
  author   = {Zejian Cui and João Cartucho and Stamatia Giannarou and Ferdinando Rodriguez y Baena},
  doi      = {10.1109/MRA.2023.3310863},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {113-128},
  title    = {Caveats on the first-generation da vinci research kit: Latent technical constraints and essential calibrations [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Engine agnostic graph environments for robotics (EAGERx): A graph-based framework for sim2real robot learning. <em>MRA</em>, <em>32</em>(2), 99-112. (<a href='https://doi.org/10.1109/MRA.2024.3433172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Sim2real, that is, the transfer of learned control policies from simulation to real world, is an area of growing interest in robotics due to its potential to efficiently handle complex tasks. The sim2real approach faces challenges due to mismatches between simulation and reality. These discrepancies arise from inaccuracies in modeling physical phenomena and asynchronous control, among other factors. To this end, we introduce EAGERx, a framework with a unified software pipeline for both real and simulated robot learning. It can support various simulators and aids in integrating state, action and time-scale abstractions to facilitate learning. EAGERx’s integrated delay simulation, domain randomization features, and proposed synchronization algorithm contribute to narrowing the sim2real gap. We demonstrate (in the context of robot learning and beyond) the efficacy of EAGERx in accommodating diverse robotic systems and maintaining consistent simulation behavior. EAGERx is open source and its code is available at https://eagerx.readthedocs.io.},
  archive  = {J},
  author   = {Bas van der Heijden and Jelle Luijkx and Laura Ferranti and Jens Kober and Robert Babuska},
  doi      = {10.1109/MRA.2024.3433172},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {99-112},
  title    = {Engine agnostic graph environments for robotics (EAGERx): A graph-based framework for sim2real robot learning},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeMuCo: Generalized multisensory correlational model for body schema learning. <em>MRA</em>, <em>32</em>(2), 80-98. (<a href='https://doi.org/10.1109/MRA.2024.3415111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Humans can autonomously learn the relationship between sensation and motion in their own bodies, estimate and control their own body states, and move while continuously adapting to the current environment. On the other hand, current robots control their bodies by learning the network structure described by humans from their experiences, making certain assumptions on the relationship between sensors and actuators. In addition, the network model does not adapt to changes in the robot’s body, the tools that are grasped, or the environment, and there is no unified theory, not only for control but also for state estimation, anomaly detection, simulation, and so on. In this study, we propose a Generalized Multisensory Correlational Model (GeMuCo), in which the robot itself acquires a body schema describing the correlation between sensors and actuators from its own experience, including model structures such as network input/output. The robot adapts to the current environment by updating this body schema model online, estimates and controls its body state, and even performs anomaly detection and simulation. We demonstrate the effectiveness of this method by applying it to tool-use considering changes in grasping state for an axis-driven robot, to joint-muscle mapping learning for a musculoskeletal robot, and to full-body tool manipulation for a low-rigidity plasticmade humanoid.},
  archive  = {J},
  author   = {Kento Kawaharazuka and Kei Okada and Masayuki Inaba},
  doi      = {10.1109/MRA.2024.3415111},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {80-98},
  title    = {GeMuCo: Generalized multisensory correlational model for body schema learning},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuromorphic quadratic programming for efficient and scalable model predictive control: Towards advancing speed and energy efficiency in robotic control. <em>MRA</em>, <em>32</em>(2), 69-79. (<a href='https://doi.org/10.1109/MRA.2024.3415005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Applications in robotics or other size-, weight- and power-constrained autonomous systems at the edge often require real-time and low-energy solutions to large optimization problems. Event-based and memory-integrated neuromorphic architectures promise to solve such optimization problems with superior energy efficiency and performance compared to conventional von Neumann architectures. Here, we present a method to solve convex continuous optimization problems with quadratic cost functions and linear constraints on Intel’s scalable neuromorphic research chip Loihi 2. When applied to model predictive control (MPC) problems for the quadruped robotic platform ANYmal, this method achieves over two orders of magnitude reduction in combined energy-delay product compared to the state-of-the-art solver, OSQP, on (edge) CPUs and GPUs with solution times under ten milliseconds for various problem sizes. These results demonstrate the benefit of non-von-Neumann architectures for robotic control applications.},
  archive  = {J},
  author   = {Ashish Rao Mangalore and Gabriel Andres Fonseca Guerra and Sumedh R. Risbud and Philipp Stratmann and Andreas Wild},
  doi      = {10.1109/MRA.2024.3415005},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {69-79},
  title    = {Neuromorphic quadratic programming for efficient and scalable model predictive control: Towards advancing speed and energy efficiency in robotic control},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A whole-body integrated AVATAR system: Implementation of telepresence with intuitive control and immersive feedback. <em>MRA</em>, <em>32</em>(2), 60-68. (<a href='https://doi.org/10.1109/MRA.2023.3328512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper proposes an intuitive and immersive whole-body teleoperation system with motion-based control and multi-modal feedback. The system consists of an anthropomorphic teleoperated robot and a haptic interface platform. The teleoperated robot has dual arms with dexterous hands, a head with a neck, a waist, giving it a human-like appearance and a large range of motion (ROM), as well as an omnidirectional mobile platform for improved mobility. The haptic interface platform enables a human operator to control the robot intuitively by measuring the operator's motion with a motion capture system, providing haptic feedback to the user’s arms, fingers, and feet, and providing 3D image feedback. Additionally, facial animation further enhances immersion by synchronizing the face expression of the robot with the user’s voice. The proposed teleoperation system offers a promising solution for the human-oriented robotic avatar system, which was verified through a global competition, the $10M ANA Avatar XPRIZE. The system was successfully evaluated with 45 minutes of training time for users who were new to our system. And the lessons learned from the competition and future improvements are discussed.},
  archive  = {J},
  author   = {Sungman Park and Junsoo Kim and Hojae Lee and Minwoong Jo and Dohoon Gong and Dawon Ju and Dami Won and Sihyeon Kim and Jinhyeok Oh and Hun Jang and Joonbum Bae},
  doi      = {10.1109/MRA.2023.3328512},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {60-68},
  title    = {A whole-body integrated AVATAR system: Implementation of telepresence with intuitive control and immersive feedback},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for high-speed quadrupedal locomotion with motor operating region constraints: Mitigating motor model discrepancies through torque clipping in realistic motor operating region. <em>MRA</em>, <em>32</em>(2), 49-59. (<a href='https://doi.org/10.1109/MRA.2024.3487322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents a method for achieving high-speed running of a quadruped robot by considering the actuator torque–speed operating region in reinforcement learning. The physical properties and constraints of the actuator are included in the training process to reduce state transitions that are infeasible in the real world due to motor torque–speed limitations. The gait reward is designed to distribute motor torque evenly across all legs, contributing to more balanced power usage and mitigating performance bottlenecks due to single-motor saturation. With the trained policy, KAIST Hound, a 45-kg quadruped robot, can run up to 6.5 m/s, which is the fastest speed among electric motor-based quadruped robots.},
  archive  = {J},
  author   = {Young-Ha Shin and Tae-Gyu Song and Gwanghyeon Ji and Hae-Won Park},
  doi      = {10.1109/MRA.2024.3487322},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {49-59},
  title    = {Reinforcement learning for high-speed quadrupedal locomotion with motor operating region constraints: Mitigating motor model discrepancies through torque clipping in realistic motor operating region},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum-based reinforcement learning for quadrupedal jumping: A reference-free design. <em>MRA</em>, <em>32</em>(2), 35-48. (<a href='https://doi.org/10.1109/MRA.2024.3487325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep reinforcement learning (DRL) has emerged as a promising solution to mastering explosive and versatile quadrupedal jumping skills. However, current DRL-based frameworks usually rely on pre-existing reference trajectories obtained by capturing animal motions or transferring experience from existing controllers. This work aims to prove that learning dynamic jumping is possible without relying on imitating a reference trajectory by leveraging a curriculum design. Starting from a vertical in-place jump, we generalize the learned policy to forward and diagonal jumps and, finally, we learn to jump across obstacles. Conditioned on the desired landing location, orientation, and obstacle dimensions, the proposed approach yields a wide range of omnidirectional jumping motions in real-world experiments. In particular, we achieve a 90 cm forward jump, exceeding all previous records for similar robots. Additionally, the robot can reliably execute continuous jumping on soft grassy grounds, which is especially remarkable as such conditions were not included in the training stage.},
  archive  = {J},
  author   = {Vassil Atanassov and Jiatao Ding and Jens Kober and Ioannis Havoutis and Cosimo Della Santina},
  doi      = {10.1109/MRA.2024.3487325},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {35-48},
  title    = {Curriculum-based reinforcement learning for quadrupedal jumping: A reference-free design},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transurethral surgical robot: Achieving efficient en bloc resection of bladder tumor. <em>MRA</em>, <em>32</em>(2), 23-34. (<a href='https://doi.org/10.1109/MRA.2025.3527381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Bladder cancer ranks as the 10th most common cancer globally. Currently, the standard surgical approach for bladder tumor removal involves transurethral piecemeal resection, which carries high recurrence (60%) and perforation (12%) rates. Although various techniques and robotic systems have been developed for en-bloc tumor resection, achieving a negative resection margin remains challenging with standard resectoscopes. Here, we present the Robot-Optimized Bladder Endoscopy Resection of Tumor (ROBERT) system, a dual-arm robotic system designed to fit into a standard irrigation sheath along with an endoscope. The ROBERT system offers enhanced dexterity and payload capacity, allowing surgeons to perform en-bloc tumor resections effectively. In both ex-vivo and in-vivo experiments, the ROBERT system achieved negative margins, with muscular tissue visually identified in the excised samples. The fastest resection was completed in approximately 6 minutes, and the largest excised tissue size was 15 ×15 × 3mm. These results demonstrate ROBERT system’s feasibility and potential for improving bladder tumor resection outcomes.},
  archive  = {J},
  author   = {Muneaki Miyasaka and Jiajun Liu and Wenjie Lai and Yu Xi Terence Law and Gerald Lim and Banjamin Quek and Ziting Wang and Qing Hui Wu and Edmund Chiong and Soo Jay Phee},
  doi      = {10.1109/MRA.2025.3527381},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {23-34},
  title    = {Transurethral surgical robot: Achieving efficient en bloc resection of bladder tumor},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robotic system for transanal endoscopic microsurgery: Design, dexterity optimization, and prototyping. <em>MRA</em>, <em>32</em>(2), 8-22. (<a href='https://doi.org/10.1109/MRA.2023.3323849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper proposes a master-slave operated robotic system that features the novel slave manipulator with a modular distal continuum section to address the shortcomings of traditional transanal endoscopic microsurgery (TEM). The slave manipulator consists of two 7-DoF surgical instruments and a 5-DoF endoscopic arm that are designed with distal continuum structures and unfolded with a Y configuration after inserting through a transanal port to enhance hand-eye coordination and instrument triangulation. The proposed robot is designed for adaptation in narrow and shallow rectal spaces, facilitating intuitive hand-eye coordination and enhanced operational dexterity with reduced obstruction of the field of view. A novel hybrid coaxial continuum unit (HCCU) has been designed to offer excellent bending characteristics and structural stiffness. This unit has been developed as a modular design and supports different connection configurations to form the multi-DoF surgical instruments and endoscopic arm. FEA-based structure optimization has been implemented to improve the mechanical performances of the HCCU unit. Dexterity optimization under anatomical constraints is proposed to improve the maneuverability of the multi-DoF distal continuum section. Experimental investigations on bending and anti-twisting performances on the designed HCCU joint are carried out. The average error value of distal positioning within [- 100°, 100°] does not exceed 1.10%, and the torsional stiffness is 6.86 mNm/°. The payload capability of the surgical instrument has been investigated to demonstrate a maximum value of 5 N. The robotic system is prototyped and the trajectory tracking experiments have been performed to validate its positioning accuracy. The user study has been investigated, and the simulated operation tasks that include grape peeling and suturing operations as well as apricot suturing and threading operations, have been performed. The experimental results demonstrate its potential to be utilized in TEM surgery with an extensive surgical field of view and excellent maneuverability.},
  archive  = {J},
  author   = {Jichen Li and Shuxin Wang and Zhiqiang Zhang and Chaoyang Shi},
  doi      = {10.1109/MRA.2023.3323849},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {6},
  number   = {2},
  pages    = {8-22},
  title    = {A robotic system for transanal endoscopic microsurgery: Design, dexterity optimization, and prototyping},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE robotics and automation society launches a science and technology watch board [President’s message]. <em>MRA</em>, <em>32</em>(2), 6-7. (<a href='https://doi.org/10.1109/MRA.2025.3560416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Aude Billard},
  doi     = {10.1109/MRA.2025.3560416},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {6-7},
  title   = {IEEE robotics and automation society launches a science and technology watch board [President’s message]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Science needs diversity, robotics needs diversity: Fostering a culture of inclusion [From the editor’s desk]. <em>MRA</em>, <em>32</em>(2), 4. (<a href='https://doi.org/10.1109/MRA.2025.3559244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Yi Guo},
  doi     = {10.1109/MRA.2025.3559244},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {6},
  number  = {2},
  pages   = {4},
  title   = {Science needs diversity, robotics needs diversity: Fostering a culture of inclusion [From the editor’s desk]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Call for applications: IEEE/IFR innovation and entrepreneurship award for outstanding achievements in commercializing innovative and automation technology [Society news]. <em>MRA</em>, <em>32</em>(1), 131. (<a href='https://doi.org/10.1109/MRA.2025.3531186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  author   = {Kyung Mi Bae},
  doi      = {10.1109/MRA.2025.3531186},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {131},
  title    = {Call for applications: IEEE/IFR innovation and entrepreneurship award for outstanding achievements in commercializing innovative and automation technology [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE robotics and automation magazine welcomes new associate editors [Society news]. <em>MRA</em>, <em>32</em>(1), 130. (<a href='https://doi.org/10.1109/MRA.2025.3535904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3535904},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {130},
  title    = {IEEE robotics and automation magazine welcomes new associate editors [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2025 CASE SPIRSE competition [Society news]. <em>MRA</em>, <em>32</em>(1), 130. (<a href='https://doi.org/10.1109/MRA.2025.3531187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  author   = {Kyung Mi Bae},
  doi      = {10.1109/MRA.2025.3531187},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {130},
  title    = {2025 CASE SPIRSE competition [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2025 RAS AdCom election results. <em>MRA</em>, <em>32</em>(1), 129. (<a href='https://doi.org/10.1109/MRA.2025.3531184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  author   = {Kyung Mi Bae},
  doi      = {10.1109/MRA.2025.3531184},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {129},
  title    = {2025 RAS AdCom election results},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating the future: Insights from early-career academia [Student’s corner]. <em>MRA</em>, <em>32</em>(1), 124-126. (<a href='https://doi.org/10.1109/MRA.2025.3527659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Dipam Patel},
  doi     = {10.1109/MRA.2025.3527659},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {124-126},
  title   = {Navigating the future: Insights from early-career academia [Student’s corner]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing reproducibility, benchmarks, and education with remote sim2real: Remote simulation to real robot hardware. <em>MRA</em>, <em>32</em>(1), 117-123. (<a href='https://doi.org/10.1109/MRA.2025.3527291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Spencer Teetaert and Wenda Zhao and Antonio Loquercio and Siqi Zhou and Lukas Brunke and Martin Schuck and Wolfgang Hönig and Jacopo Panerati and Angela P. Schoellig},
  doi     = {10.1109/MRA.2025.3527291},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {117-123},
  title   = {Advancing reproducibility, benchmarks, and education with remote sim2real: Remote simulation to real robot hardware},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tale of two rovers: How different philosophies foster innovation in the 2023 university rover challenge [Competitions]. <em>MRA</em>, <em>32</em>(1), 110-116. (<a href='https://doi.org/10.1109/MRA.2025.3527286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Stephen Jacobs and Riley McAllister and Kendra Gillo and Tyler Robert Cook and Tyler Wolf and Parmis Hassani and Jack Ulbrich-Baker and Dhiluka Mapa and Nathan Adkins and Daniel McDonald and Chao Chen and Yu Gu},
  doi     = {10.1109/MRA.2025.3527286},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {110-116},
  title   = {A tale of two rovers: How different philosophies foster innovation in the 2023 university rover challenge [Competitions]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward fully autonomous aviation: PIBOT, a humanoid robot pilot for human-centric aircraft cockpits. <em>MRA</em>, <em>32</em>(1), 91-109. (<a href='https://doi.org/10.1109/MRA.2024.3505774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Humanoid robots have been considered ideal for automating daily tasks, though most research has centered on bipedal locomotion. Many activities we do routinely, such as driving a car, require real-time system manipulation as well as substantial field-specific knowledge. Recent breakthroughs in natural language processing, particularly with large language models (LLMs), are empowering humanoid robots to access and process vast information sources and operate systems with an unprecedented level of autonomy. This article introduces PIBOT, a humanoid robot that can pilot unmodified general aviation (GA) aircraft, physically manipulating instruments while following strict rules of the air and verbally communicating with copilots and air traffic controllers (ATCs). Building on these capabilities, we developed an LLM-based task planner that interprets natural language commands, translating them into action sequences. Then, the behavior decision module breaks tasks into precise limb movements, enabling humanlike control of cockpit instruments. In a series of rigorous simulations, PIBOT demonstrates its capabilities to successfully take off and land an airplane from a cold-and-dark start, showcasing its potential for a fully autonomous robot pilot.},
  archive  = {J},
  author   = {Sungjae Min and Gyuree Kang and Hyungjoo Kim and David Hyunchul Shim},
  doi      = {10.1109/MRA.2024.3505774},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {91-109},
  title    = {Toward fully autonomous aviation: PIBOT, a humanoid robot pilot for human-centric aircraft cockpits},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Humanoid robot RHP friends: Seamless combination of autonomous and teleoperated tasks in a nursing context. <em>MRA</em>, <em>32</em>(1), 79-90. (<a href='https://doi.org/10.1109/MRA.2024.3521995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article describes RHP Friends, a social humanoid robot developed to enable assistive robotic deployments in human-coexisting environments. As a use case application, we present its potential use in nursing by extending its capabilities to operate devices and tools according to the task and by enabling remote assistance operations. To meet a wide variety of tasks and situations in environments designed by and for humans, we develop a system that seamlessly integrates the slim and lightweight robot and several technologies: locomanipulation, multicontact motion, teleoperation, and object detection and tracking. We demonstrate the system’s usage in a nursing application. The robot efficiently performs the daily task of patient transfer and a nonroutine task, represented by a request to operate a circuit breaker. This demonstration, held at the 2023 International Robot Exhibition (IREX), was conducted three times a day over three days.},
  archive  = {J},
  author   = {Mehdi Benallegue and Guillaume Lorthioir and Antonin Dallard and Rafael Cisneros-Limón and Iori Kumagai and Mitsuharu Morisawa and Hiroshi Kaminaga and Masaki Murooka and Antoine Andre and Pierre Gergondet and Kenji Kaneko and Guillaume Caron and Fumio Kanehiro and Abderrahmane Kheddar and Soh Yukizaki and Junichi Karasuyama and Junichi Murakami and Masayuki Kamon},
  doi      = {10.1109/MRA.2024.3521995},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {79-90},
  title    = {Humanoid robot RHP friends: Seamless combination of autonomous and teleoperated tasks in a nursing context},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human–Humanoid robots’ cross-embodiment behavior-skill transfer using decomposed adversarial learning from demonstration: HOTU, a Human–Humanoid robots’ skill transfer framework. <em>MRA</em>, <em>32</em>(1), 68-78. (<a href='https://doi.org/10.1109/MRA.2025.3527283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Humanoid robots are envisioned as embodied intelligent agents capable of performing a wide range of human-level loco-manipulation tasks, particularly in scenarios that require strenuous and repetitive labor. However, learning these skills is challenging due to the high degrees of freedom of humanoid robots, and collecting sufficient training data for humanoid is a laborious process. Given the rapid introduction of new humanoid platforms, a cross-embodiment framework that allows generalizable skill transfer is becoming increasingly critical. To address this, we propose a transferable framework that reduces the data bottleneck by using a unified digital human model as a common prototype and bypassing the need for retraining on every new robot platform. The model learns behavior primitives from human demonstrations through adversarial imitation, and the complex robot structures are decomposed into functional components, each of which are trained independently and dynamically coordinated. Task generalization is achieved through a human-object interaction graph, and skills are transferred to different robots via embodiment-specific kinematic motion retargeting and dynamic fine-tuning. Our framework is validated on five humanoid robots with diverse configurations, demonstrating stable loco-manipulation and highlighting its effectiveness in reducing data requirements and increasing the efficiency of skill transfer across platforms.},
  archive  = {J},
  author   = {Junjia Liu and Zhuo Li and Minghao Yu and Zhipeng Dong and Sylvain Calinon and Darwin Caldwell and Fei Chen},
  doi      = {10.1109/MRA.2025.3527283},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {68-78},
  title    = {Human–Humanoid robots’ cross-embodiment behavior-skill transfer using decomposed adversarial learning from demonstration: HOTU, a Human–Humanoid robots’ skill transfer framework},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). I-CTRL: Imitation to control humanoid robots through bounded residual reinforcement learning. <em>MRA</em>, <em>32</em>(1), 59-67. (<a href='https://doi.org/10.1109/MRA.2025.3527284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Humanoid robots have the potential to mimic human motions with high visual fidelity, yet translating these motions into practical physical execution remains a significant challenge. Existing techniques in the graphics community often prioritize visual fidelity over physics-based feasibility, posing a significant challenge for deploying bipedal systems in practical applications. This article addresses these issues through bounded residual reinforcement learning (RL) to produce physics-based high-quality motion imitation onto legged humanoid robots that enhance motion resemblance while successfully following the reference human trajectory. Our framework, Imitation to Control Humanoid Robots Through Bounded Residual Reinforcement Learning (I-CTRL), reformulates motion imitation as a constrained refinement over nonphysics-based retargeted motions. I-CTRL excels in motion imitation with simple and unique rewards that generalize across five robots. Moreover, our framework introduces an automatic priority scheduler (APS) to manage large-scale motion datasets when efficiently training a unified RL policy across diverse motions. The proposed approach signifies a crucial step forward in advancing the control of bipedal robots, emphasizing the importance of aligning visual and physical realism for successful motion imitation.},
  archive  = {J},
  author   = {Yashuai Yan and Esteve Valls Mascaro and Tobias Egle and Dongheui Lee},
  doi      = {10.1109/MRA.2025.3527284},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {59-67},
  title    = {I-CTRL: Imitation to control humanoid robots through bounded residual reinforcement learning},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the reality gap: Analyzing sim-to-real transfer techniques for reinforcement learning in humanoid bipedal locomotion. <em>MRA</em>, <em>32</em>(1), 49-58. (<a href='https://doi.org/10.1109/MRA.2024.3505784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Reinforcement learning (RL) offers a promising solution for controlling humanoid robots, particularly for bipedal locomotion, by learning adaptive and flexible control strategies. However, direct RL application is hindered by time-consuming trial-and-error processes, necessitating training in simulation before real-world transfer. This introduces a reality gap that degrades performance. Although various methods have been proposed for sim-to-real transfer, they have not been validated on a consistent hardware platform, making it difficult to determine which components are key to overcoming the reality gap. In contrast, we systematically evaluate techniques to enhance RL policy robustness during sim-to-real transfer by controlling variables and comparing them on a single robot to isolate and analyze the impact of each technique. These techniques include dynamics randomization, state history usage, noise/bias/delay modeling, state selection, perturbations, and network size. We quantitatively assess the reality gap by simulating diverse conditions and conducting experiments on real hardware. Our findings provide insights into bridging the reality gap, advancing robust RL-trained humanoid robots for real-world applications.},
  archive  = {J},
  author   = {Donghyeon Kim and Hokyun Lee and Junhyeok Cha and Jaeheung Park},
  doi      = {10.1109/MRA.2024.3505784},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {49-58},
  title    = {Bridging the reality gap: Analyzing sim-to-real transfer techniques for reinforcement learning in humanoid bipedal locomotion},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motion planning for humanoid locomotion: Applications to homelike environments. <em>MRA</em>, <em>32</em>(1), 35-48. (<a href='https://doi.org/10.1109/MRA.2025.3527287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {“What can your humanoid robot do?” is probably the most commonly asked question that we, as roboticists, have to answer when interacting with the general public. Often, the question is framed in the familiar household or office setting, with implied expectations of robust locomotion on uneven and cluttered terrain and compliant interaction with people, objects, and the environment. Moreover, the question implies the existence within the humanoid robot of a set of embodied loco-manipulation skills implemented by a motion planner, skills that are retrievable when given the corresponding commands. In this article, we formulate an answer to this question in the form of an efficient, modular, and extensible motion planner. We demonstrate its use with three challenging scenarios, designed to highlight both the robot’s safe operation and its precise movement in unstructured environments. Additionally, we discuss key techniques derived from our experience in the practical implementation of torque-controlled humanoid robots.},
  archive  = {J},
  author   = {George Mesesan and Robert Schuller and Johannes Englsberger and Máximo A. Roa and Jinoh Lee and Christian Ott and Alin Albu-Schäffer},
  doi      = {10.1109/MRA.2025.3527287},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {35-48},
  title    = {Motion planning for humanoid locomotion: Applications to homelike environments},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The open stack of tasks library: OpenSoT: A software dedicated to hierarchical whole-body control of robots subject to constraints. <em>MRA</em>, <em>32</em>(1), 24-34. (<a href='https://doi.org/10.1109/MRA.2024.3487395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The Open Stack of Tasks (OpenSoT) library is a state-of-the-art framework for instantaneous whole-body motion planning and control based on quadratic programming optimization. The library is designed to enable users to easily write and solve a variety of complex instantaneous whole-body control problems with minimal input, facilitating the addition of new tasks, constraints, and solvers. OpenSoT is designed to be real-time safe and can be conveniently interfaced with other software components, such as Robotic Operating System or other robotic-oriented frameworks. This article aims to present the use of the OpenSoT library to a large audience of researchers, engineers, and practitioners as well as provide insights into its software design, which has matured over nearly 10 years of development.},
  archive  = {J},
  author   = {Enrico Mingo Hoffman and Arturo Laurenzi and Nikos G. Tsagarakis},
  doi      = {10.1109/MRA.2024.3487395},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {24-34},
  title    = {The open stack of tasks library: OpenSoT: A software dedicated to hierarchical whole-body control of robots subject to constraints},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and control of the humanoid robot COMAN+: Hardware capabilities and software implementations. <em>MRA</em>, <em>32</em>(1), 12-23. (<a href='https://doi.org/10.1109/MRA.2024.3505773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Despite the prevalence of robots operating within controlled environments, such as industries, recent advancements in both autonomy and human–robot interaction have expanded the potential for their use within a diverse range of scenarios. Research efforts in humanoid robotics aim to develop platforms possessing the requisite versatility and dexterity to mimic human motion. This allows such machines to perform complex tasks alongside humans, while ensuring safety during operations. Following these principles, this article presents the robot COMAN+, focusing on its hardware capabilities and software implementations. COMAN+ is developed by the Humanoid and Human Centered Mechatronics (HHCM) Research Line at Istituto Italiano di Tecnologia: It is a human-sized torque-controlled humanoid assembled with a focus on robustness, reliability, and strength. Its custom-made actuation system and sturdy yet lightweight skeleton make it ideal for working in rough conditions with a high power-to-weight ratio for heavy-duty tasks.},
  archive  = {J},
  author   = {Francesco Ruscelli and Luca Rossini and Enrico Mingo Hoffman and Lorenzo Baccelliere and Arturo Laurenzi and Luca Muratore and Davide Antonucci and Stefano Cordasco and Nikos G. Tsagarakis},
  doi      = {10.1109/MRA.2024.3505773},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  number   = {1},
  pages    = {12-23},
  title    = {Design and control of the humanoid robot COMAN+: Hardware capabilities and software implementations},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Humanoid robotics: Integrating cognitive and physical abilities for human-centered environments [From the guest editors]. <em>MRA</em>, <em>32</em>(1), 8-10. (<a href='https://doi.org/10.1109/MRA.2025.3527820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Oliver Urbann and Fei Chen and Julian Eßer and Robert Griffin and Kenji Hashimoto and Fumio Kanehiro and Paul Oh and Olivier Stasse and Yuichi Tazaki},
  doi     = {10.1109/MRA.2025.3527820},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {8-10},
  title   = {Humanoid robotics: Integrating cognitive and physical abilities for human-centered environments [From the guest editors]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAS publication review process goes double anonymous [President’s message]. <em>MRA</em>, <em>32</em>(1), 6-7. (<a href='https://doi.org/10.1109/MRA.2025.3536956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Aude Billard},
  doi     = {10.1109/MRA.2025.3536956},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {6-7},
  title   = {RAS publication review process goes double anonymous [President’s message]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). We are not there yet: Why is humanoid robotics hard? [From the editor’s desk]. <em>MRA</em>, <em>32</em>(1), 4-5. (<a href='https://doi.org/10.1109/MRA.2025.3527250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Yi Guo},
  doi     = {10.1109/MRA.2025.3527250},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {3},
  number  = {1},
  pages   = {4-5},
  title   = {We are not there yet: Why is humanoid robotics hard? [From the editor’s desk]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
