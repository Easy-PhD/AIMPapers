<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc">TEVC - 161</h2>
<ul>
<li><details>
<summary>
(2025). Brain-inspired multiscale evolutionary neural architecture search for deep spiking neural networks. <em>TEVC</em>, <em>29</em>(5), 2258-2270. (<a href='https://doi.org/10.1109/TEVC.2024.3507812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have been widely applied not only for their advantages in energy efficiency with discrete signal processing but also for their natural suitability to integrate multiscale biological plasticity. However, most SNNs still adopt the structure of the well-established deep neural networks (DNNs), with few attempts at implementing automatic neural architecture search (NAS) for SNNs. The neural motifs topology, modular regional structures, and global cross-brain region connections in the human brain are the product of natural evolution, serving as a perfect reference for designing brain-inspired SNN architecture. Here, we propose an efficient multiscale evolutionary NAS (MSE-NAS) for SNN, simultaneously considering micro-, meso-, and macro-scale brain topologies as the evolutionary search space and is supplemented with customized brain-inspired indirect evaluation (BIE) function, encoding scheme and genetic operations. This is the first instance that the evolutionary characteristics of microconnections and electrophysiological patterns have been incorporated into one single evolutionary framework. The proposal of MSE-NAS proves that the evolutionary structure and mechanism of the human brain can essentially help better handle artificial intelligence tasks, revealing the important value and key role of integrating evolutionary computation (EC) principles in optimizing biologically realistic neural models. Extensive experiments demonstrate that MSE-NAS achieves superior performance with shorter simulation steps on static datasets (CIFAR10 and CIFAR100) and neuromorphic datasets (CIFAR10-DVS and DVS128-Gesture). More importantly, the emergence of general capabilities, such as transferability and robustness brought about by evolution confirms the innovative progress and important value of EC in the field of brain-inspired intelligence.},
  archive      = {J_TEVC},
  author       = {Wenxuan Pan and Feifei Zhao and Guobin Shen and Bing Han and Yi Zeng},
  doi          = {10.1109/TEVC.2024.3507812},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2258-2270},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Brain-inspired multiscale evolutionary neural architecture search for deep spiking neural networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale multiobjective evolutionary quantile estimation model for wind power probabilistic forecasting. <em>TEVC</em>, <em>29</em>(5), 2244-2257. (<a href='https://doi.org/10.1109/TEVC.2024.3486741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term wind power probabilistic forecasting can furnish decision-makers with comprehensive information to enhance management capabilities. Most wind power probabilistic predictions are modeled by multiple training of the pinball loss at a single quantile. However, this modeling leads to two underlying limitations, i.e., traditional probabilistic forecasting models fail to achieve a balance between the accuracy and width and are prone to quantile crossover. This article proposes a novel model called large-scale multiobjective evolutionary quantile estimation (LMOEQE) to obtain high-quality wind power probabilistic estimations. Specifically, for avoiding quantile crossover, a multiquantile regression monotone fuzzy neural network (MQRMFNN) is first proposed to simultaneously output monotonically increasing probability distributions. Then, a multiple loss function framework involving the accuracy, reliability and width is designed. Based on this framework, we regard the training of MQRMFNN as a large-scale multiobjective problem (MOP) to achieve the tradeoff on each metric of the probability distribution. But optimizing large-scale MOP for probabilistic neural network is extremely demanding in terms of efficiency and performance. A large-scale distributed multiobjective competitive swarm optimizer (LDMOCSO) is proposed for solving the constructed large-scale MOP. It implements a distributed competitive update strategy of different states to leverage global information from the decision space, effectively enhancing the convergence speed and diversity. All the methods show the superiority in real-world datasets.},
  archive      = {J_TEVC},
  author       = {Jianhua Zhu and Yaoyao He},
  doi          = {10.1109/TEVC.2024.3486741},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2244-2257},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A large-scale multiobjective evolutionary quantile estimation model for wind power probabilistic forecasting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous multiagent zero-shot coordination by coevolution. <em>TEVC</em>, <em>29</em>(5), 2229-2243. (<a href='https://doi.org/10.1109/TEVC.2024.3485177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multiagent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this article, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three subprocesses: 1) pairing; 2) updating; and 3) selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks. To the best of our knowledge, we are the first to underscore the significance of the heterogeneous ZSC tasks and to introduce an effective framework for addressing it.},
  archive      = {J_TEVC},
  author       = {Ke Xue and Yutong Wang and Cong Guan and Lei Yuan and Haobo Fu and Qiang Fu and Chao Qian and Yang Yu},
  doi          = {10.1109/TEVC.2024.3485177},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2229-2243},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Heterogeneous multiagent zero-shot coordination by coevolution},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary computation and explainable AI: A roadmap to understandable intelligent systems. <em>TEVC</em>, <em>29</em>(5), 2213-2228. (<a href='https://doi.org/10.1109/TEVC.2024.3476443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence methods are being increasingly applied across various domains, but their often opaque nature has raised concerns about accountability and trust. In response, the field of explainable AI (XAI) has emerged to address the need for human-understandable AI systems. Evolutionary computation (EC), a family of powerful optimization and learning algorithms, offers significant potential to contribute to XAI, and vice versa. This article provides an introduction to XAI and reviews current techniques for explaining machine learning (ML) models. We then explore how EC can be leveraged in XAI and examine existing XAI approaches that incorporate EC techniques. Furthermore, we discuss the application of XAI principles within EC itself, investigating how these principles can illuminate the behavior and outcomes of EC algorithms, their (automatic) configuration, and the underlying problem landscapes they optimize. Finally, we discuss open challenges in XAI and highlight opportunities for future research at the intersection of XAI and EC. Our goal is to demonstrate EC’s suitability for addressing current explainability challenges and to encourage further exploration of these methods, ultimately contributing to the development of more understandable and trustworthy ML models and EC algorithms.},
  archive      = {J_TEVC},
  author       = {Ryan Zhou and Jaume Bacardit and Alexander Edward Ian Brownlee and Stefano Cagnoni and Martin Fyvie and Giovanni Iacca and John McCall and Niki van Stein and David Walker and Ting Hu},
  doi          = {10.1109/TEVC.2024.3476443},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2213-2228},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary computation and explainable AI: A roadmap to understandable intelligent systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pareto optimization for fair subset selection: A case study on personalized recommendation. <em>TEVC</em>, <em>29</em>(5), 2198-2212. (<a href='https://doi.org/10.1109/TEVC.2024.3487624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subset selection is a fundamental problem across a wide range of applications. In this study, we explore scenarios where the variables within the original dataset are divided into distinct groups. Subsequently, we investigate an optimization problem that includes extra fairness constraints (i.e., partition matroid constraints), restricting the selection of a specified number of variables from each group, which is known as the fair subset selection (FSS) problem. First, for the case where the existing Pareto optimization algorithms do not have the ability to well handle the fairness constraints, due to they do not consider fairness constraints in the process of solutions generation. In this article, a Pareto Optimization algorithm named POFSS is proposed for FSS, by introducing a designed fairness balance flip operator. Also, we prove that POFSS has the approximation ability of $\max \{ {}[{\alpha }/{l}](1-e^{-\gamma }), {}({\gamma }/{k}), 1-e^{-r\overline {k}/k } \}$ in polynomial time when $ l \lt \log _{2}{n}$ and the probability of mutation is constant $c/n~(c\lt 2)$ and this approximation ratio is no worse than the previous theoretical result ( $\alpha $ , $\gamma $ represent two submodular ratios, and l is the number of disjoint groups). In addition, we apply POFSS to one typical FSS task named personalized recommendation (PR), where an acceleration strategy is designed and the acceleration ratio is strictly proved. Finally, the experimental results on the PR task show the proposed POFSS outperforms the state-of-the-art methods in addressing the FSS.},
  archive      = {J_TEVC},
  author       = {Lei Zhang and Zhanpeng Wang and Haipeng Yang and Xiang Sun and Fan Cheng},
  doi          = {10.1109/TEVC.2024.3487624},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2198-2212},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Pareto optimization for fair subset selection: A case study on personalized recommendation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moral preferences co-evolve with cooperation in networked populations. <em>TEVC</em>, <em>29</em>(5), 2188-2197. (<a href='https://doi.org/10.1109/TEVC.2024.3486572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unravelling the evolution of cooperation is essential for advancing natural and artificial intelligence (AI) systems. Previous studies have investigated the impact of additional incentives, such as reciprocity and reputation, on cooperative behavior. However, a fundamental question persists: under what conditions do moral preferences evolve and does this evolution subsequently promote cooperation in networked populations of agents? To address this question, we propose a comprehensive framework to systematically explore the co-evolution of moral preferences and cooperative behavior in a networked population. In our framework, the population structure is modeled as a network, with nodes corresponding to AI agents. Moral preferences are modeled through a learning algorithm that adheres to social norms. Prosocial and antisocial behaviors lead to rewards or punishments, and learning agents receive morality scores based on their rewarding behavior toward others. Simulation results demonstrate the effectiveness and robustness of the proposed algorithm in a networked population, showcasing faster convergence. We find that moral preferences enhance cooperation as long as the learning rate is moderate, even in the presence of dominant defectors. This surprising finding also holds for cooperation-inhibiting network structures, provided the critical benefit-cost ratio for cooperation is sufficiently high or below average. Interestingly, moral preferences also co-evolve with cooperation in the populations. Our work not only provides new design methodologies for network algorithms, but also highlights the insight that large-scale evolutionary computation can provide for evolutionary biology and emerging AI-agent populations.},
  archive      = {J_TEVC},
  author       = {Hui Wei and Xiandong Pu and Jianlei Zhang and Chunyan Zhang and Ming Cao},
  doi          = {10.1109/TEVC.2024.3486572},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2188-2197},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Moral preferences co-evolve with cooperation in networked populations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A genetic algorithm based on deep Q-learning in optimization of remote sensing data discretization. <em>TEVC</em>, <em>29</em>(5), 2173-2187. (<a href='https://doi.org/10.1109/TEVC.2024.3484968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature discretization can improve the processing efficiency of remote sensing big data. However, the distribution of target attribute values is often difficult to ascertain, and there are complex correlations between features, making it extremely difficult to obtain an optimal discretization scheme for remote sensing data. Although feature discretization methods based on evolutionary models can achieve some considerable results, it is difficult to formulate appropriate strategies without prior knowledge as guidance, which makes searching in multidimensional space inefficient and prone to falling into local optima. Therefore, we propose a Genetic algorithm based on deep Q-learning (DQLGA) to optimize the discretization scheme of remote sensing data. First, we design a state set in the crossover and mutation stages by balancing the global and local search capabilities of genetic operators to obtain an accurate mapping of states in high-dimensional feature space. Then, we simulate the variation pattern of the optimal discretization scheme by analyzing the distribution of all individuals in the population during the evolution process to construct a reasonable adaptive reward function in reinforcement learning model. Finally, we introduce a pair of deep Q-networks with the same structure by treating the calculation of Q-values as a function fitting problem to fulfil an efficient updating of massive Q-values in state transition. We compare DQLGA with state-of-the-art feature discretization methods on remote sensing data. The experimental results indicate that DQLGA significantly improves the search efficiency of feature discretization methods based on evolutionary models, achieving higher-classification accuracy while further reducing the number of breakpoints.},
  archive      = {J_TEVC},
  author       = {Qiong Chen and Weiping Ding},
  doi          = {10.1109/TEVC.2024.3484968},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2173-2187},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A genetic algorithm based on deep Q-learning in optimization of remote sensing data discretization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symbolic regression-assisted offline data-driven evolutionary computation. <em>TEVC</em>, <em>29</em>(5), 2158-2172. (<a href='https://doi.org/10.1109/TEVC.2024.3482326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving optimization problems with expensive or implicit objective functions, evolutionary algorithms (EAs) commonly utilize surrogate models as cost-effective substitutes for evaluation. This category of algorithms is referred to as data-driven EAs (DDEAs). However, when constructing surrogate models, existing studies rely on the hand-crafted model structure, requiring prior knowledge while leading to the suboptimal fitting ability of the model. To address the issue, this article proposes a novel symbolic regression (SR)-assisted EA, namely SR-DDEA. SR-DDEA employs SR to automatically construct the model structure without prior knowledge and obtain accurate surrogates. Specifically, we develop an efficient gene expression programming algorithm to enhance the expressive ability of surrogates, assisted by a queue-based decoding strategy to improve the efficiency of the model calculations. We also employ a clustering-based selective ensemble method to maximize data utilization and obtain diverse models. Experimental findings on commonly employed benchmarks demonstrate that our algorithm surpasses other cutting-edge offline DDEAs on test problems of different scales and a practical aerodynamic airfoil design challenge.},
  archive      = {J_TEVC},
  author       = {Yu-Hong Sun and Ting Huang and Jing-Hui Zhong and Jun Zhang and Yue-Jiao Gong},
  doi          = {10.1109/TEVC.2024.3482326},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2158-2172},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Symbolic regression-assisted offline data-driven evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient large-scale expensive optimization via surrogate-assisted subproblem selection. <em>TEVC</em>, <em>29</em>(5), 2145-2157. (<a href='https://doi.org/10.1109/TEVC.2025.3544449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional large-scale evolutionary algorithms are limited in their ability to solve certain real-world applications with high-dimensional, closed-box, and computationally expensive objectives due to their need for numerous objective evaluations. Surrogate-assisted evolutionary algorithms (SAEAs) have shown effective for expensive closed-box optimization by relying on inexpensive surrogate models. However, large-scale optimization remains challenging for SAEAs due to the exponentially growing search space and the presence of multiple local optima, resulting in difficulty in training a proper model due to the lack of samples. To address these challenges, we propose constructing an initial surrogate model on randomly selected dimensions and calculating a Gaussian distribution for each sampled dimension. The surrogate then provides predictions when perturbing each sampled dimension by sampling from the distribution, enabling the identification of the most important variables for constructing an active subproblem to reduce the search space. A secondary surrogate model, built for the active subproblem, guides the offspring generation and environmental selection for a modified particle swarm optimization algorithm to effectively explores the subspace while escaping local optima in large-scale problems. Experimental results on CEC’2013 and CEC’2010 benchmark problems show that the proposed method outperforms state-of-the-art algorithms in addressing large-scale expensive optimization problems. The efficiency of the proposed method is further verified on CEC’2010 benchmark problems extended to 2000 dimensions.},
  archive      = {J_TEVC},
  author       = {Kaili Zhao and Xilu Wang and Chaoli Sun and Yaochu Jin and Asad Hayat},
  doi          = {10.1109/TEVC.2025.3544449},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2145-2157},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficient large-scale expensive optimization via surrogate-assisted subproblem selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient data-driven framework for detecting infeasible solutions in multiobjective evolutionary bilevel optimization. <em>TEVC</em>, <em>29</em>(5), 2131-2144. (<a href='https://doi.org/10.1109/TEVC.2024.3469156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting infeasible solutions is an important challenge in closed-box multiobjective bilevel optimization (MOBO) due to a lower-level (LL) optimization problem used as a constraint (along with equality and inequality constraints) in an upper-level optimization. In this context, a feasible solution is an optimal solution to the LL problem, typically addressed using evolutionary algorithms (EAs) (or other metaheuristics) for complex scenarios. Since metaheuristics do not guarantee optimality, then infeasible solutions are inherently reported. This article introduces a novel data-driven framework to automatically identify infeasible solutions reported by bilevel EAs (BEA) when addressing any MOBO problem. This framework operates without imposing strong assumptions on objectives or constraints, making it versatile and easy to implement. Besides, our approach uses solutions reported by one or multiple BEAs to detect and eliminate possible infeasible solutions. This approach helps to enhance algorithm comparison by eliminating infeasible solutions before applying existing performance indicators. The framework is successfully applied to several MOBO problems, including two real-world instances from specialized literature, solved by four different BEAs. Results suggest that the proposed framework advances the field of bilevel evolutionary optimization, offering a tool for promoting fair algorithmic comparisons and ensuring solution feasibility without requiring a deep understanding of the problem context.},
  archive      = {J_TEVC},
  author       = {Jesús-Adolfo Mejía-de-Dios and Alejandro Rodríguez-Molina and Efrén Mezura-Montes},
  doi          = {10.1109/TEVC.2024.3469156},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2131-2144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An efficient data-driven framework for detecting infeasible solutions in multiobjective evolutionary bilevel optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multisource knowledge fusion based on graph attention networks for many-task optimization. <em>TEVC</em>, <em>29</em>(5), 2116-2130. (<a href='https://doi.org/10.1109/TEVC.2024.3465542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although knowledge transfer methods are developed for many-task optimization problems, they tend to utilize solutions from a single task for knowledge transfer. Indeed, there are usually multiple relevant source tasks with commonality. Multisource data fusion can capture complementary knowledge of distinct source tasks to better assist the optimization of target tasks. However, biases potentially flow with the interaction between tasks during multisource fusion, resulting in performance degeneration. Thus, how to select multiple relevant source tasks and perform multisource knowledge transfer is challenging. To address these issues, this article proposes a multisource knowledge fusion (MKF) method based on graph attention networks. In MKF, tasks are structured using a relational graph, in which each vertex represents a task and each directed edge from vertex u to v represents that u is a source task of v. Particularly, for each task, multiple source tasks are selected based on the distribution similarity and evolutionary performance. In the graph, local message is passed from source tasks to target tasks using graph attention networks, which automatically learn the adjacency weight of each directed edge and aggregate solutions from multiple source tasks to obtain fused representations for target tasks. These fused representations are adopted to generate new solutions through mutation. In this way, multisource knowledge is fused and transferred according to their importance to the target task. Integrating MKF into differential evolution, a new algorithm named MKF-DE is put forward. Experimental results on GECCO2020MaTOP and CEC2022MaTOP show that MKF-DE outperforms state-of-the-art algorithms on most instances.},
  archive      = {J_TEVC},
  author       = {Yang-Tao Dai and Xiao-Fang Liu and Yongchun Fang and Zhi-Hui Zhan and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3465542},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2116-2130},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multisource knowledge fusion based on graph attention networks for many-task optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A newton method for hausdorff approximations of the pareto front within multiobjective evolutionary algorithms. <em>TEVC</em>, <em>29</em>(5), 2104-2115. (<a href='https://doi.org/10.1109/TEVC.2024.3469373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common goal in evolutionary multiobjective optimization is to find suitable finite-size approximations of the Pareto front of a given multiobjective optimization problem. While many multiobjective evolutionary algorithms (MOEAs) have proven to be very efficient in finding good Pareto front approximations, they may need quite a few resources or may even fail to obtain optimal or nearly optimal approximations. Hereby, optimality is implicitly defined by the chosen performance indicator. In this work, we propose a set-based Newton method for the Hausdorff approximations of the Pareto front to be used within MOEAs. To this end, we first generalize the previously proposed Newton step for the performance indicator to treat constrained problems for general reference sets. To approximate the target Pareto front, we propose a particular strategy for generating the reference set that utilizes the data gathered by the evolutionary algorithm during its run. Finally, we show the benefit of the Newton method as a postprocessing step on several benchmark test functions and different base evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Hao Wang and Angel E. Rodriguez-Fernandez and Lourdes Uribe and André Deutz and Oziel Cortés-Piña and Oliver Schütze},
  doi          = {10.1109/TEVC.2024.3469373},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2104-2115},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A newton method for hausdorff approximations of the pareto front within multiobjective evolutionary algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nearest-better network for fitness landscape analysis of continuous optimization problems. <em>TEVC</em>, <em>29</em>(5), 2089-2103. (<a href='https://doi.org/10.1109/TEVC.2024.3478825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape analysis (FLA) is quite important in evolutionary computation. In this article, we propose a novel FLA method, the nearest-better network (NBN), which uses the nearest-better relationship to simplify the original fitness landscape of continuous optimization problems. We introduce an efficient algorithm to calculate NBN for continuous problems. We also propose four numerical measurements and a 3-D visualization method based on NBN. Experiments show that compared to the other main FLA methods, the four numerical measurements proposed here can effectively measure the four intended features: 1) neutrality; 2) ruggedness; 3) modality; and 4) Basin of Attraction, respectively, and common features of the fitness landscape can be maintained in 3-D NBN visualization, regardless of the scale of the problem. NBN also provides a view of how algorithms search in high-dimensional problems with the help of the 3-D NBN visualization.},
  archive      = {J_TEVC},
  author       = {Yiya Diao and Changhe Li and Sanyou Zeng and Shengxiang Yang and Carlos A. Coello Coello},
  doi          = {10.1109/TEVC.2024.3478825},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2089-2103},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Nearest-better network for fitness landscape analysis of continuous optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective many-tasking evolutionary optimization using diversified gaussian-based knowledge transfer. <em>TEVC</em>, <em>29</em>(5), 2074-2088. (<a href='https://doi.org/10.1109/TEVC.2024.3467048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective multitasking evolutionary algorithms have shown promising performance for tackling a set of multiobjective optimization tasks simultaneously, as the optimization experience gained within one task can be transferred to accelerate the solving of others. However, most studies only select similar transfer tasks based on their designed metrics, which become less efficient when tackling a large number of optimization tasks, as their transferred knowledge may be insufficiently diversified. To alleviate this issue, this article proposes a multiobjective many-tasking evolutionary algorithm (MMaTEA) using Diversified Gaussian-based knowledge Transfer, named MMaTEA-DGT. In this algorithm, a diversified transfer selection strategy is presented to choose a number of similar and complementary source tasks for knowledge transfer. Then, based on the above diversified source tasks, a Gaussian-based transfer strategy is designed to transfer their various optimization knowledge. In this way, MMaTEA-DGT is more effective in transferring optimization knowledge to speed up the solving of many tasks. Experimental studies on both the benchmark suites and a real-world dynamic vaccine prioritization problem have indicated the superiority of MMaTEA-DGT over some recently proposed MMaTEAs.},
  archive      = {J_TEVC},
  author       = {Qiuzhen Lin and Qianhui Wang and Baihao Chen and Yulong Ye and Lijia Ma and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3467048},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2074-2088},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective many-tasking evolutionary optimization using diversified gaussian-based knowledge transfer},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum acceleration of black-box pseudo-boolean optimization algorithms. <em>TEVC</em>, <em>29</em>(5), 2062-2073. (<a href='https://doi.org/10.1109/TEVC.2024.3485194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $(1+1)$ quantum evolutionary algorithm [ $(1+1)$ QEA] uses quantum probability amplification to accelerate the classical $(1+1)$ evolutionary algorithm [ $(1+1)$ EA] for the optimization of pseudo-Boolean functions, which assign real-valued fitness to binary strings. However, determining the optimal mutation rate remains crucial to reducing the required number of function evaluations. To address this, we introduce a dynamic mutation rate strategy for the $(1+1)$ QEA, leveraging the guarantees the fixed-point amplitude amplification algorithm gives to adjust the mutation rate dynamically [ $(1+1)$ QEAdyn]. We derive upper bounds on the number of fitness evaluations the strategy requires to solve well-known benchmark functions. Notably, we close the performance gap of the $(1+1)$ QEA on the NEEDLE problem, matching the optimal performance possible in the quantum setting. Nevertheless, our results on ONEMAX and LEADINGONES lag behind known classical results. So, we delve into quantum black-box complexity, exploring the difficulty of problem-solving on a quantum computer without explicit problem knowledge. We introduce a quantum algorithm that solves the $n$ -dimensional LEADINGONES problem with at most $n$ evaluations. Additionally, we develop a quantum algorithm for the ONEMAX problem, requiring only one function evaluation. Both of these quantum algorithms surpass the capabilities of classical algorithms. Finally, we devise a quantum algorithm for solving the ONEMAX problem using only fitness comparisons and provide computational evidence that it still does so faster than any classical algorithm.},
  archive      = {J_TEVC},
  author       = {Adetunji David Ajimakin and V. Susheela Devi},
  doi          = {10.1109/TEVC.2024.3485194},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2062-2073},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Quantum acceleration of black-box pseudo-boolean optimization algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diversity-enhanced tri-stage framework for constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 2047-2061. (<a href='https://doi.org/10.1109/TEVC.2024.3458079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving a tradeoff between convergence, feasibility, and diversity is critical for solving constrained multiobjective optimization problems (CMOPs). Existing constrained multiobjective evolutionary algorithms (CMOEAs) primarily focus on constraint-handling techniques to balance constraint satisfaction and objective optimization. However, individual diversity is generally considered to be low. Owing to the insufficient enhancement of diversity, CMOEAs are unable to disperse well in the objective space to enhance the search for the constrained Pareto front (CPF) when handling CMOPs with complex constraints. To address this limitation, this study develops a diversity-enhanced tri-stage framework with three different evolutionary stages. First, sufficient convergence is enabled to move the population across the infeasible regions. Afterward, an angle-domination strategy is designed, aiming to spread the population evenly in the objective space while maintaining the achieved convergence. Third, we propose a minimum neighborhood-based domination strategy to ensure that the population searches the CPF by pursuing an even distribution in the objective space. Moreover, a weight vector preselection strategy is proposed to reduce computational overhead by avoiding ineffective searches in regions that do not include the CPF. Extensive experiments with 48 benchmark instances and 25 real-world instances validate the effectiveness of our approach over nine state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Yubo Wang and Chengyu Hu and Fei Ming and Yanchi Li and Wenyin Gong and Liang Gao},
  doi          = {10.1109/TEVC.2024.3458079},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2047-2061},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A diversity-enhanced tri-stage framework for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated and interpretable computer-aided approach for skin cancer diagnosis using genetic programming. <em>TEVC</em>, <em>29</em>(5), 2032-2046. (<a href='https://doi.org/10.1109/TEVC.2024.3459096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant melanoma is a very deadly form of skin cancer and early diagnosis can significantly reduce the mortality rate. Many computer-aided diagnosis (CAD) systems have been developed as second opinion diagnostic aids to assist dermatologists in diagnosing malignant melanoma. However, traditional CAD systems often require domain knowledge for feature extraction, while neural network-based CAD systems require specialized knowledge for designing network structures and often have poor interpretability. In this article, we propose a new skin cancer CAD system based on genetic programming (GP) to automatically learn effective features for classification with strong interpretability. The approach can automatically evolve variable-length models to extract informative features for describing skin cancer images based on a relatively simple program structure, a new function set, and a terminal set. In addition, compared with other GP methods, this approach employs a newly proposed duplicate subtree removing mechanism, which can effectively prevent the duplication of features, thereby simplifying the model and enhancing its interpretability. The proposed approach has been examined on five real-world skin cancer classification tasks. The results suggest that the proposed approach achieves better performance than GP-based, neural network-based feature learning comparison methods and traditional comparison methods in most cases. Further analysis shows that the proposed approach has employed a smaller tree structure and can automatically evolve/learn models with potentially high interpretability.},
  archive      = {J_TEVC},
  author       = {Kunjie Yu and Jintao Lian and Ying Bi and Jing Liang and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3459096},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2032-2046},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An automated and interpretable computer-aided approach for skin cancer diagnosis using genetic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding ϵ-locally optimal solutions for multiobjective multimodal optimization. <em>TEVC</em>, <em>29</em>(5), 2019-2031. (<a href='https://doi.org/10.1109/TEVC.2024.3458855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the problem of computing all locally optimal solutions of a given multiobjective problem whose images are sufficiently close to the Pareto front. Such $\epsilon $ -locally optimal solutions are particularly interesting in the context of multiobjective multimodal optimization (MMO). To accomplish this task, we first define a new set of interest, $L_{Q,\epsilon }$ , that is strongly related to the recently proposed set of $\epsilon $ -acceptable solutions. Next, we propose a new unbounded archiver, $ArchiveUpdateL_{Q,\epsilon }$ , aiming to capture $L_{Q,\epsilon }$ in the limit. This archiver can in principle be used in combination with any multiobjective evolutionary algorithm (MOEA). Further, we equip numerous MOEAs with $ArchiveUpdateL_{Q,\epsilon }$ , investigate their performances across several benchmark functions, and compare the enhanced MOEAs with their archive-free counterparts. For our experiments, we utilize the well-established metrics HV, IGDX, and $\Delta _{p}$ . Additionally, we propose and use a new performance indicator, $I_{\mathrm { EDR}}$ , which results in comparable performances but which is applicable to problems defined in higher dimensions (in particular in decision variable space).},
  archive      = {J_TEVC},
  author       = {Angel E. Rodriguez-Fernandez and Lennart Schäpermeier and Carlos Hernández and Pascal Kerschke and Heike Trautmann and Oliver Schütze},
  doi          = {10.1109/TEVC.2024.3458855},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2019-2031},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Finding ϵ-locally optimal solutions for multiobjective multimodal optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated metaheuristic algorithm design with autoregressive learning. <em>TEVC</em>, <em>29</em>(5), 2004-2018. (<a href='https://doi.org/10.1109/TEVC.2024.3464677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated design of metaheuristic algorithms offers an attractive avenue to reduce human effort and gain enhanced performance beyond human intuition. Current automated methods design algorithms within a fixed structure and operate from scratch. This poses a clear gap toward fully discovering potentials over the metaheuristic family and fertilizing from prior design experience. To bridge the gap, this article proposes an autoregressive learning-based designer for automated design of metaheuristic algorithms. Our designer formulates metaheuristic algorithm design as a sequence generation task, and harnesses an autoregressive generative network to handle the task. This offers two advances. First, through autoregressive inference, the designer generates algorithms with diverse lengths and structures, enabling to fully discover potentials over the metaheuristic family. Second, prior design knowledge learned and accumulated in neurons of the designer can be retrieved for designing algorithms for future problems, paving the way to continual design of algorithms for open-ended problem solving. Extensive experiments on numeral benchmarks and real-world problems reveal that the proposed designer generates algorithms that outperform all human-created baselines on 24 out of 25 test problems. The generated algorithms display various structures and behaviors, reasonably fitting for different problem-solving contexts. Code is available at https://github.com/auto4opt/ALDes.},
  archive      = {J_TEVC},
  author       = {Qi Zhao and Tengfei Liu and Bai Yan and Qiqi Duan and Jian Yang and Yuhui Shi},
  doi          = {10.1109/TEVC.2024.3464677},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {2004-2018},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Automated metaheuristic algorithm design with autoregressive learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal knowledge transfer for dynamic constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1990-2003. (<a href='https://doi.org/10.1109/TEVC.2024.3449142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic constrained multiobjective optimization problems (DCMOPs) are characterized by multiple conflicting optimization objectives and constraints that vary over time. The presence of both dynamism and constraints underscores the importance of preserving population diversity. This diversity is essential not only to escape local optima following environmental changes but also to climb infeasible barriers to approach feasible regions. However, existing constraint-handling techniques for enhancing solution feasibility could steer infeasible solutions toward partially feasible regions, potentially resulting in the loss of diversity. To maintain both diversity and feasibility, this work establishes two synergistic tasks: one task concentrates on exploring the unconstrained search space to preserve diversity, while the other delves into searching the constrained search space to prioritize feasibility. Particularly, in light of evolutionary transfer optimization, two knowledge transfer modules, i.e., the spatial knowledge transfer module and temporal knowledge transfer module are designed. The spatial knowledge transfer module facilitates knowledge transfer between the constrained and unconstrained search spaces to accelerate the exploration of both spaces. On the other hand, the temporal transfer module leverages historical knowledge to enhance search efficiency within the new environment. To advance the test suite toward real-world cases, we designed fourteen test problems with various properties. Experiments conducted on the proposed test problems and a real-world problem have demonstrated the efficacy of our proposed algorithm.},
  archive      = {J_TEVC},
  author       = {Zhenzhong Wang and Dejun Xu and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3449142},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1990-2003},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Spatial-temporal knowledge transfer for dynamic constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical analysis of explicit averaging and novel sign averaging in comparison-based search. <em>TEVC</em>, <em>29</em>(5), 1976-1989. (<a href='https://doi.org/10.1109/TEVC.2024.3465392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In black-box optimization, noise in the objective function is often inevitable. Noise disrupts the ranking of candidate solutions in comparison-based optimization, possibly deteriorating the search performance compared with a noiseless scenario. Explicit averaging takes the sample average of noisy objective function values and is widely used as a simple and versatile noise-handling technique. Although it is suitable for various applications, it is ineffective if the mean is not finite. We theoretically reveal that explicit averaging has a negative effect on the estimation of ground-truth rankings when assuming stably distributed noise without a finite mean. Alternatively, sign averaging (SA) is proposed as a simple but robust noise-handling technique. We theoretically prove that SA estimates the order of the medians of the noisy objective function values for a pair of points with arbitrarily high probability as the number of samples increases. Its advantages over explicit averaging and its robustness are also confirmed through numerical experiments.},
  archive      = {J_TEVC},
  author       = {Daiki Morinaga and Youhei Akimoto},
  doi          = {10.1109/TEVC.2024.3465392},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1976-1989},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Theoretical analysis of explicit averaging and novel sign averaging in comparison-based search},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact calculation of inverted generational distance. <em>TEVC</em>, <em>29</em>(5), 1966-1975. (<a href='https://doi.org/10.1109/TEVC.2024.3442920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverted generational distance (IGD) is an important performance indicator in the field of multiobjective optimization (MOO). Although it has been widely used for decades, applying IGD for fair and accurate performance evaluation remains challenging, with the biggest obstacle being the selection of the reference set. IGD generally represents the distance between the solution set and the Pareto front (PF). Since the real PF is often an infinite set, even if it is known, it is difficult to apply it directly to the calculation of IGD. As a workaround, past research typically samples a finite set, i.e., the reference set, from the PF as an approximation, indirectly used in the IGD calculation. This inevitably introduces a systematic error, which we refer to as discretization error. In this article, we prove an upper bound for the discretization error, demonstrating that if the reference set is sufficiently dense and uniformly distributed on the entire PF, the discretization error will converge to zero. Additionally, we propose a numerical method for the exact calculation of IGD and IGD+. When the analytical expression of the PF is known, this method allows for the direct calculation of IGD and IGD+ using the real PF, thus avoiding discretization error.},
  archive      = {J_TEVC},
  author       = {Zihan Wang and Chunyun Xiao and Aimin Zhou},
  doi          = {10.1109/TEVC.2024.3442920},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1966-1975},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exact calculation of inverted generational distance},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer task-averaged natural gradient for efficient many-task optimization. <em>TEVC</em>, <em>29</em>(5), 1952-1965. (<a href='https://doi.org/10.1109/TEVC.2024.3459862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing requirement for computational efficiency in evolutionary algorithms (EAs) when tackling many optimization tasks concurrently, many-task optimization (MaTO) has gained much attention in recent years. It involves extracting and transferring the knowledge from successful search experiences across many tasks. As the number of tasks and variable scale grows in MaTO, the need for efficient knowledge transfer in EAs becomes indispensable. In this article, we present a task-averaged natural gradient-assisted natural evolution strategy (TNG-NES) to deal with MaTO efficiently. The task-averaged natural gradient (TNG) captures how a group of task distributions evolves, considering their overall trends of mean and covariance. This can accelerate the optimization process across all tasks by leveraging the evolutionary similarities among multiple task search distributions. Notably, TNG-NES exhibits linear computational complexity concerning the number of tasks for knowledge transfer. Additionally, to adaptively utilize TNG for distribution evolution and mitigate negative transfer, we introduce a transfer adaptive control mechanism for TNG-NES. We conducted extensive experiments on CEC19-MaTO, WCCI22-MaTO, our proposed large-scale MaTO benchmark suite, and real-world applications. The results validate the effectiveness of TNG-NES, outperforming state-of-the-art MaTO algorithms.},
  archive      = {J_TEVC},
  author       = {Yanchi Li and Wenyin Gong and Qiong Gu},
  doi          = {10.1109/TEVC.2024.3459862},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1952-1965},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Transfer task-averaged natural gradient for efficient many-task optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive multistrategy algorithm based on extent of environmental change for dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1937-1951. (<a href='https://doi.org/10.1109/TEVC.2024.3441827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most obvious characteristic of dynamic multiobjective optimization problems (DMOPs) is the time-varying Pareto-optimal set (POS) or/and Pareto-optimal front (POF). This kind of problem poses a higher challenge to the evolutionary algorithms, as it requires populations to rapidly track and converge the updated POF in new environments. Differing from the superposition of several strategies in the literatures, we propose an adaptive multistrategy algorithm based on the extent of environmental change, called AMEEC to effectively handle various dynamic changes. AMEEC chooses the corresponding strategies for different environmental changes adaptively. When the environment changes moderately or similarly, the prediction based on the clustered center points, POS manifold prediction, and generation of random solutions based on the ideal points are employed to relocate the population individuals in the new environment. Otherwise, the trend prediction model is employed to predict the knee points of each part and the center points of each cluster, and to adaptively adjust the area of random solutions based on the ideal and nadir points focuses on enhancing the diversity of population members. The proposed AMEEC is tested comprehensively on 19 benchmark problems compared with the six state-of-the-art algorithms. All algorithms use RM-MEDA (a regularity model-based multiobjective estimation of distribution algorithm) as a static optimizer. The experimental results demonstrate that AMEEC can achieve good convergence, diversity, and distribution, and is more competitive in dealing with the dynamic problems.},
  archive      = {J_TEVC},
  author       = {Yong Wang and Kuichao Li and Gai-Ge Wang},
  doi          = {10.1109/TEVC.2024.3441827},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1937-1951},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An adaptive multistrategy algorithm based on extent of environmental change for dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memetic algorithm for vehicle routing with simultaneous pickup and delivery and time windows. <em>TEVC</em>, <em>29</em>(5), 1924-1936. (<a href='https://doi.org/10.1109/TEVC.2024.3456585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vehicle routing problem with simultaneous pickup and delivery and time windows (VRPSPDTW) has a number of real-world applications, especially in reverse logistics. In this work, we propose an effective memetic algorithm that integrates a lightweight feasible and infeasible route descent search and a learning-based adaptive route-inheritance crossover to solve this complex problem. We evaluate the effectiveness of the proposed algorithm on the set of 65 popular benchmark instances as well as 20 real-world large-scale benchmark instances. We provide a comprehensive analysis to better understand the design and performance of the proposed algorithm.},
  archive      = {J_TEVC},
  author       = {Zhenyu Lei and Jin-Kao Hao},
  doi          = {10.1109/TEVC.2024.3456585},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1924-1936},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A memetic algorithm for vehicle routing with simultaneous pickup and delivery and time windows},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple yet effective greedy evolutionary strategy for RNA design. <em>TEVC</em>, <em>29</em>(5), 1913-1923. (<a href='https://doi.org/10.1109/TEVC.2024.3461509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ribonucleic acid (RNA) design, also known as the RNA inverse folding problem, involves discovering a nucleotide sequence that folds into a target structure. This problem has been addressed from a wide number of approaches, improving the ability to solve it in a reasonable time over time. Despite all these efforts, today no method has completely solved the problem. We present GREED-RNA, a new RNA design algorithm, based on a simple greedy evolutionary strategy. The main feature is the use of several objective functions (base-pair distance, Hamming distance, probability over ensemble, partition function, ensemble defect, and GC-content) to select the best solution in each iteration, changing their weight according to the problem-solving conditions. The performance of GREED-RNA was tested using the Eterna100 benchmark, widely used in this area and never fully solved by any method. In addition, a comparative analysis against several published RNA design methods considering three metrics (solved structures, success rate, and execution time), allowed us to verify that GREED-RNA performs better than previously developed methods, thus successfully improving the current ability to solve this problem. This tool also allows users to select a range within which the GC-content of the solution sequences must fall. Source code and results are available at https://github.com/iARN-unex/GREED-RNA.},
  archive      = {J_TEVC},
  author       = {Nuria Lozano-García and Álvaro Rubio-Largo and José Maria Granado-Criado},
  doi          = {10.1109/TEVC.2024.3461509},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1913-1923},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A simple yet effective greedy evolutionary strategy for RNA design},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knee detection in bayesian multiobjective optimization using thompson sampling. <em>TEVC</em>, <em>29</em>(5), 1903-1912. (<a href='https://doi.org/10.1109/TEVC.2024.3455420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world problems often consist of multiple conflicting objectives to be optimized simultaneously, featuring a set of Pareto-optimal solutions. Estimating the entire Pareto front can be computationally expensive, and is not always necessary, as decision makers (DMs) will likely be interested only in specific regions of the Pareto front. In the absence of knowledge about the DM preferences, the so-called knees in the Pareto front are considered to be particularly attractive. In this article, we propose using Thompson sampling in the Bayesian optimization framework to estimate the location of the knee regions in a data-efficient manner. Our experimental results show that the proposed methods accurately locate the knee regions after a very small number of evaluations, providing a computationally efficient approach to single- and multiknee detection in multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Arash Heidari and Jixiang Qing and Sebastian Rojas Gonzalez and Juergen Branke and Tom Dhaene and Ivo Couckuyt},
  doi          = {10.1109/TEVC.2024.3455420},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1903-1912},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knee detection in bayesian multiobjective optimization using thompson sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A streaming feature selection method based on dynamic feature clustering and particle swarm optimization. <em>TEVC</em>, <em>29</em>(5), 1888-1902. (<a href='https://doi.org/10.1109/TEVC.2024.3451688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is an effective data preprocessing technique. In some practical applications, features may continuously arrive one by one or by groups, and we cannot know the exact number of features before learning. Streaming FS (SFS) aims to remove redundant and irrelevant features from the continuously arriving features. This article proposes a three-stage SFS method based on dynamic feature clustering and particle swarm optimization (SFS-DPSO). In the first stage, an online relevance analysis is utilized to quickly remove irrelevant features, reducing the size of newly arrived feature groups. In the second stage, a dynamic feature clustering technique is employed to divide redundant features into different groups, thereby reducing the search space for subsequent evolutionary algorithms. In the third stage, a historical information-driven integer particle swarm optimization algorithm is exploited to search for optimal feature subset in the clustered feature space. The proposed algorithm is applied in 12 typical datasets with different difficulty levels and a real-word case, experimental results show that it can achieve better-classification results in a reasonable time and is superior to most existing algorithms.},
  archive      = {J_TEVC},
  author       = {Xianfang Song and Hao Ma and Yong Zhang and Dunwei Gong and Yinan Guo and Ying Hu},
  doi          = {10.1109/TEVC.2024.3451688},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1888-1902},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A streaming feature selection method based on dynamic feature clustering and particle swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-to-few decomposition: Linking r2-based and decomposition-based multiobjective efficient global optimization algorithms. <em>TEVC</em>, <em>29</em>(5), 1873-1887. (<a href='https://doi.org/10.1109/TEVC.2024.3434511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiobjective optimization, the R2 indicator is widely used for designing the indicator-based algorithms, and the Tchebycheff approach is commonly employed in the decomposition-based algorithms. Despite their wide use, the connection between these two different paradigms is still not well understood, particularly in the field of multiobjective efficient global optimization (MOEGO). Considering that expected improvement (EI) is a cornerstone in efficient global optimization (EGO), this article first studies the relationship between R2-based EI and Tchebycheff-based EI. Then, we introduce a many-to-few (M2F) decomposition framework, offering a new perspective for linking the R2-based method and the Tchebycheff decomposition approach. By incorporating M2F decomposition into MOEGO, a new algorithm called R2/D-EGO is proposed. At each iteration, R2/D-EGO utilizes the Tchebycheff decomposition paradigm to generate a set of candidate solutions, each one corresponding to a different weight vector. Subsequently, a subset of query points is selected from the candidates based on the lower bound of R2-based EI. Empirical results indicate that the proposed R2/D-EGO is highly competitive in comparison with both the R2-based and decomposition-based MOEGO algorithms in the parallel (or batch) setting.},
  archive      = {J_TEVC},
  author       = {Liang Zhao and Xiaobin Huang and Chao Qian and Qingfu Zhang},
  doi          = {10.1109/TEVC.2024.3434511},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1873-1887},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Many-to-few decomposition: Linking r2-based and decomposition-based multiobjective efficient global optimization algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The runtime of randomized local search on the generalized needle problem. <em>TEVC</em>, <em>29</em>(5), 1864-1872. (<a href='https://doi.org/10.1109/TEVC.2024.3453776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In their recent work, Doerr and Krejca (IEEE Transactions on Evolutionary Computation, 2023) proved upper bounds on the expected runtime of the randomized local search (RLS) heuristic on generalized Needle functions. Based on these upper bounds, they deduce in a not fully rigorous manner a drastic influence of the needle radius k on the runtime. In this short article, we add the missing lower bound necessary to determine the influence of parameter k on the runtime. To this aim, we derive an exact description of the expected runtime, which also significantly improves the upper bound given by Doerr and Krejca. We also describe asymptotic estimates of the expected runtime.},
  archive      = {J_TEVC},
  author       = {Benjamin Doerr and Andrew Kelley},
  doi          = {10.1109/TEVC.2024.3453776},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1864-1872},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {The runtime of randomized local search on the generalized needle problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probe population-based initialization and genetic pool-based reproduction for evolutionary bi-objective feature selection. <em>TEVC</em>, <em>29</em>(5), 1849-1863. (<a href='https://doi.org/10.1109/TEVC.2024.3403655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection can be treated as a bi-objective optimization problem, if aimed at minimizing both classification error and number of selected features, suitable for multiobjective evolutionary algorithms (MOEAs) to solve. However, traditional MOEAs would encounter setbacks when the number of features explodes to high dimensionality, causing difficulties for searching optimal solutions in large-scale decision space. In this article, we propose two general methods applicable to integrate with the existing MOEA frameworks in addressing bi-objective feature selection, especially for the high-dimensional datasets. One based on probe populations for improving initialization is called probe population-based initialization (PPI), and the other based on genetic pools for improving reproduction is called genetic pool-based reproduction (GPR), both aimed at boosting the search ability of MOEAs. Tested on 20 datasets, in terms of four performance metrics (including the computational time), the experimental section can be divided into three parts. First, five state-of-the-art MOEAs are used as baseline algorithms to integrate with PPI and GPR, while the integrated versions are then compared with their own baselines. Second, the PPI method is additionally compared with the three representative feature selection initialization methods to further identify its advantages. Third, a complete PPI and GPR-based MOEA (termed PGMOEA) is proposed to compare with the three cutting-edge evolutionary feature selection algorithms to further position its search ability. In general, it is suggested from the empirical results that either PPI or GPR can significantly improve the overall performance of each integrated MOEA, while adopting both of them takes the most complementary effect.},
  archive      = {J_TEVC},
  author       = {Hang Xu and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3403655},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1849-1863},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Probe population-based initialization and genetic pool-based reproduction for evolutionary bi-objective feature selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to evolve with guiding solutions generated by generative adversarial network. <em>TEVC</em>, <em>29</em>(5), 1834-1848. (<a href='https://doi.org/10.1109/TEVC.2024.3437762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many search strategies have been designed to generate a promising offspring population for efficiently solving large-scale multiobjective optimization problems (LSMOPs). The effectiveness of existing search strategies relies on the quality of good parent solutions. However, especially in early generations, the current population does not always include high-quality solutions. This article proposes a generative adversarial network (GAN)-guided search (G2S) strategy for learning to evolve with guiding solutions. Its main idea is to employ GAN for mapping a set of guiding points in the objective space with good convergence and diversity back to the decision space to guide evolution. Specifically, the current population is used as real data, and the guiding points consisting of nondominated solutions and reference vectors are used as virtual data. The trained GAN generates guiding solutions in the decision space to guide the population to evolve efficiently. A large-scale multiobjective evolutionary framework using G2S is also proposed which can be embedded into multiobjective evolutionary algorithms (MOEAs) to improve their ability to handle LSMOPs. Experimental studies on several benchmark problems with the highest-5000-D decision space show that the proposed G2S is competitive compared with the state-of-the-art algorithms and has impressive efficiency as the component to improve the performance of MOEAs for solving LSMOPs.},
  archive      = {J_TEVC},
  author       = {Hongwei Ge and Zhi Zheng and Yaqing Hou and Xia Wang and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2024.3437762},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1834-1848},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning to evolve with guiding solutions generated by generative adversarial network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic multiobjective optimization algorithm guided by recurrent neural network. <em>TEVC</em>, <em>29</em>(5), 1820-1833. (<a href='https://doi.org/10.1109/TEVC.2024.3419892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, prediction-based algorithms have attracted much attention for solving dynamic multiobjective optimization (DMO) problems in the evolutionary computing community. However, this class of algorithms still has potential for further improvements by enhancing the historical information extraction approach to balance convergence and diversity. In this article, we propose a DMO algorithm based on a recurrent neural network (RNN) to balance the population’s convergence and diversity in dynamic environments. The RNN model in the proposed algorithm employs online learning in order to constantly improve according to the increasing evolutionary information. Meanwhile, differing from most existing prediction-based algorithms, the learning machine is not limited by assumptions, such as linear or nonlinear correlation, when it predicts new solutions for future evolutionary environments. Besides, an auxiliary strategy is performed, which adaptively introduces the random or mutated solutions according to the error losses between the prediction solutions and the optimal solutions in the whole optimization process. The experimental results show that the proposed algorithm is more effective for handling DMO problems than several recent algorithms.},
  archive      = {J_TEVC},
  author       = {Yaru Hu and Junwei Ou and Ponnuthurai Nagaratnam Suganthan and Witold Pedrycz and Rui Wang and Jinhua Zheng and Juan Zou and Yanjie Song},
  doi          = {10.1109/TEVC.2024.3419892},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1820-1833},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dynamic multiobjective optimization algorithm guided by recurrent neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a population sizing model for evolution strategies in multimodal landscapes. <em>TEVC</em>, <em>29</em>(5), 1807-1819. (<a href='https://doi.org/10.1109/TEVC.2024.3419931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article derives a population sizing model for standard evolution strategies (ES) in highly multimodal fitness landscapes with exponentially many local optima. The Rastrigin, Bohachevsky, and Ackley test functions are considered. Due to the highly nonconvex structure of these functions a detailed analytical description of the behavior of the ES is a challenge. Therefore, a model is derived that simplifies the complex structure of the functions under consideration. The main idea of this model is the interpretation of local landscape oscillations as frozen noise. This allows for an estimation of the success probability of the ES converging to the global optimum and in turn an estimation of the population size required. It is shown that the population size scales usually sublinearly with the search space dimension N. For the Rastrigin and Bohachevsky function, the population size scales with ${\mathcal {O}}(\sqrt {N} \ln (N))$ . As for Ackley, the scaling behavior depends strongly on the initial values. If the algorithm starts in a certain vicinity of the global optimizer, the dependence on the dimension N is rather weak. However, if the initial value exceeds a certain distance R to the optimizer, the population size scales exponentially with R.},
  archive      = {J_TEVC},
  author       = {Lisa Schönenberger and Hans-Georg Beyer},
  doi          = {10.1109/TEVC.2024.3419931},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1807-1819},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {On a population sizing model for evolution strategies in multimodal landscapes},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-assisted bi-population evolutionary algorithm for distributed flexible job-shop scheduling with maintenance decisions. <em>TEVC</em>, <em>29</em>(5), 1795-1806. (<a href='https://doi.org/10.1109/TEVC.2024.3400043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the post-pandemic era, more manufacturers have expedited the shift from centralized to distributed manufacturing to enhance supply chain resilience. Along with this, the distributed shop floor scheduling problem has attracted much attention from academia, one of which is the distributed flexible job-shop scheduling problem (DFJSP). Nonetheless, the majority of research on DFJSPs overlooks crucial real-world necessities, such as multiobjective decision making and preventive maintenance (PM). Thus, this article suggests a multiobjective DFJSP with PM (DFJSP/PM) as a new variant of the DFJSP. The aim is to achieve a tradeoff between production and maintenance to minimize the makespan, maintenance cost, and energy consumption. To this end, we establish a mathematical model and then customize a learning-assisted bi-population evolutionary algorithm (LBPEA) to solve it. In LBPEA, a novel encoding mechanism is proposed to initialize the population randomly. Then, a neighborhood search heuristic is designed to enhance the population’s quality. To balance the convergence and diversity of the population, a bi-population evolution idea is introduced during the environmental selection. Besides, a two-stage local search (LS) process is adaptively triggered to balance the allocation of computational resources between exploration and exploitation. At the first stage, a reinforcement learning mechanism is employed to intelligently select LS operators to adjust either the operations’ sequence or assignment to different factories and machines, while the second stage is to adjust the number and placement of maintenance decisions. Experimental results show that LBPEA has excellent performance in terms of convergence and diversity when solving the proposed multiobjective DFJSP/PM.},
  archive      = {J_TEVC},
  author       = {Qi Yan and Hongfeng Wang and Shengxiang Yang},
  doi          = {10.1109/TEVC.2024.3400043},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1795-1806},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A learning-assisted bi-population evolutionary algorithm for distributed flexible job-shop scheduling with maintenance decisions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact and deep Q-network assisted swarm intelligence methods for scheduling multiobjective heterogeneous unmanned surface vehicles. <em>TEVC</em>, <em>29</em>(5), 1783-1794. (<a href='https://doi.org/10.1109/TEVC.2024.3415368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex navigational environments, effective unmanned surface vehicle (USV) scheduling is critical. However, the obstacle avoidance problems are often ignored in the literature. This study addresses the multiobjective heterogeneous USV scheduling problems with obstacle avoidance. The objective is to minimize the maximum completion time and total carbon emissions. First, a mathematical model is developed to describe the concerned problems. Second, an A* algorithm is employed to obtain a path between task points with avoiding obstacles. Third, to obtain a high-quality scheduling scheme, an improved artificial bee colony (ABC) algorithm with deep Q-network (DQN) is designed. According to the problem nature, six novel rules are designed for finding high-quality solutions in initialized population. Five local search strategies are designed based on the structure of solution space. The scales of the instances and different objectives are utilized to designed a DQN, which recommends suitable local search strategies during iterations for improving convergence speed. Then, the Gurobi solver is employed to verify the proposed model. The effectiveness of the proposed strategies is verified by 13 instances with different scales. Finally, the experimental results and discussions show that the designed ABC with DQN has the strongest competitiveness among all compared algorithms.},
  archive      = {J_TEVC},
  author       = {Hui Yu and Kaizhou Gao and Zhenfang Ma and Ling Wang},
  doi          = {10.1109/TEVC.2024.3415368},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1783-1794},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exact and deep Q-network assisted swarm intelligence methods for scheduling multiobjective heterogeneous unmanned surface vehicles},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using the empirical attainment function for analyzing single-objective black-box optimization algorithms. <em>TEVC</em>, <em>29</em>(5), 1774-1782. (<a href='https://doi.org/10.1109/TEVC.2024.3462758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A widely accepted way to assess the performance of iterative black-box optimizers is to analyze their empirical cumulative distribution function (ECDF) of predefined quality targets achieved not later than a given runtime. In this work, we consider an alternative approach, based on the empirical attainment function (EAF) and we show that the target-based ECDF is an approximation of the EAF. We argue that the EAF has several advantages over the target-based ECDF. In particular, it does not require defining a priori quality targets per function, captures performance differences more precisely, and enables the use of additional summary statistics that enrich the analysis. We also show that the average area over the convergence curves is a simpler-to-calculate, but equivalent, measure of anytime performance. To facilitate the accessibility of the EAF, we integrate a module to compute it into the IOHanalyzer platform. Finally, we illustrate the use of the EAF via synthetic examples and via the data available for the black-box optimization benchmark suite.},
  archive      = {J_TEVC},
  author       = {Manuel López-Ibáñez and Diederick Vermetten and Johann Dreo and Carola Doerr},
  doi          = {10.1109/TEVC.2024.3462758},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1774-1782},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Using the empirical attainment function for analyzing single-objective black-box optimization algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community opinion maximization in social networks. <em>TEVC</em>, <em>29</em>(5), 1760-1773. (<a href='https://doi.org/10.1109/TEVC.2024.3431608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing the influence of opinions is an emerging research topic in social networks. Although the community is a key structure of social networks, little effort has been made to investigate how to maximize the influence of opinions on all communities. This article proposes a systematic approach to address this issue. First, we construct a multifaceted opinion evolution (MFOE) model with three critical influence factors, namely, individuals, neighbors, and communities, to describe the opinion evolution process in social networks. The convergence analysis confirms its ability to reveal the influence of opinions. Then, we define the overall community opinion to measure the influence of opinions on all communities and employ it as the objective function to formulate an optimization problem called community opinion maximization (COM). We show that the COM problem is NP-hard. To optimize this problem, a memetic algorithm with three problem-specific schemes is developed and termed MACOM. Extensive experimental studies on real-world social networks demonstrate the plausibility of the MFOE model and the effectiveness of MACOM.},
  archive      = {J_TEVC},
  author       = {Yilu Liu and Qingfu Zhang and Zhenkun Wang},
  doi          = {10.1109/TEVC.2024.3431608},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1760-1773},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Community opinion maximization in social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving equation learner for symbolic regression. <em>TEVC</em>, <em>29</em>(5), 1745-1759. (<a href='https://doi.org/10.1109/TEVC.2024.3404650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic regression, a multifaceted optimization challenge involving the refinement of both structural components and coefficients, has gained significant research interest in recent years. The equation learner (EQL), a neural network designed to optimize both equation structure and coefficients through gradient-based optimization algorithms, has emerged as an important topic of concern within this field. Thus far, several variations of EQL have been introduced. Nevertheless, these existing EQL methodologies suffer from a fundamental constraint that they necessitate a predefined network structure. This limitation imposes constraints on the complexity of equations and makes them ill-suited for high-dimensional or high-order problem domains. To tackle the aforementioned shortcomings, we present a novel approach known as the evolving EQL (eEQL). eEQL introduces a unique network structure characterized by automatically defined functions (ADFs). This new architectural design allows for dynamic adaptations of the network structure. Moreover, by engaging in self-learning and self-evolution during the search process, eEQL facilitates the generation of intricate, high-order, and constructive subfunctions. This enhancement can improve the accuracy and efficiency of the algorithm. To evaluate its performance, the proposed eEQL method has been tested across various datasets, including benchmark datasets, physics datasets, and real-world datasets. The results have demonstrated that our approach outperforms several well-known methods.},
  archive      = {J_TEVC},
  author       = {Junlan Dong and Jinghui Zhong and Wei-Li Liu and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3404650},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1745-1759},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolving equation learner for symbolic regression},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask-assisted evolutionary algorithm for constrained multimodal multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1729-1744. (<a href='https://doi.org/10.1109/TEVC.2024.3393921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective optimization problems (CMMOPs) are challenging in the field of optimization, requiring to consider the balance between the constraints and objectives, the balance between exploration and exploitation in the decision space and the objective space, and the balance of diversity between the decision space and the objective space. In this work, we propose a multitask-assisted evolutionary algorithm (CMMO-MTA) to achieve these balances. In CMMO-MTA, a tri-task multitasking framework is proposed, which contains one main task and two assisting tasks. The main task aims to solve the original CMMOP, and two assisting tasks are designed to transfer desired knowledge to the main task to achieve the first two balances. Furthermore, a space balance-based selection mechanism is proposed to ensure a balanced representation of solutions in both the decision space and the objective space, thereby striking the third balance. Experimental studies are conducted on 31 test problems and a real-world application to compare the proposed algorithm with seven state-of-the-art algorithms. The results demonstrate the superiority of CMMO-MTA in solving CMMOPs.},
  archive      = {J_TEVC},
  author       = {Tianzi Zheng and Jianchang Liu and Yaochu Jin and Yuanchao Liu},
  doi          = {10.1109/TEVC.2024.3393921},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1729-1744},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A multitask-assisted evolutionary algorithm for constrained multimodal multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging evolutionary algorithms and reinforcement learning: A comprehensive survey on hybrid algorithms. <em>TEVC</em>, <em>29</em>(5), 1707-1728. (<a href='https://doi.org/10.1109/TEVC.2024.3443913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary reinforcement learning (ERL), which integrates the evolutionary algorithms (EAs) and reinforcement learning (RL) for optimization, has demonstrated remarkable performance advancements. By fusing both the approaches, ERL has emerged as a promising research direction. This survey offers a comprehensive overview of the diverse research branches in ERL. Specifically, we systematically summarize the recent advancements in related algorithms and identify three primary research directions: 1) EA-assisted optimization of RL; 2) RL-assisted optimization of EA; and 3) synergistic optimization of EA and RL. Following that, we conduct an in-depth analysis of each research direction, organizing multiple research branches. We elucidate the problems that each branch aims to tackle and how the integration of EAs and RL addresses these challenges. In conclusion, we discuss potential challenges and prospective future research directions across various research directions. To facilitate researchers in delving into ERL, we organize the algorithms and codes involved on https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning.},
  archive      = {J_TEVC},
  author       = {Pengyi Li and Jianye Hao and Hongyao Tang and Xian Fu and Yan Zheng and Ke Tang},
  doi          = {10.1109/TEVC.2024.3443913},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1707-1728},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Bridging evolutionary algorithms and reinforcement learning: A comprehensive survey on hybrid algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-tree genetic programming with adaptive mutation for dynamic workflow scheduling in cloud computing. <em>TEVC</em>, <em>29</em>(5), 1692-1706. (<a href='https://doi.org/10.1109/TEVC.2024.3392968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic workflow scheduling (DWS) is a challenging and important optimization problem in cloud computing, aiming to execute multiple heterogeneous workflows on dynamically leased virtual machine resources to satisfy user-defined Quality of Service requirements. For the popular deadline-constrained DWS in cloud problem, a virtual machine selection rule (VMSR) and a task selection rule (TSR) need to be designed simultaneously to minimize the rental fee and deadline violation penalty. For this purpose, Dual-Tree Genetic Programming (DTGP) has been previously developed to automatically evolve effective VMSRs and TSRs. However, existing DTGP approaches assume that VMSR and TSR, as well as terminals used by VMSRs and TSRs are equally important and evolve both VMSRs and TSRs in a opaque manner, i.e., without using any knowledge about different impacts of trees and terminals. Several recent studies clearly indicate that different trees or terminals have varied performance impacts, making it critical to develop adaptive mutation mechanisms for effective DTGP. Driven by this motivation, this article proposes two new levels of adaptive mutation mechanisms, contributing to the development of a new DTGP algorithm, which features the use of three new probability vectors for adaptive tree selection of VMSR and TSR at the first level and adaptive terminal selection at the second level while mutating any existing dual-tree individuals. Extensive experimental results demonstrate that the proposed two adaptive mechanisms can improve the effectiveness of DTGP compared to four baseline algorithms.},
  archive      = {J_TEVC},
  author       = {Yifan Yang and Gang Chen and Hui Ma and Sven Hartmann and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3392968},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1692-1706},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dual-tree genetic programming with adaptive mutation for dynamic workflow scheduling in cloud computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural architecture search with progressive evaluation and subpopulation preservation. <em>TEVC</em>, <em>29</em>(5), 1678-1691. (<a href='https://doi.org/10.1109/TEVC.2024.3393304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is an effective approach for automating the design of deep neural networks. Evolutionary computation (EC) is commonly used in NAS due to its global optimization capability. However, the evaluation phase of architecture candidates in EC-based NAS is compute-intensive, limiting its application for many real-world problems. To overcome this challenge, we propose a novel progressive evaluation strategy for the evaluation phase in convolutional neural network architecture search, in which the number of training epochs of network individuals is progressively increased. In addition, a subpopulation preservation strategy is proposed to preserve medium-size and large-size architectures to avoid prematurely discarding networks that may not perform well in the early stages but have the potential to excel with further optimization. Our proposed algorithm reduces the computational cost of the evaluation phase and promotes population diversity and fairness by preserving promising networks based on their distribution. We evaluate the proposed progressive evaluation and subpopulation preservation of NAS (PEPNAS) algorithm on the CIFAR10, CIFAR100, and ImageNet benchmark datasets, and compare it with 36 state-of-the-art algorithms, including manually designed networks, reinforcement learning (RL) algorithms, gradient-based algorithms, and other EC-based ones. The experimental results demonstrate that PEPNAS effectively identifies networks with competitive accuracy while also markedly improving the efficiency of the search process. For instance, PEPNAS discovers the architecture on CIFAR10 with a low-error rate of 2.38% using only 0.7 GPU days. We directly adopt the searched architecture for the image classification on the CIFAR100 and ImageNet datasets, which achieves the top 1 error rates of 16.46% and 26.25%, respectively. The code is available at https://github.com/chajiajie/PEPNAS.},
  archive      = {J_TEVC},
  author       = {Yu Xue and Jiajie Zha and Danilo Pelusi and Peng Chen and Tao Luo and Liangli Zhen and Yan Wang and Mohamed Wahib},
  doi          = {10.1109/TEVC.2024.3393304},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1678-1691},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Neural architecture search with progressive evaluation and subpopulation preservation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast heterogeneous multiproblem surrogates for transfer evolutionary multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1663-1677. (<a href='https://doi.org/10.1109/TEVC.2024.3384478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer evolutionary multiobjective optimization (MOO) leverages the relevant knowledge from other source problems (distinct but possibly related) to assist the optimization of the target problem of interest. Multiproblem surrogates (MPSs) stack multiple source surrogates to reduce the number of function evaluations of the target expensive problem. The current MPSs only considers several source problems and the source and target problems are assumed to be homogeneous. In order to address the above issues, this article proposes fast heterogeneous MPSs (HeMPSs) for transfer evolutionary MOO with a large number of surrogates. First, an iterative surrogate selection strategy is designed to select the highly relevant surrogates from the large-scale surrogate pool to avoid negative transfer. Second, HeMPSs are established to align the features of the source and target models. Finally, an adaptive k-fold cross-validation method is proposed to obtain the predicted values of the target model with low-computational costs. Experiments on the MOO benchmark problems and multiobjective neural architecture search problems have demonstrated that the proposed method is able to avoid negative transfer in the large-scale scenarios and reduce the computational costs.},
  archive      = {J_TEVC},
  author       = {Hao Li and Pu Xiong and Maoguo Gong and A. K. Qin and Yue Wu and Lining Xing},
  doi          = {10.1109/TEVC.2024.3384478},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1663-1677},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Fast heterogeneous multiproblem surrogates for transfer evolutionary multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EvoX: A distributed GPU-accelerated framework for scalable evolutionary computation. <em>TEVC</em>, <em>29</em>(5), 1649-1662. (<a href='https://doi.org/10.1109/TEVC.2024.3388550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by natural evolutionary processes, evolutionary computation (EC) has established itself as a cornerstone of artificial intelligence. Recently, with the surge in data-intensive applications and large-scale complex systems, the demand for scalable EC solutions has grown significantly. However, most existing EC infrastructures fall short of catering to the heightened demands of large-scale problem solving. While the advent of some pioneering GPU-accelerated EC libraries is a step forward, they also grapple with some limitations, particularly in terms of flexibility and architectural robustness. In response, we introduce EvoX: a computing framework tailored for automated, distributed, and heterogeneous execution of EC algorithms. At the core of EvoX lies a unique programming model to streamline the development of parallelizable EC algorithms, complemented by a computation model specifically optimized for distributed GPU acceleration. Building upon this foundation, we have crafted an extensive library comprising a wide spectrum of 50+ EC algorithms for both single- and multi-objective optimization. Furthermore, the library offers comprehensive support for a diverse set of benchmark problems, ranging from dozens of numerical test functions to hundreds of reinforcement learning tasks. Through extensive experiments across a range of problem scenarios and hardware configurations, EvoX demonstrates robust system and model performances. EvoX is open source and accessible at: https://github.com/EMI-Group/EvoX.},
  archive      = {J_TEVC},
  author       = {Beichen Huang and Ran Cheng and Zhuozhao Li and Yaochu Jin and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3388550},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1649-1662},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {EvoX: A distributed GPU-accelerated framework for scalable evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-aided evolutionary search and selection for scaling-up constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1634-1648. (<a href='https://doi.org/10.1109/TEVC.2024.3380366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing constrained multiobjective evolutionary algorithms (CMOEAs) still have great room for improvement in balancing population’s convergence, diversity and feasibility on complex constrained multiobjective optimization problems (CMOPs). Besides, their effectiveness deteriorates dramatically when facing the CMOPs with scaling-up objective space or search space. We are thus motivated to design a learning-aided CMOEA with promising problem-solving ability and scalability for various CMOPs. In the proposed solver, two learning models are, respectively, trained online on constrained-ignored task and feasibility-first task, which are then used to learn the two improvement-based vectors for enhancing the search by differential evolution. In addition, the union population of parent and child solutions is divided into multiple subsets with a hierarchical clustering based on cosine similarity. A comprehensive indicator, considering objective-based performance and constraint violation degree of a solution, is developed to select the representative solution from each cluster. The effectiveness of the proposed optimizer is verified by solving the CMOPs with various irregular Pareto fronts, the number of objectives ranging from 2 to 15, and the dimensionality of search space scaling up to 1000.},
  archive      = {J_TEVC},
  author       = {Songbai Liu and Zeyi Wang and Qiuzhen Lin and Jianqiang Li and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3380366},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1634-1648},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning-aided evolutionary search and selection for scaling-up constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic interval multiobjective evolutionary algorithm based on multitask learning and inverse mapping. <em>TEVC</em>, <em>29</em>(5), 1619-1633. (<a href='https://doi.org/10.1109/TEVC.2025.3551355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic interval multiobjective optimization problems, such as those encountered in wireless sensor network scheduling and portfolio selection, are increasingly prevalent. However, they present significant challenges due to the inherent uncertainty and variability of their parameters. This article proposes a dynamic interval multiobjective evolutionary algorithm in terms of multitask learning and inverse mapping. The algorithm employs an interval-based MOEA/D as its foundational framework. Upon encountering environmental changes, prediction models for the midpoints and widths of intervals are developed using multitask learning combined with a self-evolving fuzzy system. These models generate a predicted Pareto front (PF) in the objective space. Subsequently, inverse mappings of the objective functions at the new time are established to identify solutions that correspond to the predicted PF in the decision space. Finally, these solutions are expanded to form an initial population at the new time. Testing on 18 benchmark optimization problems and an uncertain scheduling of underwater wireless sensor networks, the proposed algorithm demonstrates both competitiveness and superiority when compared to five state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Feimeng Wang and Jing Sun and Xingjia Gan and Dunwei Gong and Gaige Wang and Yongde Guo},
  doi          = {10.1109/TEVC.2025.3551355},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1619-1633},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A dynamic interval multiobjective evolutionary algorithm based on multitask learning and inverse mapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dynamic constrained multiobjective optimization with multicenters-based prediction. <em>TEVC</em>, <em>29</em>(5), 1604-1618. (<a href='https://doi.org/10.1109/TEVC.2025.3551399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic constrained multiobjective optimization problems (DCMOPs) involve complex changes in objective functions and constraints over time. These changes challenge most existing algorithms to quickly cross infeasible regions and accurately track the changing Pareto optimal set (POS) and Pareto optimal front (POF). To address this issue, this article presents a multicenters-based prediction strategy, termed FCP, for solving DCMOPs more effectively. First, we introduce a penalty function to cluster the historical optimal solutions, thereby obtaining multicenters of these solutions. These centers can roughly represent the distribution of different clusters in POS. Then, we predict cluster centers of the new environment’s POS by calculating the distance of centers from the preceding two environments. The prediction strategy can handle the change of POS caused by constraints thereby improving the accuracy of prediction. Finally, a proposed population generator calculates the distances between new centers and utilizes information from these centers to predict a well-distributed initial population. Comprehensive studies on widely used benchmark problems demonstrate that our proposed algorithm is very competitive in dealing with DCMOPs compared with seven state-of-the-art algorithms. Meanwhile, to validate the proposed prediction strategy, it is embedded into the static constraints handling techniques from other DCMOEAs to solving DCMOPs and the experimental results indicate that FCP is superior in generating initial population.},
  archive      = {J_TEVC},
  author       = {Quan Gong and Yizhang Xia and Juan Zou and Zhanglu Hou and Yuan Liu},
  doi          = {10.1109/TEVC.2025.3551399},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1604-1618},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Enhancing dynamic constrained multiobjective optimization with multicenters-based prediction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A subspace sparsity-driven knowledge transfer strategy for dynamic constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1590-1603. (<a href='https://doi.org/10.1109/TEVC.2025.3525635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic constrained multiobjective optimization problems (DCMOPs) require algorithms to quickly track the feasible Pareto optima under dynamic environments. The existing dynamic constrained multiobjective evolutionary algorithms (DCMOEAs) normally focus on the convergence speed, but cannot well guarantee distribution. To address this issue, a subspace sparsity-driven knowledge transfer strategy-based DCMOEA is developed in this article, called SSDKT. First, reference points are introduced to partition objective space into multiple subspaces. Subsequently, the feasibility of each subspace is determined by the distribution of all historical feasible optimal solutions in it, and defined as the sparsity of subspace. A predictor based on the gated recurrent unit (GRU) network is further constructed to estimate the sparsity under the future environment. Once a new environment appears, a subspace transfer strategy is designed to generate an initial population. In each feasible subspace, the GRU-based prediction method is developed and competed with Kalman filter to generate the initial solution under the new environment. Based on the predicted solution of the nearest feasible neighbor, a potential initial individual in each infeasible subspace is produced by transferring the corresponding knowledge. The experimental results on various benchmarks verify that, compared with several state-of-the-art DCMOEAs, the proposed algorithm achieves the most competitive performance in solving DCMOPs.},
  archive      = {J_TEVC},
  author       = {Guoyu Chen and Yinan Guo and Changhe Li and Feng Wang and Dunwei Gong and Liang Yuan},
  doi          = {10.1109/TEVC.2025.3525635},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1590-1603},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A subspace sparsity-driven knowledge transfer strategy for dynamic constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new prediction strategy for dynamic multiobjective optimization using diffusion model. <em>TEVC</em>, <em>29</em>(5), 1575-1589. (<a href='https://doi.org/10.1109/TEVC.2025.3551323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve dynamic multiobjective optimization problems (DMOPs), the optimization algorithms are required to track the movement of the Pareto set after the environmental changes effectively. Many prediction-based dynamic multiobjective evolutionary algorithms (DMOEAs) have been proposed to address this challenge by utilizing environmental information for population reinitialization. However, when environmental changes are complex, irregular, and severe, the solutions and information during the evolution process often contain noise, making it difficult for prediction-based DMOEAs to accurately predict and reinitialize the population. To address this issue, we propose a novel dynamic multiobjective evolutionary algorithm (DM-DMOEA) which uses a diffusion model-based prediction strategy. In DM-DMOEA, to improve the prediction accuracy, the diffusion model is introduced to extract the relationships of high-quality solutions and reinitialize the population, and a PS estimation method is employed to integrate both historical and new environmental information, providing a set of high-quality solutions for diffusion model training. To speed up the response time, a variational autoencoder (VAE) is used to map the decision space to a latent space, which can reduce the diffusion model size and accelerate the diffusion process. To evaluate the effectiveness of the proposed DM-DMOEA on DMOPs, comprehensive experiments are conducted on several benchmarks and a practical problem. The results show that the DM-DMOEA outperforms other four state-of-the-art DMOEAs in most cases.},
  archive      = {J_TEVC},
  author       = {Feng Wang and Jinsong Xie and Aimin Zhou and Ke Tang},
  doi          = {10.1109/TEVC.2025.3551323},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1575-1589},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A new prediction strategy for dynamic multiobjective optimization using diffusion model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary dynamic multiobjective optimization with learning across problems. <em>TEVC</em>, <em>29</em>(5), 1561-1574. (<a href='https://doi.org/10.1109/TEVC.2025.3596468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {dynamic multiobjective optimization (DMO) problems are prevalent in many practical applications and have garnered significant attention from both industry and academia, leading to the proposal of numerous DMO algorithms. Among these approaches, learning- and prediction-based evolutionary approaches have achieved remarkable success due to their fast learning and strong optimization capabilities when dynamic occurs. However, existing methods typically focus on learning and transferring knowledge within a single problem, often relying on historical knowledge to aid the optimization process. This could limit the data available for developing a more general prediction model for dynamic optimization. The potential for leveraging knowledge across different dynamic multiobjective problems (DMOPs) to enhance problem-solving efficiency and effectiveness remains largely unexplored. Building on this insight, this article explores the solution of DMOPs with learning not only within a single problem but also across different problems. In particular, by performing dynamic feature extraction and task-specific solution classification, we propose to construct a centralized learning model that captures the correlations across DMOPs and the corresponding optimized solutions. This approach allows optimization data from multiple problems to be effectively utilized, enabling the learning of dynamic knowledge to enhance evolutionary optimization when a change occurs. To assess the effectiveness of the proposed algorithm, extensive empirical studies have been conducted on the commonly used DMOP benchmarks with fixed and shifty dynamic settings. The numerical results demonstrate the effectiveness of the proposed algorithm in recognizing more general change patterns of DMOPs, showcasing its superiority compared to the existing state-of-the-art learning and prediction-based approaches.},
  archive      = {J_TEVC},
  author       = {Yuling Xie and Quanwu Zhao and Wei Zhou and Zexuan Zhu},
  doi          = {10.1109/TEVC.2025.3596468},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1561-1574},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary dynamic multiobjective optimization with learning across problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multisource and hidden source-based knowledge transfer for solving dynamic multiobjective optimization problems. <em>TEVC</em>, <em>29</em>(5), 1546-1560. (<a href='https://doi.org/10.1109/TEVC.2025.3550557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transfer-learning-based dynamic multiobjective optimization algorithms (TL-DMOAs) have been shown to be very promising in solving dynamic multiobjective optimization problems (DMOPs). However, it is difficult for them to model knowledge capable of delineating the Pareto optimal solutions (POSs) found in each historical environment, because the POSs’ distribution cannot be adequately reflected. Besides, existing TL-DMOAs normally focus on acquiring knowledge from historical environments, but neglect correlations behind them for excavating potential knowledge, restricting the performance in generating high-quality initial populations (HIPs). To address these issues, herein a DMOA with multisource and hidden source-based knowledge transfer (DMOA-MHKT) is proposed. First, we design a knowledge extraction strategy by introducing mean shift, a nonparametric clustering method, to cluster the historical POSs. As clusters’ representatives, the cluster centers are considered to represent environmental knowledge, because they can adequately reflect the POSs’ distribution. Second, the most similar historical environment through environmental match and the last one are selected as two explicit sources. In the former source the POSs’ cluster centers are treated as its knowledge. By contrast, based on the POSs’ cluster centers and knee points in the latter source, a scoring method is designed to generate environmental knowledge by depicting the dynamics between two continuous environments. Third, after aligning knowledge of the explicit sources, a hidden source is learned by excavating correlations and potential knowledge behind them, facilitating the generalization enhancement in generating HIPs. The experimental results especially performance comparisons with seven state-of-the-art DMOAs demonstrate that DMOA-MHKT brings significant improvements in solving DMOPs.},
  archive      = {J_TEVC},
  author       = {Wei Song and Zhi Liu and Jian Yu and Xiaoyan Sun and Yaochu Jin and Khin Wee Lai},
  doi          = {10.1109/TEVC.2025.3550557},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1546-1560},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multisource and hidden source-based knowledge transfer for solving dynamic multiobjective optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coping with a severely changing number of objectives in dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1531-1545. (<a href='https://doi.org/10.1109/TEVC.2025.3558987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multiobjective optimization problems (DMOPs) where the number of objectives (NObj) changes, the Pareto-optimal set (PS) manifold may expand or contract over time. Knowledge transfer has been utilized to solve DMOPs because it can transfer valuable information from one problem-solving instance (i.e., source) to solving another related problem instance. However, existing transfer approaches suffer from poor diversity and convergence after a severe increase and decrease in the NObjs, respectively. The reason is that most transfer approaches simply transfer knowledge from the solutions before the change, which causes degeneration in quality of transferred solutions due to dissimilarity between the problem instances before and after the severe change. In this article, we propose a simple-yet-effective transfer approach, called similarity transfer approach (STA) to tackling a severely changing NObjs. It selects the historically most similar environment to the current one as the source problem instance and transfers knowledge from that environment. Furthermore, a novel strategy of randomization enhancing transfer diversity is proposed in STA if the transfer from the most similar environment still lacks sufficient diversity when increasing the NObjs. Comprehensive studies using 13 DMOP benchmarks with a severely changing NObjs demonstrate that our proposed STA is effective in improving solution quality not only immediately after changes but also after optimization, in comparison to state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Gan Ruan and Zhanglu Hou and Xin Yao},
  doi          = {10.1109/TEVC.2025.3558987},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1531-1545},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Coping with a severely changing number of objectives in dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge transfer with mixture model in dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(5), 1517-1530. (<a href='https://doi.org/10.1109/TEVC.2025.3566481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing dynamic multiobjective evolutionary algorithms (DMOEAs) have been designed to handle dynamic multiobjective optimization problems (DMOPs) with regular environmental changes. However, they often overlook scenarios where environmental changes are irregular and less predictable. Recently, knowledge transfer has been proposed as a novel paradigm for solving DMOPs. Despite this, most transfer strategies only consider transferring knowledge obtained from the previous environment while ignoring significant differences that may exist between adjacent environments due to irregular changes. To address these issues, this article proposes a novel knowledge transfer strategy based on a Gaussian mixture model (GMM denoted as KTMM) for solving DMOPs with irregular changes. In particular, an adaptive GMM is designed to capture the knowledge of historical environments, which is then transferred to generate an initial population for the new environment. Additionally, a new method for controlling irregular changes is introduced into widely used benchmarks to form the DMOP benchmark with irregular changes. Our proposed KTMM is compared with six state-of-the-art DMOEAs on several benchmark problems with irregular changes. Experimental results demonstrate the superiority of our proposed method in most test instances and in a real-world problem.},
  archive      = {J_TEVC},
  author       = {Juan Zou and Zhanglu Hou and Shouyong Jiang and Shengxiang Yang and Gan Ruan and Yizhang Xia and Yuan Liu},
  doi          = {10.1109/TEVC.2025.3566481},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1517-1530},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge transfer with mixture model in dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dynamic flexible job shop scheduling using an evolutionary multitask optimization framework and genetic programming. <em>TEVC</em>, <em>29</em>(5), 1502-1516. (<a href='https://doi.org/10.1109/TEVC.2025.3543770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the evolution of smart and sustainable manufacturing paradigms under Industry 5.0, which emphasize adaptability, connectivity, and data-driven decision-making, the dynamic flexible job shop scheduling problem (DFJSSP) has emerged as a critical area of research. The DFJSSP involves scheduling jobs in a highly dynamic and uncertain manufacturing environment where new tasks are continually introduced, further complicating the scheduling process. In this study, the DFJSSP is extended to incorporate single crane transportation and sequence-dependent setup times, reflecting real-world manufacturing constraints. To tackle this multifaceted problem, we introduce a novel approach, i.e., a multipopulation-based evolutionary multitask optimization (EMTO) framework. In addition, the genetic programming algorithm is employed as a generative hyperheuristic to deal with the dynamic uncertainties in the shop floor. Two components are collaborated to optimize two objectives, i.e., minimizing the maximum completion time and the total tardiness. Furthermore, a dynamic transfer ratio is proposed, allowing the proportion of knowledge transfer to adapt throughout the iteration process, balancing convergence speed with population diversity. The results demonstrate that both the EMTO framework and the dynamic transfer ratio significantly enhance the performance of the algorithm. Compared to well-known constructive heuristics and reinforcement learning algorithm, the proposed approach enables parallel resolution of multiple optimization objectives, leading to enhanced scheduling efficiency and adaptability in dynamic manufacturing environments.},
  archive      = {J_TEVC},
  author       = {Xiaolong Chen and Junqing Li and Zunxun Wang and Qingda Chen and Kaizhou Gao and Quanke Pan},
  doi          = {10.1109/TEVC.2025.3543770},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1502-1516},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Optimizing dynamic flexible job shop scheduling using an evolutionary multitask optimization framework and genetic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic cascaded flow-shop scheduling using an evolutionary greedy algorithm. <em>TEVC</em>, <em>29</em>(5), 1490-1501. (<a href='https://doi.org/10.1109/TEVC.2025.3541959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production processes are inherently complex, often involving multiple production phases from raw materials to finished products, making joint scheduling problems a focal point of research. This article addresses the dynamic cascaded flowshop joint scheduling problem, which integrates a distributed permutation flowshop in Phase 1 and a hybrid flowshop in Phase 2. The challenge involves both initial scheduling and dynamic response mechanisms for new job insertions. We propose an evolutionary greedy algorithm (EGA) aimed at minimizing total flowtime. The EGA employs a multistart cooperative framework tailored to problem characteristics, alternating between a population-based EGA for Phase 1 and an elitist-based greedy algorithm for Phase 2 to generate a robust and complete schedule. Upon new job insertions, three heuristic-driven response strategies enhance solution stability and adaptability. In addition, phase-specific hybrid local search operators and an adaptive insertion strategy, leveraging knowledge-based problem properties, further improve solution quality and search efficiency. The experimental results indicate that the EGA outperforms five state-of-the-art algorithms, achieving an average improvement of 39% in RPI values across 480 instances. Moreover, the proposed local search mechanisms and dynamic response strategies significantly enhance its performance. Thus, the EGA is well-suited for addressing the studied problem.},
  archive      = {J_TEVC},
  author       = {Qiu-Ying Li and Quan-Ke Pan and Ling Wang and Liang Gao and Wei-Min Li},
  doi          = {10.1109/TEVC.2025.3541959},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1490-1501},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dynamic cascaded flow-shop scheduling using an evolutionary greedy algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Historical information-assisted dynamic response integration and adaptive niche methods for dynamic multimodal optimization. <em>TEVC</em>, <em>29</em>(5), 1475-1489. (<a href='https://doi.org/10.1109/TEVC.2025.3527478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multimodal optimization problems (DMMOPs) represent the multimodal optimization problems that the optimal solution changes over time. Due to the wide application of DMMOPs in reality, some related algorithms have been proposed in recent years. Most existing algorithms employ a single dynamic response mechanism and embed it in existing multimodal evolutionary algorithms. However, these algorithms often perform limited when environmental change involves multiple types, and they fail to consider utilizing historical information to assist static multimodal optimizers. To solve these issues, this article proposes historical information-assisted dynamic response integration and adaptive niche methods (HIA-DRI-AN) for dynamic multimodal optimization. In HIA-DRI-AN, an dynamic response integration method with adaptive adjustment mechanism is proposed for generating the initial population when the change happens. This method considers the change types of DMMOPs, and integrates targeted dynamic response mechanisms to respond to the different change types. Also, this method can adaptively self-adjust to balance the convergence and diversity of the initial population depending on the integrated response mechanism’s performance in historical environments. Furthermore, a niching adaptive division strategy is proposed to enhance the performance of the static optimizer. The strategy dynamically divides niches based on the integrated response mechanism’s performance and the current evolutionary stage, which can adjust the preference for diversity and convergence during evolution. The comprehensive experimental results on 24 test functions show that HIA-DRI-AN is superior compared to some state-of-the-art dynamic multimodal algorithms.},
  archive      = {J_TEVC},
  author       = {Kunjie Yu and Xuyang Zhang and Dezheng Zhang and Jing Liang and Yumeng Li and Heshan Wang and Ke Chen and Caitong Yue},
  doi          = {10.1109/TEVC.2025.3527478},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1475-1489},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Historical information-assisted dynamic response integration and adaptive niche methods for dynamic multimodal optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How do dynamic events change the fitness landscape of traveling salesman problems?. <em>TEVC</em>, <em>29</em>(5), 1463-1474. (<a href='https://doi.org/10.1109/TEVC.2025.3538547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traveling salesman problem (TSP) is a combinatorial optimization problem, serving as basis for many real-world applications (e.g., transportation planning, circuit board design, and DNA sequencing). In TSP, it is common to encounter some dynamic events, for example, traffic jam, and roadworks in transportation planning. To deal with such dynamic TSP (DTSP) scenarios, numerous techniques have been designed over decades. In this article, we take a different perspective to study DTSP. Instead of focusing only on algorithm design for DTSP, we investigate how dynamic events in DTSP affect its fitness landscape (e.g., the location of local optimal solutions and the ruggedness level of search space). We consider three dynamic events, including node addition, node deletion and weight changes, and analyze how they affect the TSP with respect to the overall landscape structure and solution optimality. Experimental results show that the weight change event has great effect on the problem’s fitness landscape, introducing more local optima and reducing the basin of attraction for the global optimum. This may suggest that search algorithms need to have stronger exploration capability when handling weight change dynamic events. Furthermore, our experimental studies also demonstrate that the dynamic solution adaptation strategy on the original global optimum is effective for tracking the new optimum after dynamic changes.},
  archive      = {J_TEVC},
  author       = {Hao Tong and Miqing Li and Jialin Liu and Xin Yao},
  doi          = {10.1109/TEVC.2025.3538547},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1463-1474},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {How do dynamic events change the fitness landscape of traveling salesman problems?},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial evolutionary dynamic optimization. <em>TEVC</em>, <em>29</em>(5), 1458-1462. (<a href='https://doi.org/10.1109/TEVC.2025.3613238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TEVC},
  author       = {Danial Yazdani and Wenjian Luo and Shengxiang Yang},
  doi          = {10.1109/TEVC.2025.3613238},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {10},
  number       = {5},
  pages        = {1458-1462},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial evolutionary dynamic optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance metrics for multiobjective optimization under noise. <em>TEVC</em>, <em>29</em>(4), 1449-1455. (<a href='https://doi.org/10.1109/TEVC.2024.3438115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the challenge when evaluating multiobjective optimization algorithms under noise. It argues that it is important to take into account possible selection errors by a decision maker, due to inaccurate estimates of a solution’s true objective values. It demonstrates that commonly used performance metrics do not properly account for such errors, and proposes two alternative performance metrics that do account for such errors by adapting the popular R2 and ${\mathrm { IGD}}^{+}$ metrics.},
  archive      = {J_TEVC},
  author       = {Juergen Branke},
  doi          = {10.1109/TEVC.2024.3438115},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1449-1455},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Performance metrics for multiobjective optimization under noise},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison of large language models and genetic programming for program synthesis. <em>TEVC</em>, <em>29</em>(4), 1434-1448. (<a href='https://doi.org/10.1109/TEVC.2024.3410873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models have recently become known for their ability to generate computer programs, especially through tools, such as GitHub Copilot, a domain where genetic programming (GP) has been very successful so far. Although they require different inputs (free-text versus input/output examples) their goal is the same—program synthesis. Therefore, in this work, we compare how well GitHub Copilot and GP perform on common program synthesis benchmark problems. We study the structure and diversity of the generated programs by using well-known software metrics. We find that GitHub Copilot and GP solve a similar number of benchmark problems (85.2% versus 77.8%, respectively). We find that GitHub Copilot generated smaller and less complex programs as GP, while GP is able to find new and unique problem solving strategies. This increase in diversity of solutions comes at a cost. When analyzing the success rates for 100 runs per problem, GitHub Copilot outperforms GP on over 50% of the problems.},
  archive      = {J_TEVC},
  author       = {Dominik Sobania and Justyna Petke and Martin Briesch and Franz Rothlauf},
  doi          = {10.1109/TEVC.2024.3410873},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1434-1448},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A comparison of large language models and genetic programming for program synthesis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary alternating direction method of multipliers for constrained multiobjective optimization with unknown constraints. <em>TEVC</em>, <em>29</em>(4), 1419-1433. (<a href='https://doi.org/10.1109/TEVC.2024.3425629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) pervade real-world applications in science, engineering, and design. Constraint violation (CV) has been a building block in designing evolutionary multiobjective optimization (EMO) algorithms for solving CMOPs. However, in certain scenarios, constraint functions might be unknown or inadequately defined, making CV unattainable and potentially misleading for the conventional constrained EMO algorithms. To address this issue, we present the first of its kind evolutionary optimization framework, inspired by the principles of the alternating direction method of multipliers that decouples objective and constraint functions. This framework tackles CMOPs with unknown constraints by reformulating the original problem into an additive form of two subproblems, each of which is allotted a dedicated evolutionary population. Notably, these two populations operate toward complementary evolutionary directions during their optimization processes. In order to minimize discrepancy, their evolutionary directions alternate, aiding the discovery of feasible solutions. Comparative experiments conducted against the five state-of-the-art constrained EMO algorithms on 120 benchmark test problem instances with varying properties as well as two real-world engineering optimization problems demonstrate the effectiveness and superiority of our proposed framework. Its salient features include faster convergence and enhanced resilience to various Pareto front shapes.},
  archive      = {J_TEVC},
  author       = {Shuang Li and Ke Li and Wei Li and Ming Yang},
  doi          = {10.1109/TEVC.2024.3425629},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1419-1433},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary alternating direction method of multipliers for constrained multiobjective optimization with unknown constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on evolutionary computation for identifying biomarkers of complex disease. <em>TEVC</em>, <em>29</em>(4), 1400-1418. (<a href='https://doi.org/10.1109/TEVC.2024.3414442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological markers (i.e., biomarkers) are the key to predicting disease states and revealing the molecular mechanisms in precision medicine of complex diseases (e.g., cancer). With the advancement of high-throughput sequencing technology, there has been a significant increase in the volume and diversity of known disease omics data, where many methods have been developed to identify potential disease biomarkers (DBs) for mining the complex dynamics. As emerging artificial intelligence techniques, evolutionary computation (EC) has found extensive application in the identification of DBs, making significant achievements in mining disease omics data. However, there is currently no survey or analysis available of the existing EC methods to identify DBs on the disease omics data, resulting in missed opportunities to enhance performance and achieve successful applications in precision medicine. This article aims to present a comprehensive overview of the latest EC methods for mining the dynamics of DBs, including the summary of biomolecular omics datasets, the classification of the EC methods for DB discovery, and performance comparisons of the typical EC methods. Additionally, this article discusses challenges and potential future directions of the EC methods in the identification of DBs, providing directions and prospects for future research.},
  archive      = {J_TEVC},
  author       = {Jing Liang and Zhuo Hu and Ying Bi and Han Cheng and Kunjie Yu and Cai-Tong Yue and Xianfang Wang and Wei-Feng Guo},
  doi          = {10.1109/TEVC.2024.3414442},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1400-1418},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary computation for identifying biomarkers of complex disease},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Targeted pareto optimization for subset selection with monotone objective function and cardinality constraint. <em>TEVC</em>, <em>29</em>(4), 1386-1399. (<a href='https://doi.org/10.1109/TEVC.2024.3431928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subset selection, a fundamental problem in various domains, is to choose a subset of elements from a large candidate set under a given objective or multiple objectives. Pareto optimization for subset selection (POSS) has emerged as a powerful paradigm for addressing subset selection problems. Recently, some POSS variants have been proposed to further improve its performance. In this article, we propose a new POSS variant, named targeted POSS (TPOSS). TPOSS differs from POSS in four aspects: 1) problem formulation; 2) population initialization; 3) mutation; and 4) environmental selection. The main idea of TPOSS is to focus the search on the target region of subset selection with respect to the subset cardinality in order to improve the search efficiency. We conduct comprehensive experiments to compare TPOSS with six state-of-the-art algorithms on three subset selection tasks (i.e., sparse regression, unsupervised feature selection, and hypervolume subset selection) where the size of the candidate sets ranges from 20 to 400. Experimental results show that with respect to the objective value of the best feasible subset, TPOSS outperforms the other algorithms on all the three tasks, which suggests the potential of TPOSS to enhance subset selection in various domains.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Guotong Wu and Lie Meng Pang and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2024.3431928},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1386-1399},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Targeted pareto optimization for subset selection with monotone objective function and cardinality constraint},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning assisted genetic programming ensemble hyper-heuristics for dynamic scheduling of container port trucks. <em>TEVC</em>, <em>29</em>(4), 1371-1385. (<a href='https://doi.org/10.1109/TEVC.2024.3381042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient truck dispatching is crucial for optimizing container terminal operations within dynamic and complex scenarios. Despite good progress being made recently with more advanced uncertainty-handling techniques, existing approaches still have generalization issues and require considerable expertise and manual interventions in algorithm design. In this work, we present deep reinforcement learning-assisted genetic programming hyper-heuristics (DRL-GPHHs) and their ensemble variant (DRL-GPEHH). These frameworks utilize a reinforcement learning (RL) agent to orchestrate a set of auto-generated genetic programming (GP) low-level heuristics, leveraging the collective intelligence, ensuring advanced robustness and an increased level of automation of the algorithm development. DRL-GPEHH, notably, excels through its concurrent integration of a GP heuristic ensemble, achieving enhanced adaptability and performance in complex, dynamic optimization tasks. This method effectively navigates traditional convergence issues of deep RL (DRL) in sparse reward and vast action spaces, while avoiding the reliance on expert-designed heuristics. It also addresses the inadequate performance of the single GP individual in varying and complex environments and preserves the inherent interpretability of the GP approach. Evaluations across various real port operational instances highlight the adaptability and efficacy of our frameworks. Essentially, innovations in DRL-GPHH and DRL-GPEHH reveal the synergistic potential of RL and GP in dynamic truck dispatching, yielding transformative impacts on algorithm design and significantly advancing solutions to complex real-world optimization problems.},
  archive      = {J_TEVC},
  author       = {Xinan Chen and Ruibin Bai and Rong Qu and Jing Dong and Yaochu Jin},
  doi          = {10.1109/TEVC.2024.3381042},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1371-1385},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Deep reinforcement learning assisted genetic programming ensemble hyper-heuristics for dynamic scheduling of container port trucks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leader prediction for multiobjective particle swarm optimization. <em>TEVC</em>, <em>29</em>(4), 1356-1370. (<a href='https://doi.org/10.1109/TEVC.2024.3417978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the design of multiobjective particle swarm optimization (MOPSO) algorithms, swarm leaders, i.e., the personal best (pbest) and global best (gbest), are expected to guide the particles toward Pareto-optimal solutions. However, most existing MOPSO algorithms focus on selecting such leaders from the archive of candidate solutions to approximate the Pareto front (PF) that may not yield good approximations of the Pareto set (PS). To address this challenge, this work proposes to predict both pbest and gbest for each particle by explicitly approximating the manifold structure of the PS, following the regularity property of multiobjective optimization problems. Thus, we design a leader prediction-based MOPSO (PPSO) algorithm. In our algorithm, a self-organizing mapping (SOM) method is adopted at each iteration to capture the manifold structure from the current swarm to predict leaders. Specifically, pbest is pinpointed by mapping the particle onto the neuron of SOM, while gbest is estimated by randomly selecting from the neighborhood neurons. In this way, the particles of a swarm in PPSO are guided by the predicted pbest and gbest to approximate the Pareto-optimal solutions. The developed PPSO is empirically verified with several representative algorithms, on several benchmark test instances and real-world problems. Experimental results have demonstrated the advantages of leader prediction for MOPSO over other approaches.},
  archive      = {J_TEVC},
  author       = {Shuai Wang and Aimin Zhou},
  doi          = {10.1109/TEVC.2024.3417978},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1356-1370},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Leader prediction for multiobjective particle swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary art attack for black-box adversarial example generation. <em>TEVC</em>, <em>29</em>(4), 1343-1355. (<a href='https://doi.org/10.1109/TEVC.2024.3391063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved remarkable performance in various tasks, including image classification. However, recent research has revealed the susceptibility of trained DNNs to subtle perturbations introduced into input images. Addressing these vulnerabilities is pivotal, leading to a significant area of study focused on developing attack algorithms capable of generating potent adversarial images. In scenarios where access to gradient information is restricted (black-box scenario), many existing methods introduce optimized perturbations to each individual pixels of an image to cause trained DNNs to misclassify. However, due to the high-dimensional nature of this approach, current methods have inherent limitations. In contrast, our proposed approach involves the construction of perturbations by concatenating a series of overlapping semi-transparent shapes. Through the optimization of these shapes’ characteristics, we generate perturbations that result in the desired misclassification by the DNN. By conducting a series of attacks on state-of-the-art DNNs trained of CIFAR-10 and Imagenet datasets, our method consistently outperforms existing attack algorithms in terms of both query efficiency and success rate.},
  archive      = {J_TEVC},
  author       = {Phoenix Neale Williams and Ke Li and Geyong Min},
  doi          = {10.1109/TEVC.2024.3391063},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1343-1355},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary art attack for black-box adversarial example generation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prediction and weak coevolution-based dynamic constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1328-1342. (<a href='https://doi.org/10.1109/TEVC.2024.3418470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective evolutionary algorithms (DMOEAs) have gained great popularity in dealing with the dynamic multiobjective optimization problems (DMOPs). However, the existing studies have difficulties in tackling DMOPs subject to (dynamic) constraints. In this article, we propose a prediction and weak coevolutionary multiobjective optimization algorithm (PWDCMO) to handle the dynamic constrained multiobjective optimization problems (DCMOPs), where a prediction strategy is employed to forecast potential optimal regions under the new environment, with a weak coevolutionary constrained multiobjective optimization (CCMO) as the optimizer aiming at balancing exploration and convergence. The proposed method is compared with the four popular dynamic constrained multiobjective evolutionary algorithms (DCMOEAs) on six test instances from two various test suites with their convergence and the overall performance being discussed. Furthermore, the performance of the proposed prediction strategy is also investigated to observe its impact on the final results. Additionally, the PWDCMO is employed in the optimization of an integrated coal mine energy system (ICMES) to validate the proficiency in addressing real world problems. Experimental results demonstrate the superiority of PWDCMO.},
  archive      = {J_TEVC},
  author       = {Dunwei Gong and Miao Rong and Na Hu and Yan Wang and Witold Pedrycz and Shengxiang Yang},
  doi          = {10.1109/TEVC.2024.3418470},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1328-1342},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A prediction and weak coevolution-based dynamic constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A syntactic problem solver learning landscape structures for clinical scheduling. <em>TEVC</em>, <em>29</em>(4), 1313-1327. (<a href='https://doi.org/10.1109/TEVC.2024.3378911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article attempts to derive a mathematical formulation for real-practice clinical laboratory scheduling, and to present a syntactic problem solver by leveraging instances’ landscape structures to infer the most suitable search strategy. After formulating scheduling of medical tests as a distributed scheduling problem in heterogeneous, flexible job shop environment, we establish a mixed integer programming model to minimize mean test turnaround time. Preliminary landscape analysis sustains that these clinics-orientated scheduling instances are difficult to solve under the same search strategy. The search difficulty motivates the search for a syntactic problem solver where relatedness between domain’s syntactic features and search strategies help identify effective strategies. The challenge in designing a syntactic problem solver—which landscape features to choose as domain’s syntactic features to accurately reflect instance hardness under different search strategies—are addressed. Under various local search move operators, we investigate the changes in instance landscape structures and find that the single-move size for local search operators, local-global optima connectivity, landscape ruggedness, and plateau size fairly predict the efficacy of the local searches. The above relationship is refined into a deterministic association between instance size and local search, thereby forming the syntactic problem solver. When faced with new instances, the solver automatically instantiates the best local search algorithm for various scenarios. Extensive experiments demonstrate that the proposed syntactic solver excels not only in clinical laboratory scheduling problems but also in publicly available benchmark.},
  archive      = {J_TEVC},
  author       = {Keyao Wang and Bo Liu},
  doi          = {10.1109/TEVC.2024.3378911},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1313-1327},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A syntactic problem solver learning landscape structures for clinical scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast evaluation-based bacteria colony chemotaxis algorithm for dynamic interval multiobjective optimization problems. <em>TEVC</em>, <em>29</em>(4), 1298-1312. (<a href='https://doi.org/10.1109/TEVC.2024.3418858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many real-world applications with uncertainties that can be modeled as the dynamic interval multiobjective optimization problems (DI-MOPs). However, it is challenging for the traditional algorithms to converge rapidly before time-varying parameters change to obtain optimal solutions under interval objectives. So far, there is a lack of studies on the evaluation methods for interval optimal solutions in dynamic problems. Therefore, a fast evaluation framework is proposed in this article to tackle these issues. In this framework, we first derive a new hash function based on the Canberra distance and provide a theoretical proof of the validity and local sensitivity of the hash function, from which a Canberra locality sensitive hashing (CLSH) is constructed. The CLSH accelerates the search for interval evaluation objects in uncertain environments. Further, we propose an adaptive interval crowding distance (AICD) with relaxed constraints to obtain a global improvement in the quality of the solutions. The candidate solutions in the above framework are generated by the environment awareness and directed migration of the mutiobjective bacteria colony chemotaxis (MOBCC) algorithm. This complete algorithm is called the dynamic interval MOBCC (DI-MOBCC). In addition, the theoretical proofs of the validity and local sensitivity of hash functions are also provided. Computational results on the eight benchmark optimization problems and a path planning of the mobile robots in uncertain environments validate that the DI-MOBCC is more competitive than the other state of the art algorithms in tackling DI-MOPs.},
  archive      = {J_TEVC},
  author       = {Chen-Hao Xu and Zhi-Gang Lu and Er-Shun Du and Jiang-Feng Zhang and Xiao-Qiang Guo and Xue-Ping Li and Xiang-Xing Kong and Yan-Lin Li},
  doi          = {10.1109/TEVC.2024.3418858},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1298-1312},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A fast evaluation-based bacteria colony chemotaxis algorithm for dynamic interval multiobjective optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic neural network-based preselection for expensive multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1284-1297. (<a href='https://doi.org/10.1109/TEVC.2024.3409431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of surrogate-assisted evolutionary algorithms (SAEAs) have been proposed for the expensive multiobjective optimization problems (EMOPs), building cheap surrogate models to replace the expensive real function evaluations (FEs). However, the search efficiency of these SAEAs is not yet satisfactory. More efforts are needed to further exploit useful information from the real FEs in order to better guide the search process. Facing this challenge, this article proposes a hyperbolic neural network (HNN)-based preselection operator to accelerate the optimization process based on the limited evaluated solutions. First, the preselection task is modeled as a multilabel classification problem where solutions are classified into different layers (ordinal categories) through the $\epsilon $ -relaxed objective aggregation. Second, in order to resemble the hierarchical structure of candidate solutions, a HNN is applied to tackle the multilabel classification problem. The reason for using HNN is that hyperbolic spaces more closely resemble hierarchical structures than the Euclidean spaces. Moreover, to alleviate the data deficiency issue, a data augmentation strategy is employed for training the HNN. In order to evaluate its performance, the proposed HNN-based preselection operator is embedded into two SAEAs. Experimental results on the two benchmark test suites and three real-world problems with up to 11 objectives and 150 decision variables involving seven state-of-the-art algorithms demonstrate the effectiveness of the proposed method.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yanting Yang and Wenjing Hong and Peng Yang and Aimin Zhou},
  doi          = {10.1109/TEVC.2024.3409431},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1284-1297},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Hyperbolic neural network-based preselection for expensive multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global and local search experience-based evolutionary sequential transfer optimization. <em>TEVC</em>, <em>29</em>(4), 1269-1283. (<a href='https://doi.org/10.1109/TEVC.2024.3417325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary sequential transfer optimization (ESTO), which aims to better optimize a target task using the knowledge extracted from a number of previously solved source tasks, has been gaining continually increasing research attention over the years. Particularly, solution-based ESTO (S-ESTO) that transfers task solutions has been receiving much popularity due to its ease of implementation and optimizer independency. However, the existing S-ESTO algorithms put much emphasis on utilizing source optimized solutions standing for global search experience without being aware of the potential of intermediate solutions that represent local optimization experience. Besides, most of them cannot take full advantage of the solution data from evolutionary search. In the light of the above, this study aims to develop a global and local search experience-based solution transfer technique to maximally release the potential of optimization experience hidden in the source tasks. First, a novel transferability metric named landscape encoding-based rank correlation (LERC) is developed. Then, we propose to divide the optimization experience into two classes: 1) global and 2) local search experience. Accordingly, by instantiating LERC into global and local versions, we develop two distinct transfer methods to exploit the global and local search experience, respectively. Finally, by combining the two transfer methods, we propose an S-ESTO algorithm that can transfer the global and local search experience simultaneously for maximum performance enhancement for the target task. Experiments conducted on a set of benchmark problems and a practical case study verify the efficacy of the proposed methods. The source code of our algorithm is available athttps://github.com/ccm831143/GL-LERC.},
  archive      = {J_TEVC},
  author       = {Chenming Cao and Kai Zhang and Xiaoming Xue and Kay Chen Tan and Jian Wang and Liming Zhang and Piyang Liu and Xia Yan},
  doi          = {10.1109/TEVC.2024.3417325},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1269-1283},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Global and local search experience-based evolutionary sequential transfer optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient greedy decremental hypervolume subset selection using space partition tree. <em>TEVC</em>, <em>29</em>(4), 1254-1268. (<a href='https://doi.org/10.1109/TEVC.2024.3400801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of evolutionary multiobjective optimization, the hypervolume (HV) indicator serves as a crucial metric for assessing the quality of solution sets. Due to the high costs in HV computation, HV-based optimization algorithms always meet the challenge of finding a certain number of points in a given point set to maximize the HV indicator, especially when there are many objectives. In response, the greedy decremental algorithm for HV subset selection problem (gHSSD) has emerged as a noteworthy alternative. This article introduces a general algorithm for gHSSD, applicable in any dimensionality above two. The proposed algorithm leverages a space partition tree and incorporates a once-build-multiple-use strategy, effectively reducing time complexity. We prove that the proposed algorithm has a time complexity of $O((n-k+\sqrt {n})n^{{}({d-1}/{2})}\log n)$ where n is the number of points, k is the number of points to be reserved, and d the dimensionality. Theoretically, this complexity is competitive with the current best algorithms for $d=3, 4$ and better than them for all $5\le d\le 7$ . To validate our algorithm, we have conducted extensive tests on various random point sets and multiobjective optimization benchmarks. Experimental results suggest that our implementation is more efficient than or competitive with state-of-the-art algorithms on many instances as n increases for $d=3,4$ .},
  archive      = {J_TEVC},
  author       = {Jingda Deng and Jianyong Sun and Qingfu Zhang and Hui Li},
  doi          = {10.1109/TEVC.2024.3400801},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1254-1268},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficient greedy decremental hypervolume subset selection using space partition tree},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitasking descriptor optimization for point cloud registration. <em>TEVC</em>, <em>29</em>(4), 1239-1253. (<a href='https://doi.org/10.1109/TEVC.2024.3417416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud registration (PCR) is an important task for other point cloud tasks. Feature-based methods are widely adopted for their speed and efficiency in PCR. The descriptive capability of features extracted by a single geometric descriptor is limited. Descriptive capabilities can be improved by concatenating features extracted from multiple descriptors. However, due to the existence of redundant and irrelevant features, the correct corresponding points are difficult to match, which further affects the registration effect. We propose an evolutionary multitasking point cloud descriptor optimization method. Integrate existing descriptors to optimize descriptors with stronger description ability. Labeling features to calculate the feature importance for the registration and generating multitasks. In optimized processing, approximate evaluation which is calculated by prior correspondence saved in the database replaces the expensive searching correspondences process in the entire point cloud. Finally, a multiscale filter is developed to remove error correspondences by the geometric information from multiple scale descriptor features. Experimental demonstrate that the proposed approach can optimize a feature subset with higher-descriptive capability compared to other methods and show superior PCR performance on 14 point cloud models. This is the first paper on point cloud descriptor optimization, which provides a new idea for PCR research.},
  archive      = {J_TEVC},
  author       = {Yue Wu and Jinlong Sheng and Hangqi Ding and Peiran Gong and Hao Li and Maoguo Gong and Wenping Ma and Qiguang Miao},
  doi          = {10.1109/TEVC.2024.3417416},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1239-1253},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitasking descriptor optimization for point cloud registration},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact calculation and properties of the r2 multiobjective quality indicator. <em>TEVC</em>, <em>29</em>(4), 1227-1238. (<a href='https://doi.org/10.1109/TEVC.2024.3440571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality indicators play an essential role in evolutionary multiobjective optimization (EMO). Most likely the most often used quality indicator in EMO is hypervolume, due to its strict monotonicity with respect to the dominance relation. However, hypervolume is not free of some weak points. For example, a number of recent papers pointed out its high sensitivity to the specification of the reference point. Furthermore, hypervolume is based on fully geometric reasoning which may lead to some undesired results. Thus, it is worth to consider also other quality indicators. In this article, we prove that another well-known $R2$ quality indicator is also strictly monotonic with respect to the dominance relation when calculated exactly and the reference point strongly dominates any solution in the evaluated set. Furthermore, we adapt the improved quick hypervolume algorithm to the exact calculation of $R2$ indicator. To our knowledge, this is the first exact algorithm for $R2$ calculation with publicly available implementation. In addition, through both theoretical analysis and computational experiments, we show that $R2$ performs consistently for Pareto fronts with different shapes. We discuss also differences of Pareto fronts representations generated by an indicator-based EMO with hypervolume and $R2$ , where the latter tends to generate solutions having a high chance to be preferred by the decision maker, not necessarily uniformly distributed in geometric sense. All of these results make $R2$ a sound alternative or a complement to hypervolume in EMO.},
  archive      = {J_TEVC},
  author       = {Andrzej Jaszkiewicz and Piotr Zielniewicz},
  doi          = {10.1109/TEVC.2024.3440571},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1227-1238},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exact calculation and properties of the r2 multiobjective quality indicator},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-task differential evolutionary algorithm based on bi-space similarity. <em>TEVC</em>, <em>29</em>(4), 1215-1226. (<a href='https://doi.org/10.1109/TEVC.2024.3398436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-task differential evolutionary (DE) algorithm is an effective way to optimize multiple tasks simultaneously. The optimization performance of the algorithm decreases due to the negative transfer when the number of tasks is large. To address this problem, a many-task DE algorithm based on bi-space similarity (MaTDE-BSS) is proposed to improve the positive transfer. First, the bi-space similarity metric is designed to characterize intertask similarity quantitatively. The decision space similarity and objective space similarity are considered simultaneously in the bi-space similarity metric. Second, a task selection strategy based on evolutionary state is proposed to select the optimal source task from the source task library accurately. The source task library based on bi-space similarity metric is built for storing source tasks. Finally, a dynamic knowledge transfer strategy is proposed to improve the efficiency of knowledge positive transfer in the many-task optimization. Parameters of the knowledge transfer strategy are adjusted according to bi-space similarity metric adaptively. In addition, the experimental results show that MaTDE-BSS is able to evaluate the intertask similarity more comprehensively. And MaTDE-BSS is more competitive compared to other many-task evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Ying Hou and Yanjie Shen and Honggui Han and Jingjing Wang},
  doi          = {10.1109/TEVC.2024.3398436},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1215-1226},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Many-task differential evolutionary algorithm based on bi-space similarity},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual mutation-based evolutionary algorithm for dynamic multiobjective optimization with undetectable changes. <em>TEVC</em>, <em>29</em>(4), 1199-1214. (<a href='https://doi.org/10.1109/TEVC.2024.3424393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current research on dynamic multiobjective optimization problems (DMOPs) assumes that environmental changes can be detectable. However, undetectable changes are frequently encountered in real-world applications, which pose a serious challenge for the existing methods. Because undetectable changes can lead to the failure of change detection techniques, thereby making it difficult to adapt to environmental changes for most algorithms. Therefore, to effectively deal with DMOPs with undetectable changes, this work proposes a dual mutation-based dynamic multiobjective evolutionary algorithm (DM-DMOEA). The proposed DM-DMOEA incorporates the following two main components. First, based on the exploration level of the population, an adaptive selection strategy is proposed, which enables the adaptive identification of individuals for mutation. Second, a dual mutation scheme is developed, utilizing both the polynomial mutation and the Gaussian mutation. These mutation operations are applied on the selected individuals to generate the mutated individuals, allowing for diverse exploration in the search space. After conducting the above two strategies, the population will evolve by the evolutionary criterion of multiobjective optimization. As a result, the algorithm can effectively adapt to undetectable changes in the environment. Comprehensive empirical studies are conducted on different benchmark functions and a real-world application to evaluate the performance of DM-DMOEA. Experimental results have demonstrated that DM-DMOEA is competitive in tracking the Pareto front over time when facing undetectable changes.},
  archive      = {J_TEVC},
  author       = {Yuanchao Liu and Lixin Tang and Jinliang Ding and Qingda Chen and Kanrong Liu and Jianchang Liu},
  doi          = {10.1109/TEVC.2024.3424393},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1199-1214},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A dual mutation-based evolutionary algorithm for dynamic multiobjective optimization with undetectable changes},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MQL-MM: A meta-Q-learning-based multiobjective metaheuristic for energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem. <em>TEVC</em>, <em>29</em>(4), 1183-1198. (<a href='https://doi.org/10.1109/TEVC.2024.3399314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since severe environmental problem in manufacturing industries is becoming increasingly prominent, energy-efficient production scheduling has gained more and more attentions. This article studies an energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem (EEDFHBFSP), where processing time and setup time are uncertain. The objective is to minimize fuzzy makespan and total fuzzy energy consumption simultaneously. To solve such problem, a mixed-integer linear programming model is first presented to format it. Then, a meta-Q-learning-based multiobjective metaheuristic (MQL-MM) is proposed. In MQL-MM, a machine-position-based dispatch rule is designed as the decoding scheme. A decomposition-based constructive heuristic (DCH) is employed to generate the initial population with high quality and diversity. Several problem-specific search operators are developed to explore and exploit the solution space. A meta-Q-learning-based multiobjective search framework is presented to guide the using of search operators, which includes a meta-training phase and an adaptive search phase. The meta-training phase is employed to train the search operators to construct the Q-learning model. The adaptation search phase utilizes such model to conduct the automatic selection of the search operators. Moreover, an energy-saving strategy is designed to improve the candidate solutions. Finally, we conduct extensive experiments. The experimental results show that the designs of MQL-MM are effective, and MQL-MM performs better than several well-performing methods on solving EEDFHBFSP.},
  archive      = {J_TEVC},
  author       = {Zhongshi Shao and Weishi Shao and Jianrui Chen and Dechang Pi},
  doi          = {10.1109/TEVC.2024.3399314},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1183-1198},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MQL-MM: A meta-Q-learning-based multiobjective metaheuristic for energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riesz s-energy as a diversity indicator in evolutionary multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1168-1182. (<a href='https://doi.org/10.1109/TEVC.2024.3405197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the diversity of a Pareto front approximation (PFA) is critical when comparing the performance of multiobjective evolutionary algorithms (MOEAs). In the literature, some quality indicators (QIs) measure diversity according to their specific preferences. However, just a few QIs have mathematical properties proven. In this article, we propose the Riesz s-energy $(E_{s})$ as a QI to evaluate the diversity and spread of PFAs. Theoretical results show that $E_{s}$ holds 1) some of the Weitzman properties of a desirable diversity QI; 2) monotonicity; 3) the submodularity property (for $-E_{s}$ ); and 4) that it is invariant under rotations. We provide numerical evidence on the behavior of $E_{s}$ in both artificial PFAs and PFAs generated by state-of-the-art MOEAs. The mathematical properties that $E_{s}$ satisfies show its usefulness when it is utilized as a diversity QI in evolutionary multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Jesús Guillermo Falcón-Cardona and Lourdes Uribe and Pablo Rosas},
  doi          = {10.1109/TEVC.2024.3405197},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1168-1182},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Riesz s-energy as a diversity indicator in evolutionary multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A branch-and-bound enhanced cooperative evolutionary algorithm for the hybrid seru system scheduling considering worker heterogeneity. <em>TEVC</em>, <em>29</em>(4), 1153-1167. (<a href='https://doi.org/10.1109/TEVC.2024.3432745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid seru manufacturing mode widely exists in many real-world production enterprises, where workers are usually partially cross-trained due to high-training costs and employee turnover. However, the hybrid seru system scheduling problem considering worker heterogeneity (HSSWH) has rarely been studied in academia. To fill the gap, this article introduces a branch-and-bound enhanced cooperative evolutionary algorithm (BBCEA) to solve the HSSWH. Three core search components and an evaluation component are proposed in BBCEA, which are crafted to be problem-specific. In the exploration search component, a probability model sampling method and crossover collaborate to generate offspring with high quality and diversity. In the exploitation search component, five knowledge-based operators collaborate with a knowledge-guided operator selection strategy, which is designed by fully utilizing the problem properties and feedback information. In the exact search component, a branch-and-bound method is designed to solve the bottom layer subproblem precisely, which can greatly improve the effectiveness of the algorithm. In the evaluation component, a look-up table method is proposed to reduce computation effort by avoiding duplicate calculations. Numerical experimental results validate the superiority of the BBCEA in addressing the HSSWH, which can obtain the best solution on 95% of the instances compared with the state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Yuting Wu and Ling Wang and Jing-Fang Chen},
  doi          = {10.1109/TEVC.2024.3432745},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1153-1167},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A branch-and-bound enhanced cooperative evolutionary algorithm for the hybrid seru system scheduling considering worker heterogeneity},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained probabilistic pareto dominance for expensive constrained multiobjective optimization problems. <em>TEVC</em>, <em>29</em>(4), 1138-1152. (<a href='https://doi.org/10.1109/TEVC.2024.3394005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new parameterless constraint-handling technique, named constrained probabilistic Pareto dominance (CPPD), for expensive constrained multiobjective optimization problems (CMOPs). In CPPD, when comparing two solutions, in terms of each original objective, we design a new objective for each solution, which is the negative product of two probabilities calculated based on the predicted fitness mean values and uncertainty information provided by Kriging models: 1) the probability that this solution satisfies all constraints, denoted as Probability of Feasibility (PoF) and 2) the probability that this solution is better than the other on the original objective, denoted as PoB. It is evident that for each solution, PoF and PoB indicate its feasibility and its optimality on the corresponding original objective, respectively. Then, Pareto dominance based on new objectives is executed. As a result, both competitive feasible solutions and promising infeasible solutions with good diversity can be preserved by CPPD. These two kinds of solutions can help the population to exploit the located feasible parts and to explore new feasible parts, respectively. Further, based on CPPD, we develop a Pareto-based Kriging-assisted constrained multiobjective evolutionary algorithm (called PEA) to deal with expensive CMOPs with two or three objectives. Finally, PEA is generalized to solve expensive constrained many-objective optimization problems, named $\textrm {PEA}^{+}$ . The effectiveness of CPPD, PEA, and $\textrm {PEA}^{+}$ is verified by comprehensive experiments.},
  archive      = {J_TEVC},
  author       = {Zhiyao Zhang and Yong Wang and Guangyong Sun and Tong Pang and Ke Tang},
  doi          = {10.1109/TEVC.2024.3394005},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1138-1152},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained probabilistic pareto dominance for expensive constrained multiobjective optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRBench++: Principled benchmarking of symbolic regression with domain-expert interpretation. <em>TEVC</em>, <em>29</em>(4), 1127-1137. (<a href='https://doi.org/10.1109/TEVC.2024.3423681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic regression (SR) searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on specific, challenging subtasks of regression, such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-specific task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern SR algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of SR algorithms and highlight possible improvements for the benchmark itself.},
  archive      = {J_TEVC},
  author       = {F. O. de Franca and M. Virgolin and M. Kommenda and M. S. Majumder and M. Cranmer and G. Espada and L. Ingelse and A. Fonseca and M. Landajuela and B. Petersen and R. Glatt and N. Mundhenk and C. S. Lee and J. D. Hochhalter and D. L. Randall and P. Kamienny and H. Zhang and G. Dick and A. Simon and B. Burlacu and Jaan Kasak and Meera Machado and Casper Wilstrup and W. G. La Cava},
  doi          = {10.1109/TEVC.2024.3423681},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1127-1137},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {SRBench++: Principled benchmarking of symbolic regression with domain-expert interpretation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial AutoEncoder-based large-scale dynamic multiobjective evolutionary algorithm. <em>TEVC</em>, <em>29</em>(4), 1112-1126. (<a href='https://doi.org/10.1109/TEVC.2024.3412049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) are often scaled to large-scale scenarios in real-world applications, which inevitably must face the triple challenges of massive search space, dynamic environmental changes and multiobjective conflicts simultaneously. This article proposes an adversarial autoencoder-based large-scale dynamic multiobjective evolutionary framework. It integrates deep generative modeling techniques and large-scale multiobjective evolutionary algorithms (LMOEAs) to solve large-scale DMOPs effectively and efficiently. Specifically, an adversarial autoencoder-based deep generative network training architecture is proposed for high-dimensional decision variables in large-scale DMOPs. It can transfer a generative model trained on Pareto-optimal solutions in the current environment to a new environment using only the auxiliary information exhibited through the movement trajectories of historical Pareto-optimal solutions, resulting in the generation of quality initial populations for the new environment. Meanwhile, any proven LMOEA can be integrated into the proposed framework without extensive modifications. Experimental results on a typical dynamic multiobjective test suite with problem settings from 30 to 1000 dimensions demonstrate that the optimization performance of the proposed framework outperforms existing state-of-the-art designs. Especially in large-scale scenarios, the proposed framework is considered superior in terms of solution quality and computational efficiency.},
  archive      = {J_TEVC},
  author       = {Chenyang Li and Gary G. Yen and Zhenan He},
  doi          = {10.1109/TEVC.2024.3412049},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1112-1126},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adversarial AutoEncoder-based large-scale dynamic multiobjective evolutionary algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning in genetic programming: Guiding efficient data collection for symbolic regression. <em>TEVC</em>, <em>29</em>(4), 1100-1111. (<a href='https://doi.org/10.1109/TEVC.2024.3471341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines various methods of computing uncertainty and diversity for active learning in genetic programming. We found that the model population in genetic programming can be exploited to select informative training data points by using a model ensemble combined with an uncertainty metric. We explored several uncertainty metrics and found that differential entropy performed the best. We also compared two data diversity metrics and found that correlation as a diversity metric performs better than minimum Euclidean distance, although there are some drawbacks that prevent correlation from being used on all problems. Finally, we combined uncertainty and diversity using a Pareto optimization approach to allow both to be considered in a balanced way to guide the selection of informative and unique data points for training.},
  archive      = {J_TEVC},
  author       = {Nathan Haut and Wolfgang Banzhaf and Bill Punch},
  doi          = {10.1109/TEVC.2024.3471341},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1100-1111},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Active learning in genetic programming: Guiding efficient data collection for symbolic regression},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feedback learning-based memetic algorithm for energy-aware distributed flexible job-shop scheduling with transportation constraints. <em>TEVC</em>, <em>29</em>(4), 1085-1099. (<a href='https://doi.org/10.1109/TEVC.2024.3388527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing energy concerns and development of globalization, energy-aware scheduling and distributed scheduling have become significant topics in modern manufacturing. However, realistic manufacturing scenarios, such as collaborative scheduling of distributed shops and limited transportation resources, are rarely taken into account. To bridge the gap, this article addresses the energy-aware distributed flexible job-shop with transportation constraints (EDFJSP-T) and proposes a feedback learning-based memetic algorithm (FLMA) to minimize makespan and total energy consumption simultaneously. First, a mathematical model is formulated to represent the relationship between different subproblems. Additionally, an encoding and decoding method based on forward insertion is designed to reduce the search space and obtain high-quality schedules. Second, various problem-specific operators are designed to focus on different subproblems and objectives to enrich search patterns. Third, memetic search with feedback learning is proposed via introducing observer indexes for both population state and individual state to adaptively match appropriate operators for individuals. Besides, local intensification search with multiple operators is incorporated for low-density regions to further improve exploitation ability. The parameter setting is investigated and experimental tests are carried out using different types of instances. The comparisons demonstrate the effectiveness of the feedback learning mechanism and the superiority of the FLMA over existing algorithms for solving the EDFJSP-T.},
  archive      = {J_TEVC},
  author       = {Jingjing Wang and Honggui Han and Ling Wang},
  doi          = {10.1109/TEVC.2024.3388527},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1085-1099},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A feedback learning-based memetic algorithm for energy-aware distributed flexible job-shop scheduling with transportation constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective optimization problem with hardly dominated boundaries: Benchmark, analysis, and indicator-based algorithm. <em>TEVC</em>, <em>29</em>(4), 1070-1084. (<a href='https://doi.org/10.1109/TEVC.2024.3403414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardly dominated boundary (HDB) is commonly observed in multiobjective optimization problems (HDB-MOPs). However, there are only a few benchmark problems related to HDB-MOPs in the evolutionary computation community, which is insufficient to validate the performance of the multiobjective evolutionary algorithms (MOEAs). In this article, we first introduce a new set of HDB-MOPs characterized by various shapes of Pareto fronts and scalable HDB sizes. We then systematically analyze the capabilities of several representative existing MOEAs in handling HDB-MOPs and reveal their strengths and weaknesses in solving this type of problem. Finally, based on this insightful analysis, we propose an indicator-based MOEA with an adaptive reference point (denoted as IMOEA-ARP) to effectively address HDB-MOPs. The source codes of the proposed benchmark problems and the IMOEA-ARP algorithm are available from https://github.com/CIAM-Group/EvolutionaryAlgorithm_Codes/tree/main/IMOEA-ARP.},
  archive      = {J_TEVC},
  author       = {Zhenkun Wang and Kangnian Lin and Genghui Li and Weifeng Gao},
  doi          = {10.1109/TEVC.2024.3403414},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1070-1084},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective optimization problem with hardly dominated boundaries: Benchmark, analysis, and indicator-based algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multitree genetic programming for learning color and multiscale features in image classification. <em>TEVC</em>, <em>29</em>(4), 1055-1069. (<a href='https://doi.org/10.1109/TEVC.2024.3384021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-efficient image classification, which focuses on achieving accurate classification performance with limited labeled data, has garnered significant attention. Genetic programming (GP) has achieved impressive progress in image classification, particularly in scenarios involving small amounts of labeled data. GP research typically focuses on designing tree-based model representations to learn useful image features for classification. However, most GP methods are proposed for gray-scale images and ignore the color features. Furthermore, the existing GP methods typically learn features on a single scale/resolution, restricting potential accuracy enhancements. To address these issues, this article proposes a new multitree GP representation for image feature learning and classification. In each individual, three trees are included to extract discriminative features from the red, green, and blue channels of the image. With the new image resizing layer in the tree representation, the proposed approach can achieve multiscale feature extraction, i.e., flexibly learning fine-grained details and coarse-grained structures in the image, improving the classification performance. In addition, since a limitation of GP is premature convergence due to a decline in population diversity, this article develops a hybrid parent selection method consisting of tournament and lexicase selection to increase population diversity, find the best individual, and improve classification accuracy. The experiments on six image classification datasets indicate that the proposed approach outperforms state-of-the-art neural network-based and GP-based methods in almost all comparisons. Further analyses demonstrate the effectiveness of each component and the potentially high interpretability of the proposed approach.},
  archive      = {J_TEVC},
  author       = {Qinglan Fan and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3384021},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1055-1069},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multitree genetic programming for learning color and multiscale features in image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving high-dimensional expensive multiobjective optimization problems by adaptive decision variable grouping. <em>TEVC</em>, <em>29</em>(4), 1041-1054. (<a href='https://doi.org/10.1109/TEVC.2024.3383095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plenty of decision variable grouping-based algorithms have shown satisfactory performance in solving high-dimensional optimization problems. However, most of them are tailored for inexpensive optimization problems. Extending variable grouping method to expensive optimization problems poses many challenges. One of the greatest challenges is that most grouping approaches require additional function evaluations (FEs) to discover interactions among decision variables, which is intolerable for expensive optimization problems as it incurs prohibitive computational costs. To address this issue, an adaptive variable grouping method is proposed in this article, which can achieve relatively accurate grouping results without additional FE consumption. Specifically, variables are grouped based on the contrasts between well-converged solutions and poorly converged solutions. Furthermore, the grouping scheme is adjusted dynamically during the optimization process to improve the grouping accuracy. Besides, an adaptive environmental selection-based sampling strategy is suggested, which attempts to provide the currently required solutions for reevaluation according to the demands of different optimization stages. The proposed algorithm is compared with the other five state-of-the-art multiobjective optimization evolutionary algorithms on both benchmark and real-world problems. The experimental results demonstrate the promising performance and the superior computational efficiency of the proposed algorithm in tackling high-dimensional expensive multiobjective optimization problems.},
  archive      = {J_TEVC},
  author       = {Yingwei Li and Xiang Feng and Huiqun Yu},
  doi          = {10.1109/TEVC.2024.3383095},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1041-1054},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Solving high-dimensional expensive multiobjective optimization problems by adaptive decision variable grouping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature extraction with genetic programming for root cause identification in manufacturing with interpretable machine learning. <em>TEVC</em>, <em>29</em>(4), 1029-1040. (<a href='https://doi.org/10.1109/TEVC.2024.3388725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fault detection (FD) in manufacturing, various machine learning (ML) models have been widely applied to minimize human intervention and improve detection performance. Even though ML models, such as neural networks (NNs), have been shown to identify faults effectively, root cause identification (RCI) is becoming more difficult due to their black-box structures and the tradeoff between accuracy and interpretability. In order to improve performance while maintaining interpretability, we propose a new framework named Feature Extraction for finding Root causes for Manufacturing Applications with Tree-based algorithms (FERMAT), which enhances the performance of height-limited decision trees (DTs) (C4.5) through dimensionally aware genetic programming for feature extraction. Especially in FERMAT, only interpretable features are extracted to prevent DTs from delivering uninterpretable expressions to practitioners. In the present study, FERMAT’s applicability to RCI was verified with both manufacturing and nonmanufacturing datasets with different imbalance ratios. The experimental results showed that FERMAT outperformed the other single-tree-based models by extracting good features and delivered performance comparable to the black-box models.},
  archive      = {J_TEVC},
  author       = {Chan Gyu Lee and Sungbum Jun},
  doi          = {10.1109/TEVC.2024.3388725},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1029-1040},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Feature extraction with genetic programming for root cause identification in manufacturing with interpretable machine learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A divergence-based condition to ensure quantile improvement in black-box global optimization. <em>TEVC</em>, <em>29</em>(4), 1017-1028. (<a href='https://doi.org/10.1109/TEVC.2024.3452420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {black-box global optimization aims at minimizing an objective function whose analytical form is not known. To do so, many state-of-the-art methods rely on sampling-based strategies, where sampling distributions are built in an iterative fashion, so that their mass concentrate where the objective function is low. Despite empirical success, the theoretical study of these methods remains difficult. In this work, we introduce a new framework, based on divergence-decrease conditions, to study and design black-box global optimization algorithms. Our approach allows to establish and quantify the improvement of sampling distributions at each iteration, in terms of expected value or quantile of the objective. We show that the information-geometric optimization approach fits within our framework, yielding a new approach for its analysis. We also establish sampling distribution improvement results for two novel algorithms, one related with the cross-entropy approach with mixture models, and another one using heavy-tailed sampling distributions.},
  archive      = {J_TEVC},
  author       = {Thomas Guilmeau and Emilie Chouzenoux and Víctor Elvira},
  doi          = {10.1109/TEVC.2024.3452420},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1017-1028},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A divergence-based condition to ensure quantile improvement in black-box global optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superpixel segmentation-based evolutionary multitasking algorithm for feature selection of hyperspectral images. <em>TEVC</em>, <em>29</em>(4), 1002-1016. (<a href='https://doi.org/10.1109/TEVC.2024.3392749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a very important technique for hyperspectral image (HSI) classification, as successfully selecting informative features can significantly increase the learning performance while reducing the computational cost. However, most of the existing FS methods tend to treat the HSI as a whole for FS, which does not fully consider the unique characteristics of HSIs and disregards the fact that different feature classes possess varying preferences for features. Thus, this article proposes a superpixel segmentation-based evolutionary multitasking (EMT) algorithm for FS of HSIs, called SS-EMT. First, the superpixel segmentation method is used to partition the original HSI into several superpixel blocks, which can preserve well the information of different classes of the original image. Second, in order to explore each superpixel block efficiently, an EMT algorithm using particle swarm optimization is designed, which treats each superpixel block as a subtask and then optimizes these subtasks collaboratively by transferring useful knowledge among related subtasks. In addition, a new individual evaluation mechanism is devised to obtain multiple high-quality feature subsets with different numbers of features simultaneously in a single run, thus reducing the computational cost. Finally, extensive experimental results on four common HSI datasets under three classifiers validate that our proposed method outperforms several state-of-the-art FS methods.},
  archive      = {J_TEVC},
  author       = {Lingjie Li and Yuze Zhang and Qiuzhen Lin and Zhong Ming and Carlos A. Coello Coello and Victor C. M. Leung},
  doi          = {10.1109/TEVC.2024.3392749},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1002-1016},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Superpixel segmentation-based evolutionary multitasking algorithm for feature selection of hyperspectral images},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Indexes-based and partial restart-based constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 990-1001. (<a href='https://doi.org/10.1109/TEVC.2024.3400610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems often have complex feasible regions and constrained Pareto fronts. These factors bring great challenges to current constrained multiobjective optimization evolutionary algorithms (CMOEAs). To solve this problem and further balance the objective optimization and constraint satisfaction, we propose an indexes-based and partial restart-based constrained multiobjective optimization (IRCMO) algorithm. In IRCMO, a two-stage (i.e., development and enhancement) and tri-population framework is designed. IRCMO adopts the aggregative indexes-based evaluation and adaptive collaborative partial restart strategy to assist the evolution of the first and second populations. The third population is obtained by directed sampling, which is mostly located at the boundary of the feasible region and enhances the exploration ability of extreme solutions. At the end of each generation, a progressive dual-archive strategy is designed to screen the solutions distributed uniformly from three populations. Experimental results demonstrate that IRCMO is superior to the other six state-of-the-art CMOEAs on several constraint benchmark suites and real-world problems.},
  archive      = {J_TEVC},
  author       = {Zhen Yang and Tangxu Yao and Yunliang Jiang and Jun Zhang and Xiongtao Zhang},
  doi          = {10.1109/TEVC.2024.3400610},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {990-1001},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Indexes-based and partial restart-based constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming combinatorial optimization problems in fourier space: Consequences and uses. <em>TEVC</em>, <em>29</em>(4), 977-989. (<a href='https://doi.org/10.1109/TEVC.2024.3457268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze three permutation-based combinatorial optimization problems in Fourier space, namely, the quadratic assignment problem, the linear ordering problem (LOP), and the symmetric and nonsymmetric traveling salesperson problem (STSP). In previous studies, one can find a number of theorems with necessary conditions that the Fourier coefficients of the aforementioned problems must satisfy. In this manuscript, we prove the sufficiency of these conditions, which implies that they constitute the exact characterization of the problems in Fourier space. In addition, the Fourier coefficients of the LOP and the symmetric and non-STSP are completely characterized by showing certain proportionality patterns that they must follow. Taking the characterization in Fourier space of the problems as a basis, we study classes of equivalent instances of the LOP and the symmetric and non-STSP, considering that two instances are equivalent if they have the same objective function. Furthermore, we give canonical representations for each problem in such a way that the input matrices have the minimum number of nonzero parameters.},
  archive      = {J_TEVC},
  author       = {Anne Elorza and Xabier Benavides and Josu Ceberio and Leticia Hernando and Jose A. Lozano},
  doi          = {10.1109/TEVC.2024.3457268},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {977-989},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Transforming combinatorial optimization problems in fourier space: Consequences and uses},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual-source and virtual-swarm-based particle swarm optimizer for large-scale multisource location via robot swarm. <em>TEVC</em>, <em>29</em>(4), 963-976. (<a href='https://doi.org/10.1109/TEVC.2024.3391622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisource location is a significant application in the field of robot swarm and is required to find all sources whose number and distribution are unknown in advance. With few parameters and fast search, particle swarm optimizer (PSO) variants that have certain grouping capability have been applied to address multisource location problems (MSLPs) by dividing a swarm such that every source has robots to locate. However, they are difficult to predetermine the exact number of groups, require a big number of robots, and are easily trapped in the no-signal areas when the proportion of no-signal areas is high. This work proposes a virtual-source and virtual-swarm-based PSO (VVPSO) to divide a search area into multiple cells equally, each of which has a virtual source in its center. Then, instead of robots grouping, only one group of robots is employed to traverse all virtual sources, and search their corresponding cells to locate real sources by a new PSO called real-virtual mapping PSO (RMPSO). RMPSO asymmetrically maps a robot into a particle swarm with multiple virtual particles to perform PSO, which greatly reduces the requirements for the number of robots. Experimental results show that VVPSO has great search scalability and can solve large-scale MSLPs than two state-of-the-art grouping methods and three representative multimodal PSO variants, even with only one robot. Hence, this work greatly advances the field of multisource location by using mobile robot swarm.},
  archive      = {J_TEVC},
  author       = {Junqi Zhang and Yuxuan Lin and MengChu Zhou},
  doi          = {10.1109/TEVC.2024.3391622},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {963-976},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Virtual-source and virtual-swarm-based particle swarm optimizer for large-scale multisource location via robot swarm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-based directional improvement prediction for dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 948-962. (<a href='https://doi.org/10.1109/TEVC.2024.3393151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, dynamic multiobjective evolutionary algorithms (DMOEAs) using the prediction strategy have shown promising performance for solving dynamic multiobjective optimization problems (DMOPs), as they can predict environmental changing trends in advance. However, most of them follow a regular change pattern and thus their performance is compromised when solving DMOPs with irregular change patterns (e.g., nonlinear correlations). To alleviate this challenge, this article proposes a DMOEA with a learnable prediction for tackling DMOPs. Specifically, a neural network is designed to effectively capture diverse change patterns of the environment. Based on the change patterns learned, a directional improvement prediction (DIP) is developed to guide the evolutionary search toward promising directions in the decision space. In this way, a superior initial population with good convergence and diversity is predicted by DIP, which can be more effective for solving various DMOPs. Comprehensive empirical studies show that the proposed DIP is effective and the proposed algorithm has some advantages over five competitive DMOEAs when solving three commonly used benchmarks and one real-world problem.},
  archive      = {J_TEVC},
  author       = {Yulong Ye and Songbai Liu and Junwei Zhou and Qiuzhen Lin and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3393151},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {948-962},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning-based directional improvement prediction for dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis for mixed-variable problems. <em>TEVC</em>, <em>29</em>(4), 936-947. (<a href='https://doi.org/10.1109/TEVC.2024.3399560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploratory landscape analysis (ELA) and fitness landscape analysis in general have given valuable insight into problem hardness understanding as well as facilitating algorithm design and endeavors, such as automated algorithm selection (AAS) and configuration. These techniques have largely been limited to search spaces of a single domain. In this work, we provide the means to compute exploratory landscape features for mixed-variable problems where the decision space is a mixture of continuous, binary, integer, and categorical variables. This is achieved by introducing a preprocessing scheme which needs to be incorporated into the process of ELA feature generation. To highlight the merit of our approach for practical applications, we design and conduct an AAS study based on a hyperparameter optimization benchmark suite and our preprocessing scheme. Our trained algorithm selector is able to close the gap between the single best and the virtual best solver by 57.5% over all benchmark problems.},
  archive      = {J_TEVC},
  author       = {Raphael Patrick Prager and Heike Trautmann},
  doi          = {10.1109/TEVC.2024.3399560},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {936-947},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exploratory landscape analysis for mixed-variable problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computationally expensive high-dimensional multiobjective optimization via surrogate-assisted reformulation and decomposition. <em>TEVC</em>, <em>29</em>(4), 921-935. (<a href='https://doi.org/10.1109/TEVC.2024.3380327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, various surrogate-assisted evolutionary algorithms (SAEAs) have been proposed to solve computationally expensive multiobjective optimization problems (EMOPs). Nevertheless, designing an SAEA to handle high-dimensional EMOPs and balance convergence, diversity, and computational complexity remains challenging. Here, we propose a two-phase SAEA (TP-SAEA), which follows the idea of convergence first and diversity second, for solving high-dimensional EMOPs. In Phase I, a surrogate-assisted problem reformulation method is proposed to fast-track the Pareto optimal set in association with some reference solutions. Specifically, the high-dimensional EMOP is reformulated into an expensive single-objective one with low-dimensional decision space. Then, the surrogate-assisted optimization is utilized to obtain well-converged solutions. In Phase II, the high-dimensional EMOP is decomposed into two subproblems to explore subregions of the decision space that can effectively promote the diversity of the solutions. The two subproblems are optimized independently via surrogate-assisted optimization, aiming to push the population toward different regions of the Pareto optimal front. Experiments are conducted on EMOPs with 100 to 500 decision variables compared with four state-of-the-art SAEAs. The proposed TP-SAEA obtains well-converged and diverse solutions with only 509 real function evaluations. Moreover, its superiority is examined in six real-world instances with up to 12 000 decision variables.},
  archive      = {J_TEVC},
  author       = {Linqiang Pan and Jianqing Lin and Handing Wang and Cheng He and Kay Chen Tan and Yaochu Jin},
  doi          = {10.1109/TEVC.2024.3380327},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {921-935},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Computationally expensive high-dimensional multiobjective optimization via surrogate-assisted reformulation and decomposition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiagent swarm optimization with adaptive internal and external learning for complex consensus-based distributed optimization. <em>TEVC</em>, <em>29</em>(4), 906-920. (<a href='https://doi.org/10.1109/TEVC.2024.3380436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization has attracted lots of attention in recent years. Thanks to the intrinsic parallelism and great search capacity, evolutionary computation (EC) has the potential for black-box and nonconvex distributed optimization. However, due to the decentralization of local objective functions, it is challenging to optimize the global objective function with efficient communication and guaranteed system consensus. To tackle this challenge, we propose a multiagent swarm optimization method with adaptive internal and external learning (MASOIE). In MASOIE, each agent evolves a swarm of particles by internal learning and external learning. Internal learning enables agents to optimize their local objectives, while external learning enables agents to cooperate to achieve a consensus toward the global objective. To improve the consensus ability, we design a special velocity setting of external learning for particle evolution. We provide the theoretical analysis of the system consensus of deterministic MASOIE. To improve communication efficiency, we design an adaptive communication mechanism to adjust the communication interval, enabling agents to explore at the early stage and reach system consensus at the later stage. Empirical studies show that the proposed algorithm achieves stable consensus performance, competitive solution quality and lower communication cost on benchmark functions compared with existing black-box distributed algorithms.},
  archive      = {J_TEVC},
  author       = {Tai-You Chen and Wei-Neng Chen and Feng-Feng Wei and Xiao-Min Hu and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3380436},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {906-920},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiagent swarm optimization with adaptive internal and external learning for complex consensus-based distributed optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation guarantees for the nondominated sorting genetic algorithm II (NSGA-II). <em>TEVC</em>, <em>29</em>(4), 891-905. (<a href='https://doi.org/10.1109/TEVC.2024.3402996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent theoretical works have shown that the NSGA-II efficiently computes the full Pareto front when the population size is large enough. In this work, we study how well it approximates the Pareto front when the population size is smaller. For the OneMinMax benchmark, we point out situations in which the parents and offspring cover well the Pareto front, but the next population has large gaps on the Pareto front. Our mathematical proofs suggest as reason for this undesirable behavior that the NSGA-II in the selection stage computes the crowding distance once and then removes individuals with smallest crowding distance without considering that a removal increases the crowding distance of some individuals. We then analyse two variants not prone to this problem. For the NSGA-II that updates the crowding distance after each removal [Kukkonen and Deb (2006)] and the steady-state NSGA-II [Nebro and Durillo (2009)], we prove that the gaps in the Pareto front are never more than a small constant factor larger than the theoretical minimum. This is the first mathematical work on the approximation ability of the NSGA-II and the first runtime analysis for the steady-state NSGA-II. Experiments also show the superior approximation ability of the two NSGA-II variants.},
  archive      = {J_TEVC},
  author       = {Weijie Zheng and Benjamin Doerr},
  doi          = {10.1109/TEVC.2024.3402996},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {891-905},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Approximation guarantees for the nondominated sorting genetic algorithm II (NSGA-II)},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptation of multirecombinant evolution strategies on the highly multimodal rastrigin function. <em>TEVC</em>, <em>29</em>(4), 880-890. (<a href='https://doi.org/10.1109/TEVC.2024.3400857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-adaptive, multirecombinative $(\mu /\mu _{I},\lambda)$ -Evolution strategy (ES) is investigated on the highly multimodal Rastrigin test function by theoretical and experimental means. The analysis is based on the established dynamical systems approach. To this end, the self-adaptation response (SAR) function is derived in the limit of large populations, which are necessary to achieve high success rates. Furthermore, steady-state conditions on Rastrigin are discussed and compared to the sphere function. Then, a relation for the learning parameter $\tau $ is derived to tune the sampling process of the self-adaptive ES, improving its efficiency on Rastrigin. The obtained result is compared to default $\tau $ -values. Furthermore, expected runtime experiments are conducted varying $\tau $ and population parameters of the ES. Theoretical and experimental results regarding $\tau $ are compared in terms of efficiency and robustness showing good agreement.},
  archive      = {J_TEVC},
  author       = {Amir Omeradzic and Hans-Georg Beyer},
  doi          = {10.1109/TEVC.2024.3400857},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {880-890},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Self-adaptation of multirecombinant evolution strategies on the highly multimodal rastrigin function},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to Expand/Contract pareto sets in dynamic multiobjective optimization with a changing number of objectives. <em>TEVC</em>, <em>29</em>(4), 865-879. (<a href='https://doi.org/10.1109/TEVC.2024.3375751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) with a changing number of objectives (NObjs) may have Pareto-optimal set (PS) manifold expanding or contracting over time. Knowledge transfer has been used for solving DMOPs, since it can transfer useful information from solving one problem instance to solve another related problem instance. However, we show that the state-of-the-art transfer approach based on heuristic lacks diversity on problem with extremely strong bias and loses convergence on problems with multimodality and variable correlation, after the NObjs increases and decreases, respectively. Therefore, we propose a novel transfer strategy based on learning, called learning to expand and contract PS (denoted as LEC) for enhancing diversity and convergence after NObj increases and decreases, respectively. It first learns potentially good directions for expansion and contraction separately via principal component analysis. Then, the most promising expansion and contraction directions are selected from their candidates according to whether they help diversity and convergence, respectively. Finally, PS is learned to be expanded and contracted based on these most promising directions. Comprehensive studies using 13 DMOP benchmarks with a changing NObjs demonstrate that our proposed LEC is effective on improving solution quality, not only right after changes but also after optimization of different generations, compared to state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Gan Ruan and Leandro L. Minku and Stefan Menzel and Bernhard Sendhoff and Xin Yao},
  doi          = {10.1109/TEVC.2024.3375751},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {865-879},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning to Expand/Contract pareto sets in dynamic multiobjective optimization with a changing number of objectives},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic programming with flexible region detection for fine-grained image classification. <em>TEVC</em>, <em>29</em>(4), 853-864. (<a href='https://doi.org/10.1109/TEVC.2024.3379257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image classification (FGIC) is an important computer vision task with many real-world applications. However, FGIC is challenging due to intraclass variations and interclass similarities, especially when there is limited training data. To address these challenges, a new genetic programming approach with flexible region detection (GP-RD), is proposed for different FGIC tasks, i.e., flower and fish classification tasks. The proposed GP-RD approach can automatically highlight the object, detect regions of interest, extract effective features, and combine global, local, and/or color features for classification. The performance of GP-RD is evaluated on flower and fish classification tasks within the FGIC domain, utilizing datasets with varying classes. In comparison with seven benchmark methods, GP-RD achieves significantly better performance in most comparisons. Further analysis demonstrates the interpretability, effectiveness, and efficiency of the proposed approach.},
  archive      = {J_TEVC},
  author       = {Qinyu Wang and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3379257},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {853-864},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming with flexible region detection for fine-grained image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interval multiobjective evolutionary generation algorithm for product design change plans in uncertain environments. <em>TEVC</em>, <em>29</em>(3), 836-850. (<a href='https://doi.org/10.1109/TEVC.2024.3378774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design change is an important issue in complex product development projects. In a complex product with numerous parts (also known as components), the change of one key part may spread to other parts associated with it, generating a chain reaction throughout the entire project. Therefore, it is necessary to select a suitable change plan involving only fewer crucial parts in order to enhance the product’s performance, minimize change cost, and reduce change duration/time. Focusing on the case where the correlation strength between parts cannot be accurately obtained, in this article we study an interval multiobjective evolutionary algorithm for finding excellent design change plans. First, on the basis of the established multilayer product network with interval correlation weights, an interval multiobjective optimization model of the product design change planning problem is established, where three new objective functions regarding product performance, carbon trading cost and supply risk are defined. Then, a constraint multiobjective evolutionary algorithm based on interval Pareto dominance is proposed to search for optimal change plans. Several novel operators, including the problem characteristic-guided population update strategy, the probability-based interval Pareto dominance, and the interval constraint handling strategy, are developed to enhance the algorithm’s performance. Finally, the proposed algorithm is compared with eight existing algorithms on the two design change cases, experimental results revealed its effectiveness.},
  archive      = {J_TEVC},
  author       = {Rui-Zhao Zheng and Yong Zhang and Xiao-Yan Sun and Dun-Wei Gong and Xiao-Zhi Gao},
  doi          = {10.1109/TEVC.2024.3378774},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {836-850},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An interval multiobjective evolutionary generation algorithm for product design change plans in uncertain environments},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional order differential evolution. <em>TEVC</em>, <em>29</em>(3), 822-835. (<a href='https://doi.org/10.1109/TEVC.2024.3382047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a widely recognized method to solve complex optimization problems as shown by many researchers. Yet, nonadaptive versions of DE suffer from insufficient exploration ability and uses no historical information for its performance enhancement. This work proposes fractional order DE (FODE) to enhance DE performance from two aspects. First, a bi-strategy co-deployment framework is proposed. The population-based and parameter-based strategies are combined to leverage their respective advantages. Second, the fractional order (FO) calculus is first applied to the differential vector to enhance DE’s exploration ability by using the historical information of populations, and ensures the diversity of population in an evolutionary process. We use the 2017 IEEE congress on evolutionary computation (CEC) test functions, and CEC2011 real-world problems to evaluate FODE’s performance. Its sensitivity to parameter changes is discussed and an ablation study of multistrategies is systematically performed. Furthermore, the variations of exploration and exploitation in FODE are visualized and analyzed. Experimental results show that FODE is superior to other state-of-the-art DE variants, the winners of CEC competitions, other FO calculus-based algorithms, and some powerful variants of classic algorithms.},
  archive      = {J_TEVC},
  author       = {Kaiyu Wang and Shangce Gao and MengChu Zhou and Zhi-Hui Zhan and Jiujun Cheng},
  doi          = {10.1109/TEVC.2024.3382047},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {822-835},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Fractional order differential evolution},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive multitasking for computational resource allocation in evolutionary-constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 809-821. (<a href='https://doi.org/10.1109/TEVC.2024.3376729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) have multiple objective functions that need to be optimized and constraints need to be satisfied, making them difficult to solve. Based on the multitasking optimization, the optimization of the original CMOP can be transformed into multiple related subtasks. Existing multitasking-based constrained multiobjective optimization evolutionary algorithms assist the evolution of the original problem by adopting auxiliary tasks. However, this approach may waste computational resources on tasks that are unsuitable for evolutionary states and dynamics. In this article, a new competitive multitasking-based framework is proposed for CMOPs. We maintain an archive for the constrained Pareto front (CPF) and multiple subtasks as auxiliaries. In each iteration, one of the subtasks is selected as the main task, and offspring are generated from its evolution. The offspring are viewed as knowledge and fed back to auxiliary tasks. The reward is mapped to a selection probability to control the main task selection in each iteration. Computational resources are saved by allocating only to the main task that is better suited for different evolutionary stages of different problems. The effectiveness of our approach is validated through experiments on four CMOP benchmark suites compared to 11 state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Xiaoliang Chu and Fei Ming and Wenyin Gong},
  doi          = {10.1109/TEVC.2024.3376729},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {809-821},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Competitive multitasking for computational resource allocation in evolutionary-constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved evolutionary multitasking optimization algorithm with similarity evaluation of search behavior. <em>TEVC</em>, <em>29</em>(3), 794-808. (<a href='https://doi.org/10.1109/TEVC.2024.3373131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task similarity is a major requisite to trigger knowledge sharing in evolutionary multitasking optimization (EMTO). Unfortunately, most of the existing EMTO algorithms only focus on the similarity between population distributions of tasks, but ignore the search behavior of populations, which may degrade the performance of cross-task knowledge sharing. Motivated by this, an improved EMTO algorithm with similarity evaluation of search behavior (SESB-IEMTO), employing the particle swarm optimization (PSO) algorithm as a task solver for each task, is proposed. It comprises three key elements: 1) a dynamic similarity-based evaluation strategy; 2) a cross-task knowledge adaptation method; and 3) a search direction-sharing mechanism. Primarily, the source tasks with similar search behavior are discriminated with the dynamic similarity-based evaluation strategy, where individuals can be fully exploited for cross-task evolution. Then, the knowledge derived from these source tasks is regulated by the cross-task knowledge adaption method for alleviating the risk of negative transfer caused by the heterogeneity between tasks. Moreover, to further promote knowledge sharing between tasks, the search direction-sharing mechanism is developed to navigate tasks efficiently searching for promising regions. Finally, the convergence of SESB-IEMTO is analyzed, and the effectiveness and superiority are also verified with the experiments on several benchmark tests and a real-world application study.},
  archive      = {J_TEVC},
  author       = {Xiaolong Wu and Wei Wang and Tengfei Zhang and Honggui Han and Junfei Qiao},
  doi          = {10.1109/TEVC.2024.3373131},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {794-808},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Improved evolutionary multitasking optimization algorithm with similarity evaluation of search behavior},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted evolutionary framework for expensive multitask optimization problems. <em>TEVC</em>, <em>29</em>(3), 779-793. (<a href='https://doi.org/10.1109/TEVC.2024.3370937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a surrogate-assisted evolutionary framework (called SELF) to solve expensive multitask optimization problems (ExMTOPs). SELF consists of two main phases: 1) global knowledge transfer phase and 2) local knowledge transfer phase. In the former, a multitask Gaussian process model (MTGP) is established by fusing previously evaluated solutions of multiple optimization tasks. MTGP can capture task-relevant information and the knowledge of landscapes. Then, differential evolution assisted with MTGP is proposed to preselect high-quality candidates. During the preselection, the knowledge of landscapes is transferred among multiple optimization tasks for locating promising regions quickly. In the latter, for each optimization task, Bayesian optimization is adopted to improve the quality of the best individual in the population. Moreover, the improved best individuals in the populations of multiple optimization tasks are adaptively transferred based on a transfer probability, which is computed through the task-relevant information provided by MTGP. By combining these two phases, SELF not only achieves the tradeoff between exploration and exploitation, but also utilizes the global and local knowledge transfer to improve the efficiency for solving ExMTOPs. We test SELF on seven benchmark test problems in the IEEE CEC2017 evolutionary multitask optimization competition. The results demonstrate that the performance of SELF is better than that of other seven advanced methods. In addition, we also apply SELF to deal with two real-world ExMTOPs. The designs provided by SELF exhibit the best performance among all the compared methods, verifying the potential of SELF in practical engineering applications.},
  archive      = {J_TEVC},
  author       = {Shenglian Tan and Yong Wang and Guangyong Sun and Tong Pang and Ke Tang},
  doi          = {10.1109/TEVC.2024.3370937},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {779-793},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A surrogate-assisted evolutionary framework for expensive multitask optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOEA/D with Spatial–Temporal topological tensor prediction for evolutionary dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 764-778. (<a href='https://doi.org/10.1109/TEVC.2024.3367747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving dynamic multiobjective optimization problems, most evolutionary algorithms (EAs) attempt to predict the initial population in a new environment by mining the relationships between solutions during historical environment changes. However, the complex relationships between solutions and the limited amount of available data often make it difficult to extract useful information efficiently, which may deteriorate the prediction accuracy. To address this problem, this article proposes a spatial–temporal topological tensor-based prediction method to generate the initial population in a new environment under the decomposition framework of MOEA/D. The method relies on the idea that the population distribution in each environment has topological similarity along the time dimension in the objective space, which makes it efficient to represent the population distribution in terms of a tensor and predict new solutions along each decomposition axis in a new environment by an improved tensor-based multishort time series prediction method. Experimental results on various benchmark problems and a real-world problem show that the proposed method is competitive or even superior to state-of-the-art dynamic multiobjective EAs based on prediction strategies.},
  archive      = {J_TEVC},
  author       = {Xianpeng Wang and Yumeng Zhao and Lixin Tang and Xin Yao},
  doi          = {10.1109/TEVC.2024.3367747},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {764-778},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MOEA/D with Spatial–Temporal topological tensor prediction for evolutionary dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary trainer-based deep Q-network for dynamic flexible job-shop scheduling. <em>TEVC</em>, <em>29</em>(3), 749-763. (<a href='https://doi.org/10.1109/TEVC.2024.3367181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic flexible job-shop scheduling (DFJSS) aims to achieve the optimal efficiency for production planning in the face of dynamic events. In practice, deep $Q$ -network (DQN) algorithms have been intensively studied for solving various DFJSS problems. However, these algorithms often cause moving targets for the given job-shop state. This will inevitably lead to unstable training and severe deterioration of the performance. In this article, we propose a training algorithm based on genetic algorithm to efficiently and effectively address this critical issue. Specifically, a state feature extraction method is first developed, which can effectively represent different job-shop scenarios. Furthermore, a genetic encoding strategy is designed, which can reduce the encoding length to enhance search ability. In addition, an evaluation strategy is proposed to calculate a fixed target for each job-shop state, which can avoid the parameter update of target networks. With the designs, the DQNs could be stably trained, thus their performance is greatly improved. Extensive experiments demonstrate that the proposed algorithm outperforms the state-of-the-art peer competitors in terms of both effectiveness and generalizability to multiple scheduling scenarios with different scales. In addition, the ablation study also reveals that the proposed algorithm can outperform the DQN algorithms with different updating frequencies of target networks.},
  archive      = {J_TEVC},
  author       = {Yun Liu and Fangfang Zhang and Yanan Sun and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3367181},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {749-763},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary trainer-based deep Q-network for dynamic flexible job-shop scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cooperative ant colony system for multiobjective multirobot task allocation with precedence constraints. <em>TEVC</em>, <em>29</em>(3), 734-748. (<a href='https://doi.org/10.1109/TEVC.2024.3364493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world scenarios (e.g., product manufacturing), multiple heterogeneous robots cooperate to complete complex tasks with precedence constraints. In these heterogeneous multirobot systems, the multirobot task allocation problem is important and has attracted increasing attention. The problem usually involves multiple optimization objectives for decision making. However, existing approaches meet challenges on multiobjective problems with large-scale tasks and precedence constraints in terms of solution diversity and convergence. Therefore, this article formulates a tri-objective model and proposes a cooperative ant colony system (CACS) to optimize three objectives, i.e., minimizing the makespan, average robot traveling time, and average task waiting time. In CACS, three ant colonies are created to simultaneously optimize the three objectives. To coordinate with the precedence constraints of the problem, solutions are encoded as a task-alliance sequence. A new solution construction method is developed to generate feasible solutions using dynamic heuristic information and two pheromone matrices. Particularly, one matrix deposits pheromone between tasks for task selection and the other between tasks and robots for alliance building. To further improve solution diversity and convergence, a fusion-based local search is adopted to generate high-quality solutions by combining information from multiple colonies. Thirty instances are constructed with different numbers of tasks and robots under complex precedence constrains. Experimental results show that CACS outperforms state-of-the-art methods in terms of the inverted generational distance and hypervolume metrics.},
  archive      = {J_TEVC},
  author       = {Tong Qian and Xiao-Fang Liu and Yongchun Fang},
  doi          = {10.1109/TEVC.2024.3364493},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {734-748},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A cooperative ant colony system for multiobjective multirobot task allocation with precedence constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the efficiency of the distance-based hypervolume estimation using ND-tree. <em>TEVC</em>, <em>29</em>(3), 726-733. (<a href='https://doi.org/10.1109/TEVC.2024.3391857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume is most likely the most often used quality indicator in evolutionary multiobjective optimization (EMO) due to its monotonicity with respect to the dominance relation. Since, however, exact calculation of hypervolume is computationally demanding, many researchers have proposed methods for hypervolume estimation. Many of such methods use numerical integration of the distance from the reference point to the upper boundary of the dominated region along uniformly sampled directions. To find this distance for a given direction, the maximum value of the inverse weighted Chebycheff function needs to be found. For small solution sets this could be done by the exhaustive search which, however, may be very inefficient for large solution sets, e.g., for unbounded external archives of the EMO algorithms. In this article, we adapt the ND-Tree-based algorithm for finding the minimum of the standard weighted Chebycheff function to finding the maximum of the inverse function. Through a computational experiment we show that this ND-Tree-based algorithm may be used either for reduction of the running time of hypervolume estimation by up to two orders of magnitude or for improving the estimation accuracy with the same time budget up to an order of magnitude for data sets with up to 12 objectives and 50 000 points.},
  archive      = {J_TEVC},
  author       = {Andrzej Jaszkiewicz and Piotr Zielniewicz},
  doi          = {10.1109/TEVC.2024.3391857},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {726-733},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Improving the efficiency of the distance-based hypervolume estimation using ND-tree},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A classifier-ensemble-based surrogate-assisted evolutionary algorithm for distributed data-driven optimization. <em>TEVC</em>, <em>29</em>(3), 711-725. (<a href='https://doi.org/10.1109/TEVC.2024.3361000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) have achieved effective performance in solving complex data-driven optimization problems. In the Internet of Things environment, the data of many problems are collected and processed in distributed network nodes and cannot be transmitted. As each local node can only access and build surrogate models based on partial data, local models are usually not accurate and even conflicting. To address these challenges, this article proposes a classifier-ensemble-based surrogate-assisted evolutionary algorithm (CESAEA) with the following features. First, the local nodes in CESAEA train classifiers as surrogate models based on their own data to classify candidates into several levels according to their fitness quality. The classifiers are less sensitive to the partial and biased data than regression models in local nodes. Second, the central node in CESAEA ensembles the local surrogates to form a global classifier with a relaxation condition to guide the evolutionary optimizer to generate promising candidates. The relaxation condition helps to overcome the problem of local model inconsistency. Overall, CESAEA is composed of local classifier construction, global classifier ensemble, classifier-assisted evolutionary optimization and local regression-assisted selection. As only classifiers are allowed to transmit from local nodes to the central node, the mapping relationship between decision vector and objective is hidden and thus data privacy is protected. The experimental results on benchmark functions as well as distributed feature selection problems verify the effectiveness of CESAEA compared to several state-of-the-art approaches.},
  archive      = {J_TEVC},
  author       = {Xiao-Qi Guo and Feng-Feng Wei and Jun Zhang and Wei-Neng Chen},
  doi          = {10.1109/TEVC.2024.3361000},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {711-725},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A classifier-ensemble-based surrogate-assisted evolutionary algorithm for distributed data-driven optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear subspace surrogate modeling for large-scale expensive Single/Multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 697-710. (<a href='https://doi.org/10.1109/TEVC.2023.3319640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that the surrogate-assisted evolutionary algorithms have achieved great success in addressing expensive optimization problems, they still suffer from stiff challenges when the number of dimensions of problems becomes large. The primary reason lies in that it is very hard to build an acceptable surrogate model in the high-dimensional search space with small amounts of evaluated historical data in evolution. To tackle this issue, we suggest an effective surrogate modeling method for large-scale expensive optimization in this article, where the models are built on a number of linear subspaces instead of the original search space. Specifically, a linear subspace is constructed by a pair of points/solutions which are generated based on the set of elite solutions. For each linear subspace, several historical solutions are first associated according to their distance to the linear subspace, and then a surrogate model is trained by the associated solutions and used to evaluate the offspring. To ensure the exploration and exploitation capacity of the proposed method, these linear subspaces and the surrogate models are updated after a few iterations. Experimental results on CEC’2010 and CEC’2013 single-objective optimization problems with up to 1500 decision variables show that the proposed algorithm is superior over six comparison algorithms. Moreover, we also extend the proposed algorithm to multiobjective optimization problems and verified its competitiveness on problems with up to 1500 decision variables.},
  archive      = {J_TEVC},
  author       = {Langchun Si and Xingyi Zhang and Ye Tian and Shangshang Yang and Limiao Zhang and Yaochu Jin},
  doi          = {10.1109/TEVC.2023.3319640},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {697-710},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Linear subspace surrogate modeling for large-scale expensive Single/Multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on evolutionary computation-based drug discovery. <em>TEVC</em>, <em>29</em>(3), 676-696. (<a href='https://doi.org/10.1109/TEVC.2024.3382145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug discovery is an expensive and risky process. To combat the challenges in drug discovery, an increasing number of researchers and pharmaceutical companies recognize the benefits of utilizing computational techniques. Evolutionary computation (EC) offers promise as most drug discovery problems are essentially complex optimization problems beyond conventional optimization algorithms. EC methods have been widely applied to solve these complex optimization problems especially in lead compound generation and molecular virtual evaluation, substantially speeding up the process of drug discovery and development. This article presents a comprehensive survey of EC-based drug discovery methods. Particularly, a new taxonomy of the methods is provided and the advantages and limitations of the methods are reviewed. In addition, the potential future directions of EC-based drug discovery are discussed and the publicly available resources, including databases and computational tools are compiled for the convenience of researchers seeking to pursue this field.},
  archive      = {J_TEVC},
  author       = {Qiyuan Yu and Qiuzhen Lin and Junkai Ji and Wei Zhou and Shan He and Zexuan Zhu and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3382145},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {676-696},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary computation-based drug discovery},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective mixed-integer quadratic models: A study on mathematical programming and evolutionary computation. <em>TEVC</em>, <em>29</em>(3), 661-675. (<a href='https://doi.org/10.1109/TEVC.2024.3374519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the current literature on multiobjective optimization, there is a scarcity of comparisons between equation-based white-box solvers to evolutionary black-box solvers. It is commonly held that when dealing with linear and quadratic models, equation-based deterministic solvers are generally the preferred choice. The present study aims at challenging this hypothesis, and we show that particularly in box-constrained mixed-integer (MI) problems it is worth employing evolutionary methods when the goal is to achieve a good approximation of a Pareto frontier. To do so, this article compares a mathematical programming approach with an evolutionary method for set-oriented Pareto front approximation of bi-objective quadratic MI optimization problems. The focus is on convex quadratic under-constrained models wherein the decision variables are either tightly or loosely bounded by box-constraints. Through an empirical assessment of families of quadratic models across varying Hessian forms, variable ranges, and condition numbers, the study compares the performance of the CPLEX-based diversity maximization approach to a state-of-the-art evolutionary multiobjective optimization meta-heuristic with MI mutation and crossover operators. We identify and explain strengths and weaknesses of both approaches when dealing with loosely bounded box-constraints, and prove a theorem regarding the potential undecidability of such multiobjective problems featuring unbounded integer decision variables. The empirical results systematically confirm that black-box and white-box solvers can be competitive, especially in the case of loose box-constraints.},
  archive      = {J_TEVC},
  author       = {Ofer M. Shir and Michael Emmerich},
  doi          = {10.1109/TEVC.2024.3374519},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {661-675},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective mixed-integer quadratic models: A study on mathematical programming and evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protein structure prediction using a new optimization-based evolutionary and explainable artificial intelligence approach. <em>TEVC</em>, <em>29</em>(3), 646-660. (<a href='https://doi.org/10.1109/TEVC.2024.3365814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction (PSP) is an important scientific problem because it helps humans to understand how proteins perform their biological functions. This article models the PSP problem as a multiobjective optimization problem with three fast and accurate knowledge-based energy functions. This way, using evolutionary computation (EC)-based artificial intelligence (AI) approach to solve this multiobjective PSP problem to find the optimal structure is explainable. Considering that the multiple populations for multiple objectives (MPMO) framework shows efficient performance in solving lots of multiobjective benchmarks and real-world problems, this article proposes a new AI approach named improved MPMO-based differential evolution (IMPMO-DE) to solve the multiobjective PSP problem. To our best knowledge, this is the first time that MPMO is applied to PSP, with three novel strategies. First, an adaptive archive-based mutation strategy is proposed to better balance the exploration and exploitation abilities by adaptively using different archive-based mutation operators in different evolutionary stages. Second, a mixed individual transfer strategy is proposed to share search information among the multiple populations to accelerate the convergence speed. Third, an evolvable archive update strategy is proposed to generate more promising solutions through evolving the archived solutions. IMPMO-DE is tested on 28 representative proteins and all the available template-free modeling proteins up to 404 residues in the famous critical assessment of protein structure prediction (CASP14) competition. Experimental results show that IMPMO-DE performs better than the compared state-of-the-art EC-based PSP methods and ranks above average compared with all the CASP14 competitors. More importantly, IMPMO-DE is a new efficient AI approach that opens a promising optimization-based evolutionary and explainable way for efficient PSP rather than deep learning approaches like AlphaFold2, especially for newly discovered proteins without similar known protein structures.},
  archive      = {J_TEVC},
  author       = {Jun Hong and Zhi-Hui Zhan and Langchong He and Zongben Xu and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3365814},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {646-660},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Protein structure prediction using a new optimization-based evolutionary and explainable artificial intelligence approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-population algorithm for large-scale multiobjective optimization based on fitness-aware operator and adaptive environmental selection. <em>TEVC</em>, <em>29</em>(3), 631-645. (<a href='https://doi.org/10.1109/TEVC.2023.3296488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems (MOPs) containing a large number of decision variables, which are also known as large-scale MOPs (LSMOPs), pose great challenges to most existing evolutionary algorithms. This is mainly because that a high dimensional decision space degrades the effectiveness of search operators notably, and balancing convergence and diversity becomes a challenging task. In this article, we propose a two-population-based algorithm for large-scale multiobjective optimization named large-scale two population algorithm. In the proposed algorithm, solutions are classified in to two subpopulations: 1) a convergence subpopulation (CP) and 2) a diversity subpopulation (DP), aiming at convergence and diversity, respectively. In order to improve convergence speed, a fitness-aware variation operator (FAVO) is applied to drive DP solutions toward CP. Besides, an adaptive penalty-based boundary intersection (APBI) strategy is adopted for environmental selection in order to balance convergence and diversity temporally during different stages of evolution process. Experimental results on benchmark test problems with 100-2000 decision variables demonstrate that the proposed algorithm can achieve the best overall performance compared with several state-of-the-art large-scale multiobjective evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yan Zhang and Peng Yang and Xin Yao and Aimin Zhou},
  doi          = {10.1109/TEVC.2023.3296488},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {631-645},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A two-population algorithm for large-scale multiobjective optimization based on fitness-aware operator and adaptive environmental selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dealing with structure constraints in evolutionary pareto set learning. <em>TEVC</em>, <em>29</em>(3), 616-630. (<a href='https://doi.org/10.1109/TEVC.2025.3537986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, many multiobjective evolutionary optimization algorithms (MOEAs) have been proposed to find a finite set of approximate Pareto solutions for a given problem in a single run. However, in many real-world applications, it could be desirable to have structure constraints on the entire optimal solution set, which define the patterns shared among all solutions. The current population-based MOEAs cannot properly handle such requirements. In this work, we make a first attempt to incorporate the structure constraints into the whole solution set. Specifically, we propose to model such a multiobjective optimization problem as a set optimization problem with structure constraints. The structure constraints define some patterns that all the solutions are required to share. Such patterns can be fixed components shared by all solutions, specific relations among decision variables, and the required shape of the Pareto set. In addition, we develop a simple yet efficient evolutionary stochastic optimization method to learn the set model, which only requires a low computational budget similar to classic MOEAs. With our proposed method, the decision-makers can easily tradeoff the Pareto optimality with preferred structures, which is not supported by other MOEAs. A set of experiments on benchmark test suites and real-world application problems demonstrates that our proposed method is effective.},
  archive      = {J_TEVC},
  author       = {Xi Lin and Xiaoyuan Zhang and Zhiyuan Yang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2025.3537986},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {616-630},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dealing with structure constraints in evolutionary pareto set learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted multiobjective gene selection for cell classification from large-scale single-cell RNA sequencing data. <em>TEVC</em>, <em>29</em>(3), 601-615. (<a href='https://doi.org/10.1109/TEVC.2025.3533490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate cell classification is crucial but expensive for large-scale single-cell RNA sequencing (scRNA-seq) analysis. Gene selection (GS) emerges as a pivotal technique in identifying gene subsets of scRNA-seq for classification accuracy improvement and gene scale reduction. Nevertheless, the rising scale of scRNA-seq data presents challenges to existing GS methods regarding performance and computational time. Thus, we propose a surrogate-assisted evolutionary algorithm for multiobjective GS to address these deficiencies. An innovative two-phase initialization method is proposed to select sparse solutions to provide preliminary insights into gene contributions. Then, a binary competitive swarm optimizer is proposed for effective global search, where a local search method is embedded to eliminate irrelevant genes for efficiency consideration. Additionally, a surrogate model is adopted to forecast classification accuracy efficiently and substitutes part of the computationally expensive classification process. Experiments are conducted on eight large-scale scRNA-seq datasets with more than 20 000 genes. The effectiveness of the proposed GS method for scRNA-seq cell classification compared with eight state-of-the-art methods is validated. Gene expression analysis results of selected genes further validated the significance of the genes selected by the proposed method in the classification of scRNA-seq data.},
  archive      = {J_TEVC},
  author       = {Jianqing Lin and Cheng He and Hanjing Jiang and Yabing Huang and Yaochu Jin},
  doi          = {10.1109/TEVC.2025.3533490},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {601-615},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted multiobjective gene selection for cell classification from large-scale single-cell RNA sequencing data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An iterated greedy algorithm with reinforcement learning for distributed hybrid flowshop problems with job merging. <em>TEVC</em>, <em>29</em>(3), 589-600. (<a href='https://doi.org/10.1109/TEVC.2024.3443874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed hybrid flowshop scheduling problems (DHFSPs) widely exist in various industrial production processes, and thus have received widespread attention. However, the existing research mainly focuses on interfactory and intermachine collaboration, but ignores collaborative processing between jobs. Therefore, this article considers rescheduling DHFSP with job merging and reworking (DHFRPJM) and establishes a mixed-integer linear programming model. The objective is to minimize the makespan. Based on problem-specific knowledge, a decoding heuristic and initialization strategy considering job merging are designed. An acceleration strategy based on critical path is adopted to save the computational effort of the iterated greedy algorithm. A local search strategy based on a deep reinforcement learning algorithm further improves the performance of the algorithm. Experimental results based on actual production data show that the proposed algorithm outperforms other algorithms in closely related literature.},
  archive      = {J_TEVC},
  author       = {Xin-Rui Tao and Quan-Ke Pan and Liang Gao},
  doi          = {10.1109/TEVC.2024.3443874},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {589-600},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An iterated greedy algorithm with reinforcement learning for distributed hybrid flowshop problems with job merging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning-assisted multimodal multiobjective bilevel optimization method for multirobot task allocation. <em>TEVC</em>, <em>29</em>(3), 574-588. (<a href='https://doi.org/10.1109/TEVC.2025.3535954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multirobot task allocation (MRTA) is a challenging bi-level problem in the multirobot cooperative systems (MRCSs) and offers an effective method for addressing complex tasks. However, dynamic /uncertain environments can easily invalidate original schemes in practical MRTA decision-makings. Further, a nested structure in MRTA problems makes computational expensive. Therefore, the two main tasks are 1) finding a sufficient number of equivalent schemes for MRTA problems to adapt to task environments and 2) improving algorithm search efficiency in bi-level optimization problems. In this study, a multimodal multiobjective evolutionary algorithm (MMOEA) based on deep reinforcement learning (DRL) and large neighborhood search (LNS), called MMOEA-DL, is proposed to solve MRTA problems. In the MMOEA-DL, the task allocation problem, which is considered as the upper-level optimization problem, is solved using an improved MMOEA. The traveling salesman problem (TSP) regarded as the lower-level optimization problem is addressed via end-to-end method (i.e., DRL) and LNS. By leveraging the end-to-end method to obtain the results of the lower-level optimization, the bi-level optimization problem is effectively transformed into a single-level optimization problem. To demonstrate the performance of the proposed algorithm, 16 MRTA simulation scenarios and two actual MRTA scenarios with evenly and unevenly distributed task points are introduced in the present study. The simulation results verify that the MMOEA-DL not only provides decision-makers with expanded equivalent optimal schemes to address dynamic environments or unforeseen circumstances, but also offers a novel approach to solve the multimodal multiobjective bi-level optimization problem while saving computational costs.},
  archive      = {J_TEVC},
  author       = {Yuanyuan Yu and Qirong Tang and Qingchao Jiang and Qinqin Fan},
  doi          = {10.1109/TEVC.2025.3535954},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {574-588},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A deep reinforcement learning-assisted multimodal multiobjective bilevel optimization method for multirobot task allocation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial machine-learning-assisted evolutionary computation. <em>TEVC</em>, <em>29</em>(3), 571-573. (<a href='https://doi.org/10.1109/TEVC.2025.3548888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TEVC},
  author       = {Rong Qu and Nelishia Pillay and Emma Hart and Manuel López-Ibáñez},
  doi          = {10.1109/TEVC.2025.3548888},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {571-573},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial machine-learning-assisted evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zeroth-order Actor–Critic: An evolutionary framework for sequential decision problems. <em>TEVC</em>, <em>29</em>(2), 555-569. (<a href='https://doi.org/10.1109/TEVC.2025.3529503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) have shown promise in solving sequential decision problems (SDPs) by simplifying them to static optimization problems and searching for the optimal policy parameters in a zeroth-order way. Despite their versatility, EAs often suffer from high sample complexity due to neglecting underlying temporal structures. In contrast, reinforcement learning (RL) methods typically formulate SDPs as Markov decision process (MDP). Although more sample efficient than EAs, RL methods are restricted to differentiable policies and prone to getting stuck in local optima. To address these issues, we propose a novel evolutionary framework zeroth-order actor-critic (ZOAC). We propose to use stepwise exploration in parameter space and theoretically derive the zeroth-order policy gradient. We further utilize the actor-critic architecture to effectively leverage the Markov property of SDPs and reduce the variance of gradient estimators. In each iteration, ZOAC collects trajectories with parameter space exploration, and alternates between first-order policy evaluation (PEV) and zeroth-order policy improvement (PIM). We evaluate the effectiveness of ZOAC on a challenging multilane driving task optimizing the parameters in a rule-based, nondifferentiable driving policy that consists of three submodules: 1) behavior selection; 2) path planning; and 3) trajectory tracking. We also compare it with gradient-based RL methods on three Gymnasium tasks, optimizing neural network policies with thousands of parameters. Experimental results demonstrate the strong capability of ZOAC in solving SDPs. ZOAC significantly outperforms EAs that treat the problem as static optimization and matches the performance of gradient-based RL methods even without first-order information, in terms of total average return across tasks.},
  archive      = {J_TEVC},
  author       = {Yuheng Lei and Yao Lyu and Guojian Zhan and Tao Zhang and Jiangtao Li and Jianyu Chen and Shengbo Eben Li and Sifa Zheng},
  doi          = {10.1109/TEVC.2025.3529503},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {555-569},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Zeroth-order Actor–Critic: An evolutionary framework for sequential decision problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary computation in the era of large language model: Survey and roadmap. <em>TEVC</em>, <em>29</em>(2), 534-554. (<a href='https://doi.org/10.1109/TEVC.2024.3506731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have not only revolutionized natural language processing but also extended their prowess to various domains, marking a significant stride toward artificial general intelligence. The interplay between LLMs and evolutionary algorithms (EAs), despite differing in objectives and methodologies, share a common pursuit of applicability in complex problems. Meanwhile, EA can provide an optimization framework for LLM’s further enhancement under closed box settings, empowering LLM with flexible global search capacities. On the other hand, the abundant domain knowledge inherent in LLMs could enable EA to conduct more intelligent searches. Furthermore, the text processing and generative capabilities of LLMs would aid in deploying EAs across a wide range of tasks. Based on these complementary advantages, this article provides a thorough review and a forward-looking roadmap, categorizing the reciprocal inspiration into two main avenues: 1) LLM-enhanced EA and 2) EA-enhanced LLM. Some integrated synergy methods are further introduced to exemplify the complementarity between LLMs and EAs in diverse scenarios, including code generation, software engineering, neural architecture search, and various generation tasks. As the first comprehensive review focused on the EA research in the era of LLMs, this article provides a foundational stepping stone for understanding the collaborative potential of LLMs and EAs. The identified challenges and future directions offer guidance for researchers and practitioners to unlock the full potential of this innovative collaboration in propelling advancements in optimization and artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/wuxingyu-ai/LLM4EC.},
  archive      = {J_TEVC},
  author       = {Xingyu Wu and Sheng-Hao Wu and Jibin Wu and Liang Feng and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3506731},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {534-554},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary computation in the era of large language model: Survey and roadmap},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient-guided local search for large-scale hypervolume subset selection. <em>TEVC</em>, <em>29</em>(2), 519-533. (<a href='https://doi.org/10.1109/TEVC.2025.3531950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of an unbounded archive (UA) has attracted much attention in the filed of evolutionary multiobjective optimization (EMO) since a solution set selected from the UA is often better than the final population. The size of the UA is very large (e.g., 1 000 000) since it is unbounded and it stores all the examined nondominated solutions during the execution of an EMO algorithm. Thus, an algorithm which can efficiently select a high-quality subset from a large-scale candidate set (e.g., UA) is needed. In this article, we propose a gradient-guided local search hypervolume subset selection (GL-HSS) algorithm to efficiently select a high-quality subset from a large-scale candidate set. In each iteration of GL-HSS, the gradient of the hypervolume (HV) contribution of each selected solution is used to guide the local search. As a result, the proposed algorithm can quickly improve the HV of the selected subset. Experimental results show that, compared to the existing subset selection algorithms, the proposed GL-HSS algorithm can efficiently select high-quality subsets from various large-scale candidate sets.},
  archive      = {J_TEVC},
  author       = {Yang Nan and Tianye Shu and Hisao Ishibuchi and Ke Shang},
  doi          = {10.1109/TEVC.2025.3531950},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {519-533},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Gradient-guided local search for large-scale hypervolume subset selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-individual evolutionary algorithm for cumulative capacitated vehicle routing with single and multiple depots. <em>TEVC</em>, <em>29</em>(2), 505-518. (<a href='https://doi.org/10.1109/TEVC.2024.3361910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cumulative capacitated vehicle routing problem (CCVRP) with single or multiple depots (MDCCVRP) is a variant of the popular capacitated vehicle routing problem. Instead of minimizing the total travel time, the objective here is to minimize the sum of all customers’ waiting times. This problem has a variety of real-world applications, especially in post-disaster humanitarian relief. To solve the challenging CCVRP and MDCCVRP, we propose a unified two-individual evolutionary algorithm that follows the memetic search framework. The algorithm integrates several key features: a two-individual population mechanism to accelerate convergence while maintaining population diversity, a dedicated edge assembly crossover to generate high-quality offspring, and an adaptive feasible and infeasible local search to achieve a balanced exploration between feasible and infeasible solutions. The algorithm is evaluated on 39 CCVRP instances and 78 MDCCVRP instances commonly used in the literature. Computational results show that for the CCVRP, the algorithm outperforms the leading algorithms by achieving improved best results (new upper bound) for 13 instances and matching the best results for 23 other instances. For the MDCCVRP, the algorithm achieves nine improved best results and matches the best results for the remaining instances. The critical components of the algorithm are investigated to understand their contributions.},
  archive      = {J_TEVC},
  author       = {Yuji Zou and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1109/TEVC.2024.3361910},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {505-518},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A two-individual evolutionary algorithm for cumulative capacitated vehicle routing with single and multiple depots},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From direct to directional variable Dependencies—Nonsymmetrical dependencies discovery in real-world and theoretical problems. <em>TEVC</em>, <em>29</em>(2), 490-504. (<a href='https://doi.org/10.1109/TEVC.2024.3496193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge about variable interactions is frequently employed in state-of-the-art research concerning genetic algorithms (GAs). Whether these interactions are known a priori (gray-box optimization) or are discovered by the optimizer (black-box optimization), they are used for many purposes, including proposing more effective mixing operators. Frequently, the quality of the problem structure decomposition is decisive to the optimizers’ effectiveness. However, in gray- and black-box optimization, the dependency between the variables is assumed to be symmetric. This work identifies and defines the nonsymmetrical (directional) variable dependencies. We show that these dependencies may exist (together with symmetrical) in the considered real-world problem, in which we must optimize subsequent variable groups (one after the other) in the appropriate optimization order that is not known by the optimizer. To improve GA’s effectiveness in solving the problem of such features, we propose a new linkage learning (LL) technique that can discover symmetrical and nonsymmetrical dependencies (in binary and nonbinary discrete domains) and distinguish them from each other. We show that telling these two types of dependencies from each other may significantly increase the optimizer’s effectiveness in solving real-world and theoretical problems with nonsymmetrical dependencies. Finally, we show that using the proposed LL technique does not deteriorate the effectiveness of the state-of-the-art optimizer in solving typical benchmarks containing only symmetrical dependencies.},
  archive      = {J_TEVC},
  author       = {Michal Witold Przewozniczek and Bartosz Frej and Marcin Michal Komarnicki},
  doi          = {10.1109/TEVC.2024.3496193},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {490-504},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {From direct to directional variable Dependencies—Nonsymmetrical dependencies discovery in real-world and theoretical problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOTEA-II: A collaborative multiobjective transformation-based evolutionary algorithm for bilevel optimization. <em>TEVC</em>, <em>29</em>(2), 474-489. (<a href='https://doi.org/10.1109/TEVC.2025.3538611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) for optimization have received wide attention due to their robustness and practicality. However, the traditional way of asynchronously handling bilevel optimization problems (BLOPs) ignores the benefits brought by effective upper- and lower-level collaboration. To address this issue, this article proposes a collaborative multiobjective transformation (MOT)-based EA (MOTEA-II). In MOTEA-II, the BLOP is handled within a decomposition-based multiobjective optimization paradigm using a two-stage collaborative MOT strategy. The stage-1 MOT focuses on multiple lower-level optimizations and collaboration, while stage-2 collaborates the upper-level optimization with lower-level optimization, which makes simultaneously horizontal and vertical optimization information sharing in bilevel optimization possible. In addition, a dynamic decomposition strategy is further proposed to reconstruct the hierarchy relationship in collaborative multiobjective optimization, facilitating the adaptive and flexible importance control of the upper-level objective optimization and lower-level optimality satisfaction for better-bilevel search efficiency. Empirical studies are conducted on two groups of commonly used BLOP benchmark suites and four practical applications. Experimental results show that the proposed collaborative MOTEA-II can achieve performance comparable to that of the previous MOTEA and three other representative EA-based bilevel optimization approaches, but using much fewer computational resources.},
  archive      = {J_TEVC},
  author       = {Lei Chen and Yiu-Ming Cheung and Hai-Lin Liu and Yutao Lai},
  doi          = {10.1109/TEVC.2025.3538611},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {474-489},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MOTEA-II: A collaborative multiobjective transformation-based evolutionary algorithm for bilevel optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bidirectional differential evolution-based unknown cyberattack detection system. <em>TEVC</em>, <em>29</em>(2), 459-473. (<a href='https://doi.org/10.1109/TEVC.2024.3365101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolving unknown cyberattacks, compounded by the widespread emerging technologies (say 5G, Internet of Things, etc.), have rapidly expanded the cyber threat landscape. However, most existing intrusion detection systems (IDSs) are effective in detecting only known cyberattacks, because only known cyberattack samples are usually available for IDS training. Identifying unknown cyberattacks, therefore, remains a big challenging issue. To meet this gap, in this article, motivated by artificial immunity (AIm) and differential evolution (DE), we propose a bidirectional DE-based unknown cyberattack detection system, coined BDE-IDS. Specifically, we first design a bidirectional DE algorithm for known nonself antigens (abnormal data), where bidirectional evolutionary directions are considered for increasing or decreasing the differences between known nonself antigens and self antigens (normal data), to create new antigens possibly used for generating cyberattack detectors. Second, a novel tolerance training mechanism is developed to eliminate invalid newly evolved antigens falling into the coverage of either known self or nonself antigens. Third, the remaining antigens are employed to generate detectors for unknown cyberattacks. Extensive experiments demonstrate that the BDE-IDS achieves outperformance in detecting unknown cyberattacks (as well as known cyberattacks) compared to state-of-the-art studies, including those AIm-based, signature-based, and anomaly-based IDSs.},
  archive      = {J_TEVC},
  author       = {Hanyuan Huang and Tao Li and Beibei Li and Wenhao Wang and Yanan Sun},
  doi          = {10.1109/TEVC.2024.3365101},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {459-473},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bidirectional differential evolution-based unknown cyberattack detection system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal inference-based large-scale multiobjective optimization. <em>TEVC</em>, <em>29</em>(2), 444-458. (<a href='https://doi.org/10.1109/TEVC.2025.3529938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multiobjective optimization problems (LSMOPs), characterized by a substantial number of decision variables, pose significant challenges for many existing evolutionary algorithms. However, the search efficiency of these algorithms is not yet satisfactory. This is mainly because that the search efficiency of these algorithms may deteriorate dramatically since the search space increases exponentially with the number of decision variables. Having this in mind, we proposed a large-Scale multiobjective optimization framework named causal inference-based competitive swarm optimizer (CI-CSO). Specifically, a causal-information-(CI)-based operator is designed for competitive swarm optimizers. First, a causal inference technique named information geometric causal inference (IGCI) is introduced to adequately explore the CI between decision variables and fitness values. To further distinguish the positive or negative impacts of these critical variables on solution quality, a CI processing module is designed, facilitating targeted optimization. To enhance search efficiency, CI-based offspring generator are employed, leveraging the variance of causal effects to dynamically adjust the search step size and sampling range. To evaluate its performance, the proposed CI-based operator is embedded into two multiobjective evolutionary algorithms (MOEAs) (LSTPA and LMOCSO). To demonstrate the effectiveness of the proposed framework, experimental results are presented using the LSMOP test suite and five real-world problems, each involving up to 10 000 decision variables. In addition, six classic algorithms are included for comparison.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yanting Yang and Peng Yang and Guiying Li and Ke Tang and Aimin Zhou},
  doi          = {10.1109/TEVC.2025.3529938},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {444-458},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Causal inference-based large-scale multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiform genetic programming framework for symbolic regression problems. <em>TEVC</em>, <em>29</em>(2), 429-443. (<a href='https://doi.org/10.1109/TEVC.2025.3527875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {genetic programming (GP) is a widely recognized and powerful approach for symbolic regression (SR) problems. However, existing GP methods rely on a single form to solve the problem, which limits their search diversity and increases the likelihood of getting stuck in local optima, especially in complex scenarios. In this article, we propose a general multiform GP (MFGP) framework to improve the performance of GP on complicated SR problems. As far as we know, this articel is the first attempt to integrate the multiform optimization paradigm with GP to accelerate the search performance. The key idea of the proposed framework is to construct multiple forms to solve the same problem cooperatively at the same time. During the evolution process, knowledge gained from different forms is shared among the solvers to improve the search diversity and efficiency. A knowledge transfer mechanism is specifically designed to facilitate knowledge transfer among GP solvers with different modeling forms. In addition, an adaptive resource control mechanism is designed to reallocate computing resources according to the problem solving efficiency of different solvers to further improve search efficiency. To demonstrate the effectiveness of the proposed framework, a multiform gene expression programming algorithm is designed and tested on 20 problems, including physical datasets, synthetic datasets, and real-world datasets. The experimental results have demonstrated the effectiveness of the proposed framework.},
  archive      = {J_TEVC},
  author       = {Jinghui Zhong and Junlan Dong and Wei-Li Liu and Liang Feng and Jun Zhang},
  doi          = {10.1109/TEVC.2025.3527875},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {429-443},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiform genetic programming framework for symbolic regression problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protein design by directed evolution guided by large language models. <em>TEVC</em>, <em>29</em>(2), 418-428. (<a href='https://doi.org/10.1109/TEVC.2024.3439690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed evolution, a strategy for protein engineering, optimizes protein properties (i.e., fitness) by a rigorous and resource-intensive process of screening or selecting among a vast range of mutations. By conducting an in-silico screening of sequence properties, machine learning-guided directed evolution (MLDE) can expedite the optimization process and alleviate the experimental workload. In this work, we propose a general MLDE framework in which we apply recent advancements of deep learning in protein representation learning and protein property prediction to accelerate the searching and optimization processes. In particular, we introduce an optimization pipeline that utilizes the large language models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness. Our experiments have shown the superior efficiency and efficacy of our proposed framework in the conditional protein generation, in comparison with the other state-of-the-art baseline algorithms. We expect this work will shed a new light on not only protein engineering but also on solving the combinatorial problems using the data-driven methods.},
  archive      = {J_TEVC},
  author       = {Thanh V. T. Tran and Truong Son Hy},
  doi          = {10.1109/TEVC.2024.3439690},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {418-428},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Protein design by directed evolution guided by large language models},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupling constraint: Task clone-based multitasking optimization for constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(2), 404-417. (<a href='https://doi.org/10.1109/TEVC.2024.3358854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coupling of multiple constraints can pose difficulties in solving constrained multiobjective optimization problems (CMOPs). Existing constrained multiobjective evolutionary algorithms (CMOEAs) often overlook this issue by considering all constraints together. This article proposes MTOTC, a novel multitasking optimization algorithm that addresses this challenge through a task clone technique. MTOTC clones the target CMOP with $q$ constraints into $q+1$ copies, resulting in a total of $q+2$ tasks. Each cloned task is handled using an independent population that considers a unique constraint-handling sequence, effectively decoupling the constraints in $q+1$ different ways. Additionally, the algorithm incorporates online information sharing between the target task and cloned tasks, enabling the utilization of valuable search history as much as possible. Experimental results on four recently developed complex CMOP benchmark suites and a series of real-world CMOPs demonstrate the superior performance of MTOTC compared to seven state-of-the-art CMOEAs.},
  archive      = {J_TEVC},
  author       = {Genghui Li and Zhenkun Wang and Weifeng Gao and Ling Wang},
  doi          = {10.1109/TEVC.2024.3358854},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {404-417},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Decoupling constraint: Task clone-based multitasking optimization for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biased random key genetic algorithm for solving the longest common square subsequence problem. <em>TEVC</em>, <em>29</em>(2), 390-403. (<a href='https://doi.org/10.1109/TEVC.2024.3413150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the longest common square subsequence (LCSqS) problem, a variant of the longest common subsequence (LCS) problem in which solutions must be square strings. A square string can be expressed as the concatenation of a string with itself. The LCSqS problem has applications in bioinformatics, for discovering internal similarities between molecular structures. We propose a metaheuristic approach, a biased random key genetic algorithm (BRKGA) hybridized with a beam search (BS) from the literature. Our approach is based on reducing the LCSqS problem to a set of promising LCS problems. This is achieved by cutting each input string into two parts first and then evaluating such a transformed instance by solving the LCS problem for the obtained overall set of strings. The task of the BRKGA is, hereby, to find a set of good cut points for the input strings. For this purpose, the search is carefully biased by problem-specific greedy information. For each cut point vector, the resulting LCS problem is approximately solved by the existing BS approach. The proposed algorithm is evaluated against a previously proposed state-of-the-art variable neighborhood search (VNS) on random uniform instances from the literature, new nonuniform instances, and a real-world instance set consisting of DNA strings. The results underscore the importance of our work, as our novel approach outperforms former state-of-the-art with statistical significance. Particularly, they evidence the limitations of the VNS when solving nonuniform instances, for which our method shows superior performance.},
  archive      = {J_TEVC},
  author       = {Jaume Reixach and Christian Blum and Marko Djukanović and Günther R. Raidl},
  doi          = {10.1109/TEVC.2024.3413150},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {390-403},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A biased random key genetic algorithm for solving the longest common square subsequence problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel knowledge-based genetic algorithm for robot path planning in complex environments. <em>TEVC</em>, <em>29</em>(2), 375-389. (<a href='https://doi.org/10.1109/TEVC.2025.3534026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel knowledge-based genetic algorithm (GA) to generate a collision-free path in complex environments. The proposed algorithm infuses specific domain knowledge into robot path planning through the development of five problem-specific operators that integrate a local search technique to improve efficiency. In addition, the proposed algorithm introduces a unique and straightforward representation of the robot path and an effective method for evaluating the path quality and accurately detecting collisions. The proposed algorithm is capable of finding optimal or suboptimal robot paths in both static and dynamic environments. Simulation and experimental studies are conducted to showcase the effectiveness and efficiency of the proposed algorithm. Furthermore, a comparative study is performed to highlight the indispensable role of specialized genetic operators within the proposed algorithm in solving the path planning problem.},
  archive      = {J_TEVC},
  author       = {Junfei Li and Yanrong Hu and Simon X. Yang},
  doi          = {10.1109/TEVC.2025.3534026},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {375-389},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A novel knowledge-based genetic algorithm for robot path planning in complex environments},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic multi-armed bandits: A reinforcement learning inspired approach for simulation optimization. <em>TEVC</em>, <em>29</em>(2), 360-374. (<a href='https://doi.org/10.1109/TEVC.2024.3524505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems are inherently stochastic, complicating, or even precluding the use of analytical methods. These problems are often characterized by high dimensionality, large solution spaces, and numerous local optima, which make finding optimal solutions challenging. Therefore, simulation optimization is frequently employed. This article specifically focuses on the discrete case, also known as discrete optimization via simulation. Despite their adaptions for stochastic problems, previous evolutionary algorithms face a major limitation in these problems. They discard all information about solutions that are not involved in the most recent population. However, this is ineffective, as each simulation observation gathered over the course of iterations provides valuable information that should guide the selection of subsequent solutions. Inspired by the domain of reinforcement learning (RL), we propose a novel memory concept for evolutionary algorithms that ensures global convergence and significantly improves their finite time performance. Unlike previous evolutionary algorithms, our approach permanently preserves simulation observations to progressively improve the accuracy of sample means when revisiting solutions in later iterations. Moreover, the selection of new solutions is based on the entire memory rather than just the last population. The numerical experiments demonstrate that this novel approach, which combines a genetic algorithm (GA) with such memory, consistently outperforms popular convergent state-of-the-art benchmark algorithms in a large variety of established test problems while requiring considerably less computational effort. This marks the so-called genetic multi-armed bandit (MAB) as one of the currently most powerful algorithms for solving stochastic problems.},
  archive      = {J_TEVC},
  author       = {Deniz Preil and Michael Krapp},
  doi          = {10.1109/TEVC.2024.3524505},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {360-374},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic multi-armed bandits: A reinforcement learning inspired approach for simulation optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic programming hyper heuristic with elitist mutation for integrated order batching and picker routing problem. <em>TEVC</em>, <em>29</em>(2), 346-359. (<a href='https://doi.org/10.1109/TEVC.2025.3532022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated order batching and picker routing (IOBPR) is a complex combinatorial optimization problem in real-world intelligent manufacturing systems. Heuristics are often used for solving such complex scheduling problems. Manually designing scheduling heuristics suffer from two limitations: 1) few problem features can be taken into account and 2) the design process is time consuming. Genetic programming hyper heuristic (GPHH) approaches have been proposed on many scheduling problems to automatically evolve effective heuristics. However, existing GPHH approaches are often problem specific and requires careful design of problem specific terminal sets and evolution operators. The aim of this work is to develop a GPHH approach to evolve heuristics for the IOBPR problem. In particular, we propose a novel terminal set (NT) with three types of terminals, and a GPHH with elitist mutation (GPHH-EM) algorithm. Extensive experiments demonstrate that the heuristics evolved by GPHH-EM can significantly outperform other state-of-the-art competing algorithms designed by human experts. Further analysis indicates that the three types of terminals effectively complement to improve evolved heuristics for decision making. Furthermore, the newly developed elitist mutation operator expedites the evolutionary process for GPHH to find high-quality heuristics.},
  archive      = {J_TEVC},
  author       = {Yuquan Wang and Naiming Xie and Nanlei Chen and Hui Ma and Gang Chen},
  doi          = {10.1109/TEVC.2025.3532022},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {346-359},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming hyper heuristic with elitist mutation for integrated order batching and picker routing problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLaMEA: A large language model evolutionary algorithm for automatically generating metaheuristics. <em>TEVC</em>, <em>29</em>(2), 331-345. (<a href='https://doi.org/10.1109/TEVC.2024.3497793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs), such as GPT-4 have demonstrated their ability to understand natural language and generate complex code snippets. This article introduces a novel LLM evolutionary algorithm (LLaMEA) framework, leveraging GPT models for the automated generation and refinement of algorithms. Given a set of criteria and a task definition (the search space), LLaMEA iteratively generates, mutates, and selects algorithms based on performance metrics and feedback from runtime evaluations. This framework offers a unique approach to generating optimized algorithms without requiring extensive prior expertise. We show how this framework can be used to generate novel closed box metaheuristic optimization algorithms for box-constrained, continuous optimization problems automatically. LLaMEA generates multiple algorithms that outperform state-of-the-art optimization algorithms (covariance matrix adaptation evolution strategy and differential evolution) on the 5-D closed box optimization benchmark (BBOB). The algorithms also show competitive performance on the 10- and 20-D instances of the test functions, although they have not seen such instances during the automated generation process. The results demonstrate the feasibility of the framework and identify future directions for automated generation and optimization of algorithms via LLMs.},
  archive      = {J_TEVC},
  author       = {Niki van Stein and Thomas Bäck},
  doi          = {10.1109/TEVC.2024.3497793},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {331-345},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {LLaMEA: A large language model evolutionary algorithm for automatically generating metaheuristics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-assisted multiobjective evolutionary algorithm for routing and packing. <em>TEVC</em>, <em>29</em>(2), 317-330. (<a href='https://doi.org/10.1109/TEVC.2024.3357819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many combinatorial multiobjective optimization problems involve very costly-to-evaluate objectives and constraints. It is very difficult, if not impossible, for traditional heuristics to solve these problems with an acceptable amount of computational time. In this article, we show that offline machine learning can be very useful to assist multiobjective evolutionary algorithms to tackle this kind of problem. We take a complicated real-life multiobjective routing-packing problem as the test bed. We propose to use offline machine learning methods to replace time-consuming packing heuristics for packing feasibility prediction. Experiments show that the machine learning models can be 1000 times faster than some commonly used packing heuristics and their accuracy can be as high as 98%. We adopt decomposition-based multiobjective evolutionary algorithmic to decompose the problem into a number of single objective subproblems and solve them in a collaborative manner. We propose an encoding strategy to represent each routing scheme and use genetic operators to generate new routes. Experimental studies have been conducted on 100 instances from HUAWEI’s real-world logistics application and two test suites from the literature. Our proposed method can solve each HUAWEI instance in around 1 min. Our solutions on the two test suites are comparable to other existing algorithms, and the overall computational cost of our method is significantly lower than others.},
  archive      = {J_TEVC},
  author       = {Fei Liu and Qingfu Zhang and Qingling Zhu and Xialiang Tong and Mingxuan Yuan},
  doi          = {10.1109/TEVC.2024.3357819},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {317-330},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Machine learning-assisted multiobjective evolutionary algorithm for routing and packing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization for quality diversity search with coupled descriptor functions. <em>TEVC</em>, <em>29</em>(2), 302-316. (<a href='https://doi.org/10.1109/TEVC.2024.3376733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality diversity (QD) algorithms, such as the multidimensional archive of phenotypic elites (MAP-Elites), are a class of optimization techniques that attempt to find many high-performing points that all behave differently according to a user-defined behavioral metric. In this article we propose the Bayesian optimization of elites (BOP-Elites) algorithm. Designed for problems with expensive fitness functions and coupled behavior descriptors, it is able to return a QD solution-set with excellent performance already after a relatively small number of samples. BOP-Elites models both fitness and behavioral descriptors with Gaussian Process surrogate models and uses Bayesian optimization strategies for choosing points to evaluate in order to solve the quality-diversity problem. In addition, BOP-Elites produces high-quality surrogate models which can be used after convergence to predict solutions with any behavior in a continuous range. An empirical comparison shows that BOP-Elites significantly outperforms other state-of-the-art algorithms without the need for problem-specific parameter tuning.},
  archive      = {J_TEVC},
  author       = {Paul Kent and Adam Gaier and Jean-Baptiste Mouret and Juergen Branke},
  doi          = {10.1109/TEVC.2024.3376733},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {302-316},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Bayesian optimization for quality diversity search with coupled descriptor functions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge structure preserving-based evolutionary many-task optimization. <em>TEVC</em>, <em>29</em>(2), 287-301. (<a href='https://doi.org/10.1109/TEVC.2024.3355781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a challenging research topic in evolutionary multitask optimization (EMTO), evolutionary many-task optimization (EMaTO) aims at solving more than three tasks simultaneously. The design of the EMaTO algorithm generally needs to consider two major open issues, which are how to obtain useful knowledge from similar source tasks and how to effectively transfer knowledge to the target task. In this article, we discover that knowledge structure plays a significant role in dealing with these two issues and propose a novel knowledge structure preserving-based evolutionary algorithm (KSP-EA) to efficiently solve many-task optimization problems. KSP-EA aims to achieve two goals, which are first to obtain useful structure-preserved knowledge from similar source tasks and second to effectively transfer both direct and indirect knowledge to the target task. To achieve the first goal, we propose a local-structure-preserved knowledge acquisition strategy that projects the knowledge of similar source tasks into a unified subspace without loss of the knowledge structure, thus enhancing the quality of the obtained knowledge. To achieve the second goal, we propose a tree-based knowledge propagation strategy that constructs a knowledge propagating tree to connect all the tasks and propagates knowledge along the edges of this tree. This way, the target task can obtain both direct and indirect knowledge, improving the effectiveness of knowledge transfer. We conduct extensive experiments on CEC19 and WCCI22 many-task optimization test suites and a real-world application scenario to evaluate the performance of KSP-EA. The experimental results show that our KSP-EA generally outperforms state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3355781},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {287-301},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge structure preserving-based evolutionary many-task optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of constrained continuous multiobjective optimization problems: A performance space perspective. <em>TEVC</em>, <em>29</em>(1), 275-285. (<a href='https://doi.org/10.1109/TEVC.2024.3366659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization has gained much interest in the past few years. However, constrained multiobjective optimization problems (CMOPs) are still unsatisfactorily understood. Consequently, the choice of adequate CMOPs for benchmarking is difficult and lacks a formal background. This article takes a step toward addressing this issue by exploring CMOPs from a performance space perspective. First, it presents a novel performance assessment approach designed explicitly for constrained multiobjective optimization. This methodology offers a first attempt at simultaneously measuring the performance in approximating the Pareto front and constraint satisfaction. Second, it proposes an approach to measure the capability of the given optimization problem to differentiate among algorithm performances. Finally, this approach is used to compare eight frequently used artificial test suites of CMOPs. The experimental results reveal which suites are more efficient in discerning between four well-known multiobjective optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Aljoša Vodopija and Tea Tušar and Bogdan Filipič},
  doi          = {10.1109/TEVC.2024.3366659},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {275-285},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Characterization of constrained continuous multiobjective optimization problems: A performance space perspective},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determining metaheuristic similarity using behavioral analysis. <em>TEVC</em>, <em>29</em>(1), 262-274. (<a href='https://doi.org/10.1109/TEVC.2023.3346672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many nature-inspired metaheuristics have been published, with claims of originality based on the metaphor that inspired the algorithm. Rarely is empirical evidence given to show algorithmic originality. In order to provide an easy and computationally cheap approach to characterize algorithm search behavior, a suite of 20 behavioral characteristics is proposed. This behavioral characteristic suite allows for the search behavior of an algorithm to be quantified without manual inspection. By doing so, behavioral novelty of any given algorithm may be determined by comparing the behavioral characteristics to those of well-known metaheuristics. To illustrate this use, and to evaluate whether metaheuristics are behaviorally distinct, a host of metaheuristics is run on various benchmark functions. To evaluate behavioral similarity across all problems, while acknowledging behavior to be problem dependant, a novel method is proposed. In addition to this method, new behavioral characteristics are also proposed. The behavioral vectors generated for each benchmark function are clustered. The relationships and trends present in the different clusters are summarized by creating a pair-wise matrix for every metaheuristic pair, which tallies the number of times that the pair are found within the same cluster. The tallies are then analyzed in order to make inference regarding the distinctness of any metaheuristic’s behaviors, across many different benchmark functions. The analysis finds that the range of unique search behaviors is small and that most metaheuristics share their behaviors with most other metaheuristics. The analysis also identifies both unique algorithms, as well as algorithms which have no unique behaviors.},
  archive      = {J_TEVC},
  author       = {Lauren Hayward and Andries Engelbrecht},
  doi          = {10.1109/TEVC.2023.3346672},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {262-274},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Determining metaheuristic similarity using behavioral analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible ranking-based competitive swarm optimizer for large-scale continuous multiobjective optimization. <em>TEVC</em>, <em>29</em>(1), 247-261. (<a href='https://doi.org/10.1109/TEVC.2024.3355221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the curse of dimensionality, the search efficiency of existing operators in large-scale decision space deteriorates dramatically. The competitive swarm optimizer (CSO)-based framework has great potential in tackling large-scale single-objective optimization problems. However, the existing CSOs only focus on the loser to winner learning paradigm and neglect the significance of the winner determination mechanism for large-scale search, which makes the algorithm difficult to escape from local optima. To remedy this issue, a flexible ranking-based CSO has been tailored for handling large-scale multiobjective optimization problems (MOPs). Concretely, a novel winner determination strategy is introduced to broadly identify high-quality individuals in the population to enhance diversity maintenance. In addition, a special competitive mechanism is adopted to guide the search direction, which is capable of efficiently increasing search space utilization. The simulation results validate that the proposed algorithm can significantly enhance the exploration and exploitation ability of the conventional CSO, and outperforms several state-of-the-art large-scale multiobjective optimization algorithms on both large-scale benchmark MOPs and application examples.},
  archive      = {J_TEVC},
  author       = {Xiangzhou Gao and Shenmin Song and Hu Zhang and Zhenkun Wang},
  doi          = {10.1109/TEVC.2024.3355221},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {247-261},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A flexible ranking-based competitive swarm optimizer for large-scale continuous multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-learning evolutionary algorithm for transportation-constrained and distributed energy-efficient flexible scheduling. <em>TEVC</em>, <em>29</em>(1), 232-246. (<a href='https://doi.org/10.1109/TEVC.2024.3354850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of globalization and environmental concerns, distributed scheduling and energy-efficient scheduling have become crucial topics in the informational manufacturing system. Additionally, the growing consideration about realistic constraints, such as transportation time and finite transportation resources, has made the scheduling problem increasingly complex. Facing these challenges, special mechanisms are required to improve the efficiency of solving algorithms. In this article, a bi-learning evolutionary algorithm (BLEA) is proposed to solve the distributed energy-efficient flexible job shop problem with transportation constraints (DEFJSP-T). First, we integrate statistical learning (SL) and evolutionary learning (EL) in the framework, while decomposition and Pareto dominance methods are employed in different stages to handle conflicting objectives. During the SL stage, probability models are established to statistically search for advantageous substructures on each weight vector, and an update mechanism is devised to improve the exploration. In the EL stage, the genetic operators are introduced and an improved local search that takes into account the problem properties is proposed to realize sufficient exploitation. Finally, according to the performance of the SL, a novel switching mechanism between SL and EL is designed to ensure the rational allocation of computing resources. Extensive experiments are conducted to test the performances of the BLEA. The statistical comparison shows that the BLEA is superior in solving the DEFJSP-T in terms of efficiency and effectiveness.},
  archive      = {J_TEVC},
  author       = {Zixiao Pan and Ling Wang and Jingjing Wang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2024.3354850},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {232-246},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bi-learning evolutionary algorithm for transportation-constrained and distributed energy-efficient flexible scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming. <em>TEVC</em>, <em>29</em>(1), 217-231. (<a href='https://doi.org/10.1109/TEVC.2024.3353207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LGP has been successfully applied to dynamic job shop scheduling (DJSS) to automatically evolve dispatching rules. Flow control operations are crucial in concisely describing complex knowledge of dispatching rules, such as different dispatching rules in different conditions. However, existing linear genetic programming (LGP) methods for DJSS have not fully considered the use of flow control operations. They simply included flow control operations in their primitive set, which inevitably leads to a huge number of redundant and obscure solutions in LGP search spaces. To move one step toward evolving effective and interpretable dispatching rules, this article explicitly considers the characteristics of flow control operations via grammar-guided LGP and focuses on IF operations as a starting point. Specifically, this article designs a new set of normalized terminals to improve the interpretability of IF operations and proposes three restrictions by grammar rules on the usage of IF operations: 1) specifying the available inputs; 2) the maximum number; and 3) the possible locations of IF operations. The experiment results verify that the proposed method can achieve significantly better-test performance than state-of-the-art LGP methods and improves interpretability by IF-included dispatching rules. Further investigation confirms that the explicit introduction of IF operations helps effectively evolve different dispatching rules according to their decision situations.},
  archive      = {J_TEVC},
  author       = {Zhixing Huang and Yi Mei and Fangfang Zhang and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3353207},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {217-231},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective multitask optimization with multiple knowledge types and transfer adaptation. <em>TEVC</em>, <em>29</em>(1), 205-216. (<a href='https://doi.org/10.1109/TEVC.2024.3353319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) exploits the correlation among different tasks to help handle them through knowledge transfer (KT) techniques in evolutionary algorithms. In this area, multiobjective multitask optimization (MO-MTO) utilizes EMT to solve multiple multiobjective optimization tasks simultaneously. The key to addressing MO-MTO problems (MO-MTOPs) is to transfer appropriate knowledge among optimization tasks to assist the multiobjective evolutionary process. Both the type and the amount of knowledge can significantly affect the KT process. To achieve better KT behavior, we propose a multiple knowledge types and transfer adaptation (MKTA) framework for handling MO-MTOPs. The MKTA framework incorporates multiple types of knowledge in order to obtain comprehensive KT performance. It also provides transfer adaptation strategies to control: 1) the type of knowledge and 2) the amount of knowledge for KT via parameter adaptation approaches, thereby mitigating negative KT. Furthermore, we propose an evolution-path-model-based knowledge type and incorporate the existing unified-search-space-based knowledge type to form the knowledge pool for MKTA. Finally, the MKTA framework is coupled with a ranking-based differential evolution operator to constitute the complete algorithm MTDE-MKTA. In the experimental study, MTDE-MKTA outperformed ten advanced algorithms on 39 benchmark MO-MTOPs and six groups of realworld application problems.},
  archive      = {J_TEVC},
  author       = {Yanchi Li and Wenyin Gong},
  doi          = {10.1109/TEVC.2024.3353319},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {205-216},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective multitask optimization with multiple knowledge types and transfer adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking derivative-free global optimization algorithms under limited dimensions and large evaluation budgets. <em>TEVC</em>, <em>29</em>(1), 187-204. (<a href='https://doi.org/10.1109/TEVC.2024.3379756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenge of selecting the most suitable optimization algorithm by presenting a comprehensive computational comparison between stochastic and deterministic methods. The complexity of algorithm selection arises from the absence of a universal algorithm and the abundance of available options. Manual selection without comprehensive studies can lead to suboptimal or incorrect results. In order to address this issue, we carefully selected 25 promising and representative state-of-the-art algorithms from both aforementioned classes. The evaluation with up to the 20 dimensions and large evaluation budgets $(10^{5}{\times }n)$ was carried out in a significantly expanded and improved version of the DIRECTGOLib v2.0 library, which included ten distinct collections of primarily continuous test functions. The evaluation covered various aspects, such as solution quality, time complexity, and function evaluation usage. The rankings were determined using statistical tests and performance profiles. When it comes to the problems and algorithms examined in this study, EA4eig, EBOwithCMAR, APGSK-IMODE, 1-DTC-GL, OQNLP, and DIRMIN stand out as superior to other derivative-free solvers in terms of solution quality. While deterministic algorithms can locate reasonable solutions with comparatively fewer function evaluations, most stochastic algorithms require more extensive evaluation budgets to deliver comparable results. However, the performance of stochastic algorithms tends to excel in more complex and higher-dimensional problems. These research findings offer valuable insights for practitioners and researchers, enabling them to tackle diverse optimization problems effectively.},
  archive      = {J_TEVC},
  author       = {Linas Stripinis and Jakub Kůdela and Remigijus Paulavičius},
  doi          = {10.1109/TEVC.2024.3379756},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {187-204},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Benchmarking derivative-free global optimization algorithms under limited dimensions and large evaluation budgets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple tasks for multiple objectives: A new multiobjective optimization method via multitask optimization. <em>TEVC</em>, <em>29</em>(1), 172-186. (<a href='https://doi.org/10.1109/TEVC.2023.3294307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling conflicting objectives and finding multiple Pareto optimal solutions are two challenging issues in solving multiobjective optimization problems (MOPs). Inspired by the efficiency of multitask optimization (MTO) in finding multiple optimal solutions of MTO problem (MTOP), we propose to treat MOP as a MTOP and solve it by using MTO. By transforming the MOP into a MTOP, not only that the difficulty in handling conflicting objectives can be avoided, but also that MTO can help efficiently find well-distributed multiple optimal solutions for MOP. With the above idea, this article proposes a new multiobjective optimization method via MTO, with the following three contributions: 1) a theorem is proposed to theoretically show the relationship between MOP and MTOP and how MOP can be transformed into a MTOP; 2) based on the theoretical analysis, a multiple tasks for multiple objectives (MTMOs) framework is proposed for solving MOP efficiently; and 3) a MTMO-based evolutionary algorithm is developed to solve MOP, together with two novel strategies. One is a target point estimation strategy for transforming the MOP into a MTOP automatically and accurately. The other is an archive-based implicit knowledge transfer strategy for efficiently transferring knowledge across multiple tasks to enhance the optimization results of multiple tasks together. The superiority of the proposed algorithm is validated in extensive experiments on 15 MOPs with objective numbers varying from 3 to 20 and with six state-of-the-art algorithms as competitors. Therefore, solving MOP and even many-objective optimization problem via MTO is a new, promising, and efficient method.},
  archive      = {J_TEVC},
  author       = {Jian-Yu Li and Zhi-Hui Zhan and Yun Li and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3294307},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {172-186},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple tasks for multiple objectives: A new multiobjective optimization method via multitask optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locating drone stations for a truck-drone delivery system in continuous space. <em>TEVC</em>, <em>29</em>(1), 158-171. (<a href='https://doi.org/10.1109/TEVC.2023.3344350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck-drone delivery systems have been proposed for sustainable and economical last-mile distribution, especially in urban environments. To widen the service range, some works have recommended adding facilities, such as drone stations, considering the problem in discrete space by choosing from a predefined set. In this article, an evolutionary optimization approach to the design decision of where to locate drone stations in the continuous plane is introduced, modeled, and solved. Drone stations serve as facilities for storage, charging, and launching. A truck (or other land transport means) transports parcels to the drone stations from a depot and the drones launch from the stations and deliver the parcels to each customer. The objective is to determine the positions of the drone stations in 2-D space and establish the shortest fixed truck route from the depot through all the stations and returning to the depot. The problem is constrained by the radius of service for each drone and all customers must be served, if possible. We formulate the problem as a constrained nonlinear optimization problem and present two versions of an algorithm using particle swarm optimization (PSO) with a subordinate dynamic program. Computational results show that our approach achieves much better results than a standard commercial nonlinear solver in a similar amount of computational time for both maximizing coverage of customers and minimizing distance of the truck delivery route. A design case study concerning healthcare delivery throughout the Birmingham, Alabama (USA) metropolitan area is provided.},
  archive      = {J_TEVC},
  author       = {Lingyun Zhou and Daniel F. Silva and Alice E. Smith},
  doi          = {10.1109/TEVC.2023.3344350},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {158-171},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Locating drone stations for a truck-drone delivery system in continuous space},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding the set of nearly optimal solutions of a multiobjective optimization problem. <em>TEVC</em>, <em>29</em>(1), 145-157. (<a href='https://doi.org/10.1109/TEVC.2024.3353546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multiobjective optimization (EMO) is a highly active research field that has attracted many researchers and practitioners over the past three decades. Surprisingly, until now, the goal of almost all EMO algorithms is to compute a suitable finite size representation of the Pareto set/front of a given multiobjective optimization problem or at least a part of it. In other words, the quest is restricted to optimal solutions. In this work, we argue that the entire set of nearly optimal solutions—which includes all optimal ones—is of potential interest for the decision maker as they contain in addition to the optimal solutions alternative realizations or backup solutions. We further make a first effort to reliably compute the set of nearly optimal solutions via EMO algorithms. To this end, we first propose a new set of interest, $N_{Q,\epsilon }$ , and analyze its topology. In a next step, we propose an unbounded archiver that aims to capture $N_{Q,\epsilon }$ and analyze it with respect to monotonicity and limit behavior. After this, we discuss the related subset selection problem which comes with unbounded archivers leading to four different algorithms. Finally, we numerically investigate the behavior of the archiver and the selection strategies, and present some results when using the archiver as external archiver to three widely used multiobjective evolutionary algorithms indicating the benefit of the new approach.},
  archive      = {J_TEVC},
  author       = {Oliver Schütze and Angel E. Rodríguez-Fernandez and Carlos Segura and Carlos Hernández},
  doi          = {10.1109/TEVC.2024.3353546},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {145-157},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Finding the set of nearly optimal solutions of a multiobjective optimization problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitask optimization with lower confidence bound-based solution selection strategy. <em>TEVC</em>, <em>29</em>(1), 132-144. (<a href='https://doi.org/10.1109/TEVC.2023.3349250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) is an emerging research direction within the evolutionary computation community, attempting to concurrently solve multiple optimization tasks by exploiting the underlying synergies between the tasks. Recently, numerous explicit transfer strategies have been developed for enhancing positive transfer among optimization tasks. Nevertheless, most of these methods conduct knowledge transfer by transferring the best solutions from a source task to the target task, while ignoring the proper use of information from the target task in solution selection. As a result, the transferred solutions could not well adapt to the target task, thus limiting the effectiveness of knowledge transfer across tasks. To address this issue, this article proposes a solution selection method based on the lower confidence bound (LCB) for EMT, which is designed by leveraging task-specific information of both source and target tasks. With the proposed LCB metric, a number of high-quality solutions that could be more helpful for the target task can be selected and transferred to enhance positive transfer in EMT. To verify the effectiveness of the proposed approach, the solution selection method is embedded into several existing EMT algorithms and then evaluated on the single-objective multitasking benchmarks, the multiobjective multitasking benchmark, and a real-world application. The obtained results confirmed the generality and efficacy of the proposed solution selection approach.},
  archive      = {J_TEVC},
  author       = {Zhenzhong Wang and Lulu Cao and Liang Feng and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2023.3349250},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {132-144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitask optimization with lower confidence bound-based solution selection strategy},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speeding-up evolutionary algorithms to solve black-box optimization problems. <em>TEVC</em>, <em>29</em>(1), 117-131. (<a href='https://doi.org/10.1109/TEVC.2024.3352450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, one of the challenges of these algorithms is that they require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a tradeoff between the evaluation cost and its accuracy. In this article, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which the solutions are still properly ranked, and consequently, more evaluations can be computed in the same amount of time with minimal accuracy loss. An experimental section on four very different problems reveals that the proposed approach can reach the same objective value in less than half of the time in certain cases.},
  archive      = {J_TEVC},
  author       = {Judith Echevarrieta and Etor Arza and Aritz Pérez},
  doi          = {10.1109/TEVC.2024.3352450},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {117-131},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Speeding-up evolutionary algorithms to solve black-box optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExTrEMO: Transfer evolutionary multiobjective optimization with proof of faster convergence. <em>TEVC</em>, <em>29</em>(1), 102-116. (<a href='https://doi.org/10.1109/TEVC.2023.3349313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer multiobjective optimization promises sample-efficient discovery of near Pareto-optimal solutions to a target task by utilizing experiential priors from related source tasks. In this article, we show that in domains where evaluation data is at a premium, e.g., in scientific and engineering disciplines involving time-consuming computer simulations or complex real-world experimentation, knowledge transfer through surrogate models can be pivotal in saving sample evaluation costs. While state-of-the-art algorithms (without transfer) typically assume budgets in the order of only a few hundred evaluations, we seek to explore how far we can get on even tighter budgets. The uniqueness of our proposed expensive transfer evolutionary multiobjective optimizer (ExTrEMO) is that it can maximally utilize external information from hundreds of source datasets, including those that may be negatively correlated with the target task. This is achieved by melding evolutionary search with factorized transfer Gaussian process surrogates, capturing varied source-target correlations in potentially decentralized computation environments. We provide a regret bound analysis for ExTrEMO that translates to a theoretical proof of increasingly faster convergence as a result of multisource transfers. The theory is experimentally verified on benchmark functions and toward accelerated design of biomedical microdevices. We release our code at https://github.com/LiuJ-2023/ExTrEMO.},
  archive      = {J_TEVC},
  author       = {Jiao Liu and Abhishek Gupta and Chinchun Ooi and Yew-Soon Ong},
  doi          = {10.1109/TEVC.2023.3349313},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {102-116},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {ExTrEMO: Transfer evolutionary multiobjective optimization with proof of faster convergence},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing with low budgets: A comparison on the black-box optimization benchmarking suite and OpenAI gym. <em>TEVC</em>, <em>29</em>(1), 91-101. (<a href='https://doi.org/10.1109/TEVC.2023.3346788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing ubiquity of machine learning (ML) has led it to enter various areas of computer science, including black-box optimization (BBO). Recent research is particularly concerned with Bayesian optimization (BO). BO-based algorithms are popular in the ML community, as they are used for hyperparameter optimization and more generally for algorithm configuration. However, their efficiency decreases as the dimensionality of the problem and the budget of evaluations increase. Meanwhile, derivative-free optimization methods have evolved independently in the optimization community. Therefore, we urge to understand whether cross-fertilization is possible between the two communities, ML and BBO, i.e., whether algorithms that are heavily used in ML also work well in BBO and vice versa. Comparative experiments often involve rather small benchmarks and show visible problems in the experimental setup, such as poor initialization of baselines, overfitting due to problem-specific setting of hyperparameters, and low statistical significance. With this article, we update and extend a comparative study presented by Hutter et al. in 2013. We compare BBO tools for ML with more classical heuristics, first on the well-known Black-Box Optimization Benchmarking test suite from the COCO environment and then on Direct Policy Search for OpenAI Gym, a reinforcement learning benchmark. Our results confirm that BO-based optimizers perform well on both benchmarks when budgets are limited, albeit with a higher computational cost, while they are often outperformed by algorithms from other families when the evaluation budget becomes larger. We also show that some algorithms from the BBO community perform surprisingly well on ML tasks.},
  archive      = {J_TEVC},
  author       = {Elena Raponi and Nathanaël Carraz Rakotonirina and Jérémy Rapin and Carola Doerr and Olivier Teytaud},
  doi          = {10.1109/TEVC.2023.3346788},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {91-101},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Optimizing with low budgets: A comparison on the black-box optimization benchmarking suite and OpenAI gym},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multiobjective optimization for large-scale portfolio selection with both random and uncertain returns. <em>TEVC</em>, <em>29</em>(1), 76-90. (<a href='https://doi.org/10.1109/TEVC.2023.3349073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Big Data, managing large-scale portfolios of thousands of securities is one of the most challenging tasks in the asset management industry. This study uses an evolutionary multiobjective technique to solve large-scale portfolio optimization problems with both long-term listed and newly listed securities. The future returns of long-term listed securities are defined as random variables whose probability distributions are estimated based on sufficient historical data, while the returns of newly listed securities are defined as uncertain variables whose uncertainty distributions are estimated based on experts’ knowledge. Our approach defines security returns as theoretically uncertain random variables and proposes a three-moment optimization model with practical trading constraints. In this study, a framework for applying arbitrary multiobjective evolutionary algorithms to portfolio optimization is established, and a novel evolutionary algorithm based on large-scale optimization techniques is developed to solve the proposed model. The experimental results show that the proposed algorithm outperforms state-of-the-art evolutionary algorithms in large-scale portfolio optimization.},
  archive      = {J_TEVC},
  author       = {Weilong Liu and Yong Zhang and Kailong Liu and Barry Quinn and Xingyu Yang and Qiao Peng},
  doi          = {10.1109/TEVC.2023.3349073},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {76-90},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multiobjective optimization for large-scale portfolio selection with both random and uncertain returns},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted constrained optimization evolutionary algorithm by searching multiple kinds of global and local regions. <em>TEVC</em>, <em>29</em>(1), 61-75. (<a href='https://doi.org/10.1109/TEVC.2023.3346435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a surrogate-assisted evolutionary algorithm to tackle expensive inequality-constrained optimization problems through global exploration and local exploitation. The algorithm begins with an exploration stage that involves sampling in three kinds of global regions: 1) the feasible region; 2) the better-objective region; and 3) the converging region. Specifically, sampling in the uncertain feasible region mitigates issues caused by inaccurate objective surrogates. In addition, sampling in the uncertain region containing better-objective values than the current best-feasible solution reduces the risk of missing the global optimum due to inaccurate constraint surrogates. Moreover, sampling in the converging region facilitates quick convergence to the global feasible optimum. Following the exploration stage, promising feasible and infeasible solutions are further refined using local surrogate-based search strategies. To address the risk of missing the global optimum resulting from limited local region scope, the regions are adaptively extended if predicted infill points lie on the boundary. If an infill point is determined to showcase a better-objective value after accurate evaluation, a rewarding local search is performed within the local region. This exploration-exploitation process iterates until the computation budget is exhausted. Experimental results demonstrate that the proposed algorithm outperforms the selected state-of-the-art algorithms on the majority of tested problems.},
  archive      = {J_TEVC},
  author       = {Yong Zeng and Yuansheng Cheng and Jun Liu},
  doi          = {10.1109/TEVC.2023.3346435},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {61-75},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A surrogate-assisted constrained optimization evolutionary algorithm by searching multiple kinds of global and local regions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary instance selection with multiple partial adaptive classifiers for domain adaptation. <em>TEVC</em>, <em>29</em>(1), 46-60. (<a href='https://doi.org/10.1109/TEVC.2023.3346406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation reuses the knowledge learned from an existing (source) domain to classify unlabeled data from another related (target) domain. However, the two domains have different data distributions. Common approaches to bridge the two distributions are selecting/reweighting instances, building domain-invariant feature subspaces, or directly building adaptive classifiers. Recent domain adaptation work has shown that combining the above first two approaches before applying the third approach achieves better performance than performing each approach individually. However, most existing instance selection approaches are based on a ranking mechanism, ignore interdependences between instances, and require a predefined number of selected instances. Furthermore, adaptive classifiers are sensitive to their parameters which are challenging to optimize due to the lack of target labeled instances. This article introduces a novel evolutionary instance selection approach for domain adaptation. We propose a compacted representation and an efficient fitness function for particle swarm optimization to automatically determine the number of selected instances while considering the interdependencies among instances. This article also proposes to use multiple partial classifiers to build a more reliable and robust adaptive classifier. The results show that evolutionary instance selection selects better instances than the ranking approach. In cooperation with multiple partial classifiers, the proposed algorithm achieves better performance than nine state-of-the-art and well-known domain adaptation approaches.},
  archive      = {J_TEVC},
  author       = {Bach Hoai Nguyen and Bing Xue and Peter Andreae and Mengjie Zhang},
  doi          = {10.1109/TEVC.2023.3346406},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {46-60},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary instance selection with multiple partial adaptive classifiers for domain adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tractive population-assisted dual-population and two-phase evolutionary algorithm for constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(1), 31-45. (<a href='https://doi.org/10.1109/TEVC.2023.3345470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both dual-population and two-phase strategies are effective for utilizing infeasible solution information and significantly enhancing the ability of algorithms to solve constrained multiobjective optimization problems. However, most existing algorithms tend to underperform when facing problems with complex constraints. To address these issues, a constrained multiobjective evolutionary algorithm named DPTPEA, which combines dual-population and two-phase strategies, is proposed in this article. DPTPEA employs two collaborative populations [the exploitive population (expPop) and the tractive population (tracPop)] and divides the evolutionary process of the tracPop into two phases (Phase 1 and Phase 2). In Phase 1, the tracPop ignores constraints and drags the expPop across the infeasible region by sharing offspring information. In Phase 2, the tracPop adopts the epsilon-constrained method to converge toward the constrained Pareto front and to guide the expPop exploiting different feasible regions. Moreover, a dynamic cooperation strategy, a boundary point direction sampling strategy, and a dynamic environmental selection are proposed to improve the exploration ability of tracPop for solving complex problems. Comprehensive experiments on three popular test suites demonstrate that DPTPEA outperforms seven state-of-the-art algorithms on most test problems.},
  archive      = {J_TEVC},
  author       = {Shumin Xie and Kangshun Li and Wenxiang Wang and Hui Wang and Chaoda Peng and Hassan Jalil},
  doi          = {10.1109/TEVC.2023.3345470},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {31-45},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A tractive population-assisted dual-population and two-phase evolutionary algorithm for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge learning for evolutionary computation. <em>TEVC</em>, <em>29</em>(1), 16-30. (<a href='https://doi.org/10.1109/TEVC.2023.3278132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation (EC) is a kind of meta-heuristic algorithm that takes inspiration from natural evolution and swarm intelligence behaviors. In the EC algorithm, there is a huge amount of data generated during the evolutionary process. These data reflect the evolutionary behavior and therefore mining and utilizing these data can obtain promising knowledge for improving the effectiveness and efficiency of EC algorithms to better solve optimization problems. Considering this and inspired by the ability of human beings that acquire knowledge from the historical successful experiences of their predecessors, this article proposes a novel EC paradigm, named knowledge learning EC (KLEC). The KLEC aims to learn from historical successful experiences to obtain a knowledge library and to guide the evolutionary behaviors of individuals based on the knowledge library. The KLEC includes two main processes named learning from experiences to obtain knowledge and utilizing knowledge to guide evolution. First, KLEC maintains a knowledge library model (KLM) and updates this model by learning the successful experiences collected in every generation. Second, KLEC not only adopts the evolutionary operation but also utilizes the KLM to guide individuals for better evolution. The KLEC is a generic and effective framework, and we propose two algorithm instances of KLEC, which are knowledge learning (KL)-based differential evolution and KL-based particle swarm optimization. Also, we combine the KL framework with several state-of-the-art EC algorithms, showing that the performance of the state-of-the-art algorithms can be significantly enhanced by incorporating the KL framework.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3278132},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {16-30},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge learning for evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multiobjective optimization with escape and expansion forces. <em>TEVC</em>, <em>29</em>(1), 2-15. (<a href='https://doi.org/10.1109/TEVC.2023.3270483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraints may scatter the Pareto optimal solutions of a constrained multiobjective optimization problem (CMOP) into multiple feasible regions. To avoid getting trapped in local optimal feasible regions or a part of the global optimal feasible regions, a constrained multiobjective evolutionary algorithm (CMOEA) should consider both the escape force and the expansion force carefully during the search process. However, most CMOEAs fail to provide these two forces effectively. As a remedy for this limitation, this article proposes a method called three-population evolutionary algorithm (TPEA). TPEA maintains three populations, termed Pop1, Pop2, and Pop3. Pop1 is a regular population, updated with a constrained NSGA-II variant. Pop2 and Pop3 are two auxiliary populations, containing the innermost and outermost nondominated infeasible solutions, respectively. The analysis reveals that these two types of nondominated infeasible solutions can contribute to the generation of escape and expansion forces, respectively. Due to these two forces, TPEA is likely to identify more global optimal feasible regions, which is crucial for constrained multiobjective optimization. Also, a mating selection strategy is developed in TPEA to coordinate the interaction among these three populations. Extensive experiments on 58 benchmark CMOPs and 35 real-world ones demonstrate that TPEA is significantly superior or comparable to six state-of-the-art CMOEAs on most test instances.},
  archive      = {J_TEVC},
  author       = {Zhi-Zhong Liu and Fan Wu and Juan Liu and Yunchuan Qin and Kenli Li},
  doi          = {10.1109/TEVC.2023.3270483},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {2-15},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained multiobjective optimization with escape and expansion forces},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
