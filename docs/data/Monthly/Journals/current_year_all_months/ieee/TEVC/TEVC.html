<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TEVC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tevc">TEVC - 102</h2>
<ul>
<li><details>
<summary>
(2025). Performance metrics for multiobjective optimization under noise. <em>TEVC</em>, <em>29</em>(4), 1449-1455. (<a href='https://doi.org/10.1109/TEVC.2024.3438115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the challenge when evaluating multiobjective optimization algorithms under noise. It argues that it is important to take into account possible selection errors by a decision maker, due to inaccurate estimates of a solution’s true objective values. It demonstrates that commonly used performance metrics do not properly account for such errors, and proposes two alternative performance metrics that do account for such errors by adapting the popular R2 and ${\mathrm { IGD}}^{+}$ metrics.},
  archive      = {J_TEVC},
  author       = {Juergen Branke},
  doi          = {10.1109/TEVC.2024.3438115},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1449-1455},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Performance metrics for multiobjective optimization under noise},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison of large language models and genetic programming for program synthesis. <em>TEVC</em>, <em>29</em>(4), 1434-1448. (<a href='https://doi.org/10.1109/TEVC.2024.3410873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models have recently become known for their ability to generate computer programs, especially through tools, such as GitHub Copilot, a domain where genetic programming (GP) has been very successful so far. Although they require different inputs (free-text versus input/output examples) their goal is the same—program synthesis. Therefore, in this work, we compare how well GitHub Copilot and GP perform on common program synthesis benchmark problems. We study the structure and diversity of the generated programs by using well-known software metrics. We find that GitHub Copilot and GP solve a similar number of benchmark problems (85.2% versus 77.8%, respectively). We find that GitHub Copilot generated smaller and less complex programs as GP, while GP is able to find new and unique problem solving strategies. This increase in diversity of solutions comes at a cost. When analyzing the success rates for 100 runs per problem, GitHub Copilot outperforms GP on over 50% of the problems.},
  archive      = {J_TEVC},
  author       = {Dominik Sobania and Justyna Petke and Martin Briesch and Franz Rothlauf},
  doi          = {10.1109/TEVC.2024.3410873},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1434-1448},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A comparison of large language models and genetic programming for program synthesis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary alternating direction method of multipliers for constrained multiobjective optimization with unknown constraints. <em>TEVC</em>, <em>29</em>(4), 1419-1433. (<a href='https://doi.org/10.1109/TEVC.2024.3425629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) pervade real-world applications in science, engineering, and design. Constraint violation (CV) has been a building block in designing evolutionary multiobjective optimization (EMO) algorithms for solving CMOPs. However, in certain scenarios, constraint functions might be unknown or inadequately defined, making CV unattainable and potentially misleading for the conventional constrained EMO algorithms. To address this issue, we present the first of its kind evolutionary optimization framework, inspired by the principles of the alternating direction method of multipliers that decouples objective and constraint functions. This framework tackles CMOPs with unknown constraints by reformulating the original problem into an additive form of two subproblems, each of which is allotted a dedicated evolutionary population. Notably, these two populations operate toward complementary evolutionary directions during their optimization processes. In order to minimize discrepancy, their evolutionary directions alternate, aiding the discovery of feasible solutions. Comparative experiments conducted against the five state-of-the-art constrained EMO algorithms on 120 benchmark test problem instances with varying properties as well as two real-world engineering optimization problems demonstrate the effectiveness and superiority of our proposed framework. Its salient features include faster convergence and enhanced resilience to various Pareto front shapes.},
  archive      = {J_TEVC},
  author       = {Shuang Li and Ke Li and Wei Li and Ming Yang},
  doi          = {10.1109/TEVC.2024.3425629},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1419-1433},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary alternating direction method of multipliers for constrained multiobjective optimization with unknown constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on evolutionary computation for identifying biomarkers of complex disease. <em>TEVC</em>, <em>29</em>(4), 1400-1418. (<a href='https://doi.org/10.1109/TEVC.2024.3414442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological markers (i.e., biomarkers) are the key to predicting disease states and revealing the molecular mechanisms in precision medicine of complex diseases (e.g., cancer). With the advancement of high-throughput sequencing technology, there has been a significant increase in the volume and diversity of known disease omics data, where many methods have been developed to identify potential disease biomarkers (DBs) for mining the complex dynamics. As emerging artificial intelligence techniques, evolutionary computation (EC) has found extensive application in the identification of DBs, making significant achievements in mining disease omics data. However, there is currently no survey or analysis available of the existing EC methods to identify DBs on the disease omics data, resulting in missed opportunities to enhance performance and achieve successful applications in precision medicine. This article aims to present a comprehensive overview of the latest EC methods for mining the dynamics of DBs, including the summary of biomolecular omics datasets, the classification of the EC methods for DB discovery, and performance comparisons of the typical EC methods. Additionally, this article discusses challenges and potential future directions of the EC methods in the identification of DBs, providing directions and prospects for future research.},
  archive      = {J_TEVC},
  author       = {Jing Liang and Zhuo Hu and Ying Bi and Han Cheng and Kunjie Yu and Cai-Tong Yue and Xianfang Wang and Wei-Feng Guo},
  doi          = {10.1109/TEVC.2024.3414442},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1400-1418},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary computation for identifying biomarkers of complex disease},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Targeted pareto optimization for subset selection with monotone objective function and cardinality constraint. <em>TEVC</em>, <em>29</em>(4), 1386-1399. (<a href='https://doi.org/10.1109/TEVC.2024.3431928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subset selection, a fundamental problem in various domains, is to choose a subset of elements from a large candidate set under a given objective or multiple objectives. Pareto optimization for subset selection (POSS) has emerged as a powerful paradigm for addressing subset selection problems. Recently, some POSS variants have been proposed to further improve its performance. In this article, we propose a new POSS variant, named targeted POSS (TPOSS). TPOSS differs from POSS in four aspects: 1) problem formulation; 2) population initialization; 3) mutation; and 4) environmental selection. The main idea of TPOSS is to focus the search on the target region of subset selection with respect to the subset cardinality in order to improve the search efficiency. We conduct comprehensive experiments to compare TPOSS with six state-of-the-art algorithms on three subset selection tasks (i.e., sparse regression, unsupervised feature selection, and hypervolume subset selection) where the size of the candidate sets ranges from 20 to 400. Experimental results show that with respect to the objective value of the best feasible subset, TPOSS outperforms the other algorithms on all the three tasks, which suggests the potential of TPOSS to enhance subset selection in various domains.},
  archive      = {J_TEVC},
  author       = {Ke Shang and Guotong Wu and Lie Meng Pang and Hisao Ishibuchi},
  doi          = {10.1109/TEVC.2024.3431928},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1386-1399},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Targeted pareto optimization for subset selection with monotone objective function and cardinality constraint},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning assisted genetic programming ensemble hyper-heuristics for dynamic scheduling of container port trucks. <em>TEVC</em>, <em>29</em>(4), 1371-1385. (<a href='https://doi.org/10.1109/TEVC.2024.3381042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient truck dispatching is crucial for optimizing container terminal operations within dynamic and complex scenarios. Despite good progress being made recently with more advanced uncertainty-handling techniques, existing approaches still have generalization issues and require considerable expertise and manual interventions in algorithm design. In this work, we present deep reinforcement learning-assisted genetic programming hyper-heuristics (DRL-GPHHs) and their ensemble variant (DRL-GPEHH). These frameworks utilize a reinforcement learning (RL) agent to orchestrate a set of auto-generated genetic programming (GP) low-level heuristics, leveraging the collective intelligence, ensuring advanced robustness and an increased level of automation of the algorithm development. DRL-GPEHH, notably, excels through its concurrent integration of a GP heuristic ensemble, achieving enhanced adaptability and performance in complex, dynamic optimization tasks. This method effectively navigates traditional convergence issues of deep RL (DRL) in sparse reward and vast action spaces, while avoiding the reliance on expert-designed heuristics. It also addresses the inadequate performance of the single GP individual in varying and complex environments and preserves the inherent interpretability of the GP approach. Evaluations across various real port operational instances highlight the adaptability and efficacy of our frameworks. Essentially, innovations in DRL-GPHH and DRL-GPEHH reveal the synergistic potential of RL and GP in dynamic truck dispatching, yielding transformative impacts on algorithm design and significantly advancing solutions to complex real-world optimization problems.},
  archive      = {J_TEVC},
  author       = {Xinan Chen and Ruibin Bai and Rong Qu and Jing Dong and Yaochu Jin},
  doi          = {10.1109/TEVC.2024.3381042},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1371-1385},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Deep reinforcement learning assisted genetic programming ensemble hyper-heuristics for dynamic scheduling of container port trucks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leader prediction for multiobjective particle swarm optimization. <em>TEVC</em>, <em>29</em>(4), 1356-1370. (<a href='https://doi.org/10.1109/TEVC.2024.3417978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the design of multiobjective particle swarm optimization (MOPSO) algorithms, swarm leaders, i.e., the personal best (pbest) and global best (gbest), are expected to guide the particles toward Pareto-optimal solutions. However, most existing MOPSO algorithms focus on selecting such leaders from the archive of candidate solutions to approximate the Pareto front (PF) that may not yield good approximations of the Pareto set (PS). To address this challenge, this work proposes to predict both pbest and gbest for each particle by explicitly approximating the manifold structure of the PS, following the regularity property of multiobjective optimization problems. Thus, we design a leader prediction-based MOPSO (PPSO) algorithm. In our algorithm, a self-organizing mapping (SOM) method is adopted at each iteration to capture the manifold structure from the current swarm to predict leaders. Specifically, pbest is pinpointed by mapping the particle onto the neuron of SOM, while gbest is estimated by randomly selecting from the neighborhood neurons. In this way, the particles of a swarm in PPSO are guided by the predicted pbest and gbest to approximate the Pareto-optimal solutions. The developed PPSO is empirically verified with several representative algorithms, on several benchmark test instances and real-world problems. Experimental results have demonstrated the advantages of leader prediction for MOPSO over other approaches.},
  archive      = {J_TEVC},
  author       = {Shuai Wang and Aimin Zhou},
  doi          = {10.1109/TEVC.2024.3417978},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1356-1370},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Leader prediction for multiobjective particle swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary art attack for black-box adversarial example generation. <em>TEVC</em>, <em>29</em>(4), 1343-1355. (<a href='https://doi.org/10.1109/TEVC.2024.3391063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved remarkable performance in various tasks, including image classification. However, recent research has revealed the susceptibility of trained DNNs to subtle perturbations introduced into input images. Addressing these vulnerabilities is pivotal, leading to a significant area of study focused on developing attack algorithms capable of generating potent adversarial images. In scenarios where access to gradient information is restricted (black-box scenario), many existing methods introduce optimized perturbations to each individual pixels of an image to cause trained DNNs to misclassify. However, due to the high-dimensional nature of this approach, current methods have inherent limitations. In contrast, our proposed approach involves the construction of perturbations by concatenating a series of overlapping semi-transparent shapes. Through the optimization of these shapes’ characteristics, we generate perturbations that result in the desired misclassification by the DNN. By conducting a series of attacks on state-of-the-art DNNs trained of CIFAR-10 and Imagenet datasets, our method consistently outperforms existing attack algorithms in terms of both query efficiency and success rate.},
  archive      = {J_TEVC},
  author       = {Phoenix Neale Williams and Ke Li and Geyong Min},
  doi          = {10.1109/TEVC.2024.3391063},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1343-1355},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary art attack for black-box adversarial example generation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prediction and weak coevolution-based dynamic constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1328-1342. (<a href='https://doi.org/10.1109/TEVC.2024.3418470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective evolutionary algorithms (DMOEAs) have gained great popularity in dealing with the dynamic multiobjective optimization problems (DMOPs). However, the existing studies have difficulties in tackling DMOPs subject to (dynamic) constraints. In this article, we propose a prediction and weak coevolutionary multiobjective optimization algorithm (PWDCMO) to handle the dynamic constrained multiobjective optimization problems (DCMOPs), where a prediction strategy is employed to forecast potential optimal regions under the new environment, with a weak coevolutionary constrained multiobjective optimization (CCMO) as the optimizer aiming at balancing exploration and convergence. The proposed method is compared with the four popular dynamic constrained multiobjective evolutionary algorithms (DCMOEAs) on six test instances from two various test suites with their convergence and the overall performance being discussed. Furthermore, the performance of the proposed prediction strategy is also investigated to observe its impact on the final results. Additionally, the PWDCMO is employed in the optimization of an integrated coal mine energy system (ICMES) to validate the proficiency in addressing real world problems. Experimental results demonstrate the superiority of PWDCMO.},
  archive      = {J_TEVC},
  author       = {Dunwei Gong and Miao Rong and Na Hu and Yan Wang and Witold Pedrycz and Shengxiang Yang},
  doi          = {10.1109/TEVC.2024.3418470},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1328-1342},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A prediction and weak coevolution-based dynamic constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A syntactic problem solver learning landscape structures for clinical scheduling. <em>TEVC</em>, <em>29</em>(4), 1313-1327. (<a href='https://doi.org/10.1109/TEVC.2024.3378911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article attempts to derive a mathematical formulation for real-practice clinical laboratory scheduling, and to present a syntactic problem solver by leveraging instances’ landscape structures to infer the most suitable search strategy. After formulating scheduling of medical tests as a distributed scheduling problem in heterogeneous, flexible job shop environment, we establish a mixed integer programming model to minimize mean test turnaround time. Preliminary landscape analysis sustains that these clinics-orientated scheduling instances are difficult to solve under the same search strategy. The search difficulty motivates the search for a syntactic problem solver where relatedness between domain’s syntactic features and search strategies help identify effective strategies. The challenge in designing a syntactic problem solver—which landscape features to choose as domain’s syntactic features to accurately reflect instance hardness under different search strategies—are addressed. Under various local search move operators, we investigate the changes in instance landscape structures and find that the single-move size for local search operators, local-global optima connectivity, landscape ruggedness, and plateau size fairly predict the efficacy of the local searches. The above relationship is refined into a deterministic association between instance size and local search, thereby forming the syntactic problem solver. When faced with new instances, the solver automatically instantiates the best local search algorithm for various scenarios. Extensive experiments demonstrate that the proposed syntactic solver excels not only in clinical laboratory scheduling problems but also in publicly available benchmark.},
  archive      = {J_TEVC},
  author       = {Keyao Wang and Bo Liu},
  doi          = {10.1109/TEVC.2024.3378911},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1313-1327},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A syntactic problem solver learning landscape structures for clinical scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast evaluation-based bacteria colony chemotaxis algorithm for dynamic interval multiobjective optimization problems. <em>TEVC</em>, <em>29</em>(4), 1298-1312. (<a href='https://doi.org/10.1109/TEVC.2024.3418858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many real-world applications with uncertainties that can be modeled as the dynamic interval multiobjective optimization problems (DI-MOPs). However, it is challenging for the traditional algorithms to converge rapidly before time-varying parameters change to obtain optimal solutions under interval objectives. So far, there is a lack of studies on the evaluation methods for interval optimal solutions in dynamic problems. Therefore, a fast evaluation framework is proposed in this article to tackle these issues. In this framework, we first derive a new hash function based on the Canberra distance and provide a theoretical proof of the validity and local sensitivity of the hash function, from which a Canberra locality sensitive hashing (CLSH) is constructed. The CLSH accelerates the search for interval evaluation objects in uncertain environments. Further, we propose an adaptive interval crowding distance (AICD) with relaxed constraints to obtain a global improvement in the quality of the solutions. The candidate solutions in the above framework are generated by the environment awareness and directed migration of the mutiobjective bacteria colony chemotaxis (MOBCC) algorithm. This complete algorithm is called the dynamic interval MOBCC (DI-MOBCC). In addition, the theoretical proofs of the validity and local sensitivity of hash functions are also provided. Computational results on the eight benchmark optimization problems and a path planning of the mobile robots in uncertain environments validate that the DI-MOBCC is more competitive than the other state of the art algorithms in tackling DI-MOPs.},
  archive      = {J_TEVC},
  author       = {Chen-Hao Xu and Zhi-Gang Lu and Er-Shun Du and Jiang-Feng Zhang and Xiao-Qiang Guo and Xue-Ping Li and Xiang-Xing Kong and Yan-Lin Li},
  doi          = {10.1109/TEVC.2024.3418858},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1298-1312},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A fast evaluation-based bacteria colony chemotaxis algorithm for dynamic interval multiobjective optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic neural network-based preselection for expensive multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1284-1297. (<a href='https://doi.org/10.1109/TEVC.2024.3409431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of surrogate-assisted evolutionary algorithms (SAEAs) have been proposed for the expensive multiobjective optimization problems (EMOPs), building cheap surrogate models to replace the expensive real function evaluations (FEs). However, the search efficiency of these SAEAs is not yet satisfactory. More efforts are needed to further exploit useful information from the real FEs in order to better guide the search process. Facing this challenge, this article proposes a hyperbolic neural network (HNN)-based preselection operator to accelerate the optimization process based on the limited evaluated solutions. First, the preselection task is modeled as a multilabel classification problem where solutions are classified into different layers (ordinal categories) through the $\epsilon $ -relaxed objective aggregation. Second, in order to resemble the hierarchical structure of candidate solutions, a HNN is applied to tackle the multilabel classification problem. The reason for using HNN is that hyperbolic spaces more closely resemble hierarchical structures than the Euclidean spaces. Moreover, to alleviate the data deficiency issue, a data augmentation strategy is employed for training the HNN. In order to evaluate its performance, the proposed HNN-based preselection operator is embedded into two SAEAs. Experimental results on the two benchmark test suites and three real-world problems with up to 11 objectives and 150 decision variables involving seven state-of-the-art algorithms demonstrate the effectiveness of the proposed method.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yanting Yang and Wenjing Hong and Peng Yang and Aimin Zhou},
  doi          = {10.1109/TEVC.2024.3409431},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1284-1297},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Hyperbolic neural network-based preselection for expensive multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global and local search experience-based evolutionary sequential transfer optimization. <em>TEVC</em>, <em>29</em>(4), 1269-1283. (<a href='https://doi.org/10.1109/TEVC.2024.3417325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary sequential transfer optimization (ESTO), which aims to better optimize a target task using the knowledge extracted from a number of previously solved source tasks, has been gaining continually increasing research attention over the years. Particularly, solution-based ESTO (S-ESTO) that transfers task solutions has been receiving much popularity due to its ease of implementation and optimizer independency. However, the existing S-ESTO algorithms put much emphasis on utilizing source optimized solutions standing for global search experience without being aware of the potential of intermediate solutions that represent local optimization experience. Besides, most of them cannot take full advantage of the solution data from evolutionary search. In the light of the above, this study aims to develop a global and local search experience-based solution transfer technique to maximally release the potential of optimization experience hidden in the source tasks. First, a novel transferability metric named landscape encoding-based rank correlation (LERC) is developed. Then, we propose to divide the optimization experience into two classes: 1) global and 2) local search experience. Accordingly, by instantiating LERC into global and local versions, we develop two distinct transfer methods to exploit the global and local search experience, respectively. Finally, by combining the two transfer methods, we propose an S-ESTO algorithm that can transfer the global and local search experience simultaneously for maximum performance enhancement for the target task. Experiments conducted on a set of benchmark problems and a practical case study verify the efficacy of the proposed methods. The source code of our algorithm is available athttps://github.com/ccm831143/GL-LERC.},
  archive      = {J_TEVC},
  author       = {Chenming Cao and Kai Zhang and Xiaoming Xue and Kay Chen Tan and Jian Wang and Liming Zhang and Piyang Liu and Xia Yan},
  doi          = {10.1109/TEVC.2024.3417325},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1269-1283},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Global and local search experience-based evolutionary sequential transfer optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient greedy decremental hypervolume subset selection using space partition tree. <em>TEVC</em>, <em>29</em>(4), 1254-1268. (<a href='https://doi.org/10.1109/TEVC.2024.3400801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of evolutionary multiobjective optimization, the hypervolume (HV) indicator serves as a crucial metric for assessing the quality of solution sets. Due to the high costs in HV computation, HV-based optimization algorithms always meet the challenge of finding a certain number of points in a given point set to maximize the HV indicator, especially when there are many objectives. In response, the greedy decremental algorithm for HV subset selection problem (gHSSD) has emerged as a noteworthy alternative. This article introduces a general algorithm for gHSSD, applicable in any dimensionality above two. The proposed algorithm leverages a space partition tree and incorporates a once-build-multiple-use strategy, effectively reducing time complexity. We prove that the proposed algorithm has a time complexity of $O((n-k+\sqrt {n})n^{{}({d-1}/{2})}\log n)$ where n is the number of points, k is the number of points to be reserved, and d the dimensionality. Theoretically, this complexity is competitive with the current best algorithms for $d=3, 4$ and better than them for all $5\le d\le 7$ . To validate our algorithm, we have conducted extensive tests on various random point sets and multiobjective optimization benchmarks. Experimental results suggest that our implementation is more efficient than or competitive with state-of-the-art algorithms on many instances as n increases for $d=3,4$ .},
  archive      = {J_TEVC},
  author       = {Jingda Deng and Jianyong Sun and Qingfu Zhang and Hui Li},
  doi          = {10.1109/TEVC.2024.3400801},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1254-1268},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Efficient greedy decremental hypervolume subset selection using space partition tree},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitasking descriptor optimization for point cloud registration. <em>TEVC</em>, <em>29</em>(4), 1239-1253. (<a href='https://doi.org/10.1109/TEVC.2024.3417416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud registration (PCR) is an important task for other point cloud tasks. Feature-based methods are widely adopted for their speed and efficiency in PCR. The descriptive capability of features extracted by a single geometric descriptor is limited. Descriptive capabilities can be improved by concatenating features extracted from multiple descriptors. However, due to the existence of redundant and irrelevant features, the correct corresponding points are difficult to match, which further affects the registration effect. We propose an evolutionary multitasking point cloud descriptor optimization method. Integrate existing descriptors to optimize descriptors with stronger description ability. Labeling features to calculate the feature importance for the registration and generating multitasks. In optimized processing, approximate evaluation which is calculated by prior correspondence saved in the database replaces the expensive searching correspondences process in the entire point cloud. Finally, a multiscale filter is developed to remove error correspondences by the geometric information from multiple scale descriptor features. Experimental demonstrate that the proposed approach can optimize a feature subset with higher-descriptive capability compared to other methods and show superior PCR performance on 14 point cloud models. This is the first paper on point cloud descriptor optimization, which provides a new idea for PCR research.},
  archive      = {J_TEVC},
  author       = {Yue Wu and Jinlong Sheng and Hangqi Ding and Peiran Gong and Hao Li and Maoguo Gong and Wenping Ma and Qiguang Miao},
  doi          = {10.1109/TEVC.2024.3417416},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1239-1253},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitasking descriptor optimization for point cloud registration},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact calculation and properties of the r2 multiobjective quality indicator. <em>TEVC</em>, <em>29</em>(4), 1227-1238. (<a href='https://doi.org/10.1109/TEVC.2024.3440571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality indicators play an essential role in evolutionary multiobjective optimization (EMO). Most likely the most often used quality indicator in EMO is hypervolume, due to its strict monotonicity with respect to the dominance relation. However, hypervolume is not free of some weak points. For example, a number of recent papers pointed out its high sensitivity to the specification of the reference point. Furthermore, hypervolume is based on fully geometric reasoning which may lead to some undesired results. Thus, it is worth to consider also other quality indicators. In this article, we prove that another well-known $R2$ quality indicator is also strictly monotonic with respect to the dominance relation when calculated exactly and the reference point strongly dominates any solution in the evaluated set. Furthermore, we adapt the improved quick hypervolume algorithm to the exact calculation of $R2$ indicator. To our knowledge, this is the first exact algorithm for $R2$ calculation with publicly available implementation. In addition, through both theoretical analysis and computational experiments, we show that $R2$ performs consistently for Pareto fronts with different shapes. We discuss also differences of Pareto fronts representations generated by an indicator-based EMO with hypervolume and $R2$ , where the latter tends to generate solutions having a high chance to be preferred by the decision maker, not necessarily uniformly distributed in geometric sense. All of these results make $R2$ a sound alternative or a complement to hypervolume in EMO.},
  archive      = {J_TEVC},
  author       = {Andrzej Jaszkiewicz and Piotr Zielniewicz},
  doi          = {10.1109/TEVC.2024.3440571},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1227-1238},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exact calculation and properties of the r2 multiobjective quality indicator},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-task differential evolutionary algorithm based on bi-space similarity. <em>TEVC</em>, <em>29</em>(4), 1215-1226. (<a href='https://doi.org/10.1109/TEVC.2024.3398436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-task differential evolutionary (DE) algorithm is an effective way to optimize multiple tasks simultaneously. The optimization performance of the algorithm decreases due to the negative transfer when the number of tasks is large. To address this problem, a many-task DE algorithm based on bi-space similarity (MaTDE-BSS) is proposed to improve the positive transfer. First, the bi-space similarity metric is designed to characterize intertask similarity quantitatively. The decision space similarity and objective space similarity are considered simultaneously in the bi-space similarity metric. Second, a task selection strategy based on evolutionary state is proposed to select the optimal source task from the source task library accurately. The source task library based on bi-space similarity metric is built for storing source tasks. Finally, a dynamic knowledge transfer strategy is proposed to improve the efficiency of knowledge positive transfer in the many-task optimization. Parameters of the knowledge transfer strategy are adjusted according to bi-space similarity metric adaptively. In addition, the experimental results show that MaTDE-BSS is able to evaluate the intertask similarity more comprehensively. And MaTDE-BSS is more competitive compared to other many-task evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Ying Hou and Yanjie Shen and Honggui Han and Jingjing Wang},
  doi          = {10.1109/TEVC.2024.3398436},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1215-1226},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Many-task differential evolutionary algorithm based on bi-space similarity},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual mutation-based evolutionary algorithm for dynamic multiobjective optimization with undetectable changes. <em>TEVC</em>, <em>29</em>(4), 1199-1214. (<a href='https://doi.org/10.1109/TEVC.2024.3424393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current research on dynamic multiobjective optimization problems (DMOPs) assumes that environmental changes can be detectable. However, undetectable changes are frequently encountered in real-world applications, which pose a serious challenge for the existing methods. Because undetectable changes can lead to the failure of change detection techniques, thereby making it difficult to adapt to environmental changes for most algorithms. Therefore, to effectively deal with DMOPs with undetectable changes, this work proposes a dual mutation-based dynamic multiobjective evolutionary algorithm (DM-DMOEA). The proposed DM-DMOEA incorporates the following two main components. First, based on the exploration level of the population, an adaptive selection strategy is proposed, which enables the adaptive identification of individuals for mutation. Second, a dual mutation scheme is developed, utilizing both the polynomial mutation and the Gaussian mutation. These mutation operations are applied on the selected individuals to generate the mutated individuals, allowing for diverse exploration in the search space. After conducting the above two strategies, the population will evolve by the evolutionary criterion of multiobjective optimization. As a result, the algorithm can effectively adapt to undetectable changes in the environment. Comprehensive empirical studies are conducted on different benchmark functions and a real-world application to evaluate the performance of DM-DMOEA. Experimental results have demonstrated that DM-DMOEA is competitive in tracking the Pareto front over time when facing undetectable changes.},
  archive      = {J_TEVC},
  author       = {Yuanchao Liu and Lixin Tang and Jinliang Ding and Qingda Chen and Kanrong Liu and Jianchang Liu},
  doi          = {10.1109/TEVC.2024.3424393},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1199-1214},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A dual mutation-based evolutionary algorithm for dynamic multiobjective optimization with undetectable changes},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MQL-MM: A meta-Q-learning-based multiobjective metaheuristic for energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem. <em>TEVC</em>, <em>29</em>(4), 1183-1198. (<a href='https://doi.org/10.1109/TEVC.2024.3399314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since severe environmental problem in manufacturing industries is becoming increasingly prominent, energy-efficient production scheduling has gained more and more attentions. This article studies an energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem (EEDFHBFSP), where processing time and setup time are uncertain. The objective is to minimize fuzzy makespan and total fuzzy energy consumption simultaneously. To solve such problem, a mixed-integer linear programming model is first presented to format it. Then, a meta-Q-learning-based multiobjective metaheuristic (MQL-MM) is proposed. In MQL-MM, a machine-position-based dispatch rule is designed as the decoding scheme. A decomposition-based constructive heuristic (DCH) is employed to generate the initial population with high quality and diversity. Several problem-specific search operators are developed to explore and exploit the solution space. A meta-Q-learning-based multiobjective search framework is presented to guide the using of search operators, which includes a meta-training phase and an adaptive search phase. The meta-training phase is employed to train the search operators to construct the Q-learning model. The adaptation search phase utilizes such model to conduct the automatic selection of the search operators. Moreover, an energy-saving strategy is designed to improve the candidate solutions. Finally, we conduct extensive experiments. The experimental results show that the designs of MQL-MM are effective, and MQL-MM performs better than several well-performing methods on solving EEDFHBFSP.},
  archive      = {J_TEVC},
  author       = {Zhongshi Shao and Weishi Shao and Jianrui Chen and Dechang Pi},
  doi          = {10.1109/TEVC.2024.3399314},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1183-1198},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MQL-MM: A meta-Q-learning-based multiobjective metaheuristic for energy-efficient distributed fuzzy hybrid blocking flow-shop scheduling problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riesz s-energy as a diversity indicator in evolutionary multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 1168-1182. (<a href='https://doi.org/10.1109/TEVC.2024.3405197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the diversity of a Pareto front approximation (PFA) is critical when comparing the performance of multiobjective evolutionary algorithms (MOEAs). In the literature, some quality indicators (QIs) measure diversity according to their specific preferences. However, just a few QIs have mathematical properties proven. In this article, we propose the Riesz s-energy $(E_{s})$ as a QI to evaluate the diversity and spread of PFAs. Theoretical results show that $E_{s}$ holds 1) some of the Weitzman properties of a desirable diversity QI; 2) monotonicity; 3) the submodularity property (for $-E_{s}$ ); and 4) that it is invariant under rotations. We provide numerical evidence on the behavior of $E_{s}$ in both artificial PFAs and PFAs generated by state-of-the-art MOEAs. The mathematical properties that $E_{s}$ satisfies show its usefulness when it is utilized as a diversity QI in evolutionary multiobjective optimization.},
  archive      = {J_TEVC},
  author       = {Jesús Guillermo Falcón-Cardona and Lourdes Uribe and Pablo Rosas},
  doi          = {10.1109/TEVC.2024.3405197},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1168-1182},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Riesz s-energy as a diversity indicator in evolutionary multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A branch-and-bound enhanced cooperative evolutionary algorithm for the hybrid seru system scheduling considering worker heterogeneity. <em>TEVC</em>, <em>29</em>(4), 1153-1167. (<a href='https://doi.org/10.1109/TEVC.2024.3432745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid seru manufacturing mode widely exists in many real-world production enterprises, where workers are usually partially cross-trained due to high-training costs and employee turnover. However, the hybrid seru system scheduling problem considering worker heterogeneity (HSSWH) has rarely been studied in academia. To fill the gap, this article introduces a branch-and-bound enhanced cooperative evolutionary algorithm (BBCEA) to solve the HSSWH. Three core search components and an evaluation component are proposed in BBCEA, which are crafted to be problem-specific. In the exploration search component, a probability model sampling method and crossover collaborate to generate offspring with high quality and diversity. In the exploitation search component, five knowledge-based operators collaborate with a knowledge-guided operator selection strategy, which is designed by fully utilizing the problem properties and feedback information. In the exact search component, a branch-and-bound method is designed to solve the bottom layer subproblem precisely, which can greatly improve the effectiveness of the algorithm. In the evaluation component, a look-up table method is proposed to reduce computation effort by avoiding duplicate calculations. Numerical experimental results validate the superiority of the BBCEA in addressing the HSSWH, which can obtain the best solution on 95% of the instances compared with the state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Yuting Wu and Ling Wang and Jing-Fang Chen},
  doi          = {10.1109/TEVC.2024.3432745},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1153-1167},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A branch-and-bound enhanced cooperative evolutionary algorithm for the hybrid seru system scheduling considering worker heterogeneity},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained probabilistic pareto dominance for expensive constrained multiobjective optimization problems. <em>TEVC</em>, <em>29</em>(4), 1138-1152. (<a href='https://doi.org/10.1109/TEVC.2024.3394005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new parameterless constraint-handling technique, named constrained probabilistic Pareto dominance (CPPD), for expensive constrained multiobjective optimization problems (CMOPs). In CPPD, when comparing two solutions, in terms of each original objective, we design a new objective for each solution, which is the negative product of two probabilities calculated based on the predicted fitness mean values and uncertainty information provided by Kriging models: 1) the probability that this solution satisfies all constraints, denoted as Probability of Feasibility (PoF) and 2) the probability that this solution is better than the other on the original objective, denoted as PoB. It is evident that for each solution, PoF and PoB indicate its feasibility and its optimality on the corresponding original objective, respectively. Then, Pareto dominance based on new objectives is executed. As a result, both competitive feasible solutions and promising infeasible solutions with good diversity can be preserved by CPPD. These two kinds of solutions can help the population to exploit the located feasible parts and to explore new feasible parts, respectively. Further, based on CPPD, we develop a Pareto-based Kriging-assisted constrained multiobjective evolutionary algorithm (called PEA) to deal with expensive CMOPs with two or three objectives. Finally, PEA is generalized to solve expensive constrained many-objective optimization problems, named $\textrm {PEA}^{+}$ . The effectiveness of CPPD, PEA, and $\textrm {PEA}^{+}$ is verified by comprehensive experiments.},
  archive      = {J_TEVC},
  author       = {Zhiyao Zhang and Yong Wang and Guangyong Sun and Tong Pang and Ke Tang},
  doi          = {10.1109/TEVC.2024.3394005},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1138-1152},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained probabilistic pareto dominance for expensive constrained multiobjective optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRBench++: Principled benchmarking of symbolic regression with domain-expert interpretation. <em>TEVC</em>, <em>29</em>(4), 1127-1137. (<a href='https://doi.org/10.1109/TEVC.2024.3423681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic regression (SR) searches for analytic expressions that accurately describe studied phenomena. The main promise of this approach is that it may return an interpretable model that can be insightful to users, while maintaining high accuracy. The current standard for benchmarking these algorithms is SRBench, which evaluates methods on hundreds of datasets that are a mix of real-world and simulated processes spanning multiple domains. At present, the ability of SRBench to evaluate interpretability is limited to measuring the size of expressions on real-world data, and the exactness of model forms on synthetic data. In practice, model size is only one of many factors used by subject experts to determine how interpretable a model truly is. Furthermore, SRBench does not characterize algorithm performance on specific, challenging subtasks of regression, such as feature selection and evasion of local minima. In this work, we propose and evaluate an approach to benchmarking SR algorithms that addresses these limitations of SRBench by 1) incorporating expert evaluations of interpretability on a domain-specific task, and 2) evaluating algorithms over distinct properties of data science tasks. We evaluate 12 modern SR algorithms on these benchmarks and present an in-depth analysis of the results, discuss current challenges of SR algorithms and highlight possible improvements for the benchmark itself.},
  archive      = {J_TEVC},
  author       = {F. O. de Franca and M. Virgolin and M. Kommenda and M. S. Majumder and M. Cranmer and G. Espada and L. Ingelse and A. Fonseca and M. Landajuela and B. Petersen and R. Glatt and N. Mundhenk and C. S. Lee and J. D. Hochhalter and D. L. Randall and P. Kamienny and H. Zhang and G. Dick and A. Simon and B. Burlacu and Jaan Kasak and Meera Machado and Casper Wilstrup and W. G. La Cava},
  doi          = {10.1109/TEVC.2024.3423681},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1127-1137},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {SRBench++: Principled benchmarking of symbolic regression with domain-expert interpretation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial AutoEncoder-based large-scale dynamic multiobjective evolutionary algorithm. <em>TEVC</em>, <em>29</em>(4), 1112-1126. (<a href='https://doi.org/10.1109/TEVC.2024.3412049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) are often scaled to large-scale scenarios in real-world applications, which inevitably must face the triple challenges of massive search space, dynamic environmental changes and multiobjective conflicts simultaneously. This article proposes an adversarial autoencoder-based large-scale dynamic multiobjective evolutionary framework. It integrates deep generative modeling techniques and large-scale multiobjective evolutionary algorithms (LMOEAs) to solve large-scale DMOPs effectively and efficiently. Specifically, an adversarial autoencoder-based deep generative network training architecture is proposed for high-dimensional decision variables in large-scale DMOPs. It can transfer a generative model trained on Pareto-optimal solutions in the current environment to a new environment using only the auxiliary information exhibited through the movement trajectories of historical Pareto-optimal solutions, resulting in the generation of quality initial populations for the new environment. Meanwhile, any proven LMOEA can be integrated into the proposed framework without extensive modifications. Experimental results on a typical dynamic multiobjective test suite with problem settings from 30 to 1000 dimensions demonstrate that the optimization performance of the proposed framework outperforms existing state-of-the-art designs. Especially in large-scale scenarios, the proposed framework is considered superior in terms of solution quality and computational efficiency.},
  archive      = {J_TEVC},
  author       = {Chenyang Li and Gary G. Yen and Zhenan He},
  doi          = {10.1109/TEVC.2024.3412049},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1112-1126},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Adversarial AutoEncoder-based large-scale dynamic multiobjective evolutionary algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning in genetic programming: Guiding efficient data collection for symbolic regression. <em>TEVC</em>, <em>29</em>(4), 1100-1111. (<a href='https://doi.org/10.1109/TEVC.2024.3471341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines various methods of computing uncertainty and diversity for active learning in genetic programming. We found that the model population in genetic programming can be exploited to select informative training data points by using a model ensemble combined with an uncertainty metric. We explored several uncertainty metrics and found that differential entropy performed the best. We also compared two data diversity metrics and found that correlation as a diversity metric performs better than minimum Euclidean distance, although there are some drawbacks that prevent correlation from being used on all problems. Finally, we combined uncertainty and diversity using a Pareto optimization approach to allow both to be considered in a balanced way to guide the selection of informative and unique data points for training.},
  archive      = {J_TEVC},
  author       = {Nathan Haut and Wolfgang Banzhaf and Bill Punch},
  doi          = {10.1109/TEVC.2024.3471341},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1100-1111},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Active learning in genetic programming: Guiding efficient data collection for symbolic regression},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feedback learning-based memetic algorithm for energy-aware distributed flexible job-shop scheduling with transportation constraints. <em>TEVC</em>, <em>29</em>(4), 1085-1099. (<a href='https://doi.org/10.1109/TEVC.2024.3388527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing energy concerns and development of globalization, energy-aware scheduling and distributed scheduling have become significant topics in modern manufacturing. However, realistic manufacturing scenarios, such as collaborative scheduling of distributed shops and limited transportation resources, are rarely taken into account. To bridge the gap, this article addresses the energy-aware distributed flexible job-shop with transportation constraints (EDFJSP-T) and proposes a feedback learning-based memetic algorithm (FLMA) to minimize makespan and total energy consumption simultaneously. First, a mathematical model is formulated to represent the relationship between different subproblems. Additionally, an encoding and decoding method based on forward insertion is designed to reduce the search space and obtain high-quality schedules. Second, various problem-specific operators are designed to focus on different subproblems and objectives to enrich search patterns. Third, memetic search with feedback learning is proposed via introducing observer indexes for both population state and individual state to adaptively match appropriate operators for individuals. Besides, local intensification search with multiple operators is incorporated for low-density regions to further improve exploitation ability. The parameter setting is investigated and experimental tests are carried out using different types of instances. The comparisons demonstrate the effectiveness of the feedback learning mechanism and the superiority of the FLMA over existing algorithms for solving the EDFJSP-T.},
  archive      = {J_TEVC},
  author       = {Jingjing Wang and Honggui Han and Ling Wang},
  doi          = {10.1109/TEVC.2024.3388527},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1085-1099},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A feedback learning-based memetic algorithm for energy-aware distributed flexible job-shop scheduling with transportation constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective optimization problem with hardly dominated boundaries: Benchmark, analysis, and indicator-based algorithm. <em>TEVC</em>, <em>29</em>(4), 1070-1084. (<a href='https://doi.org/10.1109/TEVC.2024.3403414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardly dominated boundary (HDB) is commonly observed in multiobjective optimization problems (HDB-MOPs). However, there are only a few benchmark problems related to HDB-MOPs in the evolutionary computation community, which is insufficient to validate the performance of the multiobjective evolutionary algorithms (MOEAs). In this article, we first introduce a new set of HDB-MOPs characterized by various shapes of Pareto fronts and scalable HDB sizes. We then systematically analyze the capabilities of several representative existing MOEAs in handling HDB-MOPs and reveal their strengths and weaknesses in solving this type of problem. Finally, based on this insightful analysis, we propose an indicator-based MOEA with an adaptive reference point (denoted as IMOEA-ARP) to effectively address HDB-MOPs. The source codes of the proposed benchmark problems and the IMOEA-ARP algorithm are available from https://github.com/CIAM-Group/EvolutionaryAlgorithm_Codes/tree/main/IMOEA-ARP.},
  archive      = {J_TEVC},
  author       = {Zhenkun Wang and Kangnian Lin and Genghui Li and Weifeng Gao},
  doi          = {10.1109/TEVC.2024.3403414},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1070-1084},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective optimization problem with hardly dominated boundaries: Benchmark, analysis, and indicator-based algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multitree genetic programming for learning color and multiscale features in image classification. <em>TEVC</em>, <em>29</em>(4), 1055-1069. (<a href='https://doi.org/10.1109/TEVC.2024.3384021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-efficient image classification, which focuses on achieving accurate classification performance with limited labeled data, has garnered significant attention. Genetic programming (GP) has achieved impressive progress in image classification, particularly in scenarios involving small amounts of labeled data. GP research typically focuses on designing tree-based model representations to learn useful image features for classification. However, most GP methods are proposed for gray-scale images and ignore the color features. Furthermore, the existing GP methods typically learn features on a single scale/resolution, restricting potential accuracy enhancements. To address these issues, this article proposes a new multitree GP representation for image feature learning and classification. In each individual, three trees are included to extract discriminative features from the red, green, and blue channels of the image. With the new image resizing layer in the tree representation, the proposed approach can achieve multiscale feature extraction, i.e., flexibly learning fine-grained details and coarse-grained structures in the image, improving the classification performance. In addition, since a limitation of GP is premature convergence due to a decline in population diversity, this article develops a hybrid parent selection method consisting of tournament and lexicase selection to increase population diversity, find the best individual, and improve classification accuracy. The experiments on six image classification datasets indicate that the proposed approach outperforms state-of-the-art neural network-based and GP-based methods in almost all comparisons. Further analyses demonstrate the effectiveness of each component and the potentially high interpretability of the proposed approach.},
  archive      = {J_TEVC},
  author       = {Qinglan Fan and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3384021},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1055-1069},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multitree genetic programming for learning color and multiscale features in image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving high-dimensional expensive multiobjective optimization problems by adaptive decision variable grouping. <em>TEVC</em>, <em>29</em>(4), 1041-1054. (<a href='https://doi.org/10.1109/TEVC.2024.3383095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plenty of decision variable grouping-based algorithms have shown satisfactory performance in solving high-dimensional optimization problems. However, most of them are tailored for inexpensive optimization problems. Extending variable grouping method to expensive optimization problems poses many challenges. One of the greatest challenges is that most grouping approaches require additional function evaluations (FEs) to discover interactions among decision variables, which is intolerable for expensive optimization problems as it incurs prohibitive computational costs. To address this issue, an adaptive variable grouping method is proposed in this article, which can achieve relatively accurate grouping results without additional FE consumption. Specifically, variables are grouped based on the contrasts between well-converged solutions and poorly converged solutions. Furthermore, the grouping scheme is adjusted dynamically during the optimization process to improve the grouping accuracy. Besides, an adaptive environmental selection-based sampling strategy is suggested, which attempts to provide the currently required solutions for reevaluation according to the demands of different optimization stages. The proposed algorithm is compared with the other five state-of-the-art multiobjective optimization evolutionary algorithms on both benchmark and real-world problems. The experimental results demonstrate the promising performance and the superior computational efficiency of the proposed algorithm in tackling high-dimensional expensive multiobjective optimization problems.},
  archive      = {J_TEVC},
  author       = {Yingwei Li and Xiang Feng and Huiqun Yu},
  doi          = {10.1109/TEVC.2024.3383095},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1041-1054},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Solving high-dimensional expensive multiobjective optimization problems by adaptive decision variable grouping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature extraction with genetic programming for root cause identification in manufacturing with interpretable machine learning. <em>TEVC</em>, <em>29</em>(4), 1029-1040. (<a href='https://doi.org/10.1109/TEVC.2024.3388725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fault detection (FD) in manufacturing, various machine learning (ML) models have been widely applied to minimize human intervention and improve detection performance. Even though ML models, such as neural networks (NNs), have been shown to identify faults effectively, root cause identification (RCI) is becoming more difficult due to their black-box structures and the tradeoff between accuracy and interpretability. In order to improve performance while maintaining interpretability, we propose a new framework named Feature Extraction for finding Root causes for Manufacturing Applications with Tree-based algorithms (FERMAT), which enhances the performance of height-limited decision trees (DTs) (C4.5) through dimensionally aware genetic programming for feature extraction. Especially in FERMAT, only interpretable features are extracted to prevent DTs from delivering uninterpretable expressions to practitioners. In the present study, FERMAT’s applicability to RCI was verified with both manufacturing and nonmanufacturing datasets with different imbalance ratios. The experimental results showed that FERMAT outperformed the other single-tree-based models by extracting good features and delivered performance comparable to the black-box models.},
  archive      = {J_TEVC},
  author       = {Chan Gyu Lee and Sungbum Jun},
  doi          = {10.1109/TEVC.2024.3388725},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1029-1040},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Feature extraction with genetic programming for root cause identification in manufacturing with interpretable machine learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A divergence-based condition to ensure quantile improvement in black-box global optimization. <em>TEVC</em>, <em>29</em>(4), 1017-1028. (<a href='https://doi.org/10.1109/TEVC.2024.3452420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {black-box global optimization aims at minimizing an objective function whose analytical form is not known. To do so, many state-of-the-art methods rely on sampling-based strategies, where sampling distributions are built in an iterative fashion, so that their mass concentrate where the objective function is low. Despite empirical success, the theoretical study of these methods remains difficult. In this work, we introduce a new framework, based on divergence-decrease conditions, to study and design black-box global optimization algorithms. Our approach allows to establish and quantify the improvement of sampling distributions at each iteration, in terms of expected value or quantile of the objective. We show that the information-geometric optimization approach fits within our framework, yielding a new approach for its analysis. We also establish sampling distribution improvement results for two novel algorithms, one related with the cross-entropy approach with mixture models, and another one using heavy-tailed sampling distributions.},
  archive      = {J_TEVC},
  author       = {Thomas Guilmeau and Emilie Chouzenoux and Víctor Elvira},
  doi          = {10.1109/TEVC.2024.3452420},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1017-1028},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A divergence-based condition to ensure quantile improvement in black-box global optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superpixel segmentation-based evolutionary multitasking algorithm for feature selection of hyperspectral images. <em>TEVC</em>, <em>29</em>(4), 1002-1016. (<a href='https://doi.org/10.1109/TEVC.2024.3392749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a very important technique for hyperspectral image (HSI) classification, as successfully selecting informative features can significantly increase the learning performance while reducing the computational cost. However, most of the existing FS methods tend to treat the HSI as a whole for FS, which does not fully consider the unique characteristics of HSIs and disregards the fact that different feature classes possess varying preferences for features. Thus, this article proposes a superpixel segmentation-based evolutionary multitasking (EMT) algorithm for FS of HSIs, called SS-EMT. First, the superpixel segmentation method is used to partition the original HSI into several superpixel blocks, which can preserve well the information of different classes of the original image. Second, in order to explore each superpixel block efficiently, an EMT algorithm using particle swarm optimization is designed, which treats each superpixel block as a subtask and then optimizes these subtasks collaboratively by transferring useful knowledge among related subtasks. In addition, a new individual evaluation mechanism is devised to obtain multiple high-quality feature subsets with different numbers of features simultaneously in a single run, thus reducing the computational cost. Finally, extensive experimental results on four common HSI datasets under three classifiers validate that our proposed method outperforms several state-of-the-art FS methods.},
  archive      = {J_TEVC},
  author       = {Lingjie Li and Yuze Zhang and Qiuzhen Lin and Zhong Ming and Carlos A. Coello Coello and Victor C. M. Leung},
  doi          = {10.1109/TEVC.2024.3392749},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {1002-1016},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Superpixel segmentation-based evolutionary multitasking algorithm for feature selection of hyperspectral images},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Indexes-based and partial restart-based constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 990-1001. (<a href='https://doi.org/10.1109/TEVC.2024.3400610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems often have complex feasible regions and constrained Pareto fronts. These factors bring great challenges to current constrained multiobjective optimization evolutionary algorithms (CMOEAs). To solve this problem and further balance the objective optimization and constraint satisfaction, we propose an indexes-based and partial restart-based constrained multiobjective optimization (IRCMO) algorithm. In IRCMO, a two-stage (i.e., development and enhancement) and tri-population framework is designed. IRCMO adopts the aggregative indexes-based evaluation and adaptive collaborative partial restart strategy to assist the evolution of the first and second populations. The third population is obtained by directed sampling, which is mostly located at the boundary of the feasible region and enhances the exploration ability of extreme solutions. At the end of each generation, a progressive dual-archive strategy is designed to screen the solutions distributed uniformly from three populations. Experimental results demonstrate that IRCMO is superior to the other six state-of-the-art CMOEAs on several constraint benchmark suites and real-world problems.},
  archive      = {J_TEVC},
  author       = {Zhen Yang and Tangxu Yao and Yunliang Jiang and Jun Zhang and Xiongtao Zhang},
  doi          = {10.1109/TEVC.2024.3400610},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {990-1001},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Indexes-based and partial restart-based constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming combinatorial optimization problems in fourier space: Consequences and uses. <em>TEVC</em>, <em>29</em>(4), 977-989. (<a href='https://doi.org/10.1109/TEVC.2024.3457268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze three permutation-based combinatorial optimization problems in Fourier space, namely, the quadratic assignment problem, the linear ordering problem (LOP), and the symmetric and nonsymmetric traveling salesperson problem (STSP). In previous studies, one can find a number of theorems with necessary conditions that the Fourier coefficients of the aforementioned problems must satisfy. In this manuscript, we prove the sufficiency of these conditions, which implies that they constitute the exact characterization of the problems in Fourier space. In addition, the Fourier coefficients of the LOP and the symmetric and non-STSP are completely characterized by showing certain proportionality patterns that they must follow. Taking the characterization in Fourier space of the problems as a basis, we study classes of equivalent instances of the LOP and the symmetric and non-STSP, considering that two instances are equivalent if they have the same objective function. Furthermore, we give canonical representations for each problem in such a way that the input matrices have the minimum number of nonzero parameters.},
  archive      = {J_TEVC},
  author       = {Anne Elorza and Xabier Benavides and Josu Ceberio and Leticia Hernando and Jose A. Lozano},
  doi          = {10.1109/TEVC.2024.3457268},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {977-989},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Transforming combinatorial optimization problems in fourier space: Consequences and uses},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual-source and virtual-swarm-based particle swarm optimizer for large-scale multisource location via robot swarm. <em>TEVC</em>, <em>29</em>(4), 963-976. (<a href='https://doi.org/10.1109/TEVC.2024.3391622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisource location is a significant application in the field of robot swarm and is required to find all sources whose number and distribution are unknown in advance. With few parameters and fast search, particle swarm optimizer (PSO) variants that have certain grouping capability have been applied to address multisource location problems (MSLPs) by dividing a swarm such that every source has robots to locate. However, they are difficult to predetermine the exact number of groups, require a big number of robots, and are easily trapped in the no-signal areas when the proportion of no-signal areas is high. This work proposes a virtual-source and virtual-swarm-based PSO (VVPSO) to divide a search area into multiple cells equally, each of which has a virtual source in its center. Then, instead of robots grouping, only one group of robots is employed to traverse all virtual sources, and search their corresponding cells to locate real sources by a new PSO called real-virtual mapping PSO (RMPSO). RMPSO asymmetrically maps a robot into a particle swarm with multiple virtual particles to perform PSO, which greatly reduces the requirements for the number of robots. Experimental results show that VVPSO has great search scalability and can solve large-scale MSLPs than two state-of-the-art grouping methods and three representative multimodal PSO variants, even with only one robot. Hence, this work greatly advances the field of multisource location by using mobile robot swarm.},
  archive      = {J_TEVC},
  author       = {Junqi Zhang and Yuxuan Lin and MengChu Zhou},
  doi          = {10.1109/TEVC.2024.3391622},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {963-976},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Virtual-source and virtual-swarm-based particle swarm optimizer for large-scale multisource location via robot swarm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-based directional improvement prediction for dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(4), 948-962. (<a href='https://doi.org/10.1109/TEVC.2024.3393151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, dynamic multiobjective evolutionary algorithms (DMOEAs) using the prediction strategy have shown promising performance for solving dynamic multiobjective optimization problems (DMOPs), as they can predict environmental changing trends in advance. However, most of them follow a regular change pattern and thus their performance is compromised when solving DMOPs with irregular change patterns (e.g., nonlinear correlations). To alleviate this challenge, this article proposes a DMOEA with a learnable prediction for tackling DMOPs. Specifically, a neural network is designed to effectively capture diverse change patterns of the environment. Based on the change patterns learned, a directional improvement prediction (DIP) is developed to guide the evolutionary search toward promising directions in the decision space. In this way, a superior initial population with good convergence and diversity is predicted by DIP, which can be more effective for solving various DMOPs. Comprehensive empirical studies show that the proposed DIP is effective and the proposed algorithm has some advantages over five competitive DMOEAs when solving three commonly used benchmarks and one real-world problem.},
  archive      = {J_TEVC},
  author       = {Yulong Ye and Songbai Liu and Junwei Zhou and Qiuzhen Lin and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3393151},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {948-962},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning-based directional improvement prediction for dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis for mixed-variable problems. <em>TEVC</em>, <em>29</em>(4), 936-947. (<a href='https://doi.org/10.1109/TEVC.2024.3399560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploratory landscape analysis (ELA) and fitness landscape analysis in general have given valuable insight into problem hardness understanding as well as facilitating algorithm design and endeavors, such as automated algorithm selection (AAS) and configuration. These techniques have largely been limited to search spaces of a single domain. In this work, we provide the means to compute exploratory landscape features for mixed-variable problems where the decision space is a mixture of continuous, binary, integer, and categorical variables. This is achieved by introducing a preprocessing scheme which needs to be incorporated into the process of ELA feature generation. To highlight the merit of our approach for practical applications, we design and conduct an AAS study based on a hyperparameter optimization benchmark suite and our preprocessing scheme. Our trained algorithm selector is able to close the gap between the single best and the virtual best solver by 57.5% over all benchmark problems.},
  archive      = {J_TEVC},
  author       = {Raphael Patrick Prager and Heike Trautmann},
  doi          = {10.1109/TEVC.2024.3399560},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {936-947},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Exploratory landscape analysis for mixed-variable problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computationally expensive high-dimensional multiobjective optimization via surrogate-assisted reformulation and decomposition. <em>TEVC</em>, <em>29</em>(4), 921-935. (<a href='https://doi.org/10.1109/TEVC.2024.3380327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, various surrogate-assisted evolutionary algorithms (SAEAs) have been proposed to solve computationally expensive multiobjective optimization problems (EMOPs). Nevertheless, designing an SAEA to handle high-dimensional EMOPs and balance convergence, diversity, and computational complexity remains challenging. Here, we propose a two-phase SAEA (TP-SAEA), which follows the idea of convergence first and diversity second, for solving high-dimensional EMOPs. In Phase I, a surrogate-assisted problem reformulation method is proposed to fast-track the Pareto optimal set in association with some reference solutions. Specifically, the high-dimensional EMOP is reformulated into an expensive single-objective one with low-dimensional decision space. Then, the surrogate-assisted optimization is utilized to obtain well-converged solutions. In Phase II, the high-dimensional EMOP is decomposed into two subproblems to explore subregions of the decision space that can effectively promote the diversity of the solutions. The two subproblems are optimized independently via surrogate-assisted optimization, aiming to push the population toward different regions of the Pareto optimal front. Experiments are conducted on EMOPs with 100 to 500 decision variables compared with four state-of-the-art SAEAs. The proposed TP-SAEA obtains well-converged and diverse solutions with only 509 real function evaluations. Moreover, its superiority is examined in six real-world instances with up to 12 000 decision variables.},
  archive      = {J_TEVC},
  author       = {Linqiang Pan and Jianqing Lin and Handing Wang and Cheng He and Kay Chen Tan and Yaochu Jin},
  doi          = {10.1109/TEVC.2024.3380327},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {921-935},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Computationally expensive high-dimensional multiobjective optimization via surrogate-assisted reformulation and decomposition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiagent swarm optimization with adaptive internal and external learning for complex consensus-based distributed optimization. <em>TEVC</em>, <em>29</em>(4), 906-920. (<a href='https://doi.org/10.1109/TEVC.2024.3380436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization has attracted lots of attention in recent years. Thanks to the intrinsic parallelism and great search capacity, evolutionary computation (EC) has the potential for black-box and nonconvex distributed optimization. However, due to the decentralization of local objective functions, it is challenging to optimize the global objective function with efficient communication and guaranteed system consensus. To tackle this challenge, we propose a multiagent swarm optimization method with adaptive internal and external learning (MASOIE). In MASOIE, each agent evolves a swarm of particles by internal learning and external learning. Internal learning enables agents to optimize their local objectives, while external learning enables agents to cooperate to achieve a consensus toward the global objective. To improve the consensus ability, we design a special velocity setting of external learning for particle evolution. We provide the theoretical analysis of the system consensus of deterministic MASOIE. To improve communication efficiency, we design an adaptive communication mechanism to adjust the communication interval, enabling agents to explore at the early stage and reach system consensus at the later stage. Empirical studies show that the proposed algorithm achieves stable consensus performance, competitive solution quality and lower communication cost on benchmark functions compared with existing black-box distributed algorithms.},
  archive      = {J_TEVC},
  author       = {Tai-You Chen and Wei-Neng Chen and Feng-Feng Wei and Xiao-Min Hu and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3380436},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {906-920},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiagent swarm optimization with adaptive internal and external learning for complex consensus-based distributed optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation guarantees for the nondominated sorting genetic algorithm II (NSGA-II). <em>TEVC</em>, <em>29</em>(4), 891-905. (<a href='https://doi.org/10.1109/TEVC.2024.3402996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent theoretical works have shown that the NSGA-II efficiently computes the full Pareto front when the population size is large enough. In this work, we study how well it approximates the Pareto front when the population size is smaller. For the OneMinMax benchmark, we point out situations in which the parents and offspring cover well the Pareto front, but the next population has large gaps on the Pareto front. Our mathematical proofs suggest as reason for this undesirable behavior that the NSGA-II in the selection stage computes the crowding distance once and then removes individuals with smallest crowding distance without considering that a removal increases the crowding distance of some individuals. We then analyse two variants not prone to this problem. For the NSGA-II that updates the crowding distance after each removal [Kukkonen and Deb (2006)] and the steady-state NSGA-II [Nebro and Durillo (2009)], we prove that the gaps in the Pareto front are never more than a small constant factor larger than the theoretical minimum. This is the first mathematical work on the approximation ability of the NSGA-II and the first runtime analysis for the steady-state NSGA-II. Experiments also show the superior approximation ability of the two NSGA-II variants.},
  archive      = {J_TEVC},
  author       = {Weijie Zheng and Benjamin Doerr},
  doi          = {10.1109/TEVC.2024.3402996},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {891-905},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Approximation guarantees for the nondominated sorting genetic algorithm II (NSGA-II)},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptation of multirecombinant evolution strategies on the highly multimodal rastrigin function. <em>TEVC</em>, <em>29</em>(4), 880-890. (<a href='https://doi.org/10.1109/TEVC.2024.3400857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-adaptive, multirecombinative $(\mu /\mu _{I},\lambda)$ -Evolution strategy (ES) is investigated on the highly multimodal Rastrigin test function by theoretical and experimental means. The analysis is based on the established dynamical systems approach. To this end, the self-adaptation response (SAR) function is derived in the limit of large populations, which are necessary to achieve high success rates. Furthermore, steady-state conditions on Rastrigin are discussed and compared to the sphere function. Then, a relation for the learning parameter $\tau $ is derived to tune the sampling process of the self-adaptive ES, improving its efficiency on Rastrigin. The obtained result is compared to default $\tau $ -values. Furthermore, expected runtime experiments are conducted varying $\tau $ and population parameters of the ES. Theoretical and experimental results regarding $\tau $ are compared in terms of efficiency and robustness showing good agreement.},
  archive      = {J_TEVC},
  author       = {Amir Omeradzic and Hans-Georg Beyer},
  doi          = {10.1109/TEVC.2024.3400857},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {880-890},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Self-adaptation of multirecombinant evolution strategies on the highly multimodal rastrigin function},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to Expand/Contract pareto sets in dynamic multiobjective optimization with a changing number of objectives. <em>TEVC</em>, <em>29</em>(4), 865-879. (<a href='https://doi.org/10.1109/TEVC.2024.3375751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) with a changing number of objectives (NObjs) may have Pareto-optimal set (PS) manifold expanding or contracting over time. Knowledge transfer has been used for solving DMOPs, since it can transfer useful information from solving one problem instance to solve another related problem instance. However, we show that the state-of-the-art transfer approach based on heuristic lacks diversity on problem with extremely strong bias and loses convergence on problems with multimodality and variable correlation, after the NObjs increases and decreases, respectively. Therefore, we propose a novel transfer strategy based on learning, called learning to expand and contract PS (denoted as LEC) for enhancing diversity and convergence after NObj increases and decreases, respectively. It first learns potentially good directions for expansion and contraction separately via principal component analysis. Then, the most promising expansion and contraction directions are selected from their candidates according to whether they help diversity and convergence, respectively. Finally, PS is learned to be expanded and contracted based on these most promising directions. Comprehensive studies using 13 DMOP benchmarks with a changing NObjs demonstrate that our proposed LEC is effective on improving solution quality, not only right after changes but also after optimization of different generations, compared to state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Gan Ruan and Leandro L. Minku and Stefan Menzel and Bernhard Sendhoff and Xin Yao},
  doi          = {10.1109/TEVC.2024.3375751},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {865-879},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Learning to Expand/Contract pareto sets in dynamic multiobjective optimization with a changing number of objectives},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic programming with flexible region detection for fine-grained image classification. <em>TEVC</em>, <em>29</em>(4), 853-864. (<a href='https://doi.org/10.1109/TEVC.2024.3379257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image classification (FGIC) is an important computer vision task with many real-world applications. However, FGIC is challenging due to intraclass variations and interclass similarities, especially when there is limited training data. To address these challenges, a new genetic programming approach with flexible region detection (GP-RD), is proposed for different FGIC tasks, i.e., flower and fish classification tasks. The proposed GP-RD approach can automatically highlight the object, detect regions of interest, extract effective features, and combine global, local, and/or color features for classification. The performance of GP-RD is evaluated on flower and fish classification tasks within the FGIC domain, utilizing datasets with varying classes. In comparison with seven benchmark methods, GP-RD achieves significantly better performance in most comparisons. Further analysis demonstrates the interpretability, effectiveness, and efficiency of the proposed approach.},
  archive      = {J_TEVC},
  author       = {Qinyu Wang and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3379257},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {8},
  number       = {4},
  pages        = {853-864},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming with flexible region detection for fine-grained image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interval multiobjective evolutionary generation algorithm for product design change plans in uncertain environments. <em>TEVC</em>, <em>29</em>(3), 836-850. (<a href='https://doi.org/10.1109/TEVC.2024.3378774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design change is an important issue in complex product development projects. In a complex product with numerous parts (also known as components), the change of one key part may spread to other parts associated with it, generating a chain reaction throughout the entire project. Therefore, it is necessary to select a suitable change plan involving only fewer crucial parts in order to enhance the product’s performance, minimize change cost, and reduce change duration/time. Focusing on the case where the correlation strength between parts cannot be accurately obtained, in this article we study an interval multiobjective evolutionary algorithm for finding excellent design change plans. First, on the basis of the established multilayer product network with interval correlation weights, an interval multiobjective optimization model of the product design change planning problem is established, where three new objective functions regarding product performance, carbon trading cost and supply risk are defined. Then, a constraint multiobjective evolutionary algorithm based on interval Pareto dominance is proposed to search for optimal change plans. Several novel operators, including the problem characteristic-guided population update strategy, the probability-based interval Pareto dominance, and the interval constraint handling strategy, are developed to enhance the algorithm’s performance. Finally, the proposed algorithm is compared with eight existing algorithms on the two design change cases, experimental results revealed its effectiveness.},
  archive      = {J_TEVC},
  author       = {Rui-Zhao Zheng and Yong Zhang and Xiao-Yan Sun and Dun-Wei Gong and Xiao-Zhi Gao},
  doi          = {10.1109/TEVC.2024.3378774},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {836-850},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An interval multiobjective evolutionary generation algorithm for product design change plans in uncertain environments},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional order differential evolution. <em>TEVC</em>, <em>29</em>(3), 822-835. (<a href='https://doi.org/10.1109/TEVC.2024.3382047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a widely recognized method to solve complex optimization problems as shown by many researchers. Yet, nonadaptive versions of DE suffer from insufficient exploration ability and uses no historical information for its performance enhancement. This work proposes fractional order DE (FODE) to enhance DE performance from two aspects. First, a bi-strategy co-deployment framework is proposed. The population-based and parameter-based strategies are combined to leverage their respective advantages. Second, the fractional order (FO) calculus is first applied to the differential vector to enhance DE’s exploration ability by using the historical information of populations, and ensures the diversity of population in an evolutionary process. We use the 2017 IEEE congress on evolutionary computation (CEC) test functions, and CEC2011 real-world problems to evaluate FODE’s performance. Its sensitivity to parameter changes is discussed and an ablation study of multistrategies is systematically performed. Furthermore, the variations of exploration and exploitation in FODE are visualized and analyzed. Experimental results show that FODE is superior to other state-of-the-art DE variants, the winners of CEC competitions, other FO calculus-based algorithms, and some powerful variants of classic algorithms.},
  archive      = {J_TEVC},
  author       = {Kaiyu Wang and Shangce Gao and MengChu Zhou and Zhi-Hui Zhan and Jiujun Cheng},
  doi          = {10.1109/TEVC.2024.3382047},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {822-835},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Fractional order differential evolution},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive multitasking for computational resource allocation in evolutionary-constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 809-821. (<a href='https://doi.org/10.1109/TEVC.2024.3376729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization problems (CMOPs) have multiple objective functions that need to be optimized and constraints need to be satisfied, making them difficult to solve. Based on the multitasking optimization, the optimization of the original CMOP can be transformed into multiple related subtasks. Existing multitasking-based constrained multiobjective optimization evolutionary algorithms assist the evolution of the original problem by adopting auxiliary tasks. However, this approach may waste computational resources on tasks that are unsuitable for evolutionary states and dynamics. In this article, a new competitive multitasking-based framework is proposed for CMOPs. We maintain an archive for the constrained Pareto front (CPF) and multiple subtasks as auxiliaries. In each iteration, one of the subtasks is selected as the main task, and offspring are generated from its evolution. The offspring are viewed as knowledge and fed back to auxiliary tasks. The reward is mapped to a selection probability to control the main task selection in each iteration. Computational resources are saved by allocating only to the main task that is better suited for different evolutionary stages of different problems. The effectiveness of our approach is validated through experiments on four CMOP benchmark suites compared to 11 state-of-the-art methods.},
  archive      = {J_TEVC},
  author       = {Xiaoliang Chu and Fei Ming and Wenyin Gong},
  doi          = {10.1109/TEVC.2024.3376729},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {809-821},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Competitive multitasking for computational resource allocation in evolutionary-constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved evolutionary multitasking optimization algorithm with similarity evaluation of search behavior. <em>TEVC</em>, <em>29</em>(3), 794-808. (<a href='https://doi.org/10.1109/TEVC.2024.3373131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task similarity is a major requisite to trigger knowledge sharing in evolutionary multitasking optimization (EMTO). Unfortunately, most of the existing EMTO algorithms only focus on the similarity between population distributions of tasks, but ignore the search behavior of populations, which may degrade the performance of cross-task knowledge sharing. Motivated by this, an improved EMTO algorithm with similarity evaluation of search behavior (SESB-IEMTO), employing the particle swarm optimization (PSO) algorithm as a task solver for each task, is proposed. It comprises three key elements: 1) a dynamic similarity-based evaluation strategy; 2) a cross-task knowledge adaptation method; and 3) a search direction-sharing mechanism. Primarily, the source tasks with similar search behavior are discriminated with the dynamic similarity-based evaluation strategy, where individuals can be fully exploited for cross-task evolution. Then, the knowledge derived from these source tasks is regulated by the cross-task knowledge adaption method for alleviating the risk of negative transfer caused by the heterogeneity between tasks. Moreover, to further promote knowledge sharing between tasks, the search direction-sharing mechanism is developed to navigate tasks efficiently searching for promising regions. Finally, the convergence of SESB-IEMTO is analyzed, and the effectiveness and superiority are also verified with the experiments on several benchmark tests and a real-world application study.},
  archive      = {J_TEVC},
  author       = {Xiaolong Wu and Wei Wang and Tengfei Zhang and Honggui Han and Junfei Qiao},
  doi          = {10.1109/TEVC.2024.3373131},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {794-808},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Improved evolutionary multitasking optimization algorithm with similarity evaluation of search behavior},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted evolutionary framework for expensive multitask optimization problems. <em>TEVC</em>, <em>29</em>(3), 779-793. (<a href='https://doi.org/10.1109/TEVC.2024.3370937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a surrogate-assisted evolutionary framework (called SELF) to solve expensive multitask optimization problems (ExMTOPs). SELF consists of two main phases: 1) global knowledge transfer phase and 2) local knowledge transfer phase. In the former, a multitask Gaussian process model (MTGP) is established by fusing previously evaluated solutions of multiple optimization tasks. MTGP can capture task-relevant information and the knowledge of landscapes. Then, differential evolution assisted with MTGP is proposed to preselect high-quality candidates. During the preselection, the knowledge of landscapes is transferred among multiple optimization tasks for locating promising regions quickly. In the latter, for each optimization task, Bayesian optimization is adopted to improve the quality of the best individual in the population. Moreover, the improved best individuals in the populations of multiple optimization tasks are adaptively transferred based on a transfer probability, which is computed through the task-relevant information provided by MTGP. By combining these two phases, SELF not only achieves the tradeoff between exploration and exploitation, but also utilizes the global and local knowledge transfer to improve the efficiency for solving ExMTOPs. We test SELF on seven benchmark test problems in the IEEE CEC2017 evolutionary multitask optimization competition. The results demonstrate that the performance of SELF is better than that of other seven advanced methods. In addition, we also apply SELF to deal with two real-world ExMTOPs. The designs provided by SELF exhibit the best performance among all the compared methods, verifying the potential of SELF in practical engineering applications.},
  archive      = {J_TEVC},
  author       = {Shenglian Tan and Yong Wang and Guangyong Sun and Tong Pang and Ke Tang},
  doi          = {10.1109/TEVC.2024.3370937},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {779-793},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A surrogate-assisted evolutionary framework for expensive multitask optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOEA/D with Spatial–Temporal topological tensor prediction for evolutionary dynamic multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 764-778. (<a href='https://doi.org/10.1109/TEVC.2024.3367747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving dynamic multiobjective optimization problems, most evolutionary algorithms (EAs) attempt to predict the initial population in a new environment by mining the relationships between solutions during historical environment changes. However, the complex relationships between solutions and the limited amount of available data often make it difficult to extract useful information efficiently, which may deteriorate the prediction accuracy. To address this problem, this article proposes a spatial–temporal topological tensor-based prediction method to generate the initial population in a new environment under the decomposition framework of MOEA/D. The method relies on the idea that the population distribution in each environment has topological similarity along the time dimension in the objective space, which makes it efficient to represent the population distribution in terms of a tensor and predict new solutions along each decomposition axis in a new environment by an improved tensor-based multishort time series prediction method. Experimental results on various benchmark problems and a real-world problem show that the proposed method is competitive or even superior to state-of-the-art dynamic multiobjective EAs based on prediction strategies.},
  archive      = {J_TEVC},
  author       = {Xianpeng Wang and Yumeng Zhao and Lixin Tang and Xin Yao},
  doi          = {10.1109/TEVC.2024.3367747},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {764-778},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MOEA/D with Spatial–Temporal topological tensor prediction for evolutionary dynamic multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary trainer-based deep Q-network for dynamic flexible job-shop scheduling. <em>TEVC</em>, <em>29</em>(3), 749-763. (<a href='https://doi.org/10.1109/TEVC.2024.3367181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic flexible job-shop scheduling (DFJSS) aims to achieve the optimal efficiency for production planning in the face of dynamic events. In practice, deep $Q$ -network (DQN) algorithms have been intensively studied for solving various DFJSS problems. However, these algorithms often cause moving targets for the given job-shop state. This will inevitably lead to unstable training and severe deterioration of the performance. In this article, we propose a training algorithm based on genetic algorithm to efficiently and effectively address this critical issue. Specifically, a state feature extraction method is first developed, which can effectively represent different job-shop scenarios. Furthermore, a genetic encoding strategy is designed, which can reduce the encoding length to enhance search ability. In addition, an evaluation strategy is proposed to calculate a fixed target for each job-shop state, which can avoid the parameter update of target networks. With the designs, the DQNs could be stably trained, thus their performance is greatly improved. Extensive experiments demonstrate that the proposed algorithm outperforms the state-of-the-art peer competitors in terms of both effectiveness and generalizability to multiple scheduling scenarios with different scales. In addition, the ablation study also reveals that the proposed algorithm can outperform the DQN algorithms with different updating frequencies of target networks.},
  archive      = {J_TEVC},
  author       = {Yun Liu and Fangfang Zhang and Yanan Sun and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3367181},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {749-763},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary trainer-based deep Q-network for dynamic flexible job-shop scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cooperative ant colony system for multiobjective multirobot task allocation with precedence constraints. <em>TEVC</em>, <em>29</em>(3), 734-748. (<a href='https://doi.org/10.1109/TEVC.2024.3364493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world scenarios (e.g., product manufacturing), multiple heterogeneous robots cooperate to complete complex tasks with precedence constraints. In these heterogeneous multirobot systems, the multirobot task allocation problem is important and has attracted increasing attention. The problem usually involves multiple optimization objectives for decision making. However, existing approaches meet challenges on multiobjective problems with large-scale tasks and precedence constraints in terms of solution diversity and convergence. Therefore, this article formulates a tri-objective model and proposes a cooperative ant colony system (CACS) to optimize three objectives, i.e., minimizing the makespan, average robot traveling time, and average task waiting time. In CACS, three ant colonies are created to simultaneously optimize the three objectives. To coordinate with the precedence constraints of the problem, solutions are encoded as a task-alliance sequence. A new solution construction method is developed to generate feasible solutions using dynamic heuristic information and two pheromone matrices. Particularly, one matrix deposits pheromone between tasks for task selection and the other between tasks and robots for alliance building. To further improve solution diversity and convergence, a fusion-based local search is adopted to generate high-quality solutions by combining information from multiple colonies. Thirty instances are constructed with different numbers of tasks and robots under complex precedence constrains. Experimental results show that CACS outperforms state-of-the-art methods in terms of the inverted generational distance and hypervolume metrics.},
  archive      = {J_TEVC},
  author       = {Tong Qian and Xiao-Fang Liu and Yongchun Fang},
  doi          = {10.1109/TEVC.2024.3364493},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {734-748},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A cooperative ant colony system for multiobjective multirobot task allocation with precedence constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the efficiency of the distance-based hypervolume estimation using ND-tree. <em>TEVC</em>, <em>29</em>(3), 726-733. (<a href='https://doi.org/10.1109/TEVC.2024.3391857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume is most likely the most often used quality indicator in evolutionary multiobjective optimization (EMO) due to its monotonicity with respect to the dominance relation. Since, however, exact calculation of hypervolume is computationally demanding, many researchers have proposed methods for hypervolume estimation. Many of such methods use numerical integration of the distance from the reference point to the upper boundary of the dominated region along uniformly sampled directions. To find this distance for a given direction, the maximum value of the inverse weighted Chebycheff function needs to be found. For small solution sets this could be done by the exhaustive search which, however, may be very inefficient for large solution sets, e.g., for unbounded external archives of the EMO algorithms. In this article, we adapt the ND-Tree-based algorithm for finding the minimum of the standard weighted Chebycheff function to finding the maximum of the inverse function. Through a computational experiment we show that this ND-Tree-based algorithm may be used either for reduction of the running time of hypervolume estimation by up to two orders of magnitude or for improving the estimation accuracy with the same time budget up to an order of magnitude for data sets with up to 12 objectives and 50 000 points.},
  archive      = {J_TEVC},
  author       = {Andrzej Jaszkiewicz and Piotr Zielniewicz},
  doi          = {10.1109/TEVC.2024.3391857},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {726-733},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Improving the efficiency of the distance-based hypervolume estimation using ND-tree},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A classifier-ensemble-based surrogate-assisted evolutionary algorithm for distributed data-driven optimization. <em>TEVC</em>, <em>29</em>(3), 711-725. (<a href='https://doi.org/10.1109/TEVC.2024.3361000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) have achieved effective performance in solving complex data-driven optimization problems. In the Internet of Things environment, the data of many problems are collected and processed in distributed network nodes and cannot be transmitted. As each local node can only access and build surrogate models based on partial data, local models are usually not accurate and even conflicting. To address these challenges, this article proposes a classifier-ensemble-based surrogate-assisted evolutionary algorithm (CESAEA) with the following features. First, the local nodes in CESAEA train classifiers as surrogate models based on their own data to classify candidates into several levels according to their fitness quality. The classifiers are less sensitive to the partial and biased data than regression models in local nodes. Second, the central node in CESAEA ensembles the local surrogates to form a global classifier with a relaxation condition to guide the evolutionary optimizer to generate promising candidates. The relaxation condition helps to overcome the problem of local model inconsistency. Overall, CESAEA is composed of local classifier construction, global classifier ensemble, classifier-assisted evolutionary optimization and local regression-assisted selection. As only classifiers are allowed to transmit from local nodes to the central node, the mapping relationship between decision vector and objective is hidden and thus data privacy is protected. The experimental results on benchmark functions as well as distributed feature selection problems verify the effectiveness of CESAEA compared to several state-of-the-art approaches.},
  archive      = {J_TEVC},
  author       = {Xiao-Qi Guo and Feng-Feng Wei and Jun Zhang and Wei-Neng Chen},
  doi          = {10.1109/TEVC.2024.3361000},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {711-725},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A classifier-ensemble-based surrogate-assisted evolutionary algorithm for distributed data-driven optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear subspace surrogate modeling for large-scale expensive Single/Multiobjective optimization. <em>TEVC</em>, <em>29</em>(3), 697-710. (<a href='https://doi.org/10.1109/TEVC.2023.3319640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that the surrogate-assisted evolutionary algorithms have achieved great success in addressing expensive optimization problems, they still suffer from stiff challenges when the number of dimensions of problems becomes large. The primary reason lies in that it is very hard to build an acceptable surrogate model in the high-dimensional search space with small amounts of evaluated historical data in evolution. To tackle this issue, we suggest an effective surrogate modeling method for large-scale expensive optimization in this article, where the models are built on a number of linear subspaces instead of the original search space. Specifically, a linear subspace is constructed by a pair of points/solutions which are generated based on the set of elite solutions. For each linear subspace, several historical solutions are first associated according to their distance to the linear subspace, and then a surrogate model is trained by the associated solutions and used to evaluate the offspring. To ensure the exploration and exploitation capacity of the proposed method, these linear subspaces and the surrogate models are updated after a few iterations. Experimental results on CEC’2010 and CEC’2013 single-objective optimization problems with up to 1500 decision variables show that the proposed algorithm is superior over six comparison algorithms. Moreover, we also extend the proposed algorithm to multiobjective optimization problems and verified its competitiveness on problems with up to 1500 decision variables.},
  archive      = {J_TEVC},
  author       = {Langchun Si and Xingyi Zhang and Ye Tian and Shangshang Yang and Limiao Zhang and Yaochu Jin},
  doi          = {10.1109/TEVC.2023.3319640},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {697-710},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Linear subspace surrogate modeling for large-scale expensive Single/Multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on evolutionary computation-based drug discovery. <em>TEVC</em>, <em>29</em>(3), 676-696. (<a href='https://doi.org/10.1109/TEVC.2024.3382145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug discovery is an expensive and risky process. To combat the challenges in drug discovery, an increasing number of researchers and pharmaceutical companies recognize the benefits of utilizing computational techniques. Evolutionary computation (EC) offers promise as most drug discovery problems are essentially complex optimization problems beyond conventional optimization algorithms. EC methods have been widely applied to solve these complex optimization problems especially in lead compound generation and molecular virtual evaluation, substantially speeding up the process of drug discovery and development. This article presents a comprehensive survey of EC-based drug discovery methods. Particularly, a new taxonomy of the methods is provided and the advantages and limitations of the methods are reviewed. In addition, the potential future directions of EC-based drug discovery are discussed and the publicly available resources, including databases and computational tools are compiled for the convenience of researchers seeking to pursue this field.},
  archive      = {J_TEVC},
  author       = {Qiyuan Yu and Qiuzhen Lin and Junkai Ji and Wei Zhou and Shan He and Zexuan Zhu and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3382145},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {676-696},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A survey on evolutionary computation-based drug discovery},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective mixed-integer quadratic models: A study on mathematical programming and evolutionary computation. <em>TEVC</em>, <em>29</em>(3), 661-675. (<a href='https://doi.org/10.1109/TEVC.2024.3374519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the current literature on multiobjective optimization, there is a scarcity of comparisons between equation-based white-box solvers to evolutionary black-box solvers. It is commonly held that when dealing with linear and quadratic models, equation-based deterministic solvers are generally the preferred choice. The present study aims at challenging this hypothesis, and we show that particularly in box-constrained mixed-integer (MI) problems it is worth employing evolutionary methods when the goal is to achieve a good approximation of a Pareto frontier. To do so, this article compares a mathematical programming approach with an evolutionary method for set-oriented Pareto front approximation of bi-objective quadratic MI optimization problems. The focus is on convex quadratic under-constrained models wherein the decision variables are either tightly or loosely bounded by box-constraints. Through an empirical assessment of families of quadratic models across varying Hessian forms, variable ranges, and condition numbers, the study compares the performance of the CPLEX-based diversity maximization approach to a state-of-the-art evolutionary multiobjective optimization meta-heuristic with MI mutation and crossover operators. We identify and explain strengths and weaknesses of both approaches when dealing with loosely bounded box-constraints, and prove a theorem regarding the potential undecidability of such multiobjective problems featuring unbounded integer decision variables. The empirical results systematically confirm that black-box and white-box solvers can be competitive, especially in the case of loose box-constraints.},
  archive      = {J_TEVC},
  author       = {Ofer M. Shir and Michael Emmerich},
  doi          = {10.1109/TEVC.2024.3374519},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {661-675},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective mixed-integer quadratic models: A study on mathematical programming and evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protein structure prediction using a new optimization-based evolutionary and explainable artificial intelligence approach. <em>TEVC</em>, <em>29</em>(3), 646-660. (<a href='https://doi.org/10.1109/TEVC.2024.3365814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction (PSP) is an important scientific problem because it helps humans to understand how proteins perform their biological functions. This article models the PSP problem as a multiobjective optimization problem with three fast and accurate knowledge-based energy functions. This way, using evolutionary computation (EC)-based artificial intelligence (AI) approach to solve this multiobjective PSP problem to find the optimal structure is explainable. Considering that the multiple populations for multiple objectives (MPMO) framework shows efficient performance in solving lots of multiobjective benchmarks and real-world problems, this article proposes a new AI approach named improved MPMO-based differential evolution (IMPMO-DE) to solve the multiobjective PSP problem. To our best knowledge, this is the first time that MPMO is applied to PSP, with three novel strategies. First, an adaptive archive-based mutation strategy is proposed to better balance the exploration and exploitation abilities by adaptively using different archive-based mutation operators in different evolutionary stages. Second, a mixed individual transfer strategy is proposed to share search information among the multiple populations to accelerate the convergence speed. Third, an evolvable archive update strategy is proposed to generate more promising solutions through evolving the archived solutions. IMPMO-DE is tested on 28 representative proteins and all the available template-free modeling proteins up to 404 residues in the famous critical assessment of protein structure prediction (CASP14) competition. Experimental results show that IMPMO-DE performs better than the compared state-of-the-art EC-based PSP methods and ranks above average compared with all the CASP14 competitors. More importantly, IMPMO-DE is a new efficient AI approach that opens a promising optimization-based evolutionary and explainable way for efficient PSP rather than deep learning approaches like AlphaFold2, especially for newly discovered proteins without similar known protein structures.},
  archive      = {J_TEVC},
  author       = {Jun Hong and Zhi-Hui Zhan and Langchong He and Zongben Xu and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3365814},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {646-660},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Protein structure prediction using a new optimization-based evolutionary and explainable artificial intelligence approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-population algorithm for large-scale multiobjective optimization based on fitness-aware operator and adaptive environmental selection. <em>TEVC</em>, <em>29</em>(3), 631-645. (<a href='https://doi.org/10.1109/TEVC.2023.3296488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems (MOPs) containing a large number of decision variables, which are also known as large-scale MOPs (LSMOPs), pose great challenges to most existing evolutionary algorithms. This is mainly because that a high dimensional decision space degrades the effectiveness of search operators notably, and balancing convergence and diversity becomes a challenging task. In this article, we propose a two-population-based algorithm for large-scale multiobjective optimization named large-scale two population algorithm. In the proposed algorithm, solutions are classified in to two subpopulations: 1) a convergence subpopulation (CP) and 2) a diversity subpopulation (DP), aiming at convergence and diversity, respectively. In order to improve convergence speed, a fitness-aware variation operator (FAVO) is applied to drive DP solutions toward CP. Besides, an adaptive penalty-based boundary intersection (APBI) strategy is adopted for environmental selection in order to balance convergence and diversity temporally during different stages of evolution process. Experimental results on benchmark test problems with 100-2000 decision variables demonstrate that the proposed algorithm can achieve the best overall performance compared with several state-of-the-art large-scale multiobjective evolutionary algorithms.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yan Zhang and Peng Yang and Xin Yao and Aimin Zhou},
  doi          = {10.1109/TEVC.2023.3296488},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {631-645},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A two-population algorithm for large-scale multiobjective optimization based on fitness-aware operator and adaptive environmental selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dealing with structure constraints in evolutionary pareto set learning. <em>TEVC</em>, <em>29</em>(3), 616-630. (<a href='https://doi.org/10.1109/TEVC.2025.3537986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, many multiobjective evolutionary optimization algorithms (MOEAs) have been proposed to find a finite set of approximate Pareto solutions for a given problem in a single run. However, in many real-world applications, it could be desirable to have structure constraints on the entire optimal solution set, which define the patterns shared among all solutions. The current population-based MOEAs cannot properly handle such requirements. In this work, we make a first attempt to incorporate the structure constraints into the whole solution set. Specifically, we propose to model such a multiobjective optimization problem as a set optimization problem with structure constraints. The structure constraints define some patterns that all the solutions are required to share. Such patterns can be fixed components shared by all solutions, specific relations among decision variables, and the required shape of the Pareto set. In addition, we develop a simple yet efficient evolutionary stochastic optimization method to learn the set model, which only requires a low computational budget similar to classic MOEAs. With our proposed method, the decision-makers can easily tradeoff the Pareto optimality with preferred structures, which is not supported by other MOEAs. A set of experiments on benchmark test suites and real-world application problems demonstrates that our proposed method is effective.},
  archive      = {J_TEVC},
  author       = {Xi Lin and Xiaoyuan Zhang and Zhiyuan Yang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2025.3537986},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {616-630},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Dealing with structure constraints in evolutionary pareto set learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted multiobjective gene selection for cell classification from large-scale single-cell RNA sequencing data. <em>TEVC</em>, <em>29</em>(3), 601-615. (<a href='https://doi.org/10.1109/TEVC.2025.3533490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate cell classification is crucial but expensive for large-scale single-cell RNA sequencing (scRNA-seq) analysis. Gene selection (GS) emerges as a pivotal technique in identifying gene subsets of scRNA-seq for classification accuracy improvement and gene scale reduction. Nevertheless, the rising scale of scRNA-seq data presents challenges to existing GS methods regarding performance and computational time. Thus, we propose a surrogate-assisted evolutionary algorithm for multiobjective GS to address these deficiencies. An innovative two-phase initialization method is proposed to select sparse solutions to provide preliminary insights into gene contributions. Then, a binary competitive swarm optimizer is proposed for effective global search, where a local search method is embedded to eliminate irrelevant genes for efficiency consideration. Additionally, a surrogate model is adopted to forecast classification accuracy efficiently and substitutes part of the computationally expensive classification process. Experiments are conducted on eight large-scale scRNA-seq datasets with more than 20 000 genes. The effectiveness of the proposed GS method for scRNA-seq cell classification compared with eight state-of-the-art methods is validated. Gene expression analysis results of selected genes further validated the significance of the genes selected by the proposed method in the classification of scRNA-seq data.},
  archive      = {J_TEVC},
  author       = {Jianqing Lin and Cheng He and Hanjing Jiang and Yabing Huang and Yaochu Jin},
  doi          = {10.1109/TEVC.2025.3533490},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {601-615},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Surrogate-assisted multiobjective gene selection for cell classification from large-scale single-cell RNA sequencing data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An iterated greedy algorithm with reinforcement learning for distributed hybrid flowshop problems with job merging. <em>TEVC</em>, <em>29</em>(3), 589-600. (<a href='https://doi.org/10.1109/TEVC.2024.3443874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed hybrid flowshop scheduling problems (DHFSPs) widely exist in various industrial production processes, and thus have received widespread attention. However, the existing research mainly focuses on interfactory and intermachine collaboration, but ignores collaborative processing between jobs. Therefore, this article considers rescheduling DHFSP with job merging and reworking (DHFRPJM) and establishes a mixed-integer linear programming model. The objective is to minimize the makespan. Based on problem-specific knowledge, a decoding heuristic and initialization strategy considering job merging are designed. An acceleration strategy based on critical path is adopted to save the computational effort of the iterated greedy algorithm. A local search strategy based on a deep reinforcement learning algorithm further improves the performance of the algorithm. Experimental results based on actual production data show that the proposed algorithm outperforms other algorithms in closely related literature.},
  archive      = {J_TEVC},
  author       = {Xin-Rui Tao and Quan-Ke Pan and Liang Gao},
  doi          = {10.1109/TEVC.2024.3443874},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {589-600},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {An iterated greedy algorithm with reinforcement learning for distributed hybrid flowshop problems with job merging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning-assisted multimodal multiobjective bilevel optimization method for multirobot task allocation. <em>TEVC</em>, <em>29</em>(3), 574-588. (<a href='https://doi.org/10.1109/TEVC.2025.3535954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multirobot task allocation (MRTA) is a challenging bi-level problem in the multirobot cooperative systems (MRCSs) and offers an effective method for addressing complex tasks. However, dynamic /uncertain environments can easily invalidate original schemes in practical MRTA decision-makings. Further, a nested structure in MRTA problems makes computational expensive. Therefore, the two main tasks are 1) finding a sufficient number of equivalent schemes for MRTA problems to adapt to task environments and 2) improving algorithm search efficiency in bi-level optimization problems. In this study, a multimodal multiobjective evolutionary algorithm (MMOEA) based on deep reinforcement learning (DRL) and large neighborhood search (LNS), called MMOEA-DL, is proposed to solve MRTA problems. In the MMOEA-DL, the task allocation problem, which is considered as the upper-level optimization problem, is solved using an improved MMOEA. The traveling salesman problem (TSP) regarded as the lower-level optimization problem is addressed via end-to-end method (i.e., DRL) and LNS. By leveraging the end-to-end method to obtain the results of the lower-level optimization, the bi-level optimization problem is effectively transformed into a single-level optimization problem. To demonstrate the performance of the proposed algorithm, 16 MRTA simulation scenarios and two actual MRTA scenarios with evenly and unevenly distributed task points are introduced in the present study. The simulation results verify that the MMOEA-DL not only provides decision-makers with expanded equivalent optimal schemes to address dynamic environments or unforeseen circumstances, but also offers a novel approach to solve the multimodal multiobjective bi-level optimization problem while saving computational costs.},
  archive      = {J_TEVC},
  author       = {Yuanyuan Yu and Qirong Tang and Qingchao Jiang and Qinqin Fan},
  doi          = {10.1109/TEVC.2025.3535954},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {574-588},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A deep reinforcement learning-assisted multimodal multiobjective bilevel optimization method for multirobot task allocation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial machine-learning-assisted evolutionary computation. <em>TEVC</em>, <em>29</em>(3), 571-573. (<a href='https://doi.org/10.1109/TEVC.2025.3548888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TEVC},
  author       = {Rong Qu and Nelishia Pillay and Emma Hart and Manuel López-Ibáñez},
  doi          = {10.1109/TEVC.2025.3548888},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {6},
  number       = {3},
  pages        = {571-573},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Guest editorial machine-learning-assisted evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zeroth-order Actor–Critic: An evolutionary framework for sequential decision problems. <em>TEVC</em>, <em>29</em>(2), 555-569. (<a href='https://doi.org/10.1109/TEVC.2025.3529503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) have shown promise in solving sequential decision problems (SDPs) by simplifying them to static optimization problems and searching for the optimal policy parameters in a zeroth-order way. Despite their versatility, EAs often suffer from high sample complexity due to neglecting underlying temporal structures. In contrast, reinforcement learning (RL) methods typically formulate SDPs as Markov decision process (MDP). Although more sample efficient than EAs, RL methods are restricted to differentiable policies and prone to getting stuck in local optima. To address these issues, we propose a novel evolutionary framework zeroth-order actor-critic (ZOAC). We propose to use stepwise exploration in parameter space and theoretically derive the zeroth-order policy gradient. We further utilize the actor-critic architecture to effectively leverage the Markov property of SDPs and reduce the variance of gradient estimators. In each iteration, ZOAC collects trajectories with parameter space exploration, and alternates between first-order policy evaluation (PEV) and zeroth-order policy improvement (PIM). We evaluate the effectiveness of ZOAC on a challenging multilane driving task optimizing the parameters in a rule-based, nondifferentiable driving policy that consists of three submodules: 1) behavior selection; 2) path planning; and 3) trajectory tracking. We also compare it with gradient-based RL methods on three Gymnasium tasks, optimizing neural network policies with thousands of parameters. Experimental results demonstrate the strong capability of ZOAC in solving SDPs. ZOAC significantly outperforms EAs that treat the problem as static optimization and matches the performance of gradient-based RL methods even without first-order information, in terms of total average return across tasks.},
  archive      = {J_TEVC},
  author       = {Yuheng Lei and Yao Lyu and Guojian Zhan and Tao Zhang and Jiangtao Li and Jianyu Chen and Shengbo Eben Li and Sifa Zheng},
  doi          = {10.1109/TEVC.2025.3529503},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {555-569},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Zeroth-order Actor–Critic: An evolutionary framework for sequential decision problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary computation in the era of large language model: Survey and roadmap. <em>TEVC</em>, <em>29</em>(2), 534-554. (<a href='https://doi.org/10.1109/TEVC.2024.3506731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have not only revolutionized natural language processing but also extended their prowess to various domains, marking a significant stride toward artificial general intelligence. The interplay between LLMs and evolutionary algorithms (EAs), despite differing in objectives and methodologies, share a common pursuit of applicability in complex problems. Meanwhile, EA can provide an optimization framework for LLM’s further enhancement under closed box settings, empowering LLM with flexible global search capacities. On the other hand, the abundant domain knowledge inherent in LLMs could enable EA to conduct more intelligent searches. Furthermore, the text processing and generative capabilities of LLMs would aid in deploying EAs across a wide range of tasks. Based on these complementary advantages, this article provides a thorough review and a forward-looking roadmap, categorizing the reciprocal inspiration into two main avenues: 1) LLM-enhanced EA and 2) EA-enhanced LLM. Some integrated synergy methods are further introduced to exemplify the complementarity between LLMs and EAs in diverse scenarios, including code generation, software engineering, neural architecture search, and various generation tasks. As the first comprehensive review focused on the EA research in the era of LLMs, this article provides a foundational stepping stone for understanding the collaborative potential of LLMs and EAs. The identified challenges and future directions offer guidance for researchers and practitioners to unlock the full potential of this innovative collaboration in propelling advancements in optimization and artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/wuxingyu-ai/LLM4EC.},
  archive      = {J_TEVC},
  author       = {Xingyu Wu and Sheng-Hao Wu and Jibin Wu and Liang Feng and Kay Chen Tan},
  doi          = {10.1109/TEVC.2024.3506731},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {534-554},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary computation in the era of large language model: Survey and roadmap},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient-guided local search for large-scale hypervolume subset selection. <em>TEVC</em>, <em>29</em>(2), 519-533. (<a href='https://doi.org/10.1109/TEVC.2025.3531950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of an unbounded archive (UA) has attracted much attention in the filed of evolutionary multiobjective optimization (EMO) since a solution set selected from the UA is often better than the final population. The size of the UA is very large (e.g., 1 000 000) since it is unbounded and it stores all the examined nondominated solutions during the execution of an EMO algorithm. Thus, an algorithm which can efficiently select a high-quality subset from a large-scale candidate set (e.g., UA) is needed. In this article, we propose a gradient-guided local search hypervolume subset selection (GL-HSS) algorithm to efficiently select a high-quality subset from a large-scale candidate set. In each iteration of GL-HSS, the gradient of the hypervolume (HV) contribution of each selected solution is used to guide the local search. As a result, the proposed algorithm can quickly improve the HV of the selected subset. Experimental results show that, compared to the existing subset selection algorithms, the proposed GL-HSS algorithm can efficiently select high-quality subsets from various large-scale candidate sets.},
  archive      = {J_TEVC},
  author       = {Yang Nan and Tianye Shu and Hisao Ishibuchi and Ke Shang},
  doi          = {10.1109/TEVC.2025.3531950},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {519-533},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Gradient-guided local search for large-scale hypervolume subset selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-individual evolutionary algorithm for cumulative capacitated vehicle routing with single and multiple depots. <em>TEVC</em>, <em>29</em>(2), 505-518. (<a href='https://doi.org/10.1109/TEVC.2024.3361910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cumulative capacitated vehicle routing problem (CCVRP) with single or multiple depots (MDCCVRP) is a variant of the popular capacitated vehicle routing problem. Instead of minimizing the total travel time, the objective here is to minimize the sum of all customers’ waiting times. This problem has a variety of real-world applications, especially in post-disaster humanitarian relief. To solve the challenging CCVRP and MDCCVRP, we propose a unified two-individual evolutionary algorithm that follows the memetic search framework. The algorithm integrates several key features: a two-individual population mechanism to accelerate convergence while maintaining population diversity, a dedicated edge assembly crossover to generate high-quality offspring, and an adaptive feasible and infeasible local search to achieve a balanced exploration between feasible and infeasible solutions. The algorithm is evaluated on 39 CCVRP instances and 78 MDCCVRP instances commonly used in the literature. Computational results show that for the CCVRP, the algorithm outperforms the leading algorithms by achieving improved best results (new upper bound) for 13 instances and matching the best results for 23 other instances. For the MDCCVRP, the algorithm achieves nine improved best results and matches the best results for the remaining instances. The critical components of the algorithm are investigated to understand their contributions.},
  archive      = {J_TEVC},
  author       = {Yuji Zou and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1109/TEVC.2024.3361910},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {505-518},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A two-individual evolutionary algorithm for cumulative capacitated vehicle routing with single and multiple depots},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From direct to directional variable Dependencies—Nonsymmetrical dependencies discovery in real-world and theoretical problems. <em>TEVC</em>, <em>29</em>(2), 490-504. (<a href='https://doi.org/10.1109/TEVC.2024.3496193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge about variable interactions is frequently employed in state-of-the-art research concerning genetic algorithms (GAs). Whether these interactions are known a priori (gray-box optimization) or are discovered by the optimizer (black-box optimization), they are used for many purposes, including proposing more effective mixing operators. Frequently, the quality of the problem structure decomposition is decisive to the optimizers’ effectiveness. However, in gray- and black-box optimization, the dependency between the variables is assumed to be symmetric. This work identifies and defines the nonsymmetrical (directional) variable dependencies. We show that these dependencies may exist (together with symmetrical) in the considered real-world problem, in which we must optimize subsequent variable groups (one after the other) in the appropriate optimization order that is not known by the optimizer. To improve GA’s effectiveness in solving the problem of such features, we propose a new linkage learning (LL) technique that can discover symmetrical and nonsymmetrical dependencies (in binary and nonbinary discrete domains) and distinguish them from each other. We show that telling these two types of dependencies from each other may significantly increase the optimizer’s effectiveness in solving real-world and theoretical problems with nonsymmetrical dependencies. Finally, we show that using the proposed LL technique does not deteriorate the effectiveness of the state-of-the-art optimizer in solving typical benchmarks containing only symmetrical dependencies.},
  archive      = {J_TEVC},
  author       = {Michal Witold Przewozniczek and Bartosz Frej and Marcin Michal Komarnicki},
  doi          = {10.1109/TEVC.2024.3496193},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {490-504},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {From direct to directional variable Dependencies—Nonsymmetrical dependencies discovery in real-world and theoretical problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOTEA-II: A collaborative multiobjective transformation-based evolutionary algorithm for bilevel optimization. <em>TEVC</em>, <em>29</em>(2), 474-489. (<a href='https://doi.org/10.1109/TEVC.2025.3538611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) for optimization have received wide attention due to their robustness and practicality. However, the traditional way of asynchronously handling bilevel optimization problems (BLOPs) ignores the benefits brought by effective upper- and lower-level collaboration. To address this issue, this article proposes a collaborative multiobjective transformation (MOT)-based EA (MOTEA-II). In MOTEA-II, the BLOP is handled within a decomposition-based multiobjective optimization paradigm using a two-stage collaborative MOT strategy. The stage-1 MOT focuses on multiple lower-level optimizations and collaboration, while stage-2 collaborates the upper-level optimization with lower-level optimization, which makes simultaneously horizontal and vertical optimization information sharing in bilevel optimization possible. In addition, a dynamic decomposition strategy is further proposed to reconstruct the hierarchy relationship in collaborative multiobjective optimization, facilitating the adaptive and flexible importance control of the upper-level objective optimization and lower-level optimality satisfaction for better-bilevel search efficiency. Empirical studies are conducted on two groups of commonly used BLOP benchmark suites and four practical applications. Experimental results show that the proposed collaborative MOTEA-II can achieve performance comparable to that of the previous MOTEA and three other representative EA-based bilevel optimization approaches, but using much fewer computational resources.},
  archive      = {J_TEVC},
  author       = {Lei Chen and Yiu-Ming Cheung and Hai-Lin Liu and Yutao Lai},
  doi          = {10.1109/TEVC.2025.3538611},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {474-489},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {MOTEA-II: A collaborative multiobjective transformation-based evolutionary algorithm for bilevel optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bidirectional differential evolution-based unknown cyberattack detection system. <em>TEVC</em>, <em>29</em>(2), 459-473. (<a href='https://doi.org/10.1109/TEVC.2024.3365101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolving unknown cyberattacks, compounded by the widespread emerging technologies (say 5G, Internet of Things, etc.), have rapidly expanded the cyber threat landscape. However, most existing intrusion detection systems (IDSs) are effective in detecting only known cyberattacks, because only known cyberattack samples are usually available for IDS training. Identifying unknown cyberattacks, therefore, remains a big challenging issue. To meet this gap, in this article, motivated by artificial immunity (AIm) and differential evolution (DE), we propose a bidirectional DE-based unknown cyberattack detection system, coined BDE-IDS. Specifically, we first design a bidirectional DE algorithm for known nonself antigens (abnormal data), where bidirectional evolutionary directions are considered for increasing or decreasing the differences between known nonself antigens and self antigens (normal data), to create new antigens possibly used for generating cyberattack detectors. Second, a novel tolerance training mechanism is developed to eliminate invalid newly evolved antigens falling into the coverage of either known self or nonself antigens. Third, the remaining antigens are employed to generate detectors for unknown cyberattacks. Extensive experiments demonstrate that the BDE-IDS achieves outperformance in detecting unknown cyberattacks (as well as known cyberattacks) compared to state-of-the-art studies, including those AIm-based, signature-based, and anomaly-based IDSs.},
  archive      = {J_TEVC},
  author       = {Hanyuan Huang and Tao Li and Beibei Li and Wenhao Wang and Yanan Sun},
  doi          = {10.1109/TEVC.2024.3365101},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {459-473},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bidirectional differential evolution-based unknown cyberattack detection system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal inference-based large-scale multiobjective optimization. <em>TEVC</em>, <em>29</em>(2), 444-458. (<a href='https://doi.org/10.1109/TEVC.2025.3529938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multiobjective optimization problems (LSMOPs), characterized by a substantial number of decision variables, pose significant challenges for many existing evolutionary algorithms. However, the search efficiency of these algorithms is not yet satisfactory. This is mainly because that the search efficiency of these algorithms may deteriorate dramatically since the search space increases exponentially with the number of decision variables. Having this in mind, we proposed a large-Scale multiobjective optimization framework named causal inference-based competitive swarm optimizer (CI-CSO). Specifically, a causal-information-(CI)-based operator is designed for competitive swarm optimizers. First, a causal inference technique named information geometric causal inference (IGCI) is introduced to adequately explore the CI between decision variables and fitness values. To further distinguish the positive or negative impacts of these critical variables on solution quality, a CI processing module is designed, facilitating targeted optimization. To enhance search efficiency, CI-based offspring generator are employed, leveraging the variance of causal effects to dynamically adjust the search step size and sampling range. To evaluate its performance, the proposed CI-based operator is embedded into two multiobjective evolutionary algorithms (MOEAs) (LSTPA and LMOCSO). To demonstrate the effectiveness of the proposed framework, experimental results are presented using the LSMOP test suite and five real-world problems, each involving up to 10 000 decision variables. In addition, six classic algorithms are included for comparison.},
  archive      = {J_TEVC},
  author       = {Bingdong Li and Yanting Yang and Peng Yang and Guiying Li and Ke Tang and Aimin Zhou},
  doi          = {10.1109/TEVC.2025.3529938},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {444-458},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Causal inference-based large-scale multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiform genetic programming framework for symbolic regression problems. <em>TEVC</em>, <em>29</em>(2), 429-443. (<a href='https://doi.org/10.1109/TEVC.2025.3527875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {genetic programming (GP) is a widely recognized and powerful approach for symbolic regression (SR) problems. However, existing GP methods rely on a single form to solve the problem, which limits their search diversity and increases the likelihood of getting stuck in local optima, especially in complex scenarios. In this article, we propose a general multiform GP (MFGP) framework to improve the performance of GP on complicated SR problems. As far as we know, this articel is the first attempt to integrate the multiform optimization paradigm with GP to accelerate the search performance. The key idea of the proposed framework is to construct multiple forms to solve the same problem cooperatively at the same time. During the evolution process, knowledge gained from different forms is shared among the solvers to improve the search diversity and efficiency. A knowledge transfer mechanism is specifically designed to facilitate knowledge transfer among GP solvers with different modeling forms. In addition, an adaptive resource control mechanism is designed to reallocate computing resources according to the problem solving efficiency of different solvers to further improve search efficiency. To demonstrate the effectiveness of the proposed framework, a multiform gene expression programming algorithm is designed and tested on 20 problems, including physical datasets, synthetic datasets, and real-world datasets. The experimental results have demonstrated the effectiveness of the proposed framework.},
  archive      = {J_TEVC},
  author       = {Jinghui Zhong and Junlan Dong and Wei-Li Liu and Liang Feng and Jun Zhang},
  doi          = {10.1109/TEVC.2025.3527875},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {429-443},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiform genetic programming framework for symbolic regression problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protein design by directed evolution guided by large language models. <em>TEVC</em>, <em>29</em>(2), 418-428. (<a href='https://doi.org/10.1109/TEVC.2024.3439690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed evolution, a strategy for protein engineering, optimizes protein properties (i.e., fitness) by a rigorous and resource-intensive process of screening or selecting among a vast range of mutations. By conducting an in-silico screening of sequence properties, machine learning-guided directed evolution (MLDE) can expedite the optimization process and alleviate the experimental workload. In this work, we propose a general MLDE framework in which we apply recent advancements of deep learning in protein representation learning and protein property prediction to accelerate the searching and optimization processes. In particular, we introduce an optimization pipeline that utilizes the large language models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness. Our experiments have shown the superior efficiency and efficacy of our proposed framework in the conditional protein generation, in comparison with the other state-of-the-art baseline algorithms. We expect this work will shed a new light on not only protein engineering but also on solving the combinatorial problems using the data-driven methods.},
  archive      = {J_TEVC},
  author       = {Thanh V. T. Tran and Truong Son Hy},
  doi          = {10.1109/TEVC.2024.3439690},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {418-428},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Protein design by directed evolution guided by large language models},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupling constraint: Task clone-based multitasking optimization for constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(2), 404-417. (<a href='https://doi.org/10.1109/TEVC.2024.3358854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coupling of multiple constraints can pose difficulties in solving constrained multiobjective optimization problems (CMOPs). Existing constrained multiobjective evolutionary algorithms (CMOEAs) often overlook this issue by considering all constraints together. This article proposes MTOTC, a novel multitasking optimization algorithm that addresses this challenge through a task clone technique. MTOTC clones the target CMOP with $q$ constraints into $q+1$ copies, resulting in a total of $q+2$ tasks. Each cloned task is handled using an independent population that considers a unique constraint-handling sequence, effectively decoupling the constraints in $q+1$ different ways. Additionally, the algorithm incorporates online information sharing between the target task and cloned tasks, enabling the utilization of valuable search history as much as possible. Experimental results on four recently developed complex CMOP benchmark suites and a series of real-world CMOPs demonstrate the superior performance of MTOTC compared to seven state-of-the-art CMOEAs.},
  archive      = {J_TEVC},
  author       = {Genghui Li and Zhenkun Wang and Weifeng Gao and Ling Wang},
  doi          = {10.1109/TEVC.2024.3358854},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {404-417},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Decoupling constraint: Task clone-based multitasking optimization for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biased random key genetic algorithm for solving the longest common square subsequence problem. <em>TEVC</em>, <em>29</em>(2), 390-403. (<a href='https://doi.org/10.1109/TEVC.2024.3413150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the longest common square subsequence (LCSqS) problem, a variant of the longest common subsequence (LCS) problem in which solutions must be square strings. A square string can be expressed as the concatenation of a string with itself. The LCSqS problem has applications in bioinformatics, for discovering internal similarities between molecular structures. We propose a metaheuristic approach, a biased random key genetic algorithm (BRKGA) hybridized with a beam search (BS) from the literature. Our approach is based on reducing the LCSqS problem to a set of promising LCS problems. This is achieved by cutting each input string into two parts first and then evaluating such a transformed instance by solving the LCS problem for the obtained overall set of strings. The task of the BRKGA is, hereby, to find a set of good cut points for the input strings. For this purpose, the search is carefully biased by problem-specific greedy information. For each cut point vector, the resulting LCS problem is approximately solved by the existing BS approach. The proposed algorithm is evaluated against a previously proposed state-of-the-art variable neighborhood search (VNS) on random uniform instances from the literature, new nonuniform instances, and a real-world instance set consisting of DNA strings. The results underscore the importance of our work, as our novel approach outperforms former state-of-the-art with statistical significance. Particularly, they evidence the limitations of the VNS when solving nonuniform instances, for which our method shows superior performance.},
  archive      = {J_TEVC},
  author       = {Jaume Reixach and Christian Blum and Marko Djukanović and Günther R. Raidl},
  doi          = {10.1109/TEVC.2024.3413150},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {390-403},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A biased random key genetic algorithm for solving the longest common square subsequence problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel knowledge-based genetic algorithm for robot path planning in complex environments. <em>TEVC</em>, <em>29</em>(2), 375-389. (<a href='https://doi.org/10.1109/TEVC.2025.3534026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel knowledge-based genetic algorithm (GA) to generate a collision-free path in complex environments. The proposed algorithm infuses specific domain knowledge into robot path planning through the development of five problem-specific operators that integrate a local search technique to improve efficiency. In addition, the proposed algorithm introduces a unique and straightforward representation of the robot path and an effective method for evaluating the path quality and accurately detecting collisions. The proposed algorithm is capable of finding optimal or suboptimal robot paths in both static and dynamic environments. Simulation and experimental studies are conducted to showcase the effectiveness and efficiency of the proposed algorithm. Furthermore, a comparative study is performed to highlight the indispensable role of specialized genetic operators within the proposed algorithm in solving the path planning problem.},
  archive      = {J_TEVC},
  author       = {Junfei Li and Yanrong Hu and Simon X. Yang},
  doi          = {10.1109/TEVC.2025.3534026},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {375-389},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A novel knowledge-based genetic algorithm for robot path planning in complex environments},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic multi-armed bandits: A reinforcement learning inspired approach for simulation optimization. <em>TEVC</em>, <em>29</em>(2), 360-374. (<a href='https://doi.org/10.1109/TEVC.2024.3524505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems are inherently stochastic, complicating, or even precluding the use of analytical methods. These problems are often characterized by high dimensionality, large solution spaces, and numerous local optima, which make finding optimal solutions challenging. Therefore, simulation optimization is frequently employed. This article specifically focuses on the discrete case, also known as discrete optimization via simulation. Despite their adaptions for stochastic problems, previous evolutionary algorithms face a major limitation in these problems. They discard all information about solutions that are not involved in the most recent population. However, this is ineffective, as each simulation observation gathered over the course of iterations provides valuable information that should guide the selection of subsequent solutions. Inspired by the domain of reinforcement learning (RL), we propose a novel memory concept for evolutionary algorithms that ensures global convergence and significantly improves their finite time performance. Unlike previous evolutionary algorithms, our approach permanently preserves simulation observations to progressively improve the accuracy of sample means when revisiting solutions in later iterations. Moreover, the selection of new solutions is based on the entire memory rather than just the last population. The numerical experiments demonstrate that this novel approach, which combines a genetic algorithm (GA) with such memory, consistently outperforms popular convergent state-of-the-art benchmark algorithms in a large variety of established test problems while requiring considerably less computational effort. This marks the so-called genetic multi-armed bandit (MAB) as one of the currently most powerful algorithms for solving stochastic problems.},
  archive      = {J_TEVC},
  author       = {Deniz Preil and Michael Krapp},
  doi          = {10.1109/TEVC.2024.3524505},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {360-374},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic multi-armed bandits: A reinforcement learning inspired approach for simulation optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic programming hyper heuristic with elitist mutation for integrated order batching and picker routing problem. <em>TEVC</em>, <em>29</em>(2), 346-359. (<a href='https://doi.org/10.1109/TEVC.2025.3532022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated order batching and picker routing (IOBPR) is a complex combinatorial optimization problem in real-world intelligent manufacturing systems. Heuristics are often used for solving such complex scheduling problems. Manually designing scheduling heuristics suffer from two limitations: 1) few problem features can be taken into account and 2) the design process is time consuming. Genetic programming hyper heuristic (GPHH) approaches have been proposed on many scheduling problems to automatically evolve effective heuristics. However, existing GPHH approaches are often problem specific and requires careful design of problem specific terminal sets and evolution operators. The aim of this work is to develop a GPHH approach to evolve heuristics for the IOBPR problem. In particular, we propose a novel terminal set (NT) with three types of terminals, and a GPHH with elitist mutation (GPHH-EM) algorithm. Extensive experiments demonstrate that the heuristics evolved by GPHH-EM can significantly outperform other state-of-the-art competing algorithms designed by human experts. Further analysis indicates that the three types of terminals effectively complement to improve evolved heuristics for decision making. Furthermore, the newly developed elitist mutation operator expedites the evolutionary process for GPHH to find high-quality heuristics.},
  archive      = {J_TEVC},
  author       = {Yuquan Wang and Naiming Xie and Nanlei Chen and Hui Ma and Gang Chen},
  doi          = {10.1109/TEVC.2025.3532022},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {346-359},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Genetic programming hyper heuristic with elitist mutation for integrated order batching and picker routing problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLaMEA: A large language model evolutionary algorithm for automatically generating metaheuristics. <em>TEVC</em>, <em>29</em>(2), 331-345. (<a href='https://doi.org/10.1109/TEVC.2024.3497793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs), such as GPT-4 have demonstrated their ability to understand natural language and generate complex code snippets. This article introduces a novel LLM evolutionary algorithm (LLaMEA) framework, leveraging GPT models for the automated generation and refinement of algorithms. Given a set of criteria and a task definition (the search space), LLaMEA iteratively generates, mutates, and selects algorithms based on performance metrics and feedback from runtime evaluations. This framework offers a unique approach to generating optimized algorithms without requiring extensive prior expertise. We show how this framework can be used to generate novel closed box metaheuristic optimization algorithms for box-constrained, continuous optimization problems automatically. LLaMEA generates multiple algorithms that outperform state-of-the-art optimization algorithms (covariance matrix adaptation evolution strategy and differential evolution) on the 5-D closed box optimization benchmark (BBOB). The algorithms also show competitive performance on the 10- and 20-D instances of the test functions, although they have not seen such instances during the automated generation process. The results demonstrate the feasibility of the framework and identify future directions for automated generation and optimization of algorithms via LLMs.},
  archive      = {J_TEVC},
  author       = {Niki van Stein and Thomas Bäck},
  doi          = {10.1109/TEVC.2024.3497793},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {331-345},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {LLaMEA: A large language model evolutionary algorithm for automatically generating metaheuristics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-assisted multiobjective evolutionary algorithm for routing and packing. <em>TEVC</em>, <em>29</em>(2), 317-330. (<a href='https://doi.org/10.1109/TEVC.2024.3357819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many combinatorial multiobjective optimization problems involve very costly-to-evaluate objectives and constraints. It is very difficult, if not impossible, for traditional heuristics to solve these problems with an acceptable amount of computational time. In this article, we show that offline machine learning can be very useful to assist multiobjective evolutionary algorithms to tackle this kind of problem. We take a complicated real-life multiobjective routing-packing problem as the test bed. We propose to use offline machine learning methods to replace time-consuming packing heuristics for packing feasibility prediction. Experiments show that the machine learning models can be 1000 times faster than some commonly used packing heuristics and their accuracy can be as high as 98%. We adopt decomposition-based multiobjective evolutionary algorithmic to decompose the problem into a number of single objective subproblems and solve them in a collaborative manner. We propose an encoding strategy to represent each routing scheme and use genetic operators to generate new routes. Experimental studies have been conducted on 100 instances from HUAWEI’s real-world logistics application and two test suites from the literature. Our proposed method can solve each HUAWEI instance in around 1 min. Our solutions on the two test suites are comparable to other existing algorithms, and the overall computational cost of our method is significantly lower than others.},
  archive      = {J_TEVC},
  author       = {Fei Liu and Qingfu Zhang and Qingling Zhu and Xialiang Tong and Mingxuan Yuan},
  doi          = {10.1109/TEVC.2024.3357819},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {317-330},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Machine learning-assisted multiobjective evolutionary algorithm for routing and packing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization for quality diversity search with coupled descriptor functions. <em>TEVC</em>, <em>29</em>(2), 302-316. (<a href='https://doi.org/10.1109/TEVC.2024.3376733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality diversity (QD) algorithms, such as the multidimensional archive of phenotypic elites (MAP-Elites), are a class of optimization techniques that attempt to find many high-performing points that all behave differently according to a user-defined behavioral metric. In this article we propose the Bayesian optimization of elites (BOP-Elites) algorithm. Designed for problems with expensive fitness functions and coupled behavior descriptors, it is able to return a QD solution-set with excellent performance already after a relatively small number of samples. BOP-Elites models both fitness and behavioral descriptors with Gaussian Process surrogate models and uses Bayesian optimization strategies for choosing points to evaluate in order to solve the quality-diversity problem. In addition, BOP-Elites produces high-quality surrogate models which can be used after convergence to predict solutions with any behavior in a continuous range. An empirical comparison shows that BOP-Elites significantly outperforms other state-of-the-art algorithms without the need for problem-specific parameter tuning.},
  archive      = {J_TEVC},
  author       = {Paul Kent and Adam Gaier and Jean-Baptiste Mouret and Juergen Branke},
  doi          = {10.1109/TEVC.2024.3376733},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {302-316},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Bayesian optimization for quality diversity search with coupled descriptor functions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge structure preserving-based evolutionary many-task optimization. <em>TEVC</em>, <em>29</em>(2), 287-301. (<a href='https://doi.org/10.1109/TEVC.2024.3355781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a challenging research topic in evolutionary multitask optimization (EMTO), evolutionary many-task optimization (EMaTO) aims at solving more than three tasks simultaneously. The design of the EMaTO algorithm generally needs to consider two major open issues, which are how to obtain useful knowledge from similar source tasks and how to effectively transfer knowledge to the target task. In this article, we discover that knowledge structure plays a significant role in dealing with these two issues and propose a novel knowledge structure preserving-based evolutionary algorithm (KSP-EA) to efficiently solve many-task optimization problems. KSP-EA aims to achieve two goals, which are first to obtain useful structure-preserved knowledge from similar source tasks and second to effectively transfer both direct and indirect knowledge to the target task. To achieve the first goal, we propose a local-structure-preserved knowledge acquisition strategy that projects the knowledge of similar source tasks into a unified subspace without loss of the knowledge structure, thus enhancing the quality of the obtained knowledge. To achieve the second goal, we propose a tree-based knowledge propagation strategy that constructs a knowledge propagating tree to connect all the tasks and propagates knowledge along the edges of this tree. This way, the target task can obtain both direct and indirect knowledge, improving the effectiveness of knowledge transfer. We conduct extensive experiments on CEC19 and WCCI22 many-task optimization test suites and a real-world application scenario to evaluate the performance of KSP-EA. The experimental results show that our KSP-EA generally outperforms state-of-the-art algorithms.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Sam Kwong and Jun Zhang},
  doi          = {10.1109/TEVC.2024.3355781},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {4},
  number       = {2},
  pages        = {287-301},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge structure preserving-based evolutionary many-task optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of constrained continuous multiobjective optimization problems: A performance space perspective. <em>TEVC</em>, <em>29</em>(1), 275-285. (<a href='https://doi.org/10.1109/TEVC.2024.3366659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multiobjective optimization has gained much interest in the past few years. However, constrained multiobjective optimization problems (CMOPs) are still unsatisfactorily understood. Consequently, the choice of adequate CMOPs for benchmarking is difficult and lacks a formal background. This article takes a step toward addressing this issue by exploring CMOPs from a performance space perspective. First, it presents a novel performance assessment approach designed explicitly for constrained multiobjective optimization. This methodology offers a first attempt at simultaneously measuring the performance in approximating the Pareto front and constraint satisfaction. Second, it proposes an approach to measure the capability of the given optimization problem to differentiate among algorithm performances. Finally, this approach is used to compare eight frequently used artificial test suites of CMOPs. The experimental results reveal which suites are more efficient in discerning between four well-known multiobjective optimization algorithms.},
  archive      = {J_TEVC},
  author       = {Aljoša Vodopija and Tea Tušar and Bogdan Filipič},
  doi          = {10.1109/TEVC.2024.3366659},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {275-285},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Characterization of constrained continuous multiobjective optimization problems: A performance space perspective},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determining metaheuristic similarity using behavioral analysis. <em>TEVC</em>, <em>29</em>(1), 262-274. (<a href='https://doi.org/10.1109/TEVC.2023.3346672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many nature-inspired metaheuristics have been published, with claims of originality based on the metaphor that inspired the algorithm. Rarely is empirical evidence given to show algorithmic originality. In order to provide an easy and computationally cheap approach to characterize algorithm search behavior, a suite of 20 behavioral characteristics is proposed. This behavioral characteristic suite allows for the search behavior of an algorithm to be quantified without manual inspection. By doing so, behavioral novelty of any given algorithm may be determined by comparing the behavioral characteristics to those of well-known metaheuristics. To illustrate this use, and to evaluate whether metaheuristics are behaviorally distinct, a host of metaheuristics is run on various benchmark functions. To evaluate behavioral similarity across all problems, while acknowledging behavior to be problem dependant, a novel method is proposed. In addition to this method, new behavioral characteristics are also proposed. The behavioral vectors generated for each benchmark function are clustered. The relationships and trends present in the different clusters are summarized by creating a pair-wise matrix for every metaheuristic pair, which tallies the number of times that the pair are found within the same cluster. The tallies are then analyzed in order to make inference regarding the distinctness of any metaheuristic’s behaviors, across many different benchmark functions. The analysis finds that the range of unique search behaviors is small and that most metaheuristics share their behaviors with most other metaheuristics. The analysis also identifies both unique algorithms, as well as algorithms which have no unique behaviors.},
  archive      = {J_TEVC},
  author       = {Lauren Hayward and Andries Engelbrecht},
  doi          = {10.1109/TEVC.2023.3346672},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {262-274},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Determining metaheuristic similarity using behavioral analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible ranking-based competitive swarm optimizer for large-scale continuous multiobjective optimization. <em>TEVC</em>, <em>29</em>(1), 247-261. (<a href='https://doi.org/10.1109/TEVC.2024.3355221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the curse of dimensionality, the search efficiency of existing operators in large-scale decision space deteriorates dramatically. The competitive swarm optimizer (CSO)-based framework has great potential in tackling large-scale single-objective optimization problems. However, the existing CSOs only focus on the loser to winner learning paradigm and neglect the significance of the winner determination mechanism for large-scale search, which makes the algorithm difficult to escape from local optima. To remedy this issue, a flexible ranking-based CSO has been tailored for handling large-scale multiobjective optimization problems (MOPs). Concretely, a novel winner determination strategy is introduced to broadly identify high-quality individuals in the population to enhance diversity maintenance. In addition, a special competitive mechanism is adopted to guide the search direction, which is capable of efficiently increasing search space utilization. The simulation results validate that the proposed algorithm can significantly enhance the exploration and exploitation ability of the conventional CSO, and outperforms several state-of-the-art large-scale multiobjective optimization algorithms on both large-scale benchmark MOPs and application examples.},
  archive      = {J_TEVC},
  author       = {Xiangzhou Gao and Shenmin Song and Hu Zhang and Zhenkun Wang},
  doi          = {10.1109/TEVC.2024.3355221},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {247-261},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A flexible ranking-based competitive swarm optimizer for large-scale continuous multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-learning evolutionary algorithm for transportation-constrained and distributed energy-efficient flexible scheduling. <em>TEVC</em>, <em>29</em>(1), 232-246. (<a href='https://doi.org/10.1109/TEVC.2024.3354850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of globalization and environmental concerns, distributed scheduling and energy-efficient scheduling have become crucial topics in the informational manufacturing system. Additionally, the growing consideration about realistic constraints, such as transportation time and finite transportation resources, has made the scheduling problem increasingly complex. Facing these challenges, special mechanisms are required to improve the efficiency of solving algorithms. In this article, a bi-learning evolutionary algorithm (BLEA) is proposed to solve the distributed energy-efficient flexible job shop problem with transportation constraints (DEFJSP-T). First, we integrate statistical learning (SL) and evolutionary learning (EL) in the framework, while decomposition and Pareto dominance methods are employed in different stages to handle conflicting objectives. During the SL stage, probability models are established to statistically search for advantageous substructures on each weight vector, and an update mechanism is devised to improve the exploration. In the EL stage, the genetic operators are introduced and an improved local search that takes into account the problem properties is proposed to realize sufficient exploitation. Finally, according to the performance of the SL, a novel switching mechanism between SL and EL is designed to ensure the rational allocation of computing resources. Extensive experiments are conducted to test the performances of the BLEA. The statistical comparison shows that the BLEA is superior in solving the DEFJSP-T in terms of efficiency and effectiveness.},
  archive      = {J_TEVC},
  author       = {Zixiao Pan and Ling Wang and Jingjing Wang and Qingfu Zhang},
  doi          = {10.1109/TEVC.2024.3354850},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {232-246},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A bi-learning evolutionary algorithm for transportation-constrained and distributed energy-efficient flexible scheduling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming. <em>TEVC</em>, <em>29</em>(1), 217-231. (<a href='https://doi.org/10.1109/TEVC.2024.3353207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LGP has been successfully applied to dynamic job shop scheduling (DJSS) to automatically evolve dispatching rules. Flow control operations are crucial in concisely describing complex knowledge of dispatching rules, such as different dispatching rules in different conditions. However, existing linear genetic programming (LGP) methods for DJSS have not fully considered the use of flow control operations. They simply included flow control operations in their primitive set, which inevitably leads to a huge number of redundant and obscure solutions in LGP search spaces. To move one step toward evolving effective and interpretable dispatching rules, this article explicitly considers the characteristics of flow control operations via grammar-guided LGP and focuses on IF operations as a starting point. Specifically, this article designs a new set of normalized terminals to improve the interpretability of IF operations and proposes three restrictions by grammar rules on the usage of IF operations: 1) specifying the available inputs; 2) the maximum number; and 3) the possible locations of IF operations. The experiment results verify that the proposed method can achieve significantly better-test performance than state-of-the-art LGP methods and improves interpretability by IF-included dispatching rules. Further investigation confirms that the explicit introduction of IF operations helps effectively evolve different dispatching rules according to their decision situations.},
  archive      = {J_TEVC},
  author       = {Zhixing Huang and Yi Mei and Fangfang Zhang and Mengjie Zhang},
  doi          = {10.1109/TEVC.2024.3353207},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {217-231},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective multitask optimization with multiple knowledge types and transfer adaptation. <em>TEVC</em>, <em>29</em>(1), 205-216. (<a href='https://doi.org/10.1109/TEVC.2024.3353319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) exploits the correlation among different tasks to help handle them through knowledge transfer (KT) techniques in evolutionary algorithms. In this area, multiobjective multitask optimization (MO-MTO) utilizes EMT to solve multiple multiobjective optimization tasks simultaneously. The key to addressing MO-MTO problems (MO-MTOPs) is to transfer appropriate knowledge among optimization tasks to assist the multiobjective evolutionary process. Both the type and the amount of knowledge can significantly affect the KT process. To achieve better KT behavior, we propose a multiple knowledge types and transfer adaptation (MKTA) framework for handling MO-MTOPs. The MKTA framework incorporates multiple types of knowledge in order to obtain comprehensive KT performance. It also provides transfer adaptation strategies to control: 1) the type of knowledge and 2) the amount of knowledge for KT via parameter adaptation approaches, thereby mitigating negative KT. Furthermore, we propose an evolution-path-model-based knowledge type and incorporate the existing unified-search-space-based knowledge type to form the knowledge pool for MKTA. Finally, the MKTA framework is coupled with a ranking-based differential evolution operator to constitute the complete algorithm MTDE-MKTA. In the experimental study, MTDE-MKTA outperformed ten advanced algorithms on 39 benchmark MO-MTOPs and six groups of realworld application problems.},
  archive      = {J_TEVC},
  author       = {Yanchi Li and Wenyin Gong},
  doi          = {10.1109/TEVC.2024.3353319},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {205-216},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiobjective multitask optimization with multiple knowledge types and transfer adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking derivative-free global optimization algorithms under limited dimensions and large evaluation budgets. <em>TEVC</em>, <em>29</em>(1), 187-204. (<a href='https://doi.org/10.1109/TEVC.2024.3379756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenge of selecting the most suitable optimization algorithm by presenting a comprehensive computational comparison between stochastic and deterministic methods. The complexity of algorithm selection arises from the absence of a universal algorithm and the abundance of available options. Manual selection without comprehensive studies can lead to suboptimal or incorrect results. In order to address this issue, we carefully selected 25 promising and representative state-of-the-art algorithms from both aforementioned classes. The evaluation with up to the 20 dimensions and large evaluation budgets $(10^{5}{\times }n)$ was carried out in a significantly expanded and improved version of the DIRECTGOLib v2.0 library, which included ten distinct collections of primarily continuous test functions. The evaluation covered various aspects, such as solution quality, time complexity, and function evaluation usage. The rankings were determined using statistical tests and performance profiles. When it comes to the problems and algorithms examined in this study, EA4eig, EBOwithCMAR, APGSK-IMODE, 1-DTC-GL, OQNLP, and DIRMIN stand out as superior to other derivative-free solvers in terms of solution quality. While deterministic algorithms can locate reasonable solutions with comparatively fewer function evaluations, most stochastic algorithms require more extensive evaluation budgets to deliver comparable results. However, the performance of stochastic algorithms tends to excel in more complex and higher-dimensional problems. These research findings offer valuable insights for practitioners and researchers, enabling them to tackle diverse optimization problems effectively.},
  archive      = {J_TEVC},
  author       = {Linas Stripinis and Jakub Kůdela and Remigijus Paulavičius},
  doi          = {10.1109/TEVC.2024.3379756},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {187-204},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Benchmarking derivative-free global optimization algorithms under limited dimensions and large evaluation budgets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple tasks for multiple objectives: A new multiobjective optimization method via multitask optimization. <em>TEVC</em>, <em>29</em>(1), 172-186. (<a href='https://doi.org/10.1109/TEVC.2023.3294307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling conflicting objectives and finding multiple Pareto optimal solutions are two challenging issues in solving multiobjective optimization problems (MOPs). Inspired by the efficiency of multitask optimization (MTO) in finding multiple optimal solutions of MTO problem (MTOP), we propose to treat MOP as a MTOP and solve it by using MTO. By transforming the MOP into a MTOP, not only that the difficulty in handling conflicting objectives can be avoided, but also that MTO can help efficiently find well-distributed multiple optimal solutions for MOP. With the above idea, this article proposes a new multiobjective optimization method via MTO, with the following three contributions: 1) a theorem is proposed to theoretically show the relationship between MOP and MTOP and how MOP can be transformed into a MTOP; 2) based on the theoretical analysis, a multiple tasks for multiple objectives (MTMOs) framework is proposed for solving MOP efficiently; and 3) a MTMO-based evolutionary algorithm is developed to solve MOP, together with two novel strategies. One is a target point estimation strategy for transforming the MOP into a MTOP automatically and accurately. The other is an archive-based implicit knowledge transfer strategy for efficiently transferring knowledge across multiple tasks to enhance the optimization results of multiple tasks together. The superiority of the proposed algorithm is validated in extensive experiments on 15 MOPs with objective numbers varying from 3 to 20 and with six state-of-the-art algorithms as competitors. Therefore, solving MOP and even many-objective optimization problem via MTO is a new, promising, and efficient method.},
  archive      = {J_TEVC},
  author       = {Jian-Yu Li and Zhi-Hui Zhan and Yun Li and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3294307},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {172-186},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Multiple tasks for multiple objectives: A new multiobjective optimization method via multitask optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locating drone stations for a truck-drone delivery system in continuous space. <em>TEVC</em>, <em>29</em>(1), 158-171. (<a href='https://doi.org/10.1109/TEVC.2023.3344350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck-drone delivery systems have been proposed for sustainable and economical last-mile distribution, especially in urban environments. To widen the service range, some works have recommended adding facilities, such as drone stations, considering the problem in discrete space by choosing from a predefined set. In this article, an evolutionary optimization approach to the design decision of where to locate drone stations in the continuous plane is introduced, modeled, and solved. Drone stations serve as facilities for storage, charging, and launching. A truck (or other land transport means) transports parcels to the drone stations from a depot and the drones launch from the stations and deliver the parcels to each customer. The objective is to determine the positions of the drone stations in 2-D space and establish the shortest fixed truck route from the depot through all the stations and returning to the depot. The problem is constrained by the radius of service for each drone and all customers must be served, if possible. We formulate the problem as a constrained nonlinear optimization problem and present two versions of an algorithm using particle swarm optimization (PSO) with a subordinate dynamic program. Computational results show that our approach achieves much better results than a standard commercial nonlinear solver in a similar amount of computational time for both maximizing coverage of customers and minimizing distance of the truck delivery route. A design case study concerning healthcare delivery throughout the Birmingham, Alabama (USA) metropolitan area is provided.},
  archive      = {J_TEVC},
  author       = {Lingyun Zhou and Daniel F. Silva and Alice E. Smith},
  doi          = {10.1109/TEVC.2023.3344350},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {158-171},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Locating drone stations for a truck-drone delivery system in continuous space},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding the set of nearly optimal solutions of a multiobjective optimization problem. <em>TEVC</em>, <em>29</em>(1), 145-157. (<a href='https://doi.org/10.1109/TEVC.2024.3353546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multiobjective optimization (EMO) is a highly active research field that has attracted many researchers and practitioners over the past three decades. Surprisingly, until now, the goal of almost all EMO algorithms is to compute a suitable finite size representation of the Pareto set/front of a given multiobjective optimization problem or at least a part of it. In other words, the quest is restricted to optimal solutions. In this work, we argue that the entire set of nearly optimal solutions—which includes all optimal ones—is of potential interest for the decision maker as they contain in addition to the optimal solutions alternative realizations or backup solutions. We further make a first effort to reliably compute the set of nearly optimal solutions via EMO algorithms. To this end, we first propose a new set of interest, $N_{Q,\epsilon }$ , and analyze its topology. In a next step, we propose an unbounded archiver that aims to capture $N_{Q,\epsilon }$ and analyze it with respect to monotonicity and limit behavior. After this, we discuss the related subset selection problem which comes with unbounded archivers leading to four different algorithms. Finally, we numerically investigate the behavior of the archiver and the selection strategies, and present some results when using the archiver as external archiver to three widely used multiobjective evolutionary algorithms indicating the benefit of the new approach.},
  archive      = {J_TEVC},
  author       = {Oliver Schütze and Angel E. Rodríguez-Fernandez and Carlos Segura and Carlos Hernández},
  doi          = {10.1109/TEVC.2024.3353546},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {145-157},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Finding the set of nearly optimal solutions of a multiobjective optimization problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitask optimization with lower confidence bound-based solution selection strategy. <em>TEVC</em>, <em>29</em>(1), 132-144. (<a href='https://doi.org/10.1109/TEVC.2023.3349250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitasking (EMT) is an emerging research direction within the evolutionary computation community, attempting to concurrently solve multiple optimization tasks by exploiting the underlying synergies between the tasks. Recently, numerous explicit transfer strategies have been developed for enhancing positive transfer among optimization tasks. Nevertheless, most of these methods conduct knowledge transfer by transferring the best solutions from a source task to the target task, while ignoring the proper use of information from the target task in solution selection. As a result, the transferred solutions could not well adapt to the target task, thus limiting the effectiveness of knowledge transfer across tasks. To address this issue, this article proposes a solution selection method based on the lower confidence bound (LCB) for EMT, which is designed by leveraging task-specific information of both source and target tasks. With the proposed LCB metric, a number of high-quality solutions that could be more helpful for the target task can be selected and transferred to enhance positive transfer in EMT. To verify the effectiveness of the proposed approach, the solution selection method is embedded into several existing EMT algorithms and then evaluated on the single-objective multitasking benchmarks, the multiobjective multitasking benchmark, and a real-world application. The obtained results confirmed the generality and efficacy of the proposed solution selection approach.},
  archive      = {J_TEVC},
  author       = {Zhenzhong Wang and Lulu Cao and Liang Feng and Min Jiang and Kay Chen Tan},
  doi          = {10.1109/TEVC.2023.3349250},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {132-144},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multitask optimization with lower confidence bound-based solution selection strategy},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speeding-up evolutionary algorithms to solve black-box optimization problems. <em>TEVC</em>, <em>29</em>(1), 117-131. (<a href='https://doi.org/10.1109/TEVC.2024.3352450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, one of the challenges of these algorithms is that they require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a tradeoff between the evaluation cost and its accuracy. In this article, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which the solutions are still properly ranked, and consequently, more evaluations can be computed in the same amount of time with minimal accuracy loss. An experimental section on four very different problems reveals that the proposed approach can reach the same objective value in less than half of the time in certain cases.},
  archive      = {J_TEVC},
  author       = {Judith Echevarrieta and Etor Arza and Aritz Pérez},
  doi          = {10.1109/TEVC.2024.3352450},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {117-131},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Speeding-up evolutionary algorithms to solve black-box optimization problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExTrEMO: Transfer evolutionary multiobjective optimization with proof of faster convergence. <em>TEVC</em>, <em>29</em>(1), 102-116. (<a href='https://doi.org/10.1109/TEVC.2023.3349313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer multiobjective optimization promises sample-efficient discovery of near Pareto-optimal solutions to a target task by utilizing experiential priors from related source tasks. In this article, we show that in domains where evaluation data is at a premium, e.g., in scientific and engineering disciplines involving time-consuming computer simulations or complex real-world experimentation, knowledge transfer through surrogate models can be pivotal in saving sample evaluation costs. While state-of-the-art algorithms (without transfer) typically assume budgets in the order of only a few hundred evaluations, we seek to explore how far we can get on even tighter budgets. The uniqueness of our proposed expensive transfer evolutionary multiobjective optimizer (ExTrEMO) is that it can maximally utilize external information from hundreds of source datasets, including those that may be negatively correlated with the target task. This is achieved by melding evolutionary search with factorized transfer Gaussian process surrogates, capturing varied source-target correlations in potentially decentralized computation environments. We provide a regret bound analysis for ExTrEMO that translates to a theoretical proof of increasingly faster convergence as a result of multisource transfers. The theory is experimentally verified on benchmark functions and toward accelerated design of biomedical microdevices. We release our code at https://github.com/LiuJ-2023/ExTrEMO.},
  archive      = {J_TEVC},
  author       = {Jiao Liu and Abhishek Gupta and Chinchun Ooi and Yew-Soon Ong},
  doi          = {10.1109/TEVC.2023.3349313},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {102-116},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {ExTrEMO: Transfer evolutionary multiobjective optimization with proof of faster convergence},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing with low budgets: A comparison on the black-box optimization benchmarking suite and OpenAI gym. <em>TEVC</em>, <em>29</em>(1), 91-101. (<a href='https://doi.org/10.1109/TEVC.2023.3346788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing ubiquity of machine learning (ML) has led it to enter various areas of computer science, including black-box optimization (BBO). Recent research is particularly concerned with Bayesian optimization (BO). BO-based algorithms are popular in the ML community, as they are used for hyperparameter optimization and more generally for algorithm configuration. However, their efficiency decreases as the dimensionality of the problem and the budget of evaluations increase. Meanwhile, derivative-free optimization methods have evolved independently in the optimization community. Therefore, we urge to understand whether cross-fertilization is possible between the two communities, ML and BBO, i.e., whether algorithms that are heavily used in ML also work well in BBO and vice versa. Comparative experiments often involve rather small benchmarks and show visible problems in the experimental setup, such as poor initialization of baselines, overfitting due to problem-specific setting of hyperparameters, and low statistical significance. With this article, we update and extend a comparative study presented by Hutter et al. in 2013. We compare BBO tools for ML with more classical heuristics, first on the well-known Black-Box Optimization Benchmarking test suite from the COCO environment and then on Direct Policy Search for OpenAI Gym, a reinforcement learning benchmark. Our results confirm that BO-based optimizers perform well on both benchmarks when budgets are limited, albeit with a higher computational cost, while they are often outperformed by algorithms from other families when the evaluation budget becomes larger. We also show that some algorithms from the BBO community perform surprisingly well on ML tasks.},
  archive      = {J_TEVC},
  author       = {Elena Raponi and Nathanaël Carraz Rakotonirina and Jérémy Rapin and Carola Doerr and Olivier Teytaud},
  doi          = {10.1109/TEVC.2023.3346788},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {91-101},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Optimizing with low budgets: A comparison on the black-box optimization benchmarking suite and OpenAI gym},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multiobjective optimization for large-scale portfolio selection with both random and uncertain returns. <em>TEVC</em>, <em>29</em>(1), 76-90. (<a href='https://doi.org/10.1109/TEVC.2023.3349073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Big Data, managing large-scale portfolios of thousands of securities is one of the most challenging tasks in the asset management industry. This study uses an evolutionary multiobjective technique to solve large-scale portfolio optimization problems with both long-term listed and newly listed securities. The future returns of long-term listed securities are defined as random variables whose probability distributions are estimated based on sufficient historical data, while the returns of newly listed securities are defined as uncertain variables whose uncertainty distributions are estimated based on experts’ knowledge. Our approach defines security returns as theoretically uncertain random variables and proposes a three-moment optimization model with practical trading constraints. In this study, a framework for applying arbitrary multiobjective evolutionary algorithms to portfolio optimization is established, and a novel evolutionary algorithm based on large-scale optimization techniques is developed to solve the proposed model. The experimental results show that the proposed algorithm outperforms state-of-the-art evolutionary algorithms in large-scale portfolio optimization.},
  archive      = {J_TEVC},
  author       = {Weilong Liu and Yong Zhang and Kailong Liu and Barry Quinn and Xingyu Yang and Qiao Peng},
  doi          = {10.1109/TEVC.2023.3349073},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {76-90},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary multiobjective optimization for large-scale portfolio selection with both random and uncertain returns},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted constrained optimization evolutionary algorithm by searching multiple kinds of global and local regions. <em>TEVC</em>, <em>29</em>(1), 61-75. (<a href='https://doi.org/10.1109/TEVC.2023.3346435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a surrogate-assisted evolutionary algorithm to tackle expensive inequality-constrained optimization problems through global exploration and local exploitation. The algorithm begins with an exploration stage that involves sampling in three kinds of global regions: 1) the feasible region; 2) the better-objective region; and 3) the converging region. Specifically, sampling in the uncertain feasible region mitigates issues caused by inaccurate objective surrogates. In addition, sampling in the uncertain region containing better-objective values than the current best-feasible solution reduces the risk of missing the global optimum due to inaccurate constraint surrogates. Moreover, sampling in the converging region facilitates quick convergence to the global feasible optimum. Following the exploration stage, promising feasible and infeasible solutions are further refined using local surrogate-based search strategies. To address the risk of missing the global optimum resulting from limited local region scope, the regions are adaptively extended if predicted infill points lie on the boundary. If an infill point is determined to showcase a better-objective value after accurate evaluation, a rewarding local search is performed within the local region. This exploration-exploitation process iterates until the computation budget is exhausted. Experimental results demonstrate that the proposed algorithm outperforms the selected state-of-the-art algorithms on the majority of tested problems.},
  archive      = {J_TEVC},
  author       = {Yong Zeng and Yuansheng Cheng and Jun Liu},
  doi          = {10.1109/TEVC.2023.3346435},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {61-75},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A surrogate-assisted constrained optimization evolutionary algorithm by searching multiple kinds of global and local regions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary instance selection with multiple partial adaptive classifiers for domain adaptation. <em>TEVC</em>, <em>29</em>(1), 46-60. (<a href='https://doi.org/10.1109/TEVC.2023.3346406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation reuses the knowledge learned from an existing (source) domain to classify unlabeled data from another related (target) domain. However, the two domains have different data distributions. Common approaches to bridge the two distributions are selecting/reweighting instances, building domain-invariant feature subspaces, or directly building adaptive classifiers. Recent domain adaptation work has shown that combining the above first two approaches before applying the third approach achieves better performance than performing each approach individually. However, most existing instance selection approaches are based on a ranking mechanism, ignore interdependences between instances, and require a predefined number of selected instances. Furthermore, adaptive classifiers are sensitive to their parameters which are challenging to optimize due to the lack of target labeled instances. This article introduces a novel evolutionary instance selection approach for domain adaptation. We propose a compacted representation and an efficient fitness function for particle swarm optimization to automatically determine the number of selected instances while considering the interdependencies among instances. This article also proposes to use multiple partial classifiers to build a more reliable and robust adaptive classifier. The results show that evolutionary instance selection selects better instances than the ranking approach. In cooperation with multiple partial classifiers, the proposed algorithm achieves better performance than nine state-of-the-art and well-known domain adaptation approaches.},
  archive      = {J_TEVC},
  author       = {Bach Hoai Nguyen and Bing Xue and Peter Andreae and Mengjie Zhang},
  doi          = {10.1109/TEVC.2023.3346406},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {46-60},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Evolutionary instance selection with multiple partial adaptive classifiers for domain adaptation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tractive population-assisted dual-population and two-phase evolutionary algorithm for constrained multiobjective optimization. <em>TEVC</em>, <em>29</em>(1), 31-45. (<a href='https://doi.org/10.1109/TEVC.2023.3345470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both dual-population and two-phase strategies are effective for utilizing infeasible solution information and significantly enhancing the ability of algorithms to solve constrained multiobjective optimization problems. However, most existing algorithms tend to underperform when facing problems with complex constraints. To address these issues, a constrained multiobjective evolutionary algorithm named DPTPEA, which combines dual-population and two-phase strategies, is proposed in this article. DPTPEA employs two collaborative populations [the exploitive population (expPop) and the tractive population (tracPop)] and divides the evolutionary process of the tracPop into two phases (Phase 1 and Phase 2). In Phase 1, the tracPop ignores constraints and drags the expPop across the infeasible region by sharing offspring information. In Phase 2, the tracPop adopts the epsilon-constrained method to converge toward the constrained Pareto front and to guide the expPop exploiting different feasible regions. Moreover, a dynamic cooperation strategy, a boundary point direction sampling strategy, and a dynamic environmental selection are proposed to improve the exploration ability of tracPop for solving complex problems. Comprehensive experiments on three popular test suites demonstrate that DPTPEA outperforms seven state-of-the-art algorithms on most test problems.},
  archive      = {J_TEVC},
  author       = {Shumin Xie and Kangshun Li and Wenxiang Wang and Hui Wang and Chaoda Peng and Hassan Jalil},
  doi          = {10.1109/TEVC.2023.3345470},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {31-45},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {A tractive population-assisted dual-population and two-phase evolutionary algorithm for constrained multiobjective optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge learning for evolutionary computation. <em>TEVC</em>, <em>29</em>(1), 16-30. (<a href='https://doi.org/10.1109/TEVC.2023.3278132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation (EC) is a kind of meta-heuristic algorithm that takes inspiration from natural evolution and swarm intelligence behaviors. In the EC algorithm, there is a huge amount of data generated during the evolutionary process. These data reflect the evolutionary behavior and therefore mining and utilizing these data can obtain promising knowledge for improving the effectiveness and efficiency of EC algorithms to better solve optimization problems. Considering this and inspired by the ability of human beings that acquire knowledge from the historical successful experiences of their predecessors, this article proposes a novel EC paradigm, named knowledge learning EC (KLEC). The KLEC aims to learn from historical successful experiences to obtain a knowledge library and to guide the evolutionary behaviors of individuals based on the knowledge library. The KLEC includes two main processes named learning from experiences to obtain knowledge and utilizing knowledge to guide evolution. First, KLEC maintains a knowledge library model (KLM) and updates this model by learning the successful experiences collected in every generation. Second, KLEC not only adopts the evolutionary operation but also utilizes the KLM to guide individuals for better evolution. The KLEC is a generic and effective framework, and we propose two algorithm instances of KLEC, which are knowledge learning (KL)-based differential evolution and KL-based particle swarm optimization. Also, we combine the KL framework with several state-of-the-art EC algorithms, showing that the performance of the state-of-the-art algorithms can be significantly enhanced by incorporating the KL framework.},
  archive      = {J_TEVC},
  author       = {Yi Jiang and Zhi-Hui Zhan and Kay Chen Tan and Jun Zhang},
  doi          = {10.1109/TEVC.2023.3278132},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {16-30},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Knowledge learning for evolutionary computation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multiobjective optimization with escape and expansion forces. <em>TEVC</em>, <em>29</em>(1), 2-15. (<a href='https://doi.org/10.1109/TEVC.2023.3270483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraints may scatter the Pareto optimal solutions of a constrained multiobjective optimization problem (CMOP) into multiple feasible regions. To avoid getting trapped in local optimal feasible regions or a part of the global optimal feasible regions, a constrained multiobjective evolutionary algorithm (CMOEA) should consider both the escape force and the expansion force carefully during the search process. However, most CMOEAs fail to provide these two forces effectively. As a remedy for this limitation, this article proposes a method called three-population evolutionary algorithm (TPEA). TPEA maintains three populations, termed Pop1, Pop2, and Pop3. Pop1 is a regular population, updated with a constrained NSGA-II variant. Pop2 and Pop3 are two auxiliary populations, containing the innermost and outermost nondominated infeasible solutions, respectively. The analysis reveals that these two types of nondominated infeasible solutions can contribute to the generation of escape and expansion forces, respectively. Due to these two forces, TPEA is likely to identify more global optimal feasible regions, which is crucial for constrained multiobjective optimization. Also, a mating selection strategy is developed in TPEA to coordinate the interaction among these three populations. Extensive experiments on 58 benchmark CMOPs and 35 real-world ones demonstrate that TPEA is significantly superior or comparable to six state-of-the-art CMOEAs on most test instances.},
  archive      = {J_TEVC},
  author       = {Zhi-Zhong Liu and Fan Wu and Juan Liu and Yunchuan Qin and Kenli Li},
  doi          = {10.1109/TEVC.2023.3270483},
  journal      = {IEEE Transactions on Evolutionary Computation},
  month        = {2},
  number       = {1},
  pages        = {2-15},
  shortjournal = {IEEE Trans. Evol. Comput.},
  title        = {Constrained multiobjective optimization with escape and expansion forces},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
