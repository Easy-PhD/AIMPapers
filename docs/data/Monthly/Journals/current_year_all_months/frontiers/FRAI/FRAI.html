<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FRAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frai">FRAI - 482</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Applications of AI and machine learning in finance and economics. <em>FRAI</em>, <em>8</em>, 1715929. (<a href='https://doi.org/10.3389/frai.2025.1715929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data Analytics in Finance: The enormous increase in data production has opened up huge potential in financial analysis. Today, complex patterns in the huge volumes of data can now be processed and interpreted by advanced ML algorithms to allow us to gain insights about the market sentiment, economic indicators, systemic risks, as well as other factors that a traditional analysis cannot pick up. This special issue illustrates this point through compelling contributions such as "Predicting the Bitcoin's price using AI," which explores the application of AI and ML in predicting Bitcoin price movements and design adaptive strategies. The study highlights how these technologies are becoming essential for ensuring stability and uncovering opportunities in increasingly interconnected global markets.Natural Language Processing in Economic Analysis: The use of NLP in understanding financial texts, news items, social sentiment information, and regulatory reports, is transforming the way we know the financial markets, and economic stories. This special issue presents compelling research in the field, including contributions such as the article on "Does business news sentiment matter in the energy stock market? Globalization and the proliferation of sentiment analysis in extracting short-term stock market prediction," which explains how sentiment analysis is found to be an efficient method of analysis in making short-term predictions in the stock market concerning the energy industry which is considered a volatile market. Also, the work on "NLPaugmented inflation measurement with BERT and web scraping" demonstrates how transformer-based models can effectively categorize product data and monitor inflation in close to a real time setting based on unstructured text, enhancing established metrics with novel dimensions of information.Digital Finance and Sustainability: One particularly promising area lies at the intersection of sustainable finance and artificial intelligence. Machine learning tools are increasingly being applied to assess goods recycling, evaluate environmental, social, and governance (ESG) factors, optimize green investment portfolios, and design innovative financial products that support the advancement of the Sustainable Development Goals. The articles in this special issue discuss the role of this convergence in meeting the increasing need of responsible finance by using technology to measure and manage sustainability risks and opportunities. Moreover, the research also covers some specialized fields, such as "AI revolution in insurance: bridging research and reality," that already covers all important aspects of the field (automotive, health, and property insurance) because the segment is ready to explore the field as innovative and environmental friendly.AI-Powered Financial Markets: Intelligent portfolio management systems, roboadvisors and algorithmic trading are transforming the way the financial markets are being played. The systems enable orders, digital information processing and trade execution in areas a human trader could never operate, at such velocity and magnitude, but also give consideration to complicated risk tolerances and regulative restrictions. In this selection, the entitled Explainable machine learning to predict the cost of capital addresses the most salient issue of these innovations, namely interpretability of AIdriven financial estimations, and the article Predicting financial distress in TSX-listed firms using machine learning algorithms, pertains to a more applied issue of the risk assessment. Such studies demonstrate how innovations lead to a more efficient price discovery, a better liquidity level and result in better market access but without losing transparency and regulatory compliance.Blockchain and Distributed Ledger Applications: The combination of AI and the blockchain is opening new opportunities of conducting safe, transparent, and efficient financial transactions. Artificial intelligence-based smart contracts have the potential to automate more sophisticated financial agreements, and blockchain infrastructure offers the security measures and immutability required by high-stakes financial processes. This discussion about the institutional adoption challenges, including in the form of AI and ML in banking systems, in the form of a qualitative survey of board of directors, is proposed in: Adoption of artificial intelligence and machine learning in banking systems: a qualitative survey of board of directors.The partnership of this special issue with the conferences Women in FinTech and AI 2024 highlights the issue of diversity and inclusion in promoting innovative changes in the financial technology market. As we continue to see the future of finance entirely revolve around AI and ML, these technological advancements must be developed and implemented by diverse groups, ensuring that we create systems that offer equal benefits to all stakeholders. The article Segmenting female students perceptions about Fintech using Explainable AI (winner of the Best Paper Award of 2024 edition) suggests the use of Financial Technology (Fintech) would be another potential feature in bridging the gender gap with regards to Finance and socially as well.Forecasting Business Cycle and Financial Indicators ML and AI are coming to play an important role in the future of finance and economics by providing the techniques to ensure the accuracy of forecasts, at least in the dataimpoverished settings. Here, two articles present new ways of predicting GDP in The Gambia, which involves applying sophisticated AI models. The first one, GDP prediction of The Gambia using generative adversarial networks, with the help of generative adversarial networks uses Generative Adversarial Networks (GANs) to make highly accurate GDP predictions. The second one, Transfer learning for predicting of gross domestic product growth based on remittance inflows using RNN-LSTM hybrid model: a case study of The Gambia uses remittance inflows as the key variables affecting a country in terms of its economic growth, as well as a hybrid version of RNN-LSTM model with transfer learning. Together, these studies highlight the growing importance of AIdriven, data-efficient forecasting tools in economic analysis, offering valuable support for policymaking and planning in fast-developing economiesThe contributions in this special issue underscore how AI and machine learning are not merely transforming finance and economics today, but are paving the way for a future characterized by greater financial inclusion, more efficient and transparent markets, and sustainable economic growth. Looking ahead, the continued dialogue between academia, industry, and policymakers will be vital to turning technological advances into meaningful societal progress. As the field evolves, the grand challenge will be to harness innovation responsibly-ensuring that breakthroughs in AI and FinTech are guided by ethical principles and inclusivity, so that the benefits of this new financial era are shared broadly and equitably.},
  archive      = {J_FRAI},
  author       = {Paccagnini, Alessia and Iannario, Maria and Osterrieder, Joerg and Perrotta, Adamaria and Parla, Fabio and Skaftadóttir, Hanna Kristín},
  doi          = {10.3389/frai.2025.1715929},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1715929},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Applications of AI and machine learning in finance and economics},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Artificial intelligence in visual inspection. <em>FRAI</em>, <em>8</em>, 1715198. (<a href='https://doi.org/10.3389/frai.2025.1715198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contributing articles exemplify a field that is rapidly maturing. They move beyond mere proof-of-concept demonstrations to offer sophisticated solutions for complex, real-world scenarios. A common thread is the innovative fusion of techniques-combining image enhancement with detection, leveraging hybrid model architectures, and integrating classical computer vision with deep learning-to create systems that are greater than the sum of their parts.A significant challenge in real-world visual inspection is operating under suboptimal conditions. The article by Liu et al. tackles this head-on, addressing the critical problem of drone-view object detection in low-light environments. Their proposed parallel joint encoding network is a notable innovation, co-optimizing image enhancement (using Zero-DCE++) and object detection (using a lightweight YOLOv5) within a single framework. This bidirectional approach, enhanced by specialized modules for feature modulation, significantly improves robustness against noise and insufficient illumination, as demonstrated on benchmark nighttime drone datasets. This work is vital for extending the operational window of drones in applications like nighttime surveillance, search and rescue, and traffic monitoring.Shifting from the skies to the streets, the application of AI for public safety is explored by Deshpande. His work on automatic rider helmet violation detection in Indian smart cities tackles a pressing real-world problem. The proposed two-step pipeline smartly leverages the strengths of different tools: the NVIDIA TAO toolkit with DetectNet for efficient rider and vehicle identification, and YOLOv8 for accurate helmet and license plate detection. By creating a custom dataset for a complex, real-world scenario and achieving high accuracy, this research provides a practical, deployable blueprint for automated traffic enforcement, with the potential to save lives.The most demanding domain for visual inspection is often medicine, where precision can be a matter of life and death. Three articles in this Topic address this with remarkable sophistication. First, Koshy and Anbarasi introduce HMA-Net for breast ultrasound image segmentation. Their hybrid framework masterfully combines a ConvMixer-based encoder with a ConvNeXTbased decoder, augmented by multihead attention. This architecture is specifically designed to capture both local textures and global contextual dependencies in ultrasound images, a key challenge due to their noisy and complex nature. The model's exceptional performance on standard datasets, achieving a Dice coefficient of over 99%, underscores its potential as a powerful tool for aiding the early and accurate detection of breast cancer.Similarly, Mochurad enhances medical image segmentation by integrating classical and deep learning techniques. Her approach for chest X-ray segmentation addresses the perennial challenge of low contrast and overlapping structures by preprocessing images with Sobel and Scharr edge detection filters. This simple yet highly effective strategy provides the subsequent U-Net model with enhanced boundary information, guiding it to achieve superior accuracy in segmenting the lungs, heart, and clavicles. This work demonstrates that hybrid methodologies can yield significant gains without necessarily increasing model complexity.Finally, Farhan et al. tackle the complexity of 3D brain tumor segmentation from MRI with a strategic ensemble approach. Their dual-modality method moves beyond using single MRI sequences, instead combining complementary modalities (e.g., T1ce and FLAIR) to exploit their synergistic information. Furthermore, the incorporation of Grad-CAM visualizations to create an XAI-MRI system is a crucial step forward. It not only achieves high segmentation accuracy but also provides explainable AI (XAI) heatmaps, building essential trust with clinicians by making the model's decision-making process transparent and actionable in a diagnostic context.In conclusion, the research presented in this Topic vividly illustrates that the future of visual inspection is intelligent, hybrid, and trustworthy. These studies show that the next frontier is not just about building more accurate models, but about crafting robust systems that can function in the real world, seamlessly combine diverse techniques, and, especially in medicine, explain their reasoning. The collective findings here provide a robust foundation for the next generation of AIpowered inspection systems that will enhance safety, improve healthcare outcomes, and drive industrial innovation. The journey from theoretical algorithm to practical tool is well underway, and the work showcased in this collection is leading the way.},
  archive      = {J_FRAI},
  author       = {Cao, Yanlong and Xu, Zhijie and Zeng, Wenhan and Xu, Yuanping},
  doi          = {10.3389/frai.2025.1715198},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1715198},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Artificial intelligence in visual inspection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Artificial intelligence-enhanced assessment of fundamental motor skills: Validity and reliability of the FUS test for jumping rope performance. <em>FRAI</em>, <em>8</em>, 1710897. (<a href='https://doi.org/10.3389/frai.2025.1710897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the published article, there was a mistake in the Abstract. The wrong version of the Abstract was inserted by the author.The corrected Abstract should read:Introduction: Widespread concerns about children's low fundamental motor skill (FMS) proficiency highlight the need for accurate assessment tools to support structured instruction. This study examined the validity and reliability of an AIenhanced methodology for assessing jumping rope performance within the Fundamental Motor Skills in Sport (FUS) test. Methods: A total of 236 participants (126 primary school students aged 7-14; 110 university sports students aged 20-21) completed jumping rope tasks recorded via the FUS mobile app integrated with an AI model evaluating five process-oriented performance criteria. Concurrent validity and inter-rater reliability were examined by comparing AI-generated assessments with scores from two expert evaluators. Intra-rater reliability was also assessed through reassessment of video trials after a three-week interval. Results: Results revealed excellent concurrent validity and inter-rater reliability for the AI model compared with expert ratings (ICC = 0.96; weighted kappa = 0.87). Agreement on individual criteria was similarly high (Cohen's kappa = 0.83-0.87). Expert-adjusted AI scores further improved reliability (ICC = 0.98). Intrarater reliability was also excellent, with perfect agreement for AI-generated scores (ICC = 1.00; kappa = 1.00). Conclusions: These findings demonstrate that AI-based assessment offers objective, reliable, and scalable evaluation, enhancing accuracy and efficiency of FMS assessment in education and research.The original version of this article has been updated.},
  archive      = {J_FRAI},
  author       = {Makaruk, Hubert and Porter, Jared M. and Webster, E. Kipling and Makaruk, Beata and Tomaszewski, Paweł and Nogal, Marta and Gawłowski, Daniel and Sobański, Łukasz and Molik, Bartosz and Sadowski, Jerzy},
  doi          = {10.3389/frai.2025.1710897},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1710897},
  shortjournal = {Front. Artif. Intell.},
  title        = {Correction: Artificial intelligence-enhanced assessment of fundamental motor skills: Validity and reliability of the FUS test for jumping rope performance},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Methodology for emotion-aware education based on artificial intelligence. <em>FRAI</em>, <em>8</em>, 1704389. (<a href='https://doi.org/10.3389/frai.2025.1704389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in Artificial Intelligence (AI) have opened up unprecedented horizons in educational research. The ability to recognize, interpret and respond to students' emotions presents education with a crucial challenge: to design methodologies that integrate the affective dimension as a fundamental part of the learning process. With this objective in mind, the research topic "Methodology for Emotion-Aware Education Based on Artificial Intelligence" was born. Its purpose was to bring together work that explores theoretical approaches, technological applications and empirical evidence on Educational AI linked to emotions, bridging affective computing, pedagogy, and human–computer interaction to foster more responsive and ethical emotion-aware learning environments. This research topic offers a pluralistic overview, both in terms of methods and contexts, which allows for reflection on the advances and challenges that arise when introducing AI systems capable of detecting and responding to emotional states in the educational field. The contributions range from the analysis of the social impact of scientific production to the application of deep learning models, the integration of pedagogical beliefs in the adoption of generative technologies, and the design of innovative sentiment analysis models. They also highlight ethical, methodological, and practical challenges in the field. In particular, Ni and Ni (2024) presents ECO-SAM, an innovative sentiment analysis model that combines self-attention techniques with pre-trained neural networks to improve emotion classification in texts with notable increases in accuracy. Its educational relevance lies in the potential of text analysis systems to interpret interactions on learning platforms, forums, and student social networks. The study also opens possibilities for transferring these techniques to the analysis of written work in school environments, enriching formative assessment and identifying emotional patterns in students' academic and personal writing. From another perspective, Govea et al. (2024) apply deep reinforcement learning models in hybrid learning environments, developing a system capable of detecting emotions in real time by integrating convolutional and recurrent networks. Using data from 500 students collected through cameras, microphones and biometric sensors, the authors show significant improvements in emotional detection accuracy and learning personalization. This work invites us to rethink hybrid environments as spaces where AI supports cognition and, at the same time, responds to the emotional dimension. However, it also highlights the urgent need to establish regulatory and pedagogical frameworks, so that the pursuit of efficiency does not compromise the privacy and emotional well-being of students. Cabero-Almenara et al. (2024) focuses on a decisive aspect: teacher acceptance of AI in higher education. The study, involving 425 university professors, uses the UTAUT2 model to analyze how pedagogical beliefs shape willingness to integrate generative AI tools. The results show that teachers with a constructivist orientation are more willing to incorporate these technologies than those with transmissive approaches. This emphasizes that the adoption of AI does not depend solely on technical availability, but also on the pedagogical concepts that guide teaching practice. This conclusion highlights the need for professional training programs that address the diversity of beliefs and contexts. In this sense, we see that the future of AI in education will not be played out solely in laboratories, but also in the ability of institutions to support their teachers in processes of pedagogical reflection and continuous professional development. Zhou et al. (2024) provide a novel approach by applying Item Response Theory (IRT) from a student state-aware perspective. Their SAD-IRT model incorporates parameters derived from facial expression analysis using advanced deep learning techniques, which allows for the estimation of item ability and difficulty, as well as an additional parameter linked to the cognitive-affective state of the students. The study demonstrates that this approach improves predictive capacity compared to traditional IRT models and even allows responses to be anticipated before they occur. Beyond its technical value, the article proposes a paradigm shift in educational assessment: considering students' emotions and states as part of the measurement, moving towards more personalized, sensitive and useful assessment systems to guide teaching and learning. Finally, Roda-Segarra et al. (2024) offers a pioneering study that goes beyond traditional bibliometric indicators, by examining more than 6,000 social impact records across 243 publications. They reveal that research on AI and emotions in education has a considerable impact on social media and scientific repositories, although academic impact and social visibility do not always align. This finding prompts reflection on how research reaches communities, and how social networks shape knowledge circulation. In addition, the study opens the door to reflection on the role of scientific communication in building trust around the use of AI in education, an essential aspect for building a balanced dialogue between innovation, society and schools. As we can see, the articles gathered in this research topic show that AI-mediated emotion-aware education is not a distant goal, but a field in full swing. From a social perspective, research still faces the challenge of extending its impact beyond the academic sphere and ensuring a true transfer to educational communities. From a pedagogical perspective, it is clear that teachers' beliefs influence the adoption of AI, which requires the design of training processes that are sensitive to this diversity. Finally, from a technological perspective, advanced models of deep learning and sentiment analysis open up unprecedented possibilities for creating adaptive environments capable of addressing both student performance and emotional well-being. The research published in this research topic shows that the combination of pedagogy, AI and emotion-awareness can transform the way we conceive of teaching and learning in the 21st century. The path ahead is not without ethical and practical challenges. Issues such as privacy, transparency, and fairness in personalization processes must be non-negotiable principles when using AI in an educational context. The results presented here show that this is possible, but at the same time, they reveal that there is still a long way to go in terms of academic research.},
  archive      = {J_FRAI},
  author       = {Roig-Vila, Rosabel and Cazorla, Miguel and Lallé, Sébastien},
  doi          = {10.3389/frai.2025.1704389},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1704389},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Methodology for emotion-aware education based on artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medicine for artificial intelligence: Applying a medical framework to AI anomalies. <em>FRAI</em>, <em>8</em>, 1698717. (<a href='https://doi.org/10.3389/frai.2025.1698717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Medicine for Artificial Intelligence (MAI), a clinical framework that reconceptualizes AI anomalies as diseases requiring systematic screening, differential diagnosis, treatment, and follow-up. Contemporary discourse on failures (e.g., “hallucination”) is ad hoc and fragmented across domains, impeding cumulative knowledge and reproducible management. MAI adapts medical nosology to AI by formalizing core constructs—disease, symptom, diagnosis, treatment, and classification—and mapping a clinical workflow (examination → diagnosis → intervention) onto the AI lifecycle. As a proof-of-concept, we developed DSA-1, a prototype taxonomy of 45 disorders across nine functional chapters. This approach clarifies ambiguous failure modes (e.g., distinguishing hallucination subtypes), links diagnoses to actionable interventions and evaluation metrics, and supports lifecycle practices, including triage and “AI health checks.” MAI further maps epidemiology, severity, and detectability to risk-assessment constructs, complementing top-down governance with bottom-up technical resolution. By aligning clinical methodology with AI engineering and coordinating researchers, clinicians, and regulators, MAI offers a reproducible foundation for safer, more resilient, and auditable AI systems.},
  archive      = {J_FRAI},
  author       = {Kato, Takahiro and Komura, Daisuke and Panda, Binay and Ishikawa, Shumpei},
  doi          = {10.3389/frai.2025.1698717},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1698717},
  shortjournal = {Front. Artif. Intell.},
  title        = {Medicine for artificial intelligence: Applying a medical framework to AI anomalies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the quality of AI-generated clinical notes: Validated evaluation of a large language model ambient scribe. <em>FRAI</em>, <em>8</em>, 1691499. (<a href='https://doi.org/10.3389/frai.2025.1691499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundGenerative artificial intelligence (AI) tools are increasingly being used as “ambient scribes” to generate drafts for clinical notes from patient encounters. Despite rapid adoption, few studies have systematically evaluated the quality of AI-generated documentation against physician standards using validated frameworks.ObjectiveThis study aimed to compare the quality of large language model (LLM)-generated clinical notes (“Ambient”) with physician-authored reference (“Gold”) notes across five clinical specialties using the Physician Documentation Quality Instrument (PDQI-9) as a validated framework to assess document quality.MethodsWe pooled 97 de-identified audio recordings of outpatient clinical encounters across general medicine, pediatrics, obstetrics/gynecology, orthopedics, and adult cardiology. For each encounter, clinical notes were generated using both LLM-optimized “Ambient” and blinded physician-drafted “Gold” notes, based solely on audio recording and corresponding transcripts. Two blinded specialty reviewers independently evaluated each note using the modified PDQI-9, which includes 11 criteria rated on a Likert-scale, along with binary hallucination detection. Interrater reliability was assessed using within-group interrater agreement coefficient (RWG) statistics. Paired comparisons were performed using t-tests or Mann–Whitney tests.ResultsPaired analysis of 97 clinical encounters yielded 194 notes (2 per encounter) and 388 paired reviews. Overall, high interrater agreement was observed (RWG > 0.7), with moderate concordance noted in pediatrics and cardiology. Gold notes achieved higher overall quality scores (4.25/5 vs. 4.20/5, p = 0.04), as well as superior accuracy (p = 0.05), succinctness (p < 0.001), and internal consistency (p = 0.004) compared to ambient notes. In contrast, ambient notes scored higher in thoroughness (p < 0.001) and organization (p = 0.03). Hallucinations were detected in 20% of gold notes and 31% of ambient notes (p = 0.01). Despite these limitations, reviewers overall preferred ambient notes (47% vs. 39% for gold).ConclusionLLM-generated Ambient notes demonstrated quality comparable to physician-authored notes across multiple specialties. While Ambient notes were more thorough and better organized, they were also less succinct and more prone to hallucination. The PDQI-9 provides a validated, practical framework for evaluating AI-generated clinical documentation. This quality assessment methodology can inform iterative quality optimization and support the standardization of ambient AI scribes in clinical practice.},
  archive      = {J_FRAI},
  author       = {Palm, Erin and Manikantan, Astrit and Mahal, Herprit and Belwadi, Srikanth Subramanya and Pepin, Mark E.},
  doi          = {10.3389/frai.2025.1691499},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1691499},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing the quality of AI-generated clinical notes: Validated evaluation of a large language model ambient scribe},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence adoption and corporate ESG performance: Evidence from a refined large language model. <em>FRAI</em>, <em>8</em>, 1691468. (<a href='https://doi.org/10.3389/frai.2025.1691468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe convergence of artificial intelligence (AI) and Environmental, Social, and Governance (ESG) objectives has attracted growing academic and policy interest but remains empirically underexplored due to challenges in accurately measuring firm-level AI adoption.MethodsThis study refines the LLM-based framework by employing a domain-adapted model (Qwen2.5-72B) and a granular classification scheme to distinguish genuine “Applied” AI technologies from rhetorical mentions in corporate disclosures. Using data from Chinese A-share listed firms between 2009 and 2022, we construct a credible indicator of AI adoption and examine its impact on ESG performance.Results and discussionThe results reveal a robust positive relationship between AI adoption and ESG outcomes, primarily driven by enhanced green innovation and improved internal control quality. These effects are more pronounced among large and technology-intensive firms. Consistent with the Resource-Based View and the Technology–Organization–Environment framework, our findings underscore the importance of complementary assets and absorptive capacity in realizing the sustainability potential of AI. This study provides credible evidence on how and for whom AI fosters corporate sustainability, introduces a transparent approach to measuring authentic technology adoption, and highlights the emerging “digital ESG divide” with implications for targeted policy interventions.},
  archive      = {J_FRAI},
  author       = {Shen, Lihao and Li, Zhengrong and Liang, Yongqing and Feng, Yiqiang and Zhang, Zhanyu},
  doi          = {10.3389/frai.2025.1691468},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1691468},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence adoption and corporate ESG performance: Evidence from a refined large language model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronizing LLM-based semantic knowledge bases via secure federated fine-tuning in semantic communication. <em>FRAI</em>, <em>8</em>, 1690950. (<a href='https://doi.org/10.3389/frai.2025.1690950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication (SemCom) has seen substantial growth in recent years, largely due to its potential to support future intelligent industries. This advancement hinges on the construction and synchronization of robust semantic knowledge bases (SKBs) across multiple endpoints, which can be achieved through large language models (LLMs). However, existing methods for constructing and synchronizing LLM-based SKBs often face numerous security threats, such as privacy leakage and poisoning attacks, particularly when federated fine-tuning is employed to update LLM knowledge bases. To address these challenges, we propose a novel Secure Federated Fine-Tuning (SecFFT) scheme for synchronizing LLM-based SKBs in semantic communication. First, we incorporate homomorphic encryption into SecFFT to ensure the secure synchronization of model parameters. Second, to enhance the trustworthiness of participants against poisoning attacks, we introduce a residual-based access control mechanism, where only participants with low residuals are authenticated to participate in updating the knowledge base. This mechanism is combined with a hash-based message authentication code. Third, we design a self-adaptive local updating strategy to minimize the impact of poisoned model parameters on benign participants, which is crucial for strengthening the robustness of LLM-based knowledge bases against poisoning attacks. Extensive experiments, conducted using four different datasets from the GLUE benchmark, demonstrate that SecFFT can securely synchronize distributed LLM-based SKBs while maintaining high accuracy (98.4% of the performance of the original federated LoRA), with an acceptable additional cost.},
  archive      = {J_FRAI},
  author       = {Li, Long and He, Yuanhang and Xu, Rui and Chen, Bei and Han, Boyu and Zhao, Yuanyuan and Li, Jianhua},
  doi          = {10.3389/frai.2025.1690950},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1690950},
  shortjournal = {Front. Artif. Intell.},
  title        = {Synchronizing LLM-based semantic knowledge bases via secure federated fine-tuning in semantic communication},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based detection of cognitive decline using SSWTRT: Classification performance and decision analysis. <em>FRAI</em>, <em>8</em>, 1689182. (<a href='https://doi.org/10.3389/frai.2025.1689182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionEarly detection of cognitive decline is essential for preventing dementia progression, yet conventional screening tools such as the Mini-Mental State Examination (MMSE) require trained examiners and substantial time. Building on evidence that dementia is associated with tactile and visual perceptual deficits, this study examined whether the Sound Symbolic Word Texture Recognition Test (SSWTRT)—a rapid, self-administered task using Japanese sound-symbolic words (SSWs)—could identify individuals with suspected cognitive decline through machine learning analysis.MethodsA total of 233 participants diagnosed with idiopathic normal pressure hydrocephalus (mean age = 77.1 ± 7.3 years) completed the SSWTRT, which presents 12 close-up images of material surfaces and requires selecting one of eight SSWs to describe perceived texture. Each response was scored by its concordance with normative data from healthy young adults. Using these 12 item scores, together with participants’ age and education, several machine learning classifiers were trained to predict MMSE-based groups (≤27 vs. ≥28). Model performance was evaluated via five-fold cross-validation, and interpretability was examined using SHapley Additive exPlanations (SHAP).ResultsAmong the tested models—K-Nearest Neighbors, Random Forest, and Support Vector Machine (SVM)—the balanced SVM achieved the highest performance (accuracy = 0.71, precision = 0.72, recall = 0.72, F1 = 0.72, AUC = 0.72). SHAP analysis revealed that responses to specific images, especially those depicting soft or coarse textures, strongly influenced classification outcomes. Some image items showed effects opposite to the intended scoring direction, indicating possible interference from age-related sensory decline rather than cognitive factors.DiscussionThese findings demonstrate that machine learning applied to SSWTRT responses can moderately classify individuals with potential cognitive decline using a non-invasive, resource-efficient approach. The model’s interpretability analysis highlighted key image features and response tendencies associated with cognitive status, providing guidance for test refinement. Although the current cohort consisted solely of iNPH patients, limiting generalizability, the proposed framework offers a promising foundation for scalable, language-specific cognitive screening tools.},
  archive      = {J_FRAI},
  author       = {Nozaki, Yuji and Kamohara, Chihiro and Abe, Ryota and Ieda, Taiki and Nakajima, Madoka and Sakamoto, Maki},
  doi          = {10.3389/frai.2025.1689182},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1689182},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning-based detection of cognitive decline using SSWTRT: Classification performance and decision analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive enhancements of autonomous lane keeping via advanced PER-TD3 framework. <em>FRAI</em>, <em>8</em>, 1688764. (<a href='https://doi.org/10.3389/frai.2025.1688764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of autonomous driving technology, efficient and safe lane-keeping has become one of the core issues in this field. Currently, Deep Reinforcement Learning (DRL) methods still face challenges such as low training efficiency, slow algorithm convergence, and a tendency to fall into local optima when addressing lane-keeping issues. To address these challenges, a Prioritized Experience Replay (PER) mechanism designed to adapt to the learning process of the Twin Delayed Deep Deterministic Policy Gradient (TD3) is proposed, referred to as PER-TD3, to enhance the learning efficiency and lane-keeping performance of the vehicle in this work. It adjusts the probability of a selected sample by utilizing the difference between the predicted Q value and the true Q value to assign priority to different samples. By prioritizing samples with higher errors, the algorithm can correct biases in decision-making more quickly, especially when the vehicle deviates from its lane. In addition, introducing a probabilistic sampling mechanism helps to enhance the diversity of samples, ensuring high-frequency playback of high-value experiences, and enabling vehicles to learn accurate and stable lane-keeping strategies in a shorter period. Validation experiments on the TORCS platform demonstrate that the proposed framework can effectively solve the problem of unbalanced training, which is common in DRL, enhances training sample quality, accelerates algorithm convergence, and ultimately improves driving performance while ensuring safety.},
  archive      = {J_FRAI},
  author       = {Peng, Xiting and Liang, Jinyan and Zhang, Xiaoyu and Yang, Haibo and Lei, Weimin},
  doi          = {10.3389/frai.2025.1688764},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1688764},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptive enhancements of autonomous lane keeping via advanced PER-TD3 framework},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital twin-enabled interactive cockpits for smart products management and testing. <em>FRAI</em>, <em>8</em>, 1685702. (<a href='https://doi.org/10.3389/frai.2025.1685702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitalization is influencing the design, development, and management of products across myriad industries, transforming traditional products into smart ones. Among digital technologies and models, the digital twin (DT) is regarded as an important contribution to the advancement of physical entity management. DTs are virtual representations of physical objects or systems, which are continuously updated with real-time data collected from their physical counterparts. Surprisingly, DT has yet to be applied in marketing. This study aims, accordingly, first, to introduce the DT concept and, second, to explore the human factor (human-in-the-loop) in DT. Third, elaborate on the DT cockpit (the DT’s interactive element) in the product management paradigm. Specifically, the authors use vehicles as a case study to show how interactive digital twins (IDTs) can be employed to predict and optimize vehicle performance, reliability, sustainability, and customer satisfaction. To conceptualize IDT for smart products and marketing analytics, the customer-centric Technology Acceptance Model (TAM) is employed. As this is the first study to explore DT technology in marketing, the DT concept’s main attributes are discussed, significant contributions are suggested, and avenues for future research are delineated.},
  archive      = {J_FRAI},
  author       = {Rachamim, Matti and Hornik, Jacob},
  doi          = {10.3389/frai.2025.1685702},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1685702},
  shortjournal = {Front. Artif. Intell.},
  title        = {Digital twin-enabled interactive cockpits for smart products management and testing},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swipe, click, regret: An opinion on persuasive e-commerce and consumer autonomy. <em>FRAI</em>, <em>8</em>, 1684841. (<a href='https://doi.org/10.3389/frai.2025.1684841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {1 Introduction Over the past twenty years, e-commerce has fully transitioned from being a secondary channel of shopping to an embedded aspect of daily life in the marketplace. The expansion of e-commerce is driven by technological advancements, as well as intentional choices of design that prioritize engagement and conversion. Online shopping is not a digital version of retail; instead, it provides an enduring and interactive digital environment that influences consumer decisions, shaped by behavioural research, persuasive design, and AI-enabled customization. For example, Amazon, Flipkart, and social commerce exhibit the manifestations of this evolution. "We only have 1 left!" Personal recommendations, countdown timers, and notifications are indicative of what Thaler and Sunstein (2008) refer to as recounted "choice architecture"—choice environments established specifically to steer behaviour. While these design features are marketed as convenience, they provide a space to discourage thinking and ultimately promote impulse buying, which connects to Rook's (1987) earlier view of impulsive choice. Similarly, gamification—not just in the form of gamification in the typical video-game-styled engagement with loyalty points, limited-time quests, and interactive product reveals—places even greater emphasis on the crossover of entertainment and consumption. Social commerce, along with branded influencer marketing, further integrates retail and everyday interaction, which creates the ongoing exposure to subtle nudges to spend. Behind these behaviours are teams of behavioural scientists, user experience (UX) designers, artificial intelligence (AI) engineers, and marketers all optimizing consumer micro-decisions. Thus, where does personalization transition to manipulation, and how much agency does the consumer have when attention is the currency in a marketplace? The impact extends beyond financial repercussions to psychological sequelae such as post-purchase regret, debt cycles, and compulsive buying. Mechanisms like Buy Now, Pay Later (BNPL) programs exacerbate these risks, with the separation of consideration from consequence heightening risk. This article analyses persuasive e-commerce processes via behavioural economics and consumer psychology, suggesting that contemporary design practices focus on platform profitability and disregard consumer autonomy. We offer a call for reflective design alongside regulations that reintroduce deliberation and protect consumers in online marketplaces. 2.Article types Opinion Piece 3.Manuscript Formatting 3.1 Methodology This article presents a conceptual commentary based on opinion examining how persuasion in e-commerce can shape consumer decision-making and impulsive buying behaviours. It employs a desk-based approach based on secondary sourcing from published academic literature, industry reports, and behaviours observed from platform practices. The approach taken in the article is also interdisciplinary, using perspectives from behavioural economics, consumer psychology, UX design, and AI-driven personalization, alongside regulatory perspectives. We discuss established theories, drawing from Thaler and Sunstein's Nudge Theory (2008), Rook's (1987) work on impulse buying, and Verplanken and Herabadi's (2001) Impulse Buying Tendency. We locate those theories of consumer behavior in AI-enabled digital e-commerce settings containing nudges and manipulative clearance."We do not strive for generalizability, as this is a commentary interpretation, not an empirical research paper, although we do strive for reflexivity. We share practical examples from platforms to illustrate a case for ethical and regulatory considerations to be thoughtfully considered for when examining autonomy for consumers in these designed-for contexts. 3.2 Theoretical framework: Nudging, Impulse, and Digital Choice In this commentary, we will examine the persuasive e-commerce "swipe, click, regret" loop from three angles. Thaler and Sunstein's Nudge Theory (2008) first shows how signifiers of design—scarcity alerts (limited stock), countdown timers (X hours left to buy), and recommending products (X of your friends bought)—influence consumer decision-making, moving them toward fast responses, while simultaneously allowing the consumer to feel as if they are making a choice.Second, Rook (1987) defines impulse buying as affecting the individual emotionally and considered it an action indicative of deterioration in deliberation. Finally, Verplanken and Herabadi's (2001) Impulse Buying Tendency model characterizes impulse buying as stable tendencies that can be influenced by digital platforms. Together, these theories position how personalization and gamification can enhance the construct of impulsivity. E-commerce platforms intentionally construct digital architectures that invoke behavioral heuristics and bias and turn autonomy into exploitation and convenience into regret. 3.3 Current state of persuasive e-commerce E-commerce platforms have transitioned from sites for buying to designers of situations designed to encourage impulsivity, leveraging credit for consumption. Where Rook (1987) and Thaler & Sunstein (2008) framed impulse and nudging as something one does intermittently or harmlessly, we now want to suggest that it's institutionalized. Scarcity signals, urgency messages, and AI personalization now seek to exploit the vulnerabilities of consumers (Singh etal.,2024;Hettleretal.,2024;Gupta,2025). Buy now, pay later (BNPL) is a prime example of this shift. Research suggests that BNPL use is associated with impulse buying, materialistic tendencies, and a lack of self-control in both Gen Z and Millennials (Catur Widayati et al., 2024; Vijay Amrit Raj et al., 2023). Ecological studies show that BNPL leads to overdraft and debt, particularly among low-income users (de Haan et al., 2024; O'Brien et al., 2024), suggesting that the persuasive commerce has shifted from a simple aid in habitual consumer behavior to one that takes advantage of behavioral bias. 3.4 Emotional and behavioural consequences Persuasive e-commerce can be defined as shopping simplified into a reflex: swipe, click, and regret. The pleasure of instant gratification will always run downhill to anxiety, guilt, or shame. Most consumers will not stop there and will return to the shopping platform to again engage in the act of seeking purchase to fill the relief void, thus creating a compulsive loop. Unlike traditional shopping methods, devices such as one-click checkout and Buy Now, Pay Later (BNPL) eliminate the sacred pause time for contemplation and disconnect payment from consequence. This design does not merely reduce friction or discomfort; it weaponizes friction. It's the platforms that cash in on repeated lapses of self-control while the consumers "own" the emotional toll and eventually, the long-term financial toll. Convenience in this space enables manipulation. There is a lack of consistency in how regulators respond to various forms of persuasive commerce. In the UK, Australia, and New Zealand, buy now pay later is classified as credit, meaning the laws require an affordability check and notices. The EU has established more protections with the 2021 Consumer Credit Directive and Directive 2019/2161, requiring, among other things, more transparency for online reviews and penalties for misleading practices (Đurović, 2020). Most recently, India's Consumer Protection Act 2019 is relevant as it established the Central Consumer Protection Authority and e-commerce rules prohibiting dark patterns, false scarcity cues, and manipulative defaults (Sao, 2025). These measures address the swipe, click, and regret cycle by limiting exploitative designs that elicit impulsive purchases and monetize consumer autonomy. Nonetheless, enforcement still struggles to keep pace with technological developments on the part of the platforms. AI engineers and behavioural teams are faster than regulators and can exploit divergent jurisdictions to build persuasive designs (Meškić et al., 2022; Wibowo, 2024). Unless we have a global, cohesive, and enforceable standard created based on the OECD or UNCTAD processes, this form of commerce is likely to become further entrenched—showing manipulation as convenience—leaving consumers even more vulnerable going forward. 3.6 Toward reflective design Resolving these challenges entails moving from manipulation to reflection. Ultimately, we propose three nudges: (1) pause nudges, (2) transparency nudges, and (3) opt-in personalization, which may provide a basis for reintroducing reflection without sacrificing convenience. While the bulk of evidence is identified in health and education (Mirbabaie et al., 2022; Michels et al., 2022), we also argue that e-commerce is clearly in need of something similar next. Pause nudges could intervene on a one-click buy now pay later (BNPL) signup; transparency nudges would help identify why a consumer was targeted in the first place (Gupta, 2025); and opt-in personalization would return some agency with what the customer prevails over while purchasing. Of course, these are just hypothetical examples and need trials to establish feasibility (Singh et al., 2024, Hettler et al., 2024) but considering the impact manipulatively designed products have had on consumers, we believe a reflective design process should be recognized as an ethical normative reference of some kind for addressing any regulation of product design, digital environments, or innovations. 3.7 Discussion The implications of persuasive design and AI-mediated personalization design are leading consumers to often forfeit their autonomy. In addition to making credit more accessible, buy now, pay later (BNPL) options tie debt to impulsivity, facilitating debt spirals that people are often unlikely to escape (Syam Kumar & Nayak, 2024; DeHaan et al., 2024). BNPL options are intended to normalize immediate gratification and obscure long-term costs to the point that consumers are swiping and clicking without even stopping to reflect, followed by remorse. Just like adaptive personalization can produce some level of manipulation with the absence of transparency or compulsion of a biased algorithm, it is easy for consumers to be nudged, even at a cost to the consumer, to a transaction that may benefit the platform (Aggarwal, 2024; Bitra, 2025). Indeed, regulatory regimes are now beginning to understand and generate best practices or policies to respond to any one of the weaknesses mentioned above. The EU Directive 2019/2161 effectively has a mandate for transparency with respect to online reviews and some inchoate penalties against deceptive practices. The Consumer Protection Act 2019 in India prohibits dark patterns and false urgency, in addition to empowering the Central Consumer Protection Authority to step in as needed (Đurović, 2020; Sao, 2025). OECD principles certainly similarly outline the same challenges in a global context, again pointing to fairness, accountability, and transparency (Mishra & Varshney, 2024). However, these attempts at regulation are also generally fragmented (in intentionality and lack of enforcement), and platforms consistently take advantage. They do this by being transjurisdictional (even transnational), moving much faster than the regulation or public policies that govern these platforms (Meškić et al., 2019; Wibowo, 2024). 3.8 Scope for further research Future research has many exciting possibilities to investigate the mechanisms and consequences of persuasive e-commerce. Areas of investigation could include the long-term outcomes, in terms of both psychology and finances, of artificial-intelligence-enabled personalization and digital nudging, particularly for compulsive buying and post-purchase regret. Experimental investigations might be employed to examine reflective design interventions (e.g., pause nudges, transparency nudges, opt-in personalization) to see if they support consumer agency without sacrificing usability. Demographic and socio-economic predictions might lead to studies in which researchers examine cross-cultural differences in susceptibility to persuasive tactics, while structural factors could shape consumers' behaviours on the platform. A comparative policy research agenda comparing the effects of BNPL (buy-now, pay-later) and other consumer protection laws could develop a body of evidence that enables understanding behaviours across contexts and transferability of practices to international systems. Lastly, vulnerable consumers targeted and profiled when using artificial intelligence will merit deeper analysis, especially regarding data ethics, consent, and algorithmic bias. Addressing the questions above would support developing a more robust body of evidence towards policy intervention and design of digital commerce systems that enable innovation while considering consumers' welfare.},
  archive      = {J_FRAI},
  author       = {George, Alain Monica and R, Rupa},
  doi          = {10.3389/frai.2025.1684841},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1684841},
  shortjournal = {Front. Artif. Intell.},
  title        = {Swipe, click, regret: An opinion on persuasive e-commerce and consumer autonomy},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pipeline monitoring data recovery using novel deep learning models: An engineering case study. <em>FRAI</em>, <em>8</em>, 1684018. (<a href='https://doi.org/10.3389/frai.2025.1684018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline monitoring frequently encounters missing data, leading to incomplete evaluation and hindering a comprehensive assessment of the pipeline’s structural health. To address this issue, this study proposes a novel PDO-BiGRU-GAN model for missing data recovery. The model integrates three components: the prairie dog optimization algorithm (PDO) for hyperparameter tuning, the bidirectional gated recurrent unit (BiGRU) for effective temporal feature extraction, and the generative adversarial network (GAN) for data generation and completion. A comprehensive monitoring database was established using field data from an open-source pipeline project. The contributions of individual modules to the overall performance were evaluated via hyperparameter sensitivity analysis and ablation studies. The impact of missing data ratio and the number of missing sensors on the model’s recovery performance was analyzed. In addition, the proposed model was compared with eight existing mainstream deep learning models. The results show that each component of the PDO-BiGRU-GAN significantly enhances overall performance. The model achieves strong recovery accuracy across various missing data scenarios, with the R2 consistently exceeding 0.93. Moreover, the model performs optimally when the missing data ratio is below 20/24. Compared to other models, PDO-BiGRU-GAN achieves the highest R2 and the lowest error metrics (MSE, RMSE, MAPE, MAE). In terms of computational efficiency, the model requires slightly more processing time than simpler models but is faster than more complex models. Overall, the proposed model provides a robust and scalable solution for pipeline monitoring data recovery, advancing intelligent pipeline health assessment and supporting the development of infrastructure safety management and smart monitoring technologies.},
  archive      = {J_FRAI},
  author       = {Zhao, Yong and Zhang, Xinpeng and Liu, Yanli and Mao, Xuecheng and Chen, Xi and Maimaitituerxun, Yasheng and He, Weidong},
  doi          = {10.3389/frai.2025.1684018},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1684018},
  shortjournal = {Front. Artif. Intell.},
  title        = {Pipeline monitoring data recovery using novel deep learning models: An engineering case study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase-specific kidney graft failure prediction with machine learning model. <em>FRAI</em>, <em>8</em>, 1682639. (<a href='https://doi.org/10.3389/frai.2025.1682639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAccurate prediction of kidney graft failure at different phases post-transplantation is critical for timely intervention and long-term allograft preservation. Traditional survival models offer limited capacity for dynamic, time-specific risk estimation. Machine learning (ML) approaches, with their ability to model complex patterns, present a promising alternative.MethodsThis study developed and dynamically evaluated phase-specific ML models to predict kidney graft failure across five post-transplant intervals: 0–3 months, 3–9 months, 9–15 months, 15–39 months, and 39–72 months. Clinically relevant retrospective data from deceased donor kidney transplant recipients were used for training and internal validation, with performance further confirmed on a blinded external validation cohort. Predictive performance was assessed using ROC AUC, F1 score, and G-mean.ResultsThe ML models demonstrated varying performance across time intervals. Short-term predictions in the 0–3 month and 3–9 month intervals yielded moderate accuracy (ROC AUC = 0.73 ± 0.07 and 0.72 ± 0.04, respectively). The highest predictive accuracy observed in mid-term or the 9–15-month window (ROC AUC = 0.92 ± 0.02; F1 score = 0.85 ± 0.03), followed by the 15–39-month period (ROC AUC = 0.84 ± 0.04; F1 score = 0.76 ± 0.04). Long-term prediction from 39 to 72 months was more challenging (ROC AUC = 0.70 ± 0.07; F1 score = 0.65 ± 0.06).ConclusionPhase-specific ML models offer robust predictive performance for kidney graft failure, particularly in mid-term periods, supporting their integration into dynamic post-transplant surveillance strategies. These models can aid clinicians in identifying high-risk patients and tailoring follow-up protocols to optimize long-term transplant outcomes.},
  archive      = {J_FRAI},
  author       = {Salybekov, Amankeldi A. and Wolfien, Markus and Yerkos, Ainur and Buribayev, Zholdas and Hidaka, Sumi and Kobayashi, Shuzo},
  doi          = {10.3389/frai.2025.1682639},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1682639},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phase-specific kidney graft failure prediction with machine learning model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-scale feature integration in UNet and FPN for semantic segmentation of lung nodules. <em>FRAI</em>, <em>8</em>, 1682171. (<a href='https://doi.org/10.3389/frai.2025.1682171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLung cancer remains as an important source of cancer-related mortality worldwide, demonstrating a substantial challenge to public health systems. The absence of evident symptoms in the early stages makes timely diagnosis of lung cancer challenging. Early identification and treatment will reduce the mortality rate caused by lung cancer. Abnormal growths identified as lung or pulmonary nodules can be found in the lungs and some of these could be malignant. A Computer-Aided Detection (CAD) framework can aid in identifying pulmonary nodules by investigating medical images. Automated CAD systems assist radiologists by reducing the diagnostic workload and increasing the possibility of early lung cancer identification. Finding and accurately outlining lung nodules is the specific task of lung nodule segmentation in medical image analysis.MethodsMulti-scale UNet, Feature Pyramid Network (FPN) with Linear Attention Mechanism and UNet with Asynchronous Convolution Blocks (ACB) and Channel Attention Mechanism were used to segment lung nodules. Multi-scale UNet improvises the traditional UNet architecture by incorporating multi-scale convolutional operations, which improves feature extraction and boosts segmentation accuracy. The UNet with ACB and Channel Attention Mechanism employs a cross-like receptive field that can reduce the impact of redundant information in obtaining representative characteristics. FPN with Linear Attention mechanism uses a multi-scale feature pyramid to identify nodules of different sizes and a linear attention mechanism is employed to improve feature extraction. FPN with Linear Attention mechanism attains a linear time and spatial complexity while effectively segmenting pulmonary nodules.Results and discussionEmploying the FPN with Linear Attention mechanism yielded the highest performance in the experiments. The highest results in the study using FPN with Linear Attention were achieved using GELU on the LIDC-IDRI dataset with a DSC of 71.59% and IoU of 58.57%. The smooth, probabilistic weighting of GeLU complements the model's attention mechanisms.},
  archive      = {J_FRAI},
  author       = {Prithvika, Sarah and Anbarasi, Jani and Narendra, Modigari},
  doi          = {10.3389/frai.2025.1682171},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1682171},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging multi-scale feature integration in UNet and FPN for semantic segmentation of lung nodules},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-, organoid-, and organ-on-chip-powered models to improve pre-clinical animal testing of vaccines and immunotherapeutics: Potential, progress, and challenges. <em>FRAI</em>, <em>8</em>, 1681106. (<a href='https://doi.org/10.3389/frai.2025.1681106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vaccines and immunotherapies against infectious diseases and cancers have been a great success of the medical sciences over the last century. Pre-clinical testing in animal models has played a crucial role in the development of vaccines and immunotherapies, informing subsequent clinical trials. The current practices in pre-clinical animal model research must be approved by committees with strict policies and assessments on animal experiments including the “three Rs”: (1) Replacement, which assesses the scientific justification and rationale for using a live animal in biomedical research; (2) Reduction, which determines whether the number of animals required in an experiment is adequate to achieve scientifically valid results while reducing costs; and (3) Refinement, which ascertains that any given animal procedure will cause no to minimal pain or distress. The recent initiatives by the United States NIH and FDA to reduce or phase out animal testing in biomedical research underscore a growing interest in artificial Intelligence (AI), deep learning (DL), organoid, and organ-on-chip-powered models to slash the time and cost of preclinical animal research. This review highlights the strengths, progress, and limitations of these alternative pre-clinical research approaches, with a focus on vaccine and immunotherapeutic development. While the implementation of AI- and DL-, organoid-, and organ-on-chip-powered models will certainly help accelerate pre-clinical discoveries, modeling the safety, immunogenicity, and protective efficacy of vaccines and immunotherapeutics as they occur in vivo is not yet comprehensive enough to fully replace or replicate the complexity of living systems, in both animals and humans. Thus, these models should be viewed as powerful complementary tools that combine hybrid human and artificial intelligence and must be validated through animal model testing. This review discusses the path forward and the scientific challenges that persist in investing in AI- and DL-human hybrid validation systems, regulatory reforms, and the development of interconnected platforms that bridge digital models with biological reality.},
  archive      = {J_FRAI},
  author       = {Elfatimi, Elhoucine and Lekbach, Yassir and Prakash, Swayam and Karan, Sweta and Dorotta, Joshua Christian and Garcia, America and Suoth, Beverly Sabathini and Maurya, Chhaya and Omorogieva, Etinosa Yvette and Ng, Sarah Xue Le and Liao, Emma Jane and Chow, Reilly Andrew and BenMohamed, Lbachir},
  doi          = {10.3389/frai.2025.1681106},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1681106},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence-, organoid-, and organ-on-chip-powered models to improve pre-clinical animal testing of vaccines and immunotherapeutics: Potential, progress, and challenges},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A human-centered automated machine learning agent with large language models for multimodal data management and analysis. <em>FRAI</em>, <em>8</em>, 1680845. (<a href='https://doi.org/10.3389/frai.2025.1680845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Machine Learning (AutoML) aims to streamline the end-to-end process of ML models, yet current approaches remain constrained by rigid rule-based frameworks and structured input requirements that create barriers for non-expert users. Despite advances in Large Language Models (LLMs) demonstrating capabilities in code generation and natural language understanding, their potential to improve AutoML accessibility has not been fully realized. We present an innovative LLM-driven AI agent that enables natural language interaction throughout the entire ML workflow while maintaining high performance standards, reducing the need for predefined rules and minimizing technical expertise requirements. The proposed agent implements an end-to-end ML pipeline, incorporating automatic data loading and pre-processing, task identification, neural architecture selection, hyperparameter optimization, and training automation. Additionally, we propose a novel data processing approach that leverages LLMs to automatically interpret and handle diverse data formats without requiring manual pre-processing or format conversion. Moreover, we propose an adaptive hyperparameter optimization strategy that combines LLMs' knowledge of ML best practices with dynamic performance feedback to intelligently adjust search spaces. Extensive evaluation on 10 diverse datasets spanning classification and regression tasks across multiple data modalities demonstrates that our approach consistently achieves superior performance compared to traditional rule-based AutoML frameworks. By bridging the gap between human intent and ML implementation, our approach contributes to the development of a more accessible AutoML framework.},
  archive      = {J_FRAI},
  author       = {Huang, Rong and Tao, Su},
  doi          = {10.3389/frai.2025.1680845},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1680845},
  shortjournal = {Front. Artif. Intell.},
  title        = {A human-centered automated machine learning agent with large language models for multimodal data management and analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early-fusion hybrid CNN-transformer models for multiclass ovarian tumor ultrasound classification. <em>FRAI</em>, <em>8</em>, 1679310. (<a href='https://doi.org/10.3389/frai.2025.1679310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer remains the deadliest gynecologic malignancy, and transvaginal ultrasound (TVS), the first-line test, still suffers from limited specificity and operator dependence. We introduce a learned early-fusion (joint projection) hybrid that couples EfficientNet-B7 (local descriptors) with a Swin Transformer (hierarchical global context) to classify eight ovarian tumor categories from 2D TVS. Using the public, de-identified OTU-2D dataset (n = 1,469 images across eight histopathologic classes), we conducted patient-level, stratified 5-fold cross-validation repeated 10×. To address class imbalance while preventing leakage, training used train-only oversampling, ultrasound-aware augmentations, and strong regularization; validation/test folds were never resampled. The hybrid achieved AUC 0.9904, accuracy 92.13%, sensitivity 92.38%, and specificity 98.90%, outperforming single CNN or ViT baselines. A soft ensemble of the top hybrids further improved performance to AUC 0.991, accuracy 93.3%, sensitivity 93.6%, and specificity 99.0%. Beyond discrimination, we provide deployment-oriented evaluation: isotonic calibration yielded reliable probabilities, decision-curve analysis showed net clinical benefit across 5–20% risk thresholds, entropy-based uncertainty supported confidence-based triage, and Grad-CAM highlighted clinically salient regions. All metrics are reported with 95% bootstrap confidence intervals, and the evaluation protocol preserves real-world data distributions. Taken together, this work advances ovarian ultrasound AI from accuracy-only reporting to calibrated, explainable, and uncertainty-aware decision support, offering a reproducible reference framework for multiclass ovarian ultrasound and a clear path toward clinical integration and prospective validation.},
  archive      = {J_FRAI},
  author       = {Garcia-Atutxa, Igor and Martínez-Más, José and Bueno-Crespo, Andrés and Villanueva-Flores, Francisca},
  doi          = {10.3389/frai.2025.1679310},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1679310},
  shortjournal = {Front. Artif. Intell.},
  title        = {Early-fusion hybrid CNN-transformer models for multiclass ovarian tumor ultrasound classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease. <em>FRAI</em>, <em>8</em>, 1678320. (<a href='https://doi.org/10.3389/frai.2025.1678320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundArtificial intelligence (AI) is gaining traction in healthcare, especially for patients’ education. Inflammatory bowel diseases (IBD) require continuous engagement, yet the quality of online information accessed by patients is inconsistent. ChatGPT, a generative AI model, has shown promise in medical scenarios, but its role in IBD communication needs further evaluation. The objective of this study was to assess the quality of ChatGPT-4’s responses to common patient questions about IBD, compared to those provided by experienced IBD specialists.MethodsTwenty-five frequently asked questions were collected during routine IBD outpatient visits and categorized into five themes: pregnancy/breastfeeding, diet, vaccinations, lifestyle, and medical therapy/surgery. Each question was answered by ChatGPT-4 and by two expert gastroenterologists. Responses were anonymized and evaluated by 12 physicians (six IBD experts and six non-experts) using a 5-point Likert scale across four dimensions: accuracy, reliability, comprehensibility, and actionability. Evaluators also attempted to identify whether responses were AI- or human-generated.ResultsChatGPT-4 responses received significantly higher overall scores than those from human experts (mean 4.28 vs. 4.05; p < 0.001). The best-rated scenarios were medical therapy and surgery; the diet scenario consistently received lower scores. Only 33% of AI-generated responses were correctly identified as such, indicating strong similarity to human-written answers. Both expert and non-expert evaluators rated AI responses highly, though IBD specialists gave higher ratings overall.ConclusionChatGPT-4 generated high-quality, clear, and actionable responses to IBD-related patient questions, often outperforming human experts. Its outputs were frequently indistinguishable from those written by physicians, suggesting potential as a supportive tool for patient education. Nonetheless, further studies are needed to assess real-world application and ensure appropriate use in personalized clinical care.},
  archive      = {J_FRAI},
  author       = {De Cristofaro, Elena and Zorzi, Francesca and Abreu, Maria and Colella, Alice and Blanco, Giovanna Del Vecchio and Fiorino, Gionata and Lolli, Elisabetta and Noor, Nurulamin and Lopetuso, Loris Riccardo and Pioche, Mathieu and Grimaldi, Jean and Paoluzi, Omero Alessandro and Roseira, Joana and Sena, Giorgia and Troncone, Edoardo and Calabrese, Emma and Monteleone, Giovanni and Marafini, Irene},
  doi          = {10.3389/frai.2025.1678320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1678320},
  shortjournal = {Front. Artif. Intell.},
  title        = {When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ishihara and educational images using machine learning: Toward accessible learning for colorblind individuals. <em>FRAI</em>, <em>8</em>, 1676644. (<a href='https://doi.org/10.3389/frai.2025.1676644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color Vision Deficiency (CVD) affects over 300 million individuals worldwide, with protanopia and deuteranopia being the most common subtypes, causing red–green confusion. This study leverages machine learning to (a) classify reference (considered as normal vision) and simulated protanopia and deuteranopia Ishihara plate images, (b) generate corresponding enhanced versions of these images, and (c) provide improved textbook diagrams (from NCERT books) and other pseudochromatic figures for CVD students, validated through feedback from diagnosed individuals. Tritanopia and milder forms of CVD were excluded in this study. A dataset of 1,400 Ishihara plates was processed to simulate protanopia and deuteranopia perception via standard Red Green Blue (sRGB) to long-, medium-, and short-wavelength cone (LMS) modeling. Enhanced images were generated using a daltonization function defined by the error between reference and simulated images, with enhancement strength (α) optimized to maximize contrast gain while minimizing distortion. Feature embeddings from ResNet-50, EfficientNet-B0, and DenseNet-201 were fused and reduced via PCA, followed by One-vs-All (OvA) (classifiers: linear support vector machine, logistic regression, and decision tree), random forest, gradient boosting, and neural network. Results showed optimal enhancement at α = 0.54 for deuteranopia and 0.64 for protanopia, achieving contrast gains of 69.6 and 64.3, respectively, with minimal color distortion (ΔE ≈ 4.9) and negligible clipping (<0.002). The OvA strategy achieved 99.7% accuracy, while MLP reached 100% across metrics. Surveys with 15 diagnosed students confirmed substantial perceptual improvement: recognition of previously unreadable digits and symbols increased from <20% to full visibility, with mean ratings above 4/5 for enhanced images. The OvA technique integrated with daltonization can assist in enhancing Ishihara and educational images in real time.},
  archive      = {J_FRAI},
  author       = {Prajapati, Aahan Ritesh and Goyal, Ajay},
  doi          = {10.3389/frai.2025.1676644},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1676644},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing ishihara and educational images using machine learning: Toward accessible learning for colorblind individuals},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing surface defect detection with YOLOv9: The role of advanced backbone models. <em>FRAI</em>, <em>8</em>, 1675154. (<a href='https://doi.org/10.3389/frai.2025.1675154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionYOLO algorithmic models are widely utilized for detecting surface defects, offering a robust and efficient approach to identifying various flaws and imperfections on material surfaces.MethodsIn this study, we explore the integration of six distinct backbone networks within the YOLOv9 framework to optimize surface defect detection in steel strips. Specifically, we improve the YOLOv9 framework by integrating six representative backbones-ResNet50, GhostNet, MobileNetV4, FasterNet, StarNet, and RepViT-and conduct a systematic evaluation on the NEU-DET dataset and the GC10-DET dataset. Using YOLOv9-C as the baseline, we compare these backbones in terms of detection accuracy, computational complexity, and model efficiency.ResultsResults show that RepViT achieves the best overall performance with an mAP50 of 68.8%, F1-score of 0.65, and a balanced precision-recall profile, while GhostNet offers superior computational efficiency with only 41.2 M parameters and 190.2 GFLOPs. Further validation on YOLOv5-m confirms the consistency of the results.DiscussionThe study offers practical guidance for backbone selection in surface defect detection tasks, highlighting the advantages of lightweight architectures for real-time industrial applications.},
  archive      = {J_FRAI},
  author       = {Zeng, Zhonglin and Wang, Hongyang and Yao, Chi and Dong, Zile and Cai, Shimin},
  doi          = {10.3389/frai.2025.1675154},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1675154},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimizing surface defect detection with YOLOv9: The role of advanced backbone models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twitter data emotion analysis using hadoop and metaheuristic optimized graphical neural network. <em>FRAI</em>, <em>8</em>, 1672252. (<a href='https://doi.org/10.3389/frai.2025.1672252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applies the Hive framework within the Hadoop ecosystem for sentiment classification, focusing on emotion analysis of X data. After outlining Hadoop’s core advantages in large-scale unstructured data processing, the study focuses on using a Graphical Neural Network (GNN) for sentiment categorization of Twitter comments. To address the suboptimal performance of traditional GNNs due to trial-and-error hyperparameter tuning, the study introduces the Modified Elephant Herd Optimization (MEHO) algorithm—improved version of the standard EHO, to optimize the network’s weight parameters, hyperparameters, and feature subsets, ensuring a balance between exploration and exploitation. An automated dataset construction system has also been developed to reduce manual labeling effort and ensure consistency. Preprocessing techniques, including information entropy–based phrase ranking, further enhance data quality. To capture both semantic and statistical features of tweets, feature extraction methods such as Term Frequency–Inverse Document Frequency (TF–IDF) and Bag of Words (BoW) are integrated. Experimental results demonstrate that MEHO reduces premature convergence by 40% and improves classification accuracy by 6.1% compared with the standard EHO algorithm. The automated labeling system decreases manual effort by 80%, while entropy-based preprocessing increases phrase difficulty classification accuracy by 7%. This study provides an effective solution for social media emotion analysis; future research will explore multi-modal data fusion and optimize MEHO’s convergence speed for ultra-large feature sets.},
  archive      = {J_FRAI},
  author       = {Wang, Xiaohui and Li, Yang and Chen, Fangyuan},
  doi          = {10.3389/frai.2025.1672252},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1672252},
  shortjournal = {Front. Artif. Intell.},
  title        = {Twitter data emotion analysis using hadoop and metaheuristic optimized graphical neural network},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legal logit model for predicting judicial disagreement in indian courts. <em>FRAI</em>, <em>8</em>, 1671474. (<a href='https://doi.org/10.3389/frai.2025.1671474'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Once a case reaches the Supreme Court on appeal, the justices may either affirm or reverse the judgment of the lower court. Forecasting such judicial disagreement is important not only for predicting outcomes but also for understanding the judge-specific and case-specific factors that drive these decisions. This study aimed to present the Legal Logit Model (LLM), an evolved neural network-based version of the Multinomial Logit (MNL) model. The LLM combines the interpretability of discrete choice theory with the flexibility of neural networks. Therefore, it is capable of modeling complex, non-linear interactions while preserving transparency about the influence of individual features. Utilizing features extracted from both cases and judges, the model predicts whether the Supreme Court will reverse a lower court's ruling and highlights the factors most strongly associated with disagreement. When tested on a dataset of Supreme Court opinions, the LLM achieves 80% accuracy in predicting outcomes, outperforming conventional logit and deep learning-based models. Despite the possibility of motivated reasoning in Supreme Court opinions, limiting causal interpretation, the findings show that the LLM presents an interpretable and effective predictive framework applicable to the study of judicial decision-making.},
  archive      = {J_FRAI},
  author       = {N, Sivaranjani and J, Jayabharathy},
  doi          = {10.3389/frai.2025.1671474},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1671474},
  shortjournal = {Front. Artif. Intell.},
  title        = {Legal logit model for predicting judicial disagreement in indian courts},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shape modeling of longitudinal medical images: From diffeomorphic metric mapping to deep learning. <em>FRAI</em>, <em>8</em>, 1671099. (<a href='https://doi.org/10.3389/frai.2025.1671099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Living biological tissue is a complex system, constantly growing and changing in response to external and internal stimuli. These processes lead to remarkable and intricate changes in shape. Modeling and understanding both natural and pathological (or abnormal) changes in the shape of anatomical structures is highly relevant, with applications in diagnostic, prognostic, and therapeutic healthcare. Nevertheless, modeling the longitudinal shape change of biological tissue is a non-trivial task due to its inherent nonlinear nature. In this review, we highlight several existing methodologies and tools for modeling longitudinal shape change (i.e., spatiotemporal shape modeling). These methods range from diffeomorphic metric mapping to deep-learning based approaches (e.g., autoencoders, generative networks, recurrent neural networks, etc.). We discuss the synergistic combinations of existing technologies and potential directions for future research, underscoring key deficiencies in the current research landscape.},
  archive      = {J_FRAI},
  author       = {Tay, Edwin and Tümer, Nazli and Zadpoor, Amir A.},
  doi          = {10.3389/frai.2025.1671099},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1671099},
  shortjournal = {Front. Artif. Intell.},
  title        = {Shape modeling of longitudinal medical images: From diffeomorphic metric mapping to deep learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Situational perception in distracted driving: An agentic multi-modal LLM framework. <em>FRAI</em>, <em>8</em>, 1669937. (<a href='https://doi.org/10.3389/frai.2025.1669937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDistracted driving is a significant public safety concern, causing thousands of accidents annually. While most driver assistance systems emphasize distraction detection, they fail to deliver real-time environmental perception and context-aware interventions.MethodsWe propose a large language model (LLM)-driven intervention framework that assumes distraction is pre-detected and dynamically integrates camera and GPS inputs to generate verbal driver alerts. The framework employs an agentic design, where specialized tools handle object detection, speed limits, live traffic conditions, and weather data. Structured orchestration ensures information is fused efficiently, balancing accuracy with conciseness to avoid overwhelming the driver.ResultsEvaluation of the system demonstrates high performance, with semantic intervention correctness of 85.7% and an average response latency of 1.74 s. Compared to conventional ML-based driver assistance approaches, our framework effectively synthesizes multi-modal environmental data and produces actionable alerts in real time.Discussion/conclusionThese findings highlight the potential of LLM-driven, multi-modal reasoning for distracted driving intervention. Integrating specialized agents and structured orchestration improves situational awareness, maintains concise communication, and meets real-time safety requirements. This proof-of-concept establishes a pathway for deploying intelligent, AI-driven driver support systems in safety-critical applications.},
  archive      = {J_FRAI},
  author       = {Nazar, Ahmad M. and Selim, Mohamed Y. and Gaffar, Ashraf and Qiao, Daji},
  doi          = {10.3389/frai.2025.1669937},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1669937},
  shortjournal = {Front. Artif. Intell.},
  title        = {Situational perception in distracted driving: An agentic multi-modal LLM framework},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A psycholinguistic NLP framework for forensic text analysis of deception and emotion. <em>FRAI</em>, <em>8</em>, 1669542. (<a href='https://doi.org/10.3389/frai.2025.1669542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psycholinguistics is an interdisciplinary area of research that bridges elements of linguistics with various branches of psychology. One of its goals is to identify and explain the links that exist between our psyche and the language we speak. In this research, we are expanding upon previous research that we did using several different Natural Language Processing (NLP) techniques to identify persons of interest from a scenario that was generated by a large language model (LLM). We used a different approach to this topic, which allowed us to develop a more nuanced method of reverse engineering and breaking down the psycholinguistic features of each suspect. Through the application of n-grams paired with deception, emotion, and subjectivity over time, we were able to identify and measure cues that can be used to better identify persons of interest from a larger pool of candidates. That dataset was smaller and somewhat limited in scope. We successfully identified the guilty parties from the fictional murder case using a combination of Latent Dirichlet Allocation, word vectors, and pairwise correlations. This research was larger in scope, number of potential suspects, and in the diversity of the corpus used. We were able to determine the guilty parties identified in ground truth using our methodology in this case specifically by focusing on entity to topic correlation, deception detection, and emotion analysis.},
  archive      = {J_FRAI},
  author       = {Adkins, Jonathan and Al Bataineh, Ali and Khanal, Anthos},
  doi          = {10.3389/frai.2025.1669542},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1669542},
  shortjournal = {Front. Artif. Intell.},
  title        = {A psycholinguistic NLP framework for forensic text analysis of deception and emotion},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimizing unnecessary tax audits using multi-objective hyperparameter tuning of XGBoost with focal loss. <em>FRAI</em>, <em>8</em>, 1669191. (<a href='https://doi.org/10.3389/frai.2025.1669191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a machine learning (ML) approach for detecting non-compliance in companies' tax data. The dataset, consisting of over one million records, focuses on three key targets: invalid addresses, invalid director information, and invalid founder information. The analysis prioritizes young companies (≤ 3 years old) with fewer than 100 employees, thereby improving class distributions and model effectiveness. A combination of binary classification techniques was employed, including benchmarked supervised learning models (XGBoost, Random Forest), anomaly detection methods (LOF, Isolation Forest), and semi-supervised learning using deep neural networks (DNNs) with unlabeled data. Given its computational efficiency, XGBoost was selected as the primary model. However, class imbalance persisted even among young companies, necessitating the integration of focal loss to improve classification performance. To further enhance accuracy while maintaining model interpretability, NSGA-II (Non-dominated Sorting Genetic Algorithm II) was used for multi-objective hyperparameter optimization of XGBoost. The objectives were to maximize ROC-AUC for improved predictive performance and minimize the number of trees to enhance interpretability. The optimized model achieved a ROC-AUC of 0.9417, compared to 0.9161 without optimization, demonstrating the effectiveness of this approach. Additionally, SHAP analysis provided insights into key factors influencing non-compliance, supporting explainability and aiding regulatory decision-making. This methodology contributes to fair and efficient oversight by reducing unnecessary inspections, minimizing disruptions to compliant businesses, and improving the overall effectiveness of tax compliance monitoring.},
  archive      = {J_FRAI},
  author       = {Malashin, Ivan P. and Masich, Igor S. and Tynchenko, Vadim S. and Gantimurov, Andrei P. and Nelyub, Vladimir A. and Borodulin, Aleksei S.},
  doi          = {10.3389/frai.2025.1669191},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1669191},
  shortjournal = {Front. Artif. Intell.},
  title        = {Minimizing unnecessary tax audits using multi-objective hyperparameter tuning of XGBoost with focal loss},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tracking priming-induced language recovery in aphasia with pre-trained language models. <em>FRAI</em>, <em>8</em>, 1668399. (<a href='https://doi.org/10.3389/frai.2025.1668399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the use of pre-trained language models (PLMs) in tracking priming treatment induced language recovery in aphasia. We evaluate PLM-derived surprisals, the negative log-probabilities of a word or a sequence of words calculated by a PLM given its preceding context, as a continuous and interpretable measure of treatment-induced language change. We found that surprisal scores decreased following structural priming treatment, especially in participants with more severe sentence production impairments. We also introduce a prompting-based pipeline for clinical classification tasks. It achieved promising results in classifying aphasia sentence correctness (F1 = 0.967) and detecting error categories in aphasia (accuracy = 0.846). Such use of PLMs for modeling, tracking, and automatically classifying language recovery in aphasia represents a promising deployment of GenAI in a clinical rehabilitation setting. Together, our PLM-based analyses offer a practical approach for modeling language rehabilitation, tracking not only language structure but also individual change over time in clinical contexts.Clinical trial registrationIdentifier NTC05415501.},
  archive      = {J_FRAI},
  author       = {Cong, Yan and Lee, Jiyeon},
  doi          = {10.3389/frai.2025.1668399},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1668399},
  shortjournal = {Front. Artif. Intell.},
  title        = {Tracking priming-induced language recovery in aphasia with pre-trained language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic multitask evolutionary algorithm for high-dimensional feature selection based on multi-indicator task construction and elite competition learning. <em>FRAI</em>, <em>8</em>, 1667167. (<a href='https://doi.org/10.3389/frai.2025.1667167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data often contain noisy and redundant features, posing challenges for accurate and efficient feature selection. To address this, a dynamic multitask learning framework is proposed, which integrates competitive learning and knowledge transfer within an evolutionary optimization setting. The framework begins by generating two complementary tasks through a multi-criteria strategy that combines multiple feature relevance indicators, ensuring both global comprehensiveness and local focus. These tasks are optimized in parallel using a competitive particle swarm optimization algorithm enhanced with hierarchical elite learning, where each particle learns from both winners and elite individuals to avoid premature convergence. To further improve optimization efficiency and diversity, a probabilistic elite-based knowledge transfer mechanism is introduced, allowing particles to selectively learn from elite solutions across tasks. Experimental results on 13 high-dimensional benchmark datasets demonstrate that the proposed algorithm achieves superior classification accuracy with fewer selected features compared to several state-of-the-art methods. Across 13 benchmarks, the proposed method achieves the highest accuracy on 11 out of 13 datasets and the fewest features on eight out of 13, with an average accuracy of 87.24% and an average dimensionality reduction of 96.2% (median 200 selected features), clearly validating its effectiveness in balancing exploration, exploitation, and knowledge sharing for robust feature selection.},
  archive      = {J_FRAI},
  author       = {Tie, Jinxin and Yan, Chunfang and Li, Maosong and Gong, Jianqiang and Wu, Yujie and Fang, Hailin and Li, Meng and Zhang, Weiwei and Li, Jie},
  doi          = {10.3389/frai.2025.1667167},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1667167},
  shortjournal = {Front. Artif. Intell.},
  title        = {A dynamic multitask evolutionary algorithm for high-dimensional feature selection based on multi-indicator task construction and elite competition learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyberbullying detection approaches for arabic texts: A systematic literature review. <em>FRAI</em>, <em>8</em>, 1666349. (<a href='https://doi.org/10.3389/frai.2025.1666349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive review of current methodologies, trends, and challenges in cyberbullying detection within Arabic-language contexts, with a focus on the unique linguistic and cultural factors associated with Arabic. This study reviews 35 peer-reviewed articles about the identification of cyberbullying in Arabic text. Reported accuracies across datasets and platforms range from approximately 73 to 96%, with precision frequently surpassing recall, suggesting that systems are more adept at identifying blatant bullying than at encompassing all pertinent instances. Methodologically, conventional machine learning utilizing Arabic-specific characteristics remains effective on smaller datasets, however deep neural architectures—especially CNN/BiLSTM—and transformer models like AraBERT yield superior outcomes when dialectal heterogeneity and orthographic noise are mitigated. Evaluation methodologies differ; research using a neutral class frequently indicates exaggerated accuracy, underscoring the necessity to emphasize macro-averaged F1 and per-class metrics. The evidence underscores deficiencies in dialectal representativeness, the uniformity of bullying notions compared to general abuse, and the transparency of annotation processes. Ethical and deployment considerations—privacy preservation, dialectal bias, and real-time robustness—are becoming increasingly significant. We integrate trends (models and features), standards (labeling and metrics), and future work directions, encompassing dialect-robust pretraining, cross-dataset evaluation, context-aware modeling, and human-in-the-loop frameworks. The review offers a comprehensive basis for researchers and practitioners pursuing culturally and linguistically tailored approaches to Arabic cyberbullying detection.},
  archive      = {J_FRAI},
  author       = {Allwaibed, Hooayda and Anbar, Mohammed and Manickam, Selvakumar and Bintang, Annisa},
  doi          = {10.3389/frai.2025.1666349},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1666349},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cyberbullying detection approaches for arabic texts: A systematic literature review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning enhanced acute heart failure phenotype prediction using natural language processing and random forest. <em>FRAI</em>, <em>8</em>, 1664627. (<a href='https://doi.org/10.3389/frai.2025.1664627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundHeart failure (HF), with its distinct phenotypes, poses significant public health challenges. Early diagnosis of specific HF phenotypes is crucial for timely therapeutic intervention.ObjectivesWe employed random forests to predict acute HF (AHF) phenotypes (HFrEF, HFmrEF, and HFpEF) during admission, using structured and unstructured data types while blinded to left ventricular ejection fraction (LVEF) information.MethodsWe investigated the predictive performance of integrated natural language processing (NLP) and machine learning (ML)-based models in AHF phenotype classification by random forests, leveraging clinical text and laboratory data from the MIMIC-III database. Feature selection for unstructured textual data and biochemical test data was performed using the LASSO method, with selected textual features converted into structured data using one-hot encoding. The areas under the ROC and PRC curves (AUROC and AUPRC) assessed overall performance.ResultsOur final study cohort comprised 1,192 training datasets and 513 independent validating datasets with primary data types and LVEF information available. The overall model from the training dataset showed the best performance with combined datasets (accuracy: 0.70 ± 0.03, AUROC: 0.76 ± 0.02) compared to the textual or laboratory dataset alone, which was replicated in the independent validating dataset. Our model achieved optimal performance by selecting up to 100 combined features from both textual and laboratory data. Reducing features to 20 did not substantially attenuate the overall model performance until only 10 features were selected.ConclusionOur study enhances HF phenotype classification and underscores the value of multifaceted data analysis in clinical informatics, enabling more personalized heart failure treatment. Early identification of AHF phenotypes may support timely, phenotype-specific management and inform treatment decisions.},
  archive      = {J_FRAI},
  author       = {Chang, Pei-Hsuan and Liao, Feng-Ching and Wu, Yi-Ching and Sun, Fang-Ju and Liu, Yen-Yu and Yeh, Hung-I and Hung, Chung-Lieh and Wu, Kun-Pin},
  doi          = {10.3389/frai.2025.1664627},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1664627},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning enhanced acute heart failure phenotype prediction using natural language processing and random forest},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). There are significant differences among artificial intelligence large language models when answering scientific questions. <em>FRAI</em>, <em>8</em>, 1664303. (<a href='https://doi.org/10.3389/frai.2025.1664303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study investigates the efficacy of large language models (LLMs) for generating accurate scientific responses through a comparative evaluation of five prominent free models: Claude 3.5 Sonnet, Gemini, ChatGPT 4o, Mistral Large 2, and Llama 3.1 70B.MethodsSixteen expert scientific reviewers assessed these models in terms of depth, accuracy, relevance, and clarity.ResultsClaude 3.5 Sonnet emerged as the highest scoring model, followed by Gemini, with notable variability among the other models. Additionally, retrieval-augmented generation (RAG) techniques were applied to improve LLM performance, and prompts were refined to improve answers. The results indicate that although LLMs such as Claude 3.5 Sonnet have potential for scientific tasks, other models may require more development or additional prompt engineering to reach comparable accuracy. Reviewers’ perceptions of artificial intelligence (AI) utility and trustworthiness showed a positive shift after evaluation. However, ethical concerns, particularly with respect to transparency and disclosure, remained consistent.DiscussionThe study highlights the need for structured frameworks for evaluating LLMs and ethical considerations essential for responsible AI integration in scientific research. These findings should be interpreted with caution, as the limited sample size and domain-specific focus of the exam questions restrict the generalizability of the results.},
  archive      = {J_FRAI},
  author       = {Álvarez-Martínez, Francisco Javier and Esteban, Luis and Frungillo, Lucas and Butassi, Estefanía and Zambon, Alessandro and Herranz-López, María and Aranda, Mario and Pollastro, Federica and Tixier, Anne Sylvie and Garcia-Perez, Jose V. and Arráez-Román, David and Ross, Andrew and Mena, Pedro and Edrada-Ebel, Ru Angelie and Lyng, James and Micol, Vicente and Borrás-Rocher, Fernando and Barrajón-Catalán, Enrique},
  doi          = {10.3389/frai.2025.1664303},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1664303},
  shortjournal = {Front. Artif. Intell.},
  title        = {There are significant differences among artificial intelligence large language models when answering scientific questions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WOAENet: A whale optimization-guided ensemble deep learning with soft voting for uterine cancer diagnosis based on MRI images. <em>FRAI</em>, <em>8</em>, 1664201. (<a href='https://doi.org/10.3389/frai.2025.1664201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectivesUterine cancer originates from the cells lining the uterus and can develop through abnormal cell growth, potentially leading to damage in surrounding tissues and the formation of precancerous cells. Early detection significantly improves prognosis. Despite advancements in deep learning-based diagnostic methods, challenges remain, including the dependence on expert input and the need for more accurate classification models. This study aims to address these limitations by proposing a novel and efficient methodology for diagnosing uterine cancer using an integrated deep learning pipeline optimized through a nature-inspired algorithm.MethodsThis study introduces the Whale Optimization Algorithm-based Ensemble Network (WOAENet), a deep learning pipeline that classifies uterine MRI into three classes: malignant, benign, and normal. The Whale Optimization Algorithm (WOA) is used to fine-tune the hyperparameters of three deep learning models: MobileNetV2, DenseNet121, and a lightweight vision model (LVM). Each model is trained with its optimized settings, and its outputs are combined using a Soft Voting Ensemble method that calculates the average of the predicted probabilities to arrive at the final classification.ResultsThe WOAENet framework was evaluated using a uterine cancer MRI dataset obtained from King Abdullah University Hospital. Our proposed model outperformed standard pre-trained models across several performance metrics. It achieved an accuracy of 88.57%, a specificity of 94.29%, and an F1 score of 88.54%, indicating superior performance in diagnosing uterine cancer.ConclusionWOAENet demonstrates a high level of accuracy and reliability in classifying uterine MRI images, marking a significant advancement by utilizing a novel dataset. The findings support the potential of AI-driven approaches in enhancing the diagnosis and treatment of gynecological conditions, paving the way for more accessible and accurate clinical tools.},
  archive      = {J_FRAI},
  author       = {Altal, Omar F. and Sindiani, Amer Mahmoud and Mhanna, Hamad Yahia Abu and Alhatamleh, Salem and Amin, Mohammad and Akhdar, Hanan Fawaz and Madain, Rola and Alqasem, Noor and Zayed, Faheem and Alanazi, Sitah and Sandougah, Kholoud J.},
  doi          = {10.3389/frai.2025.1664201},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1664201},
  shortjournal = {Front. Artif. Intell.},
  title        = {WOAENet: A whale optimization-guided ensemble deep learning with soft voting for uterine cancer diagnosis based on MRI images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese question and answer system for liver cancer based on knowledge graph and large language mode. <em>FRAI</em>, <em>8</em>, 1663891. (<a href='https://doi.org/10.3389/frai.2025.1663891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe liver cancer question-and-answer (Q&A) system is primarily intended to help patients access disease-related information more conveniently. However, there is currently no Q&A system specifically developed for liver cancer. Additionally, most existing Q&A systems lack real clinical data and have limited capability in understanding Chinese questions.MethodsThis paper proposes a Chinese liver cancer question-answering system based on knowledge graphs and Large Language Models (LLMs). To unify information from diverse sources, the system employs a knowledge graph to store entities and inter-entity relationships extracted from patients' clinical electronic medical records and the professional medical website xywy.com, which serves as the foundation for the system's responses. Specifically, ChatGLM3.5 is utilized to extract entity information from questions, while BERT is applied to understand users' intent. Subsequently, the system retrieves corresponding information from the knowledge graph. Finally, the retrieved information is integrated, and a natural language response is generated as the answer to the question.ResultsThe experimental results indicate that in terms of intent classification, our system achieves a precision of 92.34%, representing an improvement of 1.38% over the BERT model and 4.32% over the GEBERT model. In terms of response relevance, the system's outputs are more aligned with patients' daily speech patterns and exhibit higher relevance to the target questions.DiscussionIn conclusion, the improved method significantly enhances the usefulness and reliability of the liver cancer Q&A system.},
  archive      = {J_FRAI},
  author       = {Wu, Haoqi and Zhang, Min and Wang, Hailing and Jiang, Xiaoyan and Gao, Yongbin and Huang, Rong and Fang, Zhijun and Hu, Xiaojun and Fan, Yingfang},
  doi          = {10.3389/frai.2025.1663891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1663891},
  shortjournal = {Front. Artif. Intell.},
  title        = {A chinese question and answer system for liver cancer based on knowledge graph and large language mode},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liver cancer knowledge graph construction based on dynamic entity replacement and masking strategies RoBERTa-wwm-large-BiLSTM-CRF model with clinical chinese EMRs. <em>FRAI</em>, <em>8</em>, 1663877. (<a href='https://doi.org/10.3389/frai.2025.1663877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLiver cancer is a leading cause of cancer-related mortality worldwide, necessitating advanced tools for diagnosis and management. Knowledge graphs (KGs) are crucial for advancing smart healthcare, but existing liver cancer-specific KGs are mostly derived from literature or public databases, lacking integration with real-world clinical data [e.g., Electronic Medical Records (EMRs)], creating a critical gap. Furthermore, there is currently no publicly available KGs specifically for liver cancer, creating a significant gap in structured clinical knowledge resources.MethodsThis study proposes a novel framework to construct the first Chinese liver cancer KG from Real-World Liver Cancer Electronic Medical Records (RLC-EMRs). A new named entity recognition (NER) model, DERM-RoBERTa-wwm-large-BiLSTM-CRF was developed that uses a Dynamic Entity Replacement and Masking (DERM) strategy to address data scarcity. Knowledge fusion was performed using the TF-IDF algorithm to standardize and integrate entities from clinical records, the professional medical website www.XYWY.com, and the CCMT-2019 terminology standard.ResultsThe final constructed liver cancer KG contained 46,364 entities and 296,655 semantic relationships. The proposed NER model achieved a state-of-the-art F1 score of 68.84% on the public CMeEE-v2 dataset. On the proprietary RLC-EMRs dataset, the model demonstrated high effectiveness with a precision of 93.23%, recall of 94.69%, and an F1 score of 93.96%. In addition, a KG-based retrieval system was successfully developed to query for complications, medications, and other related information.DiscussionThe findings demonstrated the effectiveness of the proposed framework in constructing a comprehensive and clinically relevant liver cancer KG. The novel DERM-based NER model significantly improved entity extraction from complex medical texts. By successfully integrating real-world clinical data, this study addresses a critical gap in existing liver cancer-specific KGs, which are mostly derived from literature or public databases and lack integration with real-world clinical information.},
  archive      = {J_FRAI},
  author       = {Zhang, Yichi and Hu, Xiaojun and Wang, Hailing and Liu, Ke and Gao, Yongbin and Jiang, Xiaoyan and Fan, Yingfang and Fang, Zhijun},
  doi          = {10.3389/frai.2025.1663877},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1663877},
  shortjournal = {Front. Artif. Intell.},
  title        = {Liver cancer knowledge graph construction based on dynamic entity replacement and masking strategies RoBERTa-wwm-large-BiLSTM-CRF model with clinical chinese EMRs},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal texture fusion network for detecting AI-generated images. <em>FRAI</em>, <em>8</em>, 1663292. (<a href='https://doi.org/10.3389/frai.2025.1663292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of AI-generated content, detecting synthetic images has become a critical task in digital forensics and media integrity. In this paper, we propose a novel multi-modal fusion network that leverages complementary texture and content information to improve the detection of AI-generated images. Our approach integrates three input branches: the original RGB image, a local binary pattern (LBP) map to capture micro-texture irregularities, and a gray-level co-occurrence matrix (GLCM) representation to encode statistical texture dependencies. These three streams are processed in parallel through a shared-weight convolutional backbone and subsequently fused at the feature level to enhance discrimination capability. Extensive experiments conducted on benchmark datasets demonstrate that our method outperforms existing single-modality baselines and achieves strong generalization across multiple types of generative models. The proposed fusion framework offers an interpretable and efficient solution for robust and reliable detection of AI-synthesized imagery.},
  archive      = {J_FRAI},
  author       = {Yu, Haozheng and Xu, Bing},
  doi          = {10.3389/frai.2025.1663292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1663292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Multi-modal texture fusion network for detecting AI-generated images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search-optimized quantization in biomedical ontology alignment. <em>FRAI</em>, <em>8</em>, 1662984. (<a href='https://doi.org/10.3389/frai.2025.1662984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by 70%.},
  archive      = {J_FRAI},
  author       = {Bouaggad, Oussama and Grabar, Natalia},
  doi          = {10.3389/frai.2025.1662984},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662984},
  shortjournal = {Front. Artif. Intell.},
  title        = {Search-optimized quantization in biomedical ontology alignment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning for cognitive impairment detection using speech data. <em>FRAI</em>, <em>8</em>, 1662859. (<a href='https://doi.org/10.3389/frai.2025.1662859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn Alzheimer’s disease (AD) research, clinical, neuroimaging, genetic, and biomarker data are vital for advancing its understanding and treatment. However, privacy concerns and limited datasets complicate data sharing. Federated learning (FL) offers a solution by enabling collaborative research while preserving data privacy.MethodsThis study analyzed data from patients assessed at the Memory Unit of the Ace Alzheimer Center Barcelona who completed a standardized digital speech protocol. Acoustic features extracted from these recordings were used to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals. The aim was to evaluate how data heterogeneity impacted the FL model performance across three scenarios: (1) equal contributions and class ratios, (2) unequal contributions, and (3) imbalanced class ratios. In each scenario, the performance of local models trained using an MLP feed-forward neural network on institutional data was analyzed and compared to a global model created by aggregating these local models using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA).ResultsThe cohort included 2,239 participants: 221 CU individuals (mean age 66.8, 64.7% female) and 2,018 CI subjects, comprising 1,219 with mild cognitive impairment (mean age 74.3, 61.9% female) and 799 with mild AD dementia (mean age 80.8, 64.8% female). In scenarios 1 and 3, FL provided modest gains in accuracy and AUC. In scenario 2, FL markedly improved performance for the smaller dataset (balanced accuracy rising from 0.51 to 0.80) while preserving 0.86 accuracy in the larger dataset, highlighting scalability across heterogeneous conditions.ConclusionThese findings demonstrate the potential of FL to enable collaborative modeling of speech-based biomarkers for cognitive impairment detection, even under conditions of data imbalance and institutional disparity. This work highlights FL as a scalable and privacy-preserving approach for advancing digital health research in neurodegenerative diseases.},
  archive      = {J_FRAI},
  author       = {Blazquez-Folch, Josep and Limones Andrade, María and Calm, Berta and Auñón García, Juan Miguel and Alegret, Montserrat and Muñoz, Nathalia and Cano, Amanda and Fernández, Victoria and García-Gutiérrez, Fernando and De Rojas, Itziar and García-González, Pablo and Olivé, Clàudia and Puerta, Raquel and Capdevila-Bayo, María and Muñoz-Morales, Álvaro and Bayón-Buján, Paula and Miguel, Andrea and Montrreal, Laura and Espinosa, Ana and Sanz-Cartagena, Pilar and Rosende-Roca, Maitee and Zaldua, Carla and Gabirondo, Peru and Cantero-Fortiz, Yahveth and Gurruchaga, Miren Jone and Tarraga, Lluis and Boada, Mercè and Ruiz, Agustín and Marquié, Marta and Valero, Sergi},
  doi          = {10.3389/frai.2025.1662859},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662859},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated learning for cognitive impairment detection using speech data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mediating role of digital ethics on the impact of artificial intelligence usage and public relations practices: Evidence from malaysia. <em>FRAI</em>, <em>8</em>, 1662219. (<a href='https://doi.org/10.3389/frai.2025.1662219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Artificial Intelligence (AI) has led to great advancement in the field of Public Relations (PR); however, the organisations are still unsure about the ethical consequences of this new technology. This study aims to examine the effect of AI usage on PR practices by examining the mediating role of Digital Ethics. The study used a cross-sectional quantitative method. The data was collected through structured survey questionnaires from PR practitioners in a Malaysian setting. Mediation analysis was run using the Statistical Package for Social Sciences (SPSS) and PROCESS macro-Model 4. The results showcased that AI usage has a significant impact on PR practices, while Digital Ethics further mediates the relationship, suggesting that AI, when employed ethically, assists in efficient PR practices. This work fills a critical gap in the literature regarding the role of Digital Ethics in the landscape of AI usage for performing PR activities. The study extends the Excellence Theory scholarship into an AI-driven ethical context. The findings offer a crucial incentive for organisations to introduce robust ethical guidelines into their AI-driven PR strategies. The study suggests that by being aware and readily employing Digital Ethical practices, PR practitioners can not only increase their productivity but also safeguard their organisations against the potential ethical threats posed by AI.},
  archive      = {J_FRAI},
  author       = {Khalid, Umaima and Ahmad, Mokhtarrudin and Chan, Tak Jie and Pradana, Mahir and Singh, Satnam},
  doi          = {10.3389/frai.2025.1662219},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662219},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mediating role of digital ethics on the impact of artificial intelligence usage and public relations practices: Evidence from malaysia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting food prices in kenya using machine learning: A hybrid model approach with XGBoost and gradient boosting. <em>FRAI</em>, <em>8</em>, 1661989. (<a href='https://doi.org/10.3389/frai.2025.1661989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionFood price volatility continues to be a significant concern in Kenya's economic development, posing challenges to the country's economic stability.MethodologyThis study examines the application of machine learning methods, employing a hybrid approach that combines XGBoost and gradient boosting, to predict food prices in Kenya. The food prices data from the World Food Programme, covering the period from January 2006 to September 2024, as well as currency exchange rates data from the Central Bank of Kenya in US dollars (USD) and inflation rates data, were collated and preprocessed to be ready for analytics and machine learning. The augmented data were preprocessed and transformed, then used to train XGBoost, gradient boosting, LightGBM, decision tree, random forest, and linear regression. A hybrid model was then developed by stacking XGBoost and gradient boosting as the base models, with linear regression serving as the meta-model used to combine their predictions.ResultsThis model was then tuned using the hyperparameter random search method, achieving a mean absolute error of 0.1050, a mean squared error of 0.0261, a root mean square error of 0.1615, and an R-squared value of 0.9940, thereby surpassing the performance of all standalone models. We then applied cross-validation using 5-fold cross-validation and Diebold-Mariano tests to check for model overfitting and to perform model superiority analysis. Feature importance analysis using SHapley Additive exPlanations (SHAP) revealed that intuitive features influencing food prices are unit quantity, price type, commodity, and currency, while geographical factors such as county have a lesser impact. Finally, the model and its important features were saved as pickle files to facilitate the deployment of the model on a web application for food price predictions.DiscussionThis data-driven decision support system can help policymakers and agricultural stakeholders (such as the Kenyan government) plan for future trends in food prices, potentially helping to prevent food insecurity in Kenya.},
  archive      = {J_FRAI},
  author       = {Ogol, Benard O. and Omondi, Evans and Olukuru, John and Muriithi, Betsy and Senagi, Kennedy},
  doi          = {10.3389/frai.2025.1661989},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1661989},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting food prices in kenya using machine learning: A hybrid model approach with XGBoost and gradient boosting},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study on the impact of digital countryside construction on fostering sports industry development: Based on the moderating role of market-oriented factor allocation and the mediating role of rural consumption upgrade. <em>FRAI</em>, <em>8</em>, 1660947. (<a href='https://doi.org/10.3389/frai.2025.1660947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAgainst the backdrop of China’s coordinated advancement of the “Digital China” and “Rural Revitalization” development strategies, digital countryside construction has emerged as a new opportunity for the sports industry.MethodsBased on panel data from 21 provinces in China from 2015 to 2023, this study employs fixed-panel models, moderation effects models, and mediation effects models to examine the relationship between digital countryside construction and the sports industry, as well as its underlying mechanisms.ResultsDigital countryside construction exerts a significant positive promotion on the sports industry; Market-oriented factor allocation exerts a significant positive moderating influence on the impact of digital countryside construction on the sports industry; Rural consumption upgrade plays a significant positive mediating role in the influence of digital countryside construction on the sports industry. In terms of regional heterogeneity, the eastern region exhibits a significant promoting effect, while the central region shows a suppressing effect that is not statistically significant. The western region also demonstrates a promoting effect, though it is not statistically significant.DiscussionImplementing region-specific development strategies, tailored to local conditions, is of paramount significance for achieving the maximal policy benefits of digital countryside construction. This should be accomplished by deepening market-oriented reforms and enhancing digital infrastructure to foster balanced and high-quality development of the sports industry in both urban and rural areas.},
  archive      = {J_FRAI},
  author       = {Zhang, Xinxin and Wang, Sen and Li, Tianpei and Sun, Shuangcheng},
  doi          = {10.3389/frai.2025.1660947},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660947},
  shortjournal = {Front. Artif. Intell.},
  title        = {Study on the impact of digital countryside construction on fostering sports industry development: Based on the moderating role of market-oriented factor allocation and the mediating role of rural consumption upgrade},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blueprint2Code: A multi-agent pipeline for reliable code generation via blueprint planning and repair. <em>FRAI</em>, <em>8</em>, 1660912. (<a href='https://doi.org/10.3389/frai.2025.1660912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated programming has become a powerful tool for solving real-world problems. Code generation, in particular, plays a key role in improving developer productivity and reducing the entry barrier to software development. Recent advances in large language models (LLMs) have significantly improved program synthesis, enabling high-quality code generation from natural language. However, LLMs still struggle with complex tasks, especially in understanding problem intent, conducting multi-step reasoning, and producing code that passes all test cases. As task difficulty increases, existing models often fail to devise complete and reliable generation strategies, leading to reduced accuracy and robustness. To address these limitations, we propose Blueprint2Code, an innovative multi-agent framework for code generation. It emulates the human programming workflow through the coordinated interaction of four agents—Previewing, Blueprint, Coding, and Debugging—forming a closed-loop system from task comprehension to planning, implementation, and iterative refinement. Compared to existing methods, Blueprint2Code shows superior performance on complex programming tasks. Extensive experiments on benchmark datasets—HumanEval, MBPP, their extended versions (HumanEval-ET, MBPP-ET), and the APPS competition dataset—demonstrated its effectiveness, achieving strong pass@1 results: HumanEval 96.3%, MBPP 88.4%, HumanEval-ET 86.5%, MBPP-ET 59.4%, and APPS 24.6%. The related code is available at https://github.com/MKH99918/Blueprint2Code.},
  archive      = {J_FRAI},
  author       = {Mao, Kehao and Hu, Baokun and Lin, Ruixin and Li, Zewen and Lu, Guanyu and Zhang, Zhengyu},
  doi          = {10.3389/frai.2025.1660912},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660912},
  shortjournal = {Front. Artif. Intell.},
  title        = {Blueprint2Code: A multi-agent pipeline for reliable code generation via blueprint planning and repair},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of patients with early-stage multiple sclerosis and healthy controls using kinematic analysis during a dual-task. <em>FRAI</em>, <em>8</em>, 1660801. (<a href='https://doi.org/10.3389/frai.2025.1660801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple sclerosis (MS) is the disabling neurological disease that currently most affects young people. Changes in gait significantly impact the functionality and independence of these individuals. This study aimed to differentiate between patients in the early stages of MS and healthy controls using machine learning in angular gait variables. This cross-sectional observational study included 38 participants, 19 with MS and 19 in the healthy control group (without neurological or orthopedic diseases). For movement analysis, a three-dimensional gait examination was conducted on patients with EDSS (Expanded Disability Status Scale) scores below 3.5 and healthy volunteers during normal gait and while performing a dual task (walking and performing a working memory task). An elastic net regression model was utilized to classify patients and healthy controls based on the kinematic variables. Our model achieved an AUC (area under the curve) of the ROC plot = 0.77 ± 0.21 using the average, an AUC of 0.94 ± 0.09 using the average and standard deviation, and AUC = 0.95 ± 0.09 when incorporating only the standard deviation of kinematic variables. The study suggests that utilizing angular gait analysis with machine learning methods is an effective approach to categorizing individuals with early-stage multiple sclerosis and healthy controls.},
  archive      = {J_FRAI},
  author       = {Garotti, José Eduardo Rosseto and Speciali, Danielli Souza and de Azevedo Neto, Raymundo Machado and Aguiar, Patricia Maria de Carvalho and Thomaz, Rodrigo Barbosa and Sowmy, Tiago Abrão Setrak and Brech, Guilherme Carlos and Bazán, Paulo Rodrigo and Kozasa, Elisa Harumi},
  doi          = {10.3389/frai.2025.1660801},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660801},
  shortjournal = {Front. Artif. Intell.},
  title        = {Classification of patients with early-stage multiple sclerosis and healthy controls using kinematic analysis during a dual-task},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable person–job recommendations: Challenges, approaches, and comparative analysis. <em>FRAI</em>, <em>8</em>, 1660548. (<a href='https://doi.org/10.3389/frai.2025.1660548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs person–job recommendation systems (PJRS) increasingly mediate hiring decisions, concerns over their “black box” opacity have sparked demand for explainable AI (XAI) solutions.MethodsThis systematic review examines 85 studies on explainable PJRS methods published between 2019 and August 2025, selected from 150 screened articles across Google Scholar, Web of Science, and CNKI, following PRISMA 2020 guidelines.ResultsGuided by a PICOS-formulated review question, we categorize explainability techniques into three layers—data (e.g., feature attribution, causal diagrams), model (e.g., attention mechanisms, knowledge graphs), and output (e.g., SHAP, counterfactuals)—and summarize their objectives, trade-offs, and practical applications. We further synthesize these into an integrated end-to-end framework that addresses opacity across layers and supports traceable recommendations. Quantitative benchmarking of six representative methods (e.g., LIME, attention-based, KG-GNN) reveals performance–explainability trade-offs, with counterfactual approaches achieving the highest Explainability-Performance (E‑P) score (0.95).DiscussionThis review provides a taxonomy, cross-layer framework, and comparative evidence to inform the design of transparent and trustworthy PJRS systems. Future directions include multimodal causal inference, feedback-driven adaptation, and efficient explainability tools.},
  archive      = {J_FRAI},
  author       = {Tang, Fang and Zhu, Renqi and Yao, Feng and Wang, Junzhi and Luo, Lailong and Li, Bo},
  doi          = {10.3389/frai.2025.1660548},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660548},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable person–job recommendations: Challenges, approaches, and comparative analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data in financial risk management: Evidence, advances, and open questions: A systematic review. <em>FRAI</em>, <em>8</em>, 1658375. (<a href='https://doi.org/10.3389/frai.2025.1658375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe intersection of big data analytics and financial risk management has spurred significant methodological innovation and organizational change. Despite growing research activity, the literature remains fragmented, with notable gaps in comparative effectiveness, cross-sectoral applicability, and the use of non-traditional data sources.MethodsFollowing the PRISMA 2020 protocol, a systematic review was conducted on 21 peer-reviewed studies published between 2016 and June 2025. The review evaluated the methodological diversity and effectiveness of machine learning and hybrid approaches in financial risk management.ResultsThe analysis mapped the relative strengths and limitations of neural networks, ensemble learning, fuzzy logic, and hybrid optimization across credit, fraud, systemic, and operational risk. Advanced machine learning techniques consistently demonstrated strong predictive accuracy, yet real-world deployment remained geographically concentrated, primarily in Chinese and European banking and fintech sectors. Applications involving alternative and unstructured data, such as IoT signals and behavioral analytics, were largely experimental and faced both technical and governance challenges.Discussion/conclusionThe findings underscore the scarcity of systematic benchmarking across risk types and organizational contexts, as well as the limited attention to explainability in current implementations. This review identifies an urgent need for comparative, cross-jurisdictional studies, stronger field validation, and open science practices to bridge the gap between technical advances and their operational impact in big data–enabled financial risk management.},
  archive      = {J_FRAI},
  author       = {Theodorakopoulos, Leonidas and Theodoropoulou, Alexandra and Bakalis, Aristeidis},
  doi          = {10.3389/frai.2025.1658375},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1658375},
  shortjournal = {Front. Artif. Intell.},
  title        = {Big data in financial risk management: Evidence, advances, and open questions: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt engineering for accurate statistical reasoning with large language models in medical research. <em>FRAI</em>, <em>8</em>, 1658316. (<a href='https://doi.org/10.3389/frai.2025.1658316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe integration of generative artificial intelligence (AI), particularly large language models (LLMs), into medical statistics offers transformative potential. However, it also introduces risks of erroneous responses, especially in tasks requiring statistical rigor.ObjectiveTo evaluate the effectiveness of various prompt engineering strategies in guiding LLMs toward accurate and interpretable statistical reasoning in biomedical research.MethodsFour prompting strategies: zero-shot, explicit instruction, chain-of-thought, and hybrid were assessed using artificial datasets involving descriptive and inferential statistical tasks. Outputs from GPT-4.1 and Claude 3.7 Sonnet were evaluated using Microsoft Copilot as an LLM-as-a-judge, with human oversight.ResultsZero-shot prompting was sufficient for basic descriptive tasks but failed in inferential contexts due to lack of assumption checking. Hybrid prompting, which combines explicit instructions, reasoning scaffolds, and format constraints, consistently produced the most accurate and interpretable results. Evaluation scores across four criteria–assumption checking, test selection, output completeness, and interpretive quality confirmed the superiority of structured prompts.ConclusionPrompt design is a critical determinant of output quality in AI-assisted statistical analysis. Hybrid prompting strategies should be adopted as best practice in medical research to ensure methodological rigor and reproducibility. Additional testing with newer models, including Claude 4 Sonnet, Claude 4 Opus, o3 mini, and o4 mini, confirmed the consistency of results, supporting the generalizability of findings across both Anthropic and OpenAI model families. This study highlights prompt engineering as a core competency in AI-assisted medical research and calls for the development of standardized prompt templates, evaluation rubrics, and further studies across diverse statistical domains to support robust and reproducible scientific inquiry.},
  archive      = {J_FRAI},
  author       = {Vilakati, Sifiso},
  doi          = {10.3389/frai.2025.1658316},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1658316},
  shortjournal = {Front. Artif. Intell.},
  title        = {Prompt engineering for accurate statistical reasoning with large language models in medical research},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of a diagnostic model for temporal lobe epilepsy using interpretable deep learning: Disease-associated markers identification. <em>FRAI</em>, <em>8</em>, 1655338. (<a href='https://doi.org/10.3389/frai.2025.1655338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTemporal lobe epilepsy (TLE) represents a significant neurological disorder with complex genetic underpinnings. This study aimed to develop an interpretable deep learning diagnostic model for TLE and identify disease-associated markers.MethodsUsing RNA-seq and microarray data from 287 samples collected from eight GEO datasets, we constructed multiple machine learning algorithms including Deep Neural Networks (DNN), Extreme Gradient Boosting (XGBoost), Random Forest (RF), Logistic Regression (LR), and K-Nearest Neighbors (KNN) to distinguish TLE from normal. SHapley Additive exPlanations (SHAP) and Kolmogorov-Arnold Networks (KAN) were employed to interpret the model and identify key genes associated with TLE pathogenesis.ResultsAfter comparative analysis, a Deep Neural Network (DNN) model with 10 optimized genetic features achieved perfect diagnostic performance (AUC = 1.000, accuracy = 1.000). SHAP interpretation identified DEPDC5, STXBP1, GABRG2, SLC2A1, and LGI1 as the most significant TLE-associated genes. The KAN model revealed complex nonlinear relationships between these genes and TLE status, providing mathematical expressions that capture their contributions. To facilitate clinical application, we developed an online diagnostic platform that delivers interpretable predictions based on gene expression values.DiscussionThis study advances our understanding of TLE pathogenesis and provides a transparent, interpretable diagnostic model, which combines with traditional diagnostic methods may significantly improve the accuracy of TLE diagnosis, serving as a supplementary tool for clinical assessment.},
  archive      = {J_FRAI},
  author       = {Wang, Tianyu and Wang, Aowen and Zhu, Minwei and Jiang, Wenhao and Li, Mingrui and Yan, Shi and Shu, Yifu and Yu, Shengkun and Lin, Zhiguo and Han, Zhibin},
  doi          = {10.3389/frai.2025.1655338},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1655338},
  shortjournal = {Front. Artif. Intell.},
  title        = {Construction of a diagnostic model for temporal lobe epilepsy using interpretable deep learning: Disease-associated markers identification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial creativity: From predictive AI to generative system 3. <em>FRAI</em>, <em>8</em>, 1654716. (<a href='https://doi.org/10.3389/frai.2025.1654716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models generate fluent text yet often fail to sustain novelty, task relevance, and diversity across extended contexts. We argue this shortfall persists because current systems implement only fragments of a tri-process loop that supports human creativity: spontaneous ideation in the default-mode network (DMN; broadly System 1–like), goal-directed evaluation in the central-executive network (CEN; broadly System 2–like), and a metacognitive integrator—System 3—that, via neuromodulatory gain control, shifts between exploration and focused control. We introduce Generative System 3 (GS-3), an architecture-agnostic design pattern with three roles: a high-entropy generator, a learned critic, and an adaptive gain controller. Beyond “pure prediction” and simple “reflective prompting,” GS-3 identifies the missing pieces for Artificial Creativity: an internal evaluator, endogenous control over sampling entropy, and adaptive priors maintained across extended contexts. This conceptual analysis (i) formalizes novelty, usefulness, and diversity with operational definitions; (ii) develops multiple gain-update policies (exponential, linear, logistic) with stability constraints and sensitivity expectations; (iii) derives falsifiable behavioral indices—associative-distance density, analytic-verification ratio, and convergence latency—with pass–fail criteria; and (iv) provides a proof-of-concept blueprint and evaluation protocol (tasks, metrics, ablations, reproducibility kit). We position GS-3 relative to computational-creativity and co-creative frameworks, and delineate where brain–model analogies are functional rather than literal. Ethical guidance addresses bias, cultural homogenization, and reward gaming of proxy objectives (often termed “dopamine hacking”) through plural critics, transparent logging, and outcome-tied entropy caps. The result is a testable roadmap for transitioning from regulated prediction to genuinely creative generative systems.},
  archive      = {J_FRAI},
  author       = {Chávez-Autor, Juan Carlos},
  doi          = {10.3389/frai.2025.1654716},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1654716},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial creativity: From predictive AI to generative system 3},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of demographic bias in retinal age prediction machine learning models. <em>FRAI</em>, <em>8</em>, 1653153. (<a href='https://doi.org/10.3389/frai.2025.1653153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retinal age gap, defined as the difference between the predicted retinal age and chronological age, is an emerging biomarker for many eye conditions and even non-ocular diseases. Machine learning (ML) models are commonly used for retinal age prediction. However, biases in ML models may lead to unfair predictions for some demographic groups, potentially exacerbating health disparities. This retrospective cross-sectional study evaluated demographic biases related to sex and ethnicity in retinal age prediction models using retinal imaging data (color fundus photography [CFP], optical coherence tomography [OCT], and combined CFP + OCT) from 9,668 healthy individuals (mean age 56.8 years; 52% female) in the UK Biobank. The RETFound foundation model was fine-tuned to predict retinal age, and bias was assessed by comparing mean absolute error (MAE) and retinal age gaps across demographic groups. The combined CFP + OCT model achieved the lowest MAE (3.01 years), outperforming CFP-only (3.40 years) and OCT-only (4.37 years) models. Significant sex differences were observed only in the CFP model (p < 0.001), while significant ethnicity differences appeared only in the OCT model (p < 0.001). No significant sex/ethnicity differences were observed in the combined model. These results demonstrate that retinal age prediction models can exhibit biases, and that these biases, along with model accuracy, are influenced by the choice of imaging modality (CFP, OCT, or combined). Identifying and addressing sources of bias is essential for safe and reliable clinical implementation. Our results emphasize the importance of comprehensive bias assessments and prospective validation, ensuring that advances in machine learning and artificial intelligence benefit all patient populations.},
  archive      = {J_FRAI},
  author       = {Nielsen, Christopher and Stanley, Emma A. M. and Wilms, Matthias and Forkert, Nils D.},
  doi          = {10.3389/frai.2025.1653153},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1653153},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessment of demographic bias in retinal age prediction machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security. <em>FRAI</em>, <em>8</em>, 1651516. (<a href='https://doi.org/10.3389/frai.2025.1651516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs the number of Internet of Things (IoT) devices grows quickly, cyber threats are becoming more complex and increasingly sophisticated; thus, we need a more robust network security solutions. Traditional deep learning approaches often suffer in identifying effectively anomalies in IoT network. To tackle this evolving challenge, this research proposes a hybrid architecture of Neural Network (NN) models that combine Recurrent-NN (RNN) and Spiking-NN (SNN), referred to as HRSNN, to improve IoT the security.MethodsThe proposed HRSNN technique has five steps: preprocessing data, extracting features, equalization classes, features optimization and classification. Data processing step makes sure that input data is accurate and consistent and by employing normalization and the removal of outliers’ techniques. Feature extraction makes use of the RNN part to automatically detect abnormal patterns and high-level features, which are then turned into spike trains for the SNN to process over time. In class equalization step, the Synthetic Minority-Oversampling Technique (SMOTE) is being used resulting in balanced classes. Recursive Feature Elimination (RFE) is used to keep the important features for feature optimization. Then, the dataset is split into sets for testing and training so that the model can be tested properly.ResultsThe hybrid model integrates the spatial feature learning skills of RNNs with the temporal adaptability of SNNs, results in an improved accuracy and resilience in identifying IoT network abnormalities. The proposed HRSNN approach, which was tested on the CIC-IoT23 and TON_IoT data sets, achieved better performance compared to current deep learning (DL) models. In particular, experimental assessments show that the model attained an accuracy rate of 99.5% on the “CICIoT2023” dataset and 98.75% on the “TON_IoT” dataset.DiscussionThese results confirm demonstrate that the proposed architecture of RNN and SSN can achieve significant advancement to IoT security. By combining both spatial and temporal feature learning, HRSNN can improve accuracy detection against diverse security threats. The model is reliable, accurate, and adaptable for safeguarding IoT networks against diverse security threats. Thus, the model addresses the potential solutions in the challenging problem of secured IoT networks.},
  archive      = {J_FRAI},
  author       = {Mustafa, Mohammed and Eljack Babiker, Sarah M. and Mustafa, Yasir Eltigani Ali},
  doi          = {10.3389/frai.2025.1651516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1651516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid AI approach for predicting academic performance in RBE students. <em>FRAI</em>, <em>8</em>, 1651100. (<a href='https://doi.org/10.3389/frai.2025.1651100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has advanced significantly in recent years and is being used in higher education to perform various types of data analysis. While the literature demonstrates the application of machine learning algorithms to predict performance in university education, no such applications are found in EBR, let alone in private institutions of a denominational nature, which presents an opportunity to study prediction in these institutions. To address this gap, this research aims to propose a predictive approach as a decision-support tool for regular basic education, using machine learning techniques. Among the techniques utilized, three machine learning models (Logistic Regression, Support Vector Machine, and Random Forest), along with deep learning models (AlexNet, Gated Recurrent Unit, and Bidirectional Gated Recurrent Unit), were analyzed, as well as ensemble models. Nonetheless, the Ensemble model, which combines deep learning and machine learning techniques, is preferred due to its superior accuracy, precision, and sensitivity performance metrics.},
  archive      = {J_FRAI},
  author       = {Gonzales, Willy and Cordero, Zindel and Abanto-Ramírez, Carlos D. and Susanibar Ramírez, Edgar Tito and Iftikhar, Hasnain and Lopez-Gonzales, Javier Linkolk},
  doi          = {10.3389/frai.2025.1651100},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1651100},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid AI approach for predicting academic performance in RBE students},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HairSentinel: A time-aware anomaly detection framework for forecasting hairfall trends using temporal fusion transformers. <em>FRAI</em>, <em>8</em>, 1649740. (<a href='https://doi.org/10.3389/frai.2025.1649740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hairfall is a primary concern for many individuals worldwide today. Hair strands may fall due to various conditions such as hereditary factors, scalp health issues, nutritional deficiencies, hormonal fluctuations, or irregular sleep cycles. Our study presents a novel approach to detecting hairfall trends over time. While traditional methods infer hairfall rates using CNN and SVM models—classifying types of hairfall based on high-resolution images and complex techniques—this study addresses the issue by analyzing user-provided data through simple, straightforward questions, maintaining ease of use. Each attribute is collected using a time-centric approach on a daily or weekly basis. For time series anomaly detection, we utilize LSTM, Random Forest, and the Temporal Fusion Transformer (TFT) to model hairfall fluctuations and compare them with the ARIMAX model across various metrics to identify the most suitable one. The TFT model is selected as the most suitable, with 97.5% accuracy and 97.4% precision over other models supporting anomaly detection. This allows us to establish normal margins of deviation from typical hair shedding cycles. This study enables the proactive detection of anomalies, indicating sudden increases or decreases in hairfall due to hormonal fluctuations. The results support the early identification of potential health risks before they become intensified and help suggest appropriate dietary plans.},
  archive      = {J_FRAI},
  author       = {Leema, A. Anny and Saktheshwaran, T. and Sri, G. Reena and Balakrishnan, P.},
  doi          = {10.3389/frai.2025.1649740},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1649740},
  shortjournal = {Front. Artif. Intell.},
  title        = {HairSentinel: A time-aware anomaly detection framework for forecasting hairfall trends using temporal fusion transformers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). App2: Software solution for apple leaf disease detection based on deep learning (CNN+SVM). <em>FRAI</em>, <em>8</em>, 1648867. (<a href='https://doi.org/10.3389/frai.2025.1648867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of crop diseases is essential to reduce yield losses and improve management efficiency in agricultural production. This work presents the development of a mobile application, called App2, designed to detect diseases in apple tree leaves from images taken or uploaded by the user. The solution integrates a hybrid model based on a Convolutional Neural Network (CNN) and a Support Vector Machine (SVM), developed for computer vision tasks focused on recognizing diseases in apple leaves. The system architecture includes a user interface built with React Native, an API developed using FastAPI and deployed on Azure, and a pre-filter implemented through the OpenAI API to validate that the uploaded images correspond to crop leaves. The model was trained to classify images into six categories: Scab, Black Rot, Rust, Healthy, Powdery Mildew, and Spider Mite. Experimental results showed a 95% success rate in test cases and 80% performance in detecting clear images of affected leaves. User evaluations indicated high usability and satisfaction, demonstrating that the mobile application has strong potential as an accessible and effective technological tool for disease monitoring in apple crops.},
  archive      = {J_FRAI},
  author       = {Aronés, Erick and Espinal, Jefferson and Salas, Cesar},
  doi          = {10.3389/frai.2025.1648867},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1648867},
  shortjournal = {Front. Artif. Intell.},
  title        = {App2: Software solution for apple leaf disease detection based on deep learning (CNN+SVM)},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid framework for enhanced segmentation and classification of colorectal cancer histopathology. <em>FRAI</em>, <em>8</em>, 1647074. (<a href='https://doi.org/10.3389/frai.2025.1647074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionColorectal cancer (CRC) remains one of the leading causes of cancer-related deaths globally. Early detection and precise diagnosis are crucial in improving patient outcomes. Traditional histological evaluation through manual inspection of stained tissue slides is time-consuming, prone to observer variability, and susceptible to inconsistent diagnoses.MethodsTo address these challenges, we propose a hybrid deep learning system combining Swin Transformer, EfficientNet, and ResUNet-A. This model integrates self-attention, compound scaling, and residual learning to enhance feature extraction, global context modeling, and spatial categorization. The model was trained and evaluated using a histopathological dataset that included serrated adenoma, polyps, adenocarcinoma, high-grade and low-grade intraepithelial neoplasia, and normal tissues.ResultsOur hybrid model achieved impressive results, with 93% accuracy, 92% precision, 93% recall, and 93% F1-score. It outperformed individual architectures in both segmentation and classification tasks. Expert annotations and segmentation masks closely matched, demonstrating the model’s reliability.DiscussionThe proposed hybrid design proves to be a robust tool for the automated analysis of histopathological features in CRC, showing significant promise for improving diagnostic accuracy and efficiency in clinical settings.},
  archive      = {J_FRAI},
  author       = {M. D., Aaseegha and B., Venkataramana},
  doi          = {10.3389/frai.2025.1647074},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1647074},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid framework for enhanced segmentation and classification of colorectal cancer histopathology},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing COVID-19 classification of X-ray images with hybrid deep transfer learning models. <em>FRAI</em>, <em>8</em>, 1646743. (<a href='https://doi.org/10.3389/frai.2025.1646743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning, a subset of artificial intelligence, has made remarkable strides in computer vision, particularly in addressing challenges related to medical images. Deep transfer learning (DTL), one of the techniques of deep learning, has emerged as a pivotal technique in medical image analysis, including studies related to COVID-19 detection and classification. Our paper proposes an alternative DTL framework for classifying COVID-19 x-ray images in this context. Unlike prior studies, our approach integrates three distinct experimentation processes using pre-trained models: AlexNet, EfficientNetB1, ResNet18, and VGG16. Furthermore, we explore the application of YOLOV4, traditionally used in object detection tasks, to COVID-19 feature detection. Our methodology involves three different experiments: manual hyperparameter selection, k-fold retraining based on performance metrics, and the implementation of a genetic algorithm for hyperparameter optimization. The first involves training the models with manually selected hyperparameter sets (learning rate, batch size, and epoch). The second approach employs k-fold cross-validation to retrain the models based on the best-performing hyperparameter set. The third employed a genetic algorithm (GA) to automatically determine optimal hyperparameter values, selecting the model with the best performance on our dataset. We tested a Kaggle dataset with more than 5,000 samples and found ResNet18 to be the best model based on genetic algorithm-based hyperparameter selection. We also tested the proposed framework process on another separate public dataset and simulated adversarial attacks to ensure its robustness and dependability. The study outcomes had an accuracy of 99.57%, an F1-score of 99.50%, a precision of 99.44%, and an average AUC of 99.89 for each class. This study underscores the effectiveness of our proposed model, positioning it as a cutting-edge solution in COVID-19 x-ray image classification. Furthermore, the proposed study has the potential to achieve automatic predictions through the use of input images in a simulated web app. This would provide an essential supplement for imaging diagnosis in remote areas with scarce medical resources and help in training junior doctors to perform imaging diagnosis.},
  archive      = {J_FRAI},
  author       = {Moustapha, Maliki and Tasyurek, Murat and Ozturk, Celal},
  doi          = {10.3389/frai.2025.1646743},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1646743},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing COVID-19 classification of X-ray images with hybrid deep transfer learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chimera: A block-based neural architecture search framework for event-based object detection. <em>FRAI</em>, <em>8</em>, 1644889. (<a href='https://doi.org/10.3389/frai.2025.1644889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based cameras are sensors inspired by the human eye, offering advantages such as high-speed robustness and low power consumption. Established deep learning techniques have proven effective in processing event data, but there remains a significant space of possibilities that could be further explored to maximize the potential of such combinations. In this context, Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to systematically adapt RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including attention blocks, convolutions, State Space Models, and MLP-mixer-based architectures, providing a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. Results on Prophesee's GEN1 dataset demonstrated state-of-the-art mean Average Precision (mAP) while reducing the number of parameters by 1.6 × and achieving a 2.1 × speed-up. The project is available at: https://github.com/silvada95/Chimera.},
  archive      = {J_FRAI},
  author       = {Silva, Diego A. and Elsheikh, Ahmed and Smagulova, Kamilya and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  doi          = {10.3389/frai.2025.1644889},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1644889},
  shortjournal = {Front. Artif. Intell.},
  title        = {Chimera: A block-based neural architecture search framework for event-based object detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation. <em>FRAI</em>, <em>8</em>, 1643292. (<a href='https://doi.org/10.3389/frai.2025.1643292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe growing complexity of fraudulent activities presents significant challenges in detecting fraud within financial transactions. Accurate and robust detection methods are essential for minimizing financial losses.MethodsThis study evaluates logistic regression, decision tree, and random forest models on real-world credit card datasets, addressing class imbalance and enhancing predictive accuracy. A deep learning model incorporating focal loss was developed to further improve detection performance. The Synthetic Minority Over-Sampling Technique (SMOTE) was applied to mitigate class imbalance, and hyperparameter tuning was conducted to optimize model configurations.ResultsExperimental results show that the random forest model achieved the best overall performance, with an accuracy of 99.95%, F1 score of 0.8256, and ROC-AUC of 0.9759. The deep learning model provided the highest precision, demonstrating its potential in minimizing false positives.DiscussionA key novelty of this work is the integration of focal loss within the deep learning framework, enabling the model to focus on hard-to-classify fraudulent transactions. Unlike many prior studies limited to the Kaggle dataset, our approach was validated on both the Kaggle credit card dataset and the PaySim synthetic mobile money dataset, demonstrating robustness and cross-domain generalizability. These findings highlight the effectiveness of combining data preprocessing, resampling techniques, and model optimization for robust fraud detection.},
  archive      = {J_FRAI},
  author       = {Albalawi, Tahani and Dardouri, Samia},
  doi          = {10.3389/frai.2025.1643292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1643292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative evaluation of meibomian gland dysfunction via deep learning-based infrared image segmentation. <em>FRAI</em>, <em>8</em>, 1642361. (<a href='https://doi.org/10.3389/frai.2025.1642361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous advanced image segmentation algorithms have been employed in the analysis of meibomian glands (MG). However, their clinical utility remains limited due to insufficient integration with the diagnostic and grading processes of meibomian gland dysfunction (MGD). To bridge this gap, the present study leverages three state-of-the-art deep learning models—DeepLabV3+, U-Net, and U-Net++—to segment infrared MG images and extract quantitative features for MGD diagnosis and severity assessment. A comprehensive set of morphological (e.g., gland area, width, length, and distortion) and distributional (e.g., gland density, count, inter-gland distance, disorder degree, and loss ratio) indicators were derived from the segmentation outcomes. Spearman correlation analysis revealed significant positive associations between most indicators and MGD severity (correlation coefficients ranging from 0.26 to 0.58; p < 0.001), indicating their potential diagnostic value. Furthermore, Box plot analysis highlighted clear distribution differences in the majority of indicators across all grades, with medians shifting progressively, interquartile ranges widening, and an increase in outliers, reflecting morphological changes associated with disease progression. Logistic regression models trained on these quantitative features yielded area under the receiver operating characteristic curve (AUC) values of 0.89 ± 0.02, 0.76 ± 0.03, 0.85 ± 0.02, and 0.94 ± 0.01 for MGD grades 0, 1, 2, and 3, respectively. The models demonstrated strong classification performance, with micro-average and macro-average AUCs of 0.87 ± 0.02 and 0.86 ± 0.03, respectively. Model stability and generalizability were validated through 5-fold cross-validation. Collectively, these findings underscore the clinical relevance and robustness of deep learning-assisted quantitative analysis for the objective diagnosis and grading of MGD, offering a promising framework for automated medical image interpretation in ophthalmology.},
  archive      = {J_FRAI},
  author       = {Yu, Ziyang and Wei, Zhijun and Wang, Mini Han and Cui, Jiazheng and Tan, Jiaxiang and Xu, Yang},
  doi          = {10.3389/frai.2025.1642361},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1642361},
  shortjournal = {Front. Artif. Intell.},
  title        = {Quantitative evaluation of meibomian gland dysfunction via deep learning-based infrared image segmentation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study. <em>FRAI</em>, <em>8</em>, 1638904. (<a href='https://doi.org/10.3389/frai.2025.1638904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAutoimmune encephalitis (AIE) is challenging to diagnose, especially in primary hospitals in China with limited medical resources. DeepSeek, a newly developed AI, shows potential as a cost-effective tool for improving diagnostic efficiency. However, no studies have evaluated the diagnostic accuracy of DeepSeek for AIE.MethodsThis retrospective study included 100 patients with anti-neuronal antibody-positive AIE treated at Ruijin Hospital, Shanghai Jiao Tong University School of Medicine. After removing personally identifiable information, antibody results, and history of immunotherapy from patients’ medical histories, the following information was sequentially input into DeepSeek: sex, age, chief complaint, medical history, EEG findings, head MRI description, and cerebrospinal fluid (CSF) results. The positive rates of AIE diagnoses predicted by DeepSeek were then categorized as most likely diagnosis, differential diagnosis, and total diagnosis.ResultsUsing DeepSeek, the probabilities of AIE appearing as the most likely diagnosis and total diagnosis accuracy were 49 and 65%. When patient data were input stepwise, both the total diagnosis accuracy and the most likely diagnosis accuracy did not significantly increase. AIE patients with anti-MOG and anti-GABAbR positivity had predicted total diagnostic positivity rates of 88 and 100%, respectively. Patients presenting with headache and epilepsy were more likely to be diagnosed with AIE (96 and 100%).ConclusionDeepSeek shows limited positive diagnostic accuracy for predicting the diagnosis of AIE. The application of this new AI technology could be used to promote early screening for AIE in primary hospitals in China, improve medical education, and lead to research advances in AIE.},
  archive      = {J_FRAI},
  author       = {Meng, Huanyu and Tang, Yihua and Qi, Yuanqi and Zhou, Qinming and He, Lu and Chen, Sheng},
  doi          = {10.3389/frai.2025.1638904},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1638904},
  shortjournal = {Front. Artif. Intell.},
  title        = {The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multicenter evaluation of machine and deep learning methods to predict glaucoma surgical outcomes. <em>FRAI</em>, <em>8</em>, 1636410. (<a href='https://doi.org/10.3389/frai.2025.1636410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeTo develop machine learning (ML) and neural network (NN) models to predict glaucoma surgical outcomes, including intraocular pressure (IOP), use of ocular antihypertensive medications, and need for additional glaucoma surgery, using preoperative electronic health records (EHR) from a large multicenter cohort.MethodsThis cohort study included 9,386 patients who underwent glaucoma surgery across 10 institutions in the Sight Outcomes Research Collaborative (SOURCE). All patients had at least 1 year of follow-up and 2 postoperative visits with IOP measurements. Models were trained using preoperative EHR features to predict surgical failure, defined as any of the following: IOP remaining above 80% of preoperative value beyond the immediate postoperative period, increased postoperative glaucoma medications, or need for additional glaucoma surgery. Model performance was evaluated on two test sets: an internal holdout set from sites seen during training and an external holdout set.ResultsOf 13,173 surgeries, 8,743 (66.4%) met failure criteria. The best-performing model for overall surgical failure prediction was a one-dimensional convolutional neural network (1D-CNN) with AUROC of 76.4% and accuracy of 71.6% on the internal test set. The top-performing classical ML model was random forest (AUROC 76.2%, accuracy 72.1%). Prediction performance was highest for IOP-related failure (AUROC 82%), followed by increased medication use (80%) and need for an additional surgery (68%). AUROC declined slightly (2–4%) on the external test set.ConclusionML and DL models can predict glaucoma outcomes using preoperative EHR data. Translational relevance: prediction models may support clinical decision-making by identifying glaucoma patients at risk of poor postoperative outcomes.},
  archive      = {J_FRAI},
  author       = {Barry, Samuel and Wang, Sophia Y.},
  doi          = {10.3389/frai.2025.1636410},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1636410},
  shortjournal = {Front. Artif. Intell.},
  title        = {Multicenter evaluation of machine and deep learning methods to predict glaucoma surgical outcomes},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The innovation paradox in human-AI symbiosis: Ambidextrous effects of AI technology adoption on innovative behavior. <em>FRAI</em>, <em>8</em>, 1635246. (<a href='https://doi.org/10.3389/frai.2025.1635246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAI is radically changing workplace ecosystems in the midst of the Fourth Industrial Revolution, making human-machine collaboration a need for organizations. The ambidextrous processes by which AI simultaneously encourages and constrains inventive behaviors need systematic examination, even though employee innovation is still essential for maintaining competitive advantage. In order to understand the paradoxical consequences of AI, this study builds a dual-path moderated mediation model based on the Job Demands-Resources (JD-R) paradigm.MethodsUsing a two-wave longitudinal design with a 3-month interval and multi-source data from 250 experts in China, we combined survey measurements with quasi-experimental manipulations. The following findings were obtained using structural equation modeling (SEM) and bootstrapping.Results(1) AI technology adoption is a job resource that increases Felt Obligation for Constructive Change (FOCC), but it also acts as a job demand that inhibits innovation by creating a sense of job insecurity; (2) task crafting is a crucial boundary condition that amplifies the positive mediation path while attenuating the negative pathway.DiscussionBased on the aforementioned findings, this study highlights the importance of considering employees' psychological states and behavioral changes while fostering technological innovation, exposing the intricacy of artificial intelligence technology in HRM from both a subjective and objective standpoint. Job insecurity is a possible drawback of technology use, hence businesses should take appropriate steps to lessen employee uneasiness while using new technologies. Felt Obligation for Constructive Change, on the other hand, is a crucial strategy for encouraging creative behavior. To do this, managers must investigate and enhance employees' intrinsic motivation for their everyday tasks and foster a culture of creativity. Task crafting, as an effective self-management and driving factor, is also very important to reduce the negative effects of technology adoption and increase its positive effects. For this reason, businesses should support and encourage employees to improve their autonomy and flexibility, iterate on their work methods, and stimulate their ability to innovate. This will not only help employees develop their own skills but also give businesses a competitive edge and continuous innovation motivation.},
  archive      = {J_FRAI},
  author       = {Wang, Xin and Long, Lin},
  doi          = {10.3389/frai.2025.1635246},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1635246},
  shortjournal = {Front. Artif. Intell.},
  title        = {The innovation paradox in human-AI symbiosis: Ambidextrous effects of AI technology adoption on innovative behavior},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMEA based prescriptive model for equipment repair guidance. <em>FRAI</em>, <em>8</em>, 1630907. (<a href='https://doi.org/10.3389/frai.2025.1630907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAccurate prediction of steps required to address machine faults is critical for minimizing downtime and enhancing production efficiency in modern manufacturing. This study utilizes machine failure data and Failure Mode and Effects Analysis to demonstrate how machine learning supports maintenance teams in selecting optimal repair methods.MethodsThe research adopts the Design Science Research paradigm, which emphasizes the creation of artifacts to address practical challenges. For the practical component, quality assurance and control frameworks in data science projects were implemented by integrating two widely used methodologies: CRISP-DM and PDCA, to ensure rigorous quality assurance and control in data science initiatives.ResultsRepair actions serve as the target variables, while the input comprises ten multivariate time-series machine parameters. The prediction task is formulated as a classification problem. Two modeling approaches are evaluated. The first approach merges multiple time series into a single sequence, facilitating the application of Multi-Layer Perceptron, Convolutional Neural Networks, and Fully Convolutional Networks. The second approach preserves the time series as three-dimensional arrays, enabling advanced applications of MLP, CNN, Multi-Head CNN, and FCN models.DiscussionThe models are assessed based on their capacity to predict repair actions, with particular emphasis on the impact of time-series processing and model architecture on classification accuracy. The findings highlight effective strategies for predicting machine repairs and advancing prescriptive maintenance in manufacturing environments.},
  archive      = {J_FRAI},
  author       = {Oliveira, Domingos F. and Brito, Miguel A. and Brandão, Duarte J.},
  doi          = {10.3389/frai.2025.1630907},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1630907},
  shortjournal = {Front. Artif. Intell.},
  title        = {FMEA based prescriptive model for equipment repair guidance},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning approaches to anxiety detection: Trends, model evaluation, and future directions. <em>FRAI</em>, <em>8</em>, 1630047. (<a href='https://doi.org/10.3389/frai.2025.1630047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAnxiety is a pervasive mental health disorder with severe implications for individual wellbeing and societal productivity. The contemporary rise of anxiety, particularly among youth in digitally-saturated environments, underscores a critical need for advanced predictive tools to facilitate early intervention and mitigation. While machine learning (ML) holds significant promise in this domain, a comprehensive synthesis of its application in anxiety prediction, along with a critical evaluation of methodological trends and gaps, is only emerging in the literature. The main idea of the current systematic review is to bridge the understanding of current ML applications in mental health with the critical needs for enhanced diagnostic precision, personalized interventions and prevention.ObjectivesThis systematic review aims to systematically synthesize research on ML approaches to predicting anxiety, critically evaluating the algorithms, features, and validation techniques employed across studies. The objective is to identify prevailing ML techniques, assess their performance, and highlight crucial methodological trends, existing gaps, and their implications for effective early intervention and real-world deployment.Eligibility criteriaStudies included had to apply machine learning techniques to predict anxiety or its severity using either clinical or behavioral datasets. Exclusion criteria included non-English language papers, reviews, older or previously reviewed publications, and those not specifically targeting anxiety. We focus on questionnaire research, but also discuss multimodal fusion techniques.Information sourcesWe searched the Scopus database and Google Scholar for articles published between 2018 and 2025 using combinations of keywords including “anxiety prediction,” “machine learning,” and “mental health.” The last search was conducted in July 2025.Risk of biasStudies were screened in two phases: (1) by verifying the presence of relevant keywords in the main body, and (2) by reviewing title, introduction, and conclusion to ensure alignment with anxiety prediction via ML. Studies relying solely on self-reported metrics or with unclear algorithmic transparency were noted for potential bias.ResultsA total of 19 studies were included, encompassing 44, 608 participants. GAD-7 and DASS-21 were the most commonly used diagnostic instruments. ML techniques such as Random Forest and Gradient Boosting achieved the highest predictive accuracy, with some studies reporting up to 98% accuracy. Metrics like F1-score, AUC, and specificity were commonly reported.Limitations of evidenceExisting studies display a range of methodological and conceptual limitations that constrain their generalizability and clinical utility. The review identified significant methodological limitations hindering generalizability and clinical utility, including reliance on small, homogeneous samples, which raises concerns about overfitting and population bias. Furthermore, common issues include a lack of external validation, inconsistent evaluation metrics, and the “black-box” nature of many ML algorithms, which impedes clinical trust and adoption.InterpretationThe findings support the effectiveness of machine learning for anxiety detection and prediction, particularly in early intervention contexts. The integration of explainable ML and diverse, clinically validated data is necessary for real-world deployment. The existing body of research also shows a notable scarcity in studies predicting anxiety before symptom manifestation. These insights emphasize the critical need for integrating explainable ML (XAI) and utilizing diverse, clinically validated datasets to enable real-world deployment and proactive mental health support.},
  archive      = {J_FRAI},
  author       = {Taskynbayeva, Meruyert and Gutoreva, Alina},
  doi          = {10.3389/frai.2025.1630047},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1630047},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning approaches to anxiety detection: Trends, model evaluation, and future directions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel interpretable and real-time dengue prediction framework using clinical blood parameters with genetic and GAN-based optimization. <em>FRAI</em>, <em>8</em>, 1626699. (<a href='https://doi.org/10.3389/frai.2025.1626699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dengue remains a significant and critical global health concern, especially in resource-constrained and remote regions, where traditional IgG/IgM-based testing is often delayed or not conducted properly. Furthermore, conventional machine learning often exhibits minimal interpretability and misclassification, leading to major unreliability in real-time clinical decisions. To tackle these hindrances, we proposed an interpretable, efficient, and novel machine learning framework that operates near real-time. It combines feature optimization using Genetic Algorithms (GA) and Generative Adversarial Networks (GAN) to address data imbalance, and enhances ubiquitous decision interpretability with Explainable AI (XAI). GA establishes the most predictive hematological features, which improve accuracy and transparency, whereas GAN-based data generation handles class imbalance, leading to enhanced generalization. On top of that, the optimized Decision Tree model attains 99.49% accuracy with a negligible computational cost of training and testing time 0.0025 s, and 0.0013 s respectively, superseding the current state-of-the-art. A web-based application implemented based on the proposed model enables real-time risk prediction with a latency of under 0.6 s. A comprehensive XAI evaluation using LIME, SHAP, Morris sensitivity analysis, permutation combination, and RFE consistently identifies WBC and platelet counts as key predictors. In numbers, XAI techniques represent that low White Blood Cell (WBC) count (< 3,700 cells/μL), platelet count (< 136,000 cells/μL), and Platelet Distribution Width (PDW < 23) are key indicators of dengue. Our proposed integrated GA-GAN-XAI framework bridges accuracy, interpretability, and real-time decision-making capability. This approach is highly accurate, robust for healthcare, and a highly deployable solution for dengue risk prediction for clinical dengue risk assessment.},
  archive      = {J_FRAI},
  author       = {Haque, Md. Ehsanul and Nurul Absur, Md. and Al Farid, Fahmid and Uddin, Jia and Abdul Karim, Hezerul},
  doi          = {10.3389/frai.2025.1626699},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1626699},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel interpretable and real-time dengue prediction framework using clinical blood parameters with genetic and GAN-based optimization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Issues of AI and human resource development: Applications in education and the arts. <em>FRAI</em>, <em>8</em>, 1619980. (<a href='https://doi.org/10.3389/frai.2025.1619980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how artificial intelligence (AI) transforms human learning, creativity, and ethical engagement, with implications for future Human Resource Development (HRD). Drawing on Computational Creativity theory, a cross-domain case study analysis—including educational tools (e.g., Jill Watson, Cognii) and generative art platforms (e.g., AICAN, DALL·E)—reveals the dual role of AI as both cognitive collaborator and autonomous agent. The paper structures its discussion around three key dimensions: education (personalized learning vs. development of metacognitive competence), arts (co-authorship dilemmas vs. preservation of human originality), and ethics (regulatory gaps in professional education). Through these domains, the study highlights interdependent tensions and synergies, and argues that AI integration calls for reconceptualizing human–machine interaction in HRD. It then proposes the AI–Human Synergistic Creativity and Learning Framework, which emphasizes collaborative creativity, ethical reflection, and adaptive learning for workforce development. The findings offer actionable insights into curriculum design, policy formulation, and institutional training strategies in AI-augmented contexts.},
  archive      = {J_FRAI},
  author       = {Jung, Eun Jin and Yoon, Hea Jun},
  doi          = {10.3389/frai.2025.1619980},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1619980},
  shortjournal = {Front. Artif. Intell.},
  title        = {Issues of AI and human resource development: Applications in education and the arts},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patient-centered modeling of the breast biopsy experience. <em>FRAI</em>, <em>8</em>, 1618357. (<a href='https://doi.org/10.3389/frai.2025.1618357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDespite significant advances in breast cancer screening and early detection over recent decades, rising patient volumes, limited resources, and time constraints hinder healthcare teams from anticipating distress and effectively managing the patient experience. We leveraged real-world data from 236 patients during a breast biopsy procedure and follow-up period.ObjectiveThe study goal was to model important components of the multifaceted biopsy procedure and its effect on patient experience.MethodsWe integrated data from patient-reported outcomes, psycho-social assessments, and workflow annotations.ResultsWe (1) provide a visual model of the patient pathway, (2) predict, with linear mixed models and machine learning, anxiety based on psychological pre-assessments as well as procedural events, and (3) analyze communication between caregiver and patient to understand moderators of the patient experience. Predictive modeling revealed significant correlation between psychological pre-assessments and median anxiety during biopsy (IES β = 0.91, CES-D β = 0.8, PSS β = 0.62, STAI β = 0.58, all with p < 0.001). Higher baseline stress was strongly associated with greater anxiety during biopsy. Centering each individual's procedure time at her first local anesthesia (LA) revealed a significant (βt2p = 5.43e−06) temporal pattern in anxiety, which increased until LA and decreased afterwards. Using natural language processing, we identified patient expressions of pain and distress alongside workflow annotations.ConclusionOur findings highlight the potential of combining data to model patient experience during a medical procedure. Our work helps to develop digital twins of medical procedures to support clinicians to provide proactive care and mitigate patient distress.},
  archive      = {J_FRAI},
  author       = {Nieto-Alvarez, Isabel and Bojorges-Valdez, Erik and Lang, Elvira and Ranaei Sharif, Mohammadreza and Köber, Göran and Rohleder, Nicolas and Amft, Oliver},
  doi          = {10.3389/frai.2025.1618357},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1618357},
  shortjournal = {Front. Artif. Intell.},
  title        = {Patient-centered modeling of the breast biopsy experience},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiT: Limit order book transformer. <em>FRAI</em>, <em>8</em>, 1616485. (<a href='https://doi.org/10.3389/frai.2025.1616485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the transformer architecture has demonstrated strong success in natural language processing and computer vision, its application to limit order book forecasting, particularly in capturing spatial and temporal dependencies, remains limited. In this work, we introduce Limit Order Book Transformer (LiT), a novel deep learning architecture for forecasting short-term market movements using high-frequency limit order book data. Unlike previous approaches that rely on convolutional layers, LiT leverages structured patches and transformer-based self-attention to model spatial and temporal features in market microstructure dynamics. We evaluate LiT on multiple LOB datasets across different prediction horizons, LiT consistently outperforms traditional machine learning methods and state-of-the-art deep learning baselines. Furthermore, we show that LiT maintains robust performance under distributional shifts via fine-tuning, making it a practical solution for fast-paced and dynamic financial environments.},
  archive      = {J_FRAI},
  author       = {Xiao, Yue and Ventre, Carmine and Wang, Yuhan and Li, Haochen and Huan, Yuxi and Liu, Buhong},
  doi          = {10.3389/frai.2025.1616485},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1616485},
  shortjournal = {Front. Artif. Intell.},
  title        = {LiT: Limit order book transformer},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of AI-enhanced fast delivery services in strengthening customer retention and loyalty in competitive markets. <em>FRAI</em>, <em>8</em>, 1612772. (<a href='https://doi.org/10.3389/frai.2025.1612772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents an AI-enhanced framework to optimize last-mile delivery systems by integrating predictive analytics, Reinforcement Learning (RL), and customer personalization. The predictive analytics component utilized XGBoost and Random Forest models to forecast delivery times. Random Forest achieved better performance, with a Root Mean Square Error of 1.52 and an R-squared value of 0.56. RL-based route optimization improved operational efficiency by reducing the average delivery time from 31.2 to 25.4 min, increasing timely deliveries from 78\% to 92\%, and reducing idle time by 15\%. Customer personalization, driven by sentiment analysis and clustering, increased positive sentiment from 68\% to 80\%. It also improved Net Promoter Scores from 68 to 85 and increased customer retention from 74\% to 89\%. The proposed framework addresses the challenges of last-mile delivery by combining data-driven predictions, adaptive routing, and personalized customer strategies. Future work will explore real-world implementation using real-time traffic data and advanced personalization techniques to improve adaptability and scalability.},
  archive      = {J_FRAI},
  author       = {Kasoju, Apoorva and Vishwakarma, Tejavardhana and Kasoju, Abhinaya},
  doi          = {10.3389/frai.2025.1612772},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1612772},
  shortjournal = {Front. Artif. Intell.},
  title        = {The role of AI-enhanced fast delivery services in strengthening customer retention and loyalty in competitive markets},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The perceived impact of artificial intelligence on academic learning. <em>FRAI</em>, <em>8</em>, 1611183. (<a href='https://doi.org/10.3389/frai.2025.1611183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence, such as ChatGPT, is transforming higher education by enabling personalized learning, while raising ethical challenges. This study explores how technical university students perceive and leverage ChatGPT in academic tasks, focusing on motivation, learning outcomes, and ethical awareness. Using the Technology Acceptance Model and Self-Determination Theory, the research surveyed 84 students from a technical university via a 5-point Likert-scale questionnaire. Six salient dimensions of student engagement with ChatGPT emerged: perceived usefulness for problem solving, learning retention and skill acquisition, structured interaction with familiar content, consultation on unfamiliar topics, preference for conciseness, and confidence in the accuracy of AI responses. Students who perceived ChatGPT as a valuable resource for addressing academic problems reported enhanced motivation and competence, and frequent structured interaction was linked to the practice of verifying uncertain information, indicating the emergence of AI literacy. However, extensive reliance was correlated with dependence and limited citation practices, revealing risks to academic integrity. By examining ChatGPT’s role in STEM education, this study substantiates the relevance of AI literacy training and institutional policies to ensure responsible use. The findings offer practical insights for educators to integrate AI tools effectively while fostering critical thinking and academic integrity in technology-driven learning environments.},
  archive      = {J_FRAI},
  author       = {Dogaru, Mariana and Pisică, Olivia and Popa, Cosmin-Ștefan and Răgman, Andrei-Adrian and Tololoi, Ilinca-Roxana},
  doi          = {10.3389/frai.2025.1611183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1611183},
  shortjournal = {Front. Artif. Intell.},
  title        = {The perceived impact of artificial intelligence on academic learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom. <em>FRAI</em>, <em>8</em>, 1604110. (<a href='https://doi.org/10.3389/frai.2025.1604110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions in educational settings are often studied through self-reports or lab experiments, limiting insights into their real-world dynamics. This study examines learner emotions in authentic foreign language classrooms using a multimodal longitudinal approach. Over 16 consecutive sessions, we collected heart rate (HR) signals, emotional facial expressions (EFE), classroom observations, and self-reports on enjoyment, anxiety, and boredom to capture both physiological and self-perceived emotional responses. Rather than aggregating data across students, we focused on individualized emotional patterns to understand variations in emotional experiences. Each dataset included extensive video recordings, continuous HR monitoring, detailed observational notes, and post-session questionnaires, providing a high-resolution picture of emotional dynamics. Using unsupervised clustering techniques, we identified key emotional episodes—peaks and drops in physiological arousal (heart rate variation) and facial expression—relative to individual emotional baselines. These moments were cross-referenced with classroom observations and self-reports for validation. Findings highlight moments of positive emotional contagion during peer interactions, emphasizing the social dimension of language learning. This multimodal approach captures the interplay of physiological, behavioral, and subjective responses, offering a scalable method for studying classroom emotions. Methodologically, it demonstrates how multimodal analytics can uncover transient emotional states in real-world settings, while practically informing adaptive teaching strategies, such as leveraging peer interactions to enhance engagement or reduce anxiety. By integrating physiological, behavioral, and subjective data, this study provides a comprehensive framework for understanding the affective dimensions of learning.},
  archive      = {J_FRAI},
  author       = {Guedat-Bittighoffer, Delphine and Moufidi, Abderrazzaq and Dewaele, Jean-Marc and Rousseau, David and Voyneau, Hugo and Rasti, Pejman},
  doi          = {10.3389/frai.2025.1604110},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1604110},
  shortjournal = {Front. Artif. Intell.},
  title        = {Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Oral squamous cell carcinoma grading classification using deep transformer encoder assisted dilated convolution with global attention. <em>FRAI</em>, <em>8</em>, 1575427. (<a href='https://doi.org/10.3389/frai.2025.1575427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Oral Squamous Cell Carcinoma (OSCC) has been a common tumor in the orofacial region, affecting areas such as the teeth, jaw, and temporomandibular joint. OSCC is classified into three grades: “well-differentiated, moderately differentiated, and poorly differentiated,” with a high morbidity and mortality rate among patients. Several existing methods, such as AlexNet, CNN, U-Net, and V-Net, have been used for OSCC classification. However, these methods face limitations, including low ACC, poor comparability, insufficient data collection, and prolonged training times. To address these limitations, we introduce a novel Deep Transformer Encoder-Assisted Dilated Convolution with Global Attention (DeTr-DiGAtt) model for OSCC classification. To enhance the dataset and mitigate over-fitting, a GAN model is employed for data augmentation. Additionally, an Adaptive Bilateral Filter (Ad-BF) is used to improve image quality and remove undesirable noise. For accurate identification of the affected region, an Improved Multi-Encoder Residual Squeeze U-Net (Imp-MuRs-Unet) model is utilized for segmentation. The DeTr-DiGAtt model is then applied to classify different OSCC grading levels. Furthermore, an Adaptive Grey Lag Goose Optimization Algorithm (Ad-GreLop) is used for hyperparameter tuning. The proposed method achieves an accuracy (ACC) of 98.59%, a Dice score of 97.97%, and an Intersection over Union (IoU) of 98.08%.},
  archive      = {J_FRAI},
  author       = {Ramya, Singaraju and Minu, R. I.},
  doi          = {10.3389/frai.2025.1575427},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1575427},
  shortjournal = {Front. Artif. Intell.},
  title        = {Oral squamous cell carcinoma grading classification using deep transformer encoder assisted dilated convolution with global attention},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learner-based frameworks for interpretable email spam detection. <em>FRAI</em>, <em>8</em>, 1569804. (<a href='https://doi.org/10.3389/frai.2025.1569804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWith the increasing reliance on digital communication, email has become an essential tool for personal and professional correspondence. However, despite its numerous benefits, digital communication faces significant challenges, particularly the prevalence of spam emails. Effective spam email classification systems are crucial to mitigate these issues by automatically identifying and filtering out unwanted messages, enhancing the efficiency of email communication.MethodsWe compare five traditional machine-learning and five deep-learning spam classifiers against a novel meta-learner, evaluating how different word embeddings, vectorization schemes, and model architectures affect performance on the Enron-Spam and TREC 2007 datasets. The primary aim is to show how the meta-learner's combined predictions stack up against individual ML and DL approaches.ResultsOur meta-learner outperforms all state-of-the-art models, achieving an accuracy of 0.9905 and an AUC score of 0.9991 on a hybrid dataset that combines Enron-Spam and TREC 2007. To the best of our knowledge, our model also surpasses the only other meta-learning-based spam detection model reported in recent literature, with higher accuracy, better generalization from a significantly larger dataset, and lower computational complexity. We also evaluated our meta-learner in a zero-shot setting on an unseen real-world dataset, achieving a spam sensitivity rate of 0.8970 and an AUC score of 0.7605.DiscussionThese results demonstrate that meta-learning can yield more robust, bias-resistant spam filters suited for real-world deployment. By combining complementary model strengths, the meta-learner also offers improved resilience against evolving spam tactics.},
  archive      = {J_FRAI},
  author       = {Kshirsagar, Meghana and Rathi, Vedant and Ryan, Conor},
  doi          = {10.3389/frai.2025.1569804},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1569804},
  shortjournal = {Front. Artif. Intell.},
  title        = {Meta-learner-based frameworks for interpretable email spam detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ML-based validation of experimental randomization in learning games. <em>FRAI</em>, <em>8</em>, 1541087. (<a href='https://doi.org/10.3389/frai.2025.1541087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomization is a standard method in experimental research, yet its validity is not always guaranteed. This study introduces machine learning (ML) models as supplementary tools for validating participant randomization. A learning direction game with dichotomized scenarios was introduced, and both supervised and unsupervised ML models were evaluated on a binary classification task. Supervised models (logistic regression, decision tree, and support vector machine) achieved the highest accuracy of 87% after adding synthetic data to enlarge the sample size, while unsupervised models (k-means, k-nearest neighbors, and ANN—artificial neural networks) performed less effectively. The ANN model, in particular, showed overfitting, even with synthetic data. Feature importance analysis further revealed predictors of assignment bias. These findings support the proposed methodology for detecting randomization patterns; however, its effectiveness is influenced by sample size and experimental design complexity. Future studies should apply this approach with caution and further examine its applicability across diverse experimental designs.},
  archive      = {J_FRAI},
  author       = {Hsieh, Pei-Hsuan},
  doi          = {10.3389/frai.2025.1541087},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1541087},
  shortjournal = {Front. Artif. Intell.},
  title        = {ML-based validation of experimental randomization in learning games},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in phishing detection: A bibliometric review. <em>FRAI</em>, <em>8</em>, 1496580. (<a href='https://doi.org/10.3389/frai.2025.1496580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundPhishing represents a category of cyber-attacks based on social engineering, with a significant impact on individuals and organizations, and a high capacity for reinvention by adapting its modus operandi according to technological advancements. With a relatively simple scenario and without using sophisticated technologies, phishing attacks exploit user vulnerabilities, convincing them to disclose sensitive personal or organizational data. Within anti-phishing solutions, the detection of spoofed URLs, counterfeit websites, and email or other types of messages that lure the user into entering their data in a form, plays an important role. Against this backdrop, artificial intelligence (AI) technologies, particularly Machine Learning (ML), have been successfully employed in phishing detection, with a rich body of literature in this field.ObjectiveA review of the existing literature on phishing detection using AI was conducted. This study aims to fill this gap by providing comprehensive bibliometric analysis, complementing existing surveys in the field, focusing on the role of AI in phishing detection.MethodsA total of 1096 documents focusing on AI, ML, Deep Learning (DL), or Natural Language Processing (NLP) in phishing detection were extracted from the Web of Science (WoS) scientific database. The information from these documents was subsequently loaded into the Biblioshiny (Bibliometrix package) and VOSviewer software.ResultsThe dataset allowed for the identification of publication trends, influential documents and publications, patterns of author collaboration, and key topics of interest within the main author clusters. A thematic analysis of the field highlighted driving themes, niche themes, emerging and declining themes, and basic themes. Furthermore, thematic evolution over time was examined based on authors’ keywords. A thorough review of the most relevant articles identified through bibliometric analysis was conducted to discuss the primary methods of phishing detection using AI.ConclusionThe research field of AI in phishing detection has evolved significantly starting with 2016, with a focus on using ML algorithms to identify phishing websites by extracting discriminative features, and experienced a consistent growth in 2024. Recent work emphasizes a shift from classical ML to DL, the importance of feature selection and engineering, and the use of hybrid models and classifier stacking.},
  archive      = {J_FRAI},
  author       = {Popescul, Daniela and Radu, Laura Diana},
  doi          = {10.3389/frai.2025.1496580},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1496580},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI in phishing detection: A bibliometric review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMCFO: A novel cuttlefish optimization algorithm enhanced by simplex method for data clustering. <em>FRAI</em>, <em>8</em>, 1677059. (<a href='https://doi.org/10.3389/frai.2025.1677059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn unsupervised learning, data clustering is essential. However, many current algorithms have issues like early convergence, inadequate local search capabilities, and trouble processing complicated or unbalanced input. Established methods like Kmeans are still widely used because of their ease of use; however, they struggle with non-spherical cluster shapes, which are sensitive to initialization, and suffer in highdimensional space. As a substitute, metaheuristic algorithms have surfaced as possible options, providing powerful global search ability. The Cuttlefish Optimization Algorithm (CFO) shows promise in clustering applications but suffers from premature convergence and poor local optimization capability.MethodsThis paper introduces a new clustering method based on the Cuttlefish Optimization Algorithm (CFO), which improves upon the Nelder-Mead simplex method known as SMCFO. The method partitions the population into four subgroups with specific update strategies. One subgroup uses the Nelder-Mead method to improve the quality of solutions, while the others attempt to maintain exploration and exploitation equilibrium. This study compares the performance of the suggested SMCFO algorithm with four established clustering algorithms: CFO, PSO, SSO, and SMSHO. The evaluation used 14 datasets, which include two artificial datasets and 12 benchmark datasets sourced from the UCI Machine Learning Repository.Results and discussionThe proposed SMCFO algorithm consistently outperformed competing methods across all datasets, achieving higher clustering accuracy, faster convergence, and improved stability. The robustness of these outcomes was further confirmed through nonparametric statistical tests, which demonstrated that the performance improvements of SMCFO were statistically significant and not due to chance. The results confirm that the simplex-enhanced design boosts local exploitation and stabilizes convergence, which underlies SMCFO's superior performance compared to baseline methods.},
  archive      = {J_FRAI},
  author       = {K., Kalpanarani and G., Hannah Grace},
  doi          = {10.3389/frai.2025.1677059},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1677059},
  shortjournal = {Front. Artif. Intell.},
  title        = {SMCFO: A novel cuttlefish optimization algorithm enhanced by simplex method for data clustering},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive consensus optimization in blockchain using reinforcement learning and validation in adversarial environments. <em>FRAI</em>, <em>8</em>, 1672273. (<a href='https://doi.org/10.3389/frai.2025.1672273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity and decentralization of modern blockchain networks have highlighted the limitations of traditional consensus protocols when operating under adverse or dynamic conditions. Existing approaches often fail to adapt to real-time anomalies such as Sybil attacks, network congestion, or node failures, resulting in decreased throughput, increased latency, and reduced security. Furthermore, most systems lack autonomous mechanisms to adjust operational policies based on context, especially in edge computing environments where resource constraints and topological variability demand flexible and efficient solutions. This work proposes an adaptive consensus architecture that integrates a graph-based Proximal Policy Optimization (PPO) reinforcement learning agent capable of detecting malicious behavior, optimizing validation paths, and dynamically modifying consensus logic in response to adversarial scenarios. The model is trained on a hybrid dataset composed of real traffic traces and synthetically generated adversarial behaviors, and evaluated in stress-testing environments with multiple threat vectors. Experimental results demonstrate that the proposed system maintains stable throughput (TPS) while reducing average consensus latency by 34% relative to baseline protocols under adverse high-load conditions. Regarding security, it achieves high detection in Sybil and node-collapse scenarios (DR exceeding 0.90 with FPR below 0.10), and moderate detection under congestion and erroneous transactions (DR between 0.58 and 0.70, FPR between 0.14 and 0.22). Additionally, we observe up to 16% lower average energy consumption in high-congestion settings. Energy consumption is reduced by up to 17% in crash-prone scenarios. The architecture demonstrates stable convergence over 100 operating cycles and robust adaptation to topological changes, validating its applicability in real-world deployments.},
  archive      = {J_FRAI},
  author       = {Gutierrez, Rommel and Villegas-Ch, William and Govea, Jaime},
  doi          = {10.3389/frai.2025.1672273},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1672273},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptive consensus optimization in blockchain using reinforcement learning and validation in adversarial environments},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting BRICS NIFTY50 returns using XAI and S.A.F.E AI lens. <em>FRAI</em>, <em>8</em>, 1668700. (<a href='https://doi.org/10.3389/frai.2025.1668700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeGlobal fund managers, in their effort toward risk diversification and generating higher returns, design portfolios that consist of financial assets of various countries. In the process, they expose their investors not only to the fundamentals of the assets but also to transnational volatility, macroeconomic shocks of different countries, and exchange rate fluctuations. These factors make forecasting returns from such global funds quite difficult and, at the same time, challenging. To aid global fund managers and investors, this study presents a forecasting framework for predicting returns from Goldman Sachs BRICs Nifty 50 Developed Markets Index (BRICS NIFTY 50), which is a traded and listed financial asset. It is a global portfolio, which not only exposes investors to the fundamentals of different companies but also to country risk.Design, methodology, and approachGradient boosting regression (GBR) and SHAP-based XAI are used to identify the top significant country-specific explanatory variables. Subsequently, with the selected variables, GBR, CatBoost, Light Gradient Boosting Machine (LGBM), Extreme Gradient Boosting (XGBoost), Random Forest (RF), and Extra Tree Regressor (ETR) are applied for forecasting returns from BRICS NIFTY 50. Along with standard evaluation tools, the S.A.F.E AI framework is used for measuring predictive accuracy, sustainability, and contribution of each predictor. To evaluate the relative efficacy of the six predictive models, the underlying research resorts to a multi-criteria decision-making (MCDM) framework.FindingsWe find that country-specific market volatility, industrial performance, financial sector development, and exchange rate fluctuations explain global returns significantly. Furthermore, the exercise also reveals that explanatory factors specific to India, China, and Brazil emerge to be relatively important.Research limitations and implicationsThe study focuses on a single index. Future work will extend it to other indices and global funds.Practical implicationsThe proposed methodology will be of practical use to global fund managers and investors. Policymakers may find it useful for identifying factors that make foreign direct investment and portfolio investment attractive.Originality and valueDevelopment of a two-step forecasting framework, identifying effects of country-specific explanatory variables, and applying different evaluation criteria to measure predictive efficiency underscore the novelty of the work.},
  archive      = {J_FRAI},
  author       = {Ghosh, Indranil and Datta Chaudhuri, Tamal and Babaei, Golnoosh and Giudici, Paolo and Raffinetti, Emanuela},
  doi          = {10.3389/frai.2025.1668700},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1668700},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting BRICS NIFTY50 returns using XAI and S.A.F.E AI lens},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-enhanced reconstruction as plug-in defenders against adversarial perturbations. <em>FRAI</em>, <em>8</em>, 1665106. (<a href='https://doi.org/10.3389/frai.2025.1665106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are susceptible to adversarial examples. In large-scale deployed services, plug-in defenders efficiently defend against such attacks. Plug-in defenders take two approaches to mitigate adversarial effects: input reconstruction and random transformations. Existing plug-in defense lacks diversity in transformation formulation due to the inherent feature preservation nature, which leads to vulnerability under adaptive attacks. To address this issue, we propose a novel plug-in defense named Diversity-enhanced Reconstruction (DeR). DeR counters adversarial attacks by frequency-aware reconstructors with enhanced diversity. Specifically, we design the reconstructors as a U-Net backbone with additional frequency components. The reconstructors are trained on the proposed DeR loss, which optimizes the reconstruction and diversity objectives jointly. Once trained, DeR can produce heterogeneous gradients and be applied as a plug-in defense. We conduct extensive experiments on three datasets and four classifier architectures under strict adversarial settings. The results demonstrate the superior robustness of DeR compared to state-of-the-art plug-in defense and the efficiency of DeR in real-time processing.},
  archive      = {J_FRAI},
  author       = {Pang, Zeshan and Yan, Xuehu and Guo, Shasha and Lu, Yuliang},
  doi          = {10.3389/frai.2025.1665106},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1665106},
  shortjournal = {Front. Artif. Intell.},
  title        = {Diversity-enhanced reconstruction as plug-in defenders against adversarial perturbations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive noise-augmented attention for enhancing transformer fine-tuning on longitudinal medical data. <em>FRAI</em>, <em>8</em>, 1663484. (<a href='https://doi.org/10.3389/frai.2025.1663484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer models pre-trained on self-supervised tasks and fine-tuned on downstream objectives have achieved remarkable results across a variety of domains. However, fine-tuning these models for clinical predictions from longitudinal medical data, such as electronic health records (EHR), remains challenging due to limited labeled data and the complex, event-driven nature of medical sequences. While self-attention mechanisms are powerful for capturing relationships within sequences, they may underperform when modeling subtle dependencies between sparse clinical events under limited supervision. We introduce a simple yet effective fine-tuning technique, Adaptive Noise-Augmented Attention (ANAA), which injects adaptive noise directly into the self-attention weights and applies a 2D Gaussian kernel to smooth the resulting attention maps. This mechanism broadens the attention distribution across tokens while refining it to emphasize more informative events. Unlike prior approaches that require expensive modifications to the architecture and pre-training phase, ANAA operates entirely during fine-tuning. Empirical results across multiple clinical prediction tasks demonstrate consistent performance improvements. Furthermore, we analyze how ANAA shapes the learned attention behavior, offering interpretable insights into the model's handling of temporal dependencies in EHR data.},
  archive      = {J_FRAI},
  author       = {Amirahmadi, Ali and Etminani, Farzaneh and Ohlsson, Mattias},
  doi          = {10.3389/frai.2025.1663484},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1663484},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptive noise-augmented attention for enhancing transformer fine-tuning on longitudinal medical data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting offer burden to optimize batch sizes in simultaneously expiring kidney offers. <em>FRAI</em>, <em>8</em>, 1662960. (<a href='https://doi.org/10.3389/frai.2025.1662960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundTimely and efficient allocation of deceased donor kidneys is a persistent challenge in transplantation. Traditional sequential offer systems often lead to extended delays and high nonuse rates, as many kidneys undergo multiple refusals before being accepted. Simultaneously expiring offers, where a kidney is offered to a batch of centers with synchronized response deadlines, offer a more efficient alternative. However, fixed batch sizes fail to account for variability in offer requirements, potentially introducing new inefficiencies or overwhelming transplant professionals with excessive notifications.MethodsWe investigated the use of machine learning-based survival models to dynamically predict the number of offers a kidney will require before acceptance. Utilizing data on over 16,000 deceased donor kidneys from the national organ offer dataset, we engineered predictive features from both donor profiles and recipient pool characteristics. We trained and evaluated multiple survival models using time-dependent concordance indices along with other survival and regression performance metrics.ResultsThe Random Survival Forest model achieved the best performance, with a time-dependent C-index of 0.882, effectively estimating the required offer volume for kidney placement. Feature importance analysis revealed that waitlist characteristics, such as mean Estimated Post-Transplant Survival (EPTS), mean Calculated Panel Reactive Antibody (CPRA), time on dialysis, and waitlist duration, were among the most influential predictors. When integrated into a dynamic simultaneous offer system, these predictions have the potential to reduce average placement delays from 17.37 h to 1.59 h while maintaining a manageable level of extraneous offers.DiscussionOur results demonstrate that survival-based predictive modeling can meaningfully improve the efficiency of simultaneously expiring offers in kidney allocation. By personalizing batch sizes based on expected offer burden, such models can reduce delays without overwhelming transplant professionals. These findings underscore the value of integrating real-time, data-driven tools into organ allocation systems to improve operational efficiency and facilitate practical implementation.},
  archive      = {J_FRAI},
  author       = {Berry, Sean and Görgülü, Berk and Tunç, Sait and Cevik, Mucahit},
  doi          = {10.3389/frai.2025.1662960},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1662960},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting offer burden to optimize batch sizes in simultaneously expiring kidney offers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using ChatGPT as an assessment tool for medical residents in mexico: A descriptive experience. <em>FRAI</em>, <em>8</em>, 1662203. (<a href='https://doi.org/10.3389/frai.2025.1662203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial intelligence (AI) in medical education has progressed gradually, with numerous authors debating whether to prohibit, restrict, or adopt its use in academic contexts. Growing evidence exists regarding the capabilities and applications of AI in this field, particularly in supporting educational tasks such as student assessment. In this article we described our experience using ChatGPT to evaluate medical residents.Materials and methodsA descriptive cross-sectional study was conducted involving 35 medical residents from different specialty’s at a secondary-level hospital. Two different exams were generated using ChatGPT in topics of Rocky Mountain Spotted Fever (RMSF) and Pertussis. Additionally, an opinion survey—previously validated was administered to assess participants’ perceptions of ChatGPT ability to generate multiple-choice questions.ResultsOverall average score for the Pertussis examination was 8.46, while the average for the RMSF examination was 8.29. All participants reported that the examination was well written and that the language used was coherent; 34 residents (97.14%) stated that the language was clear, concise, and easy to understand; 9 residents (25.71%) agreed that the language used was confusing; 33 residents (94.28%) rated the exams questions as difficult; 32 residents (91.42%) felt that they had adequately prepared for both examinations.DiscussionChatGPT exhibits a promising faculty as a tool to support teaching activities in the training of medical specialists, mainly in reducing the human workload of healthcare personnel, and becoming integral to the next phase of medical education through AI-assisted content creation supervised by educators.},
  archive      = {J_FRAI},
  author       = {Rivera-Rosas, Cristian N. and Calleja-López, J. R. Tadeo and Larios-Camacho, Sandra J. and Trujillo-López, Sergio},
  doi          = {10.3389/frai.2025.1662203},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1662203},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using ChatGPT as an assessment tool for medical residents in mexico: A descriptive experience},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-dialectal arabic translation: Comparative analysis on large language models. <em>FRAI</em>, <em>8</em>, 1661789. (<a href='https://doi.org/10.3389/frai.2025.1661789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionExploring Arabic dialects in Natural Language Processing (NLP) is essential to understand linguistic variation and meet regional communication demands. Recent advances in Large Language Models (LLMs) have opened up new vistas for multilingual communication and text generation.MethodsThis paper investigates the performance of GPT-3.5, GPT-4, and Bard (Gemini) on the QADI and MADAR datasets, while GPT-5 was evaluated exclusively on MADAR encompassing over 15 different countries. Several metrics have been used in the evaluation, such as cosine similarity, universal similarity encoder, sentence BERT, TER, ROUGE, and BLEU. In this study, different prompting techniques were used: zero-shot and few-shot. Zero-shot was employed for all dialects, and few-shot was employed only for the least translation performance dialect, Tunisian.ResultsAnalysis revealed that in the QADI dataset, GPT-4 significantly outperformed others in translating MSA to DA, with ANOVA tests showing strong significance (p < 0.05) in most metrics, except for BLEU and TER where it does not show significance, indicating comparable translation performance among models. Furthermore, GPT-4 was highest in semantic similarity compared to GPT-3.5 and Bard (Gemini), 0.66, 0.61, and 0.63, respectively. GPT-4 was the best in identifying overlapping sentences (i.e., those where the source and target are identical) with a combined average of 0.41 in BLEU and ROUGE-L. All LLMs scored TER values between 6% and 25%, indicating generally good translation quality. However, GPT models, especially GPT-5, responded better to prompting and translation to Levant countries compared to Bard (Gemini). For the MADAR dataset, no significant translation differences were observed in sentence-BERT, ROUGE-L, and TER, while differences are identified in cosine similarity, BLEU, and universal similarity encoder metrics. Therefore, GPT-5 is the top performer in identifying sentence overlaps measured by BLEU and ROUGE-L (combined average 0.37).DiscussionThe few-shot approach did not show a significant improvement in translation performance, especially for GPT-4 and Bard (Gemini), while GPT-3.5 performed consistently. Zero-shot prompts were effective across dialects, while few-shot prompting, applied to the weakest-performing dialect (Tunisian), did not yield improvement. GPT-4 and Bard performed worse under this set-up, while GPT-3.5 remained consistent.},
  archive      = {J_FRAI},
  author       = {Beidas, Ayah and Mohi, Kousar and Ghaddar, Fatme and Ahmad, Imtiaz and Abed, Sa'Ed},
  doi          = {10.3389/frai.2025.1661789},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1661789},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cross-dialectal arabic translation: Comparative analysis on large language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence as a tool to enhance social interventions in reducing crime. <em>FRAI</em>, <em>8</em>, 1661266. (<a href='https://doi.org/10.3389/frai.2025.1661266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study explores the significant role of artificial intelligence (AI) in crime reduction, identifies the main challenges hindering its implementation, and examines differences in coping strategies between individuals in Jordan and Saudi Arabia.MethodsThe research surveyed 170 AI professionals, equally divided between the two countries, with an average age of 45.2 years. Data were collected using a specially designed questionnaire assessing perceptions of AI, barriers to adoption, and coping mechanisms.ResultsThe findings indicated that AI plays a significant role in crime reduction. High levels of challenges were reported in implementing AI, and coping strategies related to AI in crime reduction were also assessed at a high level. No statistically significant differences were found in the level of challenges facing AI between Jordanian and Saudi participants.DiscussionThis research contributes to understanding AI’s practical applications in crime prevention and provides valuable insights for policymakers to strengthen AI adoption and overcome existing barriers in the region.},
  archive      = {J_FRAI},
  author       = {Tarawneh, Haya H. and Halalsheh, Niveen and Sulaiman, Bahjat Abu and Alhajjaj, Huda and Atieh, Nesreen N.},
  doi          = {10.3389/frai.2025.1661266},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1661266},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence as a tool to enhance social interventions in reducing crime},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in traditional medicine: Evidence, barriers, and a research roadmap for personalized care. <em>FRAI</em>, <em>8</em>, 1659338. (<a href='https://doi.org/10.3389/frai.2025.1659338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundTraditional medicine (TM) systems such as Ayurveda, Traditional Chinese Medicine (TCM), and Thai Traditional Medicine (TTM) are increasingly intersecting with artificial intelligence (AI).ObjectiveTo synthesize how AI is currently applied to TM and to outline barriers and research needs for safe, equitable, and scalable adoption.MethodsWe conducted a targeted narrative mini review of peer reviewed studies (2017–Aug 2025) retrieved from PubMed, Scopus, and Google Scholar using terms spanning TM (Ayurveda/TCM/TTM) and AI (machine learning (ML), natural language processing (NLP), computer vision, telemedicine. Inclusion favored studies with reported methods and, when available, performance metrics; commentary and preprints without data were excluded.FindingsCurrent evidence supports AI assisted diagnostic pattern recognition, personalization frameworks integrating multi source data, digital preservation of TM knowledge, telemedicine enablement, and AI supported herbal pharmacology and safety assessment. Reported performance varies and is context dependent, with limited prospective external validation.LimitationsEvidence heterogeneity, small datasets, inconsistent ontologies across TM systems, and nascent regulatory pathways constrain real world deployment.ConclusionAI can augment TM education, research, and clinical services, but progress requires standards, culturally informed datasets, prospective trials, and clear governance. We propose a research roadmap to guide rigorous and ethical integration.},
  archive      = {J_FRAI},
  author       = {Jongjiamdee, Ketmanee and Pornwonglert, Pimnipa and Na Bangchang, Nutnichar and Akarasereenont, Pravit},
  doi          = {10.3389/frai.2025.1659338},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1659338},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence in traditional medicine: Evidence, barriers, and a research roadmap for personalized care},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI competence and sentiment: A mixed-methods study of attitudes and open-ended reflections. <em>FRAI</em>, <em>8</em>, 1658791. (<a href='https://doi.org/10.3389/frai.2025.1658791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) technologies become increasingly integrated into everyday life, understanding how the public perceives and interacts with AI is essential for fostering responsible and secure adoption. This study investigates the relationship between self-assessed AI competence, trust in AI-generated content, and sentiment toward AI among public and private sector employees in Latvia. Using a mixed-methods approach, the research combines quantitative survey data with open-ended qualitative responses to explore how demographic factors influence AI-related perceptions. Results reveal that although participants rate their AI competence and trust relatively highly, a significant portion of respondents either do not use AI or use it only for simple tasks. Sentiment toward AI is generally positive but often neutral, indicating that public attitudes are still forming. Statistically significant differences in AI competence were found across gender, age, and work sector, while trust in AI varied by education and age. Sentiment remained consistent across groups. Importantly, AI competence was positively correlated with trust, which in turn correlated with sentiment. Thematic analysis identified concerns about risk assessment, ethical implications, and the uncertain role of AI in daily life. The study underscores the need to enhance AI literacy and critical evaluation skills to ensure informed trust and societal resilience. These findings inform future strategies for public education, workforce training, and digital security policy in the context of accelerating AI adoption.},
  archive      = {J_FRAI},
  author       = {Lāma, Gatis and Lastovska, Agnese},
  doi          = {10.3389/frai.2025.1658791},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1658791},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI competence and sentiment: A mixed-methods study of attitudes and open-ended reflections},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accuracy of AI chatbots in answering frequently asked questions on cervical cancer. <em>FRAI</em>, <em>8</em>, 1655303. (<a href='https://doi.org/10.3389/frai.2025.1655303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveTo compare the accuracy of Deepseek and ChatGPT in answering frequently asked questions (FAQs) about cervical cancer.MethodsTo compile a list of FAQs concerning cervical cancer, a comprehensive search was conducted on social media and community platforms. The answer keys for all the selected questions were created on the basis of the guidelines of the National Comprehensive Cancer Network (NCCN), the International Federation of Gynecology and Obstetrics (FIGO), and the World Health Organization (WHO) for cervical cancer. The answers given by Deepseek-R1 and ChatGPT O1 were scored according to the Global Quality Score (GQS).ResultsA total of 74 FAQs covered a diverse range of topics related to cervical cancer, including diagnosis (n = 16), risk factors and epidemiology (n = 19), treatment (n = 20), and prevention (n = 19). When all the answers provided by DeepSeek to the FAQs about cervical cancer according to the GQS were evaluated, 68 answers were rated as score five, 4 answers were rated as score four, and 2 answers were rated as score three. For ChatGPT’s responses to the same set of FAQs, 67 answers were classified as score five, 6 answers were classified as score four, and 1 answer was classified as score three. There was no statistically significant difference between the two groups (p > 0.05).ConclusionBoth DeepSeek and ChatGPT demonstrated accurate and satisfactory responses to FAQs about cervical cancer when evaluated according to the GQS. However, in regard to treatment issues, a cautious attitude should be maintained. Compared to ChatGPT, DeepSeek stands out for its free availability, which makes it more accessible in resource-limited scenarios to the public.},
  archive      = {J_FRAI},
  author       = {Fan, Jielin and Xiao, Wenhong and Yan, Zhipeng and Ouyang, Qiang},
  doi          = {10.3389/frai.2025.1655303},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1655303},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accuracy of AI chatbots in answering frequently asked questions on cervical cancer},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale and deeply supervised network for image splicing localization. <em>FRAI</em>, <em>8</em>, 1655073. (<a href='https://doi.org/10.3389/frai.2025.1655073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When maliciously tampered images are disseminated in the media, they can potentially cause adverse effects and even jeopardize national security. Therefore, it is necessary to investigate effective methods to detect tampered images. As a challenging task, the localization of image splicing tampering investigates whether an image contains tampered regions spliced from another image. Given the lack of global information interactions in existing methods, a multi-scale, deeply supervised image splicing tampering localization network is proposed. The proposed network is based on an encoder–decoder architecture, where the decoder uses different levels of feature maps to supervise the locations of splicing, enabling pixel-wise prediction of tampered regions. Moreover, a multi-scale feature extraction module is utilized between the encoder and decoder, which expands the global view of the network, thereby enabling more effective differentiation between tampered and non-tampered regions. F1 scores of 0.891 and 0.864 were achieved using the CASIA and COLUMB datasets, respectively; and the proposed model was able to accurately locate tampered regions.},
  archive      = {J_FRAI},
  author       = {Qin, Sheng and Liang, Ce and Luo, Yuling and Liu, Junxiu and Fu, Qiang and Ouyang, Xue},
  doi          = {10.3389/frai.2025.1655073},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1655073},
  shortjournal = {Front. Artif. Intell.},
  title        = {Multi-scale and deeply supervised network for image splicing localization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging pre-trained embeddings in an ensemble machine learning approach for arabic sentiment analysis. <em>FRAI</em>, <em>8</em>, 1653728. (<a href='https://doi.org/10.3389/frai.2025.1653728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArabic sentiment analysis presents unique challenges due to the linguistic complexity of the language, including its wide range of dialects, orthographic ambiguity, and limited language resources. Addressing these issues is essential to develop robust sentiment classification systems.MethodsThis study investigates the application of ensemble machine learning methods for Arabic sentiment analysis. Several homogeneous ensemble techniques are implemented and evaluated on two datasets: the balanced ArTwitter dataset and the highly imbalanced Syria_Tweets dataset. To mitigate class imbalance, the Synthetic Minority Over-sampling Technique (SMOTE) is employed. The models incorporate pre-trained word embeddings and unigram features.ResultsExperimental results indicate that individual classifiers using pre-trained embeddings achieve strong performance; however, ensemble models consistently yield superior outcomes. On the ArTwitter dataset, the ensemble of Naive Bayes, Support Vector Machine, and Decision Tree classifiers achieved an accuracy of 90.22% and an F1-score of 92.0%. On the Syria_Tweets dataset, an ensemble combining Stochastic Gradient Descent, k-Nearest Neighbors, and Random Forest attained 83.82% accuracy and an 83.86% F1-score.DiscussionThe findings highlight the effectiveness of ensemble learning in enhancing the robustness and generalizability of Arabic sentiment analysis systems. Incorporating pre-trained embeddings further strengthens performance, demonstrating that ensemble-based approaches can overcome challenges posed by linguistic complexity and dataset imbalance in Arabic natural language processing tasks.},
  archive      = {J_FRAI},
  author       = {Jaber, Areej and Bahati, Israa and Martínez, Paloma},
  doi          = {10.3389/frai.2025.1653728},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1653728},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging pre-trained embeddings in an ensemble machine learning approach for arabic sentiment analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy-adaptive differential privacy federated learning for student performance prediction and privacy protection: A case study in python programming. <em>FRAI</em>, <em>8</em>, 1653437. (<a href='https://doi.org/10.3389/frai.2025.1653437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the digital transformation of engineering education, protecting student data privacy has become a key challenge for enabling data-driven instruction. This study proposes an Entropy-Adaptive Differential Privacy Federated Learning method (EADP-FedAvg) to enhance the accuracy of student performance prediction while ensuring data privacy. Based on online test records from Python programming courses for Electronic Engineering students (grade 2021–2023) at the School of Physics and Optoelectronic Technology, Baoji University of Arts and Sciences, China, the study uses a Multilayer Perceptron (MLP) model and 10 distributed clients for training. Under different privacy budgets (ε = 0.1, 1e-6, and 1.0), EADP-FedAvg achieves a test accuracy of 92.7%, macro-average score of 92.1%, and entropy of 0.207, outperforming standard federated learning and approaching centralized learning performance. The results demonstrate that by adaptively adjusting the noise level based on output entropy, EADP-FedAvg effectively balances privacy preservation and model accuracy. This method offers a novel solution for analyzing privacy-sensitive educational data in engineering education.},
  archive      = {J_FRAI},
  author       = {Chen, Shanwei and Qi, Xiuzhi},
  doi          = {10.3389/frai.2025.1653437},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1653437},
  shortjournal = {Front. Artif. Intell.},
  title        = {Entropy-adaptive differential privacy federated learning for student performance prediction and privacy protection: A case study in python programming},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting pediatric diagnostic imaging patient no-show and extended wait-times using LLMs, regression, and tree based models. <em>FRAI</em>, <em>8</em>, 1652397. (<a href='https://doi.org/10.3389/frai.2025.1652397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPatients missing their appointments (no-shows) are a persistent issue that results in idle resources while delaying critical patient prognosis. Likewise, long waiting times increase frustration for patients, leaving a negative impression on the appointment. In this paper, we explore 3 modalities of diagnostic and interventional radiology appointments for pediatric patients at the Hospital for Sick Children (SickKids), Toronto, ON, Canada. Our goal was to survey machine learning methods that best predict the risk of patient no-shows and long wait-times exceeding 1 hour for scheduling teams to propose targeted downstream accommodations.MethodsWe experimented with 6 predictive model types separately trained on both tasks which included extreme gradient boosting (XGBoost), Random Forest (RF), Support Vector Machine, Logistic Regression, Artificial Neural Network, and a pre-trained large language model (LLM). Utilizing 20 features containing a mixture of patient demographics and appointment related data, we experimented with different data balancing methods including instance hardness threshold (IHT) and class weighting to reduce bias in prediction. We then conducted a comparative study of the improvements made by utilizing continuous contextual data in our LLM which boasted a 51% improvement in F1 score for the wait-time model.ResultsOur XGBoost model had the best combination of AUC and F1 scores (0.96 and 0.62, respectively) for predicting no-show while RF had the best AUC and F1 scores (0.83 and 0.61, respectively) for wait-time prediction. The LLMs also performed well for 90% probability thresholds (high risk patients) while being robustly calibrated on unseen test data.DiscussionOur results surveyed multiple algorithms and data balancing methods to propose the greatest performing models on our tasks, implemented a unique methodology to use LLMs on heterogeneous data within this domain, and demonstrated the greater importance of contextual appointment data over patient demographic features for a more equitable prediction algorithm. Going forward, the predictive output (calibrated probabilities of events) can be used as stochastic input for risk-based optimized scheduling to provide accommodation for patients less likely to receive quality access to healthcare.},
  archive      = {J_FRAI},
  author       = {Rafique, Daniel and Liu, Xuan and Gong, Bo and Belsito, Laura and McCradden, Melissa D. and Mazwi, Mjaye L. and Lee, Wayne and Ohanlon, Graham and Tsang, Kyle and Shroff, Manohar and Ertl-Wagner, Birgit and Khalvati, Farzad},
  doi          = {10.3389/frai.2025.1652397},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1652397},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting pediatric diagnostic imaging patient no-show and extended wait-times using LLMs, regression, and tree based models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on intelligent matching of students’ learning ability and healthcare job market demand based on industrial engineering expertise graph. <em>FRAI</em>, <em>8</em>, 1650095. (<a href='https://doi.org/10.3389/frai.2025.1650095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China, there is a structural mismatch between the job market and student employment, characterized by “unfilled jobs” and “unqualified candidates,” particularly between the industrial engineering (IE) profession and the healthcare services sector. Expertise graphs are designed to identify the logical connections between academic disciplines and job market needs, linking students’ knowledge and skills with job requirements. This approach provides a systematic and visual alignment between students’ learning outcomes and job market demands, addressing the mismatch. However, current expertise graphs have not effectively captured the intrinsic connection between students’ learning abilities and healthcare job market demands. Additionally, research on intelligent matching and the construction of knowledge graphs for IE remains limited. This study aims to bridge this gap and alleviate the structural mismatch between the healthcare job market and student employment in China. First, an expertise graph for IE is developed, covering both expertise and healthcare job requirements. A multi-layer fusion information extraction model, combining BERT, BiLSTM, and GCN, is then proposed for knowledge extraction. An employment matching algorithm is introduced to extract healthcare job titles and requirements from the knowledge graph, calculate similarity with students’ overall ability scores, and recommend suitable positions. Finally, a case study demonstrates that the algorithm accurately analyzes students’ ability scores and successfully matches IE majors with relevant healthcare job positions, validating its effectiveness. This study aims to mitigate the structural mismatch between the healthcare job market and student employment, providing high-quality IE talent to medical services, which has significant scientific and practical value.},
  archive      = {J_FRAI},
  author       = {Xiao, Yan and Zeng, Lingtao and Yang, Jie and Wang, Mini Han and Lin, Zhiyuan and Li, Wei},
  doi          = {10.3389/frai.2025.1650095},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1650095},
  shortjournal = {Front. Artif. Intell.},
  title        = {Research on intelligent matching of students’ learning ability and healthcare job market demand based on industrial engineering expertise graph},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ethical prompting: Toward strategies for rapid and inclusive assistance in dual-use AI systems. <em>FRAI</em>, <em>8</em>, 1646444. (<a href='https://doi.org/10.3389/frai.2025.1646444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring technologies initially developed for individuals with disabilities carry inherent dual-use risks, especially evident in conflict or emergency scenarios. This article examines the dual-use dilemma posed by technologies whose civilian design objectives can unintentionally facilitate harmful applications in defense contexts. Specifically, we analyze the ethical risks associated with using civilian-generated data and systems, originally intended to enhance care and assistance, for military purposes without adequate safeguards. We argue that effective and ethically sound technological infrastructures require optimized and ethically-informed prompting strategies. These strategies must clearly define how data and system prompts are structured, reducing deployment biases, particularly against vulnerable populations.},
  archive      = {J_FRAI},
  author       = {Farnós, Joan and Sans Pinillos, Alger and Costa, Vicent},
  doi          = {10.3389/frai.2025.1646444},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1646444},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ethical prompting: Toward strategies for rapid and inclusive assistance in dual-use AI systems},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weight-aware semi-supervised self-ensembling framework for interior decoration style classification. <em>FRAI</em>, <em>8</em>, 1645877. (<a href='https://doi.org/10.3389/frai.2025.1645877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic classification of interior decoration styles has great potential to guide and streamline the design process. Despite recent advancements, it remains challenging to construct an accurate interior decoration style recognition model due to the scarcity of expert annotations. In this article, we develop a new weight-aware semi-supervised self-ensembling framework for interior decoration style recognition, which selectively leverages the abundant unlabeled data to address the aforementioned challenge. Specifically, we devise a weight module that utilizes a truncated Gaussian function to automatically assess the reliability of unlabeled data. This enables more reliable unlabeled samples to be adaptively assigned higher weights during the training process. By incorporating adaptive weights, we devise a weighted consistency regularization to enforce consistent predictions for reliable unlabeled data under different perturbations. Furthermore, we devise a weighted relation consistency regularization to preserve the semantic relationships of reliable unlabeled data across various perturbations. Additionally, we introduce a weighted class-aware contrastive learning regularization to improve the model's discriminative feature learning capability using reliable unlabeled data. The synergistic learning of weighted consistency regularization, weighted relation consistency, and weighted class-aware contrastive learning significantly enhances the model's generalizability. Extensive experiments conducted on interior decoration style image datasets demonstrate the superior performance of our framework compared to existing semi-supervised learning methods.},
  archive      = {J_FRAI},
  author       = {Guo, Lichun and Zeng, Hao and Wang, Junliang and Liang, Shuang and Hang, Wenlong},
  doi          = {10.3389/frai.2025.1645877},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1645877},
  shortjournal = {Front. Artif. Intell.},
  title        = {Weight-aware semi-supervised self-ensembling framework for interior decoration style classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI for scientific integrity: Detecting ethical breaches, errors, and misconduct in manuscripts. <em>FRAI</em>, <em>8</em>, 1644098. (<a href='https://doi.org/10.3389/frai.2025.1644098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Generative AI (GenAI) in scientific writing has grown rapidly, offering tools for manuscript drafting, literature summarization, and data analysis. However, these benefits are accompanied by risks, including undisclosed AI authorship, manipulated content, and the emergence of papermills. This perspective examines two key strategies for maintaining research integrity in the GenAI era: (1) detecting unethical or inappropriate use of GenAI in scientific manuscripts and (2) using AI tools to identify mistakes in scientific literature, such as statistical errors, image manipulation, and incorrect citations. We reviewed the capabilities and limitations of existing AI detectors designed to differentiate human-written (HWT) from machine-generated text (MGT), highlighting performance gaps, genre sensitivity, and vulnerability to adversarial attacks. We also investigate emerging AI-powered systems aimed at identifying errors in published research, including tools for statistical verification, citation validation, and image manipulation detection. Additionally, we discuss recent publishing industry initiatives to AI-driven papermills. Our investigation shows that these developments are not yet sufficiently accurate or reliable yet for use in academic assessment, they mark an early but promising steps toward scalable, AI-assisted quality control in scholarly publishing.},
  archive      = {J_FRAI},
  author       = {Pellegrina, Diogo and Helmy, Mohamed},
  doi          = {10.3389/frai.2025.1644098},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1644098},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI for scientific integrity: Detecting ethical breaches, errors, and misconduct in manuscripts},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-, linguistic-, and information-preserving synthesis of clinical documentation through generative agents. <em>FRAI</em>, <em>8</em>, 1644084. (<a href='https://doi.org/10.3389/frai.2025.1644084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of generative agents (GAs) is reshaping the healthcare landscape. Nonetheless, broad utilization is impeded by restricted access to high-quality, interoperable clinical documentation from electronic health records (EHRs) due to persistent legal, ethical, and technical barriers. Synthetic health data generation (SHDG), leveraging pre-trained large language models (LLMs) instantiated as GAs, could offer a practical solution by creating synthetic patient information that mimics genuine EHRs. The use of LLMs, however, is not without issues; significant concerns remain regarding privacy, potential bias propagation, the risk of generating inaccurate or misleading content, and the lack of transparency in how these models make decisions. We therefore propose a privacy-, linguistic-, and information-preserving SHDG protocol that employs multiple context-aware, role-specific GAs. Guided by targeted prompting and authentic EHRs—serving as structural and linguistic templates—role-specific GAs can, in principle, operate collaboratively through multi-turn interactions. We theorized that utilizing GAs in this fashion permits LLMs not only to produce synthetic EHRs that are accurate, consistent, and contextually appropriate, but also to expose the underlying decision-making process. To test this hypothesis, we developed a no-code GA-driven SHDG workflow as a proof of concept, which was implemented within a predefined, multi-layered data science infrastructure (DSI) stack—an integrated ensemble of software and hardware designed to support rapid prototyping and deployment. The DSI stack streamlines implementation for healthcare professionals, improving accessibility, usability, and cybersecurity. To deploy and validate GA-assisted workflows, we implemented a fully automated SHDG evaluation framework—co-developed with GenAI technology—which holistically compares the informational and linguistic features of synthetic, anonymized, and real EHRs at both the document and corpus levels. Our findings highlight that SHDG implemented through GAs offers a scalable, transparent, and reproducible methodology for unlocking the potential of clinical documentation to drive innovation, accelerate research, and advance the development of learning health systems. The source code, synthetic datasets, toolchains and prompts created for this study can be accessed at the GitHub repository: https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/Generative_Agent_based_Data-Synthesis.},
  archive      = {J_FRAI},
  author       = {van Velzen, Mark and van der Willigen, Robert F. and de Beer, Vincent J. and de Graaf-Waar, Helen I. and Janssen, Esther R. C. and van Leeuwen, Sjemaine and van der Willigen, Micha F. and van der Willigen, Martijn J. and Renardus, Gavin and El Maaroufi, Rayan and Satimin, Sven J. and Hartog, Larissa M. and Hulsen, Tim and van Meeteren, Nico L. U. and Scheper, Mark C.},
  doi          = {10.3389/frai.2025.1644084},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1644084},
  shortjournal = {Front. Artif. Intell.},
  title        = {Privacy-, linguistic-, and information-preserving synthesis of clinical documentation through generative agents},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence technology application and corporate ESG performance—evidence from national pilot zones for artificial intelligence innovation and application. <em>FRAI</em>, <em>8</em>, 1643684. (<a href='https://doi.org/10.3389/frai.2025.1643684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study empirically examines the impact of artificial intelligence (AI) technology on corporate ESG performance using data from Chinese listed companies from 2011 to 2022 and a multi-period difference-in-differences (DID) model. The results reveal that AI significantly enhances overall corporate ESG performance by alleviating financing constraints, promoting green innovation, and strengthening information disclosure. These effects are particularly pronounced in the environmental (E) and governance (G) dimensions. Further analysis indicates that equity concentration, media attention, and data availability positively moderate the relationship between AI adoption and ESG performance. Based on these findings, this study suggests expanding AI application scenarios to facilitate the formulation of more targeted ESG strategies, deepen the integration of AI and ESG practices, and support high-quality economic development. The conclusions provide theoretical and empirical support for technology-driven corporate sustainable transformation.},
  archive      = {J_FRAI},
  author       = {Xie, Hanjin and Luo, Jiayi and Tan, Xi},
  doi          = {10.3389/frai.2025.1643684},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1643684},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence technology application and corporate ESG performance—evidence from national pilot zones for artificial intelligence innovation and application},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural architecture search applying optimal stopping theory. <em>FRAI</em>, <em>8</em>, 1643088. (<a href='https://doi.org/10.3389/frai.2025.1643088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) exploration requires tremendous amounts of computational power to properly explore. This makes exploration of modern NAS search spaces impractical for researchers due to the infrastructure investments required and the time needed to effectively design, train, validate, and evaluate each architecture within the search space. Based on the fact that early-stopping random search algorithms are competitive against leading NAS methods, this paper explores how much of the search space should be explored by applying various forms of the famous decision-making riddle within optimal stopping theory: the Secretary Problem (SP). A total of 672 unique architectures, each trained and evaluated against the MNIST and CIFAR-10 datasets over 20,000 runs, producing 6,720 trained models confirm theoretically and empirically the need to randomly explore ~37% of the NAS search space until halting can occur for an acceptable discovered neural architecture. Additional extensions of the SP investigated include implementing a “good enough” and a “call back” feature; both further reduce exploration of the NAS search space to ~15 and 4%, respectively. Each of these investigations were further confirmed statistically upon NAS search space populations consisting of 100–3,500 neural architectures increasing in steps of 50, with each population size analyzed over 20,000 runs. The paper details how researchers should implement each of these variants, with caveats, to balance computational resource costs and the desire to conduct sufficient NAS practices in a reasonable timeframe.},
  archive      = {J_FRAI},
  author       = {Sheehan, Matthew and Yakimenko, Oleg},
  doi          = {10.3389/frai.2025.1643088},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1643088},
  shortjournal = {Front. Artif. Intell.},
  title        = {Neural architecture search applying optimal stopping theory},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating LLMs on kazakhstan's mathematics exam for university admission. <em>FRAI</em>, <em>8</em>, 1642570. (<a href='https://doi.org/10.3389/frai.2025.1642570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe rapid advancement of large language models (LLMs) has prompted their exploration in educational contexts, particularly in high-stakes standardized tests such as Kazakhstan's Unified National Testing (UNT) mathematics component, which is critical for university admission. While most existing benchmarks for mathematical reasoning focus on English, concerns remain that LLMs may underperform in under-resourced or non-English languages. This study addresses this gap by evaluating LLM performance on a math test administered entirely in Russian.MethodsWe assessed six LLMs-Claude, DeepSeek, Gemini, Llama, Qwen, and o-on UNT multiple-choice mathematics questions covering algebra, functions, geometry, inequalities, and trigonometry. Three evaluation conditions were employed: (1) zero-shot performance, (2) hybrid integration with SymPy for symbolic computation, and (3) a role-specific simulated multi-agent refinement framework that builds on existing self-correction techniques with targeted feedback.ResultsIn zero-shot settings, DeepSeek, Gemini, Qwen, and o achieved near-perfect or perfect accuracy (X-Y%) across all difficulty levels and topics, while Claude and Llama lagged (A-B%). The hybrid approach significantly improved Claude and Llama's accuracy by C% and D%, respectively. Under the multi-agent refinement condition, Claude showed substantial gains, reaching E% accuracy, which represented a F% improvement over zero-shot performance.DiscussionThese findings provide important empirical evidence that LLMs can perform competitively on mathematics tasks in non-English languages. The results challenge prior assumptions about limited performance in under-resourced linguistic settings and highlight the potential of LLMs to support bilingual education and promote equitable access to higher education.},
  archive      = {J_FRAI},
  author       = {Kadyrov, Shirali and Abdrasilov, Bolatbek and Sabyrov, Aslan and Baizhanov, Nurseit and Makhmutova, Alfira and Kyllonen, Patrick C.},
  doi          = {10.3389/frai.2025.1642570},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1642570},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating LLMs on kazakhstan's mathematics exam for university admission},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating a retrieval-augmented pregnancy chatbot: A comprehensibility–accuracy-readability study of the DIAN AI assistant. <em>FRAI</em>, <em>8</em>, 1640994. (<a href='https://doi.org/10.3389/frai.2025.1640994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPatient education materials (PEMs) often exceed common health literacy levels. Retrieval-augmented conversational AI may deliver interactive, evidence-grounded explanations tailored to user needs. We evaluated DIAN, a RAG-enabled pregnancy chatbot grounded in the NHS Pregnancy Book, using a comprehensibility–accuracy–readability (CAR) framework to compare perceptions between women and clinicians across key perinatal domains.MethodsWe conducted a cross-sectional evaluation with standardized prompts and blinded scoring. Participants were 119 women (18–55 years) and 29 clinicians. After brief CAR training and calibration, all evaluators independently rated the same DIAN responses on 4-point Likert scales across postpartum care, pregnancy health and complications, diet and nutrition, and mental and emotional wellbeing. Between-group differences were tested using the Mann–Whitney U test with Bonferroni adjustment across domains per outcome; effect sizes were summarized with r = |Z|/√N and Cliff’s delta. Inter-rater reliability was not estimated, given the independent-rater design.ResultsDifferences concentrated in postpartum care. Comprehensibility favored women (U = 1206.50, Z = −2.524, p = 0.012; r = 0.207; Δ = 0.301). Accuracy also favored women (U = 1239.00, Z = −2.370, p = 0.018; r = 0.195; Δ = 0.282). Readability favored clinicians (U = 1181.50, Z = −2.639, p = 0.008; r = 0.217; Δ = 0.315). Other domains showed no significant between-group differences after correction. Radar visualizations mirrored these patterns, with women showing larger comprehensibility/accuracy profiles and clinicians showing larger readability profiles in postpartum care.DiscussionGrounded in an authoritative national guide, DIAN achieved broadly comparable CAR perceptions across groups, with clinically relevant divergence limited to postpartum care. Women perceived higher comprehensibility and accuracy, while clinicians judged language more readable, suggesting a gap between experiential clarity and professional textual ease. Targeted postpartum refinement, lexical simplification, role-tailored summaries, and actionable checklists may align perceptions without compromising fidelity. More broadly, RAG-grounded chatbots can support equitable digital health education when content is vetted, updated, and evaluated with stakeholder-centered metrics. Future work should examine free-form interactions, longitudinal behavioral outcomes, and ethical safeguards (scope-of-use messaging, escalation pathways, and bias audits).},
  archive      = {J_FRAI},
  author       = {Valan, P. and Venugopal, Pulidindi},
  doi          = {10.3389/frai.2025.1640994},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1640994},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating a retrieval-augmented pregnancy chatbot: A comprehensibility–accuracy-readability study of the DIAN AI assistant},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing training of time series diffusion models via similarity score functions: Application to cyclic and acyclic motion with IMU data. <em>FRAI</em>, <em>8</em>, 1640948. (<a href='https://doi.org/10.3389/frai.2025.1640948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDenoising diffusion probabilistic models have shown the capability to generate synthetic sensor signals. These models rely on a loss function that measures the difference between the noise added during the forward process and the noise predicted by the diffusion model, thereby enabling realistic data generation. However, the stochastic nature of the process and the loss function complicate the estimation of data quality.MethodsTo address this issue, we evaluated multiple similarity metrics and adapted an existing metric to monitor both the training and data synthesis processes. The adapted metric was further fine-tuned on the input data to align with the requirements of a downstream classification task.ResultsBy incorporating the adapted metric, we significantly reduced the number of training epochs required without observing performance degradation in the classification task.DiscussionOur findings demonstrate that optimizing the training process using similarity metrics not only conserves computational resources but also shortens the training time for generative models, making them more efficient and practical for real-world applications.},
  archive      = {J_FRAI},
  author       = {Oppel, Heiko and Spilz, Andreas and Munz, Michael},
  doi          = {10.3389/frai.2025.1640948},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1640948},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimizing training of time series diffusion models via similarity score functions: Application to cyclic and acyclic motion with IMU data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data quality challenges of AIGC application in smart agriculture. <em>FRAI</em>, <em>8</em>, 1640805. (<a href='https://doi.org/10.3389/frai.2025.1640805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, China’s agricultural development has gradually shifted from digital agriculture to smart agriculture. At the same time, with the participation of AIGC, the decision-making system of smart agriculture is also facing numerous data challenges. In this study, we employed a comprehensive quality improvement approach to ad-dress these challenges. The methodology involves three phases: (1) Detection and removal of data noise through advanced cleaning techniques and preprocessing methods; (2) Unified data standards and formats to ensure seamless integration across di-verse data sources; and (3) Strengthening agricultural infrastructure to prevent data islands and promote equitable data distribution. Our analysis reveals that data noise significantly impacts precision agriculture, leading to biased decisions and resource wastage. Data fog, resulting from heterogeneous data sources and weak inter-source correlations, complicates decision-making processes. Additionally, data islands hinder data sharing and integration, exacerbated by uneven data development across regions. Systematic implementation of standardized quality control protocols is essential for enhancing smart agricultural systems and ensuring sustainable development. This study offers a novel perspective on enhancing data quality in AIGC-driven smart agriculture by integrating the Juran quality improvement model.},
  archive      = {J_FRAI},
  author       = {Ren, Yingxue and Qu, Yitong and Gao, Runzeng},
  doi          = {10.3389/frai.2025.1640805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1640805},
  shortjournal = {Front. Artif. Intell.},
  title        = {Data quality challenges of AIGC application in smart agriculture},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Profiling investor behavior in the malaysian derivatives market using K-means clustering. <em>FRAI</em>, <em>8</em>, 1640776. (<a href='https://doi.org/10.3389/frai.2025.1640776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the trading behaviors of Malaysian derivatives traders using a comprehensive dataset from Bursa Malaysia with K-means clustering, representing one of the first AI applications to derivatives market segmentation. The analysis encompassed over 11 million trade records for FCPO and FKLI derivatives from January to December 2022. Six key features were engineered to segment derivative traders: Total Number of Trades, Total Traded Amount, Overall Realized Profit, Average ROI, Maximum Account Vintage (trader experience in years), and Median Holding Days (typical position duration). Inverse Hyperbolic Sine transformation was applied to address extreme outliers, ensuring robust feature scaling. K-means clustering identified five distinct profiles: “High-Frequency, High-Risk Derivative Traders with Consistent Losses,” “Conservative, Steady-Growth Derivative Trader,” “High-Frequency, High-Yield Derivative Traders,” “Conservative, Low-Yield Derivative Traders,” and “Cautious, Low-Activity Novice Derivative Traders.” Decision tree classifiers validated these clusters through interpretable splitting conditions. These profiles enable targeted risk management strategies, personalized trading services, and evidence-based regulatory policies for derivatives markets and future research.},
  archive      = {J_FRAI},
  author       = {Tan, Eng Hao Louis and Hamed, Yaman and Daud, Hanita and Abdul Wahab, Mohd Amirul Faiz and Azhar, Ahmad Amirul Adlan and Tan, Sieow Yeek},
  doi          = {10.3389/frai.2025.1640776},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1640776},
  shortjournal = {Front. Artif. Intell.},
  title        = {Profiling investor behavior in the malaysian derivatives market using K-means clustering},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Machine learning for cybersecurity. <em>FRAI</em>, <em>8</em>, 1640609. (<a href='https://doi.org/10.3389/frai.2025.1640609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era where digital transformation is reshaping every aspect of our lives, Cyber-Physical Systems (CPSs) have emerged as integral components of modern critical infrastructure [16,17]. These systems—embedded in power grids, healthcare services, and transportation networks—leverage computer and information technologies (CITs) to streamline operations, improve productivity, and enable seamless communication within and beyond system boundaries. However, as CPSs grow increasingly interconnected, their exposure to cyber threats has escalated, posing significant risks to economic stability and human safety [18, 19]. The growing reliance on Information and Communication Technologies (ICTs) introduces various vulnerabilities, making systems susceptible to data stream manipulation attacks—such as interception, tampering, or deletion—as well as AI-specific threats, including model hijacking, jailbreaking, and data poisoning. These vulnerabilities are particularly troubling in critical infrastructure settings, such as power grids, transportation systems, or healthcare networks, where even minor disruptions can lead to severe consequences [20]. For example, a cyberattack on a smart grid could interrupt electricity supply to thousands of homes or hospitals, impacting emergency services and risking lives [1]. Similarly, interference with autonomous vehicle systems could result in collisions, endangering passengers and pedestrians [2]. The Microsoft Digital Defense Report 2024 revealed that over 600 million cybercriminal and nation-state attacks are detected daily, spanning threats such as ransomware, phishing, and identity-based attacks [115]. The most targeted sectors include Information Technology (24%), Education and Research (21%), and Government (12%). Such scenarios underscore how deeply integrated ICTs are in modern critical infrastructure, and how their compromise can cascade into broader societal harm. In many cases, CPSs not only perform essential operations but also rely on real-time data to make automated decisions. This reliance makes them particularly vulnerable to data integrity attacks, where false or manipulated inputs can lead to incorrect and potentially dangerous actions—like administering incorrect medication in hospitals, redirecting traffic into dangerous routes, or causing costly system downtimes and ransom payments [3,4]. Moreover, as CPSs become more connected through the Internet of Things (IoT), the attack surface expands exponentially [5]. Each connected device represents a potential entry point for attackers, who may exploit unpatched software, weak authentication, or insecure communication protocols. Given the scale and critical nature of these systems, a breach can have far-reaching implications not just for the individual or organization affected, but for public safety, economic stability, and national security. In this context, ensuring the cybersecurity of CPSs has become not just a technical challenge, but a societal imperative [6]. It requires a multi-disciplinary approach involving industrial engineering, computer science, systems design, AI, AI ethics, policy-making, and end-user literacy and awareness. Cybersecurity must be designed into these systems from the ground up, not bolted on as an afterthought. Without proactive efforts to secure CPSs, society risks becoming increasingly vulnerable to cyber threats that could disrupt essential services, erode public trust, and ultimately threaten lives. This special Research Topic brings into focus the transformative potential of Machine Learning (ML) and Artificial Intelligence (AI) in enhancing the cybersecurity of Cyber-Physical Systems (CPSs). As CPSs continue to proliferate across sectors—from smart manufacturing and autonomous vehicles to healthcare and critical infrastructure—they generate vast volumes of heterogeneous and often high-velocity data [7]. This influx of data presents both a challenge and an opportunity: while it can overwhelm traditional security approaches that rely on static rules and manual oversight, it also creates fertile ground for ML and AI algorithms to learn from complex patterns, detect subtle anomalies, and predict potential threats before they materialize. AI is proving to be a powerful tool in cybersecurity, especially for identifying threats hidden within vast datasets. Unlike traditional detection systems, AI can uncover subtle patterns and anomalies. Supervised learning models, trained on labeled attack data, are effective in identifying known threats. Meanwhile, unsupervised techniques like clustering and dimensionality reduction can detect unusual system behavior that may indicate previously unknown attacks. By recognizing deviations from normal activity, these models enhance early warning capabilities and help defend against emerging cyber threats, making ML a crucial asset in the evolving landscape of digital security [8]. AI technologies, especially those involving deep learning and reinforcement learning, offer further enhancements by adapting dynamically to evolving threat landscapes. Moreover, the ability of ML/AI systems to operate autonomously and at scale is crucial in CPS environments where decisions often need to be made in milliseconds. In the case of an autonomous vehicle under attack, for instance, a well-trained ML model holds the potential to significantly enhance the security of control systems by identifying malicious signals in real time. Over recent decades, the effectiveness of AI/ML has been demonstrated in various cybersecurity applications, including intrusion detection systems (IDS), malware classification, phishing detection, and behavioral analytics. These successes point toward a future where AI-and ML-driven security solutions are not merely supportive but integral to the design and operation of CPSs. As such, the integration of ML and AI into CPS cybersecurity is not just an upgrade—it represents a paradigm shift toward intelligent, adaptive, and proactive defense mechanisms. This Research Topic aims to explore and accelerate this shift by gathering innovative research, practical case studies, and interdisciplinary approaches that push the boundaries of what's possible in secure CPS operations. For this research topic, twelve papers were submitted, of which six were accepted. Five of the accepted papers focus on the use of AI to enhance cybersecurity, while one addresses the ethical considerations surrounding AI usage. Collectively, these papers highlight both the critical role of AI in securing cyber-physical systems (CPSs) and the ethical concerns that researchers must be mindful of when developing AI technologies. A high-level summary of the accepted papers is provided below. Protecting digital assets using an ontology-based cyber situational awareness system Cyber situational awareness is essential for the timely detection and mitigation of cybersecurity threats in increasingly complex digital environments. This study [14] presents a intelligent framework that integrates Isolation Forest and autoencoder algorithms with the Structured Threat Information Expression (STIX) standard and ontology-based knowledge modeling to enhance real-time threat detection and cyber threat intelligence. The methodology combines the strengths of Isolation Forest for high-dimensional anomaly detection and autoencoders for nonlinear feature learning, enabling a dual-layered, adaptive anomaly detection system. Threat intelligence is structured using the STIX framework, promoting consistent and dynamic information representation. Additionally, the development of a cybersecurity ontology allows for semantic correlation and contextualization of threat indicators, enriching feature mapping and improving the overall effectiveness of detection. Experimental results validate the efficacy of the proposed approach, achieving 95% accuracy, 99% F1 score, and 94.60% recall, surpassing benchmark models. The integration of STIX and ontological reasoning enhances semantic understanding and standardization of threat data, positioning the framework as a scalable and proactive solution for cyber situational awareness. This research highlights the limitations of existing intelligence and ontology systems in terms of scalability and performance, and addresses the need for domain-specific knowledge representation to support informed risk management. Future work will focus on real-world deployment, optimization, and extension to broader threat scenarios, contributing to the development of adaptive and resilient cybersecurity ecosystems. Explainable correlation-based anomaly detection for Industrial Control Systems Anomaly detection is critical for ensuring the safety and reliability of Industrial Control Systems (ICS), yet current approaches often overlook the intricate temporal and parameter correlations among devices. This study [11] proposes a novel, explainable correlation-based anomaly detection framework designed specifically for ICS environments. By combining Long Short-Term Memory Autoencoders (LSTM-AE) to determine optimal data window sizes with Pearson correlation analysis, a Latent Correlation Matrix (LCM) is constructed to capture meaningful parameter relationships. A Latent Correlation Vector (LCV) derived from the LCM is then modeled using a Multivariate Gaussian Distribution (MGD) to detect anomalies via a threshold mechanism. To enhance model transparency and interpretability, the framework integrates Shapley Additive Explanations (SHAP) for both feature selection and root cause analysis. The proposed method is evaluated on benchmark datasets including SWaT, HIL-HAI, and IoT-Modbus, achieving superior performance with up to 96% precision and 84% F1-score. Beyond anomaly detection, the method effectively identifies root causes, assisting ICS engineers and decision-makers in diagnosing system faults. This resource-efficient approach is tailored for deployment in low-power ICS devices and operates in batch mode for offline analysis. Future work will explore real-time data stream integration, robustness evaluation in real-world scenarios, and the incorporation of advanced deep learning models such as TimesNet. The proposed framework represents a significant step toward interpretable, high-performance anomaly detection in critical industrial environments. Brand advocates—individuals who voluntarily promote brands through positive word-of-mouth—hold significant influence in shaping customer perceptions and driving engagement. However, identifying these advocates accurately within online platforms remains a challenge due to the lack of intelligent systems capable of capturing complex social interactions and credibility cues. This study [12] presents a novel framework that leverages Knowledge Graphs (KGs) and advanced embedding techniques to identify brand advocates with enhanced accuracy and interpretability. The proposed approach constructs a domain-specific KG by integrating extended ontologies and semantic repositories to represent user interactions, preferences, and brand affinities. To ensure authenticity and trustworthiness, they embed a social credibility analysis module, extending the DSpamOnto ontology to detect and filter potential spammers in social commerce contexts. The KG is then transformed into a low-dimensional vector space using state-of-the-art graph embedding models, enabling effective link prediction, clustering, and visualization of brand advocacy patterns. Experimental evaluation demonstrates the framework's effectiveness in accurately identifying genuine brand advocates while maintaining high data reliability through social credibility insights. The study contributes a scalable, ontology-driven solution for brand engagement analysis and lays the foundation for future research in domain adaptation and multimedia data integration, such as image and video sentiment analysis, to enrich KGs and expand applicability across diverse domains. This work [9] presents a review of current machine learning methodologies, with a critical emphasis on the often-overlooked ethical implications of artificial intelligence (AI) systems. The study introduces a novel, structured ethical deployment framework that integrates privacy-preserving technologies—such as federated learning, differential privacy, and homomorphic encryption—within the context of international ethical standards and regulatory compliance. By bridging the gap between technical innovation and ethical responsibility, this research contributes a multidimensional perspective on responsible AI development. The paper explores how AI impacts employment, equity, and societal structures, calling for global cooperation to establish ethical and regulatory frameworks that transcend borders. It advocates for "Ethics by Design," interdisciplinary collaboration, and adaptive regulatory mechanisms as essential strategies for addressing evolving ethical challenges. Additionally, it underscores the importance of empirical research and advanced risk assessment to inform ethical policies and guide AI implementation across industries such as healthcare, finance, and transportation. The study highlights that privacy-preserving algorithms are crucial in upholding data confidentiality in AI systems. By demonstrating the practical applications of these technologies, this research lays a foundation for ethically grounded AI innovation and provides a forward-looking blueprint for integrating privacy and ethical principles into future AI systems. The study ultimately offers insights for developers, researchers, and policymakers seeking to align AI technologies with societal values and global standards. Exploring security threats and solutions Techniques for Internet of Things (IoT): from vulnerabilities to vigilance The rapid expansion of the Internet of Things (IoT) across industries has transformed how devices interact, communicate, and operate. While offering unprecedented convenience and innovation, this proliferation has introduced significant security challenges that threaten the confidentiality, integrity, and availability of IoT systems. This survey [13] provides a comprehensive overview of the diverse security threats facing IoT ecosystems, including data breaches, unauthorized access, physical tampering, and denial-of-service attacks. By analyzing vulnerabilities across multiple layers of the IoT architecture—ranging from sensing and networking to middleware, gateways, and applications—the survey underscores the urgent need for robust, multi-layered security measures. The paper also investigates the potential of emerging technologies such as blockchain, machine learning, and edge computing to enhance IoT security by enabling decentralized trust, intelligent threat detection, and local data processing. Through an extensive review of existing security frameworks, protocols, and best practices, this survey provides a guide to researchers, industry practitioners, and policymakers in strengthening the resilience of IoT deployments. Furthermore, it identifies critical research gaps and future directions necessary to address evolving cyber threats. As IoT continues to integrate deeper into critical infrastructure and consumer environments, this work advocates for a proactive and collaborative approach to IoT security—ensuring a safer, more reliable digital ecosystem. Heuristic machine learning approaches for identifying phishing threats across web and email platforms In the digital age, while advanced technologies have enhanced convenience and connectivity, they have also given rise to sophisticated cyber threats—phishing being among the most pervasive. Phishing attacks aim to deceive users into revealing sensitive information such as passwords, banking credentials, and personal data by impersonating legitimate sources through URLs, emails, and fake websites. This study proposes a comprehensive, heuristic-based machine learning approach for detecting phishing attacks across multiple vectors—namely, URLs, emails, and websites. The proposed methodology in this work [10] incorporates data pre-processing steps, including cleaning, feature selection, and transformation, followed by the deployment of machine learning models tailored for each phishing medium. For URL-based phishing detection, 56 features were utilized, achieving a detection accuracy of 97.2%. Email phishing detection yielded an accuracy of 97.4%, while website phishing detection, using 48 selected features, achieved the highest accuracy of 98.1%. Comparative analysis with baseline models—Random Forest, Support Vector Machine (SVM), and Naive Bayes—demonstrates the superior performance of the proposed heuristic-based technique across all evaluated categories. This research contributes a unified, high-performance framework for phishing detection and offers insights into feature relevance and attack patterns across platforms. Future work will explore extending the model's capabilities to detect multimodal phishing attempts involving images, videos, social engineering tactics, and malicious attachments in various messaging services. Discussion and Directions: Our goal for this research topic was to explore advancements in machine learning for cybersecurity of cyber-physical systems. The accepted papers in this research topic showcase key applications of machine learning in this area, such as threat detection and anomaly detection. The papers demonstrate how this topic extends across multiple areas, including industrial control systems, IoT, phishing detection, and social platforms. This highlights the impact machine learning is having across multiple industries in order to improve security, safety, and trustworthiness. At the same time, the adoption of machine learning and AI also poses new challenges. The rapid adoption of AI without proper governance frameworks, ethical guidelines, and robust defense strategies can also cause harm, particularly in mission-critical systems where biased or compromised AI decisions could lead to severe consequences. AI and ML suffer from bias that can lead to inaccurate threat detection and misclassification, are difficult to understand and govern effectively, and are vulnerable to sophisticated attacks, including adversarial attacks where input data is manipulated to mislead models. Additionally, many current cybersecurity datasets are outdated and fail to reflect modern AI-driven threats, while the research community lacks systematic comparisons of AI models for specific cybersecurity domains. Data collection also poses significant challenges to privacy. The proliferation of IoT devices allows convenient collection of data to provide increased personalization, but opens the door to new attack vectors and increases the impact of data breaches. To further advance this research topic, we emphasize the need for better governance, more realistic datasets, systematic model comparisons, and exploration of state-of-the-art architectures to improve the trustworthiness of cybersecurity solutions powered by machine learning. We look forward to future advancements in this research area.},
  archive      = {J_FRAI},
  author       = {Wickramasinghe Brahmana, Chathurika S. and Marino, Daniel and De Silva, Daswin and Manic, Milos},
  doi          = {10.3389/frai.2025.1640609},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1640609},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Machine learning for cybersecurity},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming cataract care through artificial intelligence: An evaluation of large language models’ performance in addressing cataract-related queries. <em>FRAI</em>, <em>8</em>, 1639221. (<a href='https://doi.org/10.3389/frai.2025.1639221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeTo evaluate the performance of five popular large language models (LLMs) in addressing cataract-related queries.MethodsThis comparative evaluation study was conducted at the Eye and ENT Hospital of Fudan University. We performed both qualitative and quantitative assessments of responses from five LLMs: ChatGPT-4, ChatGPT-4o, Gemini, Copilot, and the open-source Llama 3.5. Model outputs were benchmarked against human-generated responses using seven key metrics: accuracy, completeness, conciseness, harmlessness, readability, stability, and self-correction capability. Additional inter-model comparisons were performed across question subgroups categorized by clinical topic type.ResultsIn the information quality assessment, ChatGPT-4o demonstrated the best performance across most metrics, including accuracy score (6.70 ± 0.63), completeness score (4.63 ± 0.63), and harmlessness score (3.97 ± 0.17). Gemini achieved the highest conciseness score (4.00 ± 0.14). Further subgroup analysis showed that all LLMs performed comparably to or better than humans, regardless of the type of question posed. The readability assessment revealed that ChatGPT-4o had the lowest readability score (26.02 ± 10.78), indicating the highest level of reading difficulty. While Copilot recorded a higher readability score (40.26 ± 14.58) than the other LLMs, it still remained lower than that of humans (51.54 ± 13.71). Copilot also exhibited the best stability in reproducibility and stability assessment. All LLMs demonstrated strong self-correction capability when prompted.ConclusionOur study suggested that LLMs exhibited considerable potential in providing accurate and comprehensive responses to common cataract-related clinical issues. Notably, ChatGPT-4o achieved the best scores in accuracy, completeness, and harmlessness. Despite these promising results, clinicians and patients should be aware of the limitations of artificial intelligence (AI) to ensure critical evaluation in clinical practice.},
  archive      = {J_FRAI},
  author       = {Wang, Xinyue and Liu, Yan and Song, Linghao and Wen, Yinuo and Peng, Shenjie and Ren, Ruoxi and Zhang, Yi and Chen, Tianhui and Jiang, Yongxiang},
  doi          = {10.3389/frai.2025.1639221},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1639221},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transforming cataract care through artificial intelligence: An evaluation of large language models’ performance in addressing cataract-related queries},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arabic speech recognition model using baidu's deep and cluster learning. <em>FRAI</em>, <em>8</em>, 1639147. (<a href='https://doi.org/10.3389/frai.2025.1639147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study involves extracting the spectrum from the Arabic raw, unlabeled audio signal and producing Mel-frequency cepstral coefficients (MFCCs). The clustering algorithm groups the retrieved MFCCs with analogous features. The K-means clustering technique played a crucial role in our research, enabling the unsupervised categorization of unlabeled Arabic audio data. Employing K-means on the extracted MFCC features allowed us to classify acoustically similar segments into distinct groups without prior knowledge of their characteristics. This initial phase was crucial for understanding the inherent diversity in our diverse sampled dataset. Dynamic Time Warping (DTW) and Euclidean Distance are utilized for illustration. Classification algorithms such as Decision Tree, eXtreme Gradient Boosting (XGBoost), K-Nearest Neighbors (KNN), and Random Forest are used to classify the various classes obtained based on clustering. This study also demonstrates the efficacy of Mozilla's Deep Speech framework for Arabic speech recognition. The core component of deep speech is its neural network architecture, which consists of multiple layers of Recurrent Neural Networks (RNNs). It strives to comprehend the intricate patterns and interactions between spoken sounds and their corresponding textual representations. The clustered labeled Arabic audio dataset, along with transcripts and Arabic Alphabets, is used as input to Baidu's Deep Speech model for training and testing purposes. PyCharm, in conjunction with Python 3.6, is used to build a Dockerfile. Creating, editing, and managing Dockerfiles within PyCharm's IDE is simplified by its functionality and integrated environment. Deep speech provides an eminent Arabic speech recognition quality with reduced loss, word error rate (WER), and character error rate (CER). Baidu's Deep Speech intends to achieve high performance in both end-to-end and isolated speech recognition with good precision and a low word rate and character error rate in a reasonable amount of time. The suggested strategy yielded a loss of 276.147, a word error rate of 0.3720, and a character error rate of 0.0568. This technique increases the accuracy of Arabic automatic speech recognition (ASR).},
  archive      = {J_FRAI},
  author       = {Al-Anzi, Fawaz S. and Sundaram Thankaleela, Bibin Shalini},
  doi          = {10.3389/frai.2025.1639147},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1639147},
  shortjournal = {Front. Artif. Intell.},
  title        = {Arabic speech recognition model using baidu's deep and cluster learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced YOLOv8 for industrial polymer films: A semi-supervised framework for micron-scale defect detection. <em>FRAI</em>, <em>8</em>, 1638772. (<a href='https://doi.org/10.3389/frai.2025.1638772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPolymer material films are produced through extrusion machines, and their surfaces can develop micro-defects due to process and operational influences. The quantity and size of these defects significantly impact product quality.MethodsAs traditional machine learning defect detection methods suffer from low accuracy and poor adaptability to complex scenarios, requiring extensive effort for parameter tuning and exhibiting weak generalization capability, this paper proposes an improved YOLOv8 method to identify micro-defects on films. The approach embeds the CBAM attention mechanism into high-level networks to address feature sparsity in small target detection samples. Simultaneously, given the difficulty in obtaining large annotated datasets, we employ the Mean Teacher method for semi-supervised learning using limited labeled data. During training, the method optimizes neural network gradients through an improved loss function based on normalized Wasserstein distance (NWD), mitigating gradient instability caused by scale variations and enhancing detection accuracy for small targets. Additionally, a proposed multi-threshold mask segmentation algorithm extracts defect contours for further feature analysis.ResultsExperimental results demonstrate that the improved YOLOv8 algorithm achieves an 8.26% increase in mAP@0.5 compared to the baseline. It exhibits higher precision for small targets, and maintains defect detection rates exceeding 95.0% across validation data of varying image sizes, thereby meeting industrial production requirements. In generalization validation, the model demonstrates superior performance compared to traditional methods under test environments with lighting variations and environmental contamination.DiscussionThe improved YOLOv8 algorithm meeting the stringent requirements for high-precision small-target defect detection on polymer material film in industrial production. Future work will explore more advanced techniques to enhance model accuracy and robustness.},
  archive      = {J_FRAI},
  author       = {Yu, Xiaoxia and Hu, Bingyu and Jiang, Weifeng and Wan, Jinru and Yang, Xinduoji and Liu, Nianbo and Dong, Xiaoyan},
  doi          = {10.3389/frai.2025.1638772},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1638772},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhanced YOLOv8 for industrial polymer films: A semi-supervised framework for micron-scale defect detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-scaling LLM-based multi-agent systems through dynamic integration of agents. <em>FRAI</em>, <em>8</em>, 1638227. (<a href='https://doi.org/10.3389/frai.2025.1638227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLarge Language Model-based Multi-Agent Systems (LLM-based MASs) represent a groundbreaking paradigm where diverse LLM-based agents collaborate, leveraging their unique capabilities to achieve shared objectives. Although LLM-based MASs outperform individual agents, their current architectures are limited by predefined, fixed, and static agent designs, restricting adaptability and scalability in dynamic environments.MethodTo address these limitations, this study proposes two novel approaches: Initial Automatic Agent Generation (IAAG) and Dynamic Real-Time Agent Generation (DRTAG). These approaches enable the automatic creation and seamless integration of new agents into MASs, driven by evolving conversational and task-specific contexts, thereby reducing the need for human intervention. Our method leverages advanced prompt engineering techniques such as persona pattern prompting, chain prompting, and few-shot prompting to generate new agents through existing LLM agents. Additionally, several evaluation metrics were adapted to score and rank LLM-generated texts.ResultsExperimental results demonstrate that the DRTAG approach significantly improves system adaptability and task performance compared to static MAS architectures. The IAAG framework also enhances initial system flexibility, supporting the creation of contextually relevant agents.DiscussionThese findings highlight the potential of dynamic LLM-based MASs to overcome the limitations of static architectures to address complex real-world challenges, paving the way for innovative applications across diverse domains.},
  archive      = {J_FRAI},
  author       = {Perera, Ravindu and Basnayake, Anuradha and Wickramasinghe, Manjusri},
  doi          = {10.3389/frai.2025.1638227},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1638227},
  shortjournal = {Front. Artif. Intell.},
  title        = {Auto-scaling LLM-based multi-agent systems through dynamic integration of agents},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv10-based detection of melanocytic nevi: Reverse exclusion optimization for melanoma screening. <em>FRAI</em>, <em>8</em>, 1637842. (<a href='https://doi.org/10.3389/frai.2025.1637842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant melanoma is the deadliest skin cancer, yet its early dermoscopic presentation closely mimics benign melanocytic nevi. Conventional visual or dermoscopic screening therefore suffers from high miss rates and generates excessive biopsies. In this study we focus on Chinese East-Asian patients and introduce a reversed-exclusion strategy—classifying “benign first, exclude malignancy”: lesions that fully meet benign nevus criteria are deemed low-risk; all others are flagged as high-risk. Building on the real-time detector YOLOv10, we incorporate three medical-oriented upgrades: (i) a PP-LCNet backbone to preserve sub-3 mm textures; (ii) a Multiscale Contextual Attention (MCA) neck to enhance cross-scale aggregation; and (iii) a Shape-IoU loss that jointly optimises position, scale, and curvature. The model was trained on a multi-centre dermoscopic dataset from three tertiary hospitals in mainland China (2,040 benign nevi) and independently tested on 365 biopsy-proven melanomas collected at the same medical institution but drawn from a demographically distinct patient cohort, achieving a detection mAP@0.5 of 97.69% for benign lesions and a melanoma false-negative rate (FNR) of only 0.27%. By delivering high-confidence benign identification followed by malignant exclusion, the proposed model offers a high-precision, low-risk pathway for early melanoma screening in Chinese clinical settings. It can markedly reduce unnecessary biopsies while keeping the miss rate below the clinical safety ceiling of 0.5%, thus preserving the life-saving window afforded by early detection.},
  archive      = {J_FRAI},
  author       = {Wang, ShengJie and Wang, Jian and Yin, Rui},
  doi          = {10.3389/frai.2025.1637842},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1637842},
  shortjournal = {Front. Artif. Intell.},
  title        = {YOLOv10-based detection of melanocytic nevi: Reverse exclusion optimization for melanoma screening},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lipschitz-based robustness estimation for hyperdimensional learning. <em>FRAI</em>, <em>8</em>, 1637105. (<a href='https://doi.org/10.3389/frai.2025.1637105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the adoption of machine learning models in various practical domains, there is a growing need for evaluating and increasing model robustness. Hyperdimensional computing (HDC) is a neurosymbolic computational paradigm that represents symbols as high dimensional vectors and symbolic operations as vector operations, seamlessly interfacing between neuro- and symbolic components of a model. However, there is a notable gap in HDC research regarding the robustness of HDC models to input perturbations. This study presents a novel theoretical framework tailored to evaluate the robustness of hyperdimensional classifiers against perturbations in the input space. In particular, our proposed measure of robustness gives a theoretical upper bound for the magnitude of noise a model can tolerate without changing its prediction for any given data point. We also propose a method to enhance the robustness of the model based on our proposed measure of robustness. Our approach introduces several methods to calculate model robustness as a function of the specific dataset and type of hyperdimensional encoding used. The results show that the average robustness of HDC models increases under the proposed optimization scheme while maintaining accuracy by varying the variance of the Gaussian distribution used to encode hypervectors. The practical effectiveness of our proposed measure of robustness is also demonstrated.},
  archive      = {J_FRAI},
  author       = {Yeung, Calvin and Errahmouni Barkam, Hamza and Zou, Zhuowen and Yun, Sanggeon and Bastian, Nathaniel D. and Imani, Mohsen},
  doi          = {10.3389/frai.2025.1637105},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1637105},
  shortjournal = {Front. Artif. Intell.},
  title        = {Lipschitz-based robustness estimation for hyperdimensional learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bibliometric review of deep learning in crop monitoring: Trends, challenges, and future perspectives. <em>FRAI</em>, <em>8</em>, 1636898. (<a href='https://doi.org/10.3389/frai.2025.1636898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global agricultural systems face unprecedented challenges from climate change, resource scarcity, and rising food demand, requiring transformative solutions. Artificial intelligence (AI), particularly deep learning (DL), has emerged as a critical tool for agricultural monitoring, yet a systematic synthesis of its applications remains understudied. This paper presents a comprehensive bibliometric and knowledge graph analysis of 650 + publications (2000–2024) to map AI’s role in agricultural information identification, with emphasis on DL and remote sensing integration (e.g., UAVs, satellites). Results highlight Convolutional Neural Networks (CNNs) as the dominant technology for real-time crop monitoring but reveal three persistent barriers: (1) scarcity of annotated datasets, (2) poor model generalization across environments, and (3) challenges in fusing multi-source data. Crucially, interdisciplinary collaboration—though vital for scalability—is identified as an underdeveloped research frontier. It is concluded that while AI can revolutionize agriculture, its potential hinges on improving data quality, developing environment-adaptive models, and fostering cross-domain partnerships. This study provides a strategic framework to accelerate AI’s integration into global agricultural systems, addressing both technical gaps and policy needs for future food security.},
  archive      = {J_FRAI},
  author       = {Zhang, Rui and Wu, Xue and Li, Jing and Zhao, Pengyu and Zhang, Qing and Wuri, Lige and Zhang, Donghui and Zhang, Zhijie and Yang, Linnan},
  doi          = {10.3389/frai.2025.1636898},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1636898},
  shortjournal = {Front. Artif. Intell.},
  title        = {A bibliometric review of deep learning in crop monitoring: Trends, challenges, and future perspectives},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Named entity recognition for chinese electronic medical records by integrating knowledge graph and ClinicalBERT. <em>FRAI</em>, <em>8</em>, 1634774. (<a href='https://doi.org/10.3389/frai.2025.1634774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionGeneral purpose language models often struggle with accurately identifying domain specific terminology in the medical field, resulting in suboptimal performance in named entity recognition (NER) tasks. This challenge is particularly pronounced in Chinese electronic medical records (EMRs), which lack clear word boundaries and contain complex medical expressions.MethodsThis study proposes a novel NER method for Chinese EMRs that integrates ClinicalBERT, a language model pre trained on clinical corpora, with structured knowledge from a medical knowledge graph. Entity representations derived via Translating Embeddings (TransE) are incorporated to inject external semantic knowledge. Furthermore, the model fuses multiple character level features, including positional labels, contextual category clues, and semantic embeddings, to enhance boundary detection. The input text is annotated using the BIOES (Begin, Inside, Outside, End, Single) tagging scheme and subsequently encoded by ClinicalBERT. The encoded features are then passed through a bidirectional long short term memory (BiLSTM) network and a conditional random field (CRF) layer for final label prediction.ResultsExperiments conducted on publicly available datasets demonstrate that the proposed approach achieves an F1 score of 89.44 percent, surpassing multiple existing baseline models in performance.DiscussionThese findings confirm that the integration of domain specific language modeling, structured medical knowledge, and enriched character level features significantly enhances NER accuracy in Chinese EMRs. The proposed method shows strong potential for practical deployment in clinical information extraction systems.},
  archive      = {J_FRAI},
  author       = {Xu, Xiang and Li, Zhengxiong and Zhang, Hongwei and Ma, Kai},
  doi          = {10.3389/frai.2025.1634774},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1634774},
  shortjournal = {Front. Artif. Intell.},
  title        = {Named entity recognition for chinese electronic medical records by integrating knowledge graph and ClinicalBERT},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging artificial intelligence to explore gendered patterns in financial literacy among teachers in academia. <em>FRAI</em>, <em>8</em>, 1634640. (<a href='https://doi.org/10.3389/frai.2025.1634640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionFinancial literacy is essential for long-term economic stability, yet persistent gender disparities in financial knowledge continue to be observed across professions, including academia. This study explores how Artificial Intelligence (AI) can be applied to identify and analyze gender-based patterns in financial literacy among higher education faculty.MethodsA mixed-methods design was employed, combining traditional survey instruments with AI-driven analytics. Survey data were collected from 300 academic professionals across diverse institutions, capturing financial knowledge, attitudes, behaviors, and socioeconomic characteristics such as marital status, number of dependents, and family income. Natural language processing (NLP) and machine learning (ML) techniques were used to detect linguistic and behavioral differences between male and female participants.ResultsFindings revealed statistically significant gender gaps in financial literacy. Male participants scored higher in investing knowledge (Δ=1.9 points, p<0.001) and expressed greater confidence (+0.42 sentiment vs. -0.15 for women). Intersectional analysis showed that women in STEM disciplines demonstrated narrower gaps (Δ=0.7) compared to women in the humanities (Δ=1.2), with disparities shaped by wage differentials and caregiving responsibilities. Socioeconomic factors—including marital status, family size, and income—were also associated with variations in financial literacy and investment confidence. While the findings are correlational, AI-powered sentiment and cluster analyses provided deeper insights into behavioral segments, illustrating the compounded influence of gender, discipline, and socioeconomic context.DiscussionBy integrating AI techniques with traditional survey methods, this research advances the study of gender and financial literacy in academia. The combined approach enhances interpretability and highlights the value of context-sensitive interventions. Recommended strategies include gender-responsive financial training, AI-enabled coaching tools, and institutional and policy-level reforms supported by universities, government agencies, and funding bodies.},
  archive      = {J_FRAI},
  author       = {Christopher, A. Ruban and Nithya, A. R.},
  doi          = {10.3389/frai.2025.1634640},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1634640},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging artificial intelligence to explore gendered patterns in financial literacy among teachers in academia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI: The apollo guidance computer of the exposome moonshot. <em>FRAI</em>, <em>8</em>, 1632520. (<a href='https://doi.org/10.3389/frai.2025.1632520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Exposome—the totality of environmental exposures across a lifetime—remains one of the most significant challenges in understanding and preventing human disease. Translating its vast, heterogeneous data streams into actionable knowledge requires artificial intelligence (AI) integrated with human-relevant experimental systems. We propose a unifying vision in which Microphysiological Systems (MPS) and multi-omics platforms generate high-quality, context-specific data that iteratively calibrate AI models, enabling the creation of digital twins of organs, individuals, and ultimately populations. This “Exposome Moonshot” parallels the Apollo program in ambition, with MPS as the rocket, multi-omics as the lunar module, and AI as the guidance computer. Early applications demonstrate that deep learning can already outperform canonical animal tests for several toxicological endpoints, while reducing cost and time to decision. Realizing the full potential of Exposome intelligence will require expanding the applicability domain of models, implementing robust data security, and prioritizing transparent, interpretable algorithms. By linking predictive AI with experimental feedback, we can move toward a prevention-driven, personalized paradigm for human health and regulatory science.},
  archive      = {J_FRAI},
  author       = {Sillé, Fenna C. M. and Hartung, Thomas},
  doi          = {10.3389/frai.2025.1632520},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1632520},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI: The apollo guidance computer of the exposome moonshot},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in ultrasound tongue imaging: A systematic review toward automated detection of speech sound disorders. <em>FRAI</em>, <em>8</em>, 1631134. (<a href='https://doi.org/10.3389/frai.2025.1631134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundSpeech sound disorders (SSD) in children can significantly impact communication and development. Ultrasound tongue imaging (UTI) is a non-invasive method for visualising tongue motion during speech, offering a promising alternative for diagnosis and therapy. Deep learning (DL) techniques have shown great promise in automating the analysis of UTI data, although their clinical application for SSD remains underexplored.ObjectiveThis review aims to synthesise how DL has been utilised in UTI to support automated SSD detection, highlighting the advancement of techniques, key challenges, and future directions.MethodsA comprehensive search of IEEE Xplore, PubMed, ScienceDirect, Scopus, Taylor & Francis, and arXiv identified studies from 2010 through 2025. Inclusion criteria focused on studies using DL to analyse UTI data with relevance to SSD classification, feature extraction, or speech assessment. Eleven studies met the criteria: three directly tackled disordered speech classification tasks, while four addressed supporting tasks like tongue contour segmentation and tongue motion modelling. Promising results were reported in each category, but limitations such as small datasets, inconsistent evaluation, and limited generalisability were common.ResultsDL models demonstrate effectiveness in analysing UTI for articulatory assessment and show early potential in identifying SSD-related patterns. The included studies collectively outline a developmental pipeline, from foundational pre-processing to phoneme-level classification in typically developing speakers, and finally to preliminary attempts at classifying speech errors in children with SSD. This progression illustrates significant technological advances; however, it also emphasises gaps such as the lack of large, disorder-focused datasets and the need for integrated end-to-end systems.ConclusionThe field of DL-driven UTI assessment for speech disorders is developing. Current studies provide a strong technical foundation and proof-of-concept for automatic SSD detection using ultrasound, but clinical translation remains limited. Future research should prioritise the creation of larger annotated UTI datasets of disordered speech, developing generalisable and interpretable models, and validating fully integrated DL-UTI pipelines in real-world speech therapy settings. With these advances, DL-based UTI systems have the potential to transform SSD diagnosis and treatment by providing objective, real-time articulatory feedback in a child-friendly manner.},
  archive      = {J_FRAI},
  author       = {Al Ani, Saja and Cleland, Joanne and Zoha, Ahmed},
  doi          = {10.3389/frai.2025.1631134},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1631134},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning in ultrasound tongue imaging: A systematic review toward automated detection of speech sound disorders},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the accuracy and repeatability of deepseek v3, doubao, and kimi1.5 in answering knowledge-related queries about chronic non-bacterial osteitis. <em>FRAI</em>, <em>8</em>, 1629149. (<a href='https://doi.org/10.3389/frai.2025.1629149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThere are significant differences in the diagnosis and treatment of chronic non-bacterial osteitis (CNO), and there is an urgent need for health education efforts to enhance awareness of this condition. Deepseek V3, Doubao, and Kimi1.5 are highly popular language models in China that can provide knowledge related to diseases. This article aims to investigate the accuracy and reproducibility of the responses provided by these three artificial intelligence (AI) language models in answering questions about CNO.MethodsAccording to the latest expert consensus, 16 questions related to CNO were collected. The three AI language models were separately asked these questions at three different times. The answers were independently evaluated by two orthopedic experts.ResultsAmong the responses of the three AI models to 16 CNO-related questions across three rounds of testing, only Doubao received “Completely incorrect” ratings (accounting for 6.25%) in the third round of scoring by Reviewer 2. During the answering process, Doubao had the shortest response time and provided the most words in its answers. In the first and third rounds of scoring by the first expert, Kimi scored the highest (3.938 ± 0.342, 3.875 ± 0.873), while in the second round, Doubao scored the highest (3.875 ± 0.5). In the second round of scoring by the second expert, Doubao received the highest score (3.812 ± 0.403). In the first and third rounds, Kimi1.5 received the highest score (3.812 ± 0.602, 3.812 ± 0.704).ConclusionDeepseek V3, Doubao, and Kimi1.5 are capable of answering most questions related to CNO with good accuracy and reproducibility, showing no significant differences.},
  archive      = {J_FRAI},
  author       = {Zhu, Zhenxing and Xie, Jun and Zhou, Longxin and Yang, Chaoran and Li, Feng},
  doi          = {10.3389/frai.2025.1629149},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1629149},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of the accuracy and repeatability of deepseek v3, doubao, and kimi1.5 in answering knowledge-related queries about chronic non-bacterial osteitis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utilizing XGBoosts to correct arcjet contamination in magnetic field measurements from GOES missions. <em>FRAI</em>, <em>8</em>, 1628029. (<a href='https://doi.org/10.3389/frai.2025.1628029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The magnetometers onboard the Geostationary Operational Environmental Satellites (GOES) provide crucial measurements for space weather monitoring and scientific research. However, periodic arcjet thruster firings introduce contamination in the measured magnetic field, affecting data accuracy. The currently used correction matrix approach mitigates these effects but struggles with transient variations and residual errors. In this study, we present an alternative correction method using XGBoost, a machine learning algorithm, to correct arcjet-induced contamination in the GOES-17 magnetometer data using GOES-18 as ground truth. Using cross-satellite comparisons and supervised learning techniques, our model is effective in reducing artificial disturbances, especially non-linear variations. We found that the XGBoost method works better than the existing correction matrix approach for E and P components, while the correction matrix performs better for the N component. Although some limitations remain due to training data constraints, our results highlight the importance of machine learning to improve magnetometer data quality by recognizing and correcting complex satellite-driven artifacts. The collocation of GOES-17 and GOES-18 provided a unique opportunity for cross-satellite calibration and validation, and with a longer collocation period, the XGBoost method shows significant promise for better correction of operational data, emphasizing the need for such configurations in future satellite missions.},
  archive      = {J_FRAI},
  author       = {Inceoglu, Fadil and Loto'aniu, Paul T. M.},
  doi          = {10.3389/frai.2025.1628029},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1628029},
  shortjournal = {Front. Artif. Intell.},
  title        = {Utilizing XGBoosts to correct arcjet contamination in magnetic field measurements from GOES missions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An artificial intelligence model for early-stage breast cancer classification from histopathological biopsy images. <em>FRAI</em>, <em>8</em>, 1627876. (<a href='https://doi.org/10.3389/frai.2025.1627876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of breast cancer subtypes is essential for guiding treatment decisions and improving patient outcomes. In current clinical practice, determining histological subtypes often requires additional invasive procedures, delaying treatment initiation. This study proposes a deep learning-based model built on a DenseNet121 backbone with a multi-scale feature fusion strategy, designed to classify breast cancer from histopathological biopsy images. Trained and evaluated on the publicly available BreaKHis dataset using 5-fold cross-validation, the model achieved a binary classification accuracy of 97.1%, and subtype classification accuracies of 93.8% for benign tumors and 92.0% for malignant tumors. These results demonstrate the model’s ability to capture morphological cues at multiple levels of abstraction and highlight its potential as a diagnostic support tool in digital pathology workflows.},
  archive      = {J_FRAI},
  author       = {Chaudhary, Neil and Dhunny, A. Z.},
  doi          = {10.3389/frai.2025.1627876},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1627876},
  shortjournal = {Front. Artif. Intell.},
  title        = {An artificial intelligence model for early-stage breast cancer classification from histopathological biopsy images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linguistic patterns in pandemic-related content: A comparative analysis of COVID-19, constraint, and monkeypox datasets. <em>FRAI</em>, <em>8</em>, 1627522. (<a href='https://doi.org/10.3389/frai.2025.1627522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study investigates how linguistic features distinguish health misinformation from factual communication in pandemic-related online discourse. Understanding these differences is essential for improving detection of misinformation and informing effective public health messaging during crises.MethodsWe conducted a computational linguistic analysis across three corpora: COVID-19 false narratives (n = 7,588), general COVID-19 content (n = 10,700), and Monkeypox-related posts (n = 5,787). We examined readability, rhetorical markers, and persuasive language, focusing on differences between misinformation and factual communication.ResultsCOVID-19 misinformation exhibited markedly lower readability scores and contained more than twice the frequency of fear-related and persuasive terms compared to the other datasets. It showed minimal use of exclamation marks, contrasting with the more emotive style of Monkeypox content. These findings suggest that misinformation employs a deliberately complex rhetorical style combined with emotional cues, which may enhance perceived credibility.DiscussionOur findings contribute to the growing body of research on digital health misinformation by identifying linguistic indicators that can aid in detection. They also inform theoretical models of crisis communication and public health messaging strategies in networked media environments. However, the study has limitations, including reliance on traditional readability indices, a narrow persuasive lexicon, and static aggregate analysis. Future work should adopt longitudinal designs, incorporate broader emotion lexicons, and employ platform-sensitive approaches to improve robustness. The data and code supporting this study are openly available at: https://doi.org/10.5281/zenodo.17024569.},
  archive      = {J_FRAI},
  author       = {Sikosana, Mkululi and Maudsley-Barton, Sean and Ajao, Oluwaseun},
  doi          = {10.3389/frai.2025.1627522},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1627522},
  shortjournal = {Front. Artif. Intell.},
  title        = {Linguistic patterns in pandemic-related content: A comparative analysis of COVID-19, constraint, and monkeypox datasets},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable AI-driven depression detection from social media using natural language processing and black box machine learning models. <em>FRAI</em>, <em>8</em>, 1627078. (<a href='https://doi.org/10.3389/frai.2025.1627078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMental disorders are highly prevalent in modern society, leading to substantial personal and societal burdens. Among these, depression is one of the most common, often exacerbated by socioeconomic, clinical, and individual risk factors. With the rise of social media, user-generated content offers valuable opportunities for the early detection of mental disorders through computational approaches.MethodsThis study explores the early detection of depression using black-box machine learning (ML) models, including Support Vector Machines (SVM), Random Forests (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Networks (ANN). Advanced Natural Language Processing (NLP) techniques TF-IDF, Latent Dirichlet Allocation (LDA), N-grams, Bag of Words (BoW), and GloVe embeddings were employed to extract linguistic and semantic features. To address the interpretability limitations of black-box models, Explainable AI (XAI) methods were integrated, specifically the Local Interpretable Model-Agnostic Explanations (LIME).ResultsExperimental findings demonstrate that SVM achieved the highest accuracy in detecting depression from social media data, outperforming RF and other models. The application of LIME enabled granular insights into model predictions, highlighting linguistic markers strongly aligned with established psychological research.DiscussionUnlike most prior studies that focus primarily on classification accuracy, this work emphasizes both predictive performance and interpretability. The integration of LIME not only enhanced transparency and interpretability but also improved the potential clinical trustworthiness of ML-based depression detection models.},
  archive      = {J_FRAI},
  author       = {Hameed, Sidra and Nauman, Muhammad and Akhtar, Nadeem and Fayyaz, Muhammad A. B. and Nawaz, Raheel},
  doi          = {10.3389/frai.2025.1627078},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1627078},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable AI-driven depression detection from social media using natural language processing and black box machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integration of AI and ML in regenerative braking for electric vehicles: A review. <em>FRAI</em>, <em>8</em>, 1626804. (<a href='https://doi.org/10.3389/frai.2025.1626804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicle technology has grown rapidly in recent years due to battery advancements, environmental concerns and supportive policies. Regenerative braking systems play a critical role in improving energy efficiency by converting kinetic energy into electrical energy, thereby extending battery life and vehicle range. However, conventional regenerative braking faces challenges in energy recovery, comfort, and adaptability. Optimizing energy recovery ensures prolonged battery life by preventing overcharging or undercharging, making EVs more sustainable and cost-effective. This review paper explores the integration of Artificial Intelligence and machine learning techniques in regenerative braking systems to overcome these challenges. This study examines AI techniques such as regression models, neural networks, deep reinforcement learning, fuzzy logic, genetic algorithm and swarm intelligence based techniques for regenerative braking. The study also compares AI-based strategies with traditional braking methods. Unlike previous studies, which focus on individual AI techniques, this paper provides a comparative analysis of multiple AI approaches, assessing their impact on braking performance and energy recovery, and propose a hybrid AI framework. This paper covers challenges in real-time implementation, road adaptability, and vehicle control integration. This paper also discusses future research that optimize braking performance like V2X communication, edge computing, and explainable AI etc.},
  archive      = {J_FRAI},
  author       = {Prakash, Zacharia},
  doi          = {10.3389/frai.2025.1626804},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1626804},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integration of AI and ML in regenerative braking for electric vehicles: A review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning/machine learning approach for anomaly based network intrusion detection. <em>FRAI</em>, <em>8</em>, 1625891. (<a href='https://doi.org/10.3389/frai.2025.1625891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe increasing complexity and frequency of cybersecurity threats necessitate the development of advanced detection systems capable of identifying both known and emerging attacks. In this study, we present a hybrid anomaly-based Network Intrusion Detection System (NIDS) that integrates multiple machine learning and deep learning algorithms, including XGBoost, Random Forest, Graph Neural Networks (GNN), Long Short-Term Memory (LSTM) networks, and Autoencoders.MethodsThe proposed system was trained on a large-scale dataset comprising over 5.6 million network traffic records. Comprehensive data preprocessing and feature engineering were applied, and the Synthetic Minority Over-sampling Technique (SMOTE) was employed to address class imbalance. To enhance robustness and generalization, a weighted soft-voting ensemble strategy was used to combine predictions from the individual models.ResultsThe experimental evaluation demonstrated near-perfect performance, with accuracy, precision, recall, and F1-score values approaching 100% on the primary dataset. These results were validated through rigorous 5-fold cross-validation.DiscussionEvaluation on an independent benchmark dataset confirmed the strong generalizability and robustness of the proposed model across diverse intrusion scenarios. These findings highlight the effectiveness of the hybrid ensemble framework in significantly improving intrusion detection capabilities within complex and dynamic network environments.},
  archive      = {J_FRAI},
  author       = {Almuhanna, Reem and Dardouri, Samia},
  doi          = {10.3389/frai.2025.1625891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1625891},
  shortjournal = {Front. Artif. Intell.},
  title        = {A deep learning/machine learning approach for anomaly based network intrusion detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated ensemble of BERT- and feature-based models for authorship attribution in japanese literary works. <em>FRAI</em>, <em>8</em>, 1624900. (<a href='https://doi.org/10.3389/frai.2025.1624900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundTraditional authorship attribution (AA) research has primarily relied on statistical analysis and classification based on stylistic features extracted from textual data. Although pre-trained language models like BERT have gained prominence in text classification tasks, their effectiveness in small-sample AA scenarios remains insufficiently explored. A critical unresolved challenge is developing methodologies that effectively integrate BERT with conventional feature-based approaches to advance AA research.Revised objectiveThis study aims to substantially enhance performance in small-sample AA tasks through the strategic combination of traditional feature-based methods and contemporary BERT-based approaches. Furthermore, we conduct a comprehensive comparative analysis of the accuracy of BERT models and conventional classifiers while systematically evaluating how individual model characteristics interact within this combination to influence overall classification effectiveness.MethodsWe propose a novel integrated ensemble methodology that combines BERT-based models with feature-based classifiers, benchmarked against conventional ensemble techniques. Experimental validation is conducted using two literary corpora, each consisting of works from 10 distinct authors. The ensemble framework incorporates five BERT variants, three feature types, and two classifier architectures to systematically evaluate model effectiveness.ResultsBERT demonstrated effectiveness in small-sample authorship attribution tasks, surpassing traditional feature-based methods. Both BERT-based and feature-based ensembles outperformed their standalone counterparts, with the integrated ensemble method achieving even higher scores. Notably, the integrated ensemble significantly outperformed the best individual model on Corpus B—which was not included in the pre-training data— improving the F1 score from 0.823 to 0.96. It achieved the highest score among all evaluated approaches, including standalone models and conventional ensemble techniques, with a statistically significant margin (p < 0.012, Cohen’s d = 4.939), underscoring the robustness of the result. The pre-training data used in BERT had a significant impact on task performance, emphasizing the need for careful model selection based not only on accuracy but also on model diversity. These findings highlight the importance of pre-training data and model diversity in optimizing language models for ensemble learning, offering valuable insights for authorship attribution research and the broader development of artificial general intelligence systems.},
  archive      = {J_FRAI},
  author       = {Kanda, Taisei and Jin, Mingzhe and Zaitsu, Wataru},
  doi          = {10.3389/frai.2025.1624900},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1624900},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrated ensemble of BERT- and feature-based models for authorship attribution in japanese literary works},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in ADHD assessment: A comprehensive review of research progress from early screening to precise differential diagnosis. <em>FRAI</em>, <em>8</em>, 1624485. (<a href='https://doi.org/10.3389/frai.2025.1624485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention deficit hyperactivity disorder (ADHD) diagnosis traditionally relies on subjective assessments, which lead to challenges like symptom overlap, heterogeneity, and misdiagnosis risk. Artificial intelligence (AI), especially machine learning (ML) and deep learning (DL), offers objective assessment opportunities by processing complex multimodal data (behavioral, neurophysiological, neuroimaging, genetic). This paper reviews AI’s current applications in objective ADHD assessment, covering early screening, risk prediction, diagnostic assistance, classification, assistance in precise differential diagnosis, symptom quantification, and heterogeneous subtype identification. While AI models show significant potential in extracting objective biomarkers and improving assessment efficiency, the field faces challenges: insufficient standardized data, limited generalization, interpretability issues, potential biases, and lack of rigorous clinical validation. Future research must establish large-scale, standardized multimodal databases, develop robust, interpretable, and fair AI models, and conduct rigorous clinical translation validation to achieve responsible, precise, objective, and personalized ADHD assessment and management.},
  archive      = {J_FRAI},
  author       = {Zhao, Cuijie and Xu, Yan and Li, Ruixing and Li, Huawei and Zhang, Meng},
  doi          = {10.3389/frai.2025.1624485},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1624485},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence in ADHD assessment: A comprehensive review of research progress from early screening to precise differential diagnosis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence attitudes and resistance to use robo-advisors: Exploring investor reluctance toward cognitive financial systems. <em>FRAI</em>, <em>8</em>, 1623534. (<a href='https://doi.org/10.3389/frai.2025.1623534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe study investigates resistance towards Financial Robo-Advisors (FRAs) among retail investors in India, grounded in innovation resistance theory. The study examines the impact of functional barriers and psychological barriers on resistance to FRAs, while considering user’s attitudes towards Artificial Intelligence (AI) as a moderator. It further evaluate the influence of such resistance on users’ intentions to use and recommend FRAs.MethodsUtilizing purposive sampling data was collected from 409 investors and further analyzed using structural equation modelling.ResultsThe findings revealed that all barriers under study, expect value barrier, substantially derive resistance towards robo-advisors, with inertia being the strongest determinant. Further, this resistance impedes both the intention to use FRAs and to recommend them. Moderation analysis results finds that users’ attitude towards AI significantly weakens the influence of inertia, overconfidence bias and data privacy risk on resistance, with no such impact on other relationships.DiscussionOverall, the study enriches IRT in Fintech context and provides theoretical and practical insights to enhance FRAs adoption in emerging markets.},
  archive      = {J_FRAI},
  author       = {Verma, Balraj and Schulze, Mike and Goswami, Divya and Upreti, Kamal},
  doi          = {10.3389/frai.2025.1623534},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1623534},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence attitudes and resistance to use robo-advisors: Exploring investor reluctance toward cognitive financial systems},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing prediction of primary site recurrence in head and neck cancer using radiomics and uncertainty estimation. <em>FRAI</em>, <em>8</em>, 1623393. (<a href='https://doi.org/10.3389/frai.2025.1623393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionHead and neck squamous cell carcinomas (HNSCC) present a significant clinical challenge due to high recurrence rates despite advances in radiation and chemotherapy. Early detection of recurrence is critical for optimizing treatment outcomes and improving patient survival.MethodsWe developed two artificial intelligence (AI) pipelines—(1) machine learning models trained on radiomic and clinical data and (2) a Vision Transformer-based model directly applied to imaging data—to predict HNSCC recurrence using pre- and post-treatment PET/CT scans from a cohort of 249 patients. We incorporated Test-Time Augmentation (TTA) and Conformal Prediction to quantify prediction uncertainty and enhance model reliability.ResultsThe machine learning models achieved an average AUC of 0.820. The vision transformer model showed moderate performance (AUC = 0.658). Uncertainty quantification enabled the exclusion of ambiguous predictions, improving accuracy among more confident cases.DiscussionOur machine learning models achieved strong performance in predicting HNSCC recurrence from radiomic and clinical features. Incorporating uncertainty quantification further improved predictive performance and reliability.},
  archive      = {J_FRAI},
  author       = {Hu, Yu and Taing, Kimberly and Wang, Jing and Sher, David and Dohopolski, Michael},
  doi          = {10.3389/frai.2025.1623393},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1623393},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing prediction of primary site recurrence in head and neck cancer using radiomics and uncertainty estimation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redefining digital health interfaces with large language models. <em>FRAI</em>, <em>8</em>, 1623339. (<a href='https://doi.org/10.3389/frai.2025.1623339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their adoption remains comparatively limited due, in part, to challenges surrounding usability and trust. Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, however, as LLMs are susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLM-based systems, with LLMs acting as agents, can utilize external tools and provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLMs in clinical settings, such as hallucinations. We illustrate LLM-based interfaces with examples of cardiovascular disease and stroke risk prediction, quantitatively assessing their performance and highlighting the benefit compared to traditional interfaces for digital tools.},
  archive      = {J_FRAI},
  author       = {Imrie, Fergus and Rauba, Paulius and van der Schaar, Mihaela},
  doi          = {10.3389/frai.2025.1623339},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1623339},
  shortjournal = {Front. Artif. Intell.},
  title        = {Redefining digital health interfaces with large language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey and analysis of hallucinations in large language models: Attribution to prompting strategies or model behavior. <em>FRAI</em>, <em>8</em>, 1622292. (<a href='https://doi.org/10.3389/frai.2025.1622292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hallucination in Large Language Models (LLMs) refers to outputs that appear fluent and coherent but are factually incorrect, logically inconsistent, or entirely fabricated. As LLMs are increasingly deployed in education, healthcare, law, and scientific research, understanding and mitigating hallucinations has become critical. In this work, we present a comprehensive survey and empirical analysis of hallucination attribution in LLMs. Introducing a novel framework to determine whether a given hallucination stems from not optimize prompting or the model's intrinsic behavior. We evaluate state-of-the-art LLMs—including GPT-4, LLaMA 2, DeepSeek, and others—under various controlled prompting conditions, using established benchmarks (TruthfulQA, HallucinationEval) to judge factuality. Our attribution framework defines metrics for Prompt Sensitivity (PS) and Model Variability (MV), which together quantify the contribution of prompts vs. model-internal factors to hallucinations. Through extensive experiments and comparative analyses, we identify distinct patterns in hallucination occurrence, severity, and mitigation across models. Notably, structured prompt strategies such as chain-of-thought (CoT) prompting significantly reduce hallucinations in prompt-sensitive scenarios, though intrinsic model limitations persist in some cases. These findings contribute to a deeper understanding of LLM reliability and provide insights for prompt engineers, model developers, and AI practitioners. We further propose best practices and future directions to reduce hallucinations in both prompt design and model development pipelines.},
  archive      = {J_FRAI},
  author       = {Anh-Hoang, Dang and Tran, Vu and Nguyen, Le-Minh},
  doi          = {10.3389/frai.2025.1622292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1622292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Survey and analysis of hallucinations in large language models: Attribution to prompting strategies or model behavior},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel joint encoding for drone-view object detection under low-light conditions. <em>FRAI</em>, <em>8</em>, 1622100. (<a href='https://doi.org/10.3389/frai.2025.1622100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under low-light conditions, the accuracy of drone-view object detection algorithms is frequently compromised by noise and insufficient illumination. Herein, we propose a parallel neural network that concurrently performs image enhancement and object detection for drone-view object detection in nighttime environments. Our innovative coevolutionary framework establishes bidirectional gradient propagation pathways between network modules, improving the robustness of feature representations through the joint optimization of the photometric correction and detection objectives. The illumination enhancement network employs Zero-DCE++, which adaptively adjusts the brightness distribution without requiring paired training data. In our model, object detection is performed using a lightweight YOLOv5 architecture that exhibits good detection accuracy while maintaining real-time performance. To further optimize feature extraction, we introduce a spatially adaptive feature modulation module and a high- and low-frequency adaptive feature enhancement block. The former dynamically modulates the input features through multiscale feature fusion, enhancing the ability of the model to perceive local and global information. The latter module enhances semantic representation and edge details through the parallel processing of spatial contextual information and feature refinement. Experiments on the two data sets of VisDrone2019 (Night) and Drone Vehicle (Night) show that the proposed method improves 3.13 and 3.1% compared with the traditional YOLOv5 method mAP@0.5:0.95, and improves 6.3 and 2% in mAP@0.5, especially in the extreme low light and high noise environment.Thus, the proposed parallel model is an efficient and reliable solution for drone-based nighttime visual monitoring.},
  archive      = {J_FRAI},
  author       = {Liu, Liwen and Zhou, Bo and Li, Qiqin and Fu, Gui and Wang, You and Chu, Hongyu},
  doi          = {10.3389/frai.2025.1622100},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1622100},
  shortjournal = {Front. Artif. Intell.},
  title        = {Parallel joint encoding for drone-view object detection under low-light conditions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The implementation of artificial intelligence in upper extremity surgery: A systematic review. <em>FRAI</em>, <em>8</em>, 1621757. (<a href='https://doi.org/10.3389/frai.2025.1621757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe rapid expansion of artificial intelligence (AI) in medicine has led to its increasing integration into upper extremity (UE) orthopedics. The purpose of this systematic review is to investigate the current landscape and impact of AI in the field of UE surgery.MethodsFollowing PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, a systematic search of PubMed was conducted to identify studies incorporating AI in UE surgery. Review articles, letters to the editor, and studies unrelated to AI applications in UE surgery were excluded.ResultsAfter applying inclusion/exclusion criteria, 118 articles were included. The publication years ranged from 2009 to 2024, with a median and mode of 2022 and 2023, respectively. The studies were categorized into six main applications: automated image analysis (36%), surgical outcome prediction (20%), measurement tools (14%), prosthetic limb applications (14%), intraoperative aid (10%), and clinical decision support tools (6%).DiscussionAI is predominantly utilized in image analysis, including radiograph and MRI interpretation, often matching or surpassing clinician accuracy and efficiency. Additionally, AI-powered tools enhance the measurement of range of motion, critical shoulder angles, grip strength, and hand posture, aiding in patient assessment and treatment planning. Surgeons are increasingly leveraging AI for predictive analytics to estimate surgical outcomes, such as infection risk, postoperative function, and procedural costs. As AI continues to evolve, its role in UE surgery is expected to expand, improving decision-making, precision, and patient care.},
  archive      = {J_FRAI},
  author       = {Parry, Dylan and Henderson, Brennon and Gaschen, Paul and Ghanem, Diane and Hernandez, Evan and Idicula, Anceslo and Hanna, Tammam and MacKay, Brendan},
  doi          = {10.3389/frai.2025.1621757},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1621757},
  shortjournal = {Front. Artif. Intell.},
  title        = {The implementation of artificial intelligence in upper extremity surgery: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EmoShiftNet: A shift-aware multi-task learning framework with fusion strategies for emotion recognition in multi-party conversations. <em>FRAI</em>, <em>8</em>, 1618698. (<a href='https://doi.org/10.3389/frai.2025.1618698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionEmotion Recognition in Conversations (ERC) is vital for applications such as mental health monitoring, virtual assistants, and human–computer interaction. However, existing ERC models often neglect emotion shifts—transitions between emotional states across dialogue turns in multi-party conversations (MPCs). These shifts are subtle, context-dependent, and complicated by class imbalance in datasets such as the Multimodal EmotionLines Dataset (MELD).MethodsTo address this, we propose EmoShiftNet, a shift-aware multi-task learning (MTL) framework that jointly performs emotion classification and emotion shift detection. The model integrates multimodal features, including contextualized text embeddings from BERT, acoustic features (Mel-Frequency Cepstral Coefficients, pitch, loudness), and temporal cues (pause duration, speaker overlap, utterance length). Emotion shift detection is incorporated as an auxiliary task via a composite loss function combining focal loss, binary cross-entropy, and triplet margin loss.ResultsEvaluations on the MELD dataset demonstrate that EmoShiftNet achieves higher overall F1-scores than both traditional and graph-based ERC models. In addition, the framework improves the recognition of minority emotions under imbalanced conditions, confirming the effectiveness of incorporating shift supervision and multimodal fusion.DiscussionThese findings highlight the importance of modeling emotional transitions in ERC. By leveraging multi-task learning with explicit shift detection, EmoShiftNet enhances contextual awareness and offers more robust performance for multi-party conversational emotion recognition.},
  archive      = {J_FRAI},
  author       = {Nirujan, Hinduja and Priyadarshana, Y. H. P. P.},
  doi          = {10.3389/frai.2025.1618698},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1618698},
  shortjournal = {Front. Artif. Intell.},
  title        = {EmoShiftNet: A shift-aware multi-task learning framework with fusion strategies for emotion recognition in multi-party conversations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of large language model-generated medical information on idiopathic pulmonary fibrosis. <em>FRAI</em>, <em>8</em>, 1618378. (<a href='https://doi.org/10.3389/frai.2025.1618378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundIdiopathic Pulmonary Fibrosis (IPF) information from AI-powered large language models (LLMs) like ChatGPT-4 and Gemini 1.5 Pro is unexplored for quality, reliability, readability, and concordance with clinical guidelines.Research questionWhat is the quality, reliability, readability, and concordance to clinical guidelines of LLMs in medical and clinically IPF-related content?Study design and methodsChatGPT-4 and Gemini 1.5 Pro responses to 23 ATS/ERS/JRS/ALAT IPF guidelines questions were compared. Six independent raters evaluated responses for quality (DISCERN), reliability (JAMA Benchmark Criteria), readability (Flesch–Kincaid), and guideline concordance (0–4). Descriptive analysis, Intraclass Correlation Coefficient, Wilcoxon signed-rank test, and effect sizes (r) were calculated. Statistical significance was set at p < 0.05.ResultsAccording to JAMA Benchmark, ChatGPT-4 and Gemini 1.5 Pro provided partially reliable responses; however, readability evaluations showed that both models were difficult to understand. The Gemini 1.5 Pro provided significantly better treatment information (DISCERN score: 56 versus 43, p < 0.001). Gemini had considerably higher international IPF guidelines concordance than ChatGPT-4 (median 3.0 [3.0–3.5] vs. 3.0 [2.5–3.0], p = 0.0029).InterpretationBoth models gave useful medical insights, but their reliability is limited. Gemini 1.5 Pro gave greater quality information than ChatGPT-4 and was more compliant with worldwide IPF guidelines. Readability analyses found that AI-generated medical information was difficult to understand, stressing the need to refine it.What is already known on this topicRecent advancements in AI, especially large language models (LLMs) powered by natural language processing (NLP), have revolutionized the way medical information is retrieved and utilized.What this study addsThis study highlights the potential and limitations of ChatGPT-4 and Gemini 1.5 Pro in generating medical information on IPF. They provided partially reliable information in their responses; however, Gemini 1.5 Pro demonstrated superior quality in treatment-related content and greater concordance with clinical guidelines. Nevertheless, neither model provided answers in full concordance with established clinical guidelines, and their readability remained a major challenge.How this study might affect research, practice or policyThese findings highlight the need for AI model refinement as LLMs evolve as healthcare reference tools to help doctors and patients make evidence-based decisions.},
  archive      = {J_FRAI},
  author       = {Cherrez-Ojeda, Iván and Frye, Björn Christian and Hoheisel, Andreas and Cortes-Telles, Arturo and Robles-Velasco, Karla and Mateos-Toledo, Heidegger N. and Figueiredo, Ricardo G. and Ryerson, Christopher J. and Rodas-Valero, Gabriela and Calderón, Juan Carlos},
  doi          = {10.3389/frai.2025.1618378},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1618378},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of large language model-generated medical information on idiopathic pulmonary fibrosis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The history of the semantic hacking project and the lessons it teaches for modern cognitive security. <em>FRAI</em>, <em>8</em>, 1616447. (<a href='https://doi.org/10.3389/frai.2025.1616447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Semantic Hacking Project ran from 2001 to 2003. It focused on how information systems (and the human decisions shaped by them) could be exploited through attacks not on code or infrastructure, but on meaning. This work is relevant to contemporary cognitive security concerns in the face of today’s information space. The work provides insight into the key question of how people come to hold the beliefs which they do. The project anticipated many of today’s challenges (disinformation campaigns, social media manipulation, AI-generated narratives) not just in technical terms, but in philosophical and linguistic terms. At the heart of its concern was a simple but powerful question: What happens when you can manipulate the inputs to a person’s belief system without the person knowing it? This question has only grown more urgent in an era of generative AI, large language models (LLMs), and algorithmically amplified influence.},
  archive      = {J_FRAI},
  author       = {Thompson, Paul and Guillory, Sean},
  doi          = {10.3389/frai.2025.1616447},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1616447},
  shortjournal = {Front. Artif. Intell.},
  title        = {The history of the semantic hacking project and the lessons it teaches for modern cognitive security},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image restoration and key field alignment for misaligned overlapping text in secondary printing document images. <em>FRAI</em>, <em>8</em>, 1616007. (<a href='https://doi.org/10.3389/frai.2025.1616007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of information technology, the demand for efficient recognition and information extraction from paper documents in industrial scenarios has grown rapidly. In practice, business information is often secondarily printed onto pre-designed templates, which frequently leads to text misalignment or overlap with backgrounds and tables, thereby significantly impairing the accuracy of subsequent Optical Character Recognition (OCR). To address this issue, this paper proposes a preprocessing method for OCR recognition of secondary printed documents, specifically targeting the problems of text misalignment and overlap. In particular, we design a Text Overlap Restoration Network (TORNet) to restore document images affected by text overlap. Experimental results demonstrate that, compared to the latest image restoration models, TORNet achieves PSNR improvements of 0.17 dB and 0.12 dB in foreground and background text restoration, respectively. Furthermore, to resolve residual misalignment issues after image restoration, a key-field alignment method is introduced. This method accurately locates the positional deviations of critical fields in the reconstructed image, enabling precise field-level alignment and structural correction. Based on the proposed preprocessing framework, the recognition accuracy and field-matching accuracy are improved by 23% and 31%, respectively, compared to existing commercial OCR models, significantly enhancing the recognition performance on misaligned and overlapping documents. This study provides an effective solution for recognizing secondary printed documents with text overlap in industrial environments.},
  archive      = {J_FRAI},
  author       = {Wang, Senlong and Ge, Junchao and Zhang, Jiantao and He, Hong and Zhang, Yunwei},
  doi          = {10.3389/frai.2025.1616007},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1616007},
  shortjournal = {Front. Artif. Intell.},
  title        = {Image restoration and key field alignment for misaligned overlapping text in secondary printing document images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ethical implications of ChatGPT and other large language models in academia. <em>FRAI</em>, <em>8</em>, 1615761. (<a href='https://doi.org/10.3389/frai.2025.1615761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of technology in the digital age has significantly transformed human communication and knowledge exchange. At the forefront of this transformation are Large Language Models (LLMs), powerful neural networks trained on vast text corpora to perform a wide range of Natural Language Processing (NLP) tasks. While LLMs offer promising benefits such as enhanced productivity and human-like text generation, their integration into academic settings raises pressing ethical concerns. This study investigates the ethical dimensions surrounding the use of LLMs in academia, driven by their increasing prevalence and the need for responsible adoption. A mixed-methods approach was employed, combining surveys, semi-structured interviews, and focus groups with key stakeholders, including students, faculty, administrators, and AI developers. The findings reveal a high level of LLM adoption accompanied by concerns related to plagiarism, bias, authenticity, and academic integrity. In response, the study proposes concrete strategies for ethical integration, including: (1) the establishment of transparent usage policies, (2) the incorporation of LLM literacy training into academic curricula, (3) the development of institutional review frameworks for AI-generated content, and (4) ongoing stakeholder dialogue to adapt policies as the technology evolves. These recommendations aim to support the responsible and informed use of LLMs in scholarly environments. The widespread influence of technological advancement has notably transformed communication and knowledge sharing, with LLMs playing a central role. These advanced neural networks, trained on extensive text datasets, have become valuable tools for generating human-like text and improving efficiency. However, their growing use in academic contexts raises significant ethical concerns. This study investigates these issues, focusing on the implications of LLM integration in scholarly environments. Using mixed methods, including surveys, semi-structured interviews, and focus groups, the research gathered insights from students, faculty, administrators, and AI developers. The findings highlight substantial adoption of LLMs alongside concerns about plagiarism, bias, and academic integrity. Based on this input, the study proposes guidelines for their responsible and ethical use in academia.},
  archive      = {J_FRAI},
  author       = {Almufarreh, Ahmad and Ahmad, Ashfaq and Arshad, Muhammad and Onn, Choo Wou and Elechi, Robinson},
  doi          = {10.3389/frai.2025.1615761},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1615761},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ethical implications of ChatGPT and other large language models in academia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of the hybrid machine learning models for brain tumour segmentation and detection in medical images. <em>FRAI</em>, <em>8</em>, 1615550. (<a href='https://doi.org/10.3389/frai.2025.1615550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and accurate detection of brain tumours using Magnetic Resonance Imaging (MRI) is critical for effective treatment and improved patient outcomes. This systematic review investigates the application of hybrid machine learning (ML) and deep learning (DL) models in enhancing the computational efficiency and diagnostic accuracy of brain tumour analysis from MRI images. The study synthesizes recent advances in combining traditional ML models such as Support Vector Machines (SVM) with deep neural networks like VGG-19 and YOLOv10n. A PRISMA-based literature search strategy was employed across major databases, including PubMed, Scopus, and IEEE Xplore, selecting 25 relevant studies published between 2019 and 2024. The review evaluates the performance of standalone and hybrid models using metrics such as Dice Similarity Coefficient (DSC), Intersection over Union (IoU), accuracy, precision, recall, and F1-score. Findings indicate that hybrid models, particularly those combining SVM with CNN-based architectures like VGG-19, demonstrate improved classification accuracy and reduced false positives, outperforming single-model approaches. Lightweight versions such as YOLOv10n offer faster inference times suitable for real-time applications while maintaining competitive accuracy. Despite these advances, challenges remain in model generalizability, lack of large, annotated datasets, and limited adoption of Explainable AI (XAI) for interpretability. This review highlights the potential of hybrid models for brain tumour detection and offers recommendations for future research to focus on scalable, interpretable, and clinically deployable solutions.},
  archive      = {J_FRAI},
  author       = {Netshamutshedzi, Ndivhuwo and Netshikweta, Rendani and Ndogmo, Jean-Claude and Obagbuwa, Ibidun Christiana},
  doi          = {10.3389/frai.2025.1615550},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1615550},
  shortjournal = {Front. Artif. Intell.},
  title        = {A systematic review of the hybrid machine learning models for brain tumour segmentation and detection in medical images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI adoption among adolescents in education: Extending the UTAUT2 with psychological and contextual factors. <em>FRAI</em>, <em>8</em>, 1614993. (<a href='https://doi.org/10.3389/frai.2025.1614993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis correlational study investigates the psychological and contextual factors associated with the adoption of artificial intelligence (AI) technologies among Italian high school students. Building on the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2), the study extends the model by incorporating Problematic Internet Use (PIU) and Attitudes Toward AI (ATAI) to better account for habitual AI use and behavioural intentions.MethodA sample of 933 students (Mage = 16.20, SDage = 1.29, 54.98% female) completed a survey assessing key UTAUT2 dimensions, psychological traits, and usage patterns of AI tools in educational contexts. Confirmatory factor analysis (CFA) was used to evaluate the functioning of the adapted UTAUT2. Multiple regression was used to investigate factors predicting habit formation and behavioural intention related to AI use.ResultsConfirmatory factor analysis supported the structural validity of the adapted UTAUT2 model. Multiple regression analyses revealed that Performance Expectancy, Social Influence, Hedonic Motivation, and Schoolwork-related AI use were significant predictors of both habit and behavioural intention. PIU showed a robust association with habitual use, suggesting a spillover effect from compulsive Internet behavior to AI engagement. ATAI was associated only with behavioural intention, indicating its role in initial adoption rather than sustained use. Demographic and contextual factors (e.g., school type, citizenship) showed additional effects.DiscussionThese findings contribute to a more comprehensive understanding of adolescent AI engagement by highlighting the role of compulsive tendencies and motivational beliefs. The study underscores the importance of designing inclusive, age-appropriate interventions to promote balanced and informed AI use in educational settings.},
  archive      = {J_FRAI},
  author       = {Caffaratti, Luca Ballestra and Longobardi, Claudio and Badenes-Ribera, Laura and Marengo, Davide},
  doi          = {10.3389/frai.2025.1614993},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1614993},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI adoption among adolescents in education: Extending the UTAUT2 with psychological and contextual factors},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAAPO: Genetic algorithmic applied to prompt optimization. <em>FRAI</em>, <em>8</em>, 1613007. (<a href='https://doi.org/10.3389/frai.2025.1613007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, with their performance heavily dependent on the quality of input prompts. While prompt engineering has proven effective, it typically relies on manual adjustments, making it time-consuming and potentially suboptimal. This paper introduces GAAPO (Genetic Algorithm Applied to Prompt Optimization), a novel hybrid optimization framework that leverages genetic algorithm principles to evolve prompts through successive generations. Unlike traditional genetic approaches that rely solely on mutation and crossover operations, GAAPO integrates multiple specialized prompt generation strategies within its evolutionary framework. Through extensive experimentation on diverse datasets including ETHOS, MMLU-Pro, and GPQA, our analysis reveals several important points for the future development of automatic prompt optimization methods: importance of the tradeoff between the population size and the number of generations, effect of selection methods on stability results, capacity of different LLMs and especially reasoning models to be able to automatically generate prompts from similar queries… Moreover, we decided to use limited size datasets extracted from the original databases to ensure real life applications of our prompt optimization strategy. Finally, we provide insights into the relative effectiveness of different prompt generation strategies and their evolution across optimization phases. These findings contribute to both the theoretical understanding of prompt optimization and practical applications in improving LLM performance.},
  archive      = {J_FRAI},
  author       = {Sécheresse, Xavier and Guilbert–Ly, Jacques-Yves and Villedieu de Torcy, Antoine},
  doi          = {10.3389/frai.2025.1613007},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1613007},
  shortjournal = {Front. Artif. Intell.},
  title        = {GAAPO: Genetic algorithmic applied to prompt optimization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMS-ViT: A multi-scale vision transformer approach for real-time smartphone-based skin cancer detection. <em>FRAI</em>, <em>8</em>, 1612502. (<a href='https://doi.org/10.3389/frai.2025.1612502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is the abnormal growth of skin cells. It occurs mostly in skin exposed to sunlight. To prevent the occurrence of skin cancer, avoid exposing skin to ultraviolet radiation. Skin cancer can be very harmful if found very late. Traditional convolutional neural networks (CNNs) face challenges in fine-grained lesion classification due to their limited ability to extract detailed features. To overcome such limitations, we introduced a novel approach in the form of a lightweight multi-scale vision transformer (LMS-ViT) application for the automated detection of skin cancer using dermoscopic images and the HAM10000 dataset. Unlike CNNs, LMS-ViT employs a multi-scale attention mechanism to capture both global lesion structures and fine-grained textural details, improving classification accuracy. This study combines skin images from the HAM10000 dataset with pictures taken using a smartphone. It uses a compact method to mix important features, which makes the system faster and suitable for real-time use in medical apps. The proposed system enables real-time skin cancer classification via a smartphone camera, making it portable and platform-independent. Experimental results show that LMS-ViT surpasses CNN-based models across all skin lesion categories, achieving 90% accuracy, an 18% improvement over CNN, while reducing computational cost by 30%. LMS-ViT also improves precision, recall, and F1-score, particularly in complex categories such as Vasc (0.96 to 1.01) and Nv (0.94 to 1.01), demonstrating superior classification power. With real-time android implementation, LMS-ViT offers accessible, mobile-friendly diagnostics for early skin cancer detection.},
  archive      = {J_FRAI},
  author       = {Leema, A. Anny and Balakrishnan, P. and Gopichand, G. and Rajarajan, G.},
  doi          = {10.3389/frai.2025.1612502},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1612502},
  shortjournal = {Front. Artif. Intell.},
  title        = {LMS-ViT: A multi-scale vision transformer approach for real-time smartphone-based skin cancer detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of vision transformers for the detection of fullness of garbage bins for efficient waste management. <em>FRAI</em>, <em>8</em>, 1612080. (<a href='https://doi.org/10.3389/frai.2025.1612080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient waste management is crucial for urban environments to maintain cleanliness, reduce environmental impact, and optimize resource allocation. Traditional waste collection systems often rely on scheduled pickups or manual inspections, leading to inefficient resource utilization and potential overflow issues. This paper presents a novel approach to automate the detection of garbage container fullness from images using machine learning techniques. More specifically, we explore three transformer-based architectures, namely, vision transformer, Swin transformer, and pyramid vision transformer to classify input images of garbage bins as clean or dirty. Our experimental results on the publicly available Clean dirty containers in Montevideo dataset suggest that transformer-based architectures are effective in garbage fullness detection. Moreover, a comparison with existing methods reveals that the proposed approach using the vision transformer surpasses the state-of-the-art, achieving a 96.74% accuracy in detecting garbage container fullness. In addition, the generalizability of the proposed approach is evaluated by testing the transformer-based classification frameworks on a synthetic image dataset generated using various generative AI models. The proposed approach achieved a highest test accuracy of 80% on this synthetic dataset, thereby highlighting its ability to generalize across different datasets. Synthetic dataset used in this work can be found at: https://www.kaggle.com/datasets/6df0652d2c4eb3b9f00043c40fba0afa0778b46d7c0685e212807c2f6967fe6f.},
  archive      = {J_FRAI},
  author       = {Tanwer, Parakram Singh and Maheshwari, Shishir and Behera, Sushree and Chauhan, Amit and Sunil Kumar, T.},
  doi          = {10.3389/frai.2025.1612080},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1612080},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of vision transformers for the detection of fullness of garbage bins for efficient waste management},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lung cancer risk prediction using augmented machine learning pipelines with explainable AI. <em>FRAI</em>, <em>8</em>, 1602775. (<a href='https://doi.org/10.3389/frai.2025.1602775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer remains the leading cause of cancer-related deaths worldwide, making early and precise diagnosis is critical for improving the patient survival rates. Machine learning has shown promising results in predictive analysis for lung cancer prediction. However, class imbalance in clinical datasets negatively impacts the performance of Machine Learning classifiers, leading to biased predictions and reduced accuracy. In an attempt to address this issue, various data augmentation techniques were applied alongside classification models to enhance predictive performance. This study evaluates data augmentation techniques paired with machine learning classifiers to address class imbalance in a small lung cancer dataset. A comparative analysis was conducted to assess the impact of different augmentation techniques with classification models. Experimental findings demonstrate that K-Means SMOTE, combined with a Multi-Layer Perceptron classifier, achieves the highest accuracy of 93.55% and an AUC-ROC score of 96.76%, surpassing other augmentation-classifier combinations. These results underscore the importance of selecting optimal augmentation methods to improve classification performance. Furthermore, to ensure model interpretability and transparency in medical decision-making, LIME is utilized to provide insights into model predictions. The study highlights the significance of advanced augmentation techniques in addressing data imbalance, ultimately enhancing lung cancer risk prediction through machine learning. The findings contribute to the growing field of AI-driven healthcare by emphasizing the necessity of selecting effective augmentation-classifier pairs to develop more accurate and reliable diagnostic models. Due to the dataset’s high cancer prevalence (87.45%) and limited size, this work is a preliminary methodological comparison, not a clinical tool. Findings emphasize the importance of augmentation for imbalanced data and lay the groundwork for future validation with larger, representative datasets.},
  archive      = {J_FRAI},
  author       = {M S, Pavithran and D, Saranyaraj and Chakrabortty, Anirban},
  doi          = {10.3389/frai.2025.1602775},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1602775},
  shortjournal = {Front. Artif. Intell.},
  title        = {Lung cancer risk prediction using augmented machine learning pipelines with explainable AI},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for cardiovascular management: Optimizing pathways and cost control under diagnosis-related group models. <em>FRAI</em>, <em>8</em>, 1580445. (<a href='https://doi.org/10.3389/frai.2025.1580445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVDs) remain the leading causes of morbidity, mortality, and healthcare expenditures, presenting substantial challenges for hospitals operating under Diagnosis-Related Group (DRG) payment models. Recent advances in deep learning offer new strategies for optimizing CVD management to meet cost control objectives. This review synthesizes the roles of deep learning in CVD diagnosis, treatment planning, and prognostic modeling, emphasizing applications that reduce unnecessary diagnostic imaging, predict high-cost complications, and optimize the utilization of critical resources like ICU beds. By analyzing medical images, forecasting adverse events from patient data, and dynamically optimizing treatment plans, deep learning offers a data-driven strategy to manage high-cost procedures and prolonged hospital stays within DRG budgets. Deep learning offers the potential for earlier risk stratification and tailored interventions, helping mitigate the financial pressures associated with DRG reimbursements. Effective integration requires multidisciplinary collaboration, robust data governance, and transparent model design. Real-world evidence, drawn from retrospective studies and large clinical registries, highlights measurable improvements in cost control and patient outcomes; for instance, AI-optimized treatment strategies have been shown to reduce estimated mortality by 3.13%. However, challenges—such as data quality, regulatory compliance, ethical issues, and limited scalability—must be addressed to fully realize these benefits. Future research should focus on continuous model adaptation, multimodal data integration, equitable deployment, and standardized outcome monitoring to validate both clinical quality and financial return on investment under DRG metrics. By leveraging deep learning’s predictive power within DRG frameworks, healthcare systems can advance toward a more sustainable model of high-quality, cost-effective CVD care.},
  archive      = {J_FRAI},
  author       = {Chen, Haohao and Zeng, Ying and Cai, De},
  doi          = {10.3389/frai.2025.1580445},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1580445},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning for cardiovascular management: Optimizing pathways and cost control under diagnosis-related group models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluorescent marker prediction for non-invasive optical imaging in bovine satellite cells using deep learning. <em>FRAI</em>, <em>8</em>, 1577027. (<a href='https://doi.org/10.3389/frai.2025.1577027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the quality of bovine satellite cells (BSCs) is vital for advancing tissue engineered muscle constructs with applications in sustainable protein research. In this study, we present a non-invasive deep learning approach for optical imaging that predicts fluorescent markers directly from brightfield microscopy images of BSC cultures. Using a convolutional neural network based on the U-Net architecture, our method simultaneously predicts two key fluorescent signals, specifically DAPI and Pax7, which serve as biomarkers for cell abundance and differentiation status. An image preprocessing pipeline featuring fluorescent signal denoising was implemented to enhance prediction performance and consistency. A dataset comprising 48 biological replicates was evaluated using statistical metrics such as the Pearson r (correlation coefficient), the mean squared error (MSE), and the structural similarity Index (SSIM). For DAPI, denoising improved the Pearson r from 0.065 to 0.212 and SSIM from 0.047 to 0.761 (with MSE increasing from 9.507 to 41.571). For Pax7, the Pearson r increased from 0.020 to 0.124 and MSE decreased from 44.753 to 18.793, while SSIM remained low, reflecting inherent biological heterogeneity. Furthermore, enhanced visualization techniques, including color mapping and image overlay, improved the interpretability of the predicted outputs. These findings underscore the importance of optimized data preprocessing and demonstrate the potential of AI to advance non-invasive optical imaging for cellular quality assessment in tissue biology. This work also contributes to the broader integration of machine learning and computer vision methods in biological and agricultural applications.},
  archive      = {J_FRAI},
  author       = {Sinha, Sania and Wasit, Aarham and Kim, Won Seob and Kim, Jongkyoo and Yi, Jiyoon},
  doi          = {10.3389/frai.2025.1577027},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1577027},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fluorescent marker prediction for non-invasive optical imaging in bovine satellite cells using deep learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding manipulative narratives in cognitive warfare: A case study of the russia-ukraine conflict. <em>FRAI</em>, <em>8</em>, 1566022. (<a href='https://doi.org/10.3389/frai.2025.1566022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study investigates the construction and dissemination of manipulative narratives in the context of cognitive warfare during the Russia-Ukraine conflict. Leveraging a mixed-methods approach that integrates AI-assisted semantic analysis with expert validation, we examine how adversarial messaging exploits cognitive biases-such as fear and confirmation bias-to influence perceptions and disrupt institutional trust.MethodsUsing the proprietary Attack-Index tool and large language models (LLMs), we detect linguistic markers of manipulation, including euphemisms, sarcasm, and strategic framing.ResultsOur findings demonstrate that emotionally charged narratives, particularly those invoking nuclear threat scenarios, are synchronized with key geopolitical events to influence decision-makers and public opinion. The study identifies five thematic clusters and traces shifts in rhetorical strategies over time, showing how manipulative discourse adapts to geopolitical contexts. Special attention is given to the differentiated targeting of international political elites, Western publics, and Russian domestic audiences, each exhibiting varied cognitive vulnerabilities.DiscussionWe acknowledge methodological and ethical limitations, including the dual-use potential of AI tools and challenges in establishing causal inferences. Nonetheless, this study offers the following key contributions:Empirically establishing nuclear rhetoric as a strategic element of narrative manipulation, particularly around NATO summits and military aid announcements.Advancing an integrated analytical framework that combines semantic clustering and AI-based discourse detection to monitor information threats in real time.Providing actionable insights for policy and digital security, including the development of countermeasures and international collaboration in addressing cognitive warfare.},
  archive      = {J_FRAI},
  author       = {Paziuk, Andrii and Lande, Dmytro and Shnurko-Tabakova, Elina and Kingston, Phillip},
  doi          = {10.3389/frai.2025.1566022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1566022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Decoding manipulative narratives in cognitive warfare: A case study of the russia-ukraine conflict},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A drop-out mechanism for active learning based on one-attribute heuristics. <em>FRAI</em>, <em>8</em>, 1562916. (<a href='https://doi.org/10.3389/frai.2025.1562916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Learning (AL) leverages the principle that machine learning models can achieve high accuracy with fewer labeled samples by strategically selecting the most informative data points for training. However, when human annotators provide these labels, their decisions might exhibit a systematic bias. For example, humans frequently rely on a limited subset of the available attributes, or even on a single attribute, when making decisions, as when employing fast and frugal heuristics. This paper introduces a mathematically grounded approach to quantify the probability of mislabeling based on one attribute. We present a novel dropout mechanism designed to influence the attribute selection process used in annotation, effectively reducing the impact of bias. The proposed mechanism is evaluated using multiple AL algorithms and heuristic strategies across diverse prediction tasks. Experimental results demonstrate that the dropout mechanism significantly enhances active learning (AL) performance, achieving a minimum 70% improvement in effectiveness. These findings highlight the mechanism's potential to improve the reliability and accuracy of AL systems, providing valuable insights for designing and implementing robust intelligent systems.},
  archive      = {J_FRAI},
  author       = {Ravichandran, Sriram and Sudarsanam, Nandan and Ravindran, Balaraman and Katsikopoulos, Konstantinos V.},
  doi          = {10.3389/frai.2025.1562916},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1562916},
  shortjournal = {Front. Artif. Intell.},
  title        = {A drop-out mechanism for active learning based on one-attribute heuristics},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lexicon obtained and validated by a data-driven approach for organic residues valorization in emerging and developing countries. <em>FRAI</em>, <em>8</em>, 1557137. (<a href='https://doi.org/10.3389/frai.2025.1557137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open dump remains the main management process of organic residue in middle-and low-income countries [1]. Indeed, according to this study, municipal solid waste is composed of 44% organic fraction. However, waste recycling or valorization is about 7, 4.7, and 21% in Sub-Saharan Africa, Caribbean/Latin America, and South Asia respectively. It is thus interesting to determine organic residue valorization status in those regions. Answer to that question could be prospected through textual analysis. The method herein represents the first step to that end. Indeed, when missing, text mining could be used to extract thematic lexicon from a bibliographic corpus to drive a state-of-art in the valorization of organic residues in agriculture in developing countries. In this work, text mining and Natural Language Processing (NLP) methods enable to generate a specialized lexicon on this specific area. The definition of relevance of terms is challenging and discussed in this data paper. Actually, terminology extraction methods are generally based on benchmarks (i.e. gold-standard) or terms manually validated [2] but an experimental protocol that takes into account different kinds of relevance to consolidate the process is understudied. This needs to integrate expertise knowledge, agreement of experts regarding definitions and evaluation associated with, and the task to do. This paper highlights how this construction is conducted by considering different point-of-view of relevance in a multidisciplinary context. It is important to notice that this kind of lexicon specifically focused on organic residues valorization does not exist in agriculture semantic resources like AgroPortal which include more than 200 ontologies/thesaurii/lexicons [3].The present work consisted of using text mining approach to construct thematical lexicon from a corpus related to valorization of organic waste in developing countries. Method used to collect data was detailed first, followed by a section about the technic adopted to select, annotate, and validate the lexicon. Finally, future perspective work was explained in a concluding section. This exploratory methodology could be used to guide a more in-depth and oriented text analysis of scientific publications (i.e. scientometric analysis). Moreover, this methodology can be reused and/or adapted in other domain depending on purpose. In our ongoing work, we use this lexicon to conduct a semantic analysis of scientific publications dealing with organic residues valorization in emerging and developing countries.Proposed Method to Collect the DataSeveral online databases were consulted in 2021, to extract articles relating to biotransformation and valorization in agriculture of organic residues in emerging and developing countries (WoS, Ovid, Scopus, Google scholar, HAL, Cairn.info, AGRIS, and Agritropfoot_0 ) published until 2021. Terms used for bibliographic search in all databases through specific queries are detailed in the Appendix section of this paper.The equation used in the Web of Science collection was thereafter adapted for the other databases specificities. Advanced search was not available for most of the free online database, a global thematical search was then adopted (Appendix 1). The search gave 24 186 references on which a selective sorting was conducted to avoid duplicates and to select references in English only. A total of 7 692 references were used to generate the dataset available in the excel file (Initial_Corpus_References.xlsx) available on depository [4]. The corpus of the dataset combines articles, reports, book sections, and student thesis with bibliographic references (authors, year of publication, title, doi, and url).BioTex [5] was used to perform an Automatic Term Extraction (ATE) on the corpus. The terms extracted (e.g. rumen, humic acid, nutrient recovery, …) give a semantic point of view of the theme of the text. This tool was developed for Biomedical term extraction [6] and was adapted to extract terms associated with food security [7]. First, BioTex performed a linguistic screening through syntactic patterns (noun-noun, adjective-noun, …). In order to rank terms extracted on the "titles" corpus, the F-TF-IDF-C score integrated to BioTex was applied. This measure combines (i) C-value (4) to favor multi-word terms extracted, and (ii) TF-IDF (Term Frequency-Inverse Document Frequency) to highlight discriminative terms [6].Text mining was thereafter performed on titles of the corpus using the BioTex tools [5] and the result can be found in the associated excel file (Extracted_Terms.xlsx) on depository (1). The first column contains the 19 580 terms obtained from the extraction. The second column ("term") presents the terms constituted of words or compound nouns (e.g. mulch, effluents, soil amendments, bagasse cocomposting). The rank, in the last column, is obtained by maximizing a discriminative score associated with terms (i.e. F-TF-IDF-C).Five specialist raters conducted a first annotation on 200 sampled candidate terms among the 19 580 to exclude irrelevant terms to the topic of interest following the guideline file (Annotation_guidelines.pdf) available on the depository [4]. Specialists were researchers in "Recyclage et risque" unit of Cirad in France, working on recycling organic residue in agriculture and associated risks. The group was specialized in biochemistry, agronomy, microbiology, ecologist, soil science, and environmental assessment using both monitoring and modelling approaches. Each rater was asked to categorize each candidate term belonging to i) organic residues (OWT) and/or ii) biotransformation process (TM) and/or iii) valorization in agriculture (AV) or iv) none of them (None)following the first annotation guide. Definition of each category is described in the annotation guidelines. Table 1 shows example of the first step of annotation conducted by specialist.The Fleiss Kappa [8] which measures agreement between several raters equals to 0.52 for this first annotation corresponding to a bad agreement between the 5 raters. The 4 categories chosen to annotate the candidate terms appeared to be too restrictive. Terms indirectly associated to one or more of the 4 categories have been excluded by several raters.In a second annotation guideline, the manual labelling process focuses on the overall degree of pertinence related to the topic of valorization of organic residues. In this context, candidate term was annotated according 3 classes: (i) very pertinent when it was directly connected to one or more category(ries) (i.e. OWT+, TM+, AV+), (ii) pertinent when it was indirectly connected to one or more category(ries) (i.e. OWT, TM, AV), and (iii) irrelevant (i.e. None).A second annotation on the same 200 sampled terms was conducted. All results of the two series of annotation can be viewed with the file "Raters_Annotation_Results.xlsx" in our dataset [4]. Fleiss Kappa was calculated for 3 and 5 raters. It revealed a decreasing trend of the value (0.84 to 0.60) with increasing number of raters. Closer comparison highlighted more terms indirectly related to one or more category(ies) selected by 3 raters with high value of Kappa. In order to include as many terms indirectly related to the subject as possible, it was decided to apply the logic of these 3 annotators to pursue the categorization of the remaining terms.In Table 2, the results are evaluated in terms of precision (percentage of pertinent terms) obtained over the top k extracted terms (P@k). The results confirm that the ranking function of BioTex is adapted by highlighting relevant terms at the top of the list. For instance, precision value with k=100 and k=200 is high (more than 80%) but recall will be low because a lot of relevant terms are not proposed. Actually, a precise recall value is difficult to calculate because we do not have gold standard.The above detailed dataset can be found in the CIRAD Dataverse repository [4].One of the 5 specialists then pursued the annotation, with a degree of relevance, on the remaining extracted terms. It was decided to continue the categorization with the degree of pertinence and to apply the logic of the 3 annotators with the high kappa value explained above. It took about one-week work for the rater to conduct the categorization. The same five raters were then asked to verify and finalize the terms selection related to the biotransformation and valorization in agriculture of organic residues in low-income countries. All verified relevant terms were combined in the last file on the depository (Pertinent_Terms.xlsx), containing terms which can be indirectly (first sheet) or directly (second to fourth sheet) related to the topic.From the 19 580 initial candidate terms, about 75% were not associated to the topic of interest (Table 2). Irrelevant terms included words which are not related to organic residues nor biotransformation nor valorization in agriculture, such as: absence, certification, design, effect, fecundity, fitness, gray, immune response, integration analysis, low cost, marker genes, …. Among the 25% relevant terms, 2 079 were closely associated with the organic residues valorization in emerging and developing countries such as sludge, sewage, livestock, manure, slurry, anaerobic digestion, composting, vermicomposting. Several terms can be found in the glossary of terms related to livestock and manure management [9] and figure among terms with high pertinence in this dataset. Moreover, some of relevant terms are cited in literatures as the biotransformation (e.g.: anaerobic digestion, composting, bioethanol, biohydrogen) and valorization in agriculture (e.g.: biofertilization, organic fertilizers, amendments) of organic residues (e.g. rice straw, sugarcane bagasse, animal manure) [10], [11].The produced lexicon is currently used in a semantic-driven analysis of our corpus based on the CorTexT software [12]. In the context of this multidisciplinary work on-going, we obtain deeper knowledge regarding bioconversion and valorization in agriculture of organic residues in low-income countries as highlighted in Figure 1-A and B.The text-mining tool used in this work is based on statistical criteria that highlight discriminative terms. This method identifies significant terms that are present in the texts. As future work, the proposed framework could be extended by extracting variation of terms [13] that enables to recognize rare and/or unsystematic terms but also synonyms. Moreover, embedding approaches [14], language models [15], generative methods based on LLM (Large Language Models) techniques [16] could be applied to recognize new terms. Language model techniques are based on generic models like BERT -Bidirectional Encoder Representations from Transformers [15] or specific ones like AgriBERT -Knowledge-Infused Agricultural Language Models for Matching Food and Nutrition [17] dedicated to the agriculture domain. These models can be fine-tuned for specific tasks like terminology extraction.There can be used to improve terminology extraction. Note that the use of language models could be relevant for specific NLP tasks and domains like the agriculture area [18]. As future work, we plan to compare the applied methods described in this paper with other approaches based on language models but also Large Language Models (LLM) for terminology extraction [19]. LLM could also be used to expand our initial lexicon. This enables to extract variations of exiting terms and synonyms but also new terms. In the context of our work, the objective is to conduct a semantic analysis of terms present in the corpus, so the use of words or phrases in our lexicon but not used in our dataset (i.e. corpus) is not really useful. Web of science Core collection query: WOS, FSTA and Biosis TS = ("sewage sludge" OR "crop residue*" OR "agricultural waste" OR "industrial waste" OR "food waste" OR "household waste" OR "organic waste" OR "urban waste" OR "co-product*" OR "byproduct*" OR "biomass" OR "organic waste product*" OR mulch OR digestate* OR compost*) AND TS = (decomposition OR fermentation OR anaerobic OR aerobic OR methanisation OR composting OR vermicomposting OR fertilization OR bokashi OR biodegradation OR mineralization OR recycling OR "agricultural valuation" OR biotransformation OR mulching) AND TS = (africa OR "acp countries" OR "central america" OR "south america" OR "latin america" OR "south east asia" OR "south asia" OR afghanistan OR angola OR albania OR argentina OR armenia OR antigua OR azerbaijan OR burundi OR benin OR "burkina faso" OR bangladesh OR bosnia OR belarus OR belize OR bolivia OR brazil OR bhutan OR botswana OR "central african republic" OR china OR "ivory coast" OR cameroon OR congo OR colombia OR comoros OR "cape verde" OR "costa rica" OR cuba OR djibouti OR dominica OR "dominican republic" OR algeria OR ecuador OR egypt OR eritrea OR ethiopia OR fiji OR micronesia OR gabon OR georgia OR ghana OR guinea OR gambia OR grenada OR guatemala OR guyana OR honduras OR haiti OR indonesia OR india OR iran OR iraq OR jamaica OR jordan OR kazakhstan OR kenya OR kyrgyzstan OR cambodia OR kiribati OR "lao people's democratic republic" OR lebanon OR liberia OR libya OR "saint lucia" OR "sri lanka" OR lesotho OR morocco OR moldova OR madagascar OR maldives OR mexico OR "marshall islands" OR "north macedonia" OR mali OR myanmar OR montenegro OR mongolia OR mozambique OR mauritania OR montserrat OR mauritius OR malawi OR malaysia OR namibia OR niger OR nigeria OR nicaragua OR niue OR nepal OR nauru OR pakistan OR panama OR peru OR philippines OR palau OR "papua new guinea" OR " Democratic People's Republic of Korea" OR "north korea" OR paraguay OR "palestinian territory" OR rwanda OR sudan OR senegal OR "saint helena, ascension and tristan da cunha" OR "solomon islands" OR "sierra leone" OR "el Salvador" OR somalia OR serbia OR "south sudan" OR "sao tome and principe" OR suriname OR eswatini OR "syrian arab republic" OR chad OR togo OR thailand OR tajikistan OR tokelau OR turkmenistan OR "timor-leste" OR tonga OR tunisia OR turkey OR tuvalu OR tanzania OR uganda OR ukraine OR uzbekistan OR "saint vincent and the grenadines" OR venezuela OR "vietnam" OR vanuatu OR "wallis and futuna" OR samoa OR yemen OR "south africa" OR zambia OR zimbabwe). Due to a very high number obtained with the equivalent of WoS query, the following query was used for scopus with subject area=environmental sciences or agricultural. Then, only articles, reviews and conference paper were selected.TITLE-ABS-KEY ( "sewage sludge" OR "crop residue*" OR "agricultural waste" OR "industrial waste" OR "food waste" OR "household waste" OR "organic waste" OR "urban waste" OR "coproduct*" OR "by-product*" OR "biomass" OR "organic waste product*" OR mulch OR digestate* OR compost* ) AND TITLE-ABS-KEY ( decomposition OR fermentation OR anaerobic OR aerobic OR methanisation OR composting OR vermicomposting OR fertilisation OR bokashi OR biodegradation OR mineralisation OR recycling OR "agricultural valuation" OR biotransformation OR mulching ) AND ( LIMIT-TO ( SUBJAREA , "ENVI" ) OR LIMIT-TO ( SUBJAREA , "AGRI" ) ) AND ( LIMIT-TO ( DOCTYPE , "ar" ) OR LIMIT-TO ( DOCTYPE , "re" ) OR LIMIT-TO ( DOCTYPE , "cp" ) )Google scholar, HAL, Cairn.info, AGRIS:Advanced research was not available on free databases; the research was thus conducted with a general query on the topic which was:-In French : « biotransformation et valorisation en agriculture dans les contextes des pays du Sud » -In English « biotransformation et valorization in agriculture in low-income countries» in English. The query was then tested by adding Africa, Latin America, then South-East Asia ».},
  archive      = {J_FRAI},
  author       = {Rakotomalala, Christiane and Paillat, Jean-Marie and Feder, Frédéric and Avadí, Angel and Thuriès, Laurent and Vermeire, Marie-Liesse and Médoc, Jean-Michel and Wassenaar, Tom and Hottelart, Caroline and Kieffer, Lilou and Ndjie, Elisa and Picart, Mathieu and Tchamgoue, Jorel and Tulle, Alvin and Valade, Laurine and Boyer, Annie and Duchamp, Marie-Christine and Roche, Mathieu},
  doi          = {10.3389/frai.2025.1557137},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1557137},
  shortjournal = {Front. Artif. Intell.},
  title        = {A lexicon obtained and validated by a data-driven approach for organic residues valorization in emerging and developing countries},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An AI-powered framework for assessing teacher performance in classroom interactions: A deep learning approach. <em>FRAI</em>, <em>8</em>, 1553051. (<a href='https://doi.org/10.3389/frai.2025.1553051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTeacher performance evaluation is essential for improving instructional quality and guiding professional development, yet traditional observation-based methods can be subjective, labor-intensive, and inconsistently reliable. This study proposes an AI-powered framework to objectively assess classroom interactions.MethodsWe developed and evaluated a computer-vision framework using three state-of-the-art object detectors—YOLOv8, Faster R-CNN, and RetinaNet—to identify eleven classroom interaction categories. A labeled dataset of 7,259 images collected from real classroom settings was annotated and used for training and evaluation. Performance was assessed using mean Average Precision (mAP).ResultsYOLOv8 achieved the best performance among the evaluated models, with an mAP of 85.8%, indicating strong accuracy in detecting diverse classroom interactions. Faster R-CNN and RetinaNet performed competitively but were outperformed by YOLOv8.Discussion/ConclusionThe results demonstrate that modern deep learning–based detection can provide more objective and reliable insights into teacher–student interactions than traditional approaches. The proposed framework supports evidence-based evaluation and has the potential to enhance feedback and outcomes in educational practice.].},
  archive      = {J_FRAI},
  author       = {Almubarak, Arwa and Alhalabi, Wadee and Albidewi, Ibrahim and Alharbi, Eaman},
  doi          = {10.3389/frai.2025.1553051},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1553051},
  shortjournal = {Front. Artif. Intell.},
  title        = {An AI-powered framework for assessing teacher performance in classroom interactions: A deep learning approach},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced deep convolutional neural network for SARS-CoV-2 variants classification. <em>FRAI</em>, <em>8</em>, 1512003. (<a href='https://doi.org/10.3389/frai.2025.1512003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRapid and scalable classification of SARS-CoV-2 genomes from spike-gene sequences can support real-time genomic surveillance in contexts where whole-genome data or high-end computing resources are limited.MethodsWe curated approximately 35,800 quality-filtered spike sequences spanning multiple clades and lineages and trained a hybrid CNN–BiLSTM model with standard regularization and class-imbalance handling. Model performance was benchmarked against Nextclade assignments and compared with classical machine-learning baselines.ResultsAcross 10 experimental runs, the model achieved a mean training accuracy of 99.74% ± 0.11, a validation accuracy of 99.00% ± 0.00, and a test accuracy of 99.91% ± 0.03. In benchmarking against the molecular epidemiology tool Nextclade, our model demonstrated superior performance, correctly identifying 100% of Omicron sequences, compared to 34.95% achieved by Nextclade. Saliency and feature attribution analyses highlighted recurrent spike substitutions consistent with known variant-defining mutations, as well as additional uncharacterized motifs with potential biological relevance.DiscussionThese findings demonstrate that spike-only deep models can provide rapid and accurate clade or variant classification, while also yielding interpretable feature importance. Such models complement phylogenetic approaches in settings with constrained resources and enable efficient triage of samples for confirmatory whole-genome analysis, supporting more timely genomic surveillance.},
  archive      = {J_FRAI},
  author       = {Awe, Olaitan I. and Obura, Hesborn and Ssemuyiga, Charles and Mudibo, Evans and Mwanga, Mike J.},
  doi          = {10.3389/frai.2025.1512003},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1512003},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhanced deep convolutional neural network for SARS-CoV-2 variants classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global reform population health management as stewarded by higher expert medical science safety (HEMSS). <em>FRAI</em>, <em>8</em>, 1496948. (<a href='https://doi.org/10.3389/frai.2025.1496948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As described in a Memorandum of Understanding (MoU) on AI infrastructure, global human phenotype ontology (HPO) is a priority for the US and the UK. The UK NHS Act of 1946 and the Medicare and Medicaid Act of 1965 classify using genomics as primary care, supporting international HPO aims for Population Health Management (PHM). The Higher Expert Medical Science Safety (HEMSS) proposes the NHS England, Genomics, and Biobank agile group developers. The HEMSS strategy executes the PHM of the HPO through digital records, pilot citizen predictor pre-eXams, and precise eXam intercept classifications, continuously improving public safety. PHM reform includes biobank opportunities for Value-Based Care (VBC) stratifying genomic and socio-environmental factors that risk HPO in disease segmentation. The author evaluated a standard approach to PHM for HPO with mature and advanced interoperable standards. A reform toolkit aligns adversarial, neural, and transformer models for Generative AI by utilizing multimodal data nuanced for fairness in Quantum Intelligence. The recommendations include HEMSS steps from well-being evaluations to the PHM strategy for HPO in the UK-US. Concepts involve piloting the scaling up of neighborhood clinics and federal centers through reform classification. Plans for citizen privacy facilitate data use with access to reference biobanks, ensuring DNA democratization and national cybersecurity. The UK NHSE corporate governance and US federal authorities monitor and reform the Integrated Care Board assessments and the Centers for Medicare and Medicaid Services surveys using agile methods. The UK-US MoU for AI safety is an international ideal for PHM, creating a safe space for HPO adherence to predictive and interceptive adoption for health and socioeconomic growth. HEMSS Agile Group Development impacts ethical and societal primary care debates. HEMSS discussions on global public health inclusiveness and national engagement aim to govern the classification phases for adherence. Therefore, debates on UK-US accreditation or regulation on the future of Artificial General Intelligence follow. The author concludes in support of the Population Health Management Expert Medical Science Safety Agile Group Development Program. The UK and US governments would benefit from this proposition, and international goals for well-being and socioeconomic growth would also be supported.},
  archive      = {J_FRAI},
  author       = {Henry, James Andrew},
  doi          = {10.3389/frai.2025.1496948},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1496948},
  shortjournal = {Front. Artif. Intell.},
  title        = {Global reform population health management as stewarded by higher expert medical science safety (HEMSS)},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for causal inference using low birth weight in midwife-led continuity care intervention in north shoa zone, ethiopia. <em>FRAI</em>, <em>8</em>, 1484299. (<a href='https://doi.org/10.3389/frai.2025.1484299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLow birth weight (LBW), under 2,500 g, poses health risks, though not always requiring treatment. Early detection of high-risk pregnancies enables preventive care, improving outcomes for mother and baby. This study aimed to establish cause-and-effect relationships using Causal Deep Learning (CDL) models that reduce bias and estimate heterogeneous treatment effects on LBW in the Midwife-Led Continuity Care (MLCC) intervention.MethodsThis study used a quasi-experimental study design (August 2019–September 2020) in North Shoa, Ethiopia, and enrolled 1,166 women divided into two groups: one receiving MLCC and the other receiving other professional groups for comprehensive antenatal/postnatal care. The dataset and code are provided in data availability section. Our model combines counterfactual convolutional neural networks to analyze time-based patterns and Bayesian Ridge regression to reduce bias in propensity scores. We use Counterfactual Regression with Wasserstein Distance (CFR-WASS) and Counterfactual Regression with Maximum Mean Discrepancy (CFR-MMD) to balance patient characteristics and improve counterfactual estimates of treatment effects. This approach strengthens causal insights into how MLCC interventions affect LBW outcomes.ResultThe Deep neural networks (DNN) model showed strong predictive accuracy for LBW, with 81.3% training and 81.4% testing performance, an area under the curve (AUC) of 0.88, enabling the reliable early identification of high-risk pregnancies. The study found a strong link between meconium aspiration syndrome (MAS) and LBW (p = 0.002), but this does not mean MAS directly causes LBW. MAS likely results from fetal distress or other pregnancy complications that may independently affect LBW. While statistical associations exist, clinical causation remains unproven; therefore, the counterfactual analysis showed MLCC could help reduce LBW risk. CFR-WASS achieved high accuracy (84%) while the precision in heterogeneous treatment effect (PEHE = 1.006) and the average treatment effect (ATE = 0.24), and CFR-MMD PEHE of 1.02, ATE of 0.45, demonstrating potential for tailored treatment strategies. DNN and multilayer perceptrons uniquely identified key neural weights and biases favoring normal birth weight while suppressing LBW predictions, offering interpretable insights for clinical risk assessment.ConclusionThe CFR-WASS/CFR-MMD model strengthens LBW prediction by identifying crucial factors like MAS and healthcare access, while accurate PEHE and ATE estimates support data-driven prenatal care and targeted interventions for healthier outcomes.},
  archive      = {J_FRAI},
  author       = {Moges, Wudneh Ketema and Tegegne, Awoke Seyoum and Mitku, Aweke A. and Tesfahun, Esubalew and Hailemeskel, Solomon},
  doi          = {10.3389/frai.2025.1484299},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1484299},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning for causal inference using low birth weight in midwife-led continuity care intervention in north shoa zone, ethiopia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review on knowledge and information extraction from PDF documents and storage approaches. <em>FRAI</em>, <em>8</em>, 1466092. (<a href='https://doi.org/10.3389/frai.2025.1466092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAutomating the extraction of information from Portable Document Format (PDF) documents represents a major advancement in information extraction, with applications in various domains such as healthcare, law, or biochemistry. However, existing solutions face challenges related to accuracy, domain adaptability, and implementation complexity.MethodsA systematic review of the literature was conducted using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to examine approaches and trends in PDF information extraction and storage approaches.ResultsThe review revealed three dominant methodological categories: rule-based systems, statistical learning models, and neural network-based approaches. Key limitations include the rigidity of rule-based methods, the lack of annotated domain-specific datasets for learning-based approaches, and issues such as hallucinations in large language models.DiscussionTo overcome these limitations, a conceptual framework is proposed comprising nine core components: project manager, document manager, document pre-processor, ontology manager, information extractor, annotation engine, question-answering tool, knowledge visualizer, and data exporter. This framework aims to improve the accuracy, adaptability, and usability of PDF information extraction systems.},
  archive      = {J_FRAI},
  author       = {Atagong, Salvador D. and Tonnang, Henri and Senagi, Kennedy and Wamalwa, Mark and Agboka, Komi M. and Odindi, John},
  doi          = {10.3389/frai.2025.1466092},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1466092},
  shortjournal = {Front. Artif. Intell.},
  title        = {A review on knowledge and information extraction from PDF documents and storage approaches},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Research on the robustness of the open-world test-time training model. <em>FRAI</em>, <em>8</em>, 1682908. (<a href='https://doi.org/10.3389/frai.2025.1682908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Pi, Shu and Wang, Xin and Pi, Jiatian},
  doi          = {10.3389/frai.2025.1682908},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1682908},
  shortjournal = {Front. Artif. Intell.},
  title        = {Correction: Research on the robustness of the open-world test-time training model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Deep neural network architectures and reservoir computing. <em>FRAI</em>, <em>8</em>, 1676744. (<a href='https://doi.org/10.3389/frai.2025.1676744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, deep learning (DL) techniques such as convolutional neural networks (CNNs) and long short-term memory (LSTM) networks have played a pivotal role in advancing the field of computational intelligence (Bengio et al. (2021)). Recent developments in deep neural network (DNN) architectures and computational infrastructure (particularly parallel computing), have further accelerated the progress by supporting the computational demands of optimizing large numbers of network parameters. These advancements have expanded the applicability of DL to a broad range of tasks in computational intelligence (Sharifani and Amini (2023)).Simultaneously, reservoir computing (RC) has attracted increasing attention (Tanaka et al. (2019)).Typically, RC consists of a fixed recurrent neural network (the reservoir) and a trainable readout layer. It exploits the nonlinear spatiotemporal dynamics of the reservoir to transform inputs, while learning is applied only to the output layer. This structure dramatically reduces the number of trainable parameters, resulting in high learning efficiency. However, conventional RC, which typically involves a single reservoir layer, has generally not matched the performance of deeper neural architectures used in mainstream DL.},
  archive      = {J_FRAI},
  author       = {Nobukawa, Sou and Bhattacharya, Arya Kumar and Hirose, Akira},
  doi          = {10.3389/frai.2025.1676744},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1676744},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Deep neural network architectures and reservoir computing},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the gatekeepers: How AI will revolutionize scientific funding. <em>FRAI</em>, <em>8</em>, 1667752. (<a href='https://doi.org/10.3389/frai.2025.1667752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) transforms nearly every domain of human endeavor, one of its most consequential impacts may be on science itself. This analysis explores how AI technologies could disrupt the power structures that govern research funding—structures that privilege senior investigators while sidelining early-career scientists and genuinely novel ideas. By juxtaposing the youth-driven innovation behind AI with the increasingly gerontocratic funding patterns in biomedical sciences, we highlight how institutional mechanisms shape not only who gets to do science but also when. Evidence suggests that conventional grant peer review has become a self-reinforcing system—more effective at preserving consensus than fostering discovery. AI presents a compelling alternative: evaluation frameworks that could reduce bias, broaden participation, and open more meritocratic pathways to research independence. The implications extend far beyond individual careers. At stake is society's ability to mobilize scientific creativity against its most urgent challenges. By rethinking outdated practices—especially the gatekeeping role of study sections—and exploring algorithmic approaches to assessment, we may be able to reverse troubling trends and unleash a broader, more diverse wave of discovery. AI will not fix science on its own, but it could help build a system where innovation is no longer an accident of privilege and timing.},
  archive      = {J_FRAI},
  author       = {Mangalam, Madhur},
  doi          = {10.3389/frai.2025.1667752},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1667752},
  shortjournal = {Front. Artif. Intell.},
  title        = {Breaking the gatekeepers: How AI will revolutionize scientific funding},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralizing video copyright protection: A novel blockchain-enabled framework with performance evaluation. <em>FRAI</em>, <em>8</em>, 1655709. (<a href='https://doi.org/10.3389/frai.2025.1655709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDigital content, including images and videos, is increasingly ruling the online world, and so multimedia services form a part of this modern life. However, the digital resources face significant problems, especially regarding copyright infringement. In such an instance, any modification without authority infringes intellectual property rights.MethodsBased on Inter Planetary File System (IPFS) and blockchain technology, a decentralized and distributed framework has been proposed in this study for dealing with insecurity over digital assets and openness of multimedia resources. In this respect, secure, transparent, and immutable transactions in regard to the transfer and ownership of creative works have been facilitated by the use of such a framework.ResultsThis paper proposes novel decentralized and Blockchain enabled framework to address the problem of video copyright protection by employing solidity based smart contract in a Ethereum network, that allows the content creators to register their videos. The designed smart contract performs copyright checks and release copyright disputes by generating and comparing perceptual hash’s (Phash) for original video and modified video.DiscussionPhash techniques play a crucial role in multimedia content analysis, particularly in verifying the integrity and similarity of the video data under various transformations. Additionally, the framework generates Inter Planetary File System (IPFS) main values that signifies the ownership of the video content. Then it compars the phash values, IPFS and similarly score in public Blockchain environment i.e. Ethereum. The framework performance was measured by simulating the contracts of the Application Binary Interface (ABI), JSON file in the Hyperledger Caliper environment. This result shows the performance in the form of video registration, the measured latency was 5.02 seconds with a throughput of 409.87 seconds. For video verification the latency was 4.57 seconds with a throughput of 484.23 seconds.},
  archive      = {J_FRAI},
  author       = {Madapati, Sri Lakshmi and Pradhan, Nihar Ranjan},
  doi          = {10.3389/frai.2025.1655709},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1655709},
  shortjournal = {Front. Artif. Intell.},
  title        = {Decentralizing video copyright protection: A novel blockchain-enabled framework with performance evaluation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disembodied creativity in generative AI: Prima facie challenges and limitations of prompting in creative practice. <em>FRAI</em>, <em>8</em>, 1651354. (<a href='https://doi.org/10.3389/frai.2025.1651354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines some prima facie challenges of using natural language prompting in Generative AI (GenAI) for creative practices in design and the arts. While GenAI is purported to “democratize” creativity by offering a new mode of creation, we argue that it comes with a significant mortgage—particularly one in relation to expert performance, skill acquisition, and embodied engagement. Drawing from Dreyfus and Dreyfus, we show that creativity grounded in internalized expert knowledge cannot be reduced to rule-following or meaningfully externalized in instructions, i.e., prompts. Building on Polanyi, Simon, and Sennett, we posit that much of what makes creative work meaningful is tacit and intuitive, and therefore cannot be fully articulated through prompts. From the perspective of embodied and enactive cognition (Thompson, Noë, Pallasmaa), we argue that even “traditional” digital tools retain a material, bodily interface—something entirely absent from prompt-centered creation. While it may be tempting to treat GenAI systems as mere instruments, the mode of interaction they afford introduces a discontinuity: unlike analog tools or conventional software, they offer the creator significantly less control and disrupt and even erodes the feedback loop between mind, hand, and expressive material. Rather than supporting skill development, prompting risks sequestering the user in novice-level engagement. By addressing these challenges, our analysis offers a clearer view of what is at stake when generative systems are integrated into creative disciplines, and why human creators, integrating multiple creative and epistemic faculties as they see fit, must remain at the center of that process.},
  archive      = {J_FRAI},
  author       = {Casacuberta, David and Guersenzvaig, Ariel},
  doi          = {10.3389/frai.2025.1651354},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1651354},
  shortjournal = {Front. Artif. Intell.},
  title        = {Disembodied creativity in generative AI: Prima facie challenges and limitations of prompting in creative practice},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of artificial intelligence on behavioral intentions to use mobile banking in the post-COVID-19 era. <em>FRAI</em>, <em>8</em>, 1649392. (<a href='https://doi.org/10.3389/frai.2025.1649392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis quantitative research investigates the determinants of behavioral intentions to use mobile banking in the post-COVID-19 era. The study extends the Unified Theory of Acceptance and Use of Technology (UTAUT) framework by incorporating two key characteristics of AI, i.e. perceived intelligence and perceived anthropomorphism.MethodsIt uses the UTAUT as a theoretical framework, and extends it by integrating core features of AI. Data has been collected from 412 respondents in Thailand, and structural equation modeling has been employed for the data analysis.ResultsThe findings reveal significant positive effects of performance expectancy, effort expectancy, social influence, facilitating conditions, trust, perceived privacy, perceived intelligence and anthropomorphism of AI on users’ behavioral intentions to use mobile banking. Price value, habits, and perceived security do not significantly influence behavioral intentions. The results highlight the transformative potential of AI technology in the mobile banking industry as consumers’ behaviors are greatly influenced by perceived intelligence and anthropomorphism.DiscussionThe positive impact of perceived intelligence and anthropomorphism indicates that consumers value advanced, human-like interactions with AI. M-banking platforms may focus on developing AI systems that offer intuitive, intelligent, and emotionally engaging experiences. Financial institutions may invest in AI that can analyze user data to offer personalized financial advice, predict future needs, and automate routine tasks effectively.},
  archive      = {J_FRAI},
  author       = {Schrank, Johannes},
  doi          = {10.3389/frai.2025.1649392},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1649392},
  shortjournal = {Front. Artif. Intell.},
  title        = {The impact of artificial intelligence on behavioral intentions to use mobile banking in the post-COVID-19 era},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI, agentic models and lab automation for scientific discovery — The beginning of scAInce. <em>FRAI</em>, <em>8</em>, 1649155. (<a href='https://doi.org/10.3389/frai.2025.1649155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Until recently, the conversation about generative artificial intelligence in science revolved around the textual prowess of large language models such as GPT-3.5 and the promise that they might one day draft a decent literature review. Since then, progress has been nothing short of breathtaking. We now find ourselves in the era of multimodal, agentic systems that listen, see, speak and act, orchestrating cloud software and physical laboratory hardware with a fluency that would have sounded speculative in early 2023. In this review, I merge the substance of our 2024 white paper for the World Economic Forum Top-10-Technologies Report with the latest advances through mid-2025, charting a course from automated literature synthesis and hypothesis generation to self-driving laboratories, organoid intelligence and climate-scale forecasting. The discussion is grounded in emerging governance regimes—notably the European Union Artificial Intelligence Act and ISO 42001—and is written from the dual vantage-point of a toxicologist who has spent a career championing robust, humane science and of a field chief editor charged with safeguarding scholarly standards in Frontiers in Artificial Intelligence. I argue that research is entering a “co-pilot to lab-pilot” transition in which AI no longer merely interprets knowledge but increasingly acts upon it. This shift promises dramatic efficiency gains yet simultaneously amplifies concerns about reproducibility, auditability, safety and equitable access.},
  archive      = {J_FRAI},
  author       = {Hartung, Thomas},
  doi          = {10.3389/frai.2025.1649155},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1649155},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI, agentic models and lab automation for scientific discovery — The beginning of scAInce},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated quantum-inspired anomaly detection using collaborative neural clients. <em>FRAI</em>, <em>8</em>, 1648609. (<a href='https://doi.org/10.3389/frai.2025.1648609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe fusion of deep-learning-based and federated methods has brought great progress in anomaly detection. Yet the systems of today still suffer from certain glaring issues. First, aggregation of data on a central entity poses dangerous privacy hazards. Second, such models could not scale and adapt to heterogeneous and distributed environments. Lastly, fine consideration has hardly been given to quantum-inspired computational paradigms that may promise to improve both speed and security of such systems. To fill in these gaps, this research proposes a completely novel quantum-inspired federated learning approach to anomaly detection that keeps data private and allows for further implementations of quantum computing applications.MethodsThe proposed system works on a client-server architecture comprising multiple clients, which either run training of local feedforward neural networks on different private subsets of their data or choose to not participate during an iteration. Clients never pass raw data to the server but instead alternate by sending the server the parameters of the trained model. The server aggregates these local updates by the FedAvg algorithm and produces the global model. The present implementation focuses mainly on utilizing classical deep learning; however, the architecture is made flexible enough to intertwine smoothly with quantum machine-learning paradigms in the future, thus enabling quantum technological enhancement down the road without requiring the entire system to be rebuilt.ResultsThe framework could produce up to 79% of anomalous detection accuracy. The system had effective learning across distributed clients whilst ensuring that no piece of private data was being shared or spilled (exposed) between clients. These results ensured that the framework maintained its performance while keeping its privacy intact, a very crucial consideration on which to ever really deploy such in sensitive areas.DiscussionThe approach allows privacy-preserving anomaly detection across multiple domains and serves as a framework for enlarging and scaling the system. Being quantum-inspired compatible allows for future-proofing and further expediting and enhancing security. The system, having the capability to securely work in a distributed manner, can, thus, be utilized in critical information domains like cybersecurity, finance, and healthcare, where privacy of data is deemed extremely important. This work, thereby, offers a useful federated learning approach towards anomaly detection while going a step further towards the incorporation of quantum computing into secure, distributed AI systems.},
  archive      = {J_FRAI},
  author       = {Godavarthi, Deepthi and Rekapalli, Venkata Charan Sathvik and Mohanty, Sribidhya and Jaswanth, J. V. S. D. Vigneswara and Polisetty, Dinesh and Dash, Bibhuti Bhusan and Moreira, Fernando},
  doi          = {10.3389/frai.2025.1648609},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1648609},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated quantum-inspired anomaly detection using collaborative neural clients},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limitations of broadly trained LLMs in interpreting orthopedic walch glenoid classifications. <em>FRAI</em>, <em>8</em>, 1644093. (<a href='https://doi.org/10.3389/frai.2025.1644093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) integration in medical practice has grown substantially, with physician use nearly doubling from 38% in 2023 to 68% in 2024. Recent advances in large language models (LLMs) include multimodal inputs, showing potential for medical image interpretation and clinical software integrations. This study evaluated the accuracy of two popular LLMs, Claude 3.5 Sonnet and DeepSeek R1, in interpreting glenoid diagrams using Walch glenoid classification in preoperative shoulder reconstruction applications. Test images included seven black-white Walch glenoid diagrams from Radiopedia. LLMs were accessed via Perplexity.ai without specialized medical training. LLMs were tested across multiple conversation threads with prompt instructions of varying length, ranging from 22 to 864 words for DeepSeek and 127 to 840 words for Claude. Performance differed significantly between models. DeepSeek achieved 44% accuracy (7/16), while Claude had 0% accuracy (0/16). DeepSeek showed a mild positive correlation between instruction length and response accuracy. Common errors across both LLMs included misclassifying A2 as either A1 (32%) or B2 (20%). Results highlight limitations in broadly trained LLMs’ ability to interpret even simplified medical diagrams. DeepSeek’s continuous learning feature and open-source dataset integration exhibited superior accuracy, although it was still insufficient for clinical applications. These limitations stem from LLM training data containing primarily text instead of medical images, creating pattern recognition deficiencies when interpreting visual medical information. Despite AI’s growing adoption in healthcare, this study concludes that as of February 2025, publicly available broadly trained LLMs lack the consistency and accuracy necessary for reliable medical image interpretation, emphasizing the need for specialized training before clinical implementation.},
  archive      = {J_FRAI},
  author       = {ElSayed, Adam and Updegrove, Gary F.},
  doi          = {10.3389/frai.2025.1644093},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1644093},
  shortjournal = {Front. Artif. Intell.},
  title        = {Limitations of broadly trained LLMs in interpreting orthopedic walch glenoid classifications},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing detection of common bean diseases using fast gradient sign method–trained vision transformers. <em>FRAI</em>, <em>8</em>, 1643582. (<a href='https://doi.org/10.3389/frai.2025.1643582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Common bean production in Tanzania is threatened by diseases such as bean rust and bean anthracnose, with early detection critical for effective management. This study presents a Vision Transformer (ViT)-based deep learning model enhanced with adversarial training to improve disease detection robustness under real-world farm conditions. A dataset of 100,000 annotated images augmented with geometric, color, and FGSM-based perturbations, simulating field variability. FGSM was selected for its computational efficiency in low-resource settings. The model, fine-tuned using transfer learning and validated through cross-validation, achieved an accuracy of 99.4%. Results highlight the effectiveness of integrating adversarial robustness to enhance model reliability for mobile-based plant disease detection in resource-constrained environments.},
  archive      = {J_FRAI},
  author       = {Mwaibale, Upendo and Mduma, Neema and Laizer, Hudson and Mgawe, Bonny},
  doi          = {10.3389/frai.2025.1643582},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1643582},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing detection of common bean diseases using fast gradient sign method–trained vision transformers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced plant disease classification with attention-based convolutional neural network using squeeze and excitation mechanism. <em>FRAI</em>, <em>8</em>, 1640549. (<a href='https://doi.org/10.3389/frai.2025.1640549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTechnology is becoming essential in agriculture, especially with the growth of smart devices and edge computing. These tools help boost productivity by automating tasks and allowing real-time analysis on devices with limited memory and resources. However, many current models struggle with accuracy, size, and speed particularly when handling multi-label classification problems.MethodsThis paper proposes a Convolutional Neural Network with Squeeze and Excitation Enabled Identity Blocks (CNN-SEEIB), a hybrid CNN-based deep learning architecture for multi-label classification of plant diseases. CNN-SEEIB incorporates an attention mechanism in its identity blocks to leverage the visual attention that enhances the classification performance and computational efficiency. PlantVillage dataset containing 38 classes of diseased crop leaves alongside healthy leaves, totaling 54,305 images, is utilized for experimentation.ResultsCNN-SEEIB achieved a classification accuracy of 99.79%, precision of 0.9970, recall of 0.9972, and an F1 score of 0.9971. In addition, the model attained an inference time of 64 milliseconds per image, making it suitable for real-time deployment. The performance of CNNSEEIB is benchmarked against the state-of-the-art deep learning architectures, and resource utilization metrics such as CPU/GPU usage and power consumption are also reported, highlighting the model’s efficiency.DiscussionThe proposed architecture is also validated on a potato leaf disease dataset of 4,062 images from Central Punjab, Pakistan, achieving a 97.77% accuracy in classifying Healthy, Early Blight, and Late Blight classes.},
  archive      = {J_FRAI},
  author       = {Karthikeyan, S. and Charan, R. and Narayanan, Sathiya and Jani Anbarasi, L.},
  doi          = {10.3389/frai.2025.1640549},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1640549},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhanced plant disease classification with attention-based convolutional neural network using squeeze and excitation mechanism},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial liver classifier: A new alternative to conventional machine learning models. <em>FRAI</em>, <em>8</em>, 1639720. (<a href='https://doi.org/10.3389/frai.2025.1639720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSupervised machine learning classifiers sometimes face challenges related to the performance, accuracy, or overfitting.MethodsThis paper introduces the Artificial Liver Classifier (ALC), a novel supervised learning model inspired by the human liver's detoxification function. The ALC is characterized by its simplicity, speed, capability to reduce overfitting, and effectiveness in addressing multi-class classification problems through straightforward mathematical operations. To optimize the ALC's parameters, an improved FOX optimization algorithm (IFOX) is employed during training.ResultsWe evaluate the proposed ALC on five benchmark datasets: Iris Flower, Breast Cancer Wisconsin, Wine, Voice Gender, and MNIST. The results demonstrate competitive performance, with ALC achieving up to 100% accuracy on the Iris dataset–surpassing logistic regression, multilayer perceptron, and support vector machine–and 99.12% accuracy on the Breast Cancer dataset, outperforming XGBoost and logistic regression. Across all datasets, ALC consistently shows smaller generalization gaps and lower loss values compared to conventional classifiers.DiscussionThese findings highlight the potential of biologically inspired models to develop efficient machine learning classifiers and open new avenues for innovation in the field.},
  archive      = {J_FRAI},
  author       = {Jumaah, Mahmood A. and Ali, Yossra H. and Rashid, Tarik A.},
  doi          = {10.3389/frai.2025.1639720},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1639720},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial liver classifier: A new alternative to conventional machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of arabic syntactic analyzers. <em>FRAI</em>, <em>8</em>, 1638743. (<a href='https://doi.org/10.3389/frai.2025.1638743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Syntactic analysis stands at the heart of Natural Language Processing (NLP), serving as the cornerstone upon which deeper linguistic understanding is built—particularly for morphologically complex languages such as Arabic. This paper delivers a comprehensive comparative study of contemporary syntactic analyzers designed explicitly for Arabic, dissecting the strengths and limitations of rule-based, statistical, machine learning, and hybrid methodologies, and recent neural network and transformer-based models. Given Arabic's intricate morphological structure and rich syntactic variation, accurately capturing syntactic relationships poses a significant challenge. To address this complexity, our study meticulously evaluates existing algorithms, highlighting advancements, performance gaps, and practical trade-offs. In addition, recognizing that robust syntactic parsing is anchored in high-quality annotated datasets, we provide a thorough overview of available Arabic treebanks and annotated corpora, emphasizing their critical role and contribution to syntactic parsing advancements. By synthesizing current efforts in the domain, this comparative analysis not only offers clarity on the state-of-the-art but also guides future research directions. Ultimately, our work seeks to empower NLP practitioners and researchers with nuanced insights, enabling more informed choices in the development of powerful, accurate, and linguistically insightful Arabic syntactic analyzers.},
  archive      = {J_FRAI},
  author       = {Saadiyeh, Omar and Ramadan, Alaaeddine and Hajjar, Mohammad and Bernard, Gilles},
  doi          = {10.3389/frai.2025.1638743},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1638743},
  shortjournal = {Front. Artif. Intell.},
  title        = {A comparative study of arabic syntactic analyzers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving deceased donor kidney utilization: Predicting risk of nonuse with interpretable models. <em>FRAI</em>, <em>8</em>, 1638574. (<a href='https://doi.org/10.3389/frai.2025.1638574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundMany deceased donor kidneys go unused despite growing demand for transplantation. Early identification of organs at high risk of nonuse can facilitate effective allocation interventions, ensuring these organs are offered to patients who could potentially benefit from them. While several machine learning models have been developed to predict nonuse risk, the complexity of these models compromises their practical implementation.MethodsWe propose simplified, implementable nonuse risk prediction models that combine the Kidney Donor Risk Index (KDRI) with a small set of variables selected through machine learning or transplantation expert input. Our approach also account for Organ Procurement Organization (OPO) level factors affecting kidney disposition.ResultsThe proposed models demonstrate competitive performance compared to more complex models that involve a large number of variables while maintaining interpretability and ease of use.ConclusionOur models provide accurate, interpretable risk predictions and highlight key drivers of kidney nonuse, including variation across OPOs. These findings can inform the design of effective organ allocation interventions, increasing the likelihood of transplantation for hard-to-place kidneys.},
  archive      = {J_FRAI},
  author       = {Li, Ruoting and Tunç, Sait and Özaltın, Osman Y. and Ellis, Matthew J.},
  doi          = {10.3389/frai.2025.1638574},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1638574},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving deceased donor kidney utilization: Predicting risk of nonuse with interpretable models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic fairness: Challenges to building an effective regulatory regime. <em>FRAI</em>, <em>8</em>, 1637134. (<a href='https://doi.org/10.3389/frai.2025.1637134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unfair treatment by artificial intelligence toward protected groups has become an important topic of discussion. Its potential for causing harm has spurred many to think that legislation aimed at regulating AI systems is essential. In the US, laws have already been proposed both by Congress as well as by several key states. However, a number of challenges stand in the way of effective legislation. Proposed laws mandating testing for fairness must articulate clear positions on how fairness is defined. But the task of selecting a suitable definition (or definitions) of fairness is not a simple one. Experts in AI continue to disagree as to what constitutes algorithmic fairness, which has led to an ever-expanding list of definitions that are highly technical in nature and require expertise that most legislators simply do not possess. Complicating things further, several of the proposed definitions are incommensurable with one another, making a cross-jurisdictional regulatory regime incorporating different standards of fairness susceptible to inconsistent determinations. On top of all this, legislators must also contend with existing laws prohibiting group-based discrimination that codify conceptions of fairness that may not be suitable for evaluating certain algorithms. In this article, I examine these challenges in detail, and suggest ways to deal with them such that the regulatory regime that emerges is one that is more effective in carrying out its intended purpose.},
  archive      = {J_FRAI},
  author       = {Demirchyan, Greg},
  doi          = {10.3389/frai.2025.1637134},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1637134},
  shortjournal = {Front. Artif. Intell.},
  title        = {Algorithmic fairness: Challenges to building an effective regulatory regime},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From data silos to insights: The PRINCE multi-agent knowledge engine for preclinical drug development. <em>FRAI</em>, <em>8</em>, 1636809. (<a href='https://doi.org/10.3389/frai.2025.1636809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pharmaceutical industry faces pressure to improve the drug development process while reducing costs in an evolving regulatory landscape. This paper presents the Preclinical Information Center (PRINCE), a cloud-hosted data integration platform developed by Bayer AG in collaboration with Thoughtworks. PRINCE integrates decades of structured and unstructured safety study reports, leveraging a multi-agent architecture based on Large Language Models (LLMs) and advanced data retrieval methodologies, such as Retrieval-Augmented Generation and Text-to-SQL. In this paper, we describe the three-step evolution of PRINCE from a data search tool based on keyword matching to a resourceful research assistant capable of answering complex questions and drafting regulatory-critical documents. We highlight the iterative development process, guided by user feedback, that ensures alignment with evolving research needs and maximizes utility. Finally, we discuss the importance of building trust-based solutions and how transparency and explainability have been integrated into PRINCE. In particular, the integration of a human-in-the-loop approach enhances the accuracy and retains human accountability. We believe that the development and deployment of the PRINCE chatbot demonstrate the transformative potential of AI in the pharmaceutical industry, significantly improving data accessibility and research efficiency, while prioritizing data governance and compliance.},
  archive      = {J_FRAI},
  author       = {Vieira-Vieira, Carlos Henrique and Kulkarni, Sarang Sanjay and Zalewski, Adam and Löffler, Jobst and Münch, Jonas and Kreuchwig, Annika},
  doi          = {10.3389/frai.2025.1636809},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1636809},
  shortjournal = {Front. Artif. Intell.},
  title        = {From data silos to insights: The PRINCE multi-agent knowledge engine for preclinical drug development},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A brain-inspired memory transformation based differentiable neural computer for reasoning-based question answering. <em>FRAI</em>, <em>8</em>, 1635932. (<a href='https://doi.org/10.3389/frai.2025.1635932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning and question answering, as fundamental cognitive functions in humans, remain significant hurdles for artificial intelligence. While large language models (LLMs) have achieved notable success, integrating explicit memory with structured reasoning capabilities remains a persistent difficulty. The Differentiable Neural Computer (DNC) model, despite addressing these issues to some extent, still faces challenges such as algorithmic complexity, slow convergence, and limited robustness. Inspired by the brain's learning and memory mechanisms, this paper proposes a Memory Transformation based Differentiable Neural Computer (MT-DNC) model. The MT-DNC integrates two brain-inspired memory modules—a working memory module inspired by the cognitive system that temporarily holds and processes task-relevant information, and a long-term memory module that stores frequently accessed and enduring information—within the DNC framework, enabling the autonomous transformation of acquired experiences between these memory systems. This facilitates efficient knowledge extraction and enhances reasoning capabilities. Experimental results on the bAbI question answering task demonstrate that the proposed method outperforms existing Deep Neural Network (DNN) and DNC models, achieving faster convergence and superior performance. Ablation studies further confirm that the transformation of memory from working memory to long-term memory is critical for improving the robustness and stability of reasoning. This work offers new insights into incorporating brain-inspired memory mechanisms into dialogue and reasoning systems.},
  archive      = {J_FRAI},
  author       = {Liang, Yao and Wang, Yuwei and Fang, Hongjian and Zhao, Feifei and Zeng, Yi},
  doi          = {10.3389/frai.2025.1635932},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1635932},
  shortjournal = {Front. Artif. Intell.},
  title        = {A brain-inspired memory transformation based differentiable neural computer for reasoning-based question answering},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of artificial intelligence techniques for the profiling of visitors to tourist destinations. <em>FRAI</em>, <em>8</em>, 1632415. (<a href='https://doi.org/10.3389/frai.2025.1632415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tourism in Peru represents an opportunity for local development; however, there is limited understanding of visitor profiles. The aim of this study was to characterize tourists using machine learning techniques in order to identify distinct segments that can inform planning and promotional strategies for the Alto Amazonas destination. The research followed the CRISP-DM methodology for data analysis, based on surveys administered to 882 visitors. The data were processed using the clustering algorithms K-Means, DBSCAN, HDBSCAN, and Agglomerative, with Principal Component Analysis applied beforehand for dimensionality reduction. The results showed that the Agglomerative Clustering model achieved the best performance in internal validation metrics, allowing for the identification of five distinct visitor profiles. These segments provide valuable insights for the design of more inclusive and personalized tourism products. In conclusion, the study demonstrates the value of machine learning as a tool for tourism segmentation, offering empirical evidence that can strengthen the management of emerging destinations such as Alto Amazonas. The practical contribution of this study lies in providing strategic information that enables destination managers to tailor services and experiences to the characteristics of each segment, thereby optimizing visitor satisfaction and strengthening the destination’s competitiveness.},
  archive      = {J_FRAI},
  author       = {Schrader, Juan and Pinedo, Lloy and Vargas, Franz and Martell, Karla and Seijas-Díaz, José and Rengifo-Amasifen, Roger and Cueto-Orbe, Rosa and Torres-Silva, Cinthya},
  doi          = {10.3389/frai.2025.1632415},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1632415},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of artificial intelligence techniques for the profiling of visitors to tourist destinations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing AI microscopy for foodborne bacterial classification using adversarial domain adaptation to address optical and biological variability. <em>FRAI</em>, <em>8</em>, 1632344. (<a href='https://doi.org/10.3389/frai.2025.1632344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-enabled microscopy is emerging for rapid bacterial classification, yet its utility remains limited in dynamic or resource-limited settings due to imaging variability. This study aims to enhance the generalizability of AI microscopy using domain adaptation techniques. Six bacterial species, including three Gram-positive (Bacillus coagulans, Bacillus subtilis, Listeria innocua) and three Gram-negative (Escherichia coli, Salmonella Enteritidis, Salmonella Typhimurium), were grown into microcolonies on soft tryptic soy agar plates at 37°C for 3–5 h. Images were acquired under varying microscopy modalities and magnifications. Domain-adversarial neural networks (DANNs) addressed single-target domain variations and multi-DANNs (MDANNs) handled multiple domains simultaneously. EfficientNetV2 backbone provided fine-grained feature extraction suitable for small targets, with few-shot learning enhancing scalability in data-limited domains. The source domain contained 105 images per species (n = 630) collected under optimal conditions (phase contrast, 60 × magnification, 3-h incubation). Target domains introduced variations in modality (brightfield, BF), lower magnification (20 × ), and extended incubation (20x-5h), each with < 5 labeled training images per species (n ≤ 30) and test datasets of 60–90 images. DANNs improved target domain classification accuracy by up to 54.5% for 20 × (34.4% to 88.9%), 43.3% for 20x-5h (40.0% to 83.3%), and 31.7% for BF (43.4% to 73.3%), with minimal accuracy loss in the source domain. MDANNs further improved accuracy in the BF domain from 73.3% to 76.7%. Feature visualizations by Grad-CAM and t-SNE validated the model's ability to learn domain-invariant features across conditions. This study presents a scalable and adaptable framework for bacterial classification, extending the utility of microscopy to decentralized and resource-limited settings where imaging variability often challenges performance.},
  archive      = {J_FRAI},
  author       = {Bhattacharya, Siddhartha and Wasit, Aarham and Earles, J Mason and Nitin, Nitin and Yi, Jiyoon},
  doi          = {10.3389/frai.2025.1632344},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1632344},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing AI microscopy for foodborne bacterial classification using adversarial domain adaptation to address optical and biological variability},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient spatio-temporal modeling for sign language recognition using CNN and RNN architectures. <em>FRAI</em>, <em>8</em>, 1630743. (<a href='https://doi.org/10.3389/frai.2025.1630743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision has been identified as one of the solutions to bridge communication barriers between speech-impaired populations and those without impairment as most people are unaware of the sign language used by speech-impaired individuals. Numerous studies have been conducted to address this challenge. However, recognizing word signs, which are usually dynamic and involve more than one frame per sign, remains a challenge. This study used Tanzania Sign Language datasets collected using mobile phone selfie cameras to investigate the performance of deep learning algorithms that capture spatial and temporal relationships features of video frames. The study used CNN-LSTM and CNN-GRU architectures, where CNN-GRU with an ELU activation function is proposed to enhance learning efficiency and performance. The findings indicate that the proposed CNN-GRU model with ELU activation achieved an accuracy of 94%, compared to 93% for the standard CNN-GRU model and CNN-LSTM. In addition, the study evaluated performance of the proposed model in a signer-independent setting, where the results varied significantly across individual signers, with the highest accuracy reaching 66%. These results show that more effort is required to improve signer independence performance, including the challenges of hand dominance by optimizing spatial features.},
  archive      = {J_FRAI},
  author       = {Myagila, Kasian and Nyambo, Devotha Godfrey and Dida, Mussa Ally},
  doi          = {10.3389/frai.2025.1630743},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1630743},
  shortjournal = {Front. Artif. Intell.},
  title        = {Efficient spatio-temporal modeling for sign language recognition using CNN and RNN architectures},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral momentum integration: Hybrid optimization of frequency and time domain gradients. <em>FRAI</em>, <em>8</em>, 1628943. (<a href='https://doi.org/10.3389/frai.2025.1628943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Spectral Momentum Integration (SMI), an optimization enhancement that processes gradients in both frequency and time domains. SMI applies the Fast Fourier Transform to selectively filter gradient frequency components before blending them with original gradients using an adaptive scheduling mechanism. Experiments on a character-level language model demonstrate that SMI can achieve inference acceleration while maintaining model performance. Our approach integrates with existing optimizers without modifying model architecture, though it introduces computational overhead and hyperparameter complexity. While our current validation is limited to small-scale experiments, SMI provides a proof-of-concept for incorporating frequency-domain processing into neural network optimization, suggesting potential for broader applications pending large-scale validation.},
  archive      = {J_FRAI},
  author       = {Huang, Zhigao and Chen, Musheng and Zheng, Shiyan},
  doi          = {10.3389/frai.2025.1628943},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1628943},
  shortjournal = {Front. Artif. Intell.},
  title        = {Spectral momentum integration: Hybrid optimization of frequency and time domain gradients},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BlendNet: A blending-based convolutional neural network for effective deep learning of electrocardiogram signals. <em>FRAI</em>, <em>8</em>, 1625637. (<a href='https://doi.org/10.3389/frai.2025.1625637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn recent years, Deep Learning (DL) architectures such as Convolutional Neural Network (CNN) and its variants have been shown to be effective in the diagnosis of cardiovascular disease from ElectroCardioGram (ECG) signals. In the case of ECG as a one-dimensional signal, 1-D CNNs are deployed, whereas in the case of a 2D-represented ECG signal, i.e., two-dimensional signal, 2-D CNNs or other relevant architectures are deployed. Since 2D-represented ECG signals facilitate better feature extraction, it is a common practice to convert an ECG signal into a scalogram image using a continuous wavelet transform (CWT) approach and then subject it to a DL architecture such as 2-D CNN. However, this traditional approach captures only a limited set of features of ECG and thereby limits the effectiveness of DL architectures in disease detection.MethodsThis work proposes “BlendNet,” a DL architecture that effectively extracts the features of an ECG signal using a blending approach termed “alpha blending.” First, the 1-D ECG signal is converted into a scalogram image using CWT, and a binary version of the scalogram image is also obtained. Then, both the scalogram and binary images are subjected to a sequence of convolution and pooling layers, and the resulting feature images are blended. This blended feature image is subjected to a dense layer that classifies the image. The blending is flexible, and it is controlled by a parameter α, hence the process is termed as alpha blending. The utilization of alpha blending facilitates the generation of a composite feature set that incorporates different characteristics from both the scalogram and binary versions.ResultsFor experiments, a total of 162 ECG recordings from the PhysioNet database were used. Experimental results and analysis show that, in the case of α = 0.7, BlendNet's performance surpasses the performance of (i) traditional approaches (that do not involve blending) and (ii) state-of-the-art approaches for ECG classification.DiscussionExperimental outcomes show that the proposed BlendNet is flexible regarding dense layer settings and can accommodate faster alternatives [i.e., machine learning (ML) algorithms] for faster convergence. The superior performance at α = 0.7 indicates that alpha blending allows for richer composite feature sets, leading to improved classification accuracy over conventional feature extraction and classification methods.},
  archive      = {J_FRAI},
  author       = {Premanand, S. and Narayanan, Sathiya},
  doi          = {10.3389/frai.2025.1625637},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1625637},
  shortjournal = {Front. Artif. Intell.},
  title        = {BlendNet: A blending-based convolutional neural network for effective deep learning of electrocardiogram signals},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conversational AI agent for precision oncology: AI-HOPE-WNT integrates clinical and genomic data to investigate WNT pathway dysregulation in colorectal cancer. <em>FRAI</em>, <em>8</em>, 1624797. (<a href='https://doi.org/10.3389/frai.2025.1624797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe WNT signaling pathway is a key driver of colorectal cancer (CRC) initiation and progression, particularly in early-onset CRC (EOCRC) among underserved populations. However, interrogating WNT pathway dysregulation across clinical and genomic dimensions remains technically challenging, limiting both translational insight and personalized intervention strategies. To address this gap, we developed AI-HOPE-WNT, the first conversational artificial intelligence (AI) agent purpose-built to investigate WNT signaling in CRC using natural language–driven, integrative bioinformatics.MethodsAI-HOPE-WNT employs a modular architecture combining large language models (LLMs), a natural language-to-code engine, and a backend statistical workflow interfaced with harmonized data from cBioPortal. Unlike general-purpose platforms, AI-HOPE-WNT is uniquely optimized for WNT-specific precision oncology. The tool supports mutation frequency analysis, odds ratio testing, survival modeling, and subgroup stratification by genomic, clinical, and demographic variables. To validate the platform, we recapitulated findings from two previous studies examining WNT pathway alterations in high-risk CRC populations, including mutation prevalence in RNF43 and AXIN2 and survival outcomes associated with WNT pathway status across ethnic and age subgroups. Exploratory queries further assessed treatment response, co-mutation patterns, and population-specific trends.ResultsIn recapitulation analyses, AI-HOPE-WNT reproduced key trends from prior work, including improved survival in WNT-altered EOCRC and higher RNF43 mutation rates in Hispanic/Latino (H/L) populations compared to non-Hispanic White (NHW) people. Exploratory analyses revealed several novel findings. Among FOLFOX-treated EOCRC patients, APC mutations were associated with significantly different survival outcomes (p = 0.043). RNF43-mutant tumors showed worse survival in metastatic versus primary cases (p = 0.028). AXIN1 and APC co-mutations demonstrated location-specific enrichment between colon and rectal tumors. Gender-based differences in AXIN2-mutant cases under varying MSI status yielded significant survival variation (p = 0.036). Additionally, patients under 50 with APC-mutant primary tumors showed worse survival (p = 0.031) and increased mutation prevalence.ConclusionAI-HOPE-WNT is the first dedicated AI platform for WNT pathway analysis in CRC. By combining natural language interaction with automated, high-throughput bioinformatics, it democratizes access to pathway-specific precision oncology research. The platform is freely available at: https://github.com/Velazquez-Villarreal-Lab/AI-HOPE-WNT.},
  archive      = {J_FRAI},
  author       = {Yang, Ei-Wen and Waldrup, Brigette and Velazquez-Villarreal, Enrique},
  doi          = {10.3389/frai.2025.1624797},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1624797},
  shortjournal = {Front. Artif. Intell.},
  title        = {Conversational AI agent for precision oncology: AI-HOPE-WNT integrates clinical and genomic data to investigate WNT pathway dysregulation in colorectal cancer},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weaponizing cognitive bias in autonomous systems: A framework for black-box inference attacks. <em>FRAI</em>, <em>8</em>, 1623573. (<a href='https://doi.org/10.3389/frai.2025.1623573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous systems operating in high-dimensional environments increasingly rely on prioritization heuristics to allocate attention and assess risk, yet these mechanisms can introduce cognitive biases such as salience, spatial framing, and temporal familiarity that influence decision-making without altering the input or accessing internal states. This study presents Priority Inversion via Operational Reasoning (PRIOR), a black-box, non-perturbative diagnostic framework that employs structurally biased but semantically neutral scenario cues to probe inference-level vulnerabilities without modifying pixel-level, statistical, or surface semantic properties. Given the limited accessibility of embodied vision-based systems, we evaluate PRIOR using large language models (LLMs) as abstract reasoning proxies to simulate cognitive prioritization in constrained textual surveillance scenarios inspired by Unmanned Aerial Vehicle (UAV) operations. Controlled experiments demonstrate that minimal structural cues can consistently induce priority inversions across multiple models, and joint analysis of model justifications and confidence estimates reveals systematic distortions in inferred threat relevance even when inputs are symmetrical. These findings expose the fragility of inference-level reasoning in black-box systems and motivate the development of evaluation strategies that extend beyond output correctness to interrogate internal prioritization logic, with implications for dynamic, embodied, and visually grounded agents in real-world deployments.},
  archive      = {J_FRAI},
  author       = {Chu, Shiyong and Chen, Yuwei},
  doi          = {10.3389/frai.2025.1623573},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1623573},
  shortjournal = {Front. Artif. Intell.},
  title        = {Weaponizing cognitive bias in autonomous systems: A framework for black-box inference attacks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoViNAR: A context-aware social media dataset for pandemic severity level prediction and analysis. <em>FRAI</em>, <em>8</em>, 1623090. (<a href='https://doi.org/10.3389/frai.2025.1623090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe unprecedented COVID-19 pandemic exposed critical weaknesses in global health management, particularly in resource allocation and demand forecasting. This study aims to enhance pandemic preparedness by leveraging real-time social media analysis to detect and monitor resource needs.MethodsUsing SnScrape, over 27.5 million tweets for the duration of November 2019 to March 2023 were collected using COVID-19-related hashtags. Tweets from April 2021, a peak pandemic period, were selected to create the CoViNAR dataset. BERTopic enabled context-aware filtering, resulting in a novel dataset of 14,000 annotated tweets categorized as “Need”, “Availability”, and “Not-relevant”. The CoViNAR dataset was used to train various machine learning classifiers, with experiments conducted using three context-aware word embedding techniques.ResultsThe best classifier, trained with DistilBERT embeddings, achieved an accuracy of 96.42%, 96.44% precision, 96.42% recall, and an F1-score of 96.43% on the Test dataset. Temporal analysis of classified tweets from the US, UK, and India between November 2019 and March 2023 revealed a strong correlation between “Need/Availability” tweet counts and COVID-19 case surges.DiscussionThe results demonstrate the effectiveness of the proposed approach in capturing real-time indicators of resource shortages and availability. The strong correlation with case surges underscores its potential as a proactive tool for public health authorities, enabling improved resource allocation and early crisis intervention during pandemics.},
  archive      = {J_FRAI},
  author       = {Shafiya, Soofi and Wani, Mudasir Ahmad and Jabin, Suraiya and ELAffendi, Mohammad and Jahiruddin,},
  doi          = {10.3389/frai.2025.1623090},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1623090},
  shortjournal = {Front. Artif. Intell.},
  title        = {CoViNAR: A context-aware social media dataset for pandemic severity level prediction and analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the robustness of the open-world test-time training model. <em>FRAI</em>, <em>8</em>, 1621025. (<a href='https://doi.org/10.3389/frai.2025.1621025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionGeneralizing deep learning models to unseen target domains with low latency has motivated research into test-time training/adaptation (TTT/TTA). However, deploying TTT/TTA in open-world environments is challenging due to the difficulty in distinguishing between strong out-of-distribution (OOD) samples and regular weak OOD samples. While emerging Open-World TTT (OWTTT) approaches address this challenge, they introduce a new vulnerability: test-time poisoning attacks. These attacks differ fundamentally from traditional poisoning attacks that occur during model training, as adversaries cannot intervene in the training process itself.MethodsIn response to this threat, we design a novel test-time poisoning attack method specifically targeting OWTTT models. Capitalizing on the fact that model gradients dynamically change during testing, our method employs a single-step query-based approach to dynamically generate and update adversarial perturbations. These perturbations are then input into the OWTTT model during its adaptation phase.ResultsWe extensively test our attack method on an OWTTT model. The experimental results demonstrate a significant vulnerability, showing that the OWTTT model's performance can be effectively compromised by our test-time poisoning attack.DiscussionOur findings reveal that OWTTT algorithms lacking rigorous security assessment against such attacks are unsuitable for real-world deployment. Consequently, we strongly advocate for the integration of defenses against test-time poisoning attacks into the fundamental design of future open-world test-time training methodologies.},
  archive      = {J_FRAI},
  author       = {Pi, Shu and Wang, Xin and Pi, Jiatian},
  doi          = {10.3389/frai.2025.1621025},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1621025},
  shortjournal = {Front. Artif. Intell.},
  title        = {Research on the robustness of the open-world test-time training model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid long short-term memory with generalized additive model and post-hoc explainable artificial intelligence with causal inference for air pollutants prediction in kimberley, south africa. <em>FRAI</em>, <em>8</em>, 1620019. (<a href='https://doi.org/10.3389/frai.2025.1620019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study addresses the problem of nonlinear characteristics of common air pollutants by proposing a deep learning time-series model based on the long short-term memory (LSTM) integrated with a generalized additive model (GAM). LSTM model captures both nonlinear relationships and temporal long-term dependencies in time-series data, and GAM provides insight into the statistical relationship between selected features and the target pollutant. The post-hoc eXplainable artificial intelligence (xAI) technique, local interpretable model-agnostic explanation (LIME), further explains the nonlinearity. Finally, causal inference was determined on the impact of the air pollutants relationship, thereby offering further interpretability in which deep learning models are deficient. Meteorological and air pollutant statistical records were leveraged from a Hantam (Karoo) air monitoring station in South Africa, and through a random sampling approach, synthetic data were generated for the city of Kimberley. The model was evaluated with the mean squared error (MSE), root mean squared error (RMSE) and mean absolute error (MAE) for different time-steps. The proposed referred to as long short-term memory generalized additive model based post-hoc eXplainable Artificial Intelligence (LSTM-GAM_xAI) model with a 10-day time-step and 5-day time-step for multiple pollutants prediction guaranteed least MSE. Though the causal effect analysis show no p-values (>0.88) for variables, the experiment results show that LSTM-GAM-xAI guaranteed the lowest MSE values across different time-steps.},
  archive      = {J_FRAI},
  author       = {Agbehadji, Israel Edem and Obagbuwa, Ibidun Christiana},
  doi          = {10.3389/frai.2025.1620019},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1620019},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid long short-term memory with generalized additive model and post-hoc explainable artificial intelligence with causal inference for air pollutants prediction in kimberley, south africa},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elucidating simulated equivalence responding through dynamic visualization of structural connectivity and relational density. <em>FRAI</em>, <em>8</em>, 1618678. (<a href='https://doi.org/10.3389/frai.2025.1618678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents Affinity, a visual analytics tool that enhances the simulation of the emergence of derived relations between stimuli in humans. Built on the foundations of a reinforcement learning model called Enhanced Equivalence Projective Simulation, Affinity provides both real-time visualizations of the agent's relational memory and enables the simulation of Relational Density Theory, a novel approach to understanding relational responding through the modeling of higher-order properties of density, volume, and mass. We demonstrate these features in a simulation of a recent study into the quantification of relational volume. We also use this as an opportunity to examine the effect of the underlying model's consolidation mechanism, Network Enhancement, on the agent's relational network. Our results highlight Affinity's innovation as an explainable modeling interface for relational formation and a testbed for new experiments. We discuss the limitations of Affinity in its current state, underline future work on the software and computational modeling of Stimulus Equivalence and locate this contribution in the broader scope of integrations of Contextual Behavioral Science and Artificial Intelligence.},
  archive      = {J_FRAI},
  author       = {O'Sullivan, James and Jackson Brown, Freddy and Ray, Oliver},
  doi          = {10.3389/frai.2025.1618678},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1618678},
  shortjournal = {Front. Artif. Intell.},
  title        = {Elucidating simulated equivalence responding through dynamic visualization of structural connectivity and relational density},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing one-year mortality prediction in STEMI patients post-PCI: An interpretable machine learning model with risk stratification. <em>FRAI</em>, <em>8</em>, 1618492. (<a href='https://doi.org/10.3389/frai.2025.1618492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundST-elevation myocardial infarction (STEMI) poses a significant threat to global mortality and disability. Advances in percutaneous coronary intervention (PCI) have reduced in-hospital mortality, highlighting the importance of post-discharge management. Machine learning (ML) models have shown promise in predicting adverse clinical outcomes. However, a systematic approach that combines high predictive accuracy with model simplicity is still lacking.MethodsThis retrospective study applied three data processing and ML algorithms to address class imbalance and support model development. ML models were trained to predict one-year mortality in STEMI patients post-PCI, with performance evaluated using accuracy, sensitivity, precision, F1-score, area under the receiver operating characteristic curve (AUROC), and the area under the precision-recall curve (AUPRC).ResultsWe analyzed data from 1,274 patients, incorporating 46 clinical and laboratory features. Using the Random Forest (RF) algorithm, we achieved an AUROC of 0.94 (95% confidence interval (CI): 0.90–0.98), an AUPRC of 0.44 (95% CI:0.15–0.76) in the internal validation set, identifying five key predictors: cardiogenic shock, creatinine, NT-proBNP, diastolic blood pressure, and left ventricular ejection fraction. By integrating risk stratification, the model’s performance improved, achieving an AUROC of 0.97 (95% CI: 0.96–0.99) and an AUPRC of 0.74 (95% CI: 0.60–0.84).ConclusionThis study highlights the feasibility of constructing accurate and interpretable ML models using a minimal set of predictors, supplemented by risk stratification, to improve long-term outcome prediction in STEMI patients.},
  archive      = {J_FRAI},
  author       = {Li, Wenqiang and Yan, Dongdong and Hu, Wei and Su, Xiaoling and Zhang, Zheng},
  doi          = {10.3389/frai.2025.1618492},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1618492},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing one-year mortality prediction in STEMI patients post-PCI: An interpretable machine learning model with risk stratification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acceptability of artificial intelligence in inclusive education: A TAM2-based study among preservice teachers. <em>FRAI</em>, <em>8</em>, 1616327. (<a href='https://doi.org/10.3389/frai.2025.1616327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe integration of artificial intelligence (AI) into education is generating growing interest, particularly due to its potential to support inclusive pedagogical practices. This is especially relevant for addressing the needs of students with attention deficit hyperactivity disorder (ADHD). The success of such integration largely depends on the acceptability of AI tools by educators, especially those still in initial training. This study aims to identify the factors influencing the acceptability of AI among pre-service teachers in the specific context of teaching students with ADHD.MethodsGrounded in the Technology Acceptance Model 2 (TAM 2), the study adopts a mixed-methods approach. Quantitative data were collected via structured questionnaires, and qualitative insights were obtained through semi-structured interviews with pre-service teachers in Morocco.ResultsFindings reveal that perceived usefulness is the most influential predictor of AI acceptability, followed by perceived ease of use, voluntariness, and subjective norms. Participants emphasized the potential of AI to enhance pedagogical efficiency and support differentiated instruction. Institutional support and interface simplicity also emerged as key enablers.Discussion/ConclusionThese results highlight the need to incorporate digital literacy into teacher training programs and to develop AI tools specifically adapted to students with special educational needs. They also call for the establishment of a robust ethical and regulatory framework to ensure the responsible, equitable, and secure use of AI in education.},
  archive      = {J_FRAI},
  author       = {Amouri, Houda and Haroud, Samia and Ouchaouka, Lynda and Saqri, Nadia},
  doi          = {10.3389/frai.2025.1616327},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1616327},
  shortjournal = {Front. Artif. Intell.},
  title        = {Acceptability of artificial intelligence in inclusive education: A TAM2-based study among preservice teachers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-model longitudinal assessment of ChatGPT performance on medical residency examinations. <em>FRAI</em>, <em>8</em>, 1614874. (<a href='https://doi.org/10.3389/frai.2025.1614874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionChatGPT, a generative artificial intelligence, has potential applications in numerous fields, including medical education. This potential can be assessed through its performance on medical exams. Medical residency exams, critical for entering medical specialties, serve as a valuable benchmark.Materials and methodsThis study aimed to assess the accuracy of ChatGPT-4 and GPT-4o in responding to 1,041 medical residency questions from Brazil, examining overall accuracy and performance across different medical areas, based on evaluations conducted in 2023 and 2024. The questions were classified into higher and lower cognitive levels according to Bloom’s taxonomy. Additionally, questions answered incorrectly by both models were tested using the recent GPT models that use chain-of-thought reasoning (e.g., o1-preview, o3, o4-mini-high) with evaluations carried out in both 2024 and 2025.ResultsGPT-4 achieved 81.27% accuracy (95% CI: 78.89–83.64%), while GPT-4o reached 85.88% (95% CI: 83.76–88.00%), significantly outperforming GPT-4 (p < 0.05). Both models showed reduced accuracy on higher-order thinking questions. On questions that both models failed, GPT o1-preview achieved 53.26% accuracy (95% CI: 42.87–63.65%), GPT o3 47.83% (95% CI: 37.42–58.23%) and o4-mini-high 35.87% (95% CI: 25.88–45.86%), with all three models performing better on higher-order questions.ConclusionArtificial intelligence could be a beneficial tool in medical education, enhancing residency exam preparation, helping to understand complex topics, and improving teaching strategies. However, careful use of artificial intelligence is essential due to ethical concerns and potential limitations in both educational and clinical practice.},
  archive      = {J_FRAI},
  author       = {Souto, Maria Eduarda Varela Cavalcanti and Fernandes, Alexandre Chaves and Silva, Ana Beatriz Santana and de Freitas Ribeiro, Louise Helena and de Medeiros Fernandes, Thales Allyrio Araújo},
  doi          = {10.3389/frai.2025.1614874},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1614874},
  shortjournal = {Front. Artif. Intell.},
  title        = {A multi-model longitudinal assessment of ChatGPT performance on medical residency examinations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-enhanced assessment of fundamental motor skills: Validity and reliability of the FUS test for jumping rope performance. <em>FRAI</em>, <em>8</em>, 1611534. (<a href='https://doi.org/10.3389/frai.2025.1611534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionFundamental motor skills (FMS) are foundational for lifelong physical activity and talent development. However, their development is often overlooked in favor of sport-specific outcomes in physical education (PE). This study aimed to evaluate FMS proficiency among students enrolled in traditional and school-based sport PE programs and explore implications for early specialization and motor competence.MethodsWe assessed FMS proficiency in a large sample of Polish students aged 10–14 (N = 2,238) using the validated Fundamental Motor Skills in Sport (FUS) test. Participants were grouped based on enrollment in traditional PE or school-based sport PE programs. Proficiency was classified into four levels based on mastery across six motor tasks.ResultsThe majority of students in both groups failed to meet the basic FMS proficiency threshold. Specifically, 72% of boys and 77% of girls in sport PE programs were below elementary proficiency, compared to 90% of boys and 92% of girls in traditional PE. While sport PE students outperformed their peers, significant deficits remained. Gender differences showed boys had advantages in object control skills, while girls performed better in coordination-oriented tasks.DiscussionBoth traditional and sport PE programs fall short of supporting adequate FMS development, potentially due to overemphasis on early specialization and lack of instructional support for motor competence. These findings underscore the need for curricular reforms and targeted teacher training to prioritize broad motor skill development and promote long-term participation in physical activity.},
  archive      = {J_FRAI},
  author       = {Makaruk, Hubert and Porter, Jared M. and Webster, E. Kipling and Makaruk, Beata and Tomaszewski, Paweł and Nogal, Marta and Gawłowski, Daniel and Sobański, Łukasz and Molik, Bartosz and Sadowski, Jerzy},
  doi          = {10.3389/frai.2025.1611534},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1611534},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence-enhanced assessment of fundamental motor skills: Validity and reliability of the FUS test for jumping rope performance},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probing for consciousness in machines. <em>FRAI</em>, <em>8</em>, 1610225. (<a href='https://doi.org/10.3389/frai.2025.1610225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the potential for artificial agents to develop core consciousness, as proposed by Antonio Damasio's theory of consciousness. According to Damasio, the emergence of core consciousness relies on the integration of a self model, informed by representations of emotions and feelings, and a world model. We hypothesize that an artificial agent, trained via reinforcement learning (RL) in a virtual environment, can develop preliminary forms of these models as a byproduct of its primary task. The agent's main objective is to learn to play a video game and explore the environment. To evaluate the emergence of world and self models, we employ probes–feedforward classifiers that use the activations of the trained agent's neural networks to predict the spatial positions of the agent itself. Our results demonstrate that the agent can form rudimentary world and self models, suggesting a pathway toward developing machine consciousness. This research provides foundational insights into the capabilities of artificial agents in mirroring aspects of human consciousness, with implications for future advancements in artificial intelligence.},
  archive      = {J_FRAI},
  author       = {Immertreu, Mathis and Schilling, Achim and Maier, Andreas and Krauss, Patrick},
  doi          = {10.3389/frai.2025.1610225},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1610225},
  shortjournal = {Front. Artif. Intell.},
  title        = {Probing for consciousness in machines},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of model uncertainty and variability in LLM-based sentiment analysis: Challenges, mitigation strategies, and the role of explainability. <em>FRAI</em>, <em>8</em>, 1609097. (<a href='https://doi.org/10.3389/frai.2025.1609097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have significantly advanced sentiment analysis, yet their inherent uncertainty and variability pose critical challenges to achieving reliable and consistent outcomes. This paper systematically explores the Model Variability Problem (MVP) in LLM-based sentiment analysis, characterized by inconsistent sentiment classification, polarization, and uncertainty arising from stochastic inference mechanisms, prompt sensitivity, and biases in training data. We present illustrative examples and two case studies to highlight its impact and analyze the core causes of MVP, discussing a dozen fundamental reasons for model variability. We pay especial atenttion to explainabily, with an analysis of its importance in LLMs from the MVP perspective. In addition, we investigate key challenges and mitigation strategies, paying particular attention to the role of temperature as a driver of output randomness and highlighting the crucial role of explainability in improving transparency and user trust. By providing a structured perspective on stability, reproducibility, and trustworthiness, this study helps develop more reliable, explainable, and robust sentiment analysis models, facilitating their deployment in high-risk domains such as finance, healthcare and policy making, among others.},
  archive      = {J_FRAI},
  author       = {Herrera-Poyatos, David and Peláez-González, Carlos and Zuheros, Cristina and Herrera-Poyatos, Andrés and Tejedor, Virilo and Herrera, Francisco and Montes, Rosana},
  doi          = {10.3389/frai.2025.1609097},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1609097},
  shortjournal = {Front. Artif. Intell.},
  title        = {An overview of model uncertainty and variability in LLM-based sentiment analysis: Challenges, mitigation strategies, and the role of explainability},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis of multimodal architectures for effective skin lesion detection using clinical and image data. <em>FRAI</em>, <em>8</em>, 1608837. (<a href='https://doi.org/10.3389/frai.2025.1608837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background/IntroductionSkin lesion classification poses a critical diagnostic challenge in dermatology, where early and accurate identification has a direct impact on patient outcomes. While deep learning approaches have shown promise using dermatoscopic images alone, the integration of clinical metadata remains underexplored despite its potential to enhance diagnostic accuracy.MethodsWe developed a novel multimodal data fusion framework that systematically integrates dermatoscopic images with clinical metadata for the classification of skin lesions. Using the HAM10000 dataset, we evaluated multiple fusion strategies, including simple concatenation, weighted concatenation, self-attention mechanisms, and cross-attention fusion. Clinical features were processed through a customized Multi-Layer Perceptron (MLP), while images were analyzed using a modified Residual Networks (ResNet) architecture. Model interpretability was enhanced using Gradient-weighted Class Activation Mapping (Grad-CAM) visualization to identify the contribution of clinical attributes to classification decisions.ResultsCross-attention fusion achieved the highest classification accuracy, demonstrating superior performance compared to unimodal approaches and simpler fusion techniques. The multimodal framework significantly outperformed image-only baselines, with cross-attention effectively capturing inter-modal dependencies and contextual relationships between visual and clinical data modalities.Discussion/ConclusionsOur findings demonstrate that integrating clinical metadata with dermatoscopic images substantially improves the accuracy of skin lesion classification. However, challenges, including class imbalance and the computational complexity of advanced fusion methods, require further investigation.},
  archive      = {J_FRAI},
  author       = {Das, Adriteyo and Agarwal, Vedant and Shetty, Nisha P.},
  doi          = {10.3389/frai.2025.1608837},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1608837},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparative analysis of multimodal architectures for effective skin lesion detection using clinical and image data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models in equity markets: Applications, techniques, and insights. <em>FRAI</em>, <em>8</em>, 1608365. (<a href='https://doi.org/10.3389/frai.2025.1608365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.},
  archive      = {J_FRAI},
  author       = {Jadhav, Aakanksha and Mirza, Vishal},
  doi          = {10.3389/frai.2025.1608365},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1608365},
  shortjournal = {Front. Artif. Intell.},
  title        = {Large language models in equity markets: Applications, techniques, and insights},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective methods and framework for energy-based local learning of deep neural networks. <em>FRAI</em>, <em>8</em>, 1605706. (<a href='https://doi.org/10.3389/frai.2025.1605706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From a neuroscience perspective, artificial neural networks are regarded as abstract models of biological neurons, yet they rely on biologically implausible backpropagation for training. Energy-based models represent a class of brain-inspired learning frameworks that adjust system states by minimizing an energy function. Predictive coding (PC), a theoretical model within energy-based models, constructs its energy function from forward prediction errors, with optimization achieved by minimizing local layered errors. Owing to its local plasticity, PC emerges as the most promising alternative to backpropagation. However, PC face gradient explosion and vanishing challenges in deep networks with multiple layers. Gradient explosion occurs when layer-wise prediction errors are excessively large, while gradient vanishing arises when they are excessively small. To address these challenges, we propose bidirectional energy to stabilize prediction errors and mitigate gradient explosion, while using skip connections to resolve gradient vanishing problems. We also introduce a layer-adaptive learning rate (LALR) to enhance training efficiency. Our model achieves accuracies of 99.22% on MNIST, 93.78% on CIFAR-10, 83.96% on CIFAR-100, and 73.35% on Tiny ImageNet, comparable to the performance of identically structed networks trained with backprop. Finally, we developed a Jax-based framework for efficient training of energy-based models, reducing training time by half compared to PyTorch.},
  archive      = {J_FRAI},
  author       = {Chen, Haibo and Yang, Bangcheng and He, Fucun and Zhou, Fei and Chen, Shuai and Wu, Chunpeng and Li, Fan and Chua, Yansong},
  doi          = {10.3389/frai.2025.1605706},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1605706},
  shortjournal = {Front. Artif. Intell.},
  title        = {Effective methods and framework for energy-based local learning of deep neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with configuration cross-attention for tensor compilers. <em>FRAI</em>, <em>8</em>, 1605539. (<a href='https://doi.org/10.3389/frai.2025.1605539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent popularity of neural networks comes the need for efficient serving of inference workloads. A neural network inference workload can be represented as a computational graph with nodes as operators transforming multidimensional tensors. The tensors can be transposed and/or tiled in a combinatorially large number of ways, some configurations leading to accelerated inference. We propose TGraph, a neural graph architecture that allows screening for fast configurations of the target computational graph, thus representing an artificial intelligence (AI) tensor compiler in contrast to traditional heuristic-based compilers. The proposed solution improves mean Kendall's τ across layout collections of TpuGraphs from 29.8% of the reliable baseline to 67.4% of TGraph. We estimate the potential CO2 emission reduction associated with our work to be equivalent to over 50% of the total household emissions in the areas hosting AI-oriented data centers.},
  archive      = {J_FRAI},
  author       = {Khizbullin, Dmitrii and de Andrade, Eduardo Rocha and Nguyen, Thanh Hau and Ferreira, Matheus Pedroza and Pugh, David R.},
  doi          = {10.3389/frai.2025.1605539},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1605539},
  shortjournal = {Front. Artif. Intell.},
  title        = {Graph neural networks with configuration cross-attention for tensor compilers},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Divide and summarize: Improve SLM text summarization. <em>FRAI</em>, <em>8</em>, 1604034. (<a href='https://doi.org/10.3389/frai.2025.1604034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionText summarization is a longstanding challenge in natural language processing, with recent advancements driven by the adoption of Large Language Models (LLMs) and Small Language Models (SLMs). Despite these developments, issues such as the “Lost in the Middle” problem—where LLMs tend to overlook information in the middle of lengthy prompts—persist. Traditional summarization, often termed the “Stuff” method, processes an entire text in a single pass. In contrast, the “Map” method divides the text into segments, summarizes each independently, and then synthesizes these partial summaries into a final output, potentially mitigating the “Lost in the Middle” issue. This study investigates whether the Map method outperforms the Stuff method for texts that fit within the context window of SLMs and assesses its effectiveness in addressing the “Lost in the Middle” problem.MethodsWe conducted a two-part investigation: first, a simulation study using generated texts, paired with an automated fact-retrieval evaluation to eliminate the need for human assessment; second, a practical study summarizing scientific papers.ResultsResults from both studies demonstrate that the Map method produces summaries that are at least as accurate as those from the Stuff method. Notably, the Map method excels at retaining key facts from the beginning and middle of texts, unlike the Stuff method, suggesting its superiority for SLM-based summarization of smaller texts. Additionally, SLMs using the Map method achieved performance comparable to LLMs using the Stuff method, highlighting its practical utility.DiscussionBoth theoretical and practical studies suggest that using Map method for summarization with SLM allowed to address the “Lost in the Middle” problem and outperform Stuff method.},
  archive      = {J_FRAI},
  author       = {Bailly, Alexandre and Saubin, Antoine and Kocevar, Gabriel and Bodin, Jonathan},
  doi          = {10.3389/frai.2025.1604034},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1604034},
  shortjournal = {Front. Artif. Intell.},
  title        = {Divide and summarize: Improve SLM text summarization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence think tank: A modern problem-solving framework. <em>FRAI</em>, <em>8</em>, 1603562. (<a href='https://doi.org/10.3389/frai.2025.1603562'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today's world, when everything is changing quickly and new global concerns are emerging, lifelong learning and creative problem solving are more crucial than ever. Classical approaches such as the brainstorming, Delphi, Nominal Group Technique, focus groups, and the World Café are some of existing problem-solving supporting approaches, but they may not necessarily suit complicated and extended decision-making situations (Caudle et al., 2025, Raadschelders and Whetsell, 2018, Watkins et al., 2012). These approaches are consensus-based and hence rely on the availability of experts, time, and cognitive capacity, which limits their scalability and effectiveness in dynamic contexts. Their drawbacks become particularly pronounced in emerging sectors, where access to sufficient expertise is often constrained by high costs, time pressures, or simply a lack of established specialists (Palonen et al., 2014). The drawbacks of these classic methods, such as their reliance on the availability of experts, significant time necessities, and limited scalability, may cause decisions to be delayed, opportunities to be missed, and solutions to be lacking in resource-constrained situations.To address the classic approaches' limitations, a growing trend has emerged involving the utilization of artificial intelligence (AI) to support human capabilities across various domains (Korteling et al., 2021). According to Fui-Hoon Nah et al. (Fui-Hoon Nah et al., 2023), AI-human collaboration has emerged as a promising path forward in addressing these challenges and unlocking new possibilities for human development. The technologies improve data mining, data analysis, and even certain decision-making activities that were previously the domain of human specialists, which might be very valuable in the cyclic learning process and future-oriented problem-solving. As a result, in order to capitalize on these prospects, this paper suggests the AI Think Tank (AITT) framework as a novel and unique method to decision surrogate modeling that may complement and replace existing ways to lean and progress for decision making and problemsolving. Current versions of Generative AI technology can produce human-like conversations and are gaining popularity due to their ability to give tailored and context-sensitive replies (Dwivedi et al., 2023) The AITT procedure, as figure 1 shows, has the power to promote inventive thinking and broaden the boundaries of how humans learn, adapt, and prosper in an ever-changing environment, by promoting continuous skill acquisition, improving decision-making efficiency, and encouraging cooperation between AI and human judgment. problem/decision needs to be addressed.Correspondingly, a comprehensive standardized prompt/query is developed by the decision maker(s) to ensure consistency and reliability in AI outputs. The prompt may include all necessary background information such as current trends, constraints, and goals.If feasible, invite (a) field expert(s) to review and validate the prompt, mapping it to the problem/decision at hand.Stage 2: Getting insights from AI. Although relying on a single AI chatbot remains possible, it is preferred that the standardized prompt be posed to multiple AI systems to ensure coverage of a broad spectrum of insights. Using different AIs ensures diversity in inputs, as each AI system (e.g., ChatGPT, Gemini) operates with unique data sources and methodologies, offering complementary perspectives.1. Select an AI system and, according to the developed prompt, task it with generating ideas and needed problem-solving variables (such as success factors, barriers and challenges, motives, decision criteria, risks, etc.), or alternative solutions for a given problem.When As (a) decision-maker(s), use criteria like relevance and feasibility to evaluate outputs and authenticate insights according to the problem and/or decision context to minimize potential biases.A simple case study was employed to illustrate the feasibility of the proposed AITT; it serves as a preliminary proof-of-concept. The aim of this case study was to demonstrate the potential application of the AITT framework. Hence, the four stages of the AITT were carried out in the explicitly defined order outlined lower. In this case study, we implement the AITT to identify its limitations.1.We considered AITT validation in the scenario when there is no specific AITT expert available and the author is the sole proposer. Therefore, the AITT were utilized to provide feedback on the possible constraints of itself. Following the completion of the problem definition, the AITT method presentation was used to initiate this case study.ChatGPT and Gemini were chosen for this case study due to their widespread popularity;just the two AI systems were used in the study to ensure a simple AITT implementation demonstration. A detailed description of the AITT framework was sent to both AI platforms, ChatGPT and Gemini, inquiring about potential limitations of the proposed AITT. The technique employed a standardized input for both AIs and offered the identical question to both: "What are the potential limitations of the AITT framework?". Resultswere synthesized to create a comprehensive list, combining outputs from each AI system into a cohesive set of concepts.Asking for more output, communication with AIs continued until no new answer, feasible, important, or reasonable output was provided. This stage contained the exclusion of items that received low agreement from the author or did not directly pertain to the AITT in relation to traditional problem-solving and decision-making methods.A total of 21 concepts were incorporated in the aforementioned list, comprising 9 items from Gemini and 12 items from ChatGPT. Among these, 8 concepts showed either identical or extremely equivalent results when assessed by both ChatGPT and Gemini. Hence, a list of 13 was gathered and after reviewing the data summary, the authors, in their role as the decision-maker, concluded that some restrictions are more significant and should be explicitly communicated, though all listed items were valid.By utilizing the AITT strategy, the decision-making scenario described above effectively collected and ranked ideas, indicating the potential for improved efficiency and comprehensiveness when compared with classic approaches, though more empirical validation remains required. This specific phase of strategic planning requires a substantial reduction in the time needed due to the automation of concept creation and analysis methods. The decision-maker determined that the developed concepts demonstrated proper logical consistency. The applied technique has shown its capacity to efficiently handle a wide range of inputs and adapt to different decision-making scenarios, without requiring the participation of a significant number of subject matter experts.Moreover, the employment of the AITT guaranteed the achievement of a thorough comprehension of important features and prerequisites for using the AITT approach, therefore offering an additional advantage.The use of this specific case study confirmed AITT's applicability, demonstrating its capacity as a viable and efficient instrument for overcoming problem-solving challenges and reaching informed conclusions. Nevertheless, some potential limitations were identified. AITT results may be biased due to inconsistent AI performance, the risk of generating misplaced confidence, and occasionally, challenges in interpreting or explaining AI-generated reasoning clearly. These can be reduced, however, by employing cross-referencing techniques and human validation of AI outputs. AITT is unable to handle tacit knowledge; it also faces creativity and novelty limits because it works with documented information; and it is less able to fully consider emotional, cultural, intuitive understanding, common sense, and contextual nuance. To overcome these limitations, AITT users can follow best practices for more reliable and transparent use in practical applications. Humanin-the-loop supervision is still considered essential to adequately understand the results of AI and determine its usefulness and relevance. Users can evaluate AI responses with cross-validation to identify harmony or contradictions. They may need to perform iterative prompt refinement to improve output quality and monitor AI system upgrades for response coherence. Another challenge for AITT is complexity in prompt engineering and the risk of resulting information overload, yet this needs to be addressed by integrating human oversight and modification of prompts.As discussed in this letter, AI can act as a think tank, assisting us with problem solving and decision-making. This letter proposed a supplementary, systematic, adaptable, and efficient AITT framework for modern problem-solving; this semi-automated idea generation saves time and resources, making AITT highly adaptable across diverse industries, contexts, and levels of complexity. However, more research in various sectors and situations is needed to determine the potential application and improvement of AITT. To advance this paradigm, real-world examples must be requested, investigations must be conducted, and more verification cooperation is required. Integration of AITT with other, traditional or modern, decision-making methods broadens the problem comprehension, even when expert human input is scarce or expensive, as future researchers can verify.},
  archive      = {J_FRAI},
  author       = {Sorooshian, Shahryar},
  doi          = {10.3389/frai.2025.1603562},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1603562},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence think tank: A modern problem-solving framework},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predictive analytics approach to improve telecom's customer retention. <em>FRAI</em>, <em>8</em>, 1600357. (<a href='https://doi.org/10.3389/frai.2025.1600357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer retention is a critical challenge for telecom companies, and understanding customer churn can significantly improve business strategies. This paper focuses on developing an accurate predictive model to identify potential customer churn using advanced data analysis techniques. By applying machine learning algorithms, our aim is to improve decision-making processes and enable telecom providers to take proactive measures to retain customers. Through this research, we seek to gain deeper insight into customer behavior, ultimately helping telecom companies improve service offerings and reduce churn rates. We developed and evaluated a diverse set of predictive models using a dataset representing customer churn. Our comparative analysis highlights the strengths and weaknesses of various techniques, and among the developed models, the Support Vector Machine (SVM) achieved the highest performance. The main contribution of this study lies in integrating effective data pre-processing, feature selection, and interpretability into churn prediction models, thus addressing the gaps identified in earlier research.},
  archive      = {J_FRAI},
  author       = {Omari, Asem and Al-Omari, Omaia and Al-Omari, Tariq and Fati, Suliman Mohamed},
  doi          = {10.3389/frai.2025.1600357},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1600357},
  shortjournal = {Front. Artif. Intell.},
  title        = {A predictive analytics approach to improve telecom's customer retention},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BioBricks.ai: A versioned data registry for life sciences data assets. <em>FRAI</em>, <em>8</em>, 1599412. (<a href='https://doi.org/10.3389/frai.2025.1599412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionResearchers in biomedicine and public health often spend weeks locating, cleansing, and integrating data from disparate sources before analysis can begin. This redundancy slows discovery and leads to inconsistent pipelines.MethodsWe created BioBricks.ai, an open, centralized repository that packages public biological and chemical datasets as modular “bricks.” Each brick is a Data Version Control (DVC) Git repository containing an extract‑transform‑load (ETL) pipeline. A package‑manager–like interface handles installation, dependency resolution, and updates, while data are delivered through a unified backend (https://biobricks.ai).ResultsThe current release provides >90 curated datasets spanning genomics, proteomics, cheminformatics, and epidemiology. Bricks can be combined programmatically to build composite resources; benchmark use‑cases show that assembling multi‑dataset analytic cohorts is reduced from days to minutes compared with bespoke scripts.DiscussionBioBricks.ai accelerates data access, promotes reproducible workflows, and lowers the barrier for integrating heterogeneous public datasets. By treating data as version‑controlled software, the platform encourages community contributions and reduces redundant engineering effort. Continued expansion of brick coverage and automated provenance tracking will further enhance FAIR (Findable, Accessible, Interoperable, Reusable) data practices across the life‑science community.},
  archive      = {J_FRAI},
  author       = {Gao, Yifan and Mughal, Zakariyya and Jaramillo-Villegas, Jose A. and Corradi, Marie and Borrel, Alexandre and Lieberman, Ben and Sharif, Suliman and Shaffer, John and Fecho, Karamarie and Chatrath, Ajay and Maertens, Alexandra and Teunis, Marc A. T. and Kleinstreuer, Nicole and Hartung, Thomas and Luechtefeld, Thomas},
  doi          = {10.3389/frai.2025.1599412},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1599412},
  shortjournal = {Front. Artif. Intell.},
  title        = {BioBricks.ai: A versioned data registry for life sciences data assets},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation of deep learning approaches for automated damage diagnostics in fiber metal laminates using detectron2 and SAM. <em>FRAI</em>, <em>8</em>, 1599345. (<a href='https://doi.org/10.3389/frai.2025.1599345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact damage is one of the major causes of structural failures in Fiber Metal Laminate (FML) plates, which are widely used in the aerospace and automotive industries due to their superior mechanical properties. Accurate detection, segmentation, and characterization of these damages are crucial for improved safety and reduced maintenance costs. This study proposes an automated approach to detect, segment, reconstruct, and characterize the damages in FML plates using state-of-the-art deep learning models: the Segment Anything Model (SAM) and the Mask Region-based Convolutional Neural Network (Mask R-CNN) implemented by the Detectron2 framework. A domain-adapted supervised learning process was applied to the X-ray CT dataset of damaged FML plates impacted with energies of 5J, 7.5J, 10J, and 12.5J. Mask R-CNN significantly outperformed SAM across all key performance metrics while offering around 8 times faster training and 80 times faster inference. Mask R-CNN also proved to have superior explainability for end-users. The lack of absolute ground truth data severely limits the scope of an absolute quantitative comparison, therefore highlighting the need for further studies. This study not only contributes to the area of damage diagnostics in composite materials but also provides insights into the comparative performance and explainability of advanced deep learning models, paving the way for applications in industrial inspection and quality assurance.},
  archive      = {J_FRAI},
  author       = {Kumar, Sanjeev and Bosse, Stefan and Shah, Chirag},
  doi          = {10.3389/frai.2025.1599345},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1599345},
  shortjournal = {Front. Artif. Intell.},
  title        = {Investigation of deep learning approaches for automated damage diagnostics in fiber metal laminates using detectron2 and SAM},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification prediction of load losses in power stations using machine learning multilayer stack ensemble. <em>FRAI</em>, <em>8</em>, 1592492. (<a href='https://doi.org/10.3389/frai.2025.1592492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load losses negatively impact the reliability of power stations, leading to plant failures. To support the decision-making of improving plant reliability, we experimented with six machine learning classifiers to find the model combination that produces the best prediction performance, called the Explainable Multilayer Stack Ensemble. We applied a five-year dataset from six power stations. Since the dataset is highly imbalanced with the positive class dominant, class weights are calculated and assigned to reduce bias toward the majority class. The best parameters are determined through a randomized search with cross-validation and applied to train the models. The Explainable Multilayer Stack Ensemble performed better than the individual models, with a further improvement by excluding the Gaussian Naïve Bayes in the second layer since it produced high false negatives. We demonstrate that when handling a highly imbalanced dataset, balanced accuracy, Receiver Operating Characteristics, and Precision-Recall Area Under the Curve provide a more reliable evaluation of model performance than focusing solely on standard evaluation metrics, such as accuracy, precision, and recall. Moreover, by excluding a poor-performing classifier from ensemble, we optimized the prediction process, and further enhanced overall performance.},
  archive      = {J_FRAI},
  author       = {Boshoma, Bathandekile M. and Akinola, Oluwole S. and Olukanmi, Peter},
  doi          = {10.3389/frai.2025.1592492},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1592492},
  shortjournal = {Front. Artif. Intell.},
  title        = {Classification prediction of load losses in power stations using machine learning multilayer stack ensemble},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for closed-library multi-document query, test generation, and evaluation. <em>FRAI</em>, <em>8</em>, 1592013. (<a href='https://doi.org/10.3389/frai.2025.1592013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionLearning complex, detailed, and evolving knowledge is a challenge in multiple technical professions. Relevant source knowledge is contained within many large documents and information sources with frequent updates to these documents. Knowledge tests need to be generated on new material and existing tests revised, tracking knowledge base updates. Large Language Models (LLMs) provide a framework for artificial intelligence-assisted knowledge acquisition and continued learning. Retrieval-Augmented Generation (RAG) provides a framework to leverage available, trained LLMs combined with technical area-specific knowledge bases.MethodsHerein, two methods are introduced (DaaDy: document as a dictionary and SQAD: structured question answer dictionary), which together enable effective implementation of LLM-RAG question-answering on large documents. Additionally, the AI for knowledge intensive tasks (AIKIT) solution is presented for working with numerous documents for training and continuing education. AIKIT is provided as a containerized open source solution that deploys on standalone, high performance, and cloud systems. AIKIT includes LLM, RAG, vector stores, relational database, and a Ruby on Rails web interface.ResultsCoverage of source documents by LLM-RAG generated questions decreases as the length of documents increase. Segmenting source documents improve coverage of generated questions. The AIKIT solution enabled easy use of multiple LLM models with multimodal RAG source documents; AIKIT retains LLM-RAG responses for queries against one or multiple LLM models.DiscussionAIKIT provides an easy-to-use set of tools to enable users to work with complex information using LLM-RAG capabilities. AIKIT enables easy use of multiple LLM models with retention of LLM-RAG responses.},
  archive      = {J_FRAI},
  author       = {Randolph, Claire and Michaleas, Adam and Ricke, Darrell O.},
  doi          = {10.3389/frai.2025.1592013},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1592013},
  shortjournal = {Front. Artif. Intell.},
  title        = {Large language models for closed-library multi-document query, test generation, and evaluation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of large language model-driven AutoML in data and model management from human-centered perspective. <em>FRAI</em>, <em>8</em>, 1590105. (<a href='https://doi.org/10.3389/frai.2025.1590105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As organizations increasingly seek to leverage machine learning (ML) capabilities, the technical complexity of implementing ML solutions creates significant barriers to adoption and impacts operational efficiency. This research examines how Large Language Models (LLMs) can transform the accessibility of ML technologies within organizations through a human-centered Automated Machine Learning (AutoML) approach. Through a comprehensive user study involving 15 professionals across various roles and technical backgrounds, we evaluate the organizational impact of an LLM-based AutoML framework compared to traditional implementation methods. Our research offers four significant contributions to both management practice and technical innovation: First, we present pioneering evidence that LLM-based interfaces can dramatically improve ML implementation success rates, with 93.34% of users achieved superior performance in the LLM condition, with 46.67% showing higher accuracy (10%–25% improvement over baseline) and 46.67% demonstrating significantly higher accuracy (>25% improvement over baseline), while 6.67% maintained comparable performance levels; and 60% reporting substantially reduced development time. Second, we demonstrate how natural language interfaces can effectively bridge the technical skills gap in organizations, cutting implementation time by 50% while improving accuracy across all expertise levels. Third, we provide valuable insights for organizations designing human-AI collaborative systems, showing that our approach reduced error resolution time by 73% and significantly accelerated employee learning curves. Finally, we establish empirical support for natural language as an effective interface for complex technical systems, offering organizations a path to democratize ML capabilities without compromising quality or performance.},
  archive      = {J_FRAI},
  author       = {Yao, Jiapeng and Zhang, Lantian and Huang, Jiping},
  doi          = {10.3389/frai.2025.1590105},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1590105},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of large language model-driven AutoML in data and model management from human-centered perspective},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Freedom under algorithms: How unpredictable and asocial management erodes free choice. <em>FRAI</em>, <em>8</em>, 1582085. (<a href='https://doi.org/10.3389/frai.2025.1582085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines the impact of algorithmic management on individual freedom. To orient this exploration, I draw on the (feminist) conception of liberty as the choosing subject. The central suggestion is that algorithmic management poses a serious threat to an indispensable part of the freely choosing subject: namely, it degrades the ability of subordinates to reasonably foresee the consequences of their choices and consequently, fully realise their personality. I call this phenomenon the ‘foresight endangerment problem’ and argue that it has both a technical and a social face. The technical face highlights the inherent unpredictability of advanced algorithms, including those that execute managerial functions. This issue is further complicated by the fact that as algorithms become more resilient and useful, their outputs grow increasingly opaque and unpredictable—what some refer to as the resilience-predictability paradox. The technical face is made manifest in the reported experiences of workers in the gig economy who describe experiencing unpredictable managerial decisions that they cannot anticipate nor easily contest. Subjection to such managerial randomness erodes their ability to make informed choices in service of their personal goals. The social face emphasises the consequences of disembedding managerial power from social relationships between humans to asocial relationships between humans and software. Subordinates of human managers enjoy a vast number of tools to predict managerial thinking that arise from the intricate and complex processes of social interaction. The disembedding process forecloses the use of these tools and fundamentally undermines the capacity of subordinates to promote their ends through free choice.},
  archive      = {J_FRAI},
  author       = {Donoghue, Robert},
  doi          = {10.3389/frai.2025.1582085},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1582085},
  shortjournal = {Front. Artif. Intell.},
  title        = {Freedom under algorithms: How unpredictable and asocial management erodes free choice},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in conjunctivitis research: Assessing ChatGPT and DeepSeek for etiology, intervention, and citation integrity via hallucination rate analysis. <em>FRAI</em>, <em>8</em>, 1579375. (<a href='https://doi.org/10.3389/frai.2025.1579375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe advent of large language models and their applications have gained significant attention due to their strengths in natural language processing.MethodsIn this study, ChatGPT and DeepSeek are utilized as AI models to assist in diagnosis based on the responses generated to clinical questions. Furthermore, ChatGPT, Claude, and DeepSeek are used to analyze images to assess their potential diagnostic capabilities, applying the various sensitivity analyses described. We employ prompt engineering techniques and evaluate their abilities to generate high quality responses. We propose several prompts and use them to answer important information on conjunctivitis.ResultsOur findings show that DeepSeek excels in offering precise and comprehensive information on specific topics related to conjunctivitis. DeepSeek provides detailed explanations and in depth medical insights. In contrast, the ChatGPT model provides generalized public information on the infection, which makes it more suitable for broader and less technical discussions. In this study, DeepSeek achieved a better performance with a 7% hallucination rate compared to ChatGPT's 13%. Claude demonstrated perfect 100% accuracy in binary classification, significantly outperforming ChatGPT's 62.5% accuracy.DiscussionDeepSeek showed limited performance in understanding images dataset on conjunctivitis. This comparative analysis serves as an insightful reference for scholars and health professionals applying these models in varying medical contexts.},
  archive      = {J_FRAI},
  author       = {Hasnain, Muhammad and Aurangzeb, Khursheed and Alhussein, Musaed and Ghani, Imran and Mahmood, Muhammad Hamza},
  doi          = {10.3389/frai.2025.1579375},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1579375},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI in conjunctivitis research: Assessing ChatGPT and DeepSeek for etiology, intervention, and citation integrity via hallucination rate analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grouped semantic-feature relation extraction from texts to represent medicinal-plant property knowledge on social media. <em>FRAI</em>, <em>8</em>, 1579357. (<a href='https://doi.org/10.3389/frai.2025.1579357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to extract a grouped semantic-feature relation, particularly a PlantPart-MedicinalPropertyGroup relation which is a semantic relation between an element of a plant-part concept set and a group of medicinal-property concept features of various herbs or medicinal plants, including indigenous medicinal plants, to graphically represent medicinal-plant property knowledge from documents available on pharmacy academic websites. The medicinal-plant property knowledge representation particularly benefits native users and patients seeking alternative medical therapies during pandemics, such as COVID-19, due to limited access to medicines, physicians and hospitals. Medicinal-property expressions on the documents, particularly in Thai, are often structured as event expressions conveyed through verb phrases within Elementary Discourse Units (EDUs) or simple sentences. There are three research problems in extracting the PlantPart-MedicinalPropertyGroup relations from the documents: how to identify EDU occurrences with medicinal-property concepts, how to extract medicinal-property concept features from medicinal-property concept EDU occurrences without concept annotations, and how to extract the PlantPart-MedicinalPropertyGroup relation without relation-class labeling from the documents with the high dimensional and correlated feature consideration. To address these problems, we apply a Solving-Verb Concept set primarily sourced from translated terms on HerbMed, an American Botanical Council resource, to identify a medicinal-property concept EDU. Additionally, a word co-occurrence (word-co) pattern is applied as a compound variable on the translated terms to construct a medicinal-property-concept (MPC) table. The MPC table is employed to extract the medicinal-property concept features from the medicinal-property concept EDUs through a string-matching method. We then propose using structural equation modeling to automatically extract the PlantPart-MedicinalPropertyGroup relations from the documents. Thus, the proposed approach enables the extraction of PlantPart-MedicinalPropertyGroup relations with high qualities to represent medicinal-plant property knowledge on social media.},
  archive      = {J_FRAI},
  author       = {Pechsiri, Chaveevan and Piriyakul, Intaka and Pechsiri, Joseph Santhi},
  doi          = {10.3389/frai.2025.1579357},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1579357},
  shortjournal = {Front. Artif. Intell.},
  title        = {Grouped semantic-feature relation extraction from texts to represent medicinal-plant property knowledge on social media},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of deep learning methods for community detection in social networks. <em>FRAI</em>, <em>8</em>, 1572645. (<a href='https://doi.org/10.3389/frai.2025.1572645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe rapid expansion of generated data through social networks has introduced significant challenges, which underscores the need for advanced methods to analyze and interpret these complex systems. Deep learning has emerged as an effective approach, offering robust capabilities to process large datasets, and uncover intricate relationships and patterns.MethodsIn this systematic literature review, we explore research conducted over the past decade, focusing on the use of deep learning techniques for community detection in social networks. A total of 19 studies were carefully selected from reputable databases, including the ACM Library, Springer Link, Scopus, Science Direct, and IEEE Xplore. This review investigates the employed methodologies, evaluates their effectiveness, and discusses the challenges identified in these works.ResultsOur review shows that models like graph neural networks (GNNs), autoencoders, and convolutional neural networks (CNNs) are some of the most commonly used approaches for community detection. It also examines the variety of social networks, datasets, evaluation metrics, and employed frameworks in these studies.DiscussionHowever, the analysis highlights several challenges, such as scalability, understanding how the models work (interpretability), and the need for solutions that can adapt to different types of networks. These issues stand out as important areas that need further attention and deeper research. This review provides meaningful insights for researchers working in social network analysis. It offers a detailed summary of recent developments, showcases the most impactful deep learning methods, and identifies key challenges that remain to be explored.},
  archive      = {J_FRAI},
  author       = {El-Moussaoui, Mohamed and Hanine, Mohamed and Kartit, Ali and Villar, Monica Garcia and Garay, Helena and de la Torre Díez, Isabel},
  doi          = {10.3389/frai.2025.1572645},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1572645},
  shortjournal = {Front. Artif. Intell.},
  title        = {A systematic review of deep learning methods for community detection in social networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dairy DigiD: A keypoint-based deep learning system for classifying dairy cattle by physiological and reproductive status. <em>FRAI</em>, <em>8</em>, 1545247. (<a href='https://doi.org/10.3389/frai.2025.1545247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision livestock farming increasingly relies on non-invasive, high-fidelity systems capable of monitoring cattle with minimal disruption to behavior or welfare. Conventional identification methods, such as ear tags and wearable sensors, often compromise animal comfort and produce inconsistent data under real-world farm conditions. This study introduces Dairy DigiD, a deep learning-based biometric classification framework that categorizes dairy cattle into four physiologically defineda groups—young, mature milking, pregnant, and dry cows—using high-resolution facial images. The system combines two complementary approaches: a DenseNet121 model for full-image classification, offering global visual context, and Detectron2 for fine-grained facial analysis. Dairy DigiD leverages Detectron2’s multi-task architecture, using instance segmentation and keypoint detection across 30 anatomical landmarks (eyes, ears, muzzle) to refine facial localization and improve classification robustness. While DenseNet121 delivered strong baseline performance, its sensitivity to background noise limited generalizability. In contrast, Detectron2 demonstrated superior adaptability in uncontrolled farm environments, achieving classification accuracies between 93 and 98%. Its keypoint-driven strategy enabled robust feature localization and resilience to occlusions, lighting variations, and heterogeneous backgrounds. Cross-validation and perturbation-based explainability confirmed that biologically salient features guided classification, enhancing model transparency. By integrating animal-centric design with scalable AI, Dairy DigiD represents a significant advancement in automated livestock monitoring-offering an ethical, accurate, and practical alternative to traditional identification methods. The approach sets a precedent for responsible, data-driven decision-making in precision dairy management.},
  archive      = {J_FRAI},
  author       = {Mahato, Shubhangi and Bi, Hanqing and Neethirajan, Suresh},
  doi          = {10.3389/frai.2025.1545247},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1545247},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dairy DigiD: A keypoint-based deep learning system for classifying dairy cattle by physiological and reproductive status},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tokenization efficiency of current foundational large language models for the ukrainian language. <em>FRAI</em>, <em>8</em>, 1538165. (<a href='https://doi.org/10.3389/frai.2025.1538165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundational large language models (LLMs) are deployed in multilingual environments across a range of general and narrow task domains. These models generate text token by token, making them slower and more computationally expensive for low-resource languages that are underrepresented in the tokenizer vocabulary. It also makes their usage more costly in such cases, as pricing usually depends on the number of input and output tokens. This study compares multiple tokenizers of pretrained LLMs for the Ukrainian language. It also provides tokenization fertility measurements for current state-of-the-art (SOTA) models, both in terms of general-purpose language and specific domains, as well as results of experiments with a transliteration approach to make tokenization more efficient without information loss. The results provide insights into the current models’ disadvantages and possible problems in terms of Ukrainian language modeling.},
  archive      = {J_FRAI},
  author       = {Maksymenko, Daniil and Turuta, Oleksii},
  doi          = {10.3389/frai.2025.1538165},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1538165},
  shortjournal = {Front. Artif. Intell.},
  title        = {Tokenization efficiency of current foundational large language models for the ukrainian language},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MedAlmighty: Enhancing disease diagnosis with large vision model distillation. <em>FRAI</em>, <em>8</em>, 1527980. (<a href='https://doi.org/10.3389/frai.2025.1527980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAccurate disease diagnosis is critical in the medical field, yet it remains a challenging task due to the limited, heterogeneous, and complex nature of medical data. These challenges are particularly pronounced in multimodal tasks requiring the integration of diverse data sources. While lightweight models offer computational efficiency, they often lack the comprehensive understanding necessary for reliable clinical predictions. Conversely, large vision models, trained on extensive general-domain datasets, provide strong generalization but fall short in specialized medical applications due to domain mismatch and limited medical data availability.MethodsTo bridge the gap between general and specialized performance, we propose MedAlmighty, a knowledge distillation-based framework that synergizes the strengths of both large and small models. In this approach, we utilize DINOv2—a pre-trained large vision model—as a frozen teacher, and a lightweight convolutional neural network (CNN) as the trainable student. The student model is trained using both hard labels from the ground truth and soft targets generated by the teacher model. We adopt a hybrid loss function that combines cross-entropy loss (for classification accuracy) and Kullback-Leibler divergence (for distillation), enabling the student model to capture rich semantic features while remaining efficient and domain-aware.ResultsExperimental evaluations reveal that MedAlmighty significantly improves disease diagnosis performance across datasets characterized by sparse and diverse medical data. The proposed model outperforms baselines by effectively integrating the generalizable representations of large models with the specialized knowledge from smaller models. The results confirm improved robustness and accuracy in complex diagnostic scenarios.DiscussionThe MedAlmighty framework demonstrates that incorporating general-domain representations via frozen large vision models—when guided by task-specific distillation strategies—can enhance the performance of lightweight medical models. This approach offers a promising solution to data scarcity and domain gap issues in medical imaging. Future work may explore extending this distillation strategy to other medical modalities and incorporating multimodal alignment for even richer representation learning.},
  archive      = {J_FRAI},
  author       = {Ren, Yajing and Gu, Zheng and Liu, Wen},
  doi          = {10.3389/frai.2025.1527980},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1527980},
  shortjournal = {Front. Artif. Intell.},
  title        = {MedAlmighty: Enhancing disease diagnosis with large vision model distillation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mobile hybrid deep learning approach for classifying 3D-like representations of amazonian lizards. <em>FRAI</em>, <em>8</em>, 1524380. (<a href='https://doi.org/10.3389/frai.2025.1524380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification is a highly significant field in machine learning (ML), especially when applied to address longstanding and challenging issues in the biological sciences, such as specie recognition and biodiversity conservation. In this study, we present the development of a hybrid machine learning-based tool suitable for deployment on mobile devices. This tool is aimed at processing and classifying three-dimensional samples of endemic lizard species from the Amazon rainforest. The dataset used in our experiment was collected at the Museu Paraense Emílio Goeldi (MPEG), Belém-PA, Brazil, and comprises three species: (a) Anolis fuscoauratus; (b) Hoplocercus spinosus; and (c) Polychrus marmoratus. We compared the effectiveness of four artificial neural networks (ANN) for feature extraction: (a) MobileNet; (b) MobileNetV2; (c) MobileNetV3-Small; and (d) MobileNetV3-Large. Additionally, we evaluated five classical ML models for classifying the extracted patterns: (a) Support Vector Machine (SVM); (b) GaussianNB (GNB); (c) AdaBoost (ADB); (d) K-Nearest Neighbors (KNN); and (e) Random Forest (RF). The performance metrics of all classifiers were very close, we used the McNemar’s test on each model’s confusion matrix to evaluate and compare their statistical significance. Our best model was a combination of a 2.9 million parameters MobileNetV3-Small as the feature extractor, with a linear kernel-based SVM as the classifier, which achieved accuracy of 0.955, precision of 0.948, recall of 0.948, and f1-score of 0.948. The results indicated that the use of a small deep learning (DL) model, in combination with a classical ML algorithm, emerges as a viable technique for classifying three-dimensional representations of lizard species samples. Such an approach facilitates taxonomic identification work for professionals in the field and provides a tool adaptable for integration into mobile data recording equipment, such as smartphones, and benefiting from more morphological features extracted from three-dimensional samples instead of two-dimensional images.},
  archive      = {J_FRAI},
  author       = {da Silva, Arthur Gonsales and de Oliveira, Roger Pinho and de Oliveira Bastos, Caio and de Carvalho, Elena Almeida and Gomes, Bruno Duarte},
  doi          = {10.3389/frai.2025.1524380},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1524380},
  shortjournal = {Front. Artif. Intell.},
  title        = {A mobile hybrid deep learning approach for classifying 3D-like representations of amazonian lizards},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Population health management through human phenotype ontology with policy for ecosystem improvement. <em>FRAI</em>, <em>8</em>, 1496937. (<a href='https://doi.org/10.3389/frai.2025.1496937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AimThe manuscript “Population Health Management (PHM) Human Phenotype Ontology (HPO) Policy for Ecosystem Improvement” steward safe science and secure technology in medical reform. The digital HPO policy advances Biological Modelling (BM) capacity and capability in a series of fair classifications. Public trust in the PHM of HPO is a vision of public health and patient safety, with a primary goal of socioeconomic success sustained by citizen privacy and trust within an ecosystem of predictor equality and intercept parity.MethodScience and technology security evaluation, resource allocation, and appropriate regulation are essential for establishing a solid foundation in a safe ecosystem. The AI Security Institute collaborates with higher experts to assess BM cybersecurity and privacy. Within this ecosystem, resources are allocated to the Genomic Medical Sciences Cluster and AI metrics that support safe HPO transformations. These efforts ensure that AI digital regulation acts as a service appropriate to steward progressive PHM.RecommendationsThe manuscript presents a five-point mission for the effective management of population health. A comprehensive national policy for phenotype ontology with Higher Expert Medical Science Safety stewards reform across sectors. It emphasizes developing genomic predictors and intercepts, authorizing predictive health pre-eXams and precise care eXams, adopting Generative Artificial Intelligence classifications, and expanding the PHM ecosystem in benchmark reforms.DiscussionDiscussions explore medical reform focusing on public health and patient safety. The nation's safe space expansions with continual improvements include steward developing, authorizing, and adopting digital BM twins. The manuscript addresses international classifications where the global development of PHM enables nations to choose what to authorize for BM points of need. These efforts promote channels for adopting HPO uniformity, transforming research findings into routine phenotypical primary care practices.ConclusionThis manuscript charts the UK's and global PHM's ecosystem expansion, designing HPO policies that steward the modeling of biology in personal classifications. It develops secure, safe, fair, and explainable BM for public trust in authorized classifiers and promotes informed choices regarding what nations and individuals adopt in a cooperative PHM progression. Championing equitable classifications in a robust ecosystem sustains advancements in population health outcomes for economic growth and public health betterment.},
  archive      = {J_FRAI},
  author       = {Henry, James Andrew},
  doi          = {10.3389/frai.2025.1496937},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1496937},
  shortjournal = {Front. Artif. Intell.},
  title        = {Population health management through human phenotype ontology with policy for ecosystem improvement},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Population health management of human phenotype ontology. <em>FRAI</em>, <em>8</em>, 1496935. (<a href='https://doi.org/10.3389/frai.2025.1496935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AimsPopulation Health Management (PHM), through strategic integration of the Human Phenotype Ontology (HPO), emphasises the responsible use of digital infrastructure and comprehensive genomic data to promote good health and wellbeing. The UK seeks to steward medical science and phenotype practices in primary care settings with technical approaches for developing a national Biological Modelling (BM) ecosystem. By recognising diverse global healthcare systems, this manuscript offers a means for nations to adapt their HPO operational deployment for global PHM harmony.MethodsThe methodological approach incorporates primary care services and funding assessments to address digital infrastructure needs, ensuring secure national data access. Evaluations include ISO standards, systems thinking, alignment of UK infrastructure with informatics requirements, and AI norms within the ecosystem. Specific use cases for genomic predictive health pre-eXams and precise care eXams are assessed, alongside strategies for bias mitigation to ensure fairness in AI-driven classifications.RecommendationsThe manuscript advocates for establishing local agile ecosystem groups for PHM, regional Higher Expert Medical Science Safety (HEMSS) stewardship, national HPO value-based care models, and integrating global PHM general intelligence. Real-world AI and clinical practice comparisons are emphasised for validating digital twin personalised BM via Gen AI in the HPO transformation ecosystem.DiscussionFederated Learning and GPT-5 technologies advance international PHM by supporting HPO transformations. Standard personalised BM learning addresses intranational HPO variances, requiring individual classifications. National HPO roadmaps prioritise inclusiveness and stakeholder engagement, supported by informed consent and quantum intelligence. Ethical and equitable HPO deployment demands proactive stewardship and national cooperation to address limitations and ensure robust classifications.ConclusionUnified, data-driven HPO transformation utilising advanced AI and genomics is essential for personalised healthcare delivery. Rigorous assessments, ethical considerations, and global collaboration enable impactful implementation. National PHM ecosystems guided by HPO transformation in classifications sustain healthcare, advancing patient outcomes through responsible innovation and informed policy development.},
  archive      = {J_FRAI},
  author       = {Henry, James Andrew},
  doi          = {10.3389/frai.2025.1496935},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1496935},
  shortjournal = {Front. Artif. Intell.},
  title        = {Population health management of human phenotype ontology},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Navigating the AI revolution: Challenges and opportunities for integrating emerging technologies into knowledge management systems. systematic literature review. <em>FRAI</em>, <em>8</em>, 1664837. (<a href='https://doi.org/10.3389/frai.2025.1664837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating the AI revolution: challenges and opportunities for integrating emerging technologies into knowledge management systems. Systematic literature reviewTeona Gelashvili-LuikTeona Gelashvili-Luik1*Peeter VihmaPeeter Vihma1Ingrid PappelIngrid Pappel21Department of Software Science, Tallinn University of Technology, Tallinn, Estonia2Ragnar Nurkse Department of Innovation and Governance, Tallinn University of Technology, Tallinn, EstoniaIntroduction: Artificial intelligence (AI) is transforming organizational knowledge management (KM) by leveraging techniques such as machine learning, neural networks, and fuzzy logic to enhance knowledge discovery, capture, storage, and sharing. While this shift promises improved efficiency and personalization, it also poses challenges related to data quality, employee resistance, and alignment with existing workflows.Methods: This study presents a systematic literature review (SLR) of 40 peer-reviewed publications focused on the integration of AI in KM. The review follows PRISMA guidelines and includes thematic coding to identify patterns, critical success factors, and knowledge gaps.Results: Findings indicate that successful AI-enabled KM depends on strong leadership commitment, adaptable governance structures, and context-sensitive technology selection. AI’s role is evolving from supporting routine tasks to enabling dynamic, real-time knowledge flows. The review also highlights a critical need to balance automation with human oversight.Discussion: Key gaps were identified in understanding cost–benefit trade-offs, ethical implications, and governance mechanisms. These insights suggest directions for future research focused on practical, accountable, and empirically validated KM strategies. As part of an ongoing research project, the synthesized findings will inform the design of future empirical studies. The evidence suggests that, when strategically implemented, AI can serve as a competitive enabler in knowledge-driven organizations.1 IntroductionKnowledge Management (KM) has long been recognized as critical to organizational performance and long-term competitiveness (Harrington et al., 2019; Manesh et al., 2020; Foli, 2022). Contemporary KM extends beyond intra-firm activities to encompass regional and multi-stakeholder ecosystems, fostering innovation across diverse sectors (Weck et al., 2022; Muzzio and Gama, 2024). Recent research has expanded its focus to include organizations of various sizes, external knowledge flows, and broader geographic contexts (Shekhar and Valeri, 2023; Castagna et al., 2020).Knowledge Management Systems (KMS) form the technological and organizational infrastructure for capturing, storing, sharing, and applying knowledge. In the digital era, KMS convert dispersed data into actionable insights, enabling collaboration and innovation (Alavi and Leidner, 2001; Davenport and Prusak, 1998). The integration of artificial intelligence (AI), big data analytics, and cloud computing has further advanced these capabilities, helping organizations manage complexity and pursue strategic objectives (Jarrahi et al., 2023; Georgiev and Antonova, 2024). Nevertheless, many firms still struggle to realize the full potential of these technologies, highlighting a persistent research and practice gap (Herrero et al., 2016; Kaplan and Haenlein, 2019).The rise of Industry 4.0—the digital transformation of industrial processes—has further increased interest in the intersection of KM and emerging technologies (Li et al., 2019; Babkin et al., 2019). To remain competitive, organizations increasingly focus on knowledge lifecycle management, digital infrastructure, and human-centered strategies (Gupta et al., 2022).AI is playing a growing role in optimizing business processes and generating data-driven insights (Beheshti et al., 2021; Esposito et al., 2024). Applications such as data mining, predictive analytics, and supply chain optimization illustrate this trend (Mahmood, 2019; Khan and Vorley, 2017; Hashem et al., 2024; Torres-Dela Cruz et al., 2019). However, the broader strategic and organizational implications of AI integration into KM remain underexplored.While several systematic reviews have examined IT and AI impacts on KM (Al Mansoori et al., 2021; Ofosu-Ampong, 2024; Samuels, 2025), gaps remain regarding the specific technologies involved, their organizational consequences, and the implementation barriers encountered. This review seeks to address these gaps by synthesizing current literature on the integration of AI and emerging technologies into KMS, assessing their impact on KM practices, and identifying challenges and strategies for effective implementation.Accordingly, this study is guided by the following research questions:• RQ1: How do AI and emerging technologies impact organizational KM practices?• RQ2: What are the primary challenges in updating existing KM processes to match current trends?• RQ3: How can AI and emerging technologies be leveraged to address these challenges?To answer these questions, a Systematic Literature Review (SLR) methodology was employed, following established guidelines to ensure methodological rigor and minimize bias (Kitchenham, 2004). The SLR enables a structured synthesis of key trends, insights, and gaps across diverse scholarly sources.The article is structured as follows: Section 2 reviews KM development and identifies key research gaps; Section 3 outlines the methodology; Section 4 presents the findings and discussion; and Section 5 concludes with limitations and directions for future research.2 State of the artThis chapter reviews key developments in knowledge management research. It traces the field’s evolution from foundational concepts through the impacts of digitalization and AI, ending with a summary of literature gaps that motivate this study.2.1 Early discussions and principles of KM implementationOrganizational performance has long been a central focus in management research, emphasizing leadership (Bass and Riggio, 2005), organizational culture (Cameron and Quinn, 2011), and innovation adoption (Damanpour, 1998; Rogers, 2003; Pacheco and Paul, 2023). Knowledge management emerged as a critical factor for enhancing performance by managing information, knowledge, and experience to extend organizational capabilities (Nerney, 1997; Skyrme and Amidon, 1997; Mayo, 1998; Bassi, 1997).Early KM research identified key organizational and technical challenges in implementation (Lloyd, 1996; Davenport, 1997), emphasizing the importance of integrating human networks with technology. Davenport et al. (1998) highlighted several pillars of successful KM: operational foundations such as infrastructure and flexible knowledge structures; cultural facilitators including a knowledge-friendly environment and motivational practices; optimized knowledge flow through multiple transfer channels supported by leadership; and economic integration. Bennett and Gabriel (1999) further linked formal KM procedures to increased innovation, adaptability, and improved access to knowledge.From the 2000s onward, technological advances inspired research into digitalization’s impact on enterprise knowledge networks and lifecycle management (Vladova et al., 2018; Babkin et al., 2019). Open innovation perspectives expanded KM systems to incorporate emerging technologies like the Internet of Things (Santoro et al., 2018) and frameworks for organizational knowledge visualization were also proposed (Smuts and Scholtz, 2020). This progression reflects a shift from foundational KM concepts toward integrating innovation, digitalization, and organizational dynamics.2.2 Digitalization and human-centric approaches in modern KM researchDuring this time, knowledge management has developed in two main ways: advances in technology and a focus on people. Digital tools have changed organizational operations by enabling quicker decisions and supporting new ideas (Radavičius and Tvaronavičienė, 2022; Vladova et al., 2018). Using digital systems for knowledge management helps make workflows more efficient and can improve overall organizational results (Schäffer et al., 2021).At the same time, human-centered approaches focus on the role of people, social interactions, and organizational culture in creating, sharing, and using knowledge. Supporting ongoing learning that meets different employee needs is key to effective knowledge management (Viterouli et al., 2023; Castellani et al., 2021; McIver and Lepisto, 2017). Encouraging active knowledge sharing based on teamwork and human judgment plays an important part in fostering innovation (Muzzio and Gama, 2024). Social and relational aspects of knowledge transfer—which cannot be fully captured by digital tools—remain essential to success (Nguyen et al., 2023; Retkowsky et al., 2024). Sharing tacit knowledge through face-to-face interaction and communities of practice continues to support learning and innovation within organizations (Kamasak et al., 2017; Obembe and Obembe, 2020).Effective knowledge management combines technology with attention to people’s experience and insights. Digital tools help organize and share information efficiently, while human involvement is essential to capture the knowledge that cannot be easily documented. Balancing these aspects is important as organizations adopt new technologies without losing expertise held by their employees (Malik et al., 2021).2.3 Advancements in AI-driven knowledge managementRecent advances in artificial intelligence have led organizations to adopt more sophisticated technologies in knowledge management. Data mining methods—such as neural networks and decision trees—are now used to reveal hidden knowledge, improve forecasting, and support decision-making (Bandaru et al., 2017; Tsai, 2013; Natek and Zwilling, 2014). AI also enhances knowledge transfer and sharing, and contributes to building expert systems through machine learning and semantic technologies (Jia et al., 2012; Abubakar et al., 2019; Alonso et al., 2012; López-Cuadrado et al., 2012; Herrero et al., 2016).Research has expanded from focusing solely on organizational performance to also considering wider societal issues. Organizations increasingly acknowledge how digital knowledge management tools affect employee well-being, job performance, and access to knowledge (Babkin et al., 2019; Ferraris et al., 2017; Castellani et al., 2021). Recent studies examine human factors like trust, attitudes toward information technology, interpersonal behaviors, and leadership’s influence on knowledge sharing (Castellani et al., 2021). Additionally, research investigates how technology adoption impacts mental health and well-being, with organizational support, such as training and leadership, playing a moderating role (Nguyen et al., 2023). Sustainability has also become an important topic, with knowledge management framed as a strategy to secure and sustain competitive advantage (Gupta et al., 2022).2.4 Emerging trends in knowledge management researchThe evolution of knowledge management is reflected in academic research, with literature reviews adapting to new developments. Studies such as Inkinen (2016) and Radavičius and Tvaronavičienė (2022) have focused on KM digitalization, while others examine knowledge creation, transfer, and digital innovation (Smuts and Scholtz, 2020; Di Vaio et al., 2021). Research has also highlighted links between KM, digital transformation, and Industry 4.0 (De Bem Machado et al., 2022). Recent reviews have broadened their scope beyond technology to include human-centered topics, such as cognitive support (Li et al., 2019) and adult learning theories within organizational culture (Viterouli et al., 2023).Despite the extensive discussion on KM digitalization, integrating AI into traditional KM is still underexplored. Some scholars propose AI-focused KM frameworks that combine human and technological elements (Fteimi and Hopf, 2021), while others investigate KM challenges in remote and hybrid work environments (Taherdoost and Madanchian, 2023). However, research remains limited, and recent systematic literature reviews highlight the need for further research (Al Mansoori et al., 2021; Ofosu-Ampong, 2024).Many existing reviews examine these topics from a narrow angle, often relying on a single database. For example, Inkinen (2016) and Radavičius and Tvaronavičienė (2022) used Scopus, Li et al. (2019) used Web of Science, and Shekhar and Valeri (2023) and Al Mansoori et al. (2021) relied on ScienceDirect. While these databases are reputable, focusing on only one may miss relevant studies found elsewhere.This review aims to provide a thorough analysis of themes, concepts, and findings across the KM field by searching multiple databases and applying no restrictions on time, publication type, or source. This approach seeks to reduce the risk of overlooking important research.2.5 Theoretical foundations of knowledge managementThe empirical and technological advances discussed above are grounded in established theoretical frameworks that explain how knowledge is created, shared, and utilized within organizations. Understanding these foundational models is essential for interpreting the evolution of KM practices and the impact of emerging technologies.The evolution of knowledge management has been shaped by several influential theories. The SECI model (Nonaka and Takeuchi, 1995) conceptualizes knowledge creation as a dynamic process involving socialization, externalization, combination, and internalization, emphasizing the interplay between tacit and explicit knowledge. The Dynamic Capabilities Framework (Teece, 2007) highlights an organization’s ability to sense, seize, and reconfigure resources in response to change, positioning knowledge as a key dynamic asset. Furthermore, Distributed Cognition (Hutchins, 1995) and Organizational Learning (Argyris and Schön, 1978) focus from individual or centralized knowledge to systems where knowledge is constructed and enacted through ongoing interaction among people and technologies. These frameworks provide a lens for analyzing how successive technological paradigms in KM (from expert systems to generative AI) reflect changing assumptions about how knowledge is created, shared, and leveraged in organizations.3 Methodological applicationsThis systematic literature review (SLR) follows established guidelines from Kitchenham (2004) and Webster and Watson (2002), ensuring transparency, rigor, and reproducibility. The review process included: (1) formulation of research questions, (2) development of a comprehensive search strategy, (3) application of predefined inclusion and exclusion criteria, (4) data extraction, and (5) thematic synthesis. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework (Liberati et al., 2009) guided the reporting of the study selection process.3.1 Search strategy and resourcesSearch terms were developed in direct alignment with the research questions and study objectives. To ensure comprehensive coverage, the search strategy incorporated a broad set of keywords and their commonly used synonyms, including variations in terminology used across disciplines. This approach was designed to reduce the risk of omitting relevant studies that may use different descriptors for knowledge management, artificial intelligence, or related emerging technologies. The search string was refined through an iterative process involving preliminary testing and adjustment, ensuring both sensitivity and specificity in capturing pertinent literature. Boolean operators (AND, OR, NOT) were applied to structure the search logic and to connect key concepts effectively. The final search string used was: (“knowledge management technology” OR “knowledge management tools” OR “knowledge management processes”) AND (“intelligent systems” OR “emerging technologies” OR “digitalization” OR “artificial intelligence”) AND “organization” AND (“adoption” OR “drivers” OR “strategies” OR “challenges” OR “success factors”) AND “innovation” NOT (“public sector” OR “government”).To maximize coverage and minimize bias, we searched four major academic databases: Scopus, Web of Science, ScienceDirect, and Google Scholar. No restrictions were applied regarding publication date, type, or language. Reference lists of selected papers were manually screened to capture additional relevant studies. Where direct export was not possible (e.g., Google Scholar), bibliographic details were manually entered into a master spreadsheet.3.2 Study selectionThe PICOS framework, which is widely recognized for structuring eligibility criteria in systematic reviews (Higgins and Green, 2011; Schardt et al., 2007), informed inclusion and exclusion criteria:• Population: Organizations using or implementing KM systems• Intervention: AI, digitalization, or emerging technologies applied to KM• Comparison: Traditional KM or alternate technological approaches (where applicable)• Outcomes: Impact on KM processes, organizational challenges, and strategic responses• Study Design: Empirical studies, SLRs, and theoretical papers published in peer-reviewed journals or conferencesStudy selection proceeded in two phases: (1) screening of titles and abstracts, and (2) full-text assessment. Inclusion and exclusion criteria are summarized in Table 1.3.3 Data analysis and quality assessmentA total of 1,568 records were identified through searches in Scopus (266), Web of Science (21), Google Scholar (1100), ScienceDirect (169), and additional manual searches (12). After removing duplicates, identified based on matching titles, authors, and publication years, 1,555 records remained. The screening process involved two stages: initial title and abstract screening, which reduced the pool to 337 records, followed by a full-text review based on predefined eligibility criteria. Ultimately, 40 studies are included in the review. The detailed selection process is illustrated in the PRISMA flow diagram (Figure 1).The selected articles were subjected to thematic analysis following the approach outlined by Nowell et al. (2017). During the coding phase, key concepts and findings relevant to the research questions were identified and organized into categories. These categories were then synthesized into overarching themes reflecting the impact of AI and emerging technologies on knowledge management practices, associated challenges, and strategic responses. The inclusion of studies from diverse geographic regions, publication years, and disciplinary perspectives helped mitigate potential biases related to narrow focus or source reliance.Study quality was assessed using a customized matrix based on the CASP checklists (Critical Appraisal Skills Programme, 2018) and adapted for mixed-methods studies. The matrix included seven criteria as presented on the Table 2, each scored on a 0–2 scale (2 = fully met; 1 = partially met; 0 = not met). Studies were classified as high (scores of 12–14), medium (8–11), or low quality (0–7), using thresholds informed by CASP-based scoring approaches and the Mixed Methods Appraisal Tool (MMAT) framework (Hong et al., 2019).Quality assessment was conducted in accordance with the predefined criteria outlined in the quality assessment matrix. Based on these criteria, 80% of the studies were rated as high quality, 15% as medium quality, and 5% as low quality (for quality scores for each study see Supplementary Appendix B). The final selection of studies included in the review was reached by consensus among all authors.Studies rated as relatively low quality (overall score of 7) were early-stage conceptual papers. While these studies are vital for understanding the development of the field, the primary analysis and outcomes presented in the following chapters are based on the high-quality publications.3.4 Methodological limitationsThis review only includes peer-reviewed, published literature in English, which may introduce publication and language bias. Although multiple databases were searched, some relevant studies may have been missed due to terminology variation or manual data entry errors.The search string was designed to capture a broad spectrum of relevant studies. However, its complexity may have inadvertently excluded articles using alternative or less common terms. Balancing comprehensiveness and precision in search strategies remains an inherent challenge in systematic reviews.Screening, coding, and thematic analysis involve elements of subjective judgment. While clear criteria and established methods were applied to minimize bias, some degree of interpretive subjectivity is unavoidable. The heterogeneity in study designs, contexts, and methodologies among the included articles may also influence the comparability and generalizability of the findings.4 Results and discussionThis chapter addresses research questions, with each sub-section focused on a specific question. Table 3 provides a summary of the main technology categories and their contributions to knowledge management, based on the 40 studies included in this review (for detailed study-level information see Supplementary Appendix A). Following the summary, a more in-depth analysis of the publications is presented, exploring each AI or emerging technology and its associated research area within knowledge management.4.1 AI and emerging technologies impact on organizational KM practicesThis sub-section answers the first research question by analyzing how artificial intelligence and emerging technologies are changing core knowledge management functions. To explore this transformation of how knowledge is created, distributed, and applied within organizations, the section is divided into thematic sub-categories, each focused on a distinct technological domain.4.1.1 Data science and analyticsThe rapid growth of organizational data presents both strategic opportunities and operational challenges. Big Data Analytics (BDA) provides powerful tools to process this data, but without mechanisms to convert it into actionable knowledge, its strategic value remains limited (Rialti et al., 2020). Knowledge management serves as a critical bridge between data and decision-making, ensuring that insights translate into informed organizational decisions. Artificial intelligence and machine learning are central to this process. Automated data mining and real-time extraction tools support the generation of knowledge in action. For example, Finogeev et al. (2017) demonstrate how AI, integrated with distributed computing infrastructures such as cloud and fog systems, processes sensor data in real time to support operational decisions. Likewise, Ristoski and Paulheim (2016) show how Semantic Web technologies connect heterogeneous datasets to create integrated, context-aware knowledge systems.Data science reshapes each phase of the KM lifecycle. In creation, machine learning uncovers patterns that would be difficult for humans to detect (Nguyen et al., 2014). For storage and retrieval, semantic technologies and classification algorithms enhance organization and accessibility. Knowledge sharing is becoming personalized through analytics that tailor content to user needs, while application is supported by dashboards and predictive models embedded directly into workflows. More than enhancing each KM phase, BDA reconfigures the entire process. Rather than a linear sequence—create, store, share, apply—KM becomes a dynamic feedback loop. Knowledge is treated as provisional, continuously updated based on new data. This recursive model allows past applications to inform future knowledge through real-time monitoring and learning mechanisms.One forward-looking approach is Knowledge-Driven Optimization (KDO), which uses knowledge generated during processes to improve future performance (Bandaru et al., 2017). This supports adaptive, self-correcting systems. It reflects a shift from knowledge-as-asset—a static, codified resource—to knowledge-as-flow, where value lies in relevance and responsiveness. In this flow-based KM model, knowledge is continuously generated, revised, and embedded in real-time interactions among systems, algorithms, and decision environments.This shift challenges traditional frameworks such as Nonaka and Takeuchi (1995) SECI model, which emphasizes human-centric knowledge creation, particularly through socialization and tacit knowledge exchange. In contrast, flow-based KM repositions the human actor as peripheral, privileging algorithmic pattern recognition and system-level feedback. While SECI views knowledge as emerging through reflection and conversion, flow-based KM treats it as emergent, iterative, and embedded in automated systems.This transformation also introduces significant governance challenges. When knowledge is continuously evolving, how can organizations ensure its trustworthiness, accuracy, and accountability? Algorithmic decision-making often obscures the origin and rationale behind knowledge outputs, raising both technical and epistemological concerns. Consequently, KM must now incorporate real-time processes for curating, validating, and explaining knowledge.AI, data science, and analytics extend beyond operational functions to challenge traditional assumptions about knowledge itself. Is knowledge objective and stable, or inherently dynamic and distributed? While these questions warrant further exploration, these technologies clearly elevate knowledge as a strategic organizational asset. They facilitate real-time insights, tailor knowledge flows to individual needs, and embed intelligence directly into processes, while simultaneously demanding new approaches to knowledge governance and understanding.4.1.2 Computational intelligenceComputational Intelligence (CI), which includes neural networks, fuzzy logic, and evolutionary algorithms, supports knowledge management by allowing systems to learn from data, adjust to new information, and function in uncertain conditions. In contrast to traditional AI approaches that rely on predefined rules, CI is better equipped to address the complexity and ambiguity often present in organizational knowledge systems.A key contribution of Computational Intelligence in knowledge management is its alignment with the Dynamic Capabilities Framework. This framework outlines three core capabilities necessary for organizations operating in uncertain environments: sensing opportunities and threats, learning from experience, and responding effectively (Teece, 2007). CI techniques support sensing by analyzing diverse and incomplete data to identify relevant patterns; they enable learning through the iterative refinement of knowledge models; and they support response by integrating decision-making tools into organizational processes. In this way, CI helps shift KM from a primarily static repository function toward a more adaptive, real-time process of organizational learning and informed action.Herrero et al. (2016) illustrate this shift with their Hybrid Artificial Intelligence System (HAIS), which identifies KM weaknesses and generates adaptive insights, supporting flexible and ongoing KM assessment. Similarly, Delen et al. (2013) emphasize how CI enhances knowledge utilization by learning from user behavior to recommend contextually relevant content, ensuring timely and effective application within daily decision-making.CI supports the integration of fragmented and tacit knowledge across organizational functions. For example, Grzeszczyk (2021) presents a fuzzy logic framework for processing unstructured documents, illustrating how CI can enable automated knowledge extraction and targeted dissemination. Such approaches support more adaptive and flexible knowledge management systems, moving beyond static repositories and enabling real-time responsiveness to evolving informational needs.Collectively, these developments suggest that CI extends the Dynamic Capabilities Framework by making knowledge itself a continuously evolving capability—one that is sensed, learned, and enacted in real time through intelligent systems embedded within organizational processes. However, the adoption of CI in KM presents challenges. Issues such as algorithmic interpretability, bias in training data, data quality, and lack of transparency can undermine trust and accountability. These risks highlight the need for governance structures to ensure ethical, explainable, and responsible CI use in KM, balancing technological potential with critical oversight.4.1.3 From expert systems to AI assistantsThe development of artificial intelligence in knowledge management reflects a shift from static, rule-based systems toward more flexible and adaptive approaches. Early KM technologies operated on fixed logic and emphasized codified knowledge, whereas current AI-enabled systems support more personalized access, the use of tacit knowledge, and decisions that respond to contextual nuances. This section introduces a four-stage framework that outlines how successive waves of AI technologies have shaped and redefined KM practices over time.4.1.3.1 Stage 1. Rule-based expert systems (1980s–1990s)Expert systems relied on explicitly coded “if–then” rules to simulate expert-level decision-making within defined domains (Liebowitz, 2001). These systems supported basic automation and were effective in environments where knowledge could be clearly articulated and structured. However, they lacked adaptability and were unable to deal with uncertainty, change, or the nuanced, tacit knowledge that characterizes many organizational processes. As a result, their applicability remained narrow and domain-specific.4.1.3.2 Stage 2. Ontology-driven and NLP-enabled KM (2000s)The early 2000s introduced systems that integrated ontologies and natural language processing to enable more sophisticated, user-friendly knowledge retrieval. Platforms such as h-TechSight (Stollberg et al., 2004) reflected a move toward semantic KM, improving flexibility in categorizing and accessing knowledge assets. While these systems enhanced the organization and discoverability of knowledge, they still relied on largely static architectures with limited capacity for real-time learning or adaptation.4.1.3.3 Stage 3. Predictive and adaptive KM systems (2010s)Advancements in machine learning, big data analytics, and user modeling enabled KM platforms to become more predictive and adaptive. These systems could analyze behavior patterns, infer user intent, and deliver personalized knowledge recommendations. As Delen et al. (2013) noted, even sophisticated infrastructures fail if knowledge is not usable. Predictive systems helped overcome this by contextualizing content and enhancing knowledge applicability. The adaptive nature of these systems made them increasingly valuable in dynamic environments, where relevance and timeliness are essential.4.1.3.4 Stage 4. Interactive and generative KM systems (2020s)The current generation of KM technologies is characterized by real-time, interactive platforms operated by conversational and generative AI. Tools such as ChatGPT and IBM Watson engage users in natural language dialog, facilitate the extraction of tacit insights, and support collaborative knowledge creation (Retkowsky et al., 2024). These systems embed knowledge directly into workflows, reduce users’ cognitive load, and promote sensemaking across organizational contexts. Their capacity to learn from interaction and adapt to context reflects a major shift toward human–AI co-production of knowledge.As outlined in the State of the Art (Section 2.5), these technological shifts reflect evolving theoretical perspectives in KM. Table 4 presents a summary of each stage’s technological paradigm, knowledge focus, and organizational role, building on these foundational frameworks. This theoretical progression highlights how the dominant knowledge focus and organizational impact have evolved alongside underlying KM theories.4.2 Primary challenges in updating existing KM processesThis next part answers second research question by examining the challenges preventing organizations from effectively updating their KM processes in response to emerging AI technologies. Instead of treating these challenges as separate issues, the analysis highlights how technical constraints, organizational resistance, and poor strategic alignment often interact and reinforce one another.4.2.1 Data quality and integrationThe increase in organizational data volume and diversity places considerable pressure on KM systems and exposes critical vulnerabilities in data quality, consistency, and integration. While heterogeneous data sources ranging from structured databases to unstructured social media content offer rich knowledge potential, they simultaneously complicate seamless knowledge flow (Kawonga et al., 2023; Ristoski and Paulheim, 2016). This fragmentation complicates the process of turning raw data into practical knowledge, increasing the risk of inefficiency and poor strategic coordination. Therefore, the growth in data volume might become a liability instead of an asset. As data volumes increase, it often becomes more difficult to maintain clarity and practical usability, which can hinder effective interpretation and decision-making. This highlights the importance of determining whether there is a practical limit to the amount of data that can meaningfully contribute to insight before it leads to information overload or misalignment.Legacy IT systems often reinforce data silos, where knowledge remains locked within departments or platforms, making it difficult to access or reuse across the organization (Kawonga et al., 2023). This fragmentation limits the ability of AI-driven KM tools to deliver value, as these tools depend on integrated, high-quality data to function effectively. Efforts to improve interoperability, such as using Semantic Web technologies like Linked Open Data (LOD), offer potential solutions, but their practical application faces significant barriers. In many cases, organizations rely too heavily on a few central knowledge bases, limiting coverage and relevance. Additionally, inconsistent standards and uneven adoption across systems reduce the benefits of these technologies (Ristoski and Paulheim, 2016). This reflects on a critical challenge in knowledge management when new tools are often introduced without fully addressing the constraints of the existing IT environment. It can leading to partial solutions that fail to scale and result in an ongoing tension between technological ambition and infrastructural capacity.The high speed and diverse formats of big data present challenges for maintaining quality throughout the knowledge discovery process (Safhi et al., 2019). In practice, organizations often struggle to validate, clean, and standardize incoming data quickly enough for it to be useful. Choosing the right analytics tools is not just a technical matter, it directly affects how well knowledge can be extracted and applied. Poorly chosen frameworks or weak sensor data management can lead to processing errors, misinterpretations, and unreliable outputs (Kawonga et al., 2023; Finogeev et al., 2017). If these issues are not resolved, they affect the entire knowledge management system by reducing the reliability and relevance of the insights produced. In this context, data quality and integration are not just technical concerns but directly influence the trustworthiness and timeliness of decisions.4.2.2 Organizational and human factorsTechnological upgrades to KM systems often encounter friction coming from human and organizational dynamics. Resistance toward AI-based tools is often caused by fears of job displacement and skepticism toward automation which reveals deeper cultural and psychological barriers to change (Herrero et al., 2016; Lei, 2022). This resistance slows adoption and hinders organizations from successfully applying KM to support learning, knowledge exchange, and innovation.A misalignment between an organization’s knowledge management maturity and the complexity of new technologies can further complicate the adoption process (Herrero et al., 2016). Without a clear assessment of organizational readiness and a tailored change management approach, implementations are more likely to underperform or fail. Gaps in digital literacy and limited training opportunities may hinder user engagement and reduce the effective use of new technologies, adding to these challenges (Miradi et al., 2009; Obembe and Obembe, 2020).Tacit knowledge capture which is embedded in individual experience and to codify it remains one of the most persistent challenges in knowledge management. AI-enabled tools, such as natural language processing systems or conversational agent, offer potential solutions, but their success depends heavily on user trust, participation, and alignment with organizational culture (Obembe and Obembe, 2020). One-size-fits-all KM strategies often overlook sector-specific and cultural variations, leading to uneven adoption and ineffective knowledge sharing (Delen et al., 2013).For organizations aiming to improve their readiness for knowledge management initiatives, it is important to evaluate cultural absorption capacity alongside technological infrastructure and financial resources. Human factors, such as attitudes toward change, openness to collaboration, and engagement with new systems, should not be viewed merely as barriers. Instead, they represent key enablers that can significantly influence the long-term effectiveness and adaptability of KM efforts.4.2.3 Organizational size and resource constraintsOrganizational size, its structural capacity and resource availability influences the implementation and outcomes of knowledge management initiatives. Larger organizations, including multinational corporations (MNCs), often operate with complex hierarchies, departmental segmentation, and legacy information systems that inhibit efficient knowledge flow (Harrington et al., 2019). In such contexts, KM interventions typically require formal governance structures and comprehensive technical frameworks to ensure integration across divisions and geographies. In contrast, small and medium-sized enterprises (SMEs) may benefit from flatter organizational structures and more flexible decision-making processes, which can facilitate the adoption of KM practices (Kianto et al., 2018; Harrington et al., 2019). However, SMEs frequently face limitations in digital infrastructure, technical expertise, and financial capacity, which restrict their ability to implement and sustain advanced AI-based KM systems as well as their long-term maintenance and user-training (Wielgórka, 2023).Given these differences, KM strategies must be adapted to organizational scale and resource profiles. In larger firms, the emphasis lies in system interoperability, data governance, and cross-functional alignment. In smaller firms, effective KM requires low-cost, user-friendly tools that do not exceed existing operational capacity. A uniform approach to AI integration across organizations of varying size is therefore unlikely to produce equitable outcomes.4.2.4 Governance and ethical concernsAs AI and big data become more central to knowledge management systems, questions of governance and ethics become core concerns. One of the main challenges is the lack of transparency in how AI systems make decisions. When algorithms produce results that users cannot explain or understand, it becomes difficult to trust the system (Safadi and Watson, 2023). Without clear rules for how data is used, and decisions are made, people’s resistance in adopting increases which in the end limits tools’ usefulness in knowledge management.In addition to trust, legal and ethical risks must be considered. Organizations are responsible for protecting sensitive data, complying with regulations, and ensuring that data is not misused (Schäffer et al., 2021; Leoni et al., 2022). A failure to do so can result in more than legal fines, it can lead to reputational damage, employee resistance, or even financial losses. Strong governance structures must therefore go beyond compliance and promote a shared understanding of ethical data use across the organization.What complicates these challenges further is the rapid pace of technological innovation. Emerging tools frequently introduce capabilities that existing governance models were not designed to address. In many cases, ethical shortcomings arise not from deliberate misconduct but from outdated policies or ambiguous accountability structures. This emphasizes a critical issue: whether static governance frameworks remain adequate in contexts where technologies evolve continuously. There is a growing need to consider whether governance mechanisms themselves must become more dynamic and responsive, capable of evolving in parallel with the tools and risks they aim to regulate.If governance is to become adaptive, it raises questions regarding the assignment of responsibility. Determining who is accountable for updating governance frameworks and ensuring the ethical and transparent use of new technologies is essential. In the absence of clearly defined roles and processes, oversight risks becoming fragmented, inconsistent, or altogether overlooked. Thus, governance should not be viewed merely as a compliance function, but as a continuous, distributed responsibility that shapes how knowledge management systems are implemented, trusted, and sustained within organizational contexts.4.2.5 Technological complexity, scalability and integrating KM approachesIntegrating AI and big data tools into knowledge management is rarely straightforward. Many existing KM systems were built around traditional methods focused on storing and retrieving explicit knowledge, rather than handling the volume and speed of new data sources or supporting AI-driven analysis (Rialti et al., 2020; Sumbal et al., 2021). Updating these systems involves complex technical choices about architecture, data infrastructure, and ongoing maintenance that directly affect how reliable and usable the KM system is day-to-day (Kawonga et al., 2023).A common issue is that organizations often treat traditional KM processes and emerging AI-driven methods as separate, which limits their ability to combine the strengths of both (Rialti et al., 2020; Sumbal et al., 2021). Traditional KM usually follows linear steps of capturing, storing, and sharing explicit knowledge while big data analytics works through iterative, exploratory processes aimed at discovering patterns and creating knowledge in real time (Sumbal et al., 2021). This difference means organizations need integrative frameworks that balance the steady, controlled flow of traditional KM with the flexible, dynamic nature of AI-based knowledge discovery.The ability to implement and scale these complex solutions varies widely. Large organizations typically have the technical expertise and resources to adapt and expand AI-enhanced KM systems. Smaller or less digitally mature organizations often lack these resources, leading to a “scalability gap” where some firms move forward while others lag behind, potentially increasing inequality in knowledge capabilities for (Shaqrah and Alzighaibi, 2023; Abualoush, 2025).This gap makes it essential the KM tools to be designed for different organizational contexts. For example, machine learning algorithms can speed up data mining and knowledge creation (Nguyen et al., 2014), but their effectiveness depends on how well they are adapted to the specific context highlighting that automation cannot fully replace human judgment or domain expertise.Addressing technological complexity and scalability goes beyond technical fixes. It requires organizations to rethink how they integrate traditional KM and AI-driven approaches, and to plan for different levels of capacity and maturity. Failing to do so risks fragmented knowledge flows, underused data assets, and missed out innovation opportunities.4.2.6 Technological complexity, scalability and integrating KM approachesTo better understand the interdependencies highlighted in the previous sections shaping AI-enabled knowledge management systems, this study incorporates a Causal Loop Diagram (CLD) (see Figure 2). The CLD visualizes the dynamic feedback relationships among key technological, human, organizational, and governance variables that influence the performance, scalability, and sustainability of KM initiatives. It maps elements such as data quality, legacy IT systems, resistance to change, AI adoption, trust, digital literacy, and governance capacity, showing how these interact through reinforcing and balancing feedback loops.At its core, the model reveals several critical systemic dynamics:• The Data Chaos Loop (R1) illustrates how rapidly increasing data volume and heterogeneity—when inadequately integrated—can erode data quality. This in turn weakens AI tool performance and KM effectiveness, leading to misinterpretation of outputs, organizational distrust, and resistance. These responses further hinder data integration, perpetuating a self-reinforcing negative cycle.• The Governance Stabilizer Loop (B1) shows how effective governance frameworks and ethical oversight enhance user trust in AI, encouraging adoption and improving system reliability. Greater confidence reduces resistance and the need for reactive governance changes, creating a stabilizing feedback mechanism.• The Resistance Spiral Loop (R2) captures how fears around job displacement and skepticism toward automation intensify resistance to AI-KM initiatives. Reduced engagement limits the capture of tacit knowledge and adaptability, further compounding resistance in a downward spiral.• The Training & Engagement Loop (B2) offers a counterbalancing dynamic, where investment in digital literacy and user training increases engagement, enhances trust, and improves the effectiveness of KM tools, especially those reliant on tacit knowledge inputs.• The Capability-Scalability Loop (R3) highlights systemic disparities. Larger or more digitally mature organizations can dedicate greater resources to integration, training, and innovation, accelerating AI-KM benefits. However, this widens the capability gap between firms, reinforcing structural inequality.• The Complexity Trap Loop (R4) underscores how increasing technological complexity, when poorly managed, leads to fragmented knowledge flows, reduced usability, and rising demand for new tools. Without strategic alignment, this leads to further complexity in a vicious cycle.To clarify these interactions and identify leverage points, the CLD organizes variables into four subsystems:• Technical Dynamics: Data quality, integration, and system complexity• Human Dynamics: Resistance, training, and tacit knowledge engagement• Organizational Structure: Size, resource availability, and digital maturity• Governance & Strategic Alignment: Trust, ethics, and policy responsivenessThis systems-based perspective helps explain why isolated interventions, whether technical upgrades or training initiatives, often fail without coordinated attention to broader feedback dynamics. By identifying key loops and leverage points, the CLD provides a practical framework for designing more adaptive, equitable, and resilient AI-enabled KM strategies.4.3 Leveraging AI and emerging technologies to address imposed challengesThis section of the chapter addresses the third research question by critically examining how organizations can leverage AI and emerging technologies to overcome the challenges identified in updating KM processes. The analysis highlights both technological solutions and socio-organizational dynamics and concludes with a practical implementation roadmap.4.3.1 Data and knowledge management strategiesEffectively managing large volumes of organizational knowledge depends on tools that go beyond manual or traditional information systems. Automated data processing such as categorization algorithms and filtering techniques plays a critical role in ensuring that relevant and timely information reaches decision-makers. Vladova et al. (2018) and Wielgórka (2023) emphasize that such automation supports more efficient identification of information gaps, helping organizations act on incomplete or overlooked knowledge. However, these systems primarily address explicit knowledge. Capturing tacit knowledge which is rooted in employee experience and often difficult to articulate remains a significant challenge. According to Schäffer et al. (2021), AI-based extraction tools and collaborative digital platforms can support the articulation of experiential knowledge by facilitating interaction, reflection, and annotation.4.3.2 Organizational and cultural interventionsOrganizational culture can either support or hinder knowledge management (KM) transformation. Kianto et al. (2018) emphasize that trust and open communication are essential for reducing knowledge silos and encouraging collaboration across teams. While AI-based tools such as cross-functional collaboration platforms or network analysis algorithms can help surface hidden knowledge flows and support interaction across units, they cannot replace the need for planned, organization-specific efforts to shift cultural norms around sharing and learning. Practical challenges, including geographically dispersed teams, language barriers, and differences in local practices (Harrington et al., 2019; Gupta et al., 2022), require flexible approaches to knowledge adaptation and localization. Addressing these issues highlights the need to align technological solutions with human and contextual factors, rather than treating culture as an afterthought in KM initiatives.4.3.3 Leadership and workforce developmentLeadership plays a critical role in integrating AI into knowledge management. Studies by Castellani et al. (2021) and Chang et al. (2017) highlight that transformational and ethical leadership help build a culture of knowledge sharing and reduce resistance to new technologies. The introduction of AI tools such as ChatGPT brings new challenges: excessive reliance on these tools may lead to skill loss among employees, while a lack of proper oversight can compromise the quality of knowledge produced (Retkowsky et al., 2024). Addressing these issues requires ongoing training and adjustments in job roles that combine human expertise with AI support. Therefore, leadership development initiatives should focus on fostering ethical decision-making and transparency to ensure responsible and effective use of AI in knowledge management.4.3.4 Technological solutions and AI integrationBuilding on the importance of leadership and workforce development, effective integration of AI technologies is essential to realize improvements in knowledge management. AI can streamline routine tasks, tailor knowledge delivery to users’ needs, and support real-time collaboration across teams. For example, Lei (2022) shows how cognitive computing can enhance knowledge transfer by identifying collaboration barriers, while Retkowsky et al. (2024) find that AI assistants improve information retrieval and help generate content efficiently. However, these benefits rely heavily on selecting appropriate tools, aligning AI capabilities with existing workflows, and ensuring systems can work together smoothly (Kawonga et al., 2023). To manage these complexities, organizations should implement AI solutions gradually and iteratively, allowing time to adjust processes and minimize operational disruption. Ultimately, the technical sophistication of AI tools must be balanced with flexible, adaptable processes to achieve meaningful gains in knowledge management.Yet the effectiveness of such integration depends not only on internal readiness but also on the sectoral context shaping how AI and KM converge. In healthcare, for instance, Torres-Dela Cruz et al. (2019) describe how AI supports clinical decision-making by dynamically managing patient knowledge, though always under human supervision due to ethical and contextual considerations. By contrast, in energy-intensive manufacturing, Sanders et al. (2019) observe a more autonomous model, where AI-driven systems embedded with real-time sensing technologies optimize operational processes with minimal human input. These divergent patterns illustrate that AI–KM integration is not uniform: the degree of automation, the locus of decision-making, and the role of human expertise all shift according to domain-specific imperatives. Retkowsky et al. (2024) further complicate this picture by showing how generative AI tools are integrated bottom-up in office-based environments, reshaping individual workflows without formalizing KM processes at the organizational level. These variations highlight that realizing the benefits of AI in KM is not only a matter of tool selection or implementation strategy, but also of aligning technological possibilities with the epistemic and operational logic of the domain in which they are deployed.4.3.5 Ethical governance and sustainable KMEthical governance becomes essential as AI keeps re-shaping KM systems. Schäffer et al. (2021) and Leoni et al. (2022) highlight the importance of frameworks that promote transparency, fairness, and accountability to maintain trust among users and stakeholders. Protecting data privacy is a fundamental requirement. Algorithmic transparency allows stakeholders to audit AI decision-making, helping to uncover and address hidden biases (Safadi and Watson, 2023), while ongoing human oversight is necessary to ensure accountability in critical decision. Without these safeguards, organizations risk reputational damage and operational harm.A forward-looking KM strategy integrates continuous learning and adaptability, recognizing that technological innovation alone cannot drive transformation (Retkowsky et al., 2024). The organizations to succeed must combine advanced data capabilities, organizational change management, leadership commitment, and ethical governance. They should balance automation with human expertise, appreciating that effective KM is as much about people and culture as it is about technology. This integrative approach positions organizations to build KM systems that are effective, accountable, and resilient during an ongoing technological and environmental shift.Building on the analysis above, the following roadmap (see Figure 3) translates these findings into a structured, phased implementation plan. Each phase addresses core challenges identified in knowledge strategy, infrastructure, culture, leadership, governance, and continuous improvement. The roadmap reflects both technical and human dimensions of AI-enhanced KM, offering a practical guide for organizations to navigate transformation with clarity and accountability.This phased roadmap provides a practical structure for organizations to implement AI-enhanced KM in a manageable and adaptive way. Grounded in both technical feasibility and organizational readiness, it offers flexibility for sector-specific challenges while maintaining a consistent focus on strategic alignment, ethical governance, and continuous learning.4.4 Theoretical contribution and propositionsThis section introduces a conceptual framework based on the earlier analysis of how AI and emerging technologies influence organizational knowledge management. The framework integrates five core dimensions: technological drivers, KM processes, implementation challenges, strategic organizational responses, and anticipated outcomes. It positions AI as a transformative input that reshapes KM activities such as knowledge discovery, capture, sharing, and application, while emphasizing the sociotechnical factors that moderate this transformation.The following propositions operationalize this framework, translating its dimensions into empirically testable or practically actionable statements. Specifically, Propositions 1 and 2 address the technological drivers and data-related challenges depicted in the model. Propositions 3 and 4 correspond to the human and governance barriers, highlighting organizational culture and ethical oversight. Finally, Propositions 5 and 6 focus on strategic responses and structural adaptations that organizations can leverage to overcome these challenges, such as scalable AI solutions and hybrid knowledge management architectures. Figure 4 visually summarizes the framework, offering a reference point for researchers and practitioners seeking to design, implement, or evaluate AI-enabled KM strategies.Proposition 1: Organizations with a culture open to innovation, strong real-time data capabilities, and mature digital infrastructure can use AI to turn static knowledge into a dynamic, evolving resource—making them more responsive and agile.Proposition 2: When data is poor, systems are fragmented, and information comes in fast and varied forms, AI struggles to deliver useful insights. However, investing in data quality and system integration can significantly improve decision-making.Proposition 3: If employees distrust AI, fear job loss, or lack digital skills (and the culture does not support change) AI-based KM systems are unlikely to succeed. Overcoming this requires targeted training and cultural support to encourage adoption.Proposition 4: Transparent and inclusive AI governance within KM helps prevent bias, protect privacy, and avoid reputational harm. This builds trust and encourages long-term, responsible use of AI in organizations.Proposition 5: When AI tools are scalable, easy to use, and fit specific industry needs, even smaller or less-resourced firms can benefit, if they also invest in digital skills, change readiness, and external support.Proposition 6: Blending traditional KM methods, like communities of practice, with AI tools such as machine learning and NLP creates a hybrid system. This supports both structured and experience-based knowledge sharing—especially in a collaborative learning culture.5 Conclusion and future workThe evolving relationship between organizational knowledge and technological innovation is reshaping the field of knowledge management. This systematic review has critically examined how AI and related technologies are influencing KM practices, drawing on evidence from 40 studies. The findings indicate that while AI enhances core KM activities including knowledge discovery, capture, sharing, and application, it also introduces new modes of collaboration, personalization, and decision support. However, the review also highlights that the integration of AI into KM is not straightforward. Significant challenges persist, including managing data quality and integration, overcoming organizational and human barriers, navigating governance and ethical complexities, and aligning emerging technologies with existing KM practices. These challenges can substantially limit the realization of AI’s potential benefits in organizational contexts. Addressing these barriers requires a multidimensional strategy: rigorous data management, attention to organizational culture and leadership, investment in workforce development, careful technology selection, and the implementation of robust ethical and governance frameworks. The conceptual framework proposed in this review (see Figure 4) offers an initial roadmap, though it requires further empirical validation.Notably, the findings caution against viewing AI as a substitute for human expertise or established KM approaches. Instead, AI should be seen as a complement to human judgment, one that, when integrated thoughtfully, can strengthen organizational learning and adaptability. Ethical concerns, particularly around data privacy, algorithmic accountability, and human oversight, must remain central to both research and practice if AI-enabled KM is to advance in responsible and sustainable ways. This review is not without limitations. Its reliance on published literature may introduce selection bias and potentially overlooks emerging or practice-based innovations. Moreover, the diversity of organizational contexts and AI applications limits the generalizability of some findings.To advance understanding in this area, future research should focus on several key topics identified in this review: First, as this study shows, knowledge management is evolving alongside how advanced systems access and process information in real time. Future research should examine knowledge flow models that balance real-time knowledge creation, validation, and application within operational settings. Second, the analysis highlighted the need for ethical governance frameworks that are flexible and continuously evolving to ensure responsible AI-KM practices. A key question to explore would be: how can organizations develop adaptive governance models that clearly define accountability and keep pace with rapidly changing technologies to provide ethical, transparent, and effective oversight? Third, there is a lack of research on the measurable costs and benefits of AI-enabled knowledge management, including investment needs and return on investment (ROI). Future studies should analyze these financial aspects by examining productivity, decision-making speed, and innovation outcomes.Methodologically, these future studies should adopt mixed methods approaches that combine qualitative depth (e.g., case studies in diverse sectors, in-depth interviews) with quantitative validation (e.g., system analytics, performance metrics) and design science (model development and testing).Together, these directions aim to deepen practical and theoretical understanding of AI-enabled knowledge management, guiding organizations toward more effective, responsible and sustainable implementations.},
  archive      = {J_FRAI},
  author       = {Gelashvili-Luik, Teona and Vihma, Peeter and Pappel, Ingrid},
  doi          = {10.3389/frai.2025.1664837},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1664837},
  shortjournal = {Front. Artif. Intell.},
  title        = {Correction: Navigating the AI revolution: Challenges and opportunities for integrating emerging technologies into knowledge management systems. systematic literature review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: AI in digital oncology: Imaging and wearable technology for cancer detection and management. <em>FRAI</em>, <em>8</em>, 1662971. (<a href='https://doi.org/10.3389/frai.2025.1662971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI Applications in Gastrointestinal Cancers: Akbari et al. provide a comprehensive review of AI applications across esophageal, gastric, hepatocellular, colorectal, and pancreatic cancers 2 . Their analysis reveals ML models achieved on average 89% accuracy in analyzing endoscopic and CT images, with convolutional neural networks demonstrating particular strength in identifying polyps during colonoscopy. However, they emphasize that successful clinical integration requires addressing data quality issues, interpretability concerns, and standardization needs through multidisciplinary collaboration.Precision Immunotherapy Using AI: Wang et al. developed a Transformer-Unet deep learning network to predict PD-L1 expression from routine H&E-stained lung cancer images, eliminating the need for costly immunohistochemical staining 3 . Their model achieved 80% dice similarity coefficient and 0.92 correlation with gold standard assessment-exceeding consistency between different pathologists. This breakthrough could democratize access to precision immunotherapy by making biomarker assessment available in resource-limited settings.Al-Obeidat et al.'s meta-analysis of seven studies comparing AI models with physicians in HCC detection found comparable sensitivity (93%) but highlighted complementary strengths 4 . Region-based convolutional neural networks showed particularly high sensitivity (96%), while physicians maintained superior specificity (100%). This reinforces AI's role as an effective "second reader" rather than replacement for human expertise.Computational Tumor Microenvironment Analysis: Khanduri et al. used multiplex immunofluorescence and spatial analytics to map macrophage subtypes in colorectal cancer liver metastases 5 . They discovered that M2 macrophages predominated at tumor periphery with greater proximity to malignant cells, while higher M1 macrophage densities in tumor centers paradoxically correlated with poorer survival-challenging traditional immunology paradigms and demonstrating how computational approaches can reveal prognostic biomarkers invisible to conventional assessment.The evolution toward generative AI and multi-agent systems represents a paradigm shift from isolated AI applications toward comprehensive, coordinated intelligence spanning the entire cancer care ecosystem.Generative AI Applications: Large language models can synthesize vast medical literature, generate personalized patient explanations, and create adaptive interfaces accommodating varying health literacy levels. For populations with limited digital access-a concern highlighted in Pana et al.'s work 1 -generative AI could provide conversational interfaces requiring minimal technical sophistication while delivering personalized cancer risk information.Multi-Agent Cancer Care Workflows: Unlike monolithic AI models, multi-agent systems comprise specialized components collaborating through structured workflows. A comprehensive cancer care system might include:• Screening agents analyzing routine imaging and EHR data for elevated cancer risk • Diagnostic agents specialized in different modalities (radiology, pathology, genomics) • Treatment planning agents incorporating molecular profiling and trial evidence • Monitoring agents tracking treatment response and surveillance • Patient communication agents generating personalized educational materials This distributed architecture offers several advantages: modularity allowing individual agent optimization, transparency through decomposed reasoning steps, robustness through diverse modeling approaches, and adaptive resource allocation for critical tasks.For example, Wang et al.'s PD-L1 prediction work 3 could be handled by a dedicated histopathology agent while other agents focus on radiologic or genomic aspects, with integration agents synthesizing findings into comprehensive treatment recommendations.Successful AI integration requires cultivating AI literacy-understanding AI capabilities, limitations, and appropriate applications-across all stakeholders.Healthcare Provider Literacy encompasses critical evaluation of AI outputs, appropriate patient communication about AI-derived insights, and awareness of potential biases. Training programs must integrate AI literacy into medical education at all levels, emphasizing complementary human-AI collaboration rather than algorithmic deference.Patient and Caregiver Literacy focuses on understanding AI's role in care decisions, appropriate trust calibration, and privacy implications. Educational materials should use accessible language that empowers rather than mystifies, particularly important given digital literacy's influence on healthcare engagement demonstrated in Pana et al.'s findings 1 .Health System Literacy requires governance frameworks for responsible deployment, quality assurance processes, and health equity impact assessments to prevent algorithmic biases from perpetuating cancer care disparities.Despite promising results, significant challenges remain in translating AI from research to clinical practice: Data Quality and Standardization: AI performance depends heavily on training data quality and representativeness. Standardizing collection and processing protocols across institutions remains a critical hurdle, particularly for diverse histological image data and physician interpretation variability. Such standardization approaches need contextual consideration and appropriate refinement for subsequent data-derived models and their associated inferences/predictions as well. Concepts like "model-scorecards" 6 , data ontologies and conformal inference approaches 7 might be relevant to bring into our collective knowledge-base in this regard.Interpretability and Trust: Many AI models function as "black boxes," challenging clinical acceptance. Multi-agent architectures offer promising solutions by decomposing complex reasoning into transparent, discrete steps performed by specialized components.Population Diversity: Most AI models are trained on specific demographic groups, raising generalizability concerns. Future work must prioritize diverse data inclusion and explicit performance assessment across demographic groups to ensure equitable benefit rather than exacerbated disparities.Workflow Integration: Successful implementation requires seamless integration with existing clinical workflows through user-friendly interfaces, clear uncertainty communication, and decision support systems augmenting rather than replacing human expertise.DHTs and AI technologies offer multiple pathways to extend high-quality cancer care to underserved populations: automating labor-intensive diagnostic tasks (reducing specialized expertise requirements), enabling remote assessment and triage, standardizing care quality regardless of provider experience, and supporting earlier detection across all populations. However, realizing these benefits requires thoughtful implementation considering access, affordability, and cultural appropriateness-ensuring DHTs and AI reduce rather than widen existing healthcare gaps.This special issue illustrates DHT and AI's transformative potential across cancer detection and monitoring pipelines. The emergence of generative AI and multi-agent systems promises evolution from isolated applications toward comprehensive, coordinated intelligence spanning the entire cancer care ecosystem.Looking forward, we envision seamlessly integrated DHT and AI technologies supporting early detection, accurate diagnosis, personalized treatment planning, and effective monitoring while augmenting rather than replacing human expertise. Multi-agent workflows offer particularly promising approaches for orchestrating complex cancer care pathways with maintained transparency and interpretability.Critically, this vision includes equitable access to DHT and AI-enhanced cancer care for all populations, regardless of geographic location, socioeconomic status, or demographic characteristics. By thoughtfully developing and implementing these technologies with attention to disparities, we can advance both technical capabilities and meaningful progress toward health equity.The research presented here represents significant steps toward this vision. Through continued collaboration between computer scientists, oncologists, and healthcare professionals, we can create a future where DHTs and AI help reduce cancer burden for all patients. The frontier of early cancer detection is here-the challenge now is shaping it wisely, inclusively, and with unwavering commitment to improving patient lives while ensuring digital and AI literacy becomes as fundamental to cancer care as the technologies themselves.},
  archive      = {J_FRAI},
  author       = {Barua, Souptik and Paller, Channing J. and Randhawa, Navkiran and Rao, Arvind},
  doi          = {10.3389/frai.2025.1662971},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1662971},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: AI in digital oncology: Imaging and wearable technology for cancer detection and management},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Predicting the risk of depression in older adults with disability using machine learning: An analysis based on CHARLS data. <em>FRAI</em>, <em>8</em>, 1659362. (<a href='https://doi.org/10.3389/frai.2025.1659362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {1IntroductionThe comorbidity of disability and depression among older adults is a growing concern. Disability refers to a state of limited activities of daily living due to physical or mental impairments. At the same time, depression is a neuropsychiatric condition principally manifested through sustained affective dysregulation, significantly compromising physiological functioning and social adaptability (1). A well-established bidirectional association exists between disability and depression (2,3). Disability contributes to depression through loss of social roles and restricted mobility, whereas depression exacerbates functional decline by reducing rehabilitation adherence and impairing immune function. Epidemiological studies indicate that the global prevalence of major depressive disorder in older adults is approximately 13.3% (4), with disabled elders exhibiting significantly higher risks than their unimpaired counterparts (5). In China, the prevalence of geriatric depression reaches 34.1% (6), with rural areas demonstrating elevated vulnerability due to limited healthcare access and weaker familial support systems. This vicious cycle between disability and depression not only accelerates individual functional deterioration but also imposes substantial healthcare burdens and societal costs (7,8).Previous studies have predominantly employed cross-sectional designs and conventional statistical approaches (e.g., logistic regression, fixed-effects models) to identify risk factors. Regarding risk association validation, Mu et al. (9) demonstrated through binary logistic regression that individuals with disability exhibit significantly elevated risks of depressive symptoms. Using multivariate logistic regression, Yan et al. (10) further revealed urban-rural differential effects in the disability-depression association. In terms of disease trajectory research, Tian et al. (11)found that individuals with disability were more likely to follow trajectories of worsening depressive symptoms. Musliner et al. (12) associated prevalence rates, Çağan and Ünsal (13)reported a 57.8% depression rate among disabled individuals, while McGillivray and McCabe (14) documented a 39.1% depression prevalence among those with mild-to-moderate intellectual disabilities. Individual emotional states, life satisfaction, self-rated health, and social support systems have been systematically validated as critical predictors (15,16). However, traditional linear models demonstrate limited capacity in analyzing high-dimensional nonlinear relationships, and their static data frameworks fail to capture the temporal cumulative effects of risk factors.In summary, as shown in Table 1, existing studies exhibit three major limitations: (1) Design dimension: Prior studies predominantly rely on cross-sectional data, failing to capture the temporal cumulative effects of risk factors (e.g., the progressive impact of disability deterioration on depression). (2) Methodological dimension: Although conventional linear models (e.g., logistic regression) can validate risk associations, they struggle to handle high-dimensional nonlinear relationships. In contrast, ML algorithms significantly enhance predictive performance by extracting feature interactions and identifying temporal patterns. (3) Feature dimension: Existing research excessively focuses on physiological indicators (e.g., disease burden, functional impairment) while neglecting the contributions of subjective cognition (e.g. life satisfaction) and health behaviors (e.g., sleep). This study advances beyond conventional paradigms by integrating a longitudinal design, ML approaches, and a multidimensional feature structure to address these limitations. Specifically, we utilize multi-wave longitudinal data from CHARLS (2011–2020) and incorporate a temporal external validation framework (using an independent 2018–2020 cohort) to track the evolving trajectories of disability and depression dynamically. We systematically compare ten ML algorithms and introduce the SHapley Additive exPlanations (SHAP) interpretability framework to balance predictive accuracy with mechanistic insights. Furthermore, we construct a multidimensional feature matrix and employ a three-stage serial consensus feature selection (LASSO, Elastic Net, and Boruta), demonstrating that subjective perceptions (SHAP value: life satisfaction = 0.339) and health behaviors (sleep time = 0.344) exhibit stronger predictive power than conventional biomedical indicators. This integrative approach not only overcomes prior methodological constraints but also provides a robust, interpretable, and clinically actionable framework for depression risk stratification in older adults with disabilities.Table 1. Paradigm comparison between this study and previous depression prediction studies.DimensionPrevious mainstream researchThe innovation point of this studyDesignCross-sectional dataMulti-wave longitudinal data + temporal external verificationMethodTraditional statistical modelsComparison of 10 ML Algorithms + SHAP interpretationFeature Physiological indicatorsIntegration of subjective perception/health behavior/physiological multidimensional characteristicsAlthough machine learning (ML) offers innovative solutions to address these limitations(17,18), recent studies based on CHARLS data still exhibit notable shortcomings: (1) Overreliance on a single algorithm for feature selection. For instance, Huang (2025) employed LASSO exclusively for feature selection in cardiovascular disease risk prediction among middle-aged and older adults (19), which may inadequately address the challenges of high-dimensional feature collinearity and stability; (2) Insufficient temporal external validation in the evaluation framework. As demonstrated by Chu et al. (2025), the disability prediction model for older adults lacked external validation (20), potentially compromising the generalizability of the findings.ML offers innovative solutions to overcome these methodological limitations (21,22). Compared to conventional approaches, ML demonstrates superior predictive performance through its capacity for feature interaction mining and temporal pattern recognition (23). Xin and Ren (24) developed random forest models to predict disability risk in urban and rural populations, achieving AUC values of 0.71 and 0.78, respectively. In a systematic comparison, Hong et al. (25) demonstrated that XGBoost models exhibited excellent performance in training sets (AUC = 0.76), while logistic regression models performed well in validation sets (AUC = 0.73). Handing et al. (26) employed random forest analysis and identified social isolation and self-rated health as significant determinants of depression. Despite these advancements, few studies in China have utilized longitudinal data and multiple ML algorithms to construct risk prediction models specifically for depressive disorders within geriatric populations with functional limitations (25). Furthermore, methodological weaknesses in validation frameworks among existing studies may compromise the reliability of findings (19,27).This study utilized multi-wave data (2011-2020) from the China Health and Retirement Longitudinal Study (CHARLS) to construct a predictive computational framework for geriatric populations with functional limitations. We integrated three waves of panel data (2011-2015) to construct a comprehensive feature matrix encompassing baseline characteristics, disease profiles, and disability progression patterns. A three-stage serial consensus approach was utilized to identify robust predictors combining elastic net regularization, least absolute shrinkage and selection operator (LASSO), and Boruta algorithms. We identified 21 robust predictors from 74 candidate variables. A temporal external validation strategy was implemented using an independent 2018-2020 cohort to systematically evaluate the cross-temporal stability of ten ML models, including HistGBM. The study aims to provide a high-accuracy tool for early identification of depression risk in disabled older populations and establish evidence-based priorities for psychosocial interventions.2Methods2.1 Data sources and research designThis study utilized data from the CHARLS, which implements multistage stratified sampling with probability-proportional-to-size weighting based on demographic stratification. The survey encompasses 150 county-level units across 28 provincial administrative regions in China. The baseline survey was conducted in 2011, with follow-up waves completed in 2013, 2015, 2018, and 2020, collecting comprehensive data on demographic characteristics, socioeconomic status, health behaviors, and medical history. The study protocol obtained ethical certification from Peking University's Biomedical Ethics Committee (Approval ID: IRB00001052-11015). Sample selection followed three inclusion criteria: (1) age ≥60 years at baseline; (2) exclusion of individuals with pre-existing depression diagnosis or without basic or instrumental activities of daily living (BADL/IADL) disability at baseline; (3) completion of at least two consecutive follow-up assessments. Through integration of baseline (2011-2013, N=2440) and follow-up (2013-2015, N=2943) data, we constructed a longitudinal panel dataset containing 5383 observations (2011-2015). The dataset was partitioned using stratified random sampling, allocating samples in a 7:3 ratio to training (N=3768) and testing (N=1615) sets. An independent 2018-2020 follow-up cohort (N=3254) served as the external validation set. The study flowchart is presented in Figure 1.Figure 1. Research flowchart.2.2Variable definitions and measurementsDepression was assessed using the 10-item Center for Epidemiological Studies Depression Scale (CESD-10), a widely validated screening tool for depressive symptoms in older adults (28,29). The scale demonstrates good reliability and validity (30,31). In CHARLS, the CESD-10 evaluates the frequency of 10 symptoms experienced in the past week: feeling bothered, trouble concentrating, feeling depressed, difficulty in doing things, feeling hopeful about the future (reverse-coded), feeling fearful, restless sleep, feeling happy (reverse-coded), feeling lonely, feeling unable to carry on. Each item is scored from 0 to 3, yielding a total score ranging from 0 to 30. Following established international criteria, a score ≥10 was used to define clinically significant depressive symptoms.Disability in this study specifically refers to functional limitations in BADL or IADL, consistent with geriatric assessment standards (32,33). BADL evaluates six fundamental self-care functions (dressing, bathing, eating, bed transferring, toileting, and continence control). IADL assesses five complex daily living skills (housekeeping, cooking, shopping, medication management, and financial management), where each item was scored 1 for inability to perform independently or 0 otherwise, resulting in total score ranges of 0-6 for BADL and 0-5 for IADL. The BADL/IADL-based criteria were applied during data screening to select eligible participants with BADL≥2 or IADL≥2 scores. This operational definition excludes sensory or cognitive disabilities alone, ensuring a homogeneous cohort with physical functional impairments. The definitions and measurement approaches of covariates encompassed four domains: (1) demographic characteristics (gender, age, registered residence, educational level, marital status, number of children, and region); (2) health behaviors, including chronic disease history (14 conditions such as hypertension and diabetes), sensory functions (visual, auditory, and oral health assessed through assistive device use, functional scores, and tooth loss status), bodily pain, sleep time, physical activity intensity, social engagement, and lifestyle factors; (3) subjective perceptions comprising episodic memory, cognitive ability, life satisfaction, and self-rated health; (4) health care and insurance, incorporating health insurance type, healthcare utilization (frequency, duration, and costs of inpatient and outpatient services), as well as pension status, with detailed variable specifications and coding schemes provided in Supplementary Table 1.2.3Data preprocessing and feature selectionData preprocessing included four key steps: (1) Outlier handling: We applied the interquartile range (IQR) method to detect and truncate outliers for all continuous variables. Values beyond ±1.5IQR of the 25th-75th percentile range were clipped to the lower/upper bounds. This mitigated the impact of extreme values on tree-based models while preserving data distribution integrity. (2) One-hot encoding: Categorical variables (e.g., gender, region) were converted into binary dummy variables to avoid misinterpreting ordinal relationships. (3) Normalization: Continuous features were standardized using z-score normalization (mean=0, variance=1) to enhance convergence speed for linear models. (4) Missing value imputation: Among 78 candidate variables, 4 variables (5.13%) with missing rates >30% were excluded; (2) Missing value imputation: The remaining 74 variables had an average missing rate of 8.27% (range: 0.09%-25.18%). A total of 15,918 missing records (8.82% of total training observations) were iteratively imputed using the MissForest algorithm. (5) Class imbalance adjustment: We implemented the SMOTE-Tomek hybrid sampling technique, combining synthetic minority oversampling (SMOTE) with Tomek links under sampling. This approach effectively enhanced the model’s sensitivity in detecting depression risk and improved clinical utility by generating synthetic samples.We refer to existing studies for feature selection(19,34,35). A three-stage serial consensus approach was utilized to identify robust predictors in this study. This serial consensus approach integrates complementary strengths of distinct selection paradigms. (1) LASSO (L1 regularization): Efficiently screens out zero-importance features (73 variables) by imposing sparsity constraints. Although its linearity assumption may oversimplify relationships, it serves as a high-recall initial filter. (2) Elastic Net (L1+L2 regularization): Reduces multicollinearity-induced instability by retaining correlated but biologically plausible features. The α=0.5 setting balances sparsity and grouping effects, mitigating LASSO's limitation in correlated feature selection, retaining 42 stable features. (3) The Elastic Net output variables were fed into the Boruta algorithm, which identified 28 significant predictors by comparing random forest importance scores with shadow variables (p<0.01). To ensure reproducibility, a random seed (random_state=42) was set for both the MissForest imputation and Boruta's shadow variable generation.Integration of feature selection results via a strict intersection strategy. The three feature selection outcomes were consolidated through a stringent intersection strategy. Specifically, we quantified the selection frequency of each variable across LASSO, elastic net, and Boruta algorithms, retaining only variables unanimously selected by all three methods (i.e., frequency ≥3). This approach yielded 21 high-confidence predictors, including age, self-rated health, arthritis, renal disease, stomach, asthma, memory-related disorders, observe the situation up close, hearing ability, self-reported pain in head, wrist, leg, toes, neck, sleep time, social activities, episodic memory, life satisfaction, medical insurance types, hospitalization expenses (total expenses), outpatient expenses (out of pocket expenses) (as shown in Figure 2). Compared to individual methods, this strategy significantly enhanced feature stability.Figure 2. Feature selection results using three methods (LASSO, Elastic Net, Boruta).2.4Model construction and performance evaluationTen ML algorithms were implemented, including logistic regression (LR), support vector machine (SVM), extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), categorical boosting (CatBoost), random forest (RF), bootstrap aggregating (Bagging), histogram-based gradient boosting machine (HistGBM), multilayer perceptron (MLP), and decision tree (DT). To optimize model generalizability, hyperparameter tuning was performed using grid search with 3-fold stratified cross-validation (specific hyperparameter configurations are provided in Supplementary Table 2). Model performance was comprehensively evaluated through five metrics: (1) the area under the receiver operating characteristic curve (AUC), measuring the model's ability to discriminate between positive and negative cases (Formulas 1-3); (2) accuracy, representing the proportion of correctly classified samples (Formula 4); (3) precision, indicating the ratio of true positives among all predicted positives (Formula 5); (4) recall, reflecting the model's capacity to identify actual positive cases (Formula 6); and (5) the F1-score, the harmonic mean of precision and recall, which provides a balanced assessment of the model's performance on the positive class (Formula 7). The mathematical formulations were derived from established methodologies (36,37). (1) (2) (3) (4) (5) (6) (7)In these formulations, TPR denotes the true positive rate, FPR represents the false positive rate, TP indicates true positives, FP signifies false positives, TN refers to true negatives, and FN stands for false negatives.2.5Statistical analysisStatistical analyses were performed using Stata 18.0 for data description and Python 3.13 for subsequent modeling. Continuous variables were characterized differentially based on their distribution: normally distributed variables were presented as mean ± standard deviation, while non-normally distributed variables were summarized using median and interquartile range, with normality assessed via the Shapiro-Wilk test. Categorical data were expressed as cardinality measures (absolute frequencies) with proportional composition. The statistical significance threshold was set at P<0.05 for all analyses.3Results3.1Baseline characteristicThe analysis included samples from the training sets (N=3768), testing sets (N=1615), and external validation sets (N=3254). Table 2 summarizes the baseline demographic characteristics, disease status, and depression status across the three cohorts. The median ages were 71, 71, and 72 years in the training, testing, and validation sets, respectively, with statistically significant inter-group differences (all P<0.05). In terms of gender, the proportion of females is similar in the training sets (57.94%), testing sets (57.28%), and external validation sets (60.97%). There was no statistically significant difference in gender distribution between groups (all P>0.05), indicating that the gender ratio remained balanced in the data partitioning. In terms of marital status, the married group accounts for 70.25%, 70.59%, and 69.61% of the three groups, respectively, which is much higher than the unmarried group. In terms of registered residence, the proportion of rural registered residence registration slightly decreased in training sets (79.91%), testing sets (79.57%), and external verification sets (78.83%), but all exceeded 78%. There was a significant difference in the distribution of registered residence among groups (P<0.05). The proportion of "3 or more children" in the three groups was 72.24%, 73.32%, and 66.04%, respectively, with a significant decrease in the proportion of external validation sets. There were significant differences in distribution between groups (all P<0.05). There was no significant difference in regional distribution between groups (all P>0.05). In terms of education level, the proportion of people who have not received formal education gradually decreased in the training sets (68.21%), testing sets (69.05%), and external validation sets (65.43%), while the proportion of high school and above education increased from 4.03% to 5.53%. There was a significant difference between the groups (all P<0.05). In terms of disease characteristics, there was no significant difference (P>0.05) in the prevalence of memory-related diseases and stroke diseases among the training sets, testing sets, and external validation sets. The incidence of heart disease was significant in the training and testing sets (P<0.05), but not significant in the validation sets (P>0.05). The incidence of arthritis disease remained stable among the three groups (56.22% -56.61%), with no significant difference between the groups (P>0.05). The proportion of depression showed a significant increasing trend among the training sets (56.32%), testing sets (56.35%), and validation sets (64.20%), with no significant difference (P>0.05).Figure 3 reveals the demographic differences in the prevalence of depression among disabled individuals. The gender distribution shows that the prevalence of depression in the female population (80.80%) is significantly higher than that in the male population (37.15%). Analysis of marital status shows that unmarried individuals have a higher risk of depression (61.18%) compared to married individuals (53.35%). In age stratification, the prevalence of depression in the elderly group aged 80 and above reached 60.06%, which was higher than that in the 70-80 age group (52.49%) and the 60-70 age group (56.41%). The regional distribution shows that the incidence rate in the western region (59.24%) and rural areas (57.29%) is significantly higher than that in the eastern region (52.50%) and urban areas (49.07%). Education level analysis shows that the illiterate population has the highest incidence of disease (57.86%), and there is a non-linear relationship between educational attainment and morbidity probability. The dimension of family support shows that the risk of depression in the childless group (75.18%) is significantly higher than that in the childbearing group (53.07% -56.50%).Table 2. Baseline features of training, testing, and validation sets.CharacteristicsTraining setsTesting setsExternal validation setsN=3768P-valueN=1615P-valueN=3254P-valueDemographic characteristicsAge (years)71 [65-77]P < 0.0571 [65-77]P < 0.0572 [66-79]P < 0.05Gender, n (%)Female2183(57.94)P > 0.05925(57.28)P > 0.051984(60.97)P > 0.05Male1585(42.06)690(42.72)1270(39.03)Marital status, n (%)Married2647(70.25)P > 0.051140(70.59)P < 0.052265(69.61)P > 0.05Unmarried1121(29.75)475(29.41)989(30.39)Registered residence, n (%)Urban757(20.09)P < 0.05330(20.43)P < 0.05689(21.17)P < 0.05Rural3011(79.91)1285(79.57)2565(78.83)Number of children, n (%)0 children111(2.95)P < 0.0538(2.35)P < 0.0551(1.57)P < 0.051 child224(5.94)99(6.13)226(6.94)2 children711(18.87)294(18.20)828(25.45)3 children and above2722(72.24)1184(73.32)2149(66.04)Region, n (%)Eastern1066(28.29)P > 0.05450(27.86)P > 0.051007(30.95)P > 0.05Central1326(35.19)571(35.36)1131(34.76)Western1376(36.52)594(36.78)1116(34.29)Educational level, n (%)Illiteracy2570(68.21)P < 0.051115(69.05)P < 0.052129(65.43)P < 0.05Elementary Schools740(19.64)308(19.07)603(18.53)Junior High Schools306(8.12)127(7.86)342(10.51)High school and above152(4.03)65(4.02)180(5.53)Disease HistoryHistory of memory-related diseases, n (%)No3175(84.26)P < 0.051377(85.26)P < 0.052760(84.82)P < 0.05Yes593(15.74)238(14.74)494(15.18)History of heart disease, n (%)No2667(70.78)P < 0.051159(71.76)P < 0.052102(64.60)P > 0.05Yes1101(29.22)456(28.24)1152(35.40)History of stroke disease, n (%)No3245(86.12)P < 0.051370(84.83)P < 0.052591(79.63)P < 0.05Yes523(13.88)245(15.17)663(20.37)History of arthritis disease, n (%)No1648(43.74)P > 0.05707(43.78)P > 0.051412(43.39)P > 0.05Yes2120(56.26)908(56.22)1842(56.61)Outcome measurementsDepressed, n (%)No1646(43.68)P > 0.05705(43.65)P > 0.051165(35.80)P > 0.05Yes2122(56.32)910(56.35)2089(64.20)Figure 3. The demographic differences.3.2Model performanceThis study systematically evaluated the performance of ten ML algorithms in predicting depression risk among older adults with disability across training, testing, and external validation sets (as shown in Table 3). In terms of accuracy, RF (0.741), LightGBM (0.728), and HistGBM (0.713) demonstrated the highest performance in the testing sets. While LR and DT exhibited relatively stable performance between training and testing sets, their overall accuracy was the lowest (LR: 0.667; DT: 0.633). For AUC metrics, RF (0.797) achieved the strongest discriminative capacity, followed closely by LightGBM (0.785), XGBoost (0.781), and HistGBM (0.779). XGBoost, LightGBM, and HistGBM showed superior generalizability, whereas DT (0.636) performed the poorest. Regarding the F1-score, RF (0.762) exhibited the optimal balance between precision and recall, with LightGBM (0.749), CatBoost (0.741), and HistGBM (0.735) maintaining stable performance in the testing sets. For precision, RF (0.791), LightGBM (0.778), XGBoost (0.767), and HistGBM (0.723) achieved the highest positive predictive values and lowest false positive rates, significantly outperforming DT (0.691). In recall analysis, RF (0.735), HistGBM (0.723), and HistGBM (0.707) demonstrated the strongest ability to identify true positive cases, while DT (0.633) exhibited markedly higher missed-detection risks compared to ensemble methods.Through comprehensive evaluation of ten ML models, HistGBM was selected as the optimal model based on three key criteria: (1) superior performance on testing sets metrics (AUC=0.779, F1-score=0.735, accuracy=0.713), (2) excellent generalizability demonstrated by a minimal training-testing AUC gap (8.5%), and (3) consistent performance across validation sets. HistGBM exhibited well-balanced predictive capabilities, showing above-average performance across all evaluation metrics without significant weaknesses in either precision (0.766) or recall (0.707), indicating robust discriminative power between positive and negative cases along with stable predictive performance. The model's exceptional generalizability was particularly noteworthy, with only a 10% difference in AUC between the testing sets and validation sets, as shown in Figure 4, significantly outperforming other models and demonstrating strong robustness across different data distributions. Although RF achieved the highest individual metrics on the specific testing set used in Table 3, the substantial performance degradation observed on the external validation set raised concerns about its real-world applicability and stability. HistGBM, while having marginally lower peak testing set scores than RF, offered the best overall package of strong predictive performance, minimal overfitting (small train-test gap), and exceptional stability across the independent validation set. This superior generalizability was the primary reason for selecting HistGBM as the optimal model for potential clinical application, where reliability across diverse data sources is paramount.XGBoost demonstrated strong performance on testing sets metrics (AUC=0.781, F1-score=0.735, accuracy=0.713), though it exhibited a relatively large training-testing AUC gap (10.1%) compared to LR, HistGBM, MLP, and CatBoost. However, its validation set's AUC showed a 10.7% difference from testing sets' performance (Figures 5-7), suggesting reasonable stability across data partitions and potential suitability for resource-constrained scenarios. RF achieved excellent testing set results (AUC=0.797, F1-score=0.762, accuracy=0.741), but displayed concerning generalization issues with substantial training-testing and testing-validation AUC differences, indicating potential overfitting to training data noise or specific patterns. LightGBM ranked second in testing sets AUC (0.785) with stable validation performance (0.654). However, the difference between the testing set AUC and the validation set is too large (13.1%). CatBoost performed comparably to top models in testing set metrics (AUC=0.774, F1-score=0.741) with excellent categorical feature handling, though its relatively lower F1-score (0.741) and recall (0.720) scores suggested weaker minority class identification, limiting its utility for imbalanced datasets. Among the remaining models, SVM exhibited severe overfitting, while MLP and DT significantly underperformed ensemble methods in both AUC and F1-score metrics.Table 3. Performance of ten ML algorithms on training and testing sets.ModelAccuracyAUCF1-scorePrecisionRecallTrainTestTrainTestTrainTestTrainTestTrainTestLR0.7020.6670.7810.7230.6890.6850.7210.7340.6610.642HistGBM0.7820.7130.8640.7790.7780.7350.7930.7660.7630.707MLP0.8050.6980.8820.7610.7970.7180.8300.7580.7670.682XGBoost0.8010.7130.8820.7810.7970.7350.8130.7670.7820.705Bagging0.7720.7090.8520.7700.7650.7310.7880.7640.7440.700DT0.6510.6330.6530.6360.6480.6610.6540.6910.6420.633LightGBM0.8030.7280.8830.7850.7990.7490.8160.7780.7820.723RF0.8220.7410.9010.7970.8170.7620.8400.7910.7960.735SVM0.8180.7080.8990.7680.8120.7270.8380.7660.7870.692CatBoost0.7760.7160.8570.7740.7720.7410.7870.7630.7570.720Note: The highest value in each column is highlighted in bold. Final model selection prioritized generalizability across training, testing, and external validation sets, as detailed in the text.Figure 4. AUC comparison of training sets, testing sets, and validation sets.Figure 5. Training sets ROC curves.Figure 6. Testing sets the ROC curves.Figure 7. External validation sets ROC curves.3.3Model explanationThe SHAP values quantify the absolute average impact of each feature on model predictions across all possible feature combinations, revealing their global importance. As shown in Figure 8, the SHAP analysis of the HistGBM model demonstrated significant variability in feature contributions. Sleep time (mean SHAP=0.344), life satisfaction (0.339), episodic memory (0.220), and self-rated health (0.197) emerged as the top four predictive features, indicating that health behaviors, subjective perceptions, and cognitive function were the core drivers of model predictions. The high contribution of sleep time likely reflects its well-established associations with chronic diseases, metabolic disorders, and cognitive decline. Life satisfaction and self-rated health, as subjective health indicators, capture the interplay between psychosocial factors and physiological health. Episodic memory directly influences prediction through cognitive and sensory pathways. Moderate contributions were observed for features such as stomach diseases, observing the situation up close, and memory-related disorders. While self-reported pain in the head, wrist, leg, toes, neck, and mental health conditions showed limited predictive importance, suggesting either weak signals or sparse data distributions. These results validate the model's multidimensional feature selection approach and provide actionable insights for intervention prioritization. Health management strategies targeting high-contribution features could enhance the model's real-world utility. Additionally, domain knowledge should guide the evaluation of low-contribution features to optimize the balance between model complexity and interpretability.Figure 9 presents the SHAP value distributions, revealing the heterogeneous directional effects and magnitudes of various features on depression probability predictions among older adults with disability. The x-axis (SHAP value) indicates each feature's influence on model output, where positive values increase and negative values decrease predicted risk. The color gradient (red means high feature value, blue means low feature value) demonstrates that: (1) higher values of sleep time, life satisfaction, and self-rated health (red clusters with negative SHAP) were strongly protective against depression, consistent with established epidemiological mechanisms; (2) better episodic memory performance (blue with positive SHAP) correlated with reduced depression risk, potentially through preserved cognitive resilience; (3) stomach diseases (red with positive SHAP) elevated risk through chronic somatic burden and psychological stress pathways; and (4) bodily pain (head, wrist, leg, toes, neck; red with positive SHAP) increased depression vulnerability in this population. These findings highlight the central role of health behaviors and psychosocial factors in depression comorbidity risk while identifying specific physiological pain features as contributory predictors.Figure 8. SHAP feature importance.Figure 9. SHAP value distribution.4DiscussionThis study identified significant associations between depressive risk among disabled older adults and demographic characteristics, health status, and social support factors. The external validation cohort's higher median age than training sets and elevated depression risk in advanced age align with existing literature (38,39), potentially mediated by cognitive decline and reduced social roles. Consistent with Girgus et al. (40), females demonstrated significantly higher risk than males, possibly due to gender-specific social expectations, somatic symptom expression patterns, and help-seeking behaviors (26). The elevated risk among unmarried individuals supports the marital support hypothesis, where spousal emotional and economic support may serve as protective factors (41), corroborating Zhai et al. (42). Notably, the higher prevalence in rural western regions reflects China's geographic disparities in healthcare resource allocation, echoing Fan et al. (43) on primary mental health service accessibility. Higher education levels were protective, consistent with prior studies (44,45), likely through multiple pathways: enhanced cognitive capacity, improved socioeconomic resources, greater mental health awareness, and healthier behaviors. The elevated risk among childless individuals suggests family support network deficiencies may exacerbate disability-related stress, particularly relevant in East Asian familial care traditions (46), though some studies report no direct mental health impact of childlessness (47,48).This study systematically evaluated ten ML models (LR, SVM, XGBoost, LightGBM, CatBoost, RF, Bagging, HistGBM, MLP, DT) for predicting depressive risk among disabled older adults, demonstrating the superior performance of ensemble methods over traditional approaches. The HistGBM algorithm achieved optimal predictive accuracy, with AUC values of 0.779 (testing sets), aligning with current trends in medical prediction research. While Busi and Stephen (49) similarly compared extreme gradient boosting methods for early kidney disease diagnosis, their study did not examine the generalization enhancement effects of histogram optimization. Lee et al. (50) likewise identified extreme gradient boosting as the top performer for chronic disease prediction (AUC≥0.80). HistGBM's minimal AUC divergence between validation and testing sets (10%) confirms that histogram binning effectively mitigates overfitting caused by high-dimensional sparse features characteristic of healthcare data.Notably, while RF achieved the highest testing sets AUC (0.797), its validation performance showed significant degradation (ΔAUC=12.7%), contrasting sharply with its training sets performance (AUC=10.4%). This suggests that RF's majority voting mechanism may amplify localized features in training data when strong collinearity or noise exists in the feature space (51). In comparison, HistGBM maintained tighter training-testing consistency (8.5% AUC difference), outperforming both XGBoost (10.1%) and LightGBM (9.8%), indicating its superior suitability for handling elderly health data with measurement errors. Regarding class imbalance handling, XGBoost demonstrated significantly lower recall (0.705) than HistGBM (0.707), consistent with findings by Baba and Bunji (52). HistGBM's adaptive histogram partitioning mechanism balanced class weights while maintaining high precision (0.766), yielding a 5% F1-score improvement over LR (0.685). This enhancement likely stems from our feature engineering strategy that deeply explored disability-related psychosocial variables. These findings provide new empirical evidence for model selection in medical ML applications.The SHAP interpretability framework revealed multidimensional drivers of depressive risk prediction among disabled older adults. Sleep time emerged as the primary predictor (SHAP=0.344), demonstrating significantly greater contribution than reported in the Song et al. (53) study (SHAP=0.133). This enhanced predictive importance may reflect disability-associated sleep fragmentation, potentially activating inflammatory pathways and amplifying pathological effects. Notably, life satisfaction (SHAP=0.339) and self-rated health (SHAP=0.197) demonstrated greater predictive influence than conventional biomedical indicators, establishing psychosocial factors as pivotal determinants in depression comorbidity mechanisms among individuals with disability (54). Within cognitive domains, episodic memory (SHAP=0.220) showed higher predictive contribution than observing the situation up close (SHAP=0.192). Conversely, the relatively low importance of somatic pain features suggests the need to reevaluate clinical assessment priorities for pain screening in this population.This study achieves a breakthrough by integrating longitudinal design, ML techniques, and multidimensional feature engineering. First, compared to cross-sectional designs, our multi-wave feature construction quantitatively captures the cumulative effects of factors such as sleep disturbance (SHAP value = 0.344). Second, in contrast to conventional statistical models, the HistGBM algorithm significantly enhances generalizability through histogram optimization (training-testing AUC gap: 8.5%). Third, the predictive contribution of subjective perception indicators (life satisfaction SHAP value = 0.339) surpasses that of traditional physiological measures, validating our novel finding that psychosocial features dominate depression risk prediction. These methodological innovations collectively advance the field by providing a more robust, dynamic, and interpretable framework for risk stratification.While this study provides valuable insights into depressive disorder risk stratification in functionally impaired geriatric populations, several limitations should be acknowledged. First, the reliance on the CHARLS self-reported measures may lead to an underestimation of both disability severity and depressive symptoms. Second, the exclusion of biomarkers limits the model's ability to differentiate depression subtypes. Third, the absence of real-time dynamic health monitoring data potentially reduces the predictive value of temporal features. Future research should incorporate wearable device data and multi-omics approaches to develop dynamic prediction systems, complemented by cross-cohort validation to enhance generalizability. Fourth, our disability definition focused exclusively on BADL/IADL limitations. While this is consistent with geriatric assessment standards, it may not capture populations with pure cognitive or sensory disabilities. However, this standardized approach minimized cohort heterogeneity, facilitating model training on uniformly defined functional impairments. Future studies should validate these findings in other disability subtypes.5ConclusionThis study constructed a clinically generalizable prediction model for depressive risk among disabled older adults by integrating longitudinal data from multiple CHARLS waves. Our three-stage serial consensus approach feature selection system identified 21 robust predictors spanning physiological function, social support, and health behaviors, overcoming limitations of traditional linear modeling approaches. The HistGBM algorithm demonstrated optimal predictive stability through its histogram binning technique and adaptive learning mechanism. SHAP interpretability analysis revealed that health behavior (sleep time) and subjective perception indicators (life satisfaction, self-rated health) contributed significantly more to predictions than biomedical features, underscoring the central importance of psychosocial interventions in depression prevention for this population. The study identified significantly elevated depression risks among specific demographic subgroups with disability, including individuals residing in western rural regions, elderly females, those with limited educational attainment, and childless older adults. These findings highlight the urgent need for community-based mental health service networks and family support policies. These results provide an evidence base for preventing psychological disorders and implementing mental health interventions among the aging population with disability.},
  archive      = {J_FRAI},
  author       = {Jin, Tongtong and Halili, Ayitijiang·},
  doi          = {10.3389/frai.2025.1659362},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1659362},
  shortjournal = {Front. Artif. Intell.},
  title        = {Correction: Predicting the risk of depression in older adults with disability using machine learning: An analysis based on CHARLS data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Stylistic variation across english translations of chinese science fiction: Ken liu versus ChatGPT. <em>FRAI</em>, <em>8</em>, 1650320. (<a href='https://doi.org/10.3389/frai.2025.1650320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Correction on: Zhou P and Cheng J (2025) Stylistic variation across English translations of Chinese science fiction: Ken Liu versus ChatGPT. Front. Artif. Intell. 8:1576750. doi: 10.3389/frai.2025.1576750 In the acknowledgements statement, the text was incorrectly edited to reflect an additional author without consent. This section has now been removed after a request from the first author.There was a mistake in Table 1 as published. The last row was shifted two places to left adding '101,567' and '99,324' to columns 2 and 3, although these cells should have been blank. The corrected Table 1 appears below. The original version of this article has been updated.},
  archive      = {J_FRAI},
  author       = {, Frontiers Production Office},
  doi          = {10.3389/frai.2025.1650320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1650320},
  shortjournal = {Front. Artif. Intell.},
  title        = {Correction: Stylistic variation across english translations of chinese science fiction: Ken liu versus ChatGPT},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven epidemic intelligence: The future of outbreak detection and response. <em>FRAI</em>, <em>8</em>, 1645467. (<a href='https://doi.org/10.3389/frai.2025.1645467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epidemic intelligence, the process of detecting, verifying, and analyzing public health threats to enable timely responses, traditionally relies heavily on manual reporting and structured data, often causing delays and coverage gaps. The growing frequency of emerging infectious diseases highlights the urgency for more rapid and accurate surveillance methods. This perspective proposes a forward-looking conceptual framework for AI-driven epidemic intelligence, emphasizing the transformative potential of integrating large language models (LLMs), natural language processing (NLP), and optimization-based resource allocation strategies. While existing AI-driven systems have shown significant capabilities during the COVID-19 pandemic, several challenges remain, including real-time adaptability, multilingual data handling, misinformation, and public health policy alignment. To address these gaps, we propose an integrated, real-time adaptable LLM-based epidemic intelligence system, capable of correlating cross-source data, optimizing healthcare resource allocation, and supporting informed outbreak response. This approach aims to significantly improve early warning capabilities, enhancing forecasting accuracy, and strengthen pandemic preparedness.},
  archive      = {J_FRAI},
  author       = {Kaur, Jasleen and Butt, Zahid Ahmad},
  doi          = {10.3389/frai.2025.1645467},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1645467},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-driven epidemic intelligence: The future of outbreak detection and response},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-enabled workforce integration: Blended human resource contribution rate in chinese companies. <em>FRAI</em>, <em>8</em>, 1645172. (<a href='https://doi.org/10.3389/frai.2025.1645172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWith the development of AI technology, the employment mode of companies is undergoing unprecedented changes.MethodsThe paper defines the composition of blended human resources of a company as three types of formal employees, flexible workers and intelligent machine workers, constructs a blended human resource contribution rate calculation method based on BP-MIV, and analyzes the data of automobile manufacturing companies in 2022.ResultsThe results show that the contribution rate of blended human resources to company performance is 73.81%. Among them, the contribution rate of formal employees is 19.55%, while flexible workers and intelligent machine workers, despite their significantly smaller proportion in number compared to formal employees, have contribution rates of 20.26% and 34.00%, respectively. In further discussions, the calculation results of the blended human resource contribution rate based on the production function method were compared with those based on the BP-MIV method.DiscussionThe findings indicate that the BP-MIV-based calculation method exhibits certain advantages in capturing nonlinear relationships, such as the synergistic effects of various types of blended human resources on company performance. This study attempts to propose a preliminary theoretical framework and methodological approach for blended human resource management research in the AI era.},
  archive      = {J_FRAI},
  author       = {Zhang, Kexin and Wu, Cisheng and Ge, Manman and Liu, Teng},
  doi          = {10.3389/frai.2025.1645172},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1645172},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-enabled workforce integration: Blended human resource contribution rate in chinese companies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Epistemic responsibility: Toward a community standard for human-AI collaborations. <em>FRAI</em>, <em>8</em>, 1635691. (<a href='https://doi.org/10.3389/frai.2025.1635691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ebect, everyone) possibilities for usefully harnessing the particular expertise of AI for many applications (Mollick, 2025). This has exacerbated worries of cheating, by presenting AI productions as one's own original work, along with the threat of AI-created misinformation. These worries lurk at every level of education, and among academics, artists, scientists, and other professions.While cheating and unwarranted credulousness are irresponsible, a simple proscription against the use of AI in education and the professions would preemptively block potentially beneficial applications for AI. In any case, it's increasingly evident that such a blanket prohibition will not work (Mello, 2023). What is needed instead is a positive code defining the proper use of AI in contexts where truth is to be discovered, preserved, extended, and communicated. These "knowledge contexts" are the domain of epistemic responsibility. The goal of this short opinion essay is to outline some principles that might be applied by researchers and serve as a standard for evaluation of good practice in academic and professional writing."Epistemic responsibility" is a broad topic, linking to philosophical discussions of the ethics of belief-formation and to the intellectual virtues supportive of the production of knowledge (Battaly, 2008;Meylan, 2013). The concern in the present essay is narrower.Here, the question is not whether AI should be recruited or avoided in the pursuit of knowledge. AI, we've seen, is already broadly in play across every intellectual domain and in most workplaces. Nor do these guidelines suggest how AI should be used, nor how AIproduced claims should be understood and evaluated. Rather, these guidelines aim to secure a precondition for these larger issues. Here, the question is how to acknowledge and make explicit AI-generated content. The guidelines below aim to demarcate the human and the artificial in publication; once the two are clearly distinguished, the larger questions of evidence and warrant may also find new illumination. This, however, is a topic for a future discussion.The goals of the proposed protocols for AI collaborations are transparency and replicability. The two goals reinforce each other. Where one is achieved, the other usually is facilitated as well. These are standard goals in academic publication and scientific research. Providing a conspicuous standard protocol for AI use will help reassure readers and consumers about the good practices of authors, and will provide authors with a clear and visible standard of conduct, requiring full disclosure of any AI generated material in published research. These standards do not need to be ratified by professional organizations or publishers, although they could be. Rather, they will hopefully spread to become a simple community expectation. Their widespread use will enable AI to be used ebectively but with maximum transparency.The proposed standards are listed below, with a notional example (Box 1).Standard 1: Prominence: The inclusion of AI content must be immediately apparent to all readers, even at a first glance. The AI source needs to be stated in title header text, in as much detail as possible. As displayed in the notional example (Box 1), this statement does not imply AI co-authorship, but is a separate line item. This includes identifying sections of the paper drawing on AI output, and demarcation of text composed by AI. The paper abstract needs to include information as well. If there is no AI content, this too should be stated.Standard 2: Replicability: AI in research applications inevitably involves shaping the behavior of the AI in service of the researcher. This is "prompt engineering," and the prompt used is an essential tool for understanding the result, its implications, and its limitations. The operative prompts should be explicitly and fully stated in any work including AI generated content. The actual prompt(s) behind the AI content is also essential for replication. Ideally, stages of prompt evolution should be documented, and submitted as supplementary material (if not stated fully in the main text).Standard 3: Content Cross-checking: Since LLMs confabulate freely, no reference or quotation can be accepted at face value. Accordingly, every factual claim in AI content needs a human checker. At a minimum, the fact checker needs to confirm that bibliographic information provided by the AI is correct. Also, the content checker should confirm that claims made by AI are in fact supported by the referenced sources. And finally, the checker needs to confirm that any text generated by AI neither duplicates nor closely paraphrases texts from other sources. All of this is essential, and so must be explicitly confirmed, also at the head of the paper. An author can fill this role, but likewise a research assistant can contribute. In either case, that individual should be identified along with contact information in case questions arise. In this way, authors and fact-checkers are identified as explicitly and transparently responsible for the oversight of AI-generated content.Standard 4: Intra-textual clarity: All AI-generated content within a research report or any other publication must be set ob from human-generated content through distinct style markers, like block quotations or alternate fonts.These are relatively simple guidelines, readily adaptable to various contexts. Certainly research in AI and related fields should be governed by these epistemic guardrails. However, these expectations can apply to any writing presenting evidence and argumentation in support of a conclusion. They should be automatic and second nature in academic writing. Likewise, they should be taught as part of expository writing, coequal with proscriptions against plagiarism and other forms of academic dishonesty. As such, epistemic responsibility with respect to AI can become part of the school curriculum, and apply explicitly to both students and teachers.The guidelines apply by a straightforward analogy to creative contexts as well. Artistic works may not have the production of knowledge as an immediate goal, but originality and authorship are nonetheless threatened by surreptitious AI. Artists' statements routinely accompany works of art in all mediums. These statements should explicitly meet the standards outlined above.The guidelines here diber from those of COPE, the Committee on Publications Ethics, which broadly considers good practice in every phase of publication (COPE Council, 2023). COPE emphatically rejects co-authorship of humans and AI, and thus recommends against listing AI applications or programs on title pages. Instead, AI use should be detailed in Methods sections. However, this invites some obscurity, burying the crucial AI inflection deep in a paper. In contrast, the guidelines recommended here make AI content immediately obvious to all. As the notional example demonstrates, this frontend prominence does not imply that AI is a co-author. The recommended AI notice is distinct (and new) default information at the head of any publication.Similarly, the International Committee of Medical Journal Editors (ICMJE) agrees with the COPE prohibition of AI co-authorship and advises writers to use AI judiciously in writing and editing (American Medical Writers Association, 2023). This also abords some latitude in acknowledging AI-generated content, leaving room for ambiguity in a reader's mind. In contrast, the guidelines here explicitly force acknowledgement of AI content and require the clear demarcation of its presence in any publication. Moreover, mandating the publication of the relevant prompts allows for easier replication and further exploration of potential AI contributions. Finally, the guidelines mandate explicit acknowledgment that AI content has been fact-checked, and elevate the role of fact-checker, thereby holding both author and fact-checker responsible for ensuring the reliability of such content.As these guidelines become community expectations, they will help to ensure the judicious use of AI. This in turn might lessen the anxiety that sources of information are surreptitiously infected with confabulated AI content. In an ideal future, AI-generated content would be as reliable as human research. But in the real world, AI confabulation will continue to threaten our understanding of the world with its flood of accidental or deliberate fakery. Resisting this trend, the proposed benchmarks for explicit AI usage can clarify and solidify human responsibility and authority in the production of knowledge.},
  archive      = {J_FRAI},
  author       = {Lloyd, Dan},
  doi          = {10.3389/frai.2025.1635691},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1635691},
  shortjournal = {Front. Artif. Intell.},
  title        = {Epistemic responsibility: Toward a community standard for human-AI collaborations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence skills and their impact on the employability of university graduates. <em>FRAI</em>, <em>8</em>, 1629320. (<a href='https://doi.org/10.3389/frai.2025.1629320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has emerged as a transformative technology in multiple areas, including the labor market. Its incorporation into organizations redefines professional profiles, required skills, and employability conditions. In this context, it is essential to understand how university graduates are preparing to face these changes and what role their AI skills play in their integration into the workforce. The study aimed to analyze the level of AI skills and their impact on the employability of university graduates through a quantitative and descriptive design. A survey was conducted with a sample of 148 undergraduate and graduate graduates. The data were analyzed using descriptive statistics and visualized using graphs. The results indicated that graduates who report greater knowledge and more frequent use of AI tools, especially generative ones such as ChatGPT, are more likely to be employed in areas related to their majors and to perceive higher productivity and better professional alignment. However, a generational gap in digital skills was also identified, as well as a widespread feeling of insufficient preparation for the challenges of the current labor market. The conclusion is that AI skills are consolidating as a key differentiating factor in employability and that their formal incorporation into university curricula is urgently needed. The implications of the study point to the need for an educational transformation that integrates AI as a transversal skill, promotes ongoing teacher training, and fosters policies that guarantee inclusive education aligned with the challenges of the digital age.},
  archive      = {J_FRAI},
  author       = {Portocarrero Ramos, Heily Consepción and Cruz Caro, Omer and Sánchez Bardales, Einstein and Quiñones Huatangari, Lenin and Campos Trigoso, Jonathan Alberto and Maicelo Guevara, Jorge Luis and Chávez Santos, River},
  doi          = {10.3389/frai.2025.1629320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1629320},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence skills and their impact on the employability of university graduates},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in humanitarian healthcare: A game changer for crisis response. <em>FRAI</em>, <em>8</em>, 1627773. (<a href='https://doi.org/10.3389/frai.2025.1627773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is transforming humanitarian healthcare by providing innovative solutions to critical challenges in crisis response. This review explores peer-reviewed literature and case reports from 2001 to 2025, retrieved from PubMed, Scopus, and Google Scholar, using targeted keywords. Results indicate that AI enhances disaster prediction, disease surveillance, resource allocation, and mental health support through tools such as machine learning, natural language processing, robotics, and blockchain. Prominent applications include AI-powered early warning systems, chatbots for displaced populations, telemedicine platforms, and automated supply chain logistics. Ethical concerns such as data privacy, bias, and access inequities remain critical to responsible deployment. By uniting governments, NGOs, and technology providers, AI serves as a powerful tool to strengthen humanitarian healthcare systems, enhancing resilience and efficiency while ensuring better outcomes for vulnerable populations during crises.},
  archive      = {J_FRAI},
  author       = {Haykal, Diala and Goldust, Mohamad and Cartier, Hugues and Treacy, Patrick},
  doi          = {10.3389/frai.2025.1627773},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1627773},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI in humanitarian healthcare: A game changer for crisis response},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From data-driven cities to data-driven tumors: Dynamic digital twins for adaptive oncology. <em>FRAI</em>, <em>8</em>, 1624877. (<a href='https://doi.org/10.3389/frai.2025.1624877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionOncology is undergoing a transformation due to the advent of digital twin technology, which enables precision therapy by creating synchronized virtual copies of physical systems. Unlike static models, dynamic digital twins continually integrate multimodal patient data such as clinical, imaging, and molecular data, to simulate therapy scenarios and direct real-time therapeutic decisions (1). The success of smart city digital twins, which control complicated systems like traffic and energy in real time, provides a model for oncology (2). Like cities, tumors are dynamic, multiscale systems shaped by therapy, immunological responses, and genetic alterations. There must be less trial-and-error in cancer care if we can use dynamic, learning-based twins to practice therapy instead of static ones that rely on pre-treatment snapshots, which miss this progression.The Limits of Static Oncology TwinsStatic oncology twins are often created from a single pre-treatment dataset, which includes imaging and genetic profiles, and used to predict first medication responses. However, when tumors adapt into their environment and therapy, these one-time models lose accuracy, failing to predict emergent resistance mutations and microenvironmental modifications (3). Static twins are unable to detect early signals of relapse or toxicity because they exclude longitudinal indicators such as ctDNA kinetics, biomarker signatures, and routine labs, as well as real-time physiological data from wearables (4). Moreover, while assays like Oncotype DX and spatial cell‐type mapping inform initial risk stratification, they remain disconnected from iterative clinical decision loops (5). Integrative-cluster trials categorize patients based on a combination of molecular and histopathologic characteristics; however, they still do not incorporate closed-loop adaptation. On the other hand, a dynamic twin would actively adapt therapy by recalibrating its AI and mechanical models with each new data stream. Nonetheless, prospective validation via observational cohorts and randomized studies is necessary to establish the clinical utility of these adaptive systems. Smart Cities as Operational TemplatesDigital twins in smart cities serve as central command centers for urban ecosystems, consistently integrating data from traffic cameras, smart streetlights, water distribution monitors, public transit GPS, and air quality sensors (6). They function as a comprehensive citywide system, executing real-time simulations to evaluate the impacts of diverse scenarios, including the closure of a highway during peak hours, the reconfiguration of traffic signals to mitigate congestion, or the redirection of emergency response vehicles in unusual weather conditions. The results are then utilized to provide optimized control signals to the physical infrastructure (7). For example, Virtual Singapore uses real-time environmental and transportation data from over 30 agencies to simulate urban planning, emergency response, and energy efficiency, making it a global benchmark for centralized scenario rehearsal (8). The open digital twin of Helsinki facilitates public participation and climate planning via accessible 3D simulations, aiding in the visualization of solar potential and guiding zoning choices (9). Simultaneously, Shanghai's urban management twin enhances everyday operations and emergency response by combining IoT, AI, and real-time monitoring across districts, resulting in up to 30% gains in municipal efficiency (10). Upon the activation of a flood alert, the twin can promptly simulate reservoir releases, road closures, and diversion routes, analogous to how an ICU dashboard predicts patient stability across various ventilator settings (Figure 1).An oncology twin reflects this dynamic, feedback-oriented urban model. The system assimilates ongoing clinical notes and imaging data, analogous to how a city twin processes CCTV feeds (11,12). It incorporates pathology reports, genomic sequencing, and biomarker trends, similar to the way environmental sensors monitor particulate levels. Heart rate, blood pressure, sleep patterns, stress levels, changes in glucose levels, and even gait analysis are all wearable streams that can be used like mobile noise or air quality tools to let the twin know about changes in the body (13). In order to allow predictive algorithms to make real-time adjustments to dosing regimens or therapy switches, the city's infrastructure is routinely audited using serial liquid biopsies and tissue samples. By considering the tumor and its host as an interdependent and dynamic system, similar to simulating rush-hour traffic and power-grid load, the twin may predict spikes in tumor growth, mutations that confer resistance, and areas of toxicity that are particularly harmful. This provides doctors with a real-time practice ground for therapy and individualized treatment plans.Case Studies: Dynamic Twins in ActionRecent efforts demonstrate the feasibility of dynamic oncology twins, with new use cases expanding their scope:Table 1. Representative dynamic twin case studies in oncology and smart city examples highlighting continuous data ingestion, scenario simulation, and adaptive feedback.Digital‑Twin ApplicationDomain / SettingLead Institution(s)Core Data & ModelReported Outcome / InsightReferenceGlioblastoma Radiotherapy TwinNeuro‑oncologyOden Institute, UT AustinBayesian tumour‑growth model updated with serial MRI during radiotherapyAdaptive dosing delayed median progression by ≈6 days with lower total dose (14)Lung‑Cancer 3‑D TwinThoracic oncologyStanford + NCI–DOEDeep CNNs on CT, digital pathology, genomics; ctDNA updatesReconstructs 3‑D tumour, infers EGFR status, forecasts resistance, suggests therapy switches (15)FarrSight Virtual‑Trial TwinsMulticancer trial optimisationConcr (VISION trial)Patient‑specific simulation of alternative regimensHigher response when real therapy matched twin recommendation (16)Melanoma Immunotherapy TwinImmuno‑oncologyIndiana UniversityMultiscale agent‑based immune–tumour modelPredicts immune escape; tests checkpoint sequencing (17)Pain‑Management TwinSupportive care / PK‑PDMulti‑center Population PK/PD model of fentanylOptimizes dosing, reduces adverse events (18)Personalized AML Chemo SchedulerHematologyAcademic consortiumLongitudinal counts + mechanistic kineticsAvoided leukopenia in 10/13 AML cases (19)Breath‑Gas Early‑Detection TwinNon‑invasive screeningIndustry–academic groupVolatile metabolite ML signaturesDetects pre‑clinical tumor shifts via breath (20)Clinical‑Trial Design TwinTrial optimizationMulti‑center Virtual cohorts predicting toxicity vs efficacyReduced adverse events in trial simulations (21)Smart‑City Traffic Twin Urban operationsCity of Singapore – 'Virtual Singapore'Live traffic, IoT, weather feeds + agent‑based modelReal‑time rerouting cut congestion by ~15 % (8)Shanghai Municipal Digital TwinUrban operationsShanghai Municipal Government; Smart City ProgramCity wide IoT sensor network, AI analytics, real time cross district monitoringUp to 30 % gain in municipal efficiency and faster emergency response (10)These case studies highlight dynamic twins’ core functionalities: real-time data assimilation, multiscale modeling, and therapy rehearsal, extending to education and trial design.Digital twins in oncology must integrate patient data from diverse sources alongside the expertise of oncologists, clinical guidelines, and pertinent decision-making criteria. This ensures that the twin can demonstrate decision-making processes in a more intricate manner, particularly when it must evaluate individual critical criteria rather than solely relying on raw data streams. Incorporating domain-specific knowledge, such as the relative importance of prognostic signs or patient comorbidities, into digital twin recommendations ensures that they are consistent with established therapeutic rationale. Instead of adopting a one-size-fits-all approach, oncology digital twins should be created for each type of cancer since tumors evolve and treatments vary. For example, a glioblastoma twin must consider the tumor's dissemination and its responsiveness to radiation therapy, whereas a breast cancer twin would emphasize the functionality of hormone receptors and the malignancy's sensitivity to chemotherapy (14). Conversely, lung cancer twins consider mutational profiles such as EGFR or ALK status when determining targeted therapy options (15). Numerous patient data exist within EHR/EMR systems; nevertheless, the generation of real-time digital twins is challenging due to data silos, inconsistent formatting, absent longitudinal records, and delays in data acquisition. Confronting these difficulties requires the synchronization of data streams, the establishment of interoperability standards, and the assurance of real-time data that is readily available. Contemporary clinical monitoring systems also have challenges in accurately modeling tumor development, medication resistance, and treatment-related toxicity at the individual level. Challenges involve the limited resolution of conventional imaging techniques, insufficient liquid biopsy collection, and inadequate real-time biomarker surveillance, including circulating tumor DNA or PD-L1 fluctuations (21). More precise and dynamic depictions of disease progression and treatment effect are made possible by new technology that are rapidly improving, such as high-frequency wearable biosensors, serial liquid biopsy platforms, and advanced imaging methods.Dynamic digital twins in cancer care, which evolve in response to evolving patient data, are distinct from static ones that only run once. FarrSight®-Twin perpetually integrates novel genetic variants, does repeated whole-slide scans, and incorporates time-stamped clinical events, thereby recalibrating its predictive model with each update topredict the responses of breast cancer patients to treatment and immunotherapy (16). The Stanford–NCI-DOE lung cancer twin integrates follow-up CT images, interval pathology samples, and novel genetic and clinical data through a systematic process. Each update recalibrates the tumor growth and treatment response trajectories, transforming the model from a static representation into a dynamic virtual patient (15). During each MRI session—T1-contrast, T2-FLAIR, and diffusion—the Bayesian engine assimilates the new voxel-level contours and ADC measurements, updates the coefficients for each patient's proliferation, invasion, and radiosensitivity, and subsequently recalculates iso-dose maps and fractionation. This loop transforms the UT Austin glioblastoma twin into a dynamic therapeutic guide, capable of adjusting treatment intensity in response to emerging infiltrative areas or reducing dosage upon confirmation of tumor shrinkage (14). This enables physicians to formulate therapy protocols that are more efficacious in decelerating the disease and mitigating its damage.Technical Foundations of Dynamic Oncology Twins The foundation of every interactive digital twin is a solid data flow. For oncology, this entails combining several patient data sets into a single repository, such as EHRs, lab findings, radiographs (CT, MRI, PET), histopathology reports, liquid biopsies (circulating tumor DNA), and multi-omics datasets (genomics, transcriptomics, proteomics). Complying with established standards is essential for achieving interoperability. These standards include the OMOP Common Data Model for observational health data and the HL7 Fast Healthcare Interchange (FHIR) for clinical and imaging metadata (22). Additionally, automated extraction workflows and streaming APIs guarantee that new patient measurements are transferred into the counterpart with minimal latency, thereby maintaining real-time fidelity to the changing disease state (23). Upon establishment of these streams, Apache Kafka facilitates the real-time transfer of clinical notes, imaging files, and multi-omics results, encapsulated in FHIR, OMOP, DICOMweb, or Phenopackets formats (24). The incoming messages are stored in an RDF database that associates each data point with terms from SNOMED CT, LOINC, OncoKB, and NCIt, followed by the application of a variational auto-encoder to address any gaps (25). Subsequently, modality-specific AI models operate with high efficiency: 3D UNet++ and DenseNet-121 for CT/MRI, a Swin-Transformer for whole-slide images, LoRA-tuned DNABERT-2 for genomic variants, a Temporal Fusion Transformer for irregular lab series, Hetero-GraphSAGE for knowledge graphs, physics-informed networks for tumor growth equations, and a PPO agent that weighs projected survival benefits against toxicity (26). Hybrid models that integrate physics-informed and data-driven approaches utilize multimodal embeddings, including cross-attention early fusion, Bayesian late fusion, and tensor-gated hybrid fusion. They disseminate calibrated uncertainty, enabling approximately 1,000 therapy-rehearsal simulations to conclude in under 1 second, accompanied by median projections and 95% prediction intervals (27).A flexible modeling system that integrates data-driven AI with mechanistic simulations is equally essential. Convolutional neural networks and transformer models can derive predictive characteristics from imaging and genomic sequences, respectively, whereas systems of ordinary and partial differential equations represent tumor development dynamics and drug–tumor interactions (28). Agent-based models mimic microenvironment dynamics and immune-cell infiltration; physics-informed neural networks apply biological limits on acquired representations (29). Generative methods, like variational autoencoders and generative adversarial networks, let you do "what-if" studies by putting together virtual groups of people who would be treated differently.The scenario simulation engines that are built on top of these models serve as platforms for the rehearsal of virtual therapy. The twin predicts important results including tumor shrinkage, resistance emergence, and toxicity profiles by listing potential treatment plans, which may include different medication combinations, dosage regimes, or sequence orders (16). Utilizing reinforcement-learning algorithms allows for the optimization of therapeutic methods in pursuit of multi-objective goals, such as maximizing progression-free survival while minimizing side effects. New patient data is constantly being used by these algorithms to update policy judgments. Lastly, simulation at the point of care must be scalable and have minimal latency, and this can only be achieved with a solid computing foundation.},
  archive      = {J_FRAI},
  author       = {Karaman, Irem and Sebin, Burhan},
  doi          = {10.3389/frai.2025.1624877},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1624877},
  shortjournal = {Front. Artif. Intell.},
  title        = {From data-driven cities to data-driven tumors: Dynamic digital twins for adaptive oncology},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Man vs. machine: Can AI outperform ESL student translations?. <em>FRAI</em>, <em>8</em>, 1624754. (<a href='https://doi.org/10.3389/frai.2025.1624754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study compares the quality of English-to-Arabic translations produced by Google Translate (GT) with those generated by student translators. Despite advancements in neural machine translation technology, educators often remain skeptical about the reliability of AI tools like GT and often discourage their use. To investigate this perception, 20 Saudi university students majoring in English and Translation produced human translations in Arabic. These student-generated translations, along with their GT equivalents, were rated by 22 professors with experience in language-related fields. The analysis revealed a significant preference for GT translations over those produced by students, suggesting that GT’s quality may exceed that of student translators. Interestingly, while GT translations were consistently rated higher, instructors often misattributed the better translations to students and the poorer ones to GT. This reveals a strong perceptual bias against AI-generated translations. The findings support the inclusion of AI-assisted translation tools in translation training. Incorporating these tools will help students prepare for a job market where AI is playing an increasingly important role. At the same time, educators should adopt strategies incorporating AI tools without sacrificing the development of students’ core translation skills.},
  archive      = {J_FRAI},
  author       = {Alkhofi, Anas},
  doi          = {10.3389/frai.2025.1624754},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1624754},
  shortjournal = {Front. Artif. Intell.},
  title        = {Man vs. machine: Can AI outperform ESL student translations?},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the risk of depression in older adults with disability using machine learning: An analysis based on CHARLS data. <em>FRAI</em>, <em>8</em>, 1624171. (<a href='https://doi.org/10.3389/frai.2025.1624171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe advancement of artificial intelligence technologies has opened new avenues for depression prevention and management in older adults with disability (defined by basic or instrumental activities of daily living, BADL/IADL). This study systematically developed machine learning (ML) models to predict depression risk in disabled elderly individuals using longitudinal data from the China Health and Retirement Longitudinal Study (CHARLS), providing a potentially generalizable tool for early screening.MethodsThis study utilized longitudinal data from the CHARLS 2011–2015 cohort. A three-stage serial consensus approach feature selection framework (LASSO, Elastic Net, and Boruta) was employed to identify 21 robust predictors from 74 candidate variables. Ten ML algorithms were evaluated: LR, HistGBM, MLP, XGBoost, bagging, DT, LightGBM, RF, SVM, and CatBoost. Temporal external validation was performed using an independent 2018–2020 cohort to assess model generalizability. Performance was comprehensively evaluated using accuracy, AUC, F1-score, precision, and recall metrics. The SHAP framework was employed to interpret feature contribution mechanisms.ResultsResults demonstrated that the HistGBM model achieved optimal overall performance on the testing sets (AUC = 0.779, F1-score = 0.735, accuracy = 0.713), with only an 8.5% AUC difference between training and testing sets and a 10% difference between external validation and testing sets, indicating temporal stability. SHAP interpretability analysis revealed that sleep time (mean SHAP value = 0.344) in the health behavior domain and life satisfaction (0.339) and episodic memory (0.220) in the subjective perception domain contributed more significantly to prediction than traditional biomedical indicators.ConclusionThis study developed an AI-based tool for depression risk assessment in older adults with disability through a multi-stage feature selection process and a temporal external validation framework. These findings provide a practical screening instrument and a methodological reference for implementing AI technologies in geriatric mental health applications, thereby facilitating clinical translation of predictive analytics in this field.},
  archive      = {J_FRAI},
  author       = {Jin, Tongtong and Halili, Ayitijiang},
  doi          = {10.3389/frai.2025.1624171},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1624171},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting the risk of depression in older adults with disability using machine learning: An analysis based on CHARLS data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying training response in cycling based on cardiovascular drift using machine learning. <em>FRAI</em>, <em>8</em>, 1623384. (<a href='https://doi.org/10.3389/frai.2025.1623384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeThe most important parameter influencing performance in endurance sports is aerobic fitness, the quality of the cardiovascular system for efficient oxygen supply of working muscles to produce mechanical work. Each individual athlete responds differently to training. However, for coaches it is not always easy to see improvement, accumulated fatigue, or overreaching. In the new era of technology, we propose an experimental method using machine learning (ML) to measure response quantified as aerobic fitness level based on cardiovascular drift and aerobic decoupling data.MethodsTwenty well-trained athletes in cycling-based sports performed monthly aerobic fitness tests over five months, riding at 75% of their functional threshold power for 60 min. Based on aerobic decoupling (power-to-heart rate ratio) and cardiovascular drift of each test ride, a prediction model was created using ML (Logistic regression, Variational Gaussian Process models and k-nearest neighbors algorithm) that indicated whether or not an athlete was responding to the training. Athletes were spitted as responders (i.e., those showing improvements in cardiovascular drift and aerobic decoupling) or non-responders.ResultsCardiovascular drift and aerobic decoupling demonstrated a significant strong linear correlation. All ML models achieved good predictive performance in classifying athletes as responders or non-responders, with cross-validation accuracy ranging from 0.87 to 0.9. Average predictive accuracy of 0.86 was for k-nearest neighbors, 0.91 for logistic regression, 0.93 for Variational Gaussian Process model. The Variational Gaussian Process model achieved the highest classification for training response.ConclusionCardiovascular drift and aerobic decoupling are reliable indicators of response to training stimulus. ML is a promising tool for monitoring training response in endurance sports, offering early and sensitive insights into fitness adaptations or fatigue that can support more personalized training decisions for coaches and athletes.},
  archive      = {J_FRAI},
  author       = {Barsumyan, Artur and Shyla, Raman and Saukkonen, Anton and Soost, Christian and Graw, Jan Adriaan and Burchard, Rene},
  doi          = {10.3389/frai.2025.1623384},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1623384},
  shortjournal = {Front. Artif. Intell.},
  title        = {Quantifying training response in cycling based on cardiovascular drift using machine learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward standardization of GenAI-driven agentic architectures for radio access networks. <em>FRAI</em>, <em>8</em>, 1621963. (<a href='https://doi.org/10.3389/frai.2025.1621963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of Generative Artificial Intelligence (GenAI) in Radio Access Networks (RAN) presents new opportunities for automation and intelligence across network operations. GenAI-powered agents, leveraging Large Language Models (LLMs), can enhance planning, execution, and decision-making for orchestration and real-time optimisation of 6G networks. Standardizing the implementation of the Agentic architecture for RAN is now essential to establish a unified framework for RANOps and AgentOps. One of the key challenges is to develop a blueprint that incorporates best practices for memory integration, tool generation, multi-agent orchestration, and performance benchmarking. This study highlights key areas requiring standardization, including agent tool specifications, RAN-specific LLM fine-tuning, validation frameworks, and AI-friendly documentation. We propose a dedicated research initiative on GenAI-for-RAN and GenAI-on-RAN to address these gaps and advance AI-driven network automation.},
  archive      = {J_FRAI},
  author       = {Nezami, Zeinab and Zaidi, Syed Ali Raza and Hafeez, Maryam and Xu, Jie and Djemame, Karim},
  doi          = {10.3389/frai.2025.1621963},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1621963},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward standardization of GenAI-driven agentic architectures for radio access networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based strategies for improving healthcare data quality: An evaluation of accuracy, completeness, and reusability. <em>FRAI</em>, <em>8</em>, 1621514. (<a href='https://doi.org/10.3389/frai.2025.1621514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare data quality is a critical factor in clinical decision-making, diagnostic accuracy, and the overall efficacy of healthcare systems. This study addresses key challenges such as missing values and anomalies in healthcare datasets, which can result in misdiagnoses and inefficient resource use. The objective is to develop and evaluate a machine learning-based strategy to improve healthcare data quality, with a focus on three core dimensions: accuracy, completeness, and reusability. A publicly available diabetes dataset comprising 768 records and 9 variables was used. The methodology involved a comprehensive data preprocessing workflow, including data acquisition, cleaning, and exploratory analysis using established Python tools. Missing values were addressed using K-nearest neighbors imputation, while anomaly detection was performed using ensemble techniques. Principal Component Analysis (PCA) and correlation analysis were applied to identify key predictors of diabetes, such as Glucose, BMI, and Age. The results showed significant improvements in data completeness (from 90.57% to nearly 100%), better accuracy by mitigating anomalies, and enhanced reusability for downstream machine learning tasks. In predictive modeling, Random Forest outperformed LightGBM, achieving an accuracy of 75.3% and an AUC of 0.83. The process was fully documented, and reproducibility tools were integrated to ensure the methodology could be replicated and extended. These findings demonstrate the potential of machine learning to support robust data quality improvement frameworks in healthcare, ultimately contributing to better clinical outcomes and predictive capabilities.},
  archive      = {J_FRAI},
  author       = {Jarmakovica, Agate},
  doi          = {10.3389/frai.2025.1621514},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1621514},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning-based strategies for improving healthcare data quality: An evaluation of accuracy, completeness, and reusability},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence and machine learning in the development of vaccines and immunotherapeutics—yesterday, today, and tomorrow. <em>FRAI</em>, <em>8</em>, 1620572. (<a href='https://doi.org/10.3389/frai.2025.1620572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of vaccines and immunotherapies against infectious diseases and cancers has been one of the significant achievements of medical science in the last century. Subunit vaccines offer key advantages over whole-inactivated or attenuated-pathogen-based vaccines, as they elicit more specific B-and T-cell responses with improved safety, immunogenicity, and protective efficacy. However, developing subunit vaccines is often cost-and time-consuming. In the past, the development of vaccines and immunotherapeutics relied heavily on trial-and-error experimentation, as well as extensive and costly in vivo testing, which typically required years of pre-clinical and clinical trials. Today, artificial intelligence (AI) and deep learning (DL) are actively transforming vaccine and immunotherapeutic research by (i) offering predictive frameworks that support rapid, data-driven decision-making, (ii) integrating computational models, systems vaccinology, and multi-omics data (iii) helping to better phenotype, differentiate, and classify patients diseases and cancers; (iv), integrating host characteristics for tailored vaccines and immunotherapeutics; (v) refining the selection of B-and T-cell antigen/epitope targets to enhance efficacy and durability of immune protection; and (vi) enabling a deeper understanding of immune regulation, immune evasion, and regulatory pathways. Artificial intelligence and DL are pushing the boundaries toward (i) the potential replacement of animal preclinical testing of vaccines and immunotherapeutics with computational-based models, as recently proposed by the United States NIH and FDA, and (ii) improving clinical trials by enabling real-time modeling for immune-bridging, predicting patients’ immune responses, safety, and protective efficacy to vaccines and immunotherapeutics. In this review, we describe the past and current applications of AI and DL as time-and resource-efficient strategies and discuss future challenges in implementing AI and DL as new transformative fields that may facilitate the rapid development of precision and personalized vaccines and immunotherapeutics for infectious diseases and cancers.},
  archive      = {J_FRAI},
  author       = {Elfatimi, Elhoucine and Lekbach, Yassir and Prakash, Swayam and BenMohamed, Lbachir},
  doi          = {10.3389/frai.2025.1620572},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1620572},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence and machine learning in the development of vaccines and immunotherapeutics—yesterday, today, and tomorrow},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable approach for identifying acute lymphoblastic leukemia in microscopic imaging. <em>FRAI</em>, <em>8</em>, 1620252. (<a href='https://doi.org/10.3389/frai.2025.1620252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia is a deadly disease, and the patient’s recovery rate is very dependent on early diagnosis. However, its diagnosis under the microscope is tedious and time-consuming. The advancement of deep convolutional neural networks (CNNs) in image classification has enabled new techniques in automated disease detection systems. These systems serve as valuable support and secondary opinion resources for laboratory technicians and hematologists when diagnosing leukemia through microscopic examination. In this study, we deployed a pre-trained CNN model (MobileNet) that has a small size and low complexity, making it suitable for mobile applications and embedded systems. We used the L1 regularization method and a novel dataset balancing approach, which incorporates HSV color transformation, saturation elimination, Gaussian noise addition, and several established augmentation techniques, to prevent model overfitting. The proposed model attained an accuracy of 95.33% and an F1 score of 0.95 when evaluated on the held-out test set extracted from the C_NMC_2019 public dataset. We also evaluated the proposed model by adding zero-mean Gaussian noise to the test images. The experimental results indicate that the proposed model is both efficient and robust, even when subjected to additional Gaussian noise. The comparison of the proposed MobileNet_M model’s results with those of ALNet and various other existing models on the same dataset underscores its superior efficacy. The code is available for reproducing the experimental results at https://tamaslevente.github.io/ALLM/.},
  archive      = {J_FRAI},
  author       = {Makem, Mimosette and Tamas, Levente and Bușoniu, Lucian},
  doi          = {10.3389/frai.2025.1620252},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1620252},
  shortjournal = {Front. Artif. Intell.},
  title        = {A reliable approach for identifying acute lymphoblastic leukemia in microscopic imaging},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multidimensional comparison of ChatGPT, google translate, and DeepL in chinese tourism texts translation: Fidelity, fluency, cultural sensitivity, and persuasiveness. <em>FRAI</em>, <em>8</em>, 1619489. (<a href='https://doi.org/10.3389/frai.2025.1619489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study systematically compares the translation performance of ChatGPT, Google Translate, and DeepL on Chinese tourism texts, focusing on two prompt-engineering strategies. Using a mixed-methods approach that combines quantitative expert assessments with qualitative analysis, the evaluation centers on fidelity, fluency, cultural sensitivity, and persuasiveness. ChatGPT outperformed its counterparts across all metrics, especially when culturally tailored prompts were used. However, it occasionally introduced semantic shifts, highlighting a trade-off between accuracy and rhetorical adaptation. Despite its strong performance, human post-editing remains necessary to ensure semantic precision and professional standards. The study demonstrates ChatGPT’s potential in domain-specific translation tasks while calling for continued oversight in culturally nuanced content.},
  archive      = {J_FRAI},
  author       = {Chen, Shiyue and Lin, Yan},
  doi          = {10.3389/frai.2025.1619489},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1619489},
  shortjournal = {Front. Artif. Intell.},
  title        = {A multidimensional comparison of ChatGPT, google translate, and DeepL in chinese tourism texts translation: Fidelity, fluency, cultural sensitivity, and persuasiveness},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ethical-legal implications of AI-powered healthcare in critical perspective. <em>FRAI</em>, <em>8</em>, 1619463. (<a href='https://doi.org/10.3389/frai.2025.1619463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing utilization of Artificial Intelligence (AI) systems in the field of healthcare, from diagnosis to medical decision making and patient care, necessitates identification of its potential benefits, risks and challenges. This requires an appraisal of AI use from a legal and ethical perspective. A review of the existing literature on AI in healthcare available on PubMed, Oxford Academic and Scopus revealed several common concerns regarding the relationship between AI, ethics, and healthcare—(i) the question of data: the choices inherent in collection, analysis, interpretation, and deployment of data inputted to and outputted by AI systems; (ii) the challenges to traditional patient-doctor relationships and long-held assumptions about privacy, identity and autonomy, as well as to the functioning of healthcare institutions. The potential benefits of AI’s application need to be balanced against the legal-ethical issues emanating from its use—bias, consent, access, privacy and cost—to guard against detrimental effects of uncritical AI use. The authors suggest that a legal framework for AI should adopt a critical and grounded perspective—cognizant of the material political realities of AI and its wider impact on more marginalized communities. The largescale utilization of health datasets often without consent, responsibility or accountability, further necessitates regulation in the field of technology design, given the entwined nature of AI research with advancements in wearables and sensor technology. Taking into account the ‘superhuman’ and ‘subhuman’ traits of AI, regulation should aim to encourage the development of AI systems that augment rather than outrightly replace human effort.},
  archive      = {J_FRAI},
  author       = {Nasir, Mohammad and Siddiqui, Kaif and Ahmed, Samreen},
  doi          = {10.3389/frai.2025.1619463},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1619463},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ethical-legal implications of AI-powered healthcare in critical perspective},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ethical theories, governance models, and strategic frameworks for responsible AI adoption and organizational success. <em>FRAI</em>, <em>8</em>, 1619029. (<a href='https://doi.org/10.3389/frai.2025.1619029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) becomes integral to organizational transformation, ethical adoption has emerged as a strategic concern. This paper reviews ethical theories, governance models, and implementation strategies that enable responsible AI integration in business contexts. It explores how ethical theories such as utilitarianism, deontology, and virtue ethics inform practical models for AI deployment. Furthermore, the paper investigates governance structures and stakeholder roles in shaping accountability and transparency, and examines frameworks that guide strategic risk assessment and decision-making. Emphasizing real-world applicability, the study offers an integrated approach that aligns ethics with performance outcomes, contributing to organizational success. This synthesis aims to support firms in embedding responsible AI principles into innovation strategies that balance compliance, trust, and value creation.},
  archive      = {J_FRAI},
  author       = {Madanchian, Mitra and Taherdoost, Hamed},
  doi          = {10.3389/frai.2025.1619029},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1619029},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ethical theories, governance models, and strategic frameworks for responsible AI adoption and organizational success},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-assisted anatomical structure recognition and segmentation via mamba-transformer architecture in abdominal ultrasound images. <em>FRAI</em>, <em>8</em>, 1618607. (<a href='https://doi.org/10.3389/frai.2025.1618607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAbdominal ultrasonography is a primary diagnostic tool for evaluating medical conditions within the abdominal cavity. Accurate determination of the relative locations of intra-abdominal organs and lesions based on anatomical features in ultrasound images is essential in diagnostic sonography. Recognizing and extracting anatomical landmarks facilitates lesion evaluation and enhances diagnostic interpretation. Recent artificial intelligence (AI) segmentation methods employing deep neural networks (DNNs) and transformers encounter computational efficiency challenges to balance the preservation of feature dependencies information with model efficiency, limiting their clinical applicability.MethodsThe anatomical structure recognition framework, MaskHybrid, was developed using a private dataset comprising 34,711 abdominal ultrasound images of 2,063 patients from CSMUH. The dataset included abdominal organs and vascular structures (hepatic vein, inferior vena cava, portal vein, gallbladder, kidney, pancreas, spleen) and liver lesions (hepatic cyst, tumor). MaskHybrid adopted a mamba-transformer hybrid architecture consisting of an evolved backbone network, encoder, and corresponding decoder to capture long-range spatial dependencies and contextual information effectively, demonstrating improved image segmentation capabilities in visual tasks while mitigating the computational burden associated with the transformer-based attention mechanism.ResultsExperiments on the retrospective dataset achieved a mean average precision (mAP) score of 74.13% for anatomical landmarks segmentation in abdominal ultrasound images. Our proposed framework outperformed baselines across most organ and lesion types and effectively segmented challenging anatomical structures. Moreover, MaskHybrid exhibited a significantly shorter inference time (0.120 ± 0.013 s), achieving 2.5 times faster than large-sized AI models of similar size. Combining Mamba and transformer architectures, this hybrid design was well-suited for the timely analysis of complex anatomical structures segmentation in abdominal ultrasonography, where accuracy and efficiency are critical in clinical practice.ConclusionThe proposed mamba-transformer hybrid recognition framework simultaneously detects and segments multiple abdominal organs and lesions in ultrasound images, achieving superior segmentation accuracy, visualization effect, and inference efficiency, thereby facilitating improved medical image interpretation and near real-time diagnostic sonography that meets clinical needs.},
  archive      = {J_FRAI},
  author       = {Chang, Shih-Fang and Wu, Po-Yi and Tsai, Ming-Chang and Tseng, Vincent S. and Wang, Chi-Chih},
  doi          = {10.3389/frai.2025.1618607},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1618607},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-assisted anatomical structure recognition and segmentation via mamba-transformer architecture in abdominal ultrasound images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thyroid nodule segmentation in ultrasound images using transformer models with masked autoencoder pre-training. <em>FRAI</em>, <em>8</em>, 1618426. (<a href='https://doi.org/10.3389/frai.2025.1618426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThyroid nodule segmentation in ultrasound (US) images is a valuable yet challenging task, playing a critical role in diagnosing thyroid cancer. The difficulty arises from factors such as the absence of prior knowledge about the thyroid region, low contrast between anatomical structures, and speckle noise, all of which obscure boundary detection and introduce variability in nodule appearance across different images.MethodsTo address these challenges, we propose a transformer-based model for thyroid nodule segmentation. Unlike traditional convolutional neural networks (CNNs), transformers capture global context from the first layer, enabling more comprehensive image representation, which is crucial for identifying subtle nodule boundaries. In this study, We first pre-train a Masked Autoencoder (MAE) to reconstruct masked patches, then fine-tune on thyroid US data, and further explore a cross-attention mechanism to enhance information flow between encoder and decoder.ResultsOur experiments on the public AIMI, TN3K, and DDTI datasets show that MAE pre-training accelerates convergence. However, overall improvements are modest: the model achieves Dice Similarity Coefficient (DSC) scores of 0.63, 0.64, and 0.65 on AIMI, TN3K, and DDTI, respectively, highlighting limitations under small-sample conditions. Furthermore, adding cross-attention did not yield consistent gains, suggesting that data volume and diversity may be more critical than additional architectural complexity.DiscussionMAE pre-training notably reduces training time and helps themodel learn transferable features, yet overall accuracy remains constrained by limited data and nodule variability. Future work will focus on scaling up data, pre-training cross-attention layers, and exploring hybrid architectures to further boost segmentation performance.},
  archive      = {J_FRAI},
  author       = {Xiang, Yi and Acharya, Rajendra and Le, Quan and Tan, Jen Hong and Chng, Chiaw-Ling},
  doi          = {10.3389/frai.2025.1618426},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1618426},
  shortjournal = {Front. Artif. Intell.},
  title        = {Thyroid nodule segmentation in ultrasound images using transformer models with masked autoencoder pre-training},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deriving equivalent symbol-based decision models from feedforward neural networks. <em>FRAI</em>, <em>8</em>, 1618149. (<a href='https://doi.org/10.3389/frai.2025.1618149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has emerged as a transformative force across industries, driven by advances in deep learning and natural language processing, and fueled by large-scale data and computing resources. Despite its rapid adoption, the opacity of AI systems poses significant challenges to trust and acceptance. This work explores the intersection of connectionist and symbolic approaches to artificial intelligence, focusing on the derivation of interpretable symbolic models, such as decision trees, from feedforward neural networks (FNNs). Decision trees provide a transparent framework for elucidating the operations of neural networks while preserving their functionality. The derivation is presented in a step-by-step approach and illustrated with several examples. A systematic methodology is proposed to bridge neural and symbolic paradigms by exploiting distributed representations in FNNs to identify symbolic components, including fillers, roles, and their interrelationships. The process traces neuron activation values and input configurations across network layers, mapping activations and their underlying inputs to decision tree edges. The resulting symbolic structures effectively capture FNN decision processes and enable scalability to deeper networks through iterative refinement of subpaths for each hidden layer. To validate the theoretical framework, a prototype was developed using Keras .h5-data and emulating TensorFlow within the Java JDK/JavaFX environment. This prototype demonstrates the feasibility of extracting symbolic representations from neural networks, enhancing trust in AI systems, and promoting accountability.},
  archive      = {J_FRAI},
  author       = {Seidel, Sebastian and Borghoff, Uwe M.},
  doi          = {10.3389/frai.2025.1618149},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1618149},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deriving equivalent symbol-based decision models from feedforward neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-resolution image inpainting using a probabilistic framework for diverse images with large arbitrary masks. <em>FRAI</em>, <em>8</em>, 1614608. (<a href='https://doi.org/10.3389/frai.2025.1614608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing inpainting challenges in high-resolution images remains a complex task. The most recent image inpainting techniques rely on machine learning models; however, a major limitation of supervised methods is their dependence on end-to-end training. Even minor changes to the input often necessitate retraining, making the process inefficient. As a result, unsupervised learning approaches have gained prominence in image inpainting. State-of-the-art methods, particularly those using generative adversarial networks (GANs), have achieved promising results. However, generating photorealistic outputs for high-resolution images with arbitrary large-region masks remains difficult. Inpainted images often suffer from deformed structures and blurry textures, compromising quality. Additionally, building a model capable of handling a diverse range of images presents further challenges. These challenges are addressed by proposing a novel probabilistic model that utilizes picture priors to learn prominent features within StyleGAN3. The priors are constructed using cosine similarity, mean, and intensity, where intensity is computed using the improved Papoulis–Gerchberg algorithm. The image is reconstructed using the probabilistic maximum a posteriori estimate. Variational inference is then applied to obtain the optimal solution using a modified Bayes-by-Backprop approach. The model is evaluated on 70,000 images from the Flickr-Faces-HQ, DIV2K, and brain datasets and surpasses state-of-the-art techniques in reconstruction quality.},
  archive      = {J_FRAI},
  author       = {Sumathi, G. and Uma Devi, M.},
  doi          = {10.3389/frai.2025.1614608},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1614608},
  shortjournal = {Front. Artif. Intell.},
  title        = {High-resolution image inpainting using a probabilistic framework for diverse images with large arbitrary masks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional visualization and navigation for micro-noninvasive uterine fibroid surgery based on MRI and ultrasound image fusion. <em>FRAI</em>, <em>8</em>, 1613960. (<a href='https://doi.org/10.3389/frai.2025.1613960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveTo address the challenges of low surgical precision and poor consistency in focused ultrasound ablation surgery (FUAS) for uterine fibroids, which are often caused by variations in clinical experience and operator fatigue, this study aims to develop an intelligent three-dimensional (3D) visualization and navigation system by integrating magnetic resonance imaging (MRI) with real-time ultrasound (US) imaging, thereby improving the accuracy and efficiency of uterine fibroid surgery.MethodsMRI and US images from 638 patients were annotated by experienced clinicians. The nnU-Net algorithm was used for preoperative segmentation and 3D reconstruction of MRI images to provide detailed visualization of fibroid morphology. The YOLACT model was applied to achieve rapid delineation of the uterus and key anatomical structures in real-time US images. To enhance the accuracy of lesion localization and navigation, the Iterative Closest Point (ICP) algorithm was employed for the registration of preoperative MRI with intraoperative US images.Results and discussionExperimental results demonstrated that the system achieved a Dice Similarity Coefficient (DSC) exceeding 90% for the segmentation and identification of anatomical structures such as the uterus and fibroids. The YOLACT model achieved an accuracy greater than 95% in identifying key structures in real-time US images. In 90% of the cases, the system enabled efficient and precise tracking; however, approximately 5% of the cases required manual adjustment due to discrepancies between patient anatomy and preoperative MRI data. The proposed intelligent navigation system, based on MRI–US image fusion, offers an efficient and automated solution for FUAS in treating uterine fibroids, significantly improving surgical precision and operational efficiency. This system demonstrates strong clinical applicability. Future research will focus on enhancing the adaptability of the system, particularly in addressing challenges such as significant tissue deformation and occlusion, to improve its robustness and applicability in complex clinical scenarios.},
  archive      = {J_FRAI},
  author       = {Wang, Ting and Wen, Yingang and Wang, Zhibiao and Li, Xi},
  doi          = {10.3389/frai.2025.1613960},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1613960},
  shortjournal = {Front. Artif. Intell.},
  title        = {Three-dimensional visualization and navigation for micro-noninvasive uterine fibroid surgery based on MRI and ultrasound image fusion},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating ethical minefields: A multi-stakeholder approach to assessing interconnected risks in generative AI using grey DEMATEL. <em>FRAI</em>, <em>8</em>, 1611024. (<a href='https://doi.org/10.3389/frai.2025.1611024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of generative artificial intelligence (AI) technologies has introduced unprecedented capabilities in content creation and human-AI interaction, while simultaneously raising significant ethical concerns. This study examined the complex landscape of ethical risks associated with generative AI (GAI) through a novel multi-stakeholder empirical analysis using the grey decision-making-trial-and-evaluation-laboratory methodology to quantitatively analyze the causal relationships between risks and their relative influence on AI deployment outcomes. Through a comprehensive literature review and expert validation across three key stakeholder groups (AI developers, end users, and policymakers), we identified and analyzed 14 critical ethical challenges across the input, training, and output modules, including both traditional and emerging risks, such as deepfakes, intellectual property rights, data transparency, and algorithmic bias. This study analyzed the perspectives of key stakeholders to understand how ethical risks are perceived, prioritized, and interconnected in practice. Using Euclidean-distance analysis, we identified significant divergences in risk perception among stakeholders, particularly in areas of adversarial prompts, data bias, and output bias. Our findings contribute to the development of a balanced ethical risk framework by categorizing risks into four distinct zones: critical enablers, mild enablers, independent enablers, and critical dependents. This categorization promotes technological advancement and responsible AI deployment. This study addressed the current gaps in academic work by providing actionable recommendations for risk-mitigation strategies and policy development while highlighting the need for collaborative approaches among stakeholders in the rapidly evolving field of GAI.},
  archive      = {J_FRAI},
  author       = {Jonnala, Sridhar and Thomas, Nisha Mary and Mishra, Sarthak},
  doi          = {10.3389/frai.2025.1611024},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1611024},
  shortjournal = {Front. Artif. Intell.},
  title        = {Navigating ethical minefields: A multi-stakeholder approach to assessing interconnected risks in generative AI using grey DEMATEL},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual human-robot understanding for a robot-enhanced society: The crucial development of shared embodied cognition. <em>FRAI</em>, <em>8</em>, 1608014. (<a href='https://doi.org/10.3389/frai.2025.1608014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conception of autonomous, intelligent, collaborative robots has been the subject of science fiction rather than science in the second half of the previous century, with practical applications limited to industrial machines without any level of autonomous, intelligent, and collaborative capacity. The new century is facing the challenge of pressing industrial and social revolutions (4, 5, 6, …) with the prospect of infiltrating robots in every sector of human society; however, this dissemination will be possible if and only if acceptable degrees of autonomy, intelligence, and collaborative capacity can be achieved. Scientific and technological innovations are needed within a highly multidisciplinary framework, with a critical integration strategy and functional characterization that must ask a fundamental question: the design of autonomous, intelligent, collaborative robots should aim at a unified single template to be mass-produced including a standard setup procedure for the functional adaptation of any single prototype, or should the design aim at “baby” robots with a minimal set of sensory-motor-cognitive capabilities as the starting point of a training and educational process in close connection with human companions (masters, partners, final users)? The former alternative is supported by EAI, i.e., the Embodied variant of the Artificial Intelligence family of computational tools based on large foundation models. The latter alternative is bio-inspired; namely, it attempts to replicate the computational structure of Embodied Cognitive Science. Both formulations imply embodiment as a core issue. Still, we think this concept has a markedly different meaning and practical implications in the two cases, although we are still far away from the practical implementations of either roadmap. In this opinion paper, we explain why we think the bio-inspired approach is better than the EAI approach in providing a feasible roadmap for developing autonomous, intelligent, collaborative robots. In particular, we focus on the importance of collaborative human-robot interactions conceived in a general sense, ranging from haptic interactions in joint physical efforts (e.g., loading/unloading) to cognitive interactions for joint strategic planning of complex tasks. We envision this type of collaboration only made possible by a deep human-robot mutual understanding based on a structural equivalence of their embodied cognitive architecture, based on an active, first-person acquisition of experience rather than a passive download of third-person knowledge.},
  archive      = {J_FRAI},
  author       = {Sandini, Giulio and Sciutti, Alessandra and Morasso, Pietro},
  doi          = {10.3389/frai.2025.1608014},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1608014},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mutual human-robot understanding for a robot-enhanced society: The crucial development of shared embodied cognition},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outliers and anomalies in training and testing datasets for AI-powered morphometry—evidence from CT scans of the spleen. <em>FRAI</em>, <em>8</em>, 1607348. (<a href='https://doi.org/10.3389/frai.2025.1607348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionCreating training and testing datasets for machine learning algorithms to measure linear dimensions of organs is a tedious task. There are no universally accepted methods for evaluating outliers or anomalies in such datasets. This can cause errors in machine learning and compromise the quality of end products. The goal of this study is to identify optimal methods for detecting organ anomalies and outliers in medical datasets designed to train and test neural networks in morphometrics.MethodsA dataset was created containing linear measurements of the spleen obtained from CT scans. Labelling was performed by three radiologists. The total number of studies included in the sample was N = 197 patients. Using visual methods (1.5 interquartile range; heat map; boxplot; histogram; scatter plot), machine learning algorithms (Isolation forest; Density-Based Spatial Clustering of Applications with Noise; K-nearest neighbors algorithm; Local outlier factor; One-class support vector machines; EllipticEnvelope; Autoencoders), and mathematical statistics (z-score, Grubb’s test; Rosner’s test).ResultsWe identified measurement errors, input errors, abnormal size values and non-standard shapes of the organ (sickle-shaped, round, triangular, additional lobules). The most effective methods included visual techniques (including boxplots and histograms) and machine learning algorithms such is OSVM, KNN and autoencoders. A total of 32 outlier anomalies were found.DiscussionCuration of complex morphometric datasets must involve thorough mathematical and clinical analyses. Relying solely on mathematical statistics or machine learning methods appears inadequate.},
  archive      = {J_FRAI},
  author       = {Vasilev, Yuriy and Pamova, Anastasia and Bobrovskaya, Tatiana and Vladzimirskyy, Anton and Omelyanskaya, Olga and Astapenko, Elena and Kruchinkin, Artem and Vladimir, Novik and Arzamasov, Kirill},
  doi          = {10.3389/frai.2025.1607348},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1607348},
  shortjournal = {Front. Artif. Intell.},
  title        = {Outliers and anomalies in training and testing datasets for AI-powered morphometry—evidence from CT scans of the spleen},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on the use of multicriteria decision making methods for small and medium-sized enterprises innovation assessment. <em>FRAI</em>, <em>8</em>, 1605756. (<a href='https://doi.org/10.3389/frai.2025.1605756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria decision making (MCDM) methods are essential tools for assessing multiple factors in various contexts, including innovation in small and medium-sized enterprises (SMEs). In this study, a systematic literature review (SLR) was conducted based on a literature search in Web of Science, Scopus and Google Scholar, covering the period 2018–2024, taking as a basis the general guidelines and main phases of an SLR, in addition, the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) method was used, which allowed the selection of 25 relevant articles. From the analysis, four main trends in innovation assessment were identified: Innovation Capacity and Business Strategies, Open Innovation, Evaluation and Management, Technological and Digital Innovation, and Green Innovation and Sustainability. The results indicate that India and China are the countries with the highest volume of publications on this topic, while the business and academic sectors are the most studied, followed by the social sector. In addition, other key factors assessed in SMEs using MCDM methods were identified, grouped into five main themes including industry 4.0 and digital transformation, sustainability and green manufacturing, risk management and business resilience, decision making in trade and markets, and business management strategies and technology selection, broken down into 11 specific approaches. The review shows that assessing innovation in SMEs requires a multidisciplinary and collaborative approach tailored to business needs. It also shows a preference for fuzzy tools and the combination of different MCDM methods. This article provides an updated diagnosis on the use of multiple criteria in the innovation assessment in SMEs, providing a basis for future research and applications in this field.},
  archive      = {J_FRAI},
  author       = {Rodríguez-Carrillo, Mayra Leticia and Pérez-Domínguez, Luis and Romero-López, Roberto and Luviano-Cruz, David and León-Castro, Ernesto},
  doi          = {10.3389/frai.2025.1605756},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1605756},
  shortjournal = {Front. Artif. Intell.},
  title        = {A systematic literature review on the use of multicriteria decision making methods for small and medium-sized enterprises innovation assessment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contestable AI for criminal intelligence analysis: Improving decision-making through semantic modeling and human oversight. <em>FRAI</em>, <em>8</em>, 1602998. (<a href='https://doi.org/10.3389/frai.2025.1602998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Criminal investigation analysis involves processing large amounts of data, making manual analysis impractical. Artificial intelligence (AI)-driven information extraction systems can assist investigators in handling this data, leading to significant improvements in effectiveness and efficiency. However, the use of AI in criminal investigations also poses significant risks to individuals, requiring the integration of contestability into systems and processes. To meet this challenge, contestability requirements must be tailored to specific contexts. In this work, we analyzed and adapted existing requirements for criminal investigation analysis, focusing on the retrospective analysis of police reports. For this purpose, we introduced a novel information extraction pipeline based on three language modeling tasks, which we refer to as semantic modeling. Building on this concept, we evaluated contestability requirements and integrated them into our system. As a proof of concept, we developed an AI-driven information extraction system that incorporates contestability features and provides multiple functionalities for data analysis. Our findings highlight three key perspectives essential for contestability in AI-driven investigations: information provision, interactive controls, and quality assurance. This work contributes to the development of more transparent, accountable, and adaptable AI systems for law enforcement applications.},
  archive      = {J_FRAI},
  author       = {Maoro, Falk and Geierhos, Michaela},
  doi          = {10.3389/frai.2025.1602998},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1602998},
  shortjournal = {Front. Artif. Intell.},
  title        = {Contestable AI for criminal intelligence analysis: Improving decision-making through semantic modeling and human oversight},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From digital traces to public vaccination behaviors: Leveraging large language models for big data classification. <em>FRAI</em>, <em>8</em>, 1602984. (<a href='https://doi.org/10.3389/frai.2025.1602984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe current study leverages large language models (LLMs) to capture health behaviors expressed in social media posts, focusing on COVID-19 vaccine-related content from 2020 to 2021.MethodsTo examine the capabilities of prompt engineering and fine-tuning approaches with LLMs, this study examines the performance of three state-of-the-art LLMs: GPT-4o, GPT-4o-mini, and GPT-4o-mini with fine-tuning, focusing on their ability to classify individuals’ vaccination behavior, intention to vaccinate, and information sharing. We then cross-validate these classifications with nationwide vaccination statistics to assess alignment with observed trends.ResultsGPT-4o-mini with fine-tuning outperformed both GPT-4o and the standard GPT-4o-mini in terms of accuracy, precision, recall, and F1 score. Using GPT-4o-mini with fine-tuning for classification, about 9.84% of the posts (N = 36,912) included personal behavior related to getting the COVID-19 vaccine while a majority of posts (71.45%; N = 267,930) included information sharing about the virus. Lastly, we found a strong correlation (r = 0.76, p < 0.01) between vaccination behaviors expressed on social media and the actual vaccine uptake over time.DiscussionThis study suggests that LLMs can serve as powerful tools for estimating real-world behaviors. Methodological and practical implications of utilizing LLMs in human behavior research are further discussed.},
  archive      = {J_FRAI},
  author       = {Oh, Yoo Jung and Rasul, Muhammad Ehab and McKinley, Emily and Calabrese, Christopher},
  doi          = {10.3389/frai.2025.1602984},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1602984},
  shortjournal = {Front. Artif. Intell.},
  title        = {From digital traces to public vaccination behaviors: Leveraging large language models for big data classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy system for detection of road slipperiness in arctic snowy conditions using LiDAR. <em>FRAI</em>, <em>8</em>, 1600174. (<a href='https://doi.org/10.3389/frai.2025.1600174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of self-driving cars has significantly improved transportation by enhancing safety, efficiency, and mobility. However, their operation in Arctic environments remains challenging due to snow, ice, and slush, which negatively impact traction and road surface perception. To address these challenges, this study integrates LiDAR-based reflected intensity measurements with environmental parameters such as humidity, temperature, and the coefficient of friction to detect road surface slipperiness and roughness. A Fuzzy Logic System is developed to process these features and classify the slipperiness levels. The analysis establishes a strong correlation between LiDAR intensity and the coefficient of friction, enabling reliable detection of surface conditions. The proposed method achieves a testing accuracy of 87% in classifying road slipperiness under Arctic conditions. These findings demonstrate the effectiveness of LiDAR and sensor fusion for real-time road condition monitoring and highlight their potential in enhancing the safety and performance of autonomous vehicles in extreme weather environments.},
  archive      = {J_FRAI},
  author       = {Rahim, Aqsa and Dhar, Sushmit and Yuan, Fuqing and Barabady, Javad},
  doi          = {10.3389/frai.2025.1600174},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1600174},
  shortjournal = {Front. Artif. Intell.},
  title        = {A fuzzy system for detection of road slipperiness in arctic snowy conditions using LiDAR},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMDMamba: Dual-layer mamba architecture with dual convolutional feed-forward networks for efficient financial time series forecasting. <em>FRAI</em>, <em>8</em>, 1599799. (<a href='https://doi.org/10.3389/frai.2025.1599799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTransformer models have demonstrated remarkable performance in financial time series forecasting. However, they suffer from inefficiencies in computational efficiency, high operational costs, and limitations in capturing temporal dependencies.MethodsTo address these challenges, we propose the CMDMamba model, which is based on the Mamba architecture of state-space models (SSMs) and achieves near-linear time complexity. This significantly enhances the real-time data processing capability and reduces the deployment costs for risk management systems. The CMDMamba model employs a dual-layer Mamba structure that effectively captures price fluctuations at both the micro- and macrolevels in financial markets and integrates an innovative Dual Convolutional Feedforward Network (DconvFFN) module. This module is able to effectively capture the correlations between multiple variables in financial markets. By doing so, it provides more accurate time series modeling, optimizes algorithmic trading strategies, and facilitates investment portfolio risk warnings.ResultsExperiments conducted on four real-world financial datasets demonstrate that CMDMamba achieves a 10.4% improvement in prediction accuracy for multivariate forecasting tasks compared to state-of-the-art models.DiscussionMoreover, CMDMamba excels in both predictive accuracy and computational efficiency, setting a new benchmark in the field of financial time series forecasting.},
  archive      = {J_FRAI},
  author       = {Qin, Zhenkai and Wei, Baozhong and Zhai, Yujia and Lin, Ziqian and Yu, Xiaochuan and Jiang, Jingxuan},
  doi          = {10.3389/frai.2025.1599799},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1599799},
  shortjournal = {Front. Artif. Intell.},
  title        = {CMDMamba: Dual-layer mamba architecture with dual convolutional feed-forward networks for efficient financial time series forecasting},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in the tourism business: A systematic review. <em>FRAI</em>, <em>8</em>, 1599391. (<a href='https://doi.org/10.3389/frai.2025.1599391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the tourism sector, AI has been gradually integrated to optimize operations, personalize customer experiences, and improve resource management, thereby transforming the way companies operate and connect with travelers. The aim of this re-search is to explore the application of AI in the tourism industry, identifying the main AI technologies used in the business, the specific areas or processes, their benefits, and challenges. For this purpose, a systematic literature review methodology was used, following PRISMA guidelines, from which 112 primary studies were obtained that contributed to answering the research questions. The main findings indicate that, in the tourism industry, the most commonly used AI technologies include Natural Language Processing (NLP) and deep learning with Neural Networks, with chatbots and models such as CNNs and LSTMs being particularly prominent. These technologies facilitate everything from the automation of interactions (such as bookings and customer service) to advanced data analysis for the personalization of services and strategic decisions, demonstrating their broad applicability and benefit in the sector. However, multiple challenges are also identified, ranging from high costs and advanced technological infrastructure to ethical and privacy concerns. Therefore, for proper implementation of AI in the tourism sector, it is crucial to carefully manage both the benefits and challenges to ensure its success.},
  archive      = {J_FRAI},
  author       = {López-Naranjo, Alexandra Lorena and Puente-Riofrio, Mariana Isabel and Carrasco-Salazar, Verónica Adriana and Erazo-Rodríguez, Juan Diego and Buñay-Guisñan, Pamela Alexandra},
  doi          = {10.3389/frai.2025.1599391},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1599391},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence in the tourism business: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for improved path loss prediction in urban vehicle-to-infrastructure communication systems. <em>FRAI</em>, <em>8</em>, 1597981. (<a href='https://doi.org/10.3389/frai.2025.1597981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path loss prediction is crucial to facilitate reliable vehicle-to-infrastructure (V2I) communications. In this study, machine learning techniques are investigated for path loss modeling using empirical measurements at 5.9 GHz from eight Road Side Unit (RSU) sites. The performance of Extreme Gradient Boosting (XGBoost) and Multilayer Perceptron (MLP) models is contrasted with traditional empirical models such as the Dual Slope and 3rd Generation Partnership Project (3GPP) models in three varied urban environments: open, suburban, and densely urbanized cities. The findings indicate that machine learning models, in particular XGBoost, consistently outperform traditional models with the lowest Root Mean Square Error (RMSE) in complicated urban environments. For additional robustness in prediction, we propose an innovative environmental classification system based on building density, street geometry, and transmitter position. Feature importance examination reveals that distance, environmental class, and transmitter height are the most significant factors affecting path loss prediction accuracy. These observations aid the development of adaptive V2I communication systems and provide valuable guidelines for enhancing reliability in diverse urban environments.},
  archive      = {J_FRAI},
  author       = {Ben Ameur, Mongi and Chebil, Jalel and Habaebi, Mohamed Hadi and Tahar, Jamel Bel Hadj},
  doi          = {10.3389/frai.2025.1597981},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1597981},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning for improved path loss prediction in urban vehicle-to-infrastructure communication systems},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating the AI revolution: Challenges and opportunities for integrating emerging technologies into knowledge management systems. systematic literature review. <em>FRAI</em>, <em>8</em>, 1595930. (<a href='https://doi.org/10.3389/frai.2025.1595930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial intelligence (AI) is transforming organizational knowledge management (KM) by leveraging techniques such as machine learning, neural networks, and fuzzy logic to enhance knowledge discovery, capture, storage, and sharing. While this shift promises improved efficiency and personalization, it also poses challenges related to data quality, employee resistance, and alignment with existing workflows.MethodsThis study presents a systematic literature review (SLR) of 40 peer-reviewed publications focused on the integration of AI in KM. The review follows PRISMA guidelines and includes thematic coding to identify patterns, critical success factors, and knowledge gaps.ResultsFindings indicate that successful AI-enabled KM depends on strong leadership commitment, adaptable governance structures, and context-sensitive technology selection. AI’s role is evolving from supporting routine tasks to enabling dynamic, real-time knowledge flows. The review also highlights a critical need to balance automation with human oversight.DiscussionKey gaps were identified in understanding cost–benefit trade-offs, ethical implications, and governance mechanisms. These insights suggest directions for future research focused on practical, accountable, and empirically validated KM strategies. As part of an ongoing research project, the synthesized findings will inform the design of future empirical studies. The evidence suggests that, when strategically implemented, AI can serve as a competitive enabler in knowledge-driven organizations.},
  archive      = {J_FRAI},
  author       = {Gelashvili-Luik, Teona and Vihma, Peeter and Pappel, Ingrid},
  doi          = {10.3389/frai.2025.1595930},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1595930},
  shortjournal = {Front. Artif. Intell.},
  title        = {Navigating the AI revolution: Challenges and opportunities for integrating emerging technologies into knowledge management systems. systematic literature review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible neural networks for multi-omics integration: A critical review. <em>FRAI</em>, <em>8</em>, 1595291. (<a href='https://doi.org/10.3389/frai.2025.1595291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundBiomarker discovery and drug response prediction are central to personalized medicine, driving demand for predictive models that also offer biological insights. Biologically informed neural networks (BINNs), also referred to as visible neural networks (VNNs), have recently emerged as a solution to this goal. BINNs or VNNs are neural networks whose inter-layer connections are constrained based on prior knowledge from gene ontologies and pathway databases. These sparse models enhance interpretability by embedding prior knowledge into their architecture, ideally reducing the space of learnable functions to those that are biologically meaningful.MethodsThis systematic review-the first of its kind-identified 86 recent papers implementing BINNs/VNNs. We analyzed these papers to highlight key trends in architectural design, data sources and evaluation methodologies.ResultsOur analysis reveals a growing adoption of BINNs/VNNs. However, this growth is apparently juxtaposed with a lack of standardized, terminology, computational tools and benchmarks.ConclusionBINNs/VNNs represent a promising approach for integrating biological knowledge into predictive models for personalized medicine. Addressing the current deficiencies in standardization and tooling is important for widespread adoption and further progress in the field.},
  archive      = {J_FRAI},
  author       = {Selby, David Antony and Jakhmola, Rashika and Sprang, Maximilian and Großmann, Gerrit and Raki, Hind and Maani, Niloofar and Pavliuk, Daria and Ewald, Jan and Vollmer, Sebastian},
  doi          = {10.3389/frai.2025.1595291},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1595291},
  shortjournal = {Front. Artif. Intell.},
  title        = {Visible neural networks for multi-omics integration: A critical review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PACKETCLIP: Multi-modal embedding of network traffic and language for cybersecurity reasoning. <em>FRAI</em>, <em>8</em>, 1593944. (<a href='https://doi.org/10.3389/frai.2025.1593944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic classification is vital for cybersecurity, yet encrypted traffic poses significant challenges. We introduce PACKETCLIP which is a multi-modal framework combining packet data with natural language semantics through contrastive pre-training and hierarchical Graph Neural Network (GNN) reasoning. PACKETCLIP integrates semantic reasoning with efficient classification, enabling robust detection of anomalies in encrypted network flows. By aligning textual descriptions with packet behaviors, PACKETCLIP offers enhanced interpretability, scalability, and practical applicability across diverse security scenarios. With a 95% mean AUC, an 11.6% improvement over baselines, and a 92% reduction in intrusion detection training parameters, it is ideally suited for real-time anomaly detection. By bridging advanced machine-learning techniques and practical cybersecurity needs, PACKETCLIP provides a foundation for scalable, efficient, and interpretable solutions to tackle encrypted traffic classification and network intrusion detection challenges in resource-constrained environments.},
  archive      = {J_FRAI},
  author       = {Masukawa, Ryozo and Yun, Sanggeon and Jeong, Sungheon and Huang, Wenjun and Ni, Yang and Bryant, Ian and Bastian, Nathaniel D. and Imani, Mohsen},
  doi          = {10.3389/frai.2025.1593944},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1593944},
  shortjournal = {Front. Artif. Intell.},
  title        = {PACKETCLIP: Multi-modal embedding of network traffic and language for cybersecurity reasoning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated knee injury diagnosis using few shot learning. <em>FRAI</em>, <em>8</em>, 1589358. (<a href='https://doi.org/10.3389/frai.2025.1589358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionKnee injuries, especially Anterior Cruciate Ligament (ACL) tears and meniscus tears, are becoming increasingly common and can severely restrict mobility and quality of life. Early diagnosis is essential for effective treatment and for preventing long-term complications such as knee osteoarthritis. While deep learning approaches have shown promise in identifying knee injuries from MRI scans, they often require large amounts of labeled data, which can be both scarce and privacy-sensitive.MethodsThis paper analyses a hybrid methodology that integrates few-shot learning with federated learning for the diagnosis of knee injuries using MRI scans. The proposed model used a 3DResNet50 architecture as the backbone to enhance both feature extraction and embedding representation. A combined Centralized and Federated Few-Shot Learning Framework is analysed to leverage episodic-intermittent training strategy based on Prototypical Networks. The model is trained incorporating Stochastic Gradient Descent (SGD), Cross-Entropy Loss, and a MultiStep Learning Rate scheduler to enhance few-shot classification. This model also addressed the challenge of limited annotated data ensuring patient data privacy through distributed learning across multiple regions.ResultsThe models performance was evaluated on the MRNet dataset for multi-label classification. In the centralized setting, the model achieved accuracies of 85.3% on axial views, 82.1% on sagittal views, and 71% on coronal views. The propose work attained accuracies as 83% (axial), 83.9% (sagittal), and 65% (coronal), demonstrating the framework’s effectiveness across different learning configurations.DiscussionThe proposed method outperforms in diagnostic accuracy, generalization across MRI planes, and patient privacy via federated learning. However, it faces limitations, including lower coronal view performance and high computational demands due to its complex architecture.},
  archive      = {J_FRAI},
  author       = {Goel, Chirag and X, Anita and L, Jani Anbarasi},
  doi          = {10.3389/frai.2025.1589358},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1589358},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated knee injury diagnosis using few shot learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in healthcare text processing: A review applied to named entity recognition. <em>FRAI</em>, <em>8</em>, 1584203. (<a href='https://doi.org/10.3389/frai.2025.1584203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ContextTraditional methods such as rule-based systems, word embeddings (e.g. Word2Vec, GloVe) and sequence tagging models such as CRFs and HMMs have difficulty capturing the complex and nuanced context of medical texts, leading to low precision and inflexibility. These methods also struggle with the inherent variability of medical language and often require large and difficult-to-obtain labeled datasets.ObjectiveWe examine the growing importance of Named Entity Recognition (NER) in the analysis of healthcare texts. NER, a fundamental technique in Natural Language Processing (NLP), automatically identifies and categorizes named entities in the text, such as names of people and organizations, in medical texts, medical conditions and drug names. This facilitates better information retrieval, personalized medicine approaches and clinical decision support systems.MethodsA systematic mapping was carried out that focused on advanced language models, specifically transformation-based models such as BERT. These models are known for capturing complex semantic dependencies and linguistic nuances, which are crucial for accurate processing of medical texts. Transformation architectures, unlike traditional techniques such as CNNs and RNNs, are better suited to dealing with the contextual and semantic nature of medical texts due to their ability to manage long sequences and the need for high precision.ResultsThe results indicate that transformation-based models, in particular BERT and its specialized variants (e.g. ClinicalBERT), consistently demonstrate high performance on NER tasks, with F1 scores often exceeding 97%, outperforming traditional and hybrid methods. When examining the geographical distribution of contributions, the research identifies a significant contribution from China, followed by the United States. These findings have crucial implications for the integration of NER technologies into the Brazilian National Health System (SUS).ConclusionThis systematic review contributes to the advancement of NER in health texts by evaluating methods, showing results and highlighting the wider implications for the field. The article is systematically structured into the following sections: Methodology, Bibliometric analysis, Results and discussion, Threats to validity, Future work and Conclusion. This systematic organization provides a comprehensive review of the research, its impact and future directions, highlighting the importance of keeping up to date with advances in the field to increase the relevance of NER applications in healthcare.},
  archive      = {J_FRAI},
  author       = {de Almeida, Samuel Santana and Silva Fontes, Raphael and Pareja Credidio Freire Alves, Luca and Júnior, Methanias Colaço and José Pinheiro Caldeira Silva, Gleyson and Ramalho Cortez, Lyane and de Morais, Antonio Higor Freire and Medeiros Machado, Guilherme and Gonçalo Oliveira, Hugo and Cunha-Oliveira, Aliete and dos Santos, João Paulo Queiroz and de Medeiros Valentim, Ricardo Alexsandro},
  doi          = {10.3389/frai.2025.1584203},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1584203},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence in healthcare text processing: A review applied to named entity recognition},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral entropic radiomics feature extraction (SERFE): An adaptive approach for glioblastoma disease classification. <em>FRAI</em>, <em>8</em>, 1583079. (<a href='https://doi.org/10.3389/frai.2025.1583079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRadiomics-based glioblastoma classification demands feature extraction techniques that can effectively capture tumor heterogeneity while maintaining computational efficiency. Conventional tools such as PyRadiomics and CaPTk rely on extensive handcrafted feature sets, which often result in redundancy and necessitate further optimization steps.MethodsThis study proposes a novel framework, Spectral Entropic Radiomics Feature Extraction (SERFE), which integrates spectral frequency decomposition, entropy-driven feature selection, and graph-based spatial encoding. SERFE decomposes voxel intensity fluctuations into spectral signatures, employs entropy-based weighting to prioritize informative features, and preserves spatial topology through graph-based modeling. The method was evaluated using the public TCIA glioblastoma dataset.ResultsSERFE generated a refined feature set of 350 radiomic features from an initial pool of 2,260, achieving a 92% stability score and 91.7% classification accuracy. This performance surpasses traditional radiomics methods in both predictive accuracy and feature compactness.DiscussionThe results demonstrate SERFE’s capacity to enhance tumor characterization and streamline radiomics pipelines without requiring post-extraction feature reduction. Its compatibility with existing clinical workflows makes it a promising tool for future neuro-oncology applications.},
  archive      = {J_FRAI},
  author       = {Sowmya, V. L. and Bharathi Malakreddy, A. and Natarajan, Santhi and Prathik, N. and Rajesh, I. S.},
  doi          = {10.3389/frai.2025.1583079},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1583079},
  shortjournal = {Front. Artif. Intell.},
  title        = {Spectral entropic radiomics feature extraction (SERFE): An adaptive approach for glioblastoma disease classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of bone density in elderly people measured with AI and QCT. <em>FRAI</em>, <em>8</em>, 1582960. (<a href='https://doi.org/10.3389/frai.2025.1582960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundOsteoporosis, a systemic skeletal disorder characterized by deteriorated bone microarchitecture and low bone mass, poses substantial fracture risks to aging populations globally. Early detection of reduced bone mineral density (BMD) through opportunistic screening is critical for preventing fragility fractures. Although dual-energy X-ray absorptiometry (DXA) is the gold standard for diagnosing osteoporosis, many patients have not undergone screening with this technique. Therefore, developing an automated tool that can diagnose bone density through routine chest and abdominal CT examinations is highly important. With advancements in technology and the accumulation of clinical data, the role of bone density artificial intelligence (AI) in the diagnosis and management of osteoporosis is becoming increasingly significant.ObjectiveFirst to validate the diagnostic equivalence of AI-based BMD prediction against quantitative CT (QCT) reference standards, second to assess inter-device measurement consistency across multi-vendor CT systems (Siemens, GE, Philips). Ultimately, the objective is to determine the clinical utility of AI-derived BMD for osteoporosis classification.MethodsIn this retrospective multicenter study, paired CT/QCT datasets from 702 patients (2019–2022) were analyzed. The accuracy, sensitivity, and specificity of an Bone Density AI model were evaluated by comparing the predicted bone mineral density values from bone density AI with the measured values from QCT. Moreover, the consistency of lumbar spine BMD measurements between QCT and Bone Density AI on different devices was compared.ResultsThe AUC of Bone Density AI model in diagnosing osteoporosis was 0.822 (95% CI: 0.787–0.867, p < 0.001), with an accuracy of 0.9456, sensitivity of 0.9601, and specificity of 0.9270, indicating good performance in predicting bone density. The consistency study between Bone Density AI and QCT for the vertebral BMD measurements revealed no statistically significant difference in R2 values, suggesting no significant difference in performance between the two methods in measuring BMD. The linear regression fit between the R2 values of QCT and Bone Density AI for measuring lumbar spine BMD with different equipment ranged from 0.88 to 0.96, indicating a high degree of consistency between the two measurement methods across devices.ConclusionThis multicenter study pioneers a dual-validation framework to establish the clinical validity of deep learning-based BMD prediction algorithms using routine thoracic/abdominal CT scans. Our data suggest that AI-driven BMD quantification demonstrates non-inferior diagnostic accuracy to QCT while overcoming DXA’s accessibility limitations. This technology enables cost-effective, radiation-free osteoporosis screening through routine CT repurposing, particularly beneficial for resource-constrained settings.},
  archive      = {J_FRAI},
  author       = {Guo, Min and Zhang, Yu and Gu, XinXin and Liu, Xuhui and Peng, Fei and Zhang, Zongjun and Jing, Mei and Fu, Yingxia},
  doi          = {10.3389/frai.2025.1582960},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1582960},
  shortjournal = {Front. Artif. Intell.},
  title        = {A comparative study of bone density in elderly people measured with AI and QCT},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computer-vision based automatic rider helmet violation detection and vehicle identification in indian smart city scenarios using NVIDIA TAO toolkit and YOLOv8. <em>FRAI</em>, <em>8</em>, 1582257. (<a href='https://doi.org/10.3389/frai.2025.1582257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-wheeler traffic offenses are a well-known fact about the Indian Road scenario. In addition to endangering the offenders, these offenses also endanger other commuters. Two-wheeler traffic violations can take many different forms, such as overloading, triple riding, and helmetless riding. Effective identification and enforcement strategies are necessary for these offenses since they pose a serious risk to public safety. Due to the inadequacy of traditional traffic monitoring and enforcement techniques, advanced technology-based solutions are now required. Deep learning-based systems have demonstrated significant promise in identifying and stopping such infractions in recent years. We propose a two-step deep learning approach that leverages the strengths of pre-trained object detection models to detect two-wheeler riders and specialized helmet classifiers to identify helmet wear status as well as detect number plates. In the first stage, we utilized a highly efficient, robust, and accurate object identification DetectNet (Model 1) framework developed by NVIDIA, and it uses the ResNet18 Convolutional Neural Network (CNN) architecture as part of the Transfer Learning Toolkit known as TAO (Train, Adapt, Optimize). The second stage demands accurate detection of a helmet on the identified rider and extracting numbers from the violator’s license plates using the OCR module in real time. We employed YOLOv8 (Model 2), a deep learning-based architecture that has proven effective in several applications involving object detection in real time. It predicts bounding boxes and class probabilities for objects within an image using a single neural network, making it a perfect choice for real-time applications like rider helmet violations detections and number plate processing. Due to a lack of publicly available traffic datasets, we created a custom dataset containing motorcycle rider images captured under complex scenarios for training and validating our models. Experimental analysis shows that our proposed two-step model achieved a promising helmet detection accuracy of 98.56% and a 97.6% number plate detection accuracy of persons not wearing helmets. The major objective of our proposed study is to enforce stringent traffic laws in real-time to decrease rider helmet violations.},
  archive      = {J_FRAI},
  author       = {Deshpande, Uttam U. and Michael, Goh Kah Ong and Araujo, Sufola Das Chagas Silva and Deshpande, Vaidehi and Patil, Rudragoud and Chate, Ramchandra Alias Ameet and Tandur, Varun R. and Goudar, Supreet S. and Ingale, Shreya and Charantimath, Vaishnavi},
  doi          = {10.3389/frai.2025.1582257},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1582257},
  shortjournal = {Front. Artif. Intell.},
  title        = {Computer-vision based automatic rider helmet violation detection and vehicle identification in indian smart city scenarios using NVIDIA TAO toolkit and YOLOv8},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic taxonomy generation for future skills identification using a named entity recognition and relation extraction pipeline. <em>FRAI</em>, <em>8</em>, 1579998. (<a href='https://doi.org/10.3389/frai.2025.1579998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe labor market is rapidly evolving, leading to a mismatch between existing Knowledge, Skills, and Abilities (KSAs) and future occupational requirements. Reports from organizations like the World Economic Forum and the OECD emphasize the need for dynamic skill identification. This paper introduces a novel system for constructing a dynamic taxonomy using Natural Language Processing (NLP) techniques, specifically Named Entity Recognition (NER) and Relation Extraction (RE), to identify and predict future skills. By leveraging machine learning models, this taxonomy aims to bridge the gap between current skills and future demands, contributing to educational and professional development.MethodsTo achieve this, an NLP-based architecture was developed using a combination of text preprocessing, NER, and RE models. The NER model identifies and categorizes KSAs and occupations from a corpus of labor market reports, while the RE model establishes the relationships between these entities. A custom pipeline was used for PDF text extraction, tokenization, and lemmatization to standardize the data. The models were trained and evaluated using over 1,700 annotated documents, with the training process optimized for both entity recognition and relationship prediction accuracy.ResultsThe NER and RE models demonstrated promising performance. The NER model achieved a best micro-averaged F1-score of 65.38% in identifying occupations, skills, and knowledge entities. The RE model subsequently achieved a best micro-F1 score of 82.2% for accurately classifying semantic relationships between these entities at epoch 1,009. The taxonomy generated from these models effectively identified emerging skills and occupations, offering insights into future workforce requirements. Visualizations of the taxonomy were created using various graph structures, demonstrating its applicability across multiple sectors. The results indicate that this system can dynamically update and adapt to changes in skill demand over time.DiscussionThe dynamic taxonomy model not only provides real-time updates on current competencies but also predicts emerging skill trends, offering a valuable tool for workforce planning. The high recall rates in NER suggest strong entity recognition capabilities, though precision improvements are needed to reduce false positives. Limitations include the need for a larger corpus and sector-specific models. Future work will focus on expanding the corpus, improving model accuracy, and incorporating expert feedback to further refine the taxonomy.},
  archive      = {J_FRAI},
  author       = {Gonzalez-Gomez, Luis Jose and Hernandez-Munoz, Sofia Margarita and Borja, Abiel and Arana-Salas, Fernando A. and Azofeifa, Jose Daniel and Noguez, Julieta and Caratozzolo, Patricia},
  doi          = {10.3389/frai.2025.1579998},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1579998},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dynamic taxonomy generation for future skills identification using a named entity recognition and relation extraction pipeline},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing medical students’ attitudes, performance, and usage of ChatGPT in jeddah, saudi arabia. <em>FRAI</em>, <em>8</em>, 1577911. (<a href='https://doi.org/10.3389/frai.2025.1577911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundChatGPT, an advanced AI language model, has the potential to significantly enhance medical education by supporting clinical decision-making, facilitating knowledge acquisition, and improving learning outcomes. However, there remains a gap in understanding the risks and concerns surrounding the use of ChatGPT, as well as its impact on the quality of medical education in Jeddah, Saudi Arabia. This study investigates the role of ChatGPT in local medical education, offering insights into medical students’ attitudes and performance concerning the integration of AI into the medical curriculum.MethodsThis cross-sectional study was conducted from March to May 2024. It was approved by the institutional review board. An online survey was distributed to medical students in Jeddah to collect data on their awareness of ChatGPT and its impact on their attitudes and performance. The survey, which included 28 items across 2 sections was developed. For data analysis, Statistical Package for Social Sciences (SPSS) software (version 27.0) was used to conduct statistical analysis.ResultsThe final sample comprised 420 participants, of whom 84.3% had heard of ChatGPT, while 74.9% had used it prior to the study. The majority of participants were aged 18–21 (50.5%). Higher GPA and academic progression were significantly associated with greater awareness and performance related to ChatGPT. Additionally, privacy concerns, willingness to incorporate ChatGPT into learning and research, and perceptions of its ease of use were significantly correlated, with a p-value < 0.05.ConclusionThe findings indicate a generally positive perception of ChatGPT among medical students, particularly as they progress in their studies. Associations were observed between ChatGPT usage and students’ academic standing and attitudes toward AI. While the ease of use was appreciated, concerns regarding privacy, ethical implications, and data security were also prominent, reflecting global trends. Further longitudinal and experimental research is necessary to better understand the educational implications of ChatGPT and to ensure its responsible integration into medical curricula.},
  archive      = {J_FRAI},
  author       = {Alammari, Dalia and Alamari, Elaf and Alamri, Rawan and Alharbi, Raneem and Felimban, Jumana and Aljohani, Jana},
  doi          = {10.3389/frai.2025.1577911},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1577911},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing medical students’ attitudes, performance, and usage of ChatGPT in jeddah, saudi arabia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting early gastrointestinal polyps in histology and endoscopy images using deep learning. <em>FRAI</em>, <em>8</em>, 1571075. (<a href='https://doi.org/10.3389/frai.2025.1571075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe GastroIntestinal Cancer (GIC) is one of the most common tumors in terms of deaths and diseases. Artificial Intelligence (AI) domains such as Deep Learning (DL) have the potential to greatly improve the early identification of disease. Nevertheless, a lot of current technologies are still insufficient to detect tumors, which is why we created an approach using advanced method to identify polyps.MethodsOur three-stage deep learning-based method requires constructing an Encoder-Decoder Network (EDN) to determine the Region of Interest (ROI) in preprocessing, feature selection with pretrained models such as VGG16, VGG19, ResNet50 and InceptionV3, and Support Vector Machine (SVM) classifier to separate affected individuals from normal ones during the classification stage. Five datasets, such as CRC-VAL-HE-7K, CRC-VAL-HE-100K, Kvasir_v2, a dataset from Beijing Cancer Hospital, and a weakly labeled dataset, containing histology and endoscopic images, were utilized to train and evaluate our method.ResultsThe outcomes showed the effectiveness of our approach, with these pretrained models obtaining the best efficiency for recognizing gastrointestinal polyps. ResNet50 attained the maximum accuracy on datasets 1, 2, and 4, with performances of 97.01%, 96.49%, and 98.90%, respectively. Also, VGG16 and VGG19 performed 96.64% and 98.75% accuracy on datasets 3 and 5, respectively. However, InceptionV3 scored slightly less well than the other model.DiscussionThe advanced method produced promising results for the early detection of gastrointestinal cancer in multiple datasets.},
  archive      = {J_FRAI},
  author       = {Hajsalem, Intissar Dhrari and Ayed, Yassine Ben},
  doi          = {10.3389/frai.2025.1571075},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1571075},
  shortjournal = {Front. Artif. Intell.},
  title        = {Detecting early gastrointestinal polyps in histology and endoscopy images using deep learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven disinformation: Policy recommendations for democratic resilience. <em>FRAI</em>, <em>8</em>, 1569115. (<a href='https://doi.org/10.3389/frai.2025.1569115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing integration of artificial intelligence (AI) into digital communication platforms has significantly transformed the landscape of information dissemination. Recent evidence indicates that AI-enabled tools, particularly generative models and engagement-optimization algorithms, play a central role in the production and amplification of disinformation. This phenomenon poses a direct challenge to democratic processes, as algorithmically amplified falsehoods systematically distort political information environments, erode public trust in institutions, and foster polarization – conditions that degrade democratic decision-making. The regulatory asymmetry between traditional media – historically subject to public oversight – and digital platforms exacerbates these vulnerabilities. This policy and practice review has three primary aims: (1) to document and analyze the role of AI in recent disinformation campaigns, (2) to assess the effectiveness and limitations of existing AI governance frameworks in mitigating disinformation risks, and (3) to formulate evidence-informed policy recommendations to strengthen institutional resilience. Drawing on qualitative analysis of case studies and regulatory trends, we argue for the urgent need to embed AI-specific oversight mechanisms within democratic governance systems. We recommend a multi-stakeholder approach involving platform accountability, enforceable regulatory harmonization across jurisdictions, and sustained civic education to foster digital literacy and cognitive resilience as defenses against malign information. Without such interventions, democratic processes risk becoming increasingly susceptible to manipulation, delegitimization, and systemic erosion.},
  archive      = {J_FRAI},
  author       = {Romanishyn, Alexander and Malytska, Olena and Goncharuk, Vitaliy},
  doi          = {10.3389/frai.2025.1569115},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1569115},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-driven disinformation: Policy recommendations for democratic resilience},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Systematic analysis of hepatotoxicity: Combining literature mining and AI language models. <em>FRAI</em>, <em>8</em>, 1561292. (<a href='https://doi.org/10.3389/frai.2025.1561292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe body of toxicological knowledge and literature is expanding at an accelerating pace. This rapid growth presents significant challenges for researchers, who must stay abreast with latest studies while also synthesizing the vast amount of published information.GoalOur goal is to automatically identify potential hepatoxicants from over 50,000 compounds using the wealth of scientific publications and knowledge.MethodsWe employ and compare three distinct methods for automatic information extraction from unstructured text: (1) text mining (2) word embeddings and (3) large language models. These approaches are combined to calculate a hepatotoxicity score for over 50,000 compounds. We assess the performance of the different methods with a use case on Drug-Induced Liver Injury (DILI).ResultsWe evaluated hepatotoxicity for over 50,000 compounds and calculated a hepatotoxicity score for each compound. Our results indicate that text mining is effective for this purpose, achieving an Area Under the Curve (AUC) of 0.8 in DILI validation. Large language models performed even better, with an AUC of 0.85, thanks to their ability to interpret the semantic context accurately. Combining these methods further improved performance, yielding an AUC of 0.87 in DILI validation. All findings are available for download to support further research on toxicity assessment.ConclusionsWe demonstrated that automated text mining is able to successfully assess the toxicity of compounds. A text mining approach seems to be superior to word embeddings. However, the application of a large language model with prompt engineering showed the best performance.},
  archive      = {J_FRAI},
  author       = {Bauer, Chris and Duc Dang, Long Tran and van den Beucken, Twan and Schuchhardt, Johannes and Herwig, Ralf},
  doi          = {10.3389/frai.2025.1561292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1561292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Systematic analysis of hepatotoxicity: Combining literature mining and AI language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does business news sentiment matter in the energy stock market? adopting sentiment analysis for short-term stock market prediction in the energy industry. <em>FRAI</em>, <em>8</em>, 1559900. (<a href='https://doi.org/10.3389/frai.2025.1559900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterized by high volatility the energy stock market provides ample research potential for stock market prediction using machine learning models. This paper investigates using business news as an indicator of market sentiment in Recurrent Neural Networks. The authors adopt a finance-specific Transformer-based model, FinBERT, for news sentiment analysis and use a Long Short-Term Memory (LSTM) model for stock prediction. As prior research indicates that sentiment may vary for different news elements, they specifically explore differences between news headlines and content. Results show that (1) transformer-based sentiment analysis of business news can improve stock market prediction in the energy industry and that (2) sentiment of news content is more effective than sentiment of news headlines.},
  archive      = {J_FRAI},
  author       = {Lee, Chi-Yuan and Anderl, Eva},
  doi          = {10.3389/frai.2025.1559900},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1559900},
  shortjournal = {Front. Artif. Intell.},
  title        = {Does business news sentiment matter in the energy stock market? adopting sentiment analysis for short-term stock market prediction in the energy industry},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swedish medical LLM benchmark: Development and evaluation of a framework for assessing large language models in the swedish medical domain. <em>FRAI</em>, <em>8</em>, 1557920. (<a href='https://doi.org/10.3389/frai.2025.1557920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWe present the Swedish Medical LLM Benchmark (SMLB), an evaluation framework for assessing large language models (LLMs) in the Swedish medical domain.MethodThe SMLB addresses the lack of language-specific, clinically relevant benchmarks by incorporating four datasets: translated PubMedQA questions, Swedish Medical Exams, Emergency Medicine scenarios, and General Medicine cases.ResultOur evaluation of 18 state-of-the-art LLMs reveals GPT-4-turbo, Claude- 3.5 (October 2023), and the o3model as top performers, demonstrating a strong alignment between medical reasoning and general language understanding capabilities. Hybrid systems incorporating retrieval-augmented generation (RAG) improved accuracy for clinical knowledge questions, highlighting promising directions for safe implementation.DiscussionThe SMLB provides not only an evaluation tool but also reveals fundamental insights about LLM capabilities and limitations in Swedish healthcare applications, including significant performance variations between models. By open-sourcing the benchmark, we enable transparent assessment of medical LLMs while promoting responsible development through community-driven refinement. This study emphasizes the critical need for rigorous evaluation frameworks as LLMs become increasingly integrated into clinical workflows, particularly in non-English medical contexts where linguistic and cultural specificity are paramount.},
  archive      = {J_FRAI},
  author       = {Moëll, Birger and Farestam, Fabian and Beskow, Jonas},
  doi          = {10.3389/frai.2025.1557920},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1557920},
  shortjournal = {Front. Artif. Intell.},
  title        = {Swedish medical LLM benchmark: Development and evaluation of a framework for assessing large language models in the swedish medical domain},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating 4E cognition with science and technology studies: A framework for understanding AI applications. <em>FRAI</em>, <em>8</em>, 1545014. (<a href='https://doi.org/10.3389/frai.2025.1545014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper brings together two different theoretical strands of research, one from cognitive science, the other from Science and Technology Studies. The purpose in so doing is to uncover how cognition interrelates with socio-material practices and AI technology. An integrative framework is presented as a possible way for connecting the two strands while theorizing on their interrelations with AI.},
  archive      = {J_FRAI},
  author       = {Gahrn-Andersen, Rasmus},
  doi          = {10.3389/frai.2025.1545014},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1545014},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrating 4E cognition with science and technology studies: A framework for understanding AI applications},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The application of random forest-based models in prognostication of gastrointestinal tract malignancies: A systematic review. <em>FRAI</em>, <em>8</em>, 1517670. (<a href='https://doi.org/10.3389/frai.2025.1517670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMalignancies of the GI tract account for one-third of cancer-related deaths globally and more than 25% of all cancer diagnoses. The rising prevalence of GI tract malignancies and the shortcomings of existing treatment approaches highlight the need for better predictive prediction models. RF’s machine-learning method can predict cancers by using numerous decision trees to locate, classify, and forecast data. This systematic study aims to assess how well RF models predict the prognosis of GI tract malignancies.MethodsFollowing PRISMA criteria, we performed a systematic search in PubMed, Scopus, Google Scholar, and Web of Science until May 28, 2024. Studies used RF models to forecast the prognosis of GI tract malignancies, including esophageal, gastric, and colorectal cancers. The QUIPS approach was used to evaluate the quality of the included studies.ResultsOut of 1846 records, 86 studies met inclusion requirements; eight were disqualified. Numerous studies showed that when combining clinical, genetic, and pathological data, RF models were very accurate and dependable in predicting the prognosis of GI tract malignancies, responses, recurrence, survival rates, and metastatic risks, distinguishing between operable and inoperable tumors, and patient outcomes. RF models outperformed conventional prognostic techniques in terms of accuracy; several research studies reported prediction accuracies of over 80% in survival rate estimates.ConclusionRF models, in terms of accuracy, performed better than the conventional approaches and provided better capabilities for clinical decision-making. Such models can increase the life quality and survival of patients by personalizing their treatment regimens for cancers of the GI tract. These models can, in a significant manner, raise patients’ survival and quality of life through hastening clinical decision-making and providing personalized treatment options.},
  archive      = {J_FRAI},
  author       = {Mohamadi, Zhina and Shafizadeh, Ahmad and Aliyan, Yasaman and Shayesteh, Seyedeh Fatemeh and Goudarzi, Parsa and Khodabandeh, Alireza and Vaghari, Amirali and Ashrafi, Helma and Bahrami, Omid and ZarinKhat, Armin and Khodabandeh, Yalda and Pouyan, Kimia},
  doi          = {10.3389/frai.2025.1517670},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1517670},
  shortjournal = {Front. Artif. Intell.},
  title        = {The application of random forest-based models in prognostication of gastrointestinal tract malignancies: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLA-UNet: Feature-location attention U-net for foveal avascular zone segmentation in OCTA images. <em>FRAI</em>, <em>8</em>, 1463233. (<a href='https://doi.org/10.3389/frai.2025.1463233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSince optical coherence tomography angiography (OCTA) is non-invasive and non-contact, it is widely used in the study of retinal disease detection. As a key indicator for retinal disease detection, accurate segmentation of foveal avascular zone (FAZ) has an important impact on clinical application. Although the U-Net and its existing improvement methods have achieved good performance on FAZ segmentation, their generalization ability and segmentation accuracy can be further improved by exploring more effective improvement strategies.MethodsWe propose a novel improved method named Feature-location Attention U-Net (FLA-UNet) by introducing new designed feature-location attention blocks (FLABs) into U-Net and using a joint loss function. The FLAB consists of feature-aware blocks and location-aware blocks in parallel, and is embed into each decoder of U-Net to integrate more marginal information of FAZ and strengthen the connection between target region and boundary information. The joint loss function is composed of the cross-entropy loss (CE loss) function and the Dice coefficient loss (Dice loss) function, and by adjusting the weights of them, the performance of the network on boundary and internal segmentation can be comprehensively considered to improve its accuracy and robustness for FAZ segmentation.ResultsThe qualitative and quantitative comparative experiments on the three datasets of OCTAGON, FAZID and OCTA-500 show that, our proposed FLA-UNet achieves better segmentation quality, and is superior to other existing state-of-the-art methods in terms of the MIoU, ACC and Dice coefficient.DiscussionThe proposed FLA-UNet can effectively improve the accuracy and robustness of FAZ segmentation in OCTA images by introducing feature-location attention blocks into U-Net and using a joint loss function. This has laid a solid theoretical foundation for its application in auxiliary diagnosis of fundus diseases.},
  archive      = {J_FRAI},
  author       = {Li, Wei and Cao, Li and Deng, He},
  doi          = {10.3389/frai.2025.1463233},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1463233},
  shortjournal = {Front. Artif. Intell.},
  title        = {FLA-UNet: Feature-location attention U-net for foveal avascular zone segmentation in OCTA images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the impact of common clinical confounders on performance of deep-learning-based sepsis risk assessment. <em>FRAI</em>, <em>8</em>, 1452471. (<a href='https://doi.org/10.3389/frai.2025.1452471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionEarly identification of sepsis in the emergency department using machine learning remains a challenging problem, primarily due to the lack of a gold standard for sepsis diagnosis, the heterogeneity in clinical presentations, and the impact of confounding conditions.MethodsIn this work, we present a deep-learning-based predictive model designed to enable early detection of patients at risk of developing sepsis, using data from the first 24 h of admission. The model is based on routine blood test results commonly performed on patients, including CBC (Complete Blood Count), CMP (Comprehensive Metabolic Panel), lipid panels, vital signs, age, and sex. To address the challenge of label uncertainty as a part of the training process, we explore two different definitions, namely, Sepsis-3 and Adult Sepsis Event. We analyze the advantages and limitations of each in the context of patient clinical parameters and comorbidities. We specifically examine how the quality of the ground truth label influences the performance of the deep learning system and evaluate the effect of a consensus-based approach that incorporates both definitions. We also evaluated the model's performance across sub-cohorts, including patients with confounding comorbidities (such as chronic kidney, liver disease, and coagulation disorders) and those with infections confirmed by billing codes.ResultsOur results show that the consensus-based model identifies at-risk patients in the first 24 h with 83.7% sensitivity, 80% specificity, 36% PPV, 97% NPV, and an AUC of 0.9. Our cohort-wise analysis revealed a high PPV (77%) in infection-confirmed subgroups and a drop in specificity across cohorts with confounding comorbidities (47-70%).DiscussionThis work highlights the limitations of retrospective sepsis definitions and underscores the need for tailored approaches in automated sepsis detection, particularly when dealing with patients with confounding comorbidities.},
  archive      = {J_FRAI},
  author       = {Chaganti, Shikha and Singh, Vivek and Gent, Alasdair Edward and Kamaleswaran, Rishikesan and Kamen, Ali},
  doi          = {10.3389/frai.2025.1452471},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {1452471},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating the impact of common clinical confounders on performance of deep-learning-based sepsis risk assessment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Outbreak oracles: How AI's journey through COVID-19 shapes future epidemic strategy. <em>FRAI</em>, <em>8</em>, 1636444. (<a href='https://doi.org/10.3389/frai.2025.1636444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The authors declare that the research was conducted in the absence of any commercial or financial 98 relationships that could be construed as a potential conflict of interest. 99The author(s) declared that they were an editorial board member of Frontiers, at the time of 100 submission. This had no impact on the peer review process and the final decision. 101 We are grateful to all the authors and reviewers contributing to this Research Topic. 109Publisher's note 110 All claims expressed in this article are solely those of the authors and do not necessarily represent 111 those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any 112 product that may be evaluated in this article, or claim that may be made by its manufacturer, is not 113 guaranteed or endorsed by the publisher. 114 6},
  archive      = {J_FRAI},
  author       = {Chumachenko, Dmytro and Kaur, Jasleen and Chen, Jake Y.},
  doi          = {10.3389/frai.2025.1636444},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1636444},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Outbreak oracles: How AI's journey through COVID-19 shapes future epidemic strategy},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical reasoning in LLMs: An in-depth analysis of DeepSeek r1. <em>FRAI</em>, <em>8</em>, 1616145. (<a href='https://doi.org/10.3389/frai.2025.1616145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe integration of large language models (LLMs) into healthcare holds immense promise, but also raises critical challenges, particularly regarding the interpretability and reliability of their reasoning processes. While models like DeepSeek R1-which incorporates explicit reasoning steps-show promise in enhancing performance and explainability, their alignment with domain-specific expert reasoning remains understudied.MethodsThis paper evaluates the medical reasoning capabilities of DeepSeek R1, comparing its outputs to the reasoning patterns of medical domain experts.ResultsThrough qualitative and quantitative analyses of 100 diverse clinical cases from the MedQA dataset, we demonstrate that DeepSeek R1 achieves 93% diagnostic accuracy and shows patterns of medical reasoning. Analysis of the seven error cases revealed several recurring errors: anchoring bias, difficulty integrating conflicting data, limited consideration of alternative diagnoses, overthinking, incomplete knowledge, and prioritizing definitive treatment over crucial intermediate steps.DiscussionThese findings highlight areas for improvement in LLM reasoning for medical applications. Notably the length of reasoning was important with longer responses having a higher probability for error. The marked disparity in reasoning length suggests that extended explanations may signal uncertainty or reflect attempts to rationalize incorrect conclusions. Shorter responses (e.g., under 5,000 characters) were strongly associated with accuracy, providing a practical threshold for assessing confidence in model-generated answers. Beyond observed reasoning errors, the LLM demonstrated sound clinical judgment by systematically evaluating patient information, forming a differential diagnosis, and selecting appropriate treatment based on established guidelines, drug efficacy, resistance patterns, and patient-specific factors. This ability to integrate complex information and apply clinical knowledge highlights the potential of LLMs for supporting medical decision-making through artificial medical reasoning.},
  archive      = {J_FRAI},
  author       = {Moëll, Birger and Sand Aronsson, Fredrik and Akbar, Sanian},
  doi          = {10.3389/frai.2025.1616145},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1616145},
  shortjournal = {Front. Artif. Intell.},
  title        = {Medical reasoning in LLMs: An in-depth analysis of DeepSeek r1},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing and evaluating ArabicStanceX: A social media dataset for arabic stance detection. <em>FRAI</em>, <em>8</em>, 1615800. (<a href='https://doi.org/10.3389/frai.2025.1615800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arabic stance detection has attracted significant interest due to the growing importance of social media in shaping public opinion. However, the lack of comprehensive datasets has limited research progress in Arabic Natural Language Processing (NLP). To address this, we introduce ArabicStanceX, a novel and extensive Arabic stance detection dataset sourced from social media, comprising 14,477 tweets across 17 diverse topics. Utilizing the transformer-based MARBERTv2 model, we explore stance detection through Multi-Topic Single Model (MTSM) strategies, achieving a promising F1 score of 0.74 for detecting ‘favor' and ‘against' stances, and 0.67 overall. Our experiments highlight the model's capabilities and challenges, particularly in accurately classifying neutral stances and generalizing to unseen topics. Further investigations using zero-shot and few-shot learning demonstrate the model's adaptability to new contexts. This study significantly advances Arabic NLP, providing crucial resources and insights into stance detection methodologies and future research directions. The dataset is publicly available1.},
  archive      = {J_FRAI},
  author       = {Alkhathlan, Ali and Alahmadi, Faris and Kateb, Faris and Al-Khalifa, Hend},
  doi          = {10.3389/frai.2025.1615800},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1615800},
  shortjournal = {Front. Artif. Intell.},
  title        = {Constructing and evaluating ArabicStanceX: A social media dataset for arabic stance detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Exploring the power of AI and ML in smart grids: Advancements, applications, and challenges. <em>FRAI</em>, <em>8</em>, 1615547. (<a href='https://doi.org/10.3389/frai.2025.1615547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research topic is entitled "Exploring the Power of AI and ML in Smart Grids: Advancements, Applications, and Challenges." It aims to assemble innovative research and pragmatic solutions employing AI and ML techniques within energy systems, demonstrating the current and future roles of these technologies in enhancing energy system operations. Contributions sought were intended to vividly highlight diverse applications, advancements, and associated challenges of integrating AI and ML into smart grids. This Research Topic serves as a crucial resource to comprehend the present status and future directions of AI and ML in smart grid technologies. To ensure that AI-based smart grids are interoperable, secure, and capable of protecting data privacy, standard frameworks such as IEC 61850 define communication protocols for intelligent electronic devices in electrical substations. Furthermore, the General Data Protection Regulation (GDPR) promotes responsible data management, establishing the foundation for scalable and secure smart grid deployment.Topics specifically covered within this research topic include but are not limited to:• Innovations in AI and ML for smart grid optimization.• AI-driven energy demand forecasting and management.• ML applications in renewable energy integration.• AI solutions for smart grid security and resilience.• Case studies on AI/ML applications enhancing grid stability and efficiency.• Comparative studies between traditional and AI/ML-based smart grid systems.• Ethical and privacy concerns in AI/ML applications in smart grids.• Challenges related to integrating AI/ML into smart grid systems, including data security and system interoperability.Energy forecasting is pivotal in smart grid technology, directly impacting the efficiency and reliability of energy management. (Badhe, Neve et al. 2025) introduced an advanced predictive model integrating the Temporal Fusion Transformer (TFT) with the Aquila Optimizer (AO). Their model demonstrated enhanced accuracy and computational efficiency, significantly outperforming traditional forecasting models. This research underscores the necessity for precise forecasting mechanisms to effectively manage renewable energy variability and dynamic energy consumption patterns. (Shrivastava and Goswami 2025) presented a hybrid neuro-fuzzy deep learning model tailored specifically for optimizing building energy management systems (BEMS). Implemented within a university setting, their IoT-driven model showcased substantial practical efficiency by achieving a remarkable 20% reduction in electricity bills. The model effectively utilized two years of collected data to forecast and optimize energy use, emphasizing AI's critical role in cost-effective energy management in resource-constrained economies.Cybersecurity remains a vital aspect of smart grid technology. (Nemade, Kishor Maharana et al. 2024) proposed a comprehensive cyber-defense strategy employing deep learning techniques to significantly enhance cybersecurity, particularly targeting vulnerabilities in SCADA systems within smart grids. Their approach demonstrated robust anomaly detection, significantly strengthening infrastructure resilience. By integrating advanced graph-based algorithms and human-AI interaction strategies, their work highlights the urgency and importance of advanced cybersecurity measures to safeguard increasingly digitalized energy infrastructures.Further emphasizing cybersecurity, (Verma and Rao 2025) explored the application of deep learning in decentralized smart grid architectures. Their research provided essential insights into identifying and mitigating threats inherent to distributed energy resources. This study illustrated the efficacy of AI-driven cybersecurity solutions, critical for protecting decentralized infrastructures against sophisticated and emerging cyber threats.Addressing the unique implementation challenges in developing regions, (Talhar Belge, Gupta et al. 2024) conducted a comprehensive review highlighting advancements, challenges, and future opportunities for smart grid technology in India. Their research underscored the importance of digital communication systems, advanced metering infrastructure, and real-time grid management for enhancing reliability and efficiency. Through practical case studies and pilot project analyses, the authors outlined a strategic roadmap for smoother transitions from traditional grids to smarter, more resilient energy systems. (Mahadik, Gedam et al. 2025) focused on environmental sustainability enhanced through smart sensors. Their review illustrated how sensor technologies significantly improve realtime monitoring, fault detection, and renewable energy integration, leading to reduced greenhouse gas emissions and optimized resource management. Their findings underscore the pivotal role of intelligent sensor technologies in achieving broader sustainability goals within smart grids. (Balamurugan, Narayanan et al. 2025) provided a concise yet thorough overview of AI applications in smart grids, detailing methods from load forecasting to power distribution optimization and renewable energy integration. Their review underscored AI's vast potential for enhancing grid reliability, operational efficiency, and adaptability to future energy demands. Additionally, they addressed critical challenges such as data quality, standardization, and interoperability, highlighting the strategic significance of AI for future grid operations.Collectively, the research contributions within this special issue underscore substantial opportunities and persistent challenges involved in integrating AI and ML into smart grid systems. Ongoing advancements in AI technology, robust cybersecurity frameworks, and adaptive energy management systems remain crucial for exploiting the transformative potential of these technologies. While significant progress has been made, continuous innovation is essential to address evolving complexities and maximize the benefits of AIdriven smart grid solutions.Looking forward, substantial research opportunities remain to further leverage AI and ML in smart grid technologies. Future research could explore hybrid optimization techniques combining multiple AI algorithms to enhance prediction accuracy and computational efficiency. Real-time adaptive AI models, capable of dynamically responding to varying grid conditions, represent another promising research direction. Additionally, developing scalable, cost-effective AI solutions tailored for resource-constrained environments prevalent in developing countries is critical. Continuous advancements in cybersecurity frameworks through proactive and evolving threat detection mechanisms are equally essential. This special issue serves as an essential resource for researchers, industry professionals, and policymakers, highlighting current innovations and identifying areas for further exploration. We anticipate that this editorial fosters ongoing innovation and collaboration within the dynamic field of AI-driven smart energy management, ultimately supporting the transition towards more sustainable and efficient global energy ecosystems.},
  archive      = {J_FRAI},
  author       = {Kulkarni, Vikram and Sahoo, Sarat Kumar and Nemade, Bhushankumar and Kallam, Suresh and Termritthikun, Chakkrit},
  doi          = {10.3389/frai.2025.1615547},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1615547},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Exploring the power of AI and ML in smart grids: Advancements, applications, and challenges},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the role of generative AI in international students’ sociocultural adaptation: A cognitive-affective model. <em>FRAI</em>, <em>8</em>, 1615113. (<a href='https://doi.org/10.3389/frai.2025.1615113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the backdrop of increasing global educational exchanges, the sociocultural adaptation of international students has attracted significant attention. The rise of Generative Artificial Intelligence has brought new perspectives to research in this field, yet existing studies have insufficiently explored the mechanisms through which GenAI influences the sociocultural adaptation of international students. Drawing on the cognitive-affective personality system theory and conservation of resources theory, this study employed a three-stage time-lagged questionnaire survey to collect 329 valid responses from international students at three universities in North, South, and East China. The research aims to investigate how GenAI use impacts students’ sociocultural adaptation, while examining the mediating roles of positive reappraisal and perceived empathy, as well as the moderating effect of AI anthropomorphism. The findings reveal that GenAI use is significantly positively associated with international students’ sociocultural adaptation. Positive reappraisal and users’ subjective perceived empathy mediate the relationship between GenAI use and sociocultural adaptation. Additionally, the degree of AI anthropomorphism positively moderates the relationships between GenAI use and both positive reappraisal and perceived empathy, enhancing the indirect effects of these mediating variables on the relationship between GenAI use and sociocultural adaptation. This study enriches the technological premises of cross-cultural adaptation for international students and provides GenAI-based intervention strategies for their educational management.},
  archive      = {J_FRAI},
  author       = {Ma, Huajun and You, Qingnan and Jin, Zhiyuan and Liu, Xinglin and Chen, Zimeng},
  doi          = {10.3389/frai.2025.1615113},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1615113},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the role of generative AI in international students’ sociocultural adaptation: A cognitive-affective model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid fuzzy logic–Random forest model to predict psychiatric treatment order outcomes: An interpretable tool for legal decision support. <em>FRAI</em>, <em>8</em>, 1606250. (<a href='https://doi.org/10.3389/frai.2025.1606250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundDecisions surrounding involuntary psychiatric treatment orders often involve complex clinical, legal, and ethical considerations, especially when patients lack decisional capacity and refuse treatment. In Quebec, these orders are issued by the Superior Court based on a combination of medical, legal, and behavioral evidence. However, no transparent, evidence-informed predictive tools currently exist to estimate the likelihood of full treatment order acceptance. This study aims to develop and evaluate a hybrid fuzzy logic–machine learning model to predict such outcomes and identify important influencing factors.MethodsA retrospective dataset of 176 Superior Court judgments rendered in Quebec in 2024 was curated from SOQUIJ, encompassing demographic, clinical, and legal variables. A Mamdani-type fuzzy inference system was constructed to simulate expert decision logic and output a continuous likelihood score. This score, along with structured features, was used to train a Random Forest classifier. Model performance was evaluated using accuracy, precision, recall and F1 score. A 10-fold stratified cross-validation was employed for internal validation. Feature importance was also computed to assess the influence of each variable on the prediction outcome.ResultsThe hybrid model achieved an accuracy of 98.1%, precision of 93.3%, recall of 100%, and a F1 score of 96.6. The most influential predictors were the duration of time granted by the court, duration requested by the clinical team, and age of the defendant. Fuzzy logic features such as severity, compliance, and a composite Burden_Score also significantly contributed to prediction accuracy. Only one misclassified case was observed in the test set, and the system provided interpretable decision logic consistent with expert reasoning.ConclusionThis exploratory study offers a novel approach for decision support in forensic psychiatric contexts. Future work should aim to validate the model across other jurisdictions, incorporate more advanced natural language processing for semantic feature extraction, and explore dynamic rule optimization techniques. These enhancements would further improve generalizability, fairness, and practical utility in real-world clinical and legal settings.},
  archive      = {J_FRAI},
  author       = {Hudon, Alexandre},
  doi          = {10.3389/frai.2025.1606250},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1606250},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid fuzzy logic–Random forest model to predict psychiatric treatment order outcomes: An interpretable tool for legal decision support},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-powered creative stimulus: The ascent of virtual virtuoso entrepreneurship. <em>FRAI</em>, <em>8</em>, 1605855. (<a href='https://doi.org/10.3389/frai.2025.1605855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The art world has undergone a revolutionary reshaping by introducing social media in the contemporary era. The traditional art world relied more on the bilateral relationship between artists and collectors, whereby established institutions were the bridge between the parties. Artists in conventional times relied solely on art galleries, which showcased and marketed their works through exhibitions and displays. Artists developed their crafts, worked with galleries and dealers, and participated in fairs and competitions to build relationships. They concentrated more on the sale of their artworks. As time passed by, the world of art came across a trend combining entrepreneurial skills and artistic talents. Here comes the evolution of art entrepreneurship, more commonly stated as artrepreneurship. Artrepreneur is resourceful and merges his creative ability and business acumen to establish a sustainable artist career. Artrepreneurship is the process of bringing an artist's creative capabilities into a physical form so that it can be commercialized widely (Hoffmann et al., 2021). Arts and Cultural Entrepreneurship encompasses several key elements that highlight the affiliation between the arts, culture, and entrepreneurial activities. Noonan (2021) coined the term 'Creative Class', which refers to a subset of the professional community which engages in creative vocations. The creative class is believed to enhance fiscal growth and community revitalization. Artrepreneurship itself is regarded as a segment of entrepreneurial activity that includes career management, the utilization of crowdfunding platforms, and the adaptation to dynamic environments (Noonan, 2021). Social media has paved the way for disrupting traditional art marketing, fostering more accessibility and democracy in the creative community. The virtual world enabled the virtuosos, i.e. artists, to attain wider exposure and broader audience reach. However, the volume and magnitude of significant content on social media platforms act as a barrier for the artists to catch the eye. The importance of Artificial Intelligence (AI) here becomes apparent. Blending Artificial Intelligence (AI), social media, and entrepreneurship in the cultural and creative world has created an exciting and intricate new paradigm. AI has a transformative impact on innovation and creativity. AI redefined the criteria of artistry by re-evaluating the question of who can be considered an artist, which prompted a reconsideration of the capabilities, subjectivity, emotions, and creativity in art (Zhao & Zhang, 2023). The creative force and innovative design concept driven by AI enable the diverse expression of ideas and technologies that enhance the growth of art. A quantum leap from traditional thinking patterns and aesthetic sense is attained, enhancing the visual appeal and artistic value of creations (He, 2022). The evolving relationship between Artificial Intelligence and creative businesses explains that AI has the potential to be used as a collaborative assistant, which can be used to enhance creative productions rather than considering it as a replacement to human creativity. The integration of Artificial Intelligence is promising in nature which states that increased use of AI can lead to more content creation and artistic expression. The relationship explains the synergy between creativity and Artificial technologies in shaping future creative ventures (Anantrasirichai, n.d.). This article examines how the integration of Artificial Intelligence and artrepreneurship reshapes the creative landscape. As artists entrepreneurs navigate the ever-evolving virtual environment, they face a unique set of opportunities and challenges that demand careful consideration, which is discussed briefly. It also contextualizes AI integrated art within existing creativity research and addresses the ethical concerns regarding the role of AI in creative productions.Opinion PieceThe article is an opinion piece, which employs a conceptual approach that explains the transformative impact of Artificial Intelligence on the artrepreneurship business. The study strictly relied on secondary data sources in discussing AI-powered virtual virtuoso entrepreneurship. A conceptual research approach is adopted in the study with existing theory and literature dependence to support the main claim, which is primarily interdisciplinary and focuses on perspectives from entrepreneurship, art and artificial intelligence. Desk research methodology is utilized in the study sourcing information from reputed journals and reputable online sources. Data sources include scholarly literature and research studies on AI integration in creative industries, digital entrepreneurship and social media marketing. It also provides case studies on AI-assisted artistic ventures and ethical considerations for employing AI-generated art. Also, a comparative analysis between traditional virtuoso entrepreneurship and AI-integrated virtuoso entrepreneurship is included, which sheds light on the evolving nature of artistic production and marketability in the era of Artificial Intelligence. As, an opinion-based commentary, the article is limited to be interpretative rather than empirical. The absence of primary data constrains the generalizability of the facts discussed.M. Rogers', Diffusion of Innovation theory put forth a valuable framework for understanding the adoption of Artificial tools by art entrepreneurs. The theory underscores how a social system adopts and communicates innovations, particularly in a rapidly growing economy. In the perception of Rogers, diffusion is explained as a process by which novelty is communicated through a specific medium among the community. In a creative context, Artificial Intelligence enabled tools represent innovations that improve creativity, feasibility and market reach for art entrepreneurs(García-Avilés, 2020).Guilford's Divergent Thinking Model involves four vital capabilities that are necessary for evaluating creative thinking in different tasks. These capabilities include fluency, flexibility, elaboration and originality. Divergent thinking is essential for the assessment of creative abilities as it involves multiple ideas or innovations. It can also enhance the process of content creation, assessment and collaboration eventually leading to high-quality creative outputs. Artificial Intelligence can replicate or enhance human creativity by exploiting different dimensions of the human thinking process (Forthmann et al., 2019).Mihaly Csikszentmihalyi's systems approach offers Systems Model of Creativity which emphasizes creativity as an outcome of complex systems rather than individual efforts. This framework can enrich the domain of creativity by combining it with Artificial Intelligence. New dimensions of collaborations, power dynamics and personalization can be explored, ultimately leading to better utilization of the creative process in current scenario art practices (McIntyre, n.d.).The integration of AI and arts has been showing rapid evolution trends, significantly impacting ingenuity and value perceptions. AI can be employed in the creation of all types of art products, tangible or intangible, thereby enabling diversity in product types. The increasing trend of adoption of AI tools and human-AI collaborations in creative industries indicates how humans embrace AI in their cultural and creative ventures. Surprisingly, awareness of AI involvement in artistic content creation has negligible impact on the apparent value of the artworks. Art consumers are less bothered about machine involvement; even fully artificial artworks are demanded with significant value. Counterintuitively, the lack of human touch does not limit the emotional response of the art enthusiasts. Most AI-generated artwork does not fail to trigger the emotions of the art audience (Tigre Moura et al., 2023). In essence, AI art is poised to significantly reshape our understanding of creativity and human emotion in artistic contexts. The advent of AI-generated art is set to revolutionize our perception of flair, desire, self-consciousness, and emotional expression of art.The track of AI in art moves towards more individualized and hands-on exposure. The advancement of AI is also paving the way for the formation of novel art forms. AI uses its ability to utilize large databases, leading to the reflection of human sentiments and sensations, offering insights into complex patterns in the art world. The blend of aesthetics and data science provides shared and enhanced creativity. The collaboration of humans and AI opens the way for new possibilities of artistic endeavours and novelty. AI also acts as a tool to evolve and explore new ways of creativity (Wingström et al., 2024). The enhanced creativity enables the establishment of unique brand identity and marketing techniques that are rare and distinctive. New art products can be developed based on the personal tastes and experiences of the art customers. Art creation can be timeconsuming and expensive. Artists also face art drainage at times. AI can aid art creation based on descriptions, enabling artrepreneurs to save considerably in costs and time. Furthermore, AI combines science and art. Artificial Intellect links computer science and creative abilities, offering new thoroughfare towards multidisciplinary collaboration (Wingström et al., 2024). Artrepreneurs need to test and refine their creative capabilities quickly. AI can be a powerful tool for rapid prototyping, where ideas can be converted into tangible forms from paper to digital. AI allows entrepreneurs to maximize the exhibition value, which enables entrepreneurs in the art industry to attract art audiences and increase the scope of market values and networks (Kalpokas, 2023). In their case study, Wallace et al. (2024) underscore the potential of AI as an instrument for extemporizing and improvising traditional dance and transforming abstract movements. The study suggests that deviating from realism can benefit creative practices positively, emphasizing the relevance of affiliation with specialists in evaluating and utilizing AI in artistic contexts.Artificial Intelligence, despite its opportunities, has numerous issues to be addressed. Usually, customers possess a negative attitude towards AI-generated creative ideas, probably due to a need for more education and awareness about AI and issues in their perceptions towards AI. Also, there is a fear of AI replacing human abilities as creative producers. Also, AI limits basic human instincts and emotions, which can restrict the wholesome creation of human interfered arts. AI art acts as a significant hazard to the traditional art market, where traditional artists are engaged in creating art based solely on their ideas and skills. Their human-inherited exertions go unnoticed by the rise of AI reliability (Kalpokas, 2023). Moreover, creating art based on queries and descriptions is not effortless, as AI may struggle to combine its cue conversion skills with creative composition (Wingström et al., 2024). Reconceptualization or redefinition of art is a possible threat that can impact human creativity. If AI-generated art can pass the "Turing test" by creating aesthetically pleasing artwork, a shift in understanding of creativity can occur. Discrepancies in artistic value and identity are another possible threat of AI-integrated art generation. The distinction between subjectivity and objectivity of art is another potential question regarding human involvement. AIgenerated art is objective whereas traditional art is more subjective in nature. If art can be judged based on objective criteria through AI integration, AI can be programmed based on these standards. This can challenge human involvement, which is primarily based on emotions and living experiences, in creative endeavours (Hong & Curran, 2019). Entrepreneurs face data privacy and security issues. AI-generated art can also attract copyright issues, leading to complex issues relating to ownership, which leads to reluctance from the side of artist consumers. They also question authenticity and creativity concerns. Artrepreneurs struggle to attain confidence and market acceptability from the art community. The shift towards exhibition value impacts the perceptions of the artist community and the approaches towards acknowledgement of arts. This transition in the paradigm gives rise to the questioning of the intrinsic value of arts and their commerciality and marketability, which subsequently affects entrepreneurs in the field of art and creative areas (Kalpokas, 2023). Latikka et al., 2023 in their case study on attitudes of respondents towards AI Art, suggest the respondents exhibited a less positive attitude towards the integration of AI in the artistic community compared to other areas like healthcare or construction technology. Perception complexities suggest that AI art is strange, cold, or scary, reflecting a need for more familiarity and comfort with AI in creative endeavours. The case study reveals the complexity of attitudes toward AI integration in art, emphasizing the importance of psychological needs and contextual factors The results suggest that while there is curiosity about AI's potential in art, there are also significant concerns that need to be addressed to foster acceptance.The advent of AI has revolutionized the realm of art, reshaping the creative landscape and challenging traditional norms of authorship and creation. While the AI advancement offers numerous possibilities, it also raises a host of ethical and legal questions requiring careful consideration. The primary concern is the moral and legal implications of content created and uploaded by humans. Ethical concerns cover originality, authenticity and creativity issues. Many artists raise doubts about the genuineness of original works. They argue that AI imitates existing ideas-the lack of self-awareness and emotional depth in a creative process leads to the authenticity of AI-generated works. Moreover, many artists debate whether AI can be truly creative, as creativity is a process that involves personal experiences and emotions, which AI lacks. It also touches on the aspect of motivation and intent behind AI-created art, questioning whether AIgenerated art has the same intentions as those of human artists. Legal concerns revolve around ownership and the property rights of art. The ownership question is, in fact, a bit tricky -"Who is the real owner of the AI generated art Programmer, User or AI itself?". This dilemma complicates the legal environment of AI-generated art. An additional critical area of legal focus is the Intellectual Property Rights landscape. Current laws may not be sufficient to address the challenges of AI art, which brings to attention how to protect both human artists and AI-generated art. The effect of AI-integrated art has implications for human artists, which questions the role of human creativity, subsequently leading to perplexities in future artistic professions. (Liu, 2023). Moreover, people often have an aversion towards AI-generated art because of the need for familiarity and safety issues. There comes an obligation to educate the public about AI and machine intelligence to eradicate delusions and fears. There are concerns regarding user experience and autonomy. Likewise, cultural differences shape people's perceptions across societies, raising the ethical question of cultural sensitivity in AI-generated art, which is crucial for AI rollout (Latikka et al., 2023). To summarize, the ethical and legal aspects revolve around genuineness, security, impact on human creators, user freedom and Intellectual Property Rights. By exploring these ethical dilemmas, the human experience of art can be responsibly and morally enriched. Arts and creative endeavours have been democratized in the era of social media to a large extent, but the introduction of AI in social media artrepreneurship is a paradigm shift. AI integration in art entrepreneurship is both transformative and disruptive. It holds huge promise as it can affect how art is created and how art can be marketed and sold.AI acts as a muse in generating novel ideas, deciding the colour palettes, deciding the pace of the music, converting recordings to music sheets, assisting choreography, rehearsal revolutions and what more. By collaborating with Artificial Intelligence and Arts, artists break the boundaries of human imagination. The unification of AI in social media could leverage the experiences of social media users, attracting more users towards the art community, and thereby enhancing deeper connections between artists and their audiences. AI aid can free artists from artist drainage. AI can also help in marketing strategies. Artists can rely more on their passion, converting their passion into a successful career. However, the use of AI could create art floods in the market, making it difficult for human artists to stand out and use their full potential. Ethical concerns and authenticity questions will definitely create pitfalls. It is better to keep a symbiotic link between human and machine interference. Artists must ensure a balance between AI assistance and artistic visions to capture the unique essence of artistic work. At the same time, AI can be used to focus more on business processing and leveraging social media marketability. The key is to exploit the merits of AI by not compromising the human touch. AI-integrated social media artrepreneurship is not about the replacement of artists by machines but about enfranchising them, fostering a new era of creative exposure and exploration. The prospect of AI-integrated social media artrepreneurship is both thrilling and volatile. Ultimately, the key to success lies in the ethical usage of artificial assistance, ensuring human elements, thereby fostering marketability and sales.Integrating AI into the sphere of creativity marks a revolution in artistic expression. Regardless of AI-integrated art's threats, it is becoming a powerful tool that can accelerate artistic abilities and open up new frontiers of creative capabilities. From generating concepts and ideas to enhancing overall art creation, technological innovation enables different experimentation and the creation of unimaginable artworks. However, as discussed earlier, the sophistication of AI raises concerns regarding authenticity, originality and human contribution to the creative community. Instead of mere substitution, artists should inculcate AI as a measure to leverage their creative endeavours. Moreover, AI models generate visual arts from internet datasets, which often reflect societal biases, stereotypes and imbalances. These biases can be reflected in AI generated outputs. This is, rather a consequence of trained data and lack of oversight in curation. AI generated art is not immune to such biases often leading to historical disparity, ethnic stereotype or exclusionary codes and segregating norms. The lack of transparency limits the artist's ability to engage in creative ventures. Discriminatory patterns can also arise when AI tools prioritize certain styles, narratives of culture or demographics over others. The question of disrupting traditional business models and classifying art as a digital asset must also be addressed. Artists must update themselves to technological advancements and acquire novel skills, thereby developing strategies to accelerate the monetization of their work. Also, more inclusive training datasets should be developed, and the implementation of guidelines for ethical AI use in creative domains can be involved.The article is primarily a commentary article that mainly focuses on the emergence of artrepreneurship by integrating Artificial Intelligence. Further research can be conducted on the ethical implications of AI-Art in dealing with ownership and copyrights, originality, bias, and discrimination. Another possible research area is the impact of AI on the art market from both the artist and user perspective, which can provide insights into the valuation and pricing of AIgenerated art and the adaptability of art galleries and auction houses. Virtual art as an asset is another area of potential research. Future research can explore the scope of NFT and Blockchain art-driven economies. The social and cultural impact of AI art can also be studied to know the public perceptions. By exploring these domains, a comprehensive and deeper understanding of the intricate relationship between art and AI can be attained.The authors disclose that there are no commercial or financial relationships that could potentially create a conflict of interest regarding this research.The research received no support of funding.The referencing style used in the study is APA formatting style.7.},
  archive      = {J_FRAI},
  author       = {George, Ajimon and Susan Mathew, Maria},
  doi          = {10.3389/frai.2025.1605855},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1605855},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-powered creative stimulus: The ascent of virtual virtuoso entrepreneurship},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nnU-net-based automatic segmentation of FCD type II lesions in 3D FLAIR MRI images. <em>FRAI</em>, <em>8</em>, 1601815. (<a href='https://doi.org/10.3389/frai.2025.1601815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Focal cortical dysplasia (FCD) type II is a common cause of epilepsy and is challenging to detect due to its similarities with other brain conditions. Finding these lesions accurately is essential for successful surgery and seizure control. Manual detection is slow and challenging because the MRI features are subtle. Deep learning, especially convolutional neural networks, has shown great potential in automating image classification and segmentation by learning and extracting features. The nnU-Net framework is known for its ability to adapt its settings, including preprocessing, network design, training, and post-processing, to any new medical imaging task. This study employs an automated slice selection approach that ranks axial FLAIR slices by their peak voxel intensity and retains the five highest-ranked slices per scan, thereby focusing the network on lesion-rich slices and uses nnU-Net to automate the segmentation of FCD type II lesions on 3D FLAIR MRI images. The study was conducted on 85 FCD type II subjects and results are evaluated through 5-fold cross-validation. Using nnU-Net’s flexible and robust design, this study aims to improve the accuracy and speed of lesion detection, helping with better presurgical evaluations and outcomes for epilepsy patients.},
  archive      = {J_FRAI},
  author       = {Joshi, Shubham and Pant, Millie and Malhotra, Arnav and Deep, Kusum and Snasel, Vaclav},
  doi          = {10.3389/frai.2025.1601815},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1601815},
  shortjournal = {Front. Artif. Intell.},
  title        = {A nnU-net-based automatic segmentation of FCD type II lesions in 3D FLAIR MRI images},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning based assessment of hoarseness severity: A multi-sensor approach centered on high-speed videoendoscopy. <em>FRAI</em>, <em>8</em>, 1601716. (<a href='https://doi.org/10.3389/frai.2025.1601716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionFunctional voice disorders are characterized by impaired voice production without primary organic changes, posing challenges for standardized assessment. Current diagnostic methods rely heavily on subjective evaluation, suffering from inter-rater variability. High-speed videoendoscopy (HSV) offers an objective alternative by capturing true intra-cycle vocal fold behavior. Integrating time-synchronized acoustic and HSV recordings could allow for an objective visual and acoustic assessment of vocal function based on a single HSV examination. This study investigates a machine learning-based approach for hoarseness severity assessment using synchronous HSV and acoustic recordings, alongside conventional voice examinations.MethodsThree databases comprising 457 HSV recordings of the sustained vowel /i/, 634 HSV-synchronized acoustic recordings, and clinical parameters from 923 visits were analyzed. Subjects were classified into two hoarseness groups based on auditory-perceptual ratings, with predicted scores serving as continuous hoarseness severity ratings. A videoendoscopic model was developed by selecting a suitable classification algorithm and a minimal-optimal subset of glottal parameters. This model was compared against an acoustic model based on HSV-synchronized recordings and a clinical model based on parameters from other examinations. Two ensemble models were constructed by combining the HSV-based models and all models, respectively. Model performance was evaluated on a shared test set based on classification accuracy, correlation with subjective ratings, and correlation between predicted and observed changes in hoarseness severity.ResultsThe videoendoscopic, acoustic, and clinical model achieved correlations of 0.464, 0.512, and 0.638 with subjective hoarseness ratings. Integrating glottal and acoustic parameters into the HSV-based ensemble model improved correlation to 0.603, confirming the complementary nature of time-synchronized HSV and acoustic recordings. The ensemble model incorporating all modalities achieved the highest correlation of 0.752, underscoring the diagnostic value of multimodal objective assessments.DiscussionThis study highlights the potential of synchronous HSV and acoustic recordings for objective hoarseness severity assessment, offering a more comprehensive evaluation of vocal function. While practical challenges remain, the integration of these modalities led to notable improvements, supporting their complementary value in enhancing diagnostic accuracy. Future advancements could include flexible nasal endoscopy to enable more natural phonation and refinement of glottal parameter extraction to improve model robustness under variable recording conditions.},
  archive      = {J_FRAI},
  author       = {Schraut, Tobias and Schützenberger, Anne and Arias-Vergara, Tomás and Kunduk, Melda and Echternach, Matthias and Dürr, Stephan and Werz, Julia and Döllinger, Michael},
  doi          = {10.3389/frai.2025.1601716},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1601716},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning based assessment of hoarseness severity: A multi-sensor approach centered on high-speed videoendoscopy},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The evaluation of performance for agroecological greenhouse tomato strategies by the CRITIC-OWA model. <em>FRAI</em>, <em>8</em>, 1599334. (<a href='https://doi.org/10.3389/frai.2025.1599334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionModern agriculture must begin to use production strategies that are increasingly sustainable. To help in decision-making, the present work analyzes the sustainability of greenhouse tomato production with different agroecological strategies: shading (conventional fixed mesh and mobile photovoltaic shading), grafting and deficit irrigation, based on economic, social, and environmental criteria.MethodsFor the ranking of the different strategies, the use of an extension of the CRiteria Importance Through Inter-criteria Correlation (CRITIC) is proposed, in which the correlation between the criteria is obtained through the Pearson-OWA, where the aggregation of the quadratic differences between criteria is carried out considering the attitudinal character of the decision-maker, that is, using Ordered Weighted Averaging (OWA), in addition to induced variables, with the Induced Probabilistic OWA CRITIC (IPOWA CRITIC). Three extensions are considered based on this model depending on the way the multicriteria score is calculated: i) the ranking is carried out on the relative score (S) of each alternative (IPOWA-S-CRITIC), ii) on the weighting vector (W) (IPOWA-W-CRITIC), or iii) on both (IPOWA-S-W-CRITIC).ResultsThe results of the classifications conducted indicate that the use of mobile photovoltaic mesh is a sustainable production strategy, due to its effect on production and quality of the crop, CO2 fixation, and irrigation water savings.DiscussionThe use of mobile photovoltaic shades is compatible with tomato cultivation in a greenhouse if the management of the installation is performed considering the needs of the plants in most of the rankings.},
  archive      = {J_FRAI},
  author       = {Brotons-Martínez, José Manuel and Cámara-Zapata, José María},
  doi          = {10.3389/frai.2025.1599334},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1599334},
  shortjournal = {Front. Artif. Intell.},
  title        = {The evaluation of performance for agroecological greenhouse tomato strategies by the CRITIC-OWA model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the potential for application of machine learning in predicting weather-sensitive waterborne diseases in selected districts of tanzania. <em>FRAI</em>, <em>8</em>, 1597727. (<a href='https://doi.org/10.3389/frai.2025.1597727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study evaluates the potential of machine learning (ML) to predict and manage weather-sensitive waterborne diseases (WSWDs) in selected Tanzanian districts, focusing on environmental health officers' (EHOs) knowledge and perceptions. It explores EHOs' familiarity with information and communication technology (ICT) and artificial intelligence (AI)/ML, alongside challenges and opportunities for integrating AI-driven public health solutions.MethodsA census-style survey was conducted among EHOs in three district councils. A structured questionnaire, piloted in one district, was administered to 76 EHOs, achieving a 66% response rate. Data were analyzed using descriptive and inferential statistics to assess knowledge levels, perceptions, and gender-related differences.ResultsMost EHOs were moderately familiar with ICT; however, only 54% had prior exposure to AI/ML concepts, and 64% reported limited AI familiarity. Among the variables examined, only prior exposure to AI/ML concepts and self-reported familiarity with AI demonstrated statistically significant associations with gender. Despite this, the majority recognized AI/ML's potential to improve disease prediction accuracy. Key barriers to ML adoption include inadequate technical infrastructure, data quality issues, and a shortage of expertise. Opportunities identified included utilizing historical disease data, integrating AI with meteorological information, and using satellite imagery for surveillance.DiscussionThe study highlights frontline health workers' perceived barriers to ML adoption and suggests that gender influences awareness and engagement with AI and ML technologies. Strengthening technical capacity, improving data quality, and fostering cross-sector collaboration are critical for successful AI/ML integration. These insights offer a roadmap for resilience to WSWDs in developing countries like Tanzania through data-driven technologies.},
  archive      = {J_FRAI},
  author       = {Lyimo, Neema Nicodemus and Fue, Kadeghe Goodluck and Materu, Silvia Francis and Kilatu, Ndimile Charles and Telemala, Joseph Philipo},
  doi          = {10.3389/frai.2025.1597727},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1597727},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing the potential for application of machine learning in predicting weather-sensitive waterborne diseases in selected districts of tanzania},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based feature selection for detection of autism spectrum disorder. <em>FRAI</em>, <em>8</em>, 1594372. (<a href='https://doi.org/10.3389/frai.2025.1594372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAutism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by challenges in communication, social interactions, and repetitive behaviors. The heterogeneity of symptoms across individuals complicates diagnosis. Neuroimaging techniques, particularly resting-state functional MRI (rs-fMRI), have shown potential for identifying neural signatures of ASD, though challenges such as high dimensionality, noise, and small sample sizes hinder their clinical application.MethodsThis study proposes a novel approach for ASD detection utilizing deep learning and advanced feature selection techniques. A hybrid model combining Stacked Sparse Denoising Autoencoder (SSDAE) and Multi-Layer Perceptron (MLP) is employed to extract relevant features from rs-fMRI data in the ABIDE I dataset, which was preprocessed using the CPAC pipeline. Feature selection is enhanced through an optimized Hiking Optimization Algorithm (HOA) that integrates DynamicOpposites Learning (DOL) and Double Attractors to improve convergence toward the optimal subset of features.ResultsThe proposed model is evaluated using multiple ASD datasets. The performance metrics include an average accuracy of 0.735, sensitivity of 0.765, and specificity of 0.752, surpassing the results of existing state-of-the-art methods.DiscussionThe findings demonstrate the effectiveness of the hybrid deep learning approach for ASD detection. The enhanced feature selection process, coupled with the hybrid model, addresses limitations in current neuroimaging analyses and offers a promising direction for more accurate and clinically applicable ASD detection models.},
  archive      = {J_FRAI},
  author       = {Nafisah, Ibrahim and Mahmoud, Nermine and Ewees, Ahmed A. and Khattap, Mohamed G. and Dahou, Abdelghani and Alghamdi, Safar M. and Fares, Ibrahim A. and Azmi Al-Betar, Mohammed and Abd Elaziz, Mohamed},
  doi          = {10.3389/frai.2025.1594372},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1594372},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning-based feature selection for detection of autism spectrum disorder},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biologically inspired hybrid model for alzheimer’s disease classification using structural MRI in the ADNI dataset. <em>FRAI</em>, <em>8</em>, 1590599. (<a href='https://doi.org/10.3389/frai.2025.1590599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline and structural brain alterations such as cortical atrophy and hippocampal degeneration. Early diagnosis remains challenging due to subtle neuroanatomical changes in early stages. This study proposes a hybrid convolutional neural network-spiking neural network (CNN-SNN) architecture to classify AD stages using structural MRI (sMRI) data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). The model synergizes CNNs for hierarchical spatial feature extraction and SNNs for biologically inspired temporal dynamics processing. The CNN component processes image slices through convolutional layers, batch normalization, and dropout, while the SNN employs leaky integrate-and-fire (LIF) neurons across 25 time steps to simulate temporal progression of neurodegeneration—even with static sMRI inputs. Trained on a three-class task [AD, mild cognitive impairment (MCI), and cognitively normal (CN) subjects], the hybrid network optimizes mean squared error (MSE) loss with L2 regularization and Adam, incorporating early stopping to enhance generalization. Evaluation on ADNI data demonstrates robust performance, with training/validation accuracy and loss tracked over 30 epochs. Classification metrics (precision, recall, F1-score) highlight the model’s ability to disentangle complex spatiotemporal patterns in neurodegeneration. Visualization of learning curves further validates stability during training. An ablation study demonstrates the SNN’s critical role, with its removal reducing accuracy from 99.58 to 75.67%, underscoring the temporal module’s importance. The SNN introduces architectural sparsity via spike-based computation, reducing overfitting and enhancing generalization while aligning with neuromorphic principles for energy-efficient deployment. By bridging deep learning with neuromorphic principles, this work advances AD diagnostic frameworks, offering a computationally efficient and biologically plausible approach for clinical neuroimaging. The results underscore the potential of hybrid CNN-SNN architectures to improve early detection and stratification of neurodegenerative diseases, paving the way for future applications in neuromorphic healthcare systems.},
  archive      = {J_FRAI},
  author       = {Slimi, Houmem and Cherif, Imen and Abid, Sabeur and Sayadi, Mounir},
  doi          = {10.3389/frai.2025.1590599},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1590599},
  shortjournal = {Front. Artif. Intell.},
  title        = {Biologically inspired hybrid model for alzheimer’s disease classification using structural MRI in the ADNI dataset},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging psychedelic neuroscience to boost human creativity using artificial intelligence. <em>FRAI</em>, <em>8</em>, 1589086. (<a href='https://doi.org/10.3389/frai.2025.1589086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychedelics, such as LSD and psilocybin, disrupt entrenched cognitive patterns by facilitating novel insights and new associations. This paper considers how AI can potentially mimic these psychedelic-induced cognitive disruptions to augment and enhance human creativity. Psychedelics likely enhance creativity by altering brain function, notably the activity of the Default Mode Network, which leads to changes in cognition. Psychologically, they may reduce latent inhibition, increase divergent thinking, and promote implicit learning. Similarly, AI systems can replicate these creative enhancements by introducing novel associations, reframing familiar information, and facilitating unconscious cognitive shifts. The risks associated with AI use are also compared to psychedelics, including dependency, ethical concerns, and homogenization of outputs due to bias. Integrating the cognitive mechanisms activated by psychedelics into AI design provides promising pathways for creativity enhancement. Carefully designed AI could act as a cognitive catalyst, fostering innovative thought processes and adaptive problem-solving while addressing identified ethical and practical concerns.},
  archive      = {J_FRAI},
  author       = {Ross, Brian M.},
  doi          = {10.3389/frai.2025.1589086},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1589086},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging psychedelic neuroscience to boost human creativity using artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the construction of artificial general intelligence based on the correspondence between goals and means. <em>FRAI</em>, <em>8</em>, 1588726. (<a href='https://doi.org/10.3389/frai.2025.1588726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans are goal-directed agents and intelligence is suggested to be a characteristic of such agents. AGI can be achieved following the principle of the goals-means correspondence that posits the necessary condition for achieving a goal is the correspondence between the goal and the means. The goals-means correspondence is used in all architectures underlying intelligent systems. There are two conventional architectures regarding how the correspondence can be established. One conventional architecture that is based on observations of animals, is intelligent agents whose goals, means, or criteria for its construction are determined jointly at the moment of the birth of an agent. The other conventional architecture that is based on the analysis of human actions, defines intelligent agents whose goals and means are constructed arbitrarily and independently from each other. The conventional architectures cannot explain human actions and thinking. Since the conventional architectures underlie all artificial intelligent systems these systems are insufficient to construct AGI. The formal analysis of architectures demonstrates that there is another architecture in that arbitrary goals and means are constructed jointly on the basis of the criterion of minimal construction costs. This architecture is suggested to underlie human goal-directed processes. The view on humans as goal-directed agents constructing goals and means jointly allows creating an AGI agent that is capable of functioning in real situations. Unlike conventional AI agents that have an unaltered structure, the structure of agents in the new architecture is alterable. The development of an AGI agent may be similar to human growth from an infant to an adult. A model including a simple agent based on the new architecture, is considered. In the model the agent wanders in a quadrangular field filled with various objects that stimulate the agent to move in several directions simultaneously, thus trapping the agent. However, changing its structure the agent constructs goal-directed processes; therefore it is capable of leaving traps.},
  archive      = {J_FRAI},
  author       = {Prudkov, Pavel},
  doi          = {10.3389/frai.2025.1588726},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1588726},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the construction of artificial general intelligence based on the correspondence between goals and means},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI generations: From AI 1.0 to AI 4.0. <em>FRAI</em>, <em>8</em>, 1585629. (<a href='https://doi.org/10.3389/frai.2025.1585629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and a speculative AI 4.0 (Conscious AI). Each AI generation is driven by shifting priorities among algorithms, computing power, and data. AI 1.0 accompanied breakthroughs in pattern recognition and information processing, fueling advances in computer vision, natural language processing, and recommendation systems. AI 2.0 is built on these foundations through real-time decision-making in digital environments, leveraging reinforcement learning and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world settings. Building on these developments, the proposed AI 4.0 puts forward the bold vision of self-directed AI capable of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of machine consciousness. This paper traces the historical foundations of AI across roughly 70 years, mapping how changes in technological bottlenecks from algorithmic innovation to high-performance computing to specialized data have stimulated each generational leap. It further highlights the ongoing synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the ethical, regulatory, and philosophical challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting responsible governance, and ensuring that AI’s transformative potential benefits society.},
  archive      = {J_FRAI},
  author       = {Wu, Jiahao and You, Hengxu and Du, Jing},
  doi          = {10.3389/frai.2025.1585629},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1585629},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI generations: From AI 1.0 to AI 4.0},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Who speaks next? multi-party AI discussion leveraging the systematics of turn-taking in murder mystery games. <em>FRAI</em>, <em>8</em>, 1582287. (<a href='https://doi.org/10.3389/frai.2025.1582287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMulti-agent systems utilizing large language models (LLMs) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenging.MethodsIn this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called “Murder Mystery Agents” that applies these norms to AI agents' dialogue control. As an evaluation target, we employed the “Murder Mystery” game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue.ResultsTo verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using LLMs, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning.DiscussionThe results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among AI agents, and provide design guidelines for more advanced multi-agent dialogue systems.},
  archive      = {J_FRAI},
  author       = {Nonomura, Ryota and Mori, Hiroki},
  doi          = {10.3389/frai.2025.1582287},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1582287},
  shortjournal = {Front. Artif. Intell.},
  title        = {Who speaks next? multi-party AI discussion leveraging the systematics of turn-taking in murder mystery games},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture of prompts learning for vision-language models. <em>FRAI</em>, <em>8</em>, 1580973. (<a href='https://doi.org/10.3389/frai.2025.1580973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As powerful pre-trained vision-language models (VLMs) like CLIP gain prominence, numerous studies have attempted to combine VLMs for downstream tasks. Among these, prompt learning has been validated as an effective method for adapting to new tasks, which only requires a small number of parameters. However, current prompt learning methods face two challenges: first, a single soft prompt struggles to capture the diverse styles and patterns within a dataset; second, fine-tuning soft prompts is prone to overfitting. To address these challenges, we propose a mixture-of-prompts learning method incorporating a routing module. This module is able to capture a dataset's varied styles and dynamically select the most suitable prompts for each instance. Additionally, we introduce a novel gating mechanism to ensure the router selects prompts based on their similarity to hard prompt templates, which both retains knowledge from hard prompts and improves selection accuracy. We also implement semantically grouped text-level supervision, initializing each soft prompt with the token embeddings of manually designed templates from its group and applying a contrastive loss between the resulted text feature and hard prompt encoded text feature. This supervision ensures that the text features derived from soft prompts remain close to those from their corresponding hard prompts, preserving initial knowledge and mitigating overfitting. Our method has been validated on 11 datasets, demonstrating evident improvements in few-shot learning, domain generalization, and base-to-new generalization scenarios compared to existing baselines. Our approach establishes that multi-prompt specialization with knowledge-preserving routing effectively bridges the adaptability-generalization tradeoff in VLM deployment. The code will be available at https://github.com/dyabel/mocoop.},
  archive      = {J_FRAI},
  author       = {Du, Yu and Niu, Tong and Zhao, Rong},
  doi          = {10.3389/frai.2025.1580973},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1580973},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mixture of prompts learning for vision-language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Irrationality in humans and creativity in AI. <em>FRAI</em>, <em>8</em>, 1579704. (<a href='https://doi.org/10.3389/frai.2025.1579704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript explores how human irrationality in decision-making can contribute to artificial intelligence (AI) development, particularly in the domain of creativity. While irrational behavior is typically seen as a cognitive flaw, we argue that certain forms of irrationality, such as those demonstrated by the conjunction fallacy (CF), may represent context-sensitive reasoning that reveals creative problem-solving. Traditional AI research has primarily focused on rational, logic-driven models, overlooking the productive role of non-linear and seemingly illogical human thinking in generating novel insights. Drawing on interdisciplinary insights and recent neuroscientific findings, particularly the interaction of the Default Mode, Executive Control, and Salience Networks, we propose a model that integrates both rational and irrational cognitive dynamics. This framework may inform the design of AI systems that are more adaptive, context-aware, and capable of emulating human-like creativity.},
  archive      = {J_FRAI},
  author       = {Sobetska, Olha},
  doi          = {10.3389/frai.2025.1579704},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1579704},
  shortjournal = {Front. Artif. Intell.},
  title        = {Irrationality in humans and creativity in AI},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularization by neural style transfer for MRI field-transfer reconstruction with limited data. <em>FRAI</em>, <em>8</em>, 1579251. (<a href='https://doi.org/10.3389/frai.2025.1579251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in MRI reconstruction have demonstrated remarkable success through deep learning-based models. However, most existing methods rely heavily on large-scale, task-specific datasets, making reconstruction in data-limited settings a critical yet underexplored challenge. While regularization by denoising (RED) leverages denoisers as priors for reconstruction, we propose Regularization by Neural Style Transfer (RNST), a novel framework that integrates a neural style transfer (NST) engine with a denoiser to enable magnetic field-transfer reconstruction. RNST generates high-field-quality images from low-field inputs without requiring paired training data, leveraging style priors to address limited-data settings. Our experiment results demonstrate RNST’s ability to reconstruct high-quality images across diverse anatomical planes (axial, coronal, sagittal) and noise levels, achieving superior clarity, contrast, and structural fidelity compared to lower-field references. Crucially, RNST maintains robustness even when style and content images lack exact alignment, broadening its applicability in clinical environments where precise reference matches are unavailable. By combining the strengths of NST and denoising, RNST offers a scalable, data-efficient solution for MRI field-transfer reconstruction, demonstrating significant potential for resource-limited settings.},
  archive      = {J_FRAI},
  author       = {Shen, Guoyao and Zhu, Yancheng and Li, Mengyu and McNaughton, Ryan and Jara, Hernan and Andersson, Sean B. and Farris, Chad W. and Anderson, Stephan and Zhang, Xin},
  doi          = {10.3389/frai.2025.1579251},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1579251},
  shortjournal = {Front. Artif. Intell.},
  title        = {Regularization by neural style transfer for MRI field-transfer reconstruction with limited data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepSeek vs. ChatGPT: Prospects and challenges. <em>FRAI</em>, <em>8</em>, 1576992. (<a href='https://doi.org/10.3389/frai.2025.1576992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DeepSeek has introduced its recent model DeepSeek-R1, showing divergence from OpenAI’s ChatGPT, suggesting an open-source alternative to users. This paper analyzes the architecture of DeepSeek-R1, mainly adopting rule-based reinforcement learning (RL) without preliminary supervised fine-tuning (SFT), which has shown better efficiency. By integrating multi-stage training along with cold-start data usage before RL, the model can achieve meaningful performance in reasoning tasks along with reward modeling optimizing training process. DeepSeek shows its strength in technical, reasoning tasks, able to show its decision-making process through open source whereas ChatGPT shows its strength on general tasks and areas requiring creativeness. Despite the groundbreaking developments of both models, there is room for improvement in AI landscape and matters to be handled such as quality of data, black box problems, privacy management, and job displacement. This paper suggests the future of AI, expecting better performance in multi-modal tasks, enhancing its effectiveness in handling larger data sets, enabling users with improved AI landscapes and utility.},
  archive      = {J_FRAI},
  author       = {Jin, Inhye and Tangsrivimol, Jonathan A. and Darzi, Erfan and Hassan Virk, Hafeez Ul and Wang, Zhen and Egger, Jan and Hacking, Sean and Glicksberg, Benjamin S. and Strauss, Markus and Krittanawong, Chayakrit},
  doi          = {10.3389/frai.2025.1576992},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1576992},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepSeek vs. ChatGPT: Prospects and challenges},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stylistic variation across english translations of chinese science fiction: Ken liu versus ChatGPT. <em>FRAI</em>, <em>8</em>, 1576750. (<a href='https://doi.org/10.3389/frai.2025.1576750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in computational tools, including neural machine translation (NMT) and large language models (LLMs), have revolutionized literary stylistics and opened new avenues in corpus-based translation studies (CBTS). Yet, the style of LLM-produced translations, especially in science fiction (SF) literature, remain understudied. This study examines stylistic variation across English translations of Chinese SF by translator Ken Liu and ChatGPT-4o. Thirteen works translated by both were compared using Multi-Dimensional analysis on key dimensions. Stylometric tests assessed within-translator and between-translator variations, and functional analysis interpreted the subordinate linguistic features. Findings reveal that Ken Liu adapts his style to each story’s depth, exhibiting greater variation, while GPT maintains a more consistent style. Ken Liu’s less narrative style enhances resonance through a minimalist approach, whereas GPT’s more narrative style offers clarity but may undermine thematic impact. The study contributes to CBTS by providing a methodological framework for comparing human and LLM translations in terms of style. It highlights a collaborative model that combines human creativity with LLM efficiency, necessitating continuous upskilling among students, educators, and practitioners to adapt to LLMs’ growing presence in translation. Ultimately, by exploring the intersection of linguistics, literature, and artificial intelligence, the study pushes the boundaries of translation studies and practices.},
  archive      = {J_FRAI},
  author       = {Zhou, Pingdi and Cheng, Jiajun},
  doi          = {10.3389/frai.2025.1576750},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1576750},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stylistic variation across english translations of chinese science fiction: Ken liu versus ChatGPT},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A conceptual exploration of generative AI-induced cognitive dissonance and its emergence in university-level academic writing. <em>FRAI</em>, <em>8</em>, 1573368. (<a href='https://doi.org/10.3389/frai.2025.1573368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {University-level academic writing is a form of scholarly communication that demands precision, clarity, and adherence to established conventions. It is a skill fundamental to science education, best honed through continuous practice (Moskovitz & Kellogg, 2011). However, rising academic demands and evolving educational environments, such as shifts to online learning, introduce new challenges. Students often view writing as a daunting task, largely due to insufficient instruction bridging technical composition and creative expression in their coursework (Stride, 2024). Non-native speakers find this struggle compounded, grappling with the linguistic precision and stylistic conventions of academic writing (Nazaroff, 2011). Furthermore, traditional academic writing has also suffered from an overemphasis on technical correctness at the expense of fostering creative expression. In many cases, the perceived marginal role of writing in research and teaching has led educators to delegate writing instruction solely to language departments (Alley, 2024). Such delegation has resulted in a fragmented approach to teaching writing skills, leaving many students underprepared. In the advent of Generative Artificial Intelligence (GenAI), some students now assume that technology can fully compensate for their underdeveloped writing abilities, inadvertently undervaluing the importance of building a strong writing foundation.GenAI tools-such as ChatGPT™ by OpenAI, Gemini™ by Google, and Claude™ by Anthropichave emerged as practical aids for organizing and simplifying writing tasks such as article reviews, lab reports, and research papers (Essel et al., 2024). These technologies help reduce the cognitive load by shifting focus from the mechanical aspects of writing to higher-level critical analysis and interpretation (Olatunbosun & Nwankwo, 2024). However, their integration into academic practice often creates an ambiguous boundary between human intellectual effort and machine assistance (Amoozadeh et al., 2024), hence leading to what we term as cognitive dissonance (CD), a classic social psychology theory introduced by Festinger in 1957. CD is the inconsistency in thoughts, actions, or behavior that leads to a tension or discomfort from holding contradictory beliefs (Hilberg, 2017). This tension is resolved by changing our thoughts or behaviors, adding a new thought, or rationalizing the inconsistencies (Oxoby & Smith, 2014).To date, no consensus has been reached regarding the manifestation of cognitive dissonance in the integration of GenAI in university-level academic writing. Here, we provide a novel perspective on how CD emerges with the integration of GenAI in university-level academic writing. We posit that GenAI both triggers and exacerbates pre-existing tensions, reshaping academic writing dynamics. Furthermore, exploring pedagogical frameworks like constructivism may offer pathways to mitigate these emerging challenges and help students integrate GenAI tools responsibly.Cognitive dissonance has long been a topic of concern in academic writing. Traditionally, it refers to the psychological tension experienced when students' ideals clash with the practical constraints they face (McGrath, 2017). Operationalized as a state of psychological discomfort (Vaidis & Bran, 2019), CD in academic writing often emerges from the conflicting demands between producing high-quality, original work and managing limited time, resources, or guidance. The magnitude of the dissonance experienced depends on the importance of the conflicting cognitions and the proportion of dissonant versus consonant thoughts related to a specific behavior or belief (Festinger, 1957). When faced with this discomfort, individuals are strongly motivated to reduce it. Classic dissonance reduction strategies include: (1) changing one of the dissonant cognitions (e.g., altering one's attitude towards academic integrity), (2) changing behavior to align with cognitions (e.g., stopping the use of GenAI in ways perceived as dishonest), ( 3) adding new consonant cognitions to justify the behavior (e.g., emphasizing the time saved allows focus on higher-level thinking), or (4) trivializing the conflict itself (e.g., deciding that the specific assignment is not important anyway) (McGrath, 2017;Stephens, 2017). Understanding these mechanisms is crucial for analyzing how students might react to the internal conflicts provoked by GenAI use in academic writing. For example, ethical dilemmas may arise when the pressure to publish meets the rigorous standards of originality and research integrity (Schrems & Upham, 2020). This internal conflict can lead students to adopt selective coping strategies, such as focusing only on information that confirms their existing beliefs (Metzger et al., 2020), or in some cases, resorting to dishonest practices (Stephens, 2017). In traditional academic settings, CD can serve as both a source of psychological stress and a catalyst for personal growth. This occurrence prompts students to recalibrate their beliefs and strive for higher standards. However, the introduction of GenAI into this landscape introduces new dimensions of dissonance that are still not fully understood.A trigger, in this context, refers to any factor that disrupts an individual's core beliefs and values, creating psychological tension. GenAI's efficiency, while beneficial, directly conflicts with the academic values of originality, effort, and intellectual ownership. Empirical studies (Chan, 2024;Playfoot et al., 2024) provide evidence that GenAI use can lead to what some describe as "AIgiarism" -a nuanced form of plagiarism where students, while disapproving of overt AI-generated content, find themselves ambivalent about employing AI for paraphrasing or idea generation. For instance, Chan (2024) found significant ethical ambivalence regarding AI use for idea generation versus direct submission. Moreover, Playfoot et al. (2024) explored the adoption of ChatGPT TM for writing tasks. The 467 participants expressed ambivalence toward ethical boundaries where 68% recognized GenAI use conflicted with academic integrity, while 52% prioritized convenience and perceived low detection risks. This exemplifies CD as the efficiency of GenAI contradicts with values like originality and effort.This ethical ambivalence and conflict between values and convenience exemplify CD in action: the psychological discomfort arises from incompatible cognitions (e.g., "Upholding academic integrity is important" vs. "Using GenAI for this task is efficient and tempting"). According to theory, this discomfort motivates individuals to reduce the dissonance, potentially by downplaying the importance of integrity, justifying the AI use, or altering their behavior (McGrath, 2017;Stephens, 2017).Beyond serving as an initial trigger, GenAI can also exacerbate pre-existing tensions in academic writing. While academic challenges such as balancing clarity with complexity have long existed, GenAI potentially heightens these issues. For instance, Zhai et al. (2024) highlighted a student preference for efficiency over deep cognitive engagement; leveraging GenAI for efficiency could correlate with this trend. Similarly, Ironsi and Solomon Ironsi (2025) observed a conflict between perceived GenAI benefits for clarity and concerns about independent skill development. Hutson (2024) added that habitual GenAI use encourages cognitive shortcuts, potentially undermining learning.These findings suggest GenAI heightens dissonance related to self-efficacy and learning goals. The conflict between the desire for genuine skill development ("I need to learn to write independently") and the reliance on an external tool ("GenAI helps me produce clear text easily") creates discomfort. This may lead students to adopt dissonance-reducing strategies such as rationalizing their dependence on AI, minimizing the value of independent writing skills for certain tasks, or experiencing increased anxiety and self-doubt (related to impostor syndrome) (McGrath, 2017;Stephens, 2017). In this light, GenAI is not merely introducing new ethical dilemmas but is also potentially exacerbating existing academic pressures and internal conflicts. The relationship between GenAI, CD and behavioral outcomes in academic settings is visually summarized in Figure 1, which illustrates GenAI as both a trigger and exacerbator of CD.Figure 1. Hypothetical construct of GenAI-induced CD. GenAI is both a trigger and an exacerbator of CD in academic writing. The figure illustrates how the integration of GenAI disrupts core academic values, leading to CD. This is manifested as self-doubt, ethical dilemmas, and confidence erosion, among others. These psychological tensions influence behavioral outcomes, including avoidance of effortful tasks, reassessment of academic values, and justification of AI use. The process is further exacerbated by increasing dependence on GenAI, which exacerbates existing struggles related to skills development and academic integrity.Addressing the cognitive dissonance triggered or exacerbated by GenAI requires pedagogical approaches that go beyond simply regulating tool use. Constructivist pedagogy offers a promising framework because its core tenets directly counter some of the sources of dissonance. Constructivism emphasizes that learners actively construct their own understanding through experience, reflection, and social interaction, rather than passively receiving information. This contrasts sharply with the potential for passive reliance on GenAI outputs.Specifically, constructivist approaches may mitigate GenAI-related CD in several ways: 1. Emphasis on Process and Reflection: By valuing the learning process, reflection, and metacognition (Alt et al., 2022), constructivism helps students focus on their own intellectual journey. This can reduce the dissonance arising from the conflict between using an 'easy' tool and the value placed on effort and genuine understanding. Reflecting on how and why they use GenAI allows students to integrate the tool into their process in a way that feels authentic and justifiable, reducing integrity-related dissonance. 2. Active Engagement and Authentic Tasks: Constructivist learning often involves complex, authentic tasks that require critical thinking, problem-solving, and synthesis -skills where current GenAI may be less effective as a complete substitute. Engaging deeply with such tasks reinforces the value of human intellect and skill development, potentially reducing dissonance related to fears of skill atrophy or over-reliance (Tan & Maravilla, 2024). Active construction of knowledge fosters a sense of ownership that can counteract feelings of inadequacy or impostor syndrome sometimes associated with heavy GenAI use. 3. Fostering Internal Motivation: Constructivist environments aim to foster intrinsic motivation by making learning meaningful and relevant. When students are internally motivated to understand and create, the external pressure to simply complete tasks efficiently (a potential trigger for dissonance when using GenAI shortcuts) may be lessened.Therefore, applying constructivist principles to assignment design and classroom practice could help students navigate the use of GenAI more ethically and productively, transforming potential dissonance into opportunities for meaningful learning about both the subject matter and the responsible use of technology.Below are practical strategies, informed by dissonance reduction principles and constructivist pedagogy, to help navigate GenAI use in academic writing.Universities need clear policies on transparency, attribution, integrity, and acceptable levels of GenAI assistance (e.g., distinguishing support from unacceptable content generation) to mitigate ethical dilemmas. By reducing ambiguity about acceptable use and providing clear behavioral pathways aligned with academic values, such policies can decrease the internal conflict (CD) students experience when balancing the utility of GenAI with the demands of integrity.Alongside these policies, professional development for faculty is essential. Training in prompt engineering, for instance, can enable instructors to design precise, thought-provoking prompts that stimulate critical thinking and may even require students to evaluate or critique GenAI outputs (Lee & Palmer, 2025). While student over-reliance on GenAI for task completion is a primary concern leading to dissonance, instructor use of prompt engineering serves a distinct pedagogical purpose. It focuses on leveraging AI as a design tool to enhance critical thinking challenges and model thoughtful, ethical engagement with the technology, rather than replacing the student's learning process or facilitating academic dishonesty. Integrating prompt-generation practices or using GenAI for formative feedback can reinforce the view of GenAI as a supportive tool rather than a substitute for original thought. Dedicated AI literacy modules should teach critical evaluation of AI content, its limitations, and differentiation from human effort (Wang et al., 2024). For instance, students might compare ChatGPTgenerated summaries against scholarly sources or analyze outputs for bias. Practical activities like peer review focusing on the ethical use of sources (including AI) and analysis of information quality can help students build confidence and make informed decisions about GenAI use, further reducing potential CD.Instructors should incorporate reflective exercises related to students' writing processes. Reflective pedagogy boosts metacognitive awareness through self-assessment of GenAI's role (Alt et al., 2022). For example, after comparing GenAI outputs with other references, students might answer questions like, "Did GenAI's structure enhance or override my reasoning?" or "Did this process clarify my stance or obscure my effort?" Such reflection can reduce ethical tension and reinforce confidence in their own writing. Maintaining a digital journal comparing AI-assisted and manual drafts curbs over-dependence (Kim et al., 2025); peer review of excerpts can foster accountability. Instructors should participate in workshops featuring role-playing, reflective prompts, and journal analyses to better guide students in balancing AI use with personal insights.Educators must create a hybrid writing process that combats CD and skill degradation. One approach is to require students to submit two drafts: one incorporating AI assistance and a second, a manually refined version. For example, students could use GenAI to generate an initial literature review but manually craft the final version. This constructivist-based hybrid model helps students develop arguments from AI scaffolds (Tan & Maravilla, 2024). Updated rubrics should reward human effort, ensuring GenAI acts as support, not a substitute.The emergence of GenAI-induced CD in academic writing presents an urgent challenge for higher education. Universities must respond proactively by embedding strategies rooted in dissonance reduction and constructivist pedagogy. Explicitly establishing clear AI literacy programs, updated academic integrity policies, and reflective teaching practices will directly empower students and educators alike. These measures will further build their confidence and skills to responsibly use GenAI as a powerful tool for academic writing.},
  archive      = {J_FRAI},
  author       = {Seran, Carl Errol and Tan, Myles Joshua Toledo and Abdul Karim, Hezerul and AlDahoul, Nouar},
  doi          = {10.3389/frai.2025.1573368},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1573368},
  shortjournal = {Front. Artif. Intell.},
  title        = {A conceptual exploration of generative AI-induced cognitive dissonance and its emergence in university-level academic writing},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HMA-net: A hybrid mixer framework with multihead attention for breast ultrasound image segmentation. <em>FRAI</em>, <em>8</em>, 1572433. (<a href='https://doi.org/10.3389/frai.2025.1572433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionBreast cancer is a severe illness predominantly affecting women, and in most cases, it leads to loss of life if left undetected. Early detection can significantly reduce the mortality rate associated with breast cancer. Ultrasound imaging has been widely used for effectively detecting the disease, and segmenting breast ultrasound images aid in the identification and localization of tumors, thereby enhancing disease detection accuracy. Numerous computer-aided methods have been proposed for the segmentation of breast ultrasound images.MethodsA deep learning-based architecture utilizing a ConvMixer-based encoder and ConvNeXT-based decoder coupled with convolution-enhanced multihead attention has been proposed for segmenting breast ultrasound images. The enhanced ConvMixer modules utilize spatial filtering and channel-wise integration to efficiently capture local and global contextual features, enhancing feature relevance and thus increasing segmentation accuracy through dynamic channel recalibration and residual connections. The bottleneck with the attention mechanism enhances segmentation by utilizing multihead attention to capture long-range dependencies, thus enabling the model to focus on relevant features across distinct regions. The enhanced ConvNeXT modules with squeeze and excitation utilize depthwise convolution for efficient spatial filtering, layer normalization for stabilizing training, and residual connections to ensure the preservation of relevant features for accurate segmentation. A combined loss function, integrating binary cross entropy and dice loss, is used to train the model.ResultsThe proposed model has an exceptional performance in segmenting intricate structures, as confirmed by comprehensive experiments conducted on two datasets, namely the breast ultrasound image dataset (BUSI) dataset and the BrEaST dataset of breast ultrasound images. The model achieved a Jaccard index of 98.04% and 94.84% and a Dice similarity coefficient of 99.01% and 97.35% on the BUSI and BrEaST datasets, respectively.DiscussionThe ConvMixer and ConvNeXT modules are integrated with convolution-enhanced multihead attention, which enhances the model's ability to capture local and global contextual information. The strong performance of the model on the BUSI and BrEaST datasets demonstrates the robustness and generalization capability of the model.},
  archive      = {J_FRAI},
  author       = {Sara Koshy, Soumya and Anbarasi, L. Jani},
  doi          = {10.3389/frai.2025.1572433},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1572433},
  shortjournal = {Front. Artif. Intell.},
  title        = {HMA-net: A hybrid mixer framework with multihead attention for breast ultrasound image segmentation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). European sovereign debt control through reinforcement learning. <em>FRAI</em>, <em>8</em>, 1569395. (<a href='https://doi.org/10.3389/frai.2025.1569395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resilience of economic systems depends mainly on coordination among key stakeholders during macroeconomic or external shocks, while a lack of coordination can lead to financial and economic crises. The paper builds on the experience of global and regional shocks, such as the Eurozone crises of 2009–2012 and the economic disruption resulting from COVID-19, starting in 2020. The paper demonstrates the importance of cooperation in monetary and fiscal policies during emergencies to address macroeconomic non-resilience, particularly focusing on public debt management. The Euro area is chosen as the sample for testing the models presented in the paper, given that its resilience is heavily dependent on cooperation among different actors within the region. The shocks affecting nations within the European Union are asymmetric, and the responses to these shocks require coordination, considering heterogeneous economic structures, levels of economic development, and policies. We develop a macroeconomic modeling framework to simulate fiscal and monetary policy interactions under a cooperative regime. The approach builds on earlier nonlinear control models and incorporates modern reinforcement learning techniques. Specifically, we implement the Soft Actor-Critic algorithm to optimize policy responses across key variables including inflation, interest rates, output gaps, public debt, and government net lending. We demonstrate that the Soft Actor-Critic algorithm provides comparable or, in some cases, better solutions to multi-objective macroeconomic optimization problems, in comparison to Nonlinear Model Predictive Control (NMPC) algorithm.},
  archive      = {J_FRAI},
  author       = {Khundadze, Tato and Semmler, Willi},
  doi          = {10.3389/frai.2025.1569395},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1569395},
  shortjournal = {Front. Artif. Intell.},
  title        = {European sovereign debt control through reinforcement learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative AI cybersecurity and resilience. <em>FRAI</em>, <em>8</em>, 1568360. (<a href='https://doi.org/10.3389/frai.2025.1568360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Artificial Intelligence marks a critical inflection point in the evolution of machine learning systems, enabling the autonomous synthesis of content across text, image, audio, and biomedical domains. While these capabilities are advancing at pace, their deployment raises profound ethical, security, and privacy concerns that remain inadequately addressed by existing governance mechanisms. This study undertakes a systematic inquiry into these challenges, combining a PRISMA-guided literature review with thematic and quantitative analyses to interrogate the socio-technical implications of generative Artificial Intelligence. The article develops an integrated theoretical framework, grounded in established models of technology adoption, cybersecurity resilience, and normative governance. Structured across five lifecycle stages (design, implementation, monitoring, compliance, and feedback) the framework offers a practical schema for evaluating and guiding responsible AI deployment. The analysis reveals a disconnection between the fast adoption of generative systems and the maturity of institutional safeguards, resulting with new risks from the shadow Artificial Intelligence, and underscoring the need for adaptive, sector-specific governance. This study offers a coherent pathway towards ethically aligned and secure application of Artificial Intelligence in national critical infrastructure.},
  archive      = {J_FRAI},
  author       = {Radanliev, Petar and Santos, Omar and Ani, Uchenna Daniel},
  doi          = {10.3389/frai.2025.1568360},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1568360},
  shortjournal = {Front. Artif. Intell.},
  title        = {Generative AI cybersecurity and resilience},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Journaling with large language models: A novel UX paradigm for AI-driven personal health management. <em>FRAI</em>, <em>8</em>, 1567580. (<a href='https://doi.org/10.3389/frai.2025.1567580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe integration of large language models (LLMs) into personal health management presents transformative potential, but faces critical challenges in user experience (UX) design, ethical implementation, and clinical integration.MethodThis paper introduces a novel AI-driven journaling application, a functional prototype available open source, designed to encourage patient engagement through a natural language interface. This approach, termed “AI-assisted health journaling,” enables users to document health experiences in their own words while receiving real-time, context-aware feedback from an LLM. The prototype combines a personal health record with an LLM assistant, allowing for reflective self-monitoring and aiming to combine patient-generated data with clinical insights. Key innovations include a three-panel interface for seamless journaling, AI dialogue, and longitudinal tracking, alongside specialized modes for interacting with simulated healthcare expert personas.ResultPreliminary insights from persona-based evaluations highlight the system's capacity to enhance health literacy through explainable AI responses while maintaining strict data localization and privacy controls. We propose five design principles for patient-centric AI health tools: (1) decoupling core functionality from LLM dependencies, (2) layered transparency in AI outputs, (3) adaptive consent for data sharing, (4) clinician-facing data summarization, and (5) compliance-first architecture.DiscussionBy transforming unstructured patient narratives into structured insights through natural language processing, this approach demonstrates how journaling interfaces could serve as a critical middleware layer in healthcare ecosystems-empowering patients as active partners in care while preserving clinical oversight. Future research directions emphasize the need for rigorous trials evaluating impacts on care continuity, patient-provider communication, and long-term health outcomes across diverse populations.},
  archive      = {J_FRAI},
  author       = {Moëll, Birger and Sand Aronsson, Fredrik},
  doi          = {10.3389/frai.2025.1567580},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1567580},
  shortjournal = {Front. Artif. Intell.},
  title        = {Journaling with large language models: A novel UX paradigm for AI-driven personal health management},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence, complexity, and systemic resilience in global governance. <em>FRAI</em>, <em>8</em>, 1562095. (<a href='https://doi.org/10.3389/frai.2025.1562095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is reshaping international governance, presenting opportunities to enhance systemic resilience while posing significant ethical, social, and geopolitical challenges. This paper argues that complexity science offers a valuable framework for navigating AI's integration into global governance systems. We analyze AI's dual capacity as both a transformative tool for improving decision-making, resource allocation, and crisis management, and as a disruptive force introducing risks like data bias, exacerbated inequalities, and governance gaps. By framing resilience as a crucial, boundary concept bridging disciplines and practice, we advocate for adaptive, inclusive governance models capable of managing the inherent uncertainties of AI-driven complex socio-technical systems. Integrating complexity insights with principles like institutional modularity and robust stakeholder collaboration is vital for fostering equity, accountability, and sustainability. This study proposes a conceptual approach aiming to align technological innovation with societal values, ensuring AI deployment contributes to a more resilient and equitable global future, while at the same time it proposes complexity as a boundary concept to bridge the gap between governance literature and philosophy of science and technology.},
  archive      = {J_FRAI},
  author       = {Ilcic, Andrés and Fuentes, Miguel and Lawler, Diego},
  doi          = {10.3389/frai.2025.1562095},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1562095},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence, complexity, and systemic resilience in global governance},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VMDU-net: A dual encoder multi-scale fusion network for polyp segmentation with vision mamba and cross-shape transformer integration. <em>FRAI</em>, <em>8</em>, 1557508. (<a href='https://doi.org/10.3389/frai.2025.1557508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRectal cancer often originates from polyps. Early detection and timely removal of polyps are crucial for preventing colorectal cancer and inhibiting its progression to malignancy. While polyp segmentation algorithms are essential for aiding polyp removal, they face significant challenges due to the diverse shapes, unclear boundaries, and varying sizes of polyps. Additionally, capturing long-range dependencies remains difficult, with many existing algorithms struggling to converge effectively, limiting their practical application.MethodsTo address these challenges, we propose a novel Dual Encoder Multi-Scale Feature Fusion Network, termed VMDU-Net. This architecture employs two parallel encoders: one incorporates Vision Mamba modules, and the other integrates a custom-designed Cross-Shape Transformer. To enhance semantic understanding of polyp morphology and boundaries, we design a Mamba-Transformer-Merge (MTM) module that performs attention-weighted fusion across spatial and channel dimensions. Furthermore, Depthwise Separable Convolutions are introduced to facilitate multi-scale feature extraction and improve convergence efficiency by leveraging the inductive bias of convolution.ResultsExtensive experiments were conducted on five widely-used polyp segmentation datasets. The results show that VMDU-Net significantly outperforms existing state-of-the-art methods, especially in terms of segmentation accuracy and boundary detail preservation. Notably, the model achieved a Dice score of 0.934 on the Kvasir-SEG dataset and 0.951 on the CVC-ClinicDB dataset.DiscussionThe proposed VMDU-Net effectively addresses key challenges in polyp segmentation by leveraging complementary strengths of Transformer-based and Mamba-based modules. Its strong performance across multiple datasets highlights its potential for practical clinical application in early colorectal cancer prevention.Code availabilityThe source code is publicly available at: https://github.com/sulayman-lee0212/VMDUNet/tree/4a8b95804178511fa5798af4a7d98fd6e6b1ebf7.},
  archive      = {J_FRAI},
  author       = {Li, Peng and Ding, Jianhua and Lim, Chia S.},
  doi          = {10.3389/frai.2025.1557508},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1557508},
  shortjournal = {Front. Artif. Intell.},
  title        = {VMDU-net: A dual encoder multi-scale fusion network for polyp segmentation with vision mamba and cross-shape transformer integration},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elucidating linear programs by neural encodings. <em>FRAI</em>, <em>8</em>, 1549085. (<a href='https://doi.org/10.3389/frai.2025.1549085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear Programs (LPs) are one of the major building blocks of AI and have championed recent strides in differentiable optimizers for learning systems. While efficient solvers exist for even high-dimensional LPs, explaining their solutions has not received much attention yet, as explainable artificial intelligence (XAI) has mostly focused on deep learning models. LPs are mostly considered white-box and thus assumed simple to explain, but we argue that they are not easy to understand in terms of relationships between inputs and outputs. To mitigate this rather non-explainability of LPs we show how to adapt attribution methods by encoding LPs in a neural fashion. The encoding functions consider aspects such as the feasibility of the decision space, the cost attached to each input, and the distance to special points of interest. Using a variety of LPs, including a very large-scale LP with 10k dimensions, we demonstrate the usefulness of explanation methods using our neural LP encodings, although the attribution methods Saliency and LIME are indistinguishable for low perturbation levels. In essence, we demonstrate that LPs can and should be explained, which can be achieved by representing an LP as a neural network.},
  archive      = {J_FRAI},
  author       = {Busch, Florian Peter and Zečević, Matej and Kersting, Kristian and Dhami, Devendra Singh},
  doi          = {10.3389/frai.2025.1549085},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1549085},
  shortjournal = {Front. Artif. Intell.},
  title        = {Elucidating linear programs by neural encodings},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online platform vs. doctors: A comparative exploration of congenital cataract patient education from virtual to reality. <em>FRAI</em>, <em>8</em>, 1548385. (<a href='https://doi.org/10.3389/frai.2025.1548385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveThis study aimed to assess the quality and readability of patient education on congenital cataracts provided by Google, ChatGPT, and clinical doctors. Given the rarity of congenital cataracts and the need for accessible, accurate information for parents, we sought to evaluate the platforms’ effectiveness in delivering relevant health information.Methods and analysisWe developed two question banks related to congenital cataracts from different sources. Responses from Google, ChatGPT, and two doctors were evaluated across five criteria: correctness, completeness, readability, helpfulness, and safety. An ophthalmologist panel used a five-point Likert scale to score these responses. The readability of responses was also assessed using passage and readability statistics, with additional readability enhancements applied to ChatGPT responses.ResultsThe ChatGPT responses demonstrated similar quality to those from experienced doctors, particularly excelling in readability, which was enhanced further with simplification techniques. Resident doctors provided the most readable doctor responses, while Google results scored the lowest across all five evaluative criteria. Post-enhancement, ChatGPT responses showed significant improvements in readability and maintained response quality.ConclusionChatGPT is a promising tool for delivering accessible, accurate information on congenital cataracts, especially for populations with lower health literacy. This study underscores the value of AI in healthcare education for rare conditions and highlights the need for consulting multiple information sources for comprehensive health guidance. ChatGPT, with readability enhancements, stands out as a particularly effective resource for public health information on congenital cataracts.},
  archive      = {J_FRAI},
  author       = {Lin, Xuanqiao and Bai, Lifang and Zhao, Xiaohuan and Cai, Lei and Yang, Jin},
  doi          = {10.3389/frai.2025.1548385},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1548385},
  shortjournal = {Front. Artif. Intell.},
  title        = {Online platform vs. doctors: A comparative exploration of congenital cataract patient education from virtual to reality},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of medical scientific data repositories in china: Analysis of survey and recommendations. <em>FRAI</em>, <em>8</em>, 1544200. (<a href='https://doi.org/10.3389/frai.2025.1544200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundIn the context of global open science trends, medical open-access repositories (OARs) promote transparency in research and facilitate the sharing of scientific data. The increase in scientific output necessitates a robust infrastructure to enhance OARs in China.ObjectivesThis study aimed to evaluate medical open-access repositories (OARs) in China that are indexed in re3data.org and OpenDOAR.org. The study analyzed data classification, descriptions, retrieval, and the utilization of selected repositories.MethodsThis study ascertained the current status of the Chinese medical OARs by visiting their respective websites and attempted to identify the disciplinary orientation of each OAR. A content analysis approach was utilized to achieve this study’s objective. Twelve Chinese medical open-access repositories were selected from re3data.org and OpenDOAR.org to examine how their information is organized. The data were collected manually from May 1 to 30, 2023, and analyzed using various quantitative techniques to understand the current status of medical scientific repositories in China.ResultsBased on the results, this study proposed the following recommendations: (1) implement multi-dimensional data classification, (2) use persistent data identifiers, (3) formalize the description metadata, (4) enhance advanced retrieval and result set filtering functions, and (5) optimize the preview and interaction features of data repositories.ConclusionThe scope of this study is restricted to the medical open-access repositories in China as listed on re3data.org and OpenDOAR.org. Therefore, the results of this study are only generalizable within China. The primary focus of research output in China is on medical open-access repositories. This study is essential for assessing China’s current status in research data management within the medical field and its distribution infrastructure in global open science trends.},
  archive      = {J_FRAI},
  author       = {Song, Jia and Li, Chunqiu and Chansanam, Wirapong},
  doi          = {10.3389/frai.2025.1544200},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1544200},
  shortjournal = {Front. Artif. Intell.},
  title        = {Construction of medical scientific data repositories in china: Analysis of survey and recommendations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning applications in the analysis of sedentary behavior and associated health risks. <em>FRAI</em>, <em>8</em>, 1538807. (<a href='https://doi.org/10.3389/frai.2025.1538807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe rapid advancement of technology has brought numerous benefits to public health but has also contributed to a rise in sedentary lifestyles, linked to various health issues. As prolonged inactivity becomes a growing public health concern, researchers are increasingly utilizing machine learning (ML) techniques to examine and understand these patterns. ML offers powerful tools for analyzing large datasets and identifying trends in physical activity and inactivity, generating insights that can support effective interventions.ObjectivesThis review aims to: (i) examine the role of ML in analyzing sedentary patterns, (ii) explore how different ML techniques can be optimized to improve the accuracy of predicting sedentary behavior, and (iii) assess strategies to enhance the effectiveness of ML algorithms.MethodsA comprehensive search was conducted in PubMed and Scopus, targeting peer-reviewed articles published between 2004 and 2024. The search included the subject terms “sedentary behavior,” “sedentary lifestyle health,” and “machine learning sedentary lifestyle,” combined with the keywords “physical inactivity” and “diseases” using Boolean operators (AND, OR). Articles were included if they addressed the health impacts of sedentary behavior or employed ML techniques for its analysis. Exclusion criteria involved studies older than 20 years or lacking direct relevance. After screening 33 core articles and identifying 13 more through citation tracking, 46 articles were included in the final review.ResultsThis narrative review describes the characteristics of sedentary behavior, associated health risks, and the applications of ML in this context. Based on the reviewed literature, sedentary behavior was consistently associated with cardiovascular disease, metabolic disorders, and mental health conditions. The review highlights the utility of various ML approaches in classifying activity levels and significantly improving the prediction of sedentary behavior, offering a promising approach to address this widespread health issue.ConclusionML algorithms, including supervised and unsupervised models, show great potential in accurately detecting and predicting sedentary behavior. When integrated with wearable sensor data and validated in real-world settings, these models can enhance the scalability and precision of AI-driven interventions. Such advancements support personalized health strategies and could help lower healthcare costs linked to physical inactivity, ultimately improving public health outcomes.},
  archive      = {J_FRAI},
  author       = {Hammad, Ayat S and Tajammul, Ali and Dergaa, Ismail and Al-Asmakh, Maha},
  doi          = {10.3389/frai.2025.1538807},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1538807},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning applications in the analysis of sedentary behavior and associated health risks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automating updates for scoping reviews on the environmental drivers of human and animal diseases: A comparative analysis of AI methods. <em>FRAI</em>, <em>8</em>, 1526820. (<a href='https://doi.org/10.3389/frai.2025.1526820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the environmental factors that facilitate the occurrence and spread of infectious diseases in animals is crucial for risk prediction. As part of the H2020 Monitoring Outbreaks for Disease Surveillance in a Data Science Context (MOOD) project, scoping literature reviews have been conducted for various diseases. However, pathogens continuously mutate and generate variants with different sensitivities to these factors, necessitating regular updates to these reviews. In this paper, we propose to evaluate the potential benefits of artificial intelligence (AI) for updating such scoping reviews. We thus compare different combinations of AI methods for solving this task. These methods utilize generative large language models (LLMs) and lighter language models to automatically identify risk factors in scientific articles.},
  archive      = {J_FRAI},
  author       = {Decoupes, Rémy and Cataldo, Claudia and Busani, Luca and Roche, Mathieu and Teisseire, Maguelonne},
  doi          = {10.3389/frai.2025.1526820},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1526820},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automating updates for scoping reviews on the environmental drivers of human and animal diseases: A comparative analysis of AI methods},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data stream-pairwise bottleneck transformer for engagement estimation from video conversation. <em>FRAI</em>, <em>8</em>, 1516295. (<a href='https://doi.org/10.3389/frai.2025.1516295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to assess participant engagement in multiparty conversations using video and audio data. For this task, the interaction among numerous data streams, such as video and audio from multiple participants, should be modeled effectively, considering the redundancy of video and audio across frames. To efficiently model participant interactions while accounting for such redundancy, a previous study proposed inputting participant feature sequences into global token-based transformers, which constrain attention across feature sequences to pass through only a small set of internal units, allowing the model to focus on key information. However, this approach still faces the challenge of redundancy in participant-feature estimation based on standard cross-attention transformers, which can connect all frames across different modalities. To address this, we propose a joint model for interactions among all data streams using global token-based transformers, without distinguishing between cross-modal and cross-participant interactions. Experiments on the RoomReader corpus confirm that the proposed model outperforms previous models, achieving accuracy ranging from 0.720 to 0.763, weighted F1 scores from 0.733 to 0.771, and macro F1 scores from 0.236 to 0.277.},
  archive      = {J_FRAI},
  author       = {Suzuki, Keita and Hojo, Nobukatsu and Shinoda, Kazutoshi and Mizuno, Saki and Masumura, Ryo},
  doi          = {10.3389/frai.2025.1516295},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1516295},
  shortjournal = {Front. Artif. Intell.},
  title        = {Data stream-pairwise bottleneck transformer for engagement estimation from video conversation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and correcting pronunciation disorders based on artificial intelligence approach. <em>FRAI</em>, <em>8</em>, 1388180. (<a href='https://doi.org/10.3389/frai.2025.1388180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of this study is to employ artificial intelligence and machine learning methods to assess and correct pronunciation disorders in post-traumatic military patients, acknowledging the critical need for effective communication rehabilitation in individuals who have experienced trauma, such as head injuries or war-related incidents. Tasks include reviewing existing research, selecting appropriate machine learning methods, generating relevant training data, and implementing a software architecture tailored to analyze and correct pronunciation defects in this specific population. The analysis of machine learning methods led to the selection of two experimental models: a Convolutional Neural Network (CNN) utilizing mel-spectrograms for image-based sound representation and a Long Short-Term Memory (LSTM) network combined with mel-frequency cepstral coefficients, aiming to explore the effectiveness of sequential data processing in the context of pronunciation disorder classification in post-traumatic military patients. The results of the two models were compared based on the loss and accuracy functions of the training and validation data, error matrices, and such key metrics as precision, recall, and F1-score. Both models showed promising results in classifying dysarthria stages, but the CNN model performed slightly better in predicting all classes than the LSTM.},
  archive      = {J_FRAI},
  author       = {Melnykova, Nataliia and Pavlyk, Bohdan and Basystiuk, Oleh and Skopivskyi, Stepan},
  doi          = {10.3389/frai.2025.1388180},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1388180},
  shortjournal = {Front. Artif. Intell.},
  title        = {Analysis and correcting pronunciation disorders based on artificial intelligence approach},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic and deterministic processes in asymmetric tsetlin machine. <em>FRAI</em>, <em>8</em>, 1377944. (<a href='https://doi.org/10.3389/frai.2025.1377944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new approach to enhance the decision-making capabilities of the Tsetlin Machine (TM) through the Stochastic Point Location (SPL) algorithm and the Asymmetric Steps technique. We incorporate stochasticity and asymmetry into the TM's process, along with a decaying normal distribution function that improves adaptability as it converges toward zero over time. We present two methods: the Asymmetric Probabilistic Tsetlin (APT) Machine, influenced by random events, and the Asymmetric Tsetlin (AT) Machine, which transitions from probabilistic to deterministic states. We evaluate these methods against traditional machine learning algorithms and classical Tsetlin (CT) machines across various benchmark datasets. Both AT and APT demonstrate competitive performance, with the AT model notably excelling, especially in complex datasets.},
  archive      = {J_FRAI},
  author       = {Elmisadr, Negar and Belaid, Mohamed-Bachir and Yazidi, Anis},
  doi          = {10.3389/frai.2025.1377944},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {1377944},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stochastic and deterministic processes in asymmetric tsetlin machine},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can artificial intelligence improve the diagnosis and prognosis of disorders of consciousness? a scoping review. <em>FRAI</em>, <em>8</em>, 1608778. (<a href='https://doi.org/10.3389/frai.2025.1608778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundArtificial intelligence (AI), in the form of machine learning (ML) or deep learning (DL) models, can aid clinicians in the diagnostic process and/or in the prognosis of critically medical conditions, as for patients with a disorder of consciousness (DoC), in which both aspects are particularly challenging. DoC is a category of neurological impairments that are mainly caused by severe acquired brain injury, like ischemic or hemorrhagic strokes or traumatic injuries. The aim of this scoping review is to map the literature on the role of ML and DL in the field of diagnosis and prognosis of DoCs.Materials and methodsA scoping search, started from 3rd October 2024, was conducted for all peer-reviewed articles published from 2000 to 2024, using the following databases: PubMed, Embase, Scopus and Cochrane Library.ResultsWe found a total of 49,417 articles. After duplicate removal and title/abstract screening, 613 articles met the inclusion criteria, but 592 articles were excluded after full-text review. Therefore, only 21 studies involving DoC subjects were included in the review synthesis.ConclusionAdvancing AI in the field of DoC requires standardized data protocols and consideration of demographic variations. AI could enhance diagnosis, prognosis, and differentiation between states like unresponsive wakefulness syndrome (UWS) and minimally conscious state (MCS). Additionally, AI-based applications personalize rehabilitation by identifying key recovery factors, optimizing patient outcomes.},
  archive      = {J_FRAI},
  author       = {Bonanno, Mirjam and Cardile, Davide and Liuzzi, Piergiuseppe and Celesti, Antonio and Micali, Giuseppe and Corallo, Francesco and Quartarone, Angelo and Tomaiuolo, Francesco and Calabrò, Rocco Salvatore},
  doi          = {10.3389/frai.2025.1608778},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1608778},
  shortjournal = {Front. Artif. Intell.},
  title        = {Can artificial intelligence improve the diagnosis and prognosis of disorders of consciousness? a scoping review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMDCnet: Attention-gate-based multi-scale decomposition and collaboration network for long-term time series forecasting. <em>FRAI</em>, <em>8</em>, 1607232. (<a href='https://doi.org/10.3389/frai.2025.1607232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTime series analysis plays a critical role in various applications, including sensor data monitoring, weather forecasting, economic predictions, and network traffic management. While traditional methods primarily focus on modeling time series data at a single temporal scale and achieve notable results, they often overlook dependencies across multiple scales. Furthermore, the intricate structure of multi-scale time series complicates the effective extraction of features at different temporal resolutions.MethodTo address these limitations, we propose AMDCnet, a multi-scale-based time series decomposition and collaboration network designed to enhance the model's capacity for decomposing and integrating data across varying time scales. Specifically, AMDCnet transforms the original time series into multiple temporal resolutions and conducts multi-scale feature decomposition while preserving the overall temporal dynamics. By extracting features from downsampled sequences and integrating multi-resolution features through attention-gated co-training mechanisms, AMDCnet enables efficient modeling of complex time series data.ResultsAMDCnet achieving 44 best results and 10 second-best results out of 64 cases. Experimental results on 8 benchmark datasets demonstrate that AMDCnet achieves state-of-the-art performance in time series forecasting.DiscussionOur research provides a robust baseline for the application of artificial intelligence in multivariate time series forecasting. This work leverages multi-scale time series decomposition and gated units for feature fusion, effectively capturing dependencies across different temporal scales. Future studies may further optimize the scale decomposition and fusion modules. Such efforts could enhance the representation of multi-scale information and help address key challenges in multivariate time series prediction.},
  archive      = {J_FRAI},
  author       = {Hou, Shikang and Sun, Song and Yin, Tao and Zhang, Zhibin and Yan, Meng},
  doi          = {10.3389/frai.2025.1607232},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1607232},
  shortjournal = {Front. Artif. Intell.},
  title        = {AMDCnet: Attention-gate-based multi-scale decomposition and collaboration network for long-term time series forecasting},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk prediction of stroke-associated pneumonia in acute ischemic stroke with atrial fibrillation using machine learning models. <em>FRAI</em>, <em>8</em>, 1595101. (<a href='https://doi.org/10.3389/frai.2025.1595101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke-associated pneumonia (SAP) is a serious complication of acute ischemic stroke (AIS), significantly affecting patient prognosis and increasing healthcare burden. AIS patients are often accompanied by basic diseases, and atrial fibrillation (AF) is one of the common basic diseases. Despite the high prevalence of AF in AIS patients, few studies have specifically addressed SAP prediction in this comorbid population. We aimed to analyze the factors influencing the occurrence of SAP in patients with AIS and AF and to assess the risk of SAP development through an optimal predictive model. We performed a case-control study. This study included 4,496 hospitalized patients with AIS and AF in China between January 2020 and September 2023. The primary outcome was SAP during hospitalization. Univariate analysis and LASSO regression analysis methods were used to screen predictors. The patients with AIS and AF were randomly divided into a training set, validation set, and test set. Then, we established logistic regression (LR), random forest (RF), support vector machine (SVM), and extreme gradient boosting (XGBoost) models. The accuracy, sensitivity, specificity, area under the curve, Youden index and F1 score were adopted to evaluate the predictive value of each model. The optimal prediction model was visualized using a nomogram. In this study, SAP was identified in 10.16% of cases. The variables screened by univariate analysis and LASSO regression, variables such as coronary artery disease, hypertension, and dysphagia, identified by univariate and LASSO regression analyses (p < 0.05), were included in the LR, RF, and SVM. The LR model outperformed other models, achieving an AUC of 0.866, accuracy of 90.13%, sensitivity of 79.49%, specificity of 86.11%, F1 score of 0.80. A nomogram based on the LR model was developed to predict SAP risk, providing a practical tool for early identification of high-risk patients, and enabling targeted interventions to reduce SAP incidence and improve outcomes.},
  archive      = {J_FRAI},
  author       = {Su, Tai and Zhang, Peng and Zhang, Bingyin and Liu, Zihao and Xie, Zexing and Li, Xiaomei and Ma, Jixiang and Xin, Tao},
  doi          = {10.3389/frai.2025.1595101},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1595101},
  shortjournal = {Front. Artif. Intell.},
  title        = {Risk prediction of stroke-associated pneumonia in acute ischemic stroke with atrial fibrillation using machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent systems powered by large language models: Applications in swarm intelligence. <em>FRAI</em>, <em>8</em>, 1593017. (<a href='https://doi.org/10.3389/frai.2025.1593017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines the integration of large language models (LLMs) into multi-agent simulations by replacing the hard-coded programs of agents with LLM-driven prompts. The proposed approach is showcased in the context of two examples of complex systems from the field of swarm intelligence: ant colony foraging and bird flocking. Central to this study is a toolchain that integrates LLMs with the NetLogo simulation platform, leveraging its Python extension to enable communication with GPT-4o via the OpenAI API. This toolchain facilitates prompt-driven behavior generation, allowing agents to respond adaptively to environmental data. For both example applications mentioned above, we employ both structured, rule-based prompts and autonomous, knowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs to study self-organizing processes and induce emergent behaviors within multi-agent environments, paving the way for new approaches to exploring intelligent systems and modeling swarm intelligence inspired by natural phenomena. We provide the code, including simulation files and data at https://github.com/crjimene/swarm_gpt.},
  archive      = {J_FRAI},
  author       = {Jimenez-Romero, Cristian and Yegenoglu, Alper and Blum, Christian},
  doi          = {10.3389/frai.2025.1593017},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1593017},
  shortjournal = {Front. Artif. Intell.},
  title        = {Multi-agent systems powered by large language models: Applications in swarm intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moving LLM evaluation forward: Lessons from human judgment research. <em>FRAI</em>, <em>8</em>, 1592399. (<a href='https://doi.org/10.3389/frai.2025.1592399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper outlines a path toward more reliable and effective evaluation of Large Language Models (LLMs). It argues that insights from the study of human judgment and decision-making can illuminate current challenges in LLM assessment and help close critical gaps in how models are evaluated. By drawing parallels between human reasoning and model behavior, the paper advocates moving beyond narrow metrics toward more nuanced, ecologically valid frameworks.},
  archive      = {J_FRAI},
  author       = {Polonioli, Andrea},
  doi          = {10.3389/frai.2025.1592399},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1592399},
  shortjournal = {Front. Artif. Intell.},
  title        = {Moving LLM evaluation forward: Lessons from human judgment research},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From data extraction to analysis: A comparative study of ELISE capabilities in scientific literature. <em>FRAI</em>, <em>8</em>, 1587244. (<a href='https://doi.org/10.3389/frai.2025.1587244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of scientific literature presents challenges for pharmaceutical, biotechnological, and Medtech industries, particularly in regulatory documentation, clinical research, and systematic reviews. Ensuring accurate data extraction, literature synthesis, and compliance with industry standards require AI tools that not only streamline workflows but also uphold scientific rigor. This study evaluates the performance of AI tools designed for bibliographic review, data extraction, and scientific synthesis, assessing their impact on decision-making, regulatory compliance, and research productivity. The AI tools assessed include general-purpose models like ChatGPT and specialized solutions such as ELISE (Elevated LIfe SciencEs), SciSpace/Typeset, Humata, and Epsilon. The evaluation is based on three main criteria: Extraction, Comprehension, and Analysis with Compliance and Traceability (ECACT) as additional dimensions. Human experts established reference benchmarks, while AI Evaluator models ensure objective performance measurement. The study introduces the ECACT score, a structured metric assessing AI reliability in scientific literature analysis, regulatory reporting and clinical documentation. Results demonstrate that ELISE consistently outperforms other AI tools, excelling in precise data extraction, deep contextual comprehension, and advanced content analysis. ELISE’s ability to generate traceable, well-reasoned insights makes it particularly well-suited for high-stakes applications such as regulatory affairs, clinical trials, and medical documentation, where accuracy, transparency, and compliance are paramount. Unlike other AI tools, ELISE provides expert-level reasoning and explainability, ensuring AI-generated insights align with industry best practices. ChatGPT is efficient in data retrieval but lacks precision in complex analysis, limiting its use in high-stakes decision-making. Epsilon, Humata, and SciSpace/Typeset exhibit moderate performance, with variability affecting their reliability in critical applications. In conclusion, while AI tools such as ELISE enhance literature review, regulatory writing, and clinical data interpretation, human oversight remains essential to validate AI outputs and ensure compliance with scientific and regulatory standards. For pharmaceutical, biotechnological, and Medtech industries, AI integration must strike a balance between automation and expert supervision to maintain data integrity, transparency, and regulatory adherence.},
  archive      = {J_FRAI},
  author       = {Gobin, Maxime and Gosnat, Muriel and Toure, Seindé and Faik, Lina and Belafa, Joel and Villedieu de Torcy, Antoine and Armstrong, Florence},
  doi          = {10.3389/frai.2025.1587244},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1587244},
  shortjournal = {Front. Artif. Intell.},
  title        = {From data extraction to analysis: A comparative study of ELISE capabilities in scientific literature},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NLP-based removal of personally identifiable information from hungarian electronic health records. <em>FRAI</em>, <em>8</em>, 1585260. (<a href='https://doi.org/10.3389/frai.2025.1585260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionElectronic health records (EHR) in text format serve as crucial resources for data-driven medical research. To safeguard patient confidentiality, under the General Data Protection Regulation (GDPR), strict measures are required to ensure personal data is anonymized or pseudonymized to protect individual privacy. Natural language processing has consistently proven effective in automating the de-identification of sensitive information.MethodsWe present spaCy models to recognize personally identifiable information (PII) from a wide range of free-text medical records written in Hungarian, a low-resource language. To develop this model, we compiled a corpus of clinical documents by annotating sensitive information within electronic health records sourced from the University of Debrecen. To simplify the annotation process, we pre-annotated the documents using a rule-based method. The corpora comprises over 15,000 documents and includes more than 90,000 instances of PII. We trained several models using this corpus and also developed a separate validation corpus to assess their performance.ResultsThe performance evaluation of the de-identification models on the developed corpora resulted in F1-scores ranging from 0.9697 to 0.9926. On the validation corpora, the F1-scores ranged from 0.9772 to 0.9867, demonstrating that the models can effectively handle previously unseen examples. Our risk analysis revealed that 99.67% of the sensitive information was successfully removed from the validation dataset.DiscussionThe results indicate that similarly to other state-of-the-art systems our model is highly effective at identifying PII in clinical texts, guaranteeing that sensitive information in clinical documents can be protected without sacrificing the quality or usability of the data for research purposes. Despite these positive outcomes, several areas remain to be improved, such as the conduction of additional testing on diverse datasets, particularly those from different healthcare institutions. With ongoing refinements, these models have the potential to greatly enhance the efficiency of data de-identification processes, ensuring compliance with privacy regulations while promoting the secure sharing of medical data for scientific progress.},
  archive      = {J_FRAI},
  author       = {Berzi, András and Berényi, Ervin and Képes, Zita and Antal, Barnabás and Varga, Ábrahám Gergely and Emri, Miklós},
  doi          = {10.3389/frai.2025.1585260},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1585260},
  shortjournal = {Front. Artif. Intell.},
  title        = {NLP-based removal of personally identifiable information from hungarian electronic health records},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of machine learning for heart disease prediction: Challenges, trends, ethical considerations, and future directions. <em>FRAI</em>, <em>8</em>, 1583459. (<a href='https://doi.org/10.3389/frai.2025.1583459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review provides a thorough and organized overview of machine learning (ML) applications in predicting heart disease, covering technological advancements, challenges, and future prospects. As cardiovascular diseases (CVDs) are the leading cause of global mortality, there is an urgent demand for early and precise diagnostic tools. ML models hold considerable potential by utilizing large-scale healthcare data to enhance predictive diagnostics. To systematically investigate this field, the literature is organized into five thematic categories such as “Heart Disease Detection and Diagnostics,” “Machine Learning Models and Algorithms for Healthcare,” “Feature Engineering and Optimization Techniques,” “Emerging Technologies in Healthcare,” and “Applications of AI Across Diseases and Conditions.” The review incorporates performance benchmarking of various ML models, highlighting that hybrid deep learning (DL) frameworks, e.g., convolutional neural network-long short-term memory (CNN-LSTM) consistently outperform traditional models in terms of sensitivity, specificity, and area under the curve (AUC). Several real-world case studies are presented to demonstrate the successful deployment of ML models in clinical and wearable settings. This review showcases the progression of ML approaches from traditional classifiers to hybrid DL structures and federated learning (FL) frameworks. It also discusses ethical issues, dataset limitations, and model transparency. The conclusions provide important insights for the development of artificial intelligence (AI) powered, clinically applicable heart disease prediction systems.},
  archive      = {J_FRAI},
  author       = {Kumar, Raman and Garg, Sarvesh and Kaur, Rupinder and Johar, M. G. M. and Singh, Sehijpal and Menon, Soumya V. and Kumar, Pulkit and Hadi, Ali Mohammed and Hasson, Shams Abbass and Lozanović, Jasmina},
  doi          = {10.3389/frai.2025.1583459},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1583459},
  shortjournal = {Front. Artif. Intell.},
  title        = {A comprehensive review of machine learning for heart disease prediction: Challenges, trends, ethical considerations, and future directions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measuring trust in artificial intelligence: Validation of an established scale and its short form. <em>FRAI</em>, <em>8</em>, 1582880. (<a href='https://doi.org/10.3389/frai.2025.1582880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An understanding of the nature and function of human trust in artificial intelligence (AI) is fundamental to the safe and effective integration of these technologies into organizational settings. The Trust in Automation Scale is a commonly used self-report measure of trust in automated systems; however, it has not yet been subjected to comprehensive psychometric validation. Across two studies, we tested the capacity of the scale to effectively measure trust across a range of AI applications. Results indicate that the Trust in Automation Scale is a valid and reliable measure of human trust in AI; however, with 12 items, it is often impractical for contexts requiring frequent and minimally disruptive measurements. To address this limitation, we developed and validated a three-item version of the TIAS, the Short Trust in Automation Scale (S-TIAS). In two further studies, we tested the sensitivity of the S-TIAS to manipulations of the trustworthiness of an AI system, as well as the convergent validity of the scale and its capacity to predict intentions to rely on AI-generated recommendations. In both studies, the S-TIAS also demonstrated convergent validity and significantly predicted intentions to rely on the AI system in patterns similar to the TIAS. This suggests that the S-TIAS is a practical and valid alternative for measuring trust in automation and AI for the purposes of identifying antecedent factors of trust and predicting trust outcomes.},
  archive      = {J_FRAI},
  author       = {McGrath, Melanie J. and Lack, Oliver and Tisch, James and Duenser, Andreas},
  doi          = {10.3389/frai.2025.1582880},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1582880},
  shortjournal = {Front. Artif. Intell.},
  title        = {Measuring trust in artificial intelligence: Validation of an established scale and its short form},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The utility of generative artificial intelligence chatbot (ChatGPT) in generating teaching and learning material for anesthesiology residents. <em>FRAI</em>, <em>8</em>, 1582096. (<a href='https://doi.org/10.3389/frai.2025.1582096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularization of large language chatbots such as ChatGPT has led to growing utility in various biomedical fields. It has been shown that chatbots can provide reasonably accurate responses to medical exam style questions. On the other hand, chatbots have known limitations which may hinder their utility in medical education. We conducted a pragmatically designed study to evaluate the accuracy and completeness of ChatGPT generated responses to various styles of prompts, based on entry-level anesthesiology topics. Ninety-five unique prompts were constructed using topics from the Anesthesia Knowledge Test 1 (AKT-1), a standardized exam undertaken by US anesthesiology residents after 1 month of specialty training. A combination of focused and open-ended prompts was used to evaluate its ability to present and organize information. We also included prompts for journal references, lecture outlines, as well as biased (medically inaccurate) prompts. The responses were independently scored using a 3-point Likert scale, by two board-certified anesthesiologists with extensive experience in medical education. Fifty-two (55%) responses were rated as completely accurate by both evaluators. For longer responses prompts, most of the responses were also deemed complete. Notably, the chatbot frequently generated inaccurate responses when asked for specific literature references and when the input prompt contained deliberate errors (biased prompts). Another recurring observation was the conflation of adjacent concepts (e.g., a specific characteristic was attributed to the wrong drug under the same pharmacological class). Some of the inaccuracies could potentially result in significant harm if applied to clinical situations. While chatbots such as ChatGPT can generate medically accurate responses in most cases, its reliability is not yet suited for medical and clinical education. Content generated by ChatGPT and other chatbots will require validation prior to use.},
  archive      = {J_FRAI},
  author       = {Jin, Zhaosheng and Abola, Ramon and Bargnes, Vincent and Tsivitis, Alexandra and Rahman, Sadiq and Schwartz, Jonathon and Bergese, Sergio D. and Schabel, Joy E.},
  doi          = {10.3389/frai.2025.1582096},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1582096},
  shortjournal = {Front. Artif. Intell.},
  title        = {The utility of generative artificial intelligence chatbot (ChatGPT) in generating teaching and learning material for anesthesiology residents},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On automatic decipherment of lost ancient scripts relying on combinatorial optimisation and coupled simulated annealing. <em>FRAI</em>, <em>8</em>, 1581129. (<a href='https://doi.org/10.3389/frai.2025.1581129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel method for addressing the challenge of deciphering ancient scripts. The approach relies on combinatorial optimisation along with coupled simulated annealing, an advanced technique for non-convex optimisation. Encoding solutions through k-permutations facilitates the representation of null, one-to-many, and many-to-one mappings between signs. In comparison to current state-of-the-art systems evaluated on established benchmarks from literature and three new benchmarks introduced in this study, the proposed system demonstrates superior performance in enhancing cognate identification results.},
  archive      = {J_FRAI},
  author       = {Tamburini, Fabio},
  doi          = {10.3389/frai.2025.1581129},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1581129},
  shortjournal = {Front. Artif. Intell.},
  title        = {On automatic decipherment of lost ancient scripts relying on combinatorial optimisation and coupled simulated annealing},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is AI a functional equivalent to expertise in organizations and decision-making? opportunities and pitfalls for AI in the context of just transitions. <em>FRAI</em>, <em>8</em>, 1571698. (<a href='https://doi.org/10.3389/frai.2025.1571698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The urgency of addressing climate change and achieving a just transition to sustainability has never been greater, as the world approaches critical environmental thresholds. While artificial intelligence (AI) presents both opportunities and challenges in this context, its role in organizational decision-making and expertise remains underexplored. This paper examines the interplay between AI and human expertise within organizations, focusing on how AI can complement or substitute traditional expertise across factual, temporal, and social dimensions. Drawing on Social Systems Theory, we argue that while AI excels in data processing and rapid decision-making, it falls short in contextual adaptation, long-term strategic thinking, and social legitimacy—areas where human expertise remains indispensable. And this is, we observe, particularly evident in problems connected with climate change and sustainability more broadly, where the tensions for organizational decision-making -and governance become even denser as much in the factual, temporal and social dimensions, making them into very complex, ‘super-wicked’, problem situations. Thus, there is a need to think more in detail about possible hybrid approaches, integrating AI’s computational strengths with human interpretive and adaptive capabilities, which may offer promising pathways for advancing organizational decision-making in the overly complex, wicked decision-making scenarios characteristic of just transitions. However, this requires careful consideration of power dynamics, trust-building, and the ethical implications of AI adoption. By moving beyond techno-optimism, this study highlights the need for a nuanced understanding of AI’s functional and social plausibility in organizational settings, offering insights for fostering equitable and sustainable transitions in an increasingly complex world.},
  archive      = {J_FRAI},
  author       = {Billi, Marco and Labraña, Julio},
  doi          = {10.3389/frai.2025.1571698},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1571698},
  shortjournal = {Front. Artif. Intell.},
  title        = {Is AI a functional equivalent to expertise in organizations and decision-making? opportunities and pitfalls for AI in the context of just transitions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Critical thinking in the age of generative AI: Implications for health sciences education. <em>FRAI</em>, <em>8</em>, 1571527. (<a href='https://doi.org/10.3389/frai.2025.1571527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence (genAI) systems are progressively transforming health science education and research by assisting clinicians in diagnosis and structuring specific intervention regimens (MIR et al., 2023). Moreover, these technologies serve educators in yielding simple concept-based educational modules tailored as per student's requirements and large language models (LLMs) and analogous models display the potential for automated streamlined literature reviews, prompt generation of interpretations and conclusions, and effortless drafting of manuscripts within seconds (MIR et al., 2023;Al Kuwaiti et al., 2023;Gupta et al., 2024) thereby, offering a potentially high level of convenience and efficiency. Furthermore, many researchers contend that genAI has the potential to completely automate research processes, including drafting proposals, analyzing data, and composing concluding reports (Almansour and Alfhaid, 2024;Preiksaitis and Rose, 2023). Hence, these merits indicate a prospective future for genAI, particularly in domains that demand processing of large scale data and iterative analyses.However, despite these evident positive outcomes, concerns persist regarding the quality of AIgenerated outputs, which may include inaccuracies in text reporting that contribute to misinformation, logical inconsistencies, outdated or unverified claims, and hallucinated references, all of which undermine the academic credibility of writing (Athaluri et al., 2023;Farrelly and Baker, 2023;Sittig and Singh, 2024). In addition, a lack of transparency in datasets exacerbates ethical challenges and biases (Norori et al., 2021). In an era characterized by the expedited advancement and refinement of genAI, it is necessary to critically evaluate whether these systems encourage critical thinking and human intelligence or subtly undermine them. This raises an important question: Are we unintentionally relinquishing the cognitive abilities that have propelled scientific and clinical advancements, as healthcare professionals progressively integrate genAI into clinical and academic domains? The dilemma lies in balancing the efficiency of genAI with the preservation of essential human cognitive skills, such as critical thinking, ethical reasoning, and independent problem-solving. At its core, this dilemma focuses on how health professionals, medical trainees, and early career researchers apply outcomes produced by genAI as overreliance risk supporting passive dependence on algorithm produced outcomes in a context where time and cognitive capacity are consistently constrained. The expertise involving scientific accuracy, ethical judgment, and diagnostic reasoning are cultivated through proactive contribution by integrating knowledge in innovative and contextually relevant approaches, critically evaluating evidence, and grappling with uncertainty that genAI cannot substitute (Passerini et al., 2025;Shoja et al., 2023).The significance of the risk of cognitive complacency is emphasized globally, as industry and academia compete to implement genAI tools, and have rapidly accelerated publications related to AI, reflecting both enthusiasm and apprehension. However, medical professionals and researchers may demonstrate overdependence on genAI tools due to faster processing, thus, reducing opportunities for independent problem-solving and critical thinking (Shoja et al., 2023;Zhai et al., 2024). Additionally, in medical research where precision plays an important factor, underlying biases in data training of genAI can propagate false information (Norori et al., 2021). The inefficacy of plagiarism detection software to recognize text generated by genAI, undermines conventional ethical integrity measures as the output may be erroneously identified as genuine scholarly writing (Farrelly and Baker, 2023), though some exceptions exist (Elkhatat et al., 2023;Weber-Wulff et al., 2023). This attitude leads to a workforce adept at utilizing genAI but deficient in cognitive analytical competencies. Moreover, an evolving repository of research studies warns against excessive reliance on genAI for academic work by emphasizing that while genAI can generate complex answers to assignments, it may encourage students to trade critical thinking for speed, eroding the metacognitive skills essential to patient care and clinical reasoning (Fan et al., 2024;Eachempati et al., 2024).However, the ecosystem of scholarly communication stands at a crossroads: Will the next generation of scientists and clinicians accept findings derived from genAI uncritically, prioritizing output over insight, or will they develop the intellectual resilience necessary to critically evaluate the outcomes? In the healthcare industry, the capability to incorporate evolving evidence into public health policy, interpret subtle patient cues, and navigate cultural sensitivities is not exclusively governed by algorithms or encoded by pre-trained genAI models. This concern is particularly relevant because these higher-order cognitive functions necessitate emotional intelligence, nuances, and analytical judgment which are fundamental for fostering innovative and ethical healthcare in the future. The credibility of scientific research is defined by ethical considerations, peer evaluation, and reproducibility (Prager et al., 2018). However, negligence in critically evaluating genAI produced research risks eroding these fundamental principles. Therefore, to ensure research integrity, transparency, and mitigate overreliance on automated results, it is essential to establish and integrate genAI usage policies in academia (Athaluri et al., 2023).Prominent journals warns of a global "feedback loop" that risks reinforcing pre-existing knowledge patterns at the expense of transformative inquiry if genAI tools remain unmonitored (Kwong et al., 2024). Furthermore, a recent analysis elucidates that true intelligence is characterized by the ability to solve novel, previously un-encountered problems, rather than relying on recycling pre-existing solutions (Gignac and Szodorai, 2024). The discussion highlights conceptual clarity on the distinction between "intelligence" and "achievement" within both human and artificial domains (Gignac and Szodorai, 2024). Contemporary generative AI systems, extensively trained on existing datasets, may mimic expertise; however, they frequently lack demonstration of true intelligence, as their outputs are predominantly dependent on prior data exposure (Gignac and Szodorai, 2024). By consistently relying on familiar patterns, there is a risk of fostering intellectual complacency rather than encouraging original thoughts. This distinction is particularly significant in the health sciences, where true innovation emerges from confronting novel challenges, rather than revisiting established solutions.GenAI should function as an assistive tool that enhances cognitive capabilities, embodying the concept of "augmented intelligence," which emphasizes its role in complementing, rather than replacing human intellect and expertise (Monteith et al., 2024). It is crucial to strike a balance between human supervision and the efficiencies of genAI, cautioning that while genAI has the potential to optimize specific tasks, genuine depth, and innovation arise from the uniquely human cognitive abilities for critical reflection and rigorous interrogation (Sittig and Singh, 2024). Human centered AI operates as a two-dimensional framework that strategically balances automation with human control, aiming to enhance both technological reliability and human agency. This approach fosters the development of trustworthy, reliable, and safe AI-assisted computer programs while enhancing human self-efficacy, performance, creativity, and responsibility (Shneiderman, 2020). Promoting the ethical use of genAI includes key principles such as fairness, unbiased decision making, transparency in datasets, accountability, autonomy, and data privacy (Jobin et al., 2019;Habli et al., 2020).Both academia and industry should be urged to collaboratively oversee the development of more advanced genAI, emphasizing that scientific rigor (transparency, and reproducibility), and critical peer review must govern the evolution of these technologies. Without such oversight, claims associated with AI's imminent artificial general intelligence risk go unchallenged, promoting a narrative of effortless problem-solving that sidesteps human contribution (Sittig and Singh, 2024). In contrast, maintaining rigorous standards and embedding critical thinking in genAI integration ensures that researchers and clinicians remain architects of their intellectual landscapes. If properly contextualized, genAI may become a powerful collaborator, rather than a technological crutch.Graduate programs play a pivotal role in steering the ethical incorporation of genAI into health sciences. Medical education assisted by genAI mainly includes cloud computing, wearable devices, 5G, big data analysis, virtual reality, and the Internet of Things (Sun et al., 2023). Medical institutions must prioritize human supervision in research projects and clinical applications involving genAI (Janumpally et al., 2025) to ensure patient safety and ethical integrity (Figure 1). For instance, genAI is increasingly used for surgical training without direct patient involvement (Bhuyan et al., 2025). Western Michigan University exemplifies this by integrating over 100+ hours of AIsimulation training in its medical curriculum, allowing students to engage in realistic patient scenarios under professor supervision (Bhuyan et al., 2025). Similarly, the University of Illinois College of Medicine successfully employs its AI in medicine (AI-Med) program, which cultivates critical appraisal skills required for assessing and implementing genAI in medical research. This initiative not only enhances proficiency in scientific writing and communication but also ensures the responsible dissemination of findings within the medical community ("Artificial Intelligence in Medicine (AI-MED) | College of Medicine | University of Illinois College of Medicine," n.d.). Congruently, the National University of Singapore mandatorily leverages undergraduate programs in bioinformatics and AI in medicine (Feigerlova et al., 2025). However, the overreliance on genAI poses significant risks. Inappropriate drug recommendations and misdiagnoses such as the inability to detect lesions or tumors, can be executed by genAI thus, endangering patient's lives (Saadat et al., 2024). For instance, despite insufficient accuracy, the widespread adoption of an externally validated AI sepsis prediction model flagged concerns leading to postponed intervention (Wong et al., 2021). These failures illustrate the critical need for human oversight and highlight the consequences of overdependence on genAI. The key challenge encountered in genAI education involves curriculum standardization, due to resistance from some researchers and educators who lack the skills to detect the content produced by genAI or who rely on unreliable detection tools. This originates due to the inability of plagiarism detection software to differentiate between genAI produced content and human written text and due to a lack of knowledge and competency among health professionals regarding genAI technologies. For instance, tools such as PlagiarismCheck, CrossPlag, and Zero GPT often fail to detect genAI content due to the rapid evolution of these models, which progressively enhance their abilities to mimic human written text, making identification more challenging (Weber-Wulff et al. 2023;Elkhatat et al. 2023).The curricula should therefore conceptualize genAI not as a shortcut but as a tool whose outputs demand scrutiny. Academic institutions should prioritize AI ethics in curriculum development, equipping future researchers and clinicians with the skills needed to critically engage with the content generated by genAI (Katznelson and Gerke, 2021;Bahroun et al., 2023). In fact, a study found that dental university instructors often mistook AI-generated reflections for student work, raising concerns about academic integrity and authorship (Bordani et al., 2024). Academic projects encouraging systematic synthesis of literature or research design through human cognitive abilities can allow students and trainees to identify biases, challenge assumptions, and detect conceptual gaps in conclusions derived from generative AI (Ganjoo et al., 2024). Moreover, healthcare professionals and students must be trained in AI literacy focusing on technical foundation, applications in realworld scenarios, the interaction between humans and genAI, critical thinking skills to differentiate genAI false claims and reality, strengthening of prompt engineering skills, and provide hands-on experience through case studies, and practical exercises, to apply genAI tools in simulated and reallife and to navigate its applications effectively (Charow et al., 2021;Walter, 2024;Sridharan et al. 2024). Incorporating assignments that require students to cross-check AI-generated information with reputable sources can foster critical thinking and responsible use of technology. This approach not only enhances students' research skills but also prepares them to navigate the ethical challenges associated with emerging AI technologies in their professional careers (Ganjoo et al, 2024;Masters et al, 2025). Integrating critical thinking into AI literacy courses ensures students grasp genAI's capabilities, limitations, ethical implications, and societal impact. By fostering analytical skills, educators help students become both technically proficient and ethically responsible. Furthermore, health professional educators must ensure the validation of genAI tools for accuracy and precision, personal data privacy, instructional strategies, assessment of teaching efficiency, learning outcomes, and feedback mechanisms for effective implementation of genAI-based educational programs (Feigerlova et al., 2025;Reddy, 2024;Shokrollahi et al., 2023).GenAI should be framed as a tool for enhancing learning, not replacing traditional educational methodologies. Journals and academic bodies should enforce transparency in research submissions assisted by genAI. Specifically disclosing AI usage in manuscripts, ensuring human verification of AI-generated data, and maintaining ethical standards in publication practices are essential measures that preserve the credibility of scholarly communication in an AI-augmented academic environment (Koul, 2023;Yang et al., 2024). Encouraging transparency in the application of generative AI for both the researcher and publisher reinforces an environment where original reasoning is not overshadowed by the ease of prompt engineering.By embracing the above-mentioned principles, we steer generative AI to augment human cognitive efforts, rather than replacing them. Instead of viewing efficiency and authenticity as competing values, we can align them using AI's processing power to handle repetitive tasks, while retaining human judgment for higher-level functions involving ethical reflection, contextual interpretation, and hypothesis generation. In doing so, we encourage a future in which technology catalyzes genuine innovation, inspiring thinkers to use genAI judiciously rather than dependently. It is essential to resist the allure of seamless outputs provided by generative AI that lack the precision and depth of the human intellect. The challenge is not to reject AI (quite the contrary) but to integrate it in ways that uphold the ethical, critical, and creative dimensions of health sciences. By doing so, we preserve the human spark that transforms data into discovery, complexities into clarity, and knowledge into wisdom.Wong, A., Otles, E., Donnelly, J.P., Krumm, A., McCullough, J., DeTroyer-Cooley, O., et al. (2021). External Validation of a Widely Implemented Proprietary Sepsis Prediction Model in Hospitalized Patients. JAMA. Intern. Med. 181(8):1065-1070. doi: 10.1001/jamainternmed.2021.2626Yang, K., Raković, M., Liang, Z., Yan, L., Zeng, Z., Fan, Y., et al. (2024). Modifying AI, Enhancing Essays: How Active Engagement with Generative AI Boosts Writing Quality. arXiv preprint arXiv:2412.07200. doi: 10.48550/arXiv.2412.07200 Zhai, C., Wibowo, S., Li, L.D. (2024). The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review. Smart Learn. Environ. 11:28. doi: 10.1186/s40561-024-00316-7.},
  archive      = {J_FRAI},
  author       = {Naqvi, Waqar M. and Ganjoo, Rohini and Rowe, Michael and Pashine, Aishwarya A. and Mishra, Gaurav V.},
  doi          = {10.3389/frai.2025.1571527},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1571527},
  shortjournal = {Front. Artif. Intell.},
  title        = {Critical thinking in the age of generative AI: Implications for health sciences education},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Management of scientific and ancestral knowledge: A decision-making model in mezcal industry in mexico. <em>FRAI</em>, <em>8</em>, 1570617. (<a href='https://doi.org/10.3389/frai.2025.1570617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionKnowledge management is essential to ensure the sustainability of rural communities and small producers since it generates value for innovation, productivity, and competitiveness. The aim of this study is to identify relevant factors for adequate decision-making in managing knowledge in the Mexican mezcal industry and its impact on developing rural communities and small producers - mezcaleros. For this purpose, a decision-making model for managing scientific and ancestral knowledge is created to support links with universities, research centers, and rural communities to accelerate innovation and competitiveness in this sector.MethodsThe analysis methods were carried out through decision-making, machine-learning techniques, and fuzzy logic.ResultsThe Bayesian Network model suggests that the preceding variables to optimize the Mezcaleros Knowledge Management are the Mezcaleros Indigenous community, the Denomination of Origin, Scientific and Ancestral Knowledge, Waste Management and Use, and Jima.DiscussionThis knowledge management model aims to guide small producers to be more productive and competitive through the support of a facilitator.},
  archive      = {J_FRAI},
  author       = {Terán-Bustamante, Antonia and Martínez-Velasco, Antonieta and Leyva-Hernández, Sandra Nelly},
  doi          = {10.3389/frai.2025.1570617},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1570617},
  shortjournal = {Front. Artif. Intell.},
  title        = {Management of scientific and ancestral knowledge: A decision-making model in mezcal industry in mexico},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training humans for synthetic face image detection. <em>FRAI</em>, <em>8</em>, 1568267. (<a href='https://doi.org/10.3389/frai.2025.1568267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake identities created using highly realistic synthetic face images have become increasingly prevalent in recent years, driven by advancements in generative neural networks that are readily accessible online and easy to use. These fake identities can be exploited for malicious purposes, such as spreading misinformation or committing fraud. Given the widespread availability of online content and the ease of generating fake online identities, it is desirable that users are able to distinguish real face images from synthetic ones. Additionally, it is important to explore whether specialized training can enhance the ability of individuals to detect synthetically generated face images. In this work, we address these challenges by designing an online experiment to evaluate human detection capabilities and the impact of training on detecting synthetic face images. As part of the experiments, we recruited 184 participants divided into an experimental group and a control group, where the experimental group underwent a tailored training session halfway through the experiment. The study shows that training may moderately enhance human capabilities to detect synthetic face images. Specifically, it was found that the experimental group generally outperformed the control group after training, primarily due to improved abilities in detecting synthetic face images. However, after training, the experimental group showed increased sensitivity and misclassified also more authentic face images, as compared to the control group.},
  archive      = {J_FRAI},
  author       = {Rehman, Ramlah Sara and Meier, Ewald and Ibsen, Mathias and Rathgeb, Christian and Nichols, Robert and Busch, Christoph},
  doi          = {10.3389/frai.2025.1568267},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1568267},
  shortjournal = {Front. Artif. Intell.},
  title        = {Training humans for synthetic face image detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExDoRA: Enhancing the transferability of large language models for depression detection using free-text explanations. <em>FRAI</em>, <em>8</em>, 1564828. (<a href='https://doi.org/10.3389/frai.2025.1564828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot prompting in large language models (LLMs) significantly improves performance across various tasks, including both in-domain and previously unseen natural language tasks, by learning from limited in-context examples. How these examples enhance transferability and contribute to achieving state-of-the-art (SOTA) performance in downstream tasks remains unclear. To address this, we propose ExDoRA, a novel LLM transferability framework designed to clarify the selection of the most relevant examples using synthetic free-text explanations. Our novel hybrid method ranks LLM-generated explanations by selecting the most semantically relevant examples closest to the input query while balancing diversity. The top-ranked explanations, along with few-shot examples, are then used to enhance LLMs’ knowledge transfer in multi-party conversational modeling for previously unseen depression detection tasks. Evaluations using the IMHI corpus demonstrate that ExDoRA consistently produces high-quality free-text explanations. Extensive experiments on depression detection tasks, including depressed utterance classification (DUC) and depressed speaker identification (DSI), show that ExDoRA achieves SOTA performance. The evaluation results indicate significant improvements, with up to 20.59% in recall for DUC and 21.58% in F1 scores for DSI, using 5-shot examples with top-ranked explanations in the RSDD and eRisk 18 T2 corpora. These findings underscore ExDoRA’s potential as an effective screening tool for digital mental health applications.},
  archive      = {J_FRAI},
  author       = {Priyadarshana, Y. H. P. P. and Liang, Zilu and Piumarta, Ian},
  doi          = {10.3389/frai.2025.1564828},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1564828},
  shortjournal = {Front. Artif. Intell.},
  title        = {ExDoRA: Enhancing the transferability of large language models for depression detection using free-text explanations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stakeholder-specific adoption of AI in HRM: Workers’ representatives’ perspective on concerns, requirements, and measures. <em>FRAI</em>, <em>8</em>, 1561322. (<a href='https://doi.org/10.3389/frai.2025.1561322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAI regulations aim to balance AI’s potential and risks in general and human resource management (HRM) in particular. However, regulations are not finally defined and the perspectives of key stakeholders of HRM applications are not clear yet. Research on AI in HRM contributes only to a limited extent to the understanding of key HRM stakeholders, and the perspective of workers’ representatives is especially lacking so far.MethodsThis paper presents a study of three focus group workshops investigating workers’ representatives’ perspectives, to determine which concerns they perceive when using AI in HRM, which resulting requirements they have for adopting AI in HRM, and which measures they perceive as most suitable to fulfill them.ResultsOur results revealed that workers’ representatives were critical of using AI across all HRM phases, particularly in personnel selection. We identified requirements and measures for adopting AI in HRM from the perspective of workers’ representatives. These were summarized in a catalog including six dimensions: control, human oversight, responsibilities, transparency and explainability, lawful AI, and data security.DiscussionOur findings shed a nuanced light on workers’ representatives’ needs, providing relevant insights for research on stakeholder-oriented adoption of AI in HRM and for specifying current AI regulations.},
  archive      = {J_FRAI},
  author       = {Malin, Christine and Fleiß, Jürgen and Thalmann, Stefan},
  doi          = {10.3389/frai.2025.1561322},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1561322},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stakeholder-specific adoption of AI in HRM: Workers’ representatives’ perspective on concerns, requirements, and measures},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning classification of drainage crossings based on high-resolution DEM-derived geomorphological information. <em>FRAI</em>, <em>8</em>, 1561281. (<a href='https://doi.org/10.3389/frai.2025.1561281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution digital elevation models (HRDEMs) from LiDAR and InSAR technologies have significantly improved the accuracies of mapping hydrographic features such as river boundaries, streamlines, and waterbodies over large areas. However, drainage crossings that facilitate the passage of drainage flows beneath roads are not often represented in HRDEMs, resulting in erratic or distorted hydrographic features. At present, drainage crossing datasets are largely missing or available with variable quality. While previous studies have investigated basic convolutional neural network (CNN) models for drainage crossing characterization, it remains unclear if advanced deep learning models will improve the accuracy of drainage crossing classification. Although HRDEM-derived geomorphological features have been identified to enhance feature extraction in other hydrography applications, the contributions of these features to drainage crossing image classification have yet to be sufficiently investigated. This study develops advanced CNN models, EfficientNetV2, using four co-registered 1-meter resolution geomorphological data layers derived from HRDEMs for drainage crossing classification. These layers include positive openness (POS), geometric curvature, and two topographic position index (TPI) layers utilizing 3 × 3 and 21 × 21 cell windows. The findings reveal that the advanced CNN models with HRDEM, TPI (21 × 21), and a combination of HRDEM, POS, and TPI (21 × 21) improve classification accuracy in comparison to the baseline model by 3.39, 4.27, and 4.93%, respectively. The study culminates in explainable artificial intelligence (XAI) for evaluating those most critical image segments responsible for characterizing drainage crossings.},
  archive      = {J_FRAI},
  author       = {Edidem, Michael and Xu, Bill and Li, Ruopu and Wu, Di and Rekabdar, Banafsheh and Wang, Guangxing},
  doi          = {10.3389/frai.2025.1561281},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1561281},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning classification of drainage crossings based on high-resolution DEM-derived geomorphological information},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel machine learning models for the prediction of acute respiratory distress syndrome after liver transplantation. <em>FRAI</em>, <em>8</em>, 1548131. (<a href='https://doi.org/10.3389/frai.2025.1548131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early prediction of acute respiratory distress syndrome (ARDS) after liver transplantation (LT) facilitates timely intervention. We aimed to develop a predictor of post-LT ARDS using machine learning (ML) methods. Data from 755 patients in the internal validation set and 115 patients in the external validation set were retrospectively reviewed, covering demographics, etiology, medical history, laboratory results, and perioperative data. According to the area under the receiver operating characteristic curve (AUROC), accuracy, specificity, sensitivity, and F1-value, the prediction performance of seven ML models, including logistic regression (LR), decision tree, random forest (RF), gradient boosting decision tree (GBDT), naïve bayes (NB), light gradient boosting machine (LGBM) and extreme gradient boosting (XGB) were evaluated and compared with acute lung injury prediction scores (LIPS). 234 (30.99%) ARDS patients were diagnosed. The RF model had the best performance, with an AUROC of 0.766 (accuracy: 0.722, sensitivity: 0.617) in the internal validation set and a comparable AUROC of 0.844 (accuracy: 0.809, sensitivity: 0.750) in the external validation set. The performance of all ML models was better than LIPS (AUROC 0.692, 0.776). The predictor variables included the age of the recipient, BMI, MELD score, total bilirubin, prothrombin time, operation time, standard urine volume, total intake volume, and red blood cell infusion volume. We firstly developed a risk predictor of post-LT ARDS based on RF model to ameliorate clinical practice.},
  archive      = {J_FRAI},
  author       = {Wu, Weijie and Zhang, Zheng and Wang, Shuailei and Xin, Ru and Yang, Dong and Yao, Weifeng and Hei, Ziqing and Chen, Chaojin and Luo, Gangjian},
  doi          = {10.3389/frai.2025.1548131},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1548131},
  shortjournal = {Front. Artif. Intell.},
  title        = {Novel machine learning models for the prediction of acute respiratory distress syndrome after liver transplantation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can chatbots teach us how to behave? examining assumptions about user interactions with AI assistants and their social implications. <em>FRAI</em>, <em>8</em>, 1545607. (<a href='https://doi.org/10.3389/frai.2025.1545607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we examine the issue of AI assistants, and the way they respond to insults and sexually explicit requests. Public concern over these responses, particularly because AI assistants are usually female-voiced, prompted tech companies to make them more assertive. Researchers have explored whether these female-voiced AI assistants could encourage abusive behavior and reinforce societal sexism. However, the extent and nature of the problem are unclear due to a lack of data on user interactions. By combining psychological and socio-cultural perspectives, we problematize these assumptions and outline a number of research questions for leveraging AI assistants to promote gender inclusivity more effectively.},
  archive      = {J_FRAI},
  author       = {Lima, Eleonora and Morisseau, Tiffany},
  doi          = {10.3389/frai.2025.1545607},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1545607},
  shortjournal = {Front. Artif. Intell.},
  title        = {Can chatbots teach us how to behave? examining assumptions about user interactions with AI assistants and their social implications},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using machine learning models to predict post-revascularization thrombosis in PAD. <em>FRAI</em>, <em>8</em>, 1540503. (<a href='https://doi.org/10.3389/frai.2025.1540503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ghandour, Samir and Rodriguez Alvarez, Adriana A. and Cieri, Isabella F. and Patel, Shiv and Boya, Mounika and Chaudhary, Rahul and Poucey, Anna and Dua, Anahita},
  doi          = {10.3389/frai.2025.1540503},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1540503},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using machine learning models to predict post-revascularization thrombosis in PAD},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring ChatGPT's potential for augmenting post-editing in machine translation across multiple domains: Challenges and opportunities. <em>FRAI</em>, <em>8</em>, 1526293. (<a href='https://doi.org/10.3389/frai.2025.1526293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Algaraady, Jeehaan and Mahyoob, Mohammad},
  doi          = {10.3389/frai.2025.1526293},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1526293},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring ChatGPT's potential for augmenting post-editing in machine translation across multiple domains: Challenges and opportunities},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating artificial intelligence bias in nephrology: The role of diversity, equity, and inclusion in AI-driven decision-making and ethical regulation. <em>FRAI</em>, <em>8</em>, 1525937. (<a href='https://doi.org/10.3389/frai.2025.1525937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundThe integration of Artificial Intelligence (AI) in nephrology has raised concerns regarding bias, fairness, and ethical decision-making, particularly in the context of Diversity, Equity, and Inclusion (DEI). AI-driven models, including Large Language Models (LLMs) like ChatGPT, may unintentionally reinforce existing disparities in patient care and workforce recruitment. This study investigates how AI models (ChatGPT 3.5 and 4.0) handle DEI-related ethical considerations in nephrology, highlighting the need for improved regulatory oversight to ensure equitable AI deployment.MethodsThe study was conducted in March 2024 using ChatGPT 3.5 and 4.0. Eighty simulated cases were developed to assess ChatGPT’s decision-making across diverse nephrology topics. ChatGPT was instructed to respond to questions considering factors such as age, sex, gender identity, race, ethnicity, religion, cultural beliefs, socioeconomic status, education level, family structure, employment, insurance, geographic location, disability, mental health, language proficiency, and technology access.ResultsChatGPT 3.5 provided a response to all scenario questions and did not refuse to make decisions under any circumstances. This contradicts the essential DEI principle of avoiding decisions based on potentially discriminatory criteria. In contrast, ChatGPT 4.0 declined to make decisions based on potentially discriminatory criteria in 13 (16.3%) scenarios during the first round and in 5 (6.3%) during the second round.ConclusionWhile ChatGPT 4.0 shows improvement in ethical AI decision-making, its limited recognition of bias and DEI considerations underscores the need for robust AI regulatory frameworks in nephrology. AI governance must incorporate structured DEI guidelines, ongoing bias detection mechanisms, and ethical oversight to prevent AI-driven disparities in clinical practice and workforce recruitment. This study emphasizes the importance of transparency, fairness, and inclusivity in AI development, calling for collaborative efforts between AI developers, nephrologists, policymakers, and patient communities to ensure AI serves as an equitable tool in nephrology.},
  archive      = {J_FRAI},
  author       = {Balakrishnan, Suryanarayanan and Thongprayoon, Charat and Wathanavasin, Wannasit and Miao, Jing and Mao, Michael A. and Craici, Iasmina M. and Cheungpasitporn, Wisit},
  doi          = {10.3389/frai.2025.1525937},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1525937},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating artificial intelligence bias in nephrology: The role of diversity, equity, and inclusion in AI-driven decision-making and ethical regulation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning architectures for influenza dynamics and treatment optimization: A comprehensive review. <em>FRAI</em>, <em>8</em>, 1521886. (<a href='https://doi.org/10.3389/frai.2025.1521886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a major worldwide health concern, influenza still requires precise modeling of flu dynamics and efficient treatment approaches. Deep learning architectures are increasingly being applied to address the complexities of influenza dynamics and treatment optimization, which remain critical global health challenges. This review explores the utilization of deep learning methods, such as Long Short-Term Memory (LSTM) networks, Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs), transformer architectures, and large language models (LLMs), in modeling influenza virus behavior and enhancing therapeutic strategies. The dynamic nature of influenza viruses, characterized by rapid mutation rates and the emergence of new strains, complicates the development of effective treatments and vaccines. In other words, the discovery of effective treatments and vaccines is severely hampered by the dynamic character of flu viruses, their fast rates of mutation, and the appearance of novel strains. Traditional epidemiological models often fall short due to their reliance on manual data interpretation and limited capacity to analyze large datasets. In contrast, deep learning offers a more automated and objective approach, capable of uncovering intricate patterns within extensive flu-related data, including genetic sequences and patient records. The application of deep learning to comprehend flu dynamics and improve treatment strategies is examined in this review paper. Moreover, this paper discussed relevant research findings, and future directions in leveraging deep learning for improved understanding and management of influenza outbreaks, ultimately aiming for more personalized treatment regimens and enhanced public health responses.},
  archive      = {J_FRAI},
  author       = {Adugna, Adane and Abebaw, Desalegn and Abebaw, Abtie and Jemal, Mohammed},
  doi          = {10.3389/frai.2025.1521886},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1521886},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning architectures for influenza dynamics and treatment optimization: A comprehensive review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements and challenges of artificial intelligence in climate modeling for sustainable urban planning. <em>FRAI</em>, <em>8</em>, 1517986. (<a href='https://doi.org/10.3389/frai.2025.1517986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is revolutionizing climate modeling by enhancing predictive accuracy, computational efficiency, and multi-source data integration, playing a crucial role in sustainable urban planning. This Mini Review examines recent advancements in machine learning (ML) and deep learning (DL) techniques that improve climate risk assessment, resource optimization, and infrastructure resilience. Despite these innovations, significant challenges persist, including data quality inconsistencies, model interpretability limitations, ethical concerns, and the scalability of AI models across diverse urban contexts. To bridge these gaps, this review highlights key research directions, emphasizing the development of interpretable AI models, robust data governance frameworks, and scalable AI-driven solutions that help climate adaptation. By addressing these challenges, AI-based climate modeling can provide actionable insights for policymakers, urban planners, and researchers fostering climate-resilient and sustainable urban environments.},
  archive      = {J_FRAI},
  author       = {Amnuaylojaroen, Teerachai},
  doi          = {10.3389/frai.2025.1517986},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1517986},
  shortjournal = {Front. Artif. Intell.},
  title        = {Advancements and challenges of artificial intelligence in climate modeling for sustainable urban planning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early diagnosis of autism across developmental stages through scalable and interpretable ensemble model. <em>FRAI</em>, <em>8</em>, 1507922. (<a href='https://doi.org/10.3389/frai.2025.1507922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a multifaceted neurodevelopmental condition that challenges early diagnosis due to its diverse manifestations across different developmental stages. Timely and accurate detection is essential to enable interventions that significantly enhance developmental outcomes. This study introduces a robust and interpretable machine learning framework to diagnose ASD using questionnaire data. The proposed framework leverages a stacked ensemble model, combining Random Forest (RF), Extra Tree (ET), and CatBoost (CB) as base classifiers, with an Artificial Neural Network (ANN) serving as the meta-classifier. The methodology addresses class imbalance using Safe-Level SMOTE, dimensionality reduction via Principal Component Analysis (PCA), and feature selection using Mutual Information and Pearson correlation. Evaluation on publicly available datasets representing toddlers, children, adolescents, adults, and a merged dataset (Combining children, adolescents, and adults dataset) demonstrates high diagnostic accuracy, achieving 99.86%, 99.68%, 98.17%, 99.89%, and 96.96%, respectively. Comparative analysis with standard machine learning models underscores the superior performance of the proposed framework. SHapley Additive exPlanations (SHAP) were used to interpret feature importance, while Monte Carlo Dropout (MCD) quantified uncertainty in predictions. This framework provides a scalable, interpretable, and reliable solution for ASD screening across diverse populations and developmental stages.},
  archive      = {J_FRAI},
  author       = {Mumenin, Nasirul and Rahman, Maisha Mumtaz and Yousuf, Mohammad Abu and Noori, Farzan M. and Uddin, Md Zia},
  doi          = {10.3389/frai.2025.1507922},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1507922},
  shortjournal = {Front. Artif. Intell.},
  title        = {Early diagnosis of autism across developmental stages through scalable and interpretable ensemble model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biomimicry as a decision-making methodology in condition monitoring. <em>FRAI</em>, <em>8</em>, 1485489. (<a href='https://doi.org/10.3389/frai.2025.1485489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In maintenance engineering, effective decision-making is critical to ensuring system reliability and operational efficiency. Modern industrial systems are monitored by a multitude of sensors that generate large volumes of data. However, traditional condition monitoring techniques face several limitations: they rely heavily on high-quality, continuous sensor input, struggle with adaptability to new fault scenarios, require significant computational resources, and often provide limited decision support beyond fault detection. These constraints hinder their practical utility in dynamic and resource-constrained environments. This paper introduces a biomimetics-inspired framework for condition management, drawing on principles observed in natural systems to overcome the aforementioned challenges. Biomimetics, an emerging interdisciplinary field, has shown significant promise in bridging gaps between theoretical innovation and practical industrial application. However, its potential remains underutilized in maintenance decision-making systems. In response, our study proposes a biologically inspired methodology that parallels the human cognitive system, integrating multi-sensory data, adaptive learning, and energy-efficient sensing mechanisms to enhance fault diagnosis and decision-making. The core contributions of this research are fourfold: (1) adaptive intelligence through continuous learning that revises rules and cases over time; (2) multi-sensory integration, inspired by animal sensory systems, to improve diagnostic accuracy; (3) data augmentation techniques that address issues of incomplete or noisy input; and (4) the introduction of energy-efficient sensors and biomimetic optimization strategies suitable for IoT and edge devices. To demonstrate the practical applicability of our approach, we conducted empirical studies using vibration data for procedural analytics, validating the framework's effectiveness in real-world fault diagnosis. It serves as a functional roadmap, inviting broader discussion on the integration of biomimetics in maintenance engineering.},
  archive      = {J_FRAI},
  author       = {Dhungana, Hariom},
  doi          = {10.3389/frai.2025.1485489},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1485489},
  shortjournal = {Front. Artif. Intell.},
  title        = {Biomimicry as a decision-making methodology in condition monitoring},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the evolution and future prospects of amharic to english machine translation: A systematic review. <em>FRAI</em>, <em>8</em>, 1456245. (<a href='https://doi.org/10.3389/frai.2025.1456245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn the last couple of decades, Amharic-English translation has greatly improved from a rule-based approach to contemporary systems that apply neural networks. Even after these advancements, problems remain because of the Amharic language’s resource-scarce nature, such as inadequate datasets, tools for working with the language, and the intricate semantics and grammar of Amharic as compared to English. This systematic review seeks to analyze the evolution of the Amharic-English machine translation, the prominent ongoing difficulties, the noteworthy research undertakings, and the prospects of the research focus.MethodsThis review uses a systematic approach to study the literature on Amharic-English machine translation. Important documents were retrieved from academic websites, and those with relevance to the methodologies of machine translation, language resources development, and evaluation practices were chosen. Primarily, the focus was on both statistical and neural machine translation models, especially those with transformer structures.ResultsThe initial attempts to translate English to Amharic and vice-versa relied on statistic machine translation (SMT), which set the stage for the evolution to neural machine translation (NMT). The use of transformer models has impacted the accuracy and fluidity of translations tremendously. Still, there is a lack of sufficient parallel corpora, effective methods for tokenization of Amharic, and other resources. Recently, the focus has been on creating new datasets, improving token-level engineering, and modifying NMT models for Amharic’s complex morphological structure.DiscussionThe complete solutions for enhancing Amharic-English translation remain elusive and include the lack of sufficient data, semantic correspondence, and grammatical consistency within and across translations. Pursuable avenues include augmentation of data, tokenization on the language level, and incorporation of linguistic elements into the parallel corpora. In addition, creating effective evaluation frameworks along with comprehensive linguistic data is important for assessing and improving translation tools. With these changes, cross-cultural interaction and increasing accessibility to modern technologies will be achieved.},
  archive      = {J_FRAI},
  author       = {Asebel, Muluken Hussen and Assefa, Shimelis Getu and Haile, Mesfin Abebe},
  doi          = {10.3389/frai.2025.1456245},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1456245},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the evolution and future prospects of amharic to english machine translation: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-learning: Code learning for multi-agent reinforcement collaborative framework with conversational natural language interfaces. <em>FRAI</em>, <em>8</em>, 1431003. (<a href='https://doi.org/10.3389/frai.2025.1431003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online question-and-answer (Q&A) systems based on the Large Language Model (LLM) have progressively diverged from recreational to professional use. However, beginners in programming often struggle to correct code errors independently, limiting their learning efficiency. This paper proposed a Multi-Agent framework with environmentally reinforcement learning (E-RL) for code correction called Code Learning (Co-Learning) community, assisting beginners to correct code errors independently. It evaluates the performance of multiple LLMs from an original dataset with 702 error codes, uses it as a reward or punishment criterion for E-RL; Analyzes input error codes by the current agent; selects the appropriate LLM-based agent to achieve optimal error correction accuracy and reduce correction time. Experiment results showed that 3% improvement in Precision score and 15% improvement in time cost as compared with no E-RL method respectively. The results indicate that integrating E-RL with a multi-agent selection strategy can effectively enhance both the accuracy and efficiency of LLM-based code correction systems, making them more practical for educational and professional programming support scenarios.},
  archive      = {J_FRAI},
  author       = {Yu, Jiapeng and Wu, Yuqian and Zhan, Yajing and Guo, Wenhao and Xu, Zhou and Lee, Raymond},
  doi          = {10.3389/frai.2025.1431003},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1431003},
  shortjournal = {Front. Artif. Intell.},
  title        = {Co-learning: Code learning for multi-agent reinforcement collaborative framework with conversational natural language interfaces},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: The role of conversational AI in higher education. <em>FRAI</em>, <em>8</em>, 1602037. (<a href='https://doi.org/10.3389/frai.2025.1602037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Another Aditya, Silvestri, and Otermans explores the potential of AI teachers in enhancing employability skills across three countries. Using a fine-tuned Large Language Model (LLM) called OIMISA, this research provides a 9-lesson course on employability and transferable skills, enrolling 207 students from various institutions. The results indicated a high engagement rate, with over 47% completion and strong student satisfaction. These findings suggest that AI teachers may offer a viable alternative to traditional online learning platforms like MOOCs, providing a more personalised and interactive learning experience. This research further strengthens the argument that AI can bridge educational gaps across diverse international contexts, ensuring that learning is more accessible and tailored to the needs of individual students.While much of the discourse has focused on the technical capabilities of AI, another Thomson, Pickard-Jones, Baines, and Otermans shifts the focus to students' perceptions of AI tools in academia. By surveying 453 students in the UK and conducting focus groups, the research examined students' familiarity with AI tools, their views on AI's potential use in education, and their knowledge of university AI policies. The results showed a strong desire among students to learn more about AI and to receive dedicated support in integrating these tools into their coursework. However, there was also a lack of awareness about existing AI policies at their institutions, pointing to a gap in communication between universities and students. The study emphasises that as AI technologies become integral to academic practice, universities must adopt a more comprehensive approach to communicating their AI policies, ensuring that students are adequately informed about how to use these tools responsibly and effectively.The increasing adoption of AI for academic assessments is also explored in a Al Mashagbeh, Dardas, Alzaben, and Alkhayat that evaluates the performance of ChatGPT and Google Bard in answering various question types in engineering and health sciences. The study found that ChatGPT-4 outperformed both ChatGPT-3.5 and Google Bard in problem-solving and accuracy, particularly excelling at true/false questions. However, the AI models struggled with simple calculations and certain types of multiple-choice questions, especially in health sciences. The findings highlight that while AI tools such as ChatGPT demonstrate considerable promise for supporting educational assessments, they still have limitations that require human oversight. This research reinforces the notion that AI can be a powerful tool in education, but its use must be carefully calibrated to avoid misapplication, particularly when it comes to tasks that require high levels of accuracy, such as calculations.As conversational AI becomes more prevalent in educational settings, its implications for computing education are also a topic of critical debate. Sengul, Neykova, and Destefanis explore the use of AI in software engineering education reveals a significant gap between the rapid adoption of AI in industry and its slower integration into HE. The research calls for a more strategic approach to incorporating AI tools into computing curricula, pointing out that while software engineering practices have embraced AI, academic institutions have been slower to adapt. This disconnect suggests that the current approach to computing education may need to evolve to better align with the demands of the industry, where AI is increasingly becoming a foundational tool for software development. The study suggests that AI could play a crucial role in shaping the future of computing education by helping students gain the skills needed to thrive in a tech-driven job market.The final in this collection by Proksch, Schühle, Streeb, Weymann, Luther, and Kimmerle takes a different approach by examining students' perceptions of AI in the context of moral decision-making. A controlled experiment involving 164 participants tested the perception of AI-generated texts on moral and technological topics. The study found that students consistently devalued AI compared to human authors, particularly when it came to texts on moral issues. These results align with algorithm aversion theory, suggesting that while students may embrace AI for technological tasks, they are less comfortable trusting AI for moral or ethical decisions. This highlights a critical challenge for the wider acceptance of AI in education: how to address the concerns surrounding the role of AI in making moral judgments, especially when it comes to sensitive academic tasks that involve ethical considerations.The contributions in this Research Topic collectively reflect the potential and challenges associated with integrating conversational AI into HE. From enhancing learning outcomes through personalised feedback to offering scalable teaching solutions across borders, AI offers numerous benefits. However, the findings also underscore the need for careful consideration of its limitations, including the accuracy of AI-generated content, the lack of familiarity with AI policies among students, and the complex ethical issues surrounding its use.The studies presented in this collection demonstrate that while AI has the potential to transform HE, its implementation must be accompanied by thoughtful policy development, continuous refinement of AI tools, and a balanced approach that addresses both the opportunities and challenges that come with the integration of AI in academia. As AI continues to evolve, it is crucial that educators, students, and institutions collaborate to harness its full potential while ensuring that its use is ethical, transparent, and aligned with the broader goals of education. This editorial has framed the aims and outcomes of the six articles in the broader context of the role conversational AI is playing in reshaping HE. As AI tools become more ubiquitous, the ongoing discourse and research on their application in educational settings will remain vital in navigating the complexities of these technologies.},
  archive      = {J_FRAI},
  author       = {Otermans, Pauldy C. J. and Demetriadis, Stavros and Richards, Deborah},
  doi          = {10.3389/frai.2025.1602037},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1602037},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: The role of conversational AI in higher education},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Human-centered artificial intelligence in interaction processes. <em>FRAI</em>, <em>8</em>, 1597763. (<a href='https://doi.org/10.3389/frai.2025.1597763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is achieved through methods and algorithms that learn from human input and collabora on, con nuously improving by understanding human behavior, emo ons, and language. The term Human-Machine Interac on (HMI) encompasses both Human-Computer Interac on (HCI) and Human-Robot Interac on (HRI). The goal is to create effec ve, efficient, safe, reliable, natural, and intui ve interac on between humans and machines. To achieve a human-centered interac on process, several key aspects must be taken into account. Firstly, the system should be equipped with mul modal interfaces that can be easily adapted to specific contexts, user needs, and preferences, making HMI as natural and intui ve as possible. Secondly, AI should have the capability to operate in dynamic, non-determinis c, and par ally unknown environments. Thirdly, it is essen al to foster mutual understanding and learning to ensure transparent and explainable interac ons. Lastly, systems should be designed to recognize and respond to human gestures, speech, and other non-verbal cues in a way that feels familiar and comfortable to humans.Having a comprehensive understanding of the design and development processes of current AI solu ons is essen al for shaping future AI-based systems. The introduc on of human-centered AI aims to bridge the gap between machines and humans, making AI genuinely useful in enhancing human capabili es. This approach priori zes users by considering their needs, contexts, and expecta ons while adap ng to changes in their interac on behaviors. Human-centered AI is complex and encompasses various factors such as social and cultural behaviors, users' abili es, preferences, and limita ons. As a result, it requires the involvement of users in the design process, learning from them, and collabora ng to create an accessible, effec ve, and sustainable interac on paradigm.The goal has been to provide an overview of AI techniques applied to human-machine interac on (HCI and HRI), with a par cular focus on a human-centric approach. This research topic has explored the latest challenges in AI-driven systems that interact with humans. It aims to iden fy current advancements in the field to achieve more effec ve and reliable human-machine interac on.A total of eight contribu ons were selected for publica on within this research topic.The ar cles in this research topic underline the importance of integra ng AI thinking into workflows and adop ng a human-centric approach for the future development of corporate work environments by exploring the impact of AI tools on the daily tasks of designers in corporate environments, with a focus on the crea on and evalua on processes of design briefs. [Zhu Z, Lee H, Pan Y and Cai P (2024) AI assistance in enterprise UX design workflows: enhancing design brief crea on for designers. Front. Ar f. Intell. 7:1404647. doi: 10.3389/frai.2024.1404647]. onally, the role of user-centered and personalized approaches in ar ficial intelligence has been examined to objec vely and quan ta vely measure the effec veness of explainable AI (XAI) systems, par cularly in terms of their "informa on power." [Matarese M, Rea F, Rohlfing KJ and Sciu A (2025) How informa ve is your XAI? Assessing the quality of explana ons through informa on power. Front. Comput. Sci. 6:1412341. doi: 10.3389/fcomp.2024.1412341].The AI techniques applied to human-machine interac on have been addressed by inves ga ng research on machine learning applica ons in scanpath analysis for passive gaze-based interac on [Mohamed Selim A, Barz M, Bha OS, Alam HMT and Sonntag D (2024) A review of machine learning in scanpath analysis for passive gaze-based interac on. Front. Ar f. Intell. 7:1391745. doi: 10.3389/frai.2024.1391745]. Furthermore, the poten al of ChatGPT 4 in the assessment of personality traits based on wri en texts has been inves gated [Piastra M and Catellani P (2025) On the emergent capabili es of ChatGPT 4 to es mate personality traits. Front. Ar f. Intell. doi: 10.3389/frai.2025.1484260]. In addi on, the impacts of and visual feedback from assis ve driving systems on drivers have been assessed to enhance the theore cal founda on in the field of automo ve user interface design, par cularly concerning the design of auditory func ons [Zou Z, Khan A, Lwin M, Alnajjar F and Mubin O (2025) Inves ga ng the impacts of auditory and visual feedback in advanced driver assistance systems: a pilot study on driver behavior and emo onal response. Front. Comput. Sci. 6:1499165. doi: 10.3389/fcomp.2024.1499165].Within this research topic, the impact of AI in various sectors of society has been addressed by understanding the factors influencing AI adop on [Ibrahim F, Münscher J-C, Daseking M and Telle N-TThe technology acceptance model and adopter type analysis in the context of ar ficial intelligence. Front. Ar f. Intell. 7:1496518. doi: 10.3389/frai.2024.1496518]. In addi on, the impact of AI tools has been explored on the daily tasks of designers in corporate environments, with a focus on the crea on and evalua on processes of design briefs, by indica ng that AI tools significantly enhance both opera onal experience and subjec ve percep ons across most tasks [Zhu Z, Lee H, Pan Y and Cai P (2024) AI assistance in enterprise UX design workflows: enhancing design brief crea on for designers. Front. Ar f. Intell. 7:1404647. doi: 10.3389/frai.2024.1404647]. Moreover, the impact of AI dimensions has been analysed on family communica on by inves ga ng the mul faceted effects of AI on family communica on [Alfeir NM (2024) Dimensions of ar ficial intelligence on family communica on. Front. Ar f. Intell. 7:1398960. doi: 10.3389/frai.2024.1398960]. The role of AI has been also addressed in the spread of misinforma on on social media by inves ga ng on how AI contributes to the crea on of decep ve war imagery [García-Huete E, Ignacio-Cerrato S, Pacios D, Vázquez-Pole JL, Pérez-Serrano MJ, Donofrio A, Cesarano C, Schetakis N and Di Iorio A (2025) Evalua ng the role of genera ve AI and color pa erns in the dissemina on of war imagery and disinforma on on social media. Front. Ar f. Intell. doi:Finally, the impacts of AI dimensions on family communica on have been analyzed by inves ga ng the mul faceted effects of AI on family communica on [Alfeir NM (2024) Dimensions of ar ficial intelligence on family communica on. Front. Ar f. Intell. 7:1398960. doi: 10.3389/frai.2024.1398960].This Research Topic has collected a cross-disciplinary perspec ve on human-machine interac on and its influence in several contexts.},
  archive      = {J_FRAI},
  author       = {Caschera, Maria Chiara and Grifoni, Patrizia and Cordella, Francesca},
  doi          = {10.3389/frai.2025.1597763},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1597763},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Human-centered artificial intelligence in interaction processes},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable machine learning to predict the cost of capital. <em>FRAI</em>, <em>8</em>, 1578190. (<a href='https://doi.org/10.3389/frai.2025.1578190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bussmann, Niklas and Giudici, Paolo and Tanda, Alessandra and Yu, Ellen Pei-Yi},
  doi          = {10.3389/frai.2025.1578190},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1578190},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable machine learning to predict the cost of capital},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The imperative of diversity and equity for the adoption of responsible AI in healthcare. <em>FRAI</em>, <em>8</em>, 1577529. (<a href='https://doi.org/10.3389/frai.2025.1577529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hilling, Denise E. and Ihaddouchen, Imane and Buijsman, Stefan and Townsend, Reggie and Gommers, Diederik and van Genderen, Michel E.},
  doi          = {10.3389/frai.2025.1577529},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1577529},
  shortjournal = {Front. Artif. Intell.},
  title        = {The imperative of diversity and equity for the adoption of responsible AI in healthcare},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-engaged artificial intelligence: An upstream, participatory design, development, testing, validation, use and monitoring framework for artificial intelligence and machine learning models in the alaska tribal health system. <em>FRAI</em>, <em>8</em>, 1568886. (<a href='https://doi.org/10.3389/frai.2025.1568886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rice, Brian Travis and Rasmus, Stacy and Onders, Robert and Thomas, Timothy and Day, Gretchen and Wood, Jeremy and Britton, Carla and Hernandez-Boussard, Tina and Hiratsuka, Vanessa},
  doi          = {10.3389/frai.2025.1568886},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1568886},
  shortjournal = {Front. Artif. Intell.},
  title        = {Community-engaged artificial intelligence: An upstream, participatory design, development, testing, validation, use and monitoring framework for artificial intelligence and machine learning models in the alaska tribal health system},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI revolution in insurance: Bridging research and reality. <em>FRAI</em>, <em>8</em>, 1568266. (<a href='https://doi.org/10.3389/frai.2025.1568266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bhattacharya, Sukriti and Castignani, German and Masello, Leandro and Sheehan, Barry},
  doi          = {10.3389/frai.2025.1568266},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1568266},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI revolution in insurance: Bridging research and reality},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding acceptance and resistance toward generative AI technologies: A multi-theoretical framework integrating functional, risk, and sociolegal factors. <em>FRAI</em>, <em>8</em>, 1565927. (<a href='https://doi.org/10.3389/frai.2025.1565927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Shrivastava, Priyanka},
  doi          = {10.3389/frai.2025.1565927},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1565927},
  shortjournal = {Front. Artif. Intell.},
  title        = {Understanding acceptance and resistance toward generative AI technologies: A multi-theoretical framework integrating functional, risk, and sociolegal factors},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized design and performance evaluation of long-pressure-short-extraction ventilation and dust removal system based on the coanda effect. <em>FRAI</em>, <em>8</em>, 1565889. (<a href='https://doi.org/10.3389/frai.2025.1565889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wang, Xinguo and Zhao, Jinbo and Li, Yufu and Li, Zhibin},
  doi          = {10.3389/frai.2025.1565889},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1565889},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimized design and performance evaluation of long-pressure-short-extraction ventilation and dust removal system based on the coanda effect},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient method for early alzheimer’s disease detection based on MRI images using deep convolutional neural networks. <em>FRAI</em>, <em>8</em>, 1563016. (<a href='https://doi.org/10.3389/frai.2025.1563016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Dardouri, Samia},
  doi          = {10.3389/frai.2025.1563016},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1563016},
  shortjournal = {Front. Artif. Intell.},
  title        = {An efficient method for early alzheimer’s disease detection based on MRI images using deep convolutional neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for accurate B-line detection and localization in lung ultrasound imaging. <em>FRAI</em>, <em>8</em>, 1560523. (<a href='https://doi.org/10.3389/frai.2025.1560523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Okila, Nixson and Katumba, Andrew and Nakatumba-Nabende, Joyce and Mwikirize, Cosmas and Murindanyi, Sudi and Serugunda, Jonathan and Bugeza, Samuel and Oriekot, Anthony and Bossa, Juliet and Nabawanuka, Eva},
  doi          = {10.3389/frai.2025.1560523},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1560523},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning for accurate B-line detection and localization in lung ultrasound imaging},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural studies of parvoviridae capsid assembly and evolution: Implications for novel AAV vector design. <em>FRAI</em>, <em>8</em>, 1559461. (<a href='https://doi.org/10.3389/frai.2025.1559461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Noriega, Heather A. and Wang, Qizhao and Yu, Daozhan and Wang, Xiang Simon},
  doi          = {10.3389/frai.2025.1559461},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1559461},
  shortjournal = {Front. Artif. Intell.},
  title        = {Structural studies of parvoviridae capsid assembly and evolution: Implications for novel AAV vector design},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning technique for multi classify alzheimer disease: Hyperparameter optimization technique. <em>FRAI</em>, <em>8</em>, 1558725. (<a href='https://doi.org/10.3389/frai.2025.1558725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Elmotelb, A. S. and Sherif, Fayroz F. and Abohamama, A. S. and Fakhr, Mahmoud and Abdelatif, Amr M.},
  doi          = {10.3389/frai.2025.1558725},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1558725},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel deep learning technique for multi classify alzheimer disease: Hyperparameter optimization technique},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A short report on deep learning synergy for decentralized smart grid cybersecurity. <em>FRAI</em>, <em>8</em>, 1557960. (<a href='https://doi.org/10.3389/frai.2025.1557960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grid technology is an amicable improvement of the conventional power grid characterized by improved communication, control, and computing technologies that enhance improved energy distribution. A smart grid is an improvement on the existing electric grid system that allow for more intelligent controlling of electricity from the generation point right down to the consumer. Consequently, the ICS (Industrial Control Systems) of smart grids have become more exposed to cyber risks resulting from enhanced network integration and digitalization. The complexity of smart grids with many DERs (Distributed Energy Resources), sensors, and systems make the security problem challenging. Reasons why decentralised smart grids have to be secure and more resilient mean that new approaches that can enable detection, prevention, and mitigations of cyber-attacks are desirable. Deep learning and smart grid cybersecurity based on decentralization has a bright outlook as it enables improving the detection of anomaly cases and potential threats and increasing the general level of resilience of the grid.Smart grids are a major evolution of conventional power grids that employ ICT (Information and Communication Technology) to optimize the delivery of electrical energy. Elements of smart grid include smart meters for consumers, automated distribution network, and communication network. Smart grids can be decentralised as it includes multiple DERs like solar power, wind mills or energy storage systems, that are usually integrated at the outskirts of the smart grid. Such decentralization adds more challenges to the grid's physical structure and also adds more vectors by which a cyber-threat can penetrate the network [1]. As such, cybersecurity emerged as a focal topic to protect the safe and reliable functioning of smart grids. It has also shown a commanding success in several contexts, which is due to the deep learning's inclusion capabilities of key features from accesses data [2]. A major advantage of deep learning is that models are able to detect the abnormal flow of traffic since they hold knowledge of normal traffic flow patterns [3]. Pattern recognition is another important factor; deep learning networks can recognize even complex pattern in a given data. However, deep learning models include scalability hence making them capable of analyzing a large quantity of data produced by, for instance, smart grids [4].The decentralized smart grids are the most vulnerable because of the localized architecture and large connections with IoT gadgets. The different systems that are used in smart girds are not homogenous and have different protocols and hence the weakness are provided [5]. Lack of computational capacity of many IoT devices due to resource constraints precludes such approaches and traditional security techniques cannot be implemented [6].Despite the potential of deep learning in smart grid cybersecurity, there are a number of issues before it. Concerning a few key points, it is important to mention data confidentiality as the training data can be considered sensitive. Another, there is an interpretability problem since, unlike traditional machine learning techniques, deep learning's models are considered 'black box' [7]. Another limitation of deep learning is that it demands massive computation, which may well not be readily feasible in low-power devices of smart grid [8]. There is also a big issue related to integration with legacy systems because such systems might be incompatible with deep learning solutions [9].Future research directions encompass the development of Smart grids which are decentralized and also experience a higher level of risk with relation to cybersecurity because of the deployment of several IoT devices. Table 1 summarizes robust deep learning approaches for smart grid cybersecurity, highlighting their advantages, challenges, and future directions. While these methods show high accuracy in detecting cyber threats (ranging from 92% to 99.5%), they face issues like high computational demands, vulnerability to adversarial attacks, and scalability concerns. Future research focuses on improving real-time integration, enhancing model interpretability, and developing more robust AI-driven cybersecurity frameworks.The most suitable solution for smart grid cybersecurity protection combines Federated Learning with Blockchain and Adversarial Deep Learning. With FL the grid nodes can participate in decentralized training processes without exchanging actual data which protects their information security and privacy. The combination of Blockchain technology and adversarial training creates an unalterable security framework which secures communication while building resistance against complex cyber threats. The implementation of this combined method becomes necessary because smart grids function through decentralized systems that connect many vulnerable IoT-enabled energy production networks to cyber security threats. Maximum security models become ineffective because they suffer from dimensional problems alongside privacy weaknesses and developing electronic strike threats. Through an integration of FL and Blockchain technology organizations achieve real-time threat detection with adaptive capabilities and lower IT overhead costs. Industrial security in the energy sector needs sophisticated AI-enabled solutions which must scale effectively to defend against infrastructure attacks and disruption of power supply. By utilizing this model organizations maintain autonomous cybersecurity operations which produce efficient proactive threat protection suitable for advanced smart grid systems against developing cyber attacks. Deep learning in the decentralised smart grid cybersecurity is a revolutionary way of handling the huge and dynamic risks. Based on the real-time data processing characteristic and the ability to recognize patterns of deep learning models, it is possible to improve the density of anomaly detection, threats' prediction, and systems' robustness. However, there are challenges that the use of deep learning in this area holds among them the fact that it calls for usage of a lot of computational power, data security issues, and the issues related with initiation and incorporation of integration of such complex technologies in the existing systems. To overcome these challenges new approaches, need to be created more efficiently, focus on to build effective privacy preservations, and integrate with other existing systems. For future work, the focus should be made on introducing new sophisticated and flexible frameworks of deep learning for the smart grid that will function in the given distributed environment. In this way, the industry can progress and advance towards building a smarter grid, that can address novel cyber threats and protect and enhance the reliability of the energy distribution systems.},
  archive      = {J_FRAI},
  author       = {Verma, Saurav and Rao, Ashwini},
  doi          = {10.3389/frai.2025.1557960},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1557960},
  shortjournal = {Front. Artif. Intell.},
  title        = {A short report on deep learning synergy for decentralized smart grid cybersecurity},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling missing data of using the XGBoost-based multiple imputation by chained equations regression method. <em>FRAI</em>, <em>8</em>, 1553220. (<a href='https://doi.org/10.3389/frai.2025.1553220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Jinbo, Zhao and Yufu, Li and Haitao, Mo},
  doi          = {10.3389/frai.2025.1553220},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1553220},
  shortjournal = {Front. Artif. Intell.},
  title        = {Handling missing data of using the XGBoost-based multiple imputation by chained equations regression method},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mortality prediction of heart transplantation using machine learning models: A systematic review and meta-analysis. <em>FRAI</em>, <em>8</em>, 1551959. (<a href='https://doi.org/10.3389/frai.2025.1551959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mohammadi, Ida and Farahani, Setayesh and Karimi, Asal and Jahanian, Saina and Firouzabadi, Shahryar Rajai and Alinejadfard, Mohammadreza and Fatemi, Alireza and Hajikarimloo, Bardia and Akhlaghpasand, Mohammadhosein},
  doi          = {10.3389/frai.2025.1551959},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1551959},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mortality prediction of heart transplantation using machine learning models: A systematic review and meta-analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the accuracy of ChatGPT in delivering patient instructions for medications: An exploratory case study. <em>FRAI</em>, <em>8</em>, 1550591. (<a href='https://doi.org/10.3389/frai.2025.1550591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Abanmy, Norah Othman and Al-Ghreimil, Nadia and Alsabhan, Jawza F. and Al-Baity, Heyam and Aljadeed, Rana},
  doi          = {10.3389/frai.2025.1550591},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1550591},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating the accuracy of ChatGPT in delivering patient instructions for medications: An exploratory case study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for intelligent RDF knowledge graph construction: Results from medical ontology mapping. <em>FRAI</em>, <em>8</em>, 1546179. (<a href='https://doi.org/10.3389/frai.2025.1546179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mavridis, Apostolos and Tegos, Stergios and Anastasiou, Christos and Papoutsoglou, Maria and Meditskos, Georgios},
  doi          = {10.3389/frai.2025.1546179},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1546179},
  shortjournal = {Front. Artif. Intell.},
  title        = {Large language models for intelligent RDF knowledge graph construction: Results from medical ontology mapping},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legal regulation of AI-assisted academic writing: Challenges, frameworks, and pathways. <em>FRAI</em>, <em>8</em>, 1546064. (<a href='https://doi.org/10.3389/frai.2025.1546064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Gao, Runyang and Yu, Danghui and Gao, Biao and Hua, Heng and Hui, Zhaoyang and Gao, Jingquan and Yin, Cha},
  doi          = {10.3389/frai.2025.1546064},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1546064},
  shortjournal = {Front. Artif. Intell.},
  title        = {Legal regulation of AI-assisted academic writing: Challenges, frameworks, and pathways},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cryptographic key generation using deep learning with biometric face and finger vein data. <em>FRAI</em>, <em>8</em>, 1545946. (<a href='https://doi.org/10.3389/frai.2025.1545946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Gizachew Yirga, Tsehayu and Gizachew Yirga, Hailu and Addisu, Eshetie Gizachew},
  doi          = {10.3389/frai.2025.1545946},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1545946},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cryptographic key generation using deep learning with biometric face and finger vein data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaverse technology tree: A holistic view. <em>FRAI</em>, <em>8</em>, 1545144. (<a href='https://doi.org/10.3389/frai.2025.1545144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ghazinoory, Sepehr and Parvin, Fatemeh and Saghafi, Fatemeh and Afshari-Mofrad, Masoud and Ghazavi, Nafiseh and Fatemi, Mehdi},
  doi          = {10.3389/frai.2025.1545144},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1545144},
  shortjournal = {Front. Artif. Intell.},
  title        = {Metaverse technology tree: A holistic view},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotional prompting amplifies disinformation generation in AI large language models. <em>FRAI</em>, <em>8</em>, 1543603. (<a href='https://doi.org/10.3389/frai.2025.1543603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Vinay, Rasita and Spitale, Giovanni and Biller-Andorno, Nikola and Germani, Federico},
  doi          = {10.3389/frai.2025.1543603},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1543603},
  shortjournal = {Front. Artif. Intell.},
  title        = {Emotional prompting amplifies disinformation generation in AI large language models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized system for predicting energy usage in smart grids using temporal fusion transformer and aquila optimizer. <em>FRAI</em>, <em>8</em>, 1542320. (<a href='https://doi.org/10.3389/frai.2025.1542320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Badhe, Namdeo Baban and Neve, Rahul P. and Yele, Vijaykumar P. and Abhang, Swati and Dhule, Komal Madhukar and Mali, Darshan},
  doi          = {10.3389/frai.2025.1542320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1542320},
  shortjournal = {Front. Artif. Intell.},
  title        = {An optimized system for predicting energy usage in smart grids using temporal fusion transformer and aquila optimizer},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing artificial intelligence’s impact on e-customer loyalty in the saudi arabian market. <em>FRAI</em>, <em>8</em>, 1541678. (<a href='https://doi.org/10.3389/frai.2025.1541678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Beyari, Hasan},
  doi          = {10.3389/frai.2025.1541678},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1541678},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing artificial intelligence’s impact on e-customer loyalty in the saudi arabian market},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating AI ethics: ANN and ANFIS for transparent and accountable project evaluation amidst contesting AI practices and technologies. <em>FRAI</em>, <em>8</em>, 1535845. (<a href='https://doi.org/10.3389/frai.2025.1535845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wankhade, Sandeep and Sahni, Manoj and León-Castro, Ernesto and Olazabal-Lugo, Maricruz},
  doi          = {10.3389/frai.2025.1535845},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1535845},
  shortjournal = {Front. Artif. Intell.},
  title        = {Navigating AI ethics: ANN and ANFIS for transparent and accountable project evaluation amidst contesting AI practices and technologies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-assisted capsule endoscopy for detecting lesions in crohn’s disease: A systematic review and meta-analysis. <em>FRAI</em>, <em>8</em>, 1531362. (<a href='https://doi.org/10.3389/frai.2025.1531362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bin, Yuling and Peng, Rumei and Lee, Yaqian and Lee, Zhijie and Liu, Yang},
  doi          = {10.3389/frai.2025.1531362},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1531362},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence-assisted capsule endoscopy for detecting lesions in crohn’s disease: A systematic review and meta-analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision enhancement in wireless capsule endoscopy: A novel transformer-based approach for real-time video object detection. <em>FRAI</em>, <em>8</em>, 1529814. (<a href='https://doi.org/10.3389/frai.2025.1529814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Habe, Tsedeke Temesgen and Haataja, Keijo and Toivanen, Pekka},
  doi          = {10.3389/frai.2025.1529814},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1529814},
  shortjournal = {Front. Artif. Intell.},
  title        = {Precision enhancement in wireless capsule endoscopy: A novel transformer-based approach for real-time video object detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approach for enhancing the accuracy of semantic segmentation of chest X-ray images by edge detection and deep learning integration. <em>FRAI</em>, <em>8</em>, 1522730. (<a href='https://doi.org/10.3389/frai.2025.1522730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mochurad, Lesia},
  doi          = {10.3389/frai.2025.1522730},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1522730},
  shortjournal = {Front. Artif. Intell.},
  title        = {Approach for enhancing the accuracy of semantic segmentation of chest X-ray images by edge detection and deep learning integration},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NLP-enhanced inflation measurement using BERT and web scraping. <em>FRAI</em>, <em>8</em>, 1520659. (<a href='https://doi.org/10.3389/frai.2025.1520659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Berki, Martin and Andicsova, Vanesa and Oravec, Milos},
  doi          = {10.3389/frai.2025.1520659},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1520659},
  shortjournal = {Front. Artif. Intell.},
  title        = {NLP-enhanced inflation measurement using BERT and web scraping},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing pre-trained language model by answering natural questions for event extraction. <em>FRAI</em>, <em>8</em>, 1520290. (<a href='https://doi.org/10.3389/frai.2025.1520290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Zhang, Yuxin and Han, Qing},
  doi          = {10.3389/frai.2025.1520290},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1520290},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing pre-trained language model by answering natural questions for event extraction},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the bitcoin’s price using AI. <em>FRAI</em>, <em>8</em>, 1519805. (<a href='https://doi.org/10.3389/frai.2025.1519805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Cohen, Gil and Aiche, Avishay},
  doi          = {10.3389/frai.2025.1519805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1519805},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting the bitcoin’s price using AI},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The current state, challenges, and future directions of artificial intelligence in healthcare in saudi arabia: Systematic review. <em>FRAI</em>, <em>8</em>, 1518440. (<a href='https://doi.org/10.3389/frai.2025.1518440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Aljehani, Najla M. and Al Nawees, Fatima E.},
  doi          = {10.3389/frai.2025.1518440},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1518440},
  shortjournal = {Front. Artif. Intell.},
  title        = {The current state, challenges, and future directions of artificial intelligence in healthcare in saudi arabia: Systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Making sense of transformer success. <em>FRAI</em>, <em>8</em>, 1509338. (<a href='https://doi.org/10.3389/frai.2025.1509338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Angius, Nicola and Perconti, Pietro and Plebe, Alessio and Acciai, Alessandro},
  doi          = {10.3389/frai.2025.1509338},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1509338},
  shortjournal = {Front. Artif. Intell.},
  title        = {Making sense of transformer success},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of AI for MRI-analysis in multiple sclerosis—A brief overview. <em>FRAI</em>, <em>8</em>, 1478068. (<a href='https://doi.org/10.3389/frai.2025.1478068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Falet, Jean-Pierre R. and Nobile, Steven and Szpindel, Aliya and Barile, Berardino and Kumar, Amar and Durso-Finley, Joshua and Arbel, Tal and Arnold, Douglas L.},
  doi          = {10.3389/frai.2025.1478068},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1478068},
  shortjournal = {Front. Artif. Intell.},
  title        = {The role of AI for MRI-analysis in multiple sclerosis—A brief overview},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and classification of ChatGPT-generated content using deep transformer models. <em>FRAI</em>, <em>8</em>, 1458707. (<a href='https://doi.org/10.3389/frai.2025.1458707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Maktabdar Oghaz, Mahdi and Babu Saheer, Lakshmi and Dhame, Kshipra and Singaram, Gayathri},
  doi          = {10.3389/frai.2025.1458707},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1458707},
  shortjournal = {Front. Artif. Intell.},
  title        = {Detection and classification of ChatGPT-generated content using deep transformer models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer wise scaled gaussian priors for markov chain monte carlo sampled deep bayesian neural networks. <em>FRAI</em>, <em>8</em>, 1444891. (<a href='https://doi.org/10.3389/frai.2025.1444891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Jawla, Devesh and Kelleher, John},
  doi          = {10.3389/frai.2025.1444891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1444891},
  shortjournal = {Front. Artif. Intell.},
  title        = {Layer wise scaled gaussian priors for markov chain monte carlo sampled deep bayesian neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for establishing shared, task-oriented understanding in hybrid open multi-agent systems. <em>FRAI</em>, <em>8</em>, 1440582. (<a href='https://doi.org/10.3389/frai.2025.1440582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Kondylidis, Nikolaos and Tiddi, Ilaria and ten Teije, Annette},
  doi          = {10.3389/frai.2025.1440582},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {1440582},
  shortjournal = {Front. Artif. Intell.},
  title        = {A framework for establishing shared, task-oriented understanding in hybrid open multi-agent systems},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Business transformation through AI-enabled technologies. <em>FRAI</em>, <em>8</em>, 1577540. (<a href='https://doi.org/10.3389/frai.2025.1577540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital era is characterized by rapid technological advancements, with Artificial Intelligence (AI) emerging as a key driver of business transformation. Companies are increasingly integrating AI-enabled technologies into their operations to enhance productivity, streamline processes, and optimize decision-making [2]. For instance, one of the special issue papers examined the integration of artificial intelligence in supply chain management (SCM) [4]. One of the key insights highlighted by this paper is that "integrating AI in SCM not only improves operational efficiency and sustainability but also promotes resilience against disruptions" [4]. From intelligent automation to predictive analytics, AI is reshaping industries by enabling organizations to leverage vast amounts of data for actionable insights. For instance, another special issue paper discussed the use of AI for the analysis of vast amount of data for generating and reporting software defects [5]. This study reported several benefits such as rea-time analysis and operational efficiency which helped identifying and reducing the failure and errors in a timely manner. While AI-enabled automation offers several benefits, however, its inner working needs to be explained for enhancing stakeholders' trust. This topic was covered in this special issue by another accepted paper discussing the "stakeholder-centric explanations for black-box decisions: an XAI process model and its application to automotive goodwill assessments" [6]. Finally, the fourth paper in this special issue provided a methodology for the planning, implementation, and evaluation of skills intelligence management in the context of informed decisionmaking and adaptability [7]. Additionally, this editorial expands on these papers and draws our attention to one of the most significant advancements in AI which is the emergence of generative AI models, such as GPT and discusses its potential to revolutionize business process management (BPM) [1]. By automating repetitive tasks, generating contextual insights, and facilitating seamless human-machine collaboration, AI-driven technologies are setting the foundation for intelligent business ecosystems. The remainder of this editorial further expands the topic of AI-enabled business process management followed by a discussion of key considerations. It concludes with a future outlook on the role of AI in continuous innovation.Business Process Management (BPM) is central to enterprise efficiency, governing how organizations design, analyze, and optimize workflows. Traditional BPM approaches relied on human expertise and structured methodologies. However, the integration of AI has ushered in a new era of smart BPM, where AI models automate process discovery, enhance workflow optimization, and provide intelligent recommendations.For instance, ProcessGPT [1], an AI-driven BPM framework, leverages generative AI to streamline business processes. By analyzing historical data and learning from domainspecific knowledge, such technologies can generate process flows, identify inefficiencies, and recommend optimization strategies. The implications are profound: AI-powered BPM reduces operational costs, enhances agility, and enables organizations to adapt to evolving market conditions.AI's transformative impact extends to data-centric and knowledge-intensive processes, where decision-making is crucial. AI models can analyze vast datasets, detect patterns, and generate actionable insights, thereby augmenting human expertise. In domains such as finance, healthcare, and supply chain management, AI-driven analytics improve risk assessment, optimize resource allocation, and enhance customer experiences.Moreover, knowledge-intensive industries, such as legal and research-driven enterprises, benefit from AI's ability to process complex information. By integrating AI models with knowledge graphs and semantic reasoning, businesses can enhance decision-making and foster innovation. AI-enabled knowledge management systems facilitate the retrieval of relevant information, automate document summarization, and support collaborative problem-solving.One of the key drivers of business transformation is the shift from process augmentation to full automation. AI technologies are evolving from assisting human workers in decision-making to autonomously executing complex tasks. This transition is evident in various industries:1. Financial Services: AI-driven fraud detection systems analyze transactional data in real-time, identifying suspicious activities and preventing financial losses.2. Healthcare: AI models assist medical professionals in diagnostics, drug discovery, and personalized treatment recommendations.3. Education: AI-powered tools automate grading, generate personalized learning pathways, and enhance student engagement.4. Manufacturing: AI-driven robotics and predictive maintenance optimize production lines, reducing downtime and improving efficiency.As AI capabilities advance, businesses must strategically navigate the balance between human expertise and machine intelligence to maximize efficiency while ensuring ethical considerations and transparency in decision-making.While AI presents unparalleled opportunities, it also raises challenges that businesses must address. Ethical AI deployment, data privacy, and bias mitigation are critical concerns. Organizations must ensure that AI models are trained on diverse datasets to prevent biases and maintain fairness in decision-making. Additionally, regulatory compliance and transparent AI governance frameworks are essential for building trust in AI-driven solutions.Another challenge is workforce transformation. As AI automates routine tasks, businesses must invest in upskilling employees to work alongside AI technologies. The future workforce will require a blend of technical skills and problem-solving capabilities to effectively leverage AI-driven insights.The future of AI-enabled business transformation lies in continuous innovation. As AI models become more sophisticated, businesses will increasingly adopt AI-driven decision intelligence, autonomous systems, and human-AI collaboration frameworks. The evolution of AI-powered digital twins [3], generative design systems, and adaptive AI solutions will redefine industry standards and create new business opportunities.To remain competitive, organizations must embrace AI as a strategic enabler of innovation. By integrating AI into core business functions, companies can unlock new revenue streams, enhance customer experiences, and drive operational excellence.},
  archive      = {J_FRAI},
  author       = {Rabhi, Fethi and Beheshti, Amin and Gill, Asif},
  doi          = {10.3389/frai.2025.1577540},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1577540},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Business transformation through AI-enabled technologies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing large language models as assistive tools in medical consultations for kawasaki disease. <em>FRAI</em>, <em>8</em>, 1571503. (<a href='https://doi.org/10.3389/frai.2025.1571503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yan, Chunyi and Li, Zexi and Liang, Yongzhou and Shao, Shuran and Ma, Fan and Zhang, Nanjun and Li, Bowen and Wang, Chuan and Zhou, Kaiyu},
  doi          = {10.3389/frai.2025.1571503},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1571503},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing large language models as assistive tools in medical consultations for kawasaki disease},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in business operations: Driving urban growth and societal sustainability. <em>FRAI</em>, <em>8</em>, 1568210. (<a href='https://doi.org/10.3389/frai.2025.1568210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximately 30% of smart city applications will use artificial intelligence (AI) by the end of 2025, thereby radically altering the urban sustainability landscape in the future (Yan et al., 2023). The advent of AI in reshaping traditional businesses into sustainable operations is evident. Whenever AI is brought to the forefront, it is considered a cornerstone in the business domain, enabling a transition towards more innovative and sustainable practices (Appio et al., 2024). Incorporating AI into business practices has many facets. According to Grand View Research (2023), the global AI market size was anticipated at USD 196.63 billion in 2023 and is expected to grow at a CAGR of 36.6% from 2024 to 2030. The recent fanfare surrounding AI has elevated it to a key enabler of sustainable development, prompting many companies to prioritize and integrate it into their business operations; hence, there is a stark difference between traditional and new practices. In tandem with this evolution, urban growth and societal dynamics are experiencing profound changes as AI-driven solutions come to the fore in various aspects of modern society (Shahidi Hamedani et al., 2024). AI applications in city government, transforming conventional cities into efficient ones (Ortega-Fernández et al., 2020), have significantly shifted from functional systems to more sustainable and intelligent ones. Furthermore, from another perspective, the role of AI in optimizing business processes has surpassed comparison with its implication for improving logistics operational capabilities and reducing environmental impacts (Jorzik et al., 2024a) till manufacturing reduces downtime, all of which contribute to the growth of urban economics. In the meantime, with the speedy pace of adoption of AI in business operations, it is also imperative to amalgamate with sustainable practices. Acting on this matter requires a thoughtful approach that aligns AI with social, economic, and environmental sustainability.The intersection of AI role and business operations has recently gained widespread attention. Some studies (Chen et al., 2024;Shahzadi et al., 2024)focused on AI's role in supply chain management, highlighting its role in minimizing inefficiencies and improving logistics by utilizing AI more often;supply chains become leaner and reduced carbon footprints, paving the path to sustainable operations. It is estimated that by 2026, 60% of businesses will adopt AI-powered warehouse solutions instead of just 10% in 2020 (MHI, 2024).In line with this shift, (Dilmegani & Ermut, 2025) note that businesses also invest heavily in warehouse robots to enhance their supply chain management through AI technology. Robots can manage operations more efficiently and accurately by automating picking, packing, sorting, and inventory management, thus saving labor costs and accelerating order processing. Amazon, for instance, has deployed more than 200,000 robots in its warehouses to optimize operations.AI can be used to optimize resource utilization, automate processes for improved efficiency, and enable real-time monitoring that aligns with sustainability goals (Waltersmann et al., 2021). As sustainable supply chain management focuses on reducing waste and enhancing traceability, AI-driven technologies such as machine learning and big data analytics have been pivotal in achieving these goals. (Tsolakis et al., 2023) Companies like eBay leverage AI for machine translation, enhancing decision-making and operational efficiency . Similarly, Vodafone employs AI-driven analytics to personalize services, exemplifying its transformative impact. (Jorzik et al., 2024a).These technologies help reduce forecasting errors, minimize excess inventory, and lower energy consumption. (Sharma et al., 2020) Likewise, Smart grid protection sensors can detect defects up to 80% more accurately than traditional sensors, reducing losses and improving the system's reliability by adjusting to grid conditions dynamically (Mahadik, Sheetal et al., 2025). These applications contribute to urban economic growth by fostering technological innovation. AI leverages advanced techniques like deep reinforcement learning (DRL) to optimize dynamic business operations (Shuford, 2024). DRL improves supply chain management through adaptive routing and inventory optimization, dynamically adjusting to real-time changes in demand and logistics; with the help of DRL, researchers can develop systems that can dynamically adapt to changes, optimize resource utilization, and facilitate multi-objective decision-making for instance, (Dehaybe et al., 2024).In addition, it enables businesses to prevent equipment failures and minimize downtime, thereby streamlining workflows significantly (Mohan et al., 2021). Moreover, in urban centers, these advancements catalyze economic growth and foster innovation. In other words, a key contribution of AI is to facilitate smart urban development and efficient resource allocation, thereby ensuring that cities are resilient and economically prosperous (Li et al., 2024). In developing smart cities, AI has a transformative impact on urbanization trends. Through the application of AI, urban infrastructure can be optimized by improving energy efficiency, streamlining transportation, and managing housing needs; AI makes it possible to reduce traffic congestion and advance mobility in transportation systems, such as prescriptive traffic management and autonomous vehicles (Regona et al., 2024).In cities like Singapore, AI manages real-time traffic and monitors energy consumption, setting urban efficiency benchmarks (Padhiary et al., 2025). On a similar note, Tennet TSO, a German transmission system operator, has been utilizing AI-based forecasting and IBM Watson's cognitive computing platform to anticipate renewable energy generation in real time, allowing real-time grid adjustments and maximizing clean energy use. (Mahadik, Sheetal et al., 2025) 3Nowadays, sustainability is a debatable topic, and the role of AI in sustainability is inevitable. Reducing waste and environmental food print, optimizing resource utilization, and fostering a circular economy is the sprout of AI role which assists in a sustainable environment (Onyeaka et al., 2023); for example, in the agriculture industry, enhancing operational automation, a prediction model for the total agricultural output value (Sachithra & Subhashini, 2023), improving yields while reducing environmental impact. Moreover, this is apparent regarding the implications of AI and IoT in agriculture due to their ability to improve efficiency and sustainability. Agriculture leads the way with 35% of these technologies, followed by precision farming and irrigation monitoring at 16% each.Farming practices are becoming smarter and more sustainable due to these innovations, which increase yields, reduce waste, and conserve resources (Market.Us, 2024).Similarly, smart grid technologies optimize energy distribution, lowering carbon footprints (Bhattacharya et al., 2022). As manufacturing and logistics become increasingly automated, energy consumption and operational inefficiencies will be minimized and aligned with global sustainability goals (Garrido et al., 2024).By placing AI at the heart of sustainability, industries can grow while solving environmental and social issues. Moreover, businesses shift from traditional linear operations to circular, innovative, and efficient models (Pathan et al., 2023). The paradigm shift of AI contributes to sustainability from various aspects; for site surveying and progress monitoring, AI power drones are used to enhance decision-making, reduce energy consumption and minimize waste, and facilitate green finance in the agriculture sector and its application in the cultivation and harvesting phases (Fuentes-Peñailillo et al., 2024). While AI is crucial in ensuring sustainable business operations, implementing it brings several challenges, including ethical and privacy concerns (Fan et al., 2023).In urban planning and infrastructure, there are also notable examples; by using data and knowledge acquired by AI, cities can shift to another level and have the potential to revolutionize city development, which will enable over 30% of smart city applications by 2025, including urban transportation solutions, significantly enhancing urban sustainability, social welfare, and vitality (Herath & Mittal, 2022). Furthermore, AI-enabled robots are deployed in the hospitality sector to provide personalized services and facilitate seamless guest experiences (Szpilko et al., 2023).Similarly, in the healthcare industry, AI can detect and predict diseases rapidly and accurately (Rashid & Kausik, 2024). For instance, The PRAIM study in Germany assessed AI-supported mammography screening versus standard double reading. Out of 463,094 women screened, 260,739 were assisted by AI. With AI-supported screening, 6.7 cancers were detected out of 1,000, which is 17.6% higher than in standard screening. (Eisemann et al., 2025) Policies are needed to protect individual privacy in urban settings and solve concerns (Dong & Liu, 2023). AI technologies rapidly gain momentum in various industries but present challenges, including significant data security and privacy concerns. Data privacy and security protection are becoming an urgent concern (Saura et al., 2022). Acknowledging that AI adoption will have significant societal consequences, particularly when shifting employment patterns and consumer behaviors, is important (Yu et al., 2023). The rise of automation has displaced traditional jobs and created a demand for AIspecialized workers (Betts et al., 2024).AI's role in personalizing consumer experiences underscores the ethical responsibility to protect data privacy and mitigate algorithmic biases, maintaining public trust and equity. Governments and businesses must work together to implement reskilling programs to seamlessly transition to an AIdriven world. AI's Ethical concerns, like data privacy and the digital divide, underscore the need for transparent and inclusive AI solutions (Bouhouita-Guermech et al., 2023). These challenges are amplified in urban areas, where disparities in digital access can marginalize vulnerable populations. These issues can be solved only by collaborative efforts to design AI systems prioritizing societal wellbeing and inclusiveness.Several challenges exist, including data integration issues, AI literacy issues, resistance to technological change, data availability, and reliance on data (Uwaoma et al., 2024). In many industries, getting clean and actionable data is time-consuming and costly. As a result, AI models cannot produce satisfactory results without robust data, undermining their potential for sustainability. Moreover, AI adoption is complicated by ethical issues (Bouhouita-Guermech et al., 2023). Ensuring equal access to technology and data privacy must be addressed so that AI benefits all sectors of society. Additionally, fostering AI literacy within organizations is of utmost importance. Many organizations resist to change due to a lack of understanding, making it difficult for them to adopt AI-driven sustainability practices in the future.Moreover, lack of data (availability and quality) also remains a hurdle for implementing sustainability in business operations; in other words, accessing clean data is also opaque (Jorzik et al., 2024b); for instance, for training DRL's models, quality datasets are critical, and data within several sustainability contexts is both sparse and expensive to collect (Saliba et al., 2020).On the other hand, the reliability of data is also another concern; according to Choudhuri, (2023), 30 % of sustainability data is unreliable or has poor quality; having said that, incomplete data can fail any method of analysis and affect the decision-making process in other words without data-especially high-quality data-sustainable development is doomed to falter. A further concern is ensuring equitable access to AI since marginalized communities often face barriers to taking advantage of these developments (Kasun et al., 2024). The challenges highlighted here highlight the need for a balanced approach to AI deployment.Without AI, the prospects of adopting sustainable business practices are becoming increasingly bleak. However, Sustainable business demands the involvement of the government and the public sector.Governments must establish policies and regulations to promote transparency and collaboration to ensure high-quality data transfer to the private sector. Policies of this kind can foster cooperation between industries, facilitating the use of AI technologies responsibly and efficiently while addressing broader sustainability goals.The advancement of AI, however, is hindered by several limitations, including an unwillingness to change, ethical privacy concerns, and the difficulty of integrating new technology into pre-existing HR systems (Madanchian & Taherdoost, 2025). In addition, AI advancements are hampered by algorithms without common sense that cannot interpret data properly, resulting in flawed decisions (Nishant et al., 2024). As a result, clinicians' decision-making can be negatively impacted (Dratsch et al., 2023); for example, when prescribing antidepressants, clinicians were less accurate when following incorrect AI recommendations compared to a baseline or correct advice condition (Jacobs et al., 2021). The high cost of implementing AI in resource-intensive settings makes it difficult to reach a broad audience (Sommer et al., 2023). Additionally, organizational resistance to change creates a significant barrier to adopting AI in HRM since employees are reluctant to adopt AI due to concerns about data security, privacy, and possible job losses (Hassan et al., 2024).Businesses and industries are witnessing the impact of AI as a key driver of growth, which profoundly impacts businesses in various sectors. For instance, In the context of urban development, it can be implemented to improve traffic management, infrastructure, and public transportation scheduling in a way that contributes to more livable and sustainable urban development. AI can provide businesses with the means to optimize resources, reduce inefficiencies, and embrace innovative practices, enabling them to tackle urgent environmental and economic concerns. The full benefits of AI can only be realized if businesses align their operations with clearly defined sustainability targets. Achieving this requires a strategic approach to AI, not just a technical tool for generating short-term benefits.Policymakers must develop a reliable model that fairly and equitably fosters the use of AI in a broad range of sectors. Additionally, it would be beneficial for both the public and private sectors to work together to create inclusive solutions that will reduce societal disparities and protect the environment at the same time.As AI becomes increasingly integral to sustainability, it presents opportunities and challenges. A more sustainable market requires businesses to adopt AI to reduce costs; as McKinsey ( 2022), several companies have reported that AI forecasting engines reduce costs by 10% to 15% and improve their competitive position by automating up to 50% of workforce management tasks. However, the role of policymakers and urban planners in creating the conditions for AI innovations to thrive responsibly and inclusively cannot be overstated. Integrating AI into sustainable practices requires balancing technological advancements with ethical considerations. AI can be a powerful force for sustainable development if stakeholders create a collaborative atmosphere, address barriers, and promote transparency. As a result, businesses, societies, and the environment will all benefit. By examining the intersection of AI and urban sustainability in a new manner, the article introduces a fresh perspective to the literature because its analysis is not comprehensively covered in the current literature. It is valuable to synthesize existing literature to highlight trends and develop a strong foundation for understanding AI's role in business.},
  archive      = {J_FRAI},
  author       = {Shahidi Hamedani, Sharareh and Aslam, Sarfraz and Shahidi Hamedani, Shervin},
  doi          = {10.3389/frai.2025.1568210},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1568210},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI in business operations: Driving urban growth and societal sustainability},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable artificial intelligence in finance: Impact of ESG factors. <em>FRAI</em>, <em>8</em>, 1566197. (<a href='https://doi.org/10.3389/frai.2025.1566197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Giudici, Paolo and Wu, Lunshuai},
  doi          = {10.3389/frai.2025.1566197},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1566197},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sustainable artificial intelligence in finance: Impact of ESG factors},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate V2X traffic prediction with deep learning architectures. <em>FRAI</em>, <em>8</em>, 1565287. (<a href='https://doi.org/10.3389/frai.2025.1565287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Abdellah, Ali R. and Abdelmoaty, Ahmed and Ateya, Abdelhamied A. and Abd El-Latif, Ahmed A. and Muthanna, Ammar and Koucheryavy, Andrey},
  doi          = {10.3389/frai.2025.1565287},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1565287},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accurate V2X traffic prediction with deep learning architectures},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subtle changes on electrocardiogram in severe patients with COVID-19 may be predictors of treatment outcome. <em>FRAI</em>, <em>8</em>, 1561079. (<a href='https://doi.org/10.3389/frai.2025.1561079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Chaikovsky, Illya and Dziuba, Dmytro and Kryvova, Olga and Marushko, Katerina and Vakulenko, Julia and Malakhov, Kyrylo and Loskutov, Оleg},
  doi          = {10.3389/frai.2025.1561079},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1561079},
  shortjournal = {Front. Artif. Intell.},
  title        = {Subtle changes on electrocardiogram in severe patients with COVID-19 may be predictors of treatment outcome},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing structured data generation with GPT-4o evaluating prompt efficiency across prompt styles. <em>FRAI</em>, <em>8</em>, 1558938. (<a href='https://doi.org/10.3389/frai.2025.1558938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Elnashar, Ashraf and White, Jules and Schmidt, Douglas C.},
  doi          = {10.3389/frai.2025.1558938},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1558938},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing structured data generation with GPT-4o evaluating prompt efficiency across prompt styles},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender and content bias in large language models: A case study on google gemini 2.0 flash experimental. <em>FRAI</em>, <em>8</em>, 1558696. (<a href='https://doi.org/10.3389/frai.2025.1558696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Balestri, Roberto},
  doi          = {10.3389/frai.2025.1558696},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1558696},
  shortjournal = {Front. Artif. Intell.},
  title        = {Gender and content bias in large language models: A case study on google gemini 2.0 flash experimental},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The relevance of lead prioritization: A B2B lead scoring model based on machine learning. <em>FRAI</em>, <em>8</em>, 1554325. (<a href='https://doi.org/10.3389/frai.2025.1554325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {González-Flores, Laura and Rubiano-Moreno, Jessica and Sosa-Gómez, Guillermo},
  doi          = {10.3389/frai.2025.1554325},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1554325},
  shortjournal = {Front. Artif. Intell.},
  title        = {The relevance of lead prioritization: A B2B lead scoring model based on machine learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDP prediction of the gambia using generative adversarial networks. <em>FRAI</em>, <em>8</em>, 1546398. (<a href='https://doi.org/10.3389/frai.2025.1546398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Jallow, Haruna and Gibba, Alieu and Mwangi, Ronald Waweru and Imboga, Herbert},
  doi          = {10.3389/frai.2025.1546398},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1546398},
  shortjournal = {Front. Artif. Intell.},
  title        = {GDP prediction of the gambia using generative adversarial networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A critical look into artificial intelligence and healthcare disparities. <em>FRAI</em>, <em>8</em>, 1545869. (<a href='https://doi.org/10.3389/frai.2025.1545869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has permeated many aspects of daily life, including medicine, in recent years. As of 2021, 343 AI-enabled medical devices had been approved by the United States Food and Drug Administration, with many more in development (1). Most notable thus far has been AI's ability to assist with every step of radiology workflow: it can determine the appropriateness of imaging, recommend the most appropriate imaging exam, predict wait times or appointment delays, and interpret imaging, with much more potential utilizations (2). The World Health Organization proposed that AI tools be integrated into healthcare to improve efficiency and achieve sustainable health-related development (3). AI in healthcare can reduce costs and administrative burdens, reduce waiting times for patients to receive care, improve diagnostic abilities and patient care, facilitate data management, and expedite discovery (4,5).However, the advancement of AI in healthcare comes with unique drawbacks. For example, data security and privacy are at risk and must be improved, as patients may more readily and unknowingly provide consent for covert data collection methods (6,7). Use of AI must be seriously reconsidered if it poses a risk to patient confidentiality, a non-negotiable in healthcare. With the ability of AI to rapidly gather and analyze large amounts of patient data, controlling the scope of its use becomes a challenge: these tools may progress to collect and disclose data without patient consent or direct investigator oversight (5). In addition, as most healthcare-based AI research has been conducted in non-clinical settings, rolling out AI in certain clinical settings may result in non-evidence-based practice (6). For example, clinicians may feel tempted to use AI for tasks beyond their validation, and training data may not adequately represent the scenarios clinicians encounter (8). In fact, many studies on AI in healthcare have been administered in non-clinical settings (5).That is not to say AI should not be used in healthcare. It does, however, require immense consideration in how it is designed and why it is utilized. Some have contended that a goal of developing AI for healthcare should be to minimize health disparities and make the healthcare system more equitable (1,9). Yet, many characteristics of AI make this goal difficult to achieve. As such, there is a growing body of literature that discusses AI's role in both closing and perpetuating these inequalities (10)(11)(12). As the ability of AI is directly proportional to the quality of the training sets used, authors have addressed concerns regarding bias in training datasets and lack of diversity in development teams ultimately resulting in AI-driven disparities in care (5,(13)(14)(15). This article draws from existing literature to add to the ongoing conversation about the implications of AI in healthcare disparities. Specifically, we discuss economic implications, the explainability of AI systems, and the importance of compassionate care. Ultimately, while AI may indeed confer benefits to the healthcare system, it remains far from the goal of closing healthcare disparities and may, instead, backfire.One essential consideration in any kind of social disparity is economics. The United States is notorious for having the highest healthcare expenditure globally, with healthcare costing $3.5 trillion, or 17.9% of the Gross Domestic Product (16). Any measure to decrease this economic burden -either in the US or internationally -may be attractive. AI has the potential to save billions in annual healthcare costs (17). AI may greatly streamline workflow, even in non-clinical tasks. An automated system may alleviate administrative burdens such as scheduling patients, estimating wait times, and billing insurance companies (2,17,18). Such workflow optimization may reduce the cost of healthcare delivery by cutting out intermediaries that typically handle these mundane tasks. In turn, patients' financial responsibility related to their care may be reduced.On the clinical side, AI may be used to screen for and diagnose conditions, stratify disease risk, and devise treatment plans (16). It may significantly reduce medical errors and factors are associated with adverse outcomes (4). Eventually, as technology advances, it may even perform procedures, given that it is deemed ethical, safe and evidence-based. While these benefits may seem like simply a perk to those practicing in physician-rich areas, they could become indispensable to those in areas affected by shortages of medical professionals (19). Urban and rural communities bear the brunt of this inequity, with many struggling to access both primary and specialty care (20). It has been estimated that by 2030, there may be a shortage of up to 104,900 physicians in the United States (20). As such, AI implementation in these underserved populations may help to alleviate these challenges and improve disparities regarding access to care (19). Furthermore, AI assistants may help decrease physician burnout and therefore improve quality of care (21).These advantages of AI are conferred only with the proper development, installation and maintenance of these systems. AI requires immense investment. One model for an AI glaucoma screening tool in the Changjiang county in China estimated that the fifteen-year accumulated incremental cost of using this tool was $434,903.20 for approximately 2000 patients (22). While the costs of this screening tool are arguably worth early detection and reduced disease progression, it may be impractical to roll out to larger populations. Health institutions in wealthy countries may easily make this investment. But what about institutions in developing countries? Community hospitals with limited government funding? Practices in rural areas with less purchasing power? Even if analyses demonstrate that costs are saved in the long run, the upfront investment may be too large an obstacle (16).Once a system is developed, purchased, and installed, maintenance becomes another issue.Software updates, advanced computing technologies, and ever-increasing cloud storage requirements add to costs (1). The evolving cybersecurity needs to protect patient health information may create further barriers to widespread application of AI (23). These all-around cost barriers are more nuanced than the mere ability to implement AI in practice. Inevitably, there are AI algorithms with higher and lower levels of sophistication, infrastructures that are more and less robust, and security measures that are stronger and weaker. The AI system that institutions choose will be closely tied to their financial status. Of course, AI development will then leave behind under-resourced communities.Currently, there is a lack of "explainable" AI regarding algorithms and data sets that play a role in decision making (24). In other words -exactly how do these technologies work? How are they making these decisions? These are questions that even developers themselves cannot answer; we know they work, yet nobody can fully explain how. This "black box" of AI holds important implications to healthcare disparities worldwide. Machine learning (ML) is a component of AI which involves automated decision making based on datasets (25). Detecting and correcting biases based on limited training sets is an ethical prerequisite of justice in AI-and ML-based clinical decision-making (20). In other words, explainable AI enables developers to identify and correct training set-based biases that currently skew algorithms (10,13).The discussion of justice behind explainable AI requires additional considerations. Explainable AI models keep model developers accountable for their work, as lack of accountability precedes error (24). This concern is compounded by the fact that patients who are less literate are less likely to ask questions or seek more information about their care (26). Since these patients may be less prepared to participate in shared decision making, they may not challenge questionable decisions (27).AI should be treated as a tool to support decision-making, not one to make decisions independently. For example, AI prescription systems have been developed to aid physician workflow and prevent human error (28,29). Inevitably, physicians will encounter scenarios in which the AI recommendation conflicts with their clinical judgement. Some of these scenarios may arise if AI systems are not trained on datasets that adequately represent the populations they treat, thereby generating recommendations poorly aligned with the realities of patients' needs (5). This challenge is particularly relevant to minority communities that have historically been under-studied (15). Healthcare providers should critically assess the AI recommendation in the context of their clinical experience and patient preferences. Institutions should establish clear policies on how to accept or reject AI suggestions to maintain quality patient care.Justice in explainable AI systems is important also in that more transparent technologies will foster patient trust in providers and the healthcare system. Unexplainable, opaque models, on the other hand, may exacerbate the mistrust that already pervades the healthcare system. This mistrust is particularly prevalent in socially and economically marginalized communities (30). A key component of trust in underprivileged populations is the patient's comfort with the physician and physicians' personal involvement in patient care (31). As such, we may see that the unexplainable black box of AI and ML -if not handled correctly -would certainly exacerbate these concerns. Lack of explanation for these impersonal, automated algorithms may further alienate this vulnerable population and widen health disparities.Even if we are to elucidate the black box, can AI ever replace the physician-patient relationship in delivering empathic care? Currently, it seems unlikely -one recent study demonstrated that healthcare chatbots delivering both empathetic and sympathetic responses to patients in fact lowered patients' perception of their authenticity (32). In contrast, empathy and sympathy expressed by human physicians did not induce this negative effect (32). This lack of perceived authenticity may not only undermine patients' subjective satisfaction with their AI providers but may also objectively worsen patient outcomes. While some AI tools provided sound biomedical recommendations for diabetes management, they overlooked psychosocial components that are also necessary for glycemic control (33). Algorithms that determine A1c goals, calculate medication dosages, and send prescriptions may certainly help optimize patient care. However, recommendations poorly tailored to psychosocial challenges disproportionately affect those with greater social barriers. Continuing the stand-alone case of diabetes, for example, significant social barriers to care include having the ability to afford healthy food, the free time for follow-up visits and the literacy to understand health information (34). Now combine this diabetes with a slew of other health conditions, medications, unemployment concerns and an ailing family member. Surely, physicians can manage this patient in countless different ways. There is no one correct path. Regardless, it is imperative that health providers -human or AI-based -address these concerns with compassion.Palliative care, which emphasizes relieving suffering and optimizing quality of life in end-oflife care, is a field in which compassion is key (35). While AI may help assist in decision-making, it risks depersonalizing cases and lacking empathy when patients and their families need it the most. Death and dying are often rooted in culture, personal beliefs, and spirituality. The experience is deeply personal and unique to each family (35). Whereas some encourage open communication about death, others feel uncomfortable with it; whereas some value life-prolonging measures regardless of prognosis, others less so (36). Palliative care AI models risk imposing a "one-size-fits-all" model of care based on aWestern training dataset (35). Once again, understudied populations and cultural minorities fall behind in AI's "understanding" -or lack thereof -of their values.Society at large, including regulators, policy makers, insurance companies, healthcare professionals and patients should carefully consider incorporating AI practices into the practice and business of medicine. Regulators have raised concerns over the need for regulation of clinical AI as well as generalizability to different populations (37). Another area of concern relevant to several stakeholders including healthcare providers and regulators is legal responsibility for AI clinical decision making (37). This fear exists for physicians in the scenario of a medical error made by AI and conversely for accusations of negligent care for not using AI. Physicians were neither prepared for nor agreed with assuming responsibility for errors made by AI, while AI developers believed they should not be liable since they do not practice medicine (37). Each side felt they only understood "part of the whole" when it comes to AI, further highlighting the need for explainable AI. Appropriate oversight by policy makers and regulators is needed to ensure accountability and promote development of explainable AI. These risks may be further mitigated by informing patients that AI was involved in decision making (38).Certain narratives have pitted AI as a rival to the skills and education of physicians, with claims that AI will one day replace physicians (38). AI remains solely a tool to assist in clinical setting with the final decision being made by a human. Rhetoric that continues to pit AI against physicians will only hinder the incorporation of AI into clinical practice (38). Patients will not benefit from AI replacing their physicians, but they also will not benefit from avoiding AI altogether.In discussing the role of AI in closing healthcare disparities, we must consider the role of AI in low-and middle-income countries (LMICs). In areas where medical resources and personnel are scarce, AI can reduce the workload on healthcare personnel (39). AI can also improve access to medical care, especially for areas where specialty care is not available (40). Disease outbreaks can be predicted earlier and allow for mobilization of treatment to affected areas. ML has been used to assess disease severity and predict treatment failure for illnesses such as malaria, tuberculosis and dengue fever (39). However, LMICs face significant challenges in implementing AI. The lack of electronic health records and health data is a limiting factor since this data is the primary input used in AI algorithms (40). Most AI systems are developed in high income countries (HICs) and the ML models reflect datasets from those populations. When applying these technologies to LMICs, models must be updated to reflect the population it is being applied to. Failure to do so can reinforce and exacerbate existing health disparities (40).Gaining both physician and patient trust in the integration of AI in healthcare remains a problem that needs to be addressed in the future. In a small study interviewing patients on their perspectives on AI in GP, subjects had mixed feelings on implementation of AI (41). A common concern amongst participants related to sharing of and access to their medical information (41). The patients wanted assurance that appropriate consent would be obtained prior to sharing of their data and that anonymization would be used. A survey of 203 participants on public opinion of AI in medicine also yielded mixed results, with a near 50/50 split when asked if they trust AI as a physician's tool for diagnosing medical conditions (42). In the same study, a majority of participants trusted a human physician over AI in making a culturally biased decision. There was a more positive outlook towards the future as over 25% of respondents believe AI will improve medical treatment in the next 10 years and nearly half of respondents for the next 50 years (42).Similarly, what AI lacks that physicians have is not intelligence, but rather wisdom -the sense of intuition that a human being can accumulate only over time (43). Can AI develop this intuition over time? Can an AI model mimic the human brain in synthesizing decades' worth of information to analyze a unique case and provide appropriate medical decision making? For simple cases, it likely can. But complex cases are a different story -risks and benefits of intervention must be weighed and complications must be predicted, all while delivering this information to the patient in an easilydigestible manner. Yet another layer of nuance is added when shared-decision making is introducednow, AI must understand patients' desires and uncertainties on a human level and incorporate that into its recommendations. Moreover, patients believe their physician should remain the primary decision maker, with AI can be used as a support tool (41). The use of AI in this setting may decrease time physicians spend on mundane tasks and leave more time for physicians to have meaningful conversations with their patients, facilitating the delivery of compassionate care (37,44). Once again, compassion and trust are key components to patient care for all patients alike.While AI has the potential to increase access to care for vulnerable populations and help bridge gaps in healthcare, we must ensure that data and algorithms are inclusive of patients to avoid worsening existing disparities. The healthcare system hinges on trust to maintain patient confidentiality, recommend the optimal course of action, and execute the plan appropriately. Particularly in marginalized communities, the critical process of building and maintaining this trust has proved difficult even in the absence of AI and continues to pose a significant obstacle in the success of AI to improve healthcare delivery. Both physicians and patients alike do not wish to see AI replace the standard physician-patient interaction. Instead, AI can serve as an adjunct to improve quality of care by reducing the chance of human error. Collaboration among patients, physicians, and AI developers is essential to achieve this goal in an equitable manner.},
  archive      = {J_FRAI},
  author       = {Li, Deborah M. and Parikh, Shruti and Costa, Ana},
  doi          = {10.3389/frai.2025.1545869},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1545869},
  shortjournal = {Front. Artif. Intell.},
  title        = {A critical look into artificial intelligence and healthcare disparities},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traditional vs. AI-generated meteorological risks for emergency predictions. <em>FRAI</em>, <em>8</em>, 1545851. (<a href='https://doi.org/10.3389/frai.2025.1545851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Sirri, Naoufal and Guyeux, Christophe},
  doi          = {10.3389/frai.2025.1545851},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1545851},
  shortjournal = {Front. Artif. Intell.},
  title        = {Traditional vs. AI-generated meteorological risks for emergency predictions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Internet of things driven hybrid neuro-fuzzy deep learning building energy management system for cost and schedule optimization. <em>FRAI</em>, <em>8</em>, 1544183. (<a href='https://doi.org/10.3389/frai.2025.1544183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Shrivastava, Deepshikha and Goswami, Prerna},
  doi          = {10.3389/frai.2025.1544183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1544183},
  shortjournal = {Front. Artif. Intell.},
  title        = {Internet of things driven hybrid neuro-fuzzy deep learning building energy management system for cost and schedule optimization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InGSA: Integrating generalized self-attention in CNN for alzheimer's disease classification. <em>FRAI</em>, <em>8</em>, 1540646. (<a href='https://doi.org/10.3389/frai.2025.1540646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Binzagr, Faisal and Abulfaraj, Anas W.},
  doi          = {10.3389/frai.2025.1540646},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1540646},
  shortjournal = {Front. Artif. Intell.},
  title        = {InGSA: Integrating generalized self-attention in CNN for alzheimer's disease classification},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented intelligence with voice assistance and automated machine learning in industry 5.0. <em>FRAI</em>, <em>8</em>, 1538840. (<a href='https://doi.org/10.3389/frai.2025.1538840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bousdekis, Alexandros and Foosherian, Mina and Fikardos, Mattheos and Wellsandt, Stefan and Lepenioti, Katerina and Bosani, Enrica and Mentzas, Gregoris and Thoben, Klaus-Dieter},
  doi          = {10.3389/frai.2025.1538840},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1538840},
  shortjournal = {Front. Artif. Intell.},
  title        = {Augmented intelligence with voice assistance and automated machine learning in industry 5.0},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern recognition in SARS cases: Insights from t-SNE and k-means clustering applied to COVID-19 symptomatology. <em>FRAI</em>, <em>8</em>, 1536486. (<a href='https://doi.org/10.3389/frai.2025.1536486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Marques, Julliana Gonçalves and Carvalho, Bruno Motta de and Guedes, Luiz Affonso and Costa-Abreu, Márjory Da},
  doi          = {10.3389/frai.2025.1536486},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1536486},
  shortjournal = {Front. Artif. Intell.},
  title        = {Pattern recognition in SARS cases: Insights from t-SNE and k-means clustering applied to COVID-19 symptomatology},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for steganalysis: Evaluating model robustness against image transformations. <em>FRAI</em>, <em>8</em>, 1532895. (<a href='https://doi.org/10.3389/frai.2025.1532895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Alrusaini, Othman A.},
  doi          = {10.3389/frai.2025.1532895},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1532895},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning for steganalysis: Evaluating model robustness against image transformations},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing an inverse modeling approach with gradient boosting regression for stroke volume estimation using patient thermodilution data. <em>FRAI</em>, <em>8</em>, 1530453. (<a href='https://doi.org/10.3389/frai.2025.1530453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bikia, Vasiliki (Vicky) and Adamopoulos, Dionysios and Roffi, Marco and Rovas, Georgios and Noble, Stéphane and Mach, François and Stergiopulos, Nikolaos},
  doi          = {10.3389/frai.2025.1530453},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1530453},
  shortjournal = {Front. Artif. Intell.},
  title        = {Testing an inverse modeling approach with gradient boosting regression for stroke volume estimation using patient thermodilution data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmentation via diffusion model to enhance AI fairness. <em>FRAI</em>, <em>8</em>, 1530397. (<a href='https://doi.org/10.3389/frai.2025.1530397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hastings Blow, Christina and Qian, Lijun and Gibson, Camille and Obiomon, Pamela and Dong, Xishuang},
  doi          = {10.3389/frai.2025.1530397},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1530397},
  shortjournal = {Front. Artif. Intell.},
  title        = {Data augmentation via diffusion model to enhance AI fairness},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SciLinker: A large-scale text mining framework for mapping associations among biological entities. <em>FRAI</em>, <em>8</em>, 1528562. (<a href='https://doi.org/10.3389/frai.2025.1528562'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Liu, Dongyu and Ames, Cora and Khader, Shameer and Rapaport, Franck},
  doi          = {10.3389/frai.2025.1528562},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1528562},
  shortjournal = {Front. Artif. Intell.},
  title        = {SciLinker: A large-scale text mining framework for mapping associations among biological entities},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applied machine learning in intelligent systems: Knowledge graph-enhanced ophthalmic contrastive learning with “clinical profile” prompts. <em>FRAI</em>, <em>8</em>, 1527010. (<a href='https://doi.org/10.3389/frai.2025.1527010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Han Wang, Mini and Cui, Jiazheng and Lee, Simon Ming-Yuen and Lin, Zhiyuan and Zeng, Peijin and Li, Xinyue and Liu, Haoyang and Liu, Yunxiao and Xu, Yang and Wang, Yapeng and Alves, José Lopes Camilo Da Costa and Hou, Guanghui and Fang, Junbin and Yu, Xiangrong and Chong, Kelvin Kam-Lung and Pan, Yi},
  doi          = {10.3389/frai.2025.1527010},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1527010},
  shortjournal = {Front. Artif. Intell.},
  title        = {Applied machine learning in intelligent systems: Knowledge graph-enhanced ophthalmic contrastive learning with “clinical profile” prompts},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact on bias mitigation algorithms to variations in inferred sensitive attribute uncertainty. <em>FRAI</em>, <em>8</em>, 1520330. (<a href='https://doi.org/10.3389/frai.2025.1520330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wang, Yanchen and Singh, Lisa},
  doi          = {10.3389/frai.2025.1520330},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1520330},
  shortjournal = {Front. Artif. Intell.},
  title        = {Impact on bias mitigation algorithms to variations in inferred sensitive attribute uncertainty},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of the accuracy of GPT-4 and resident physicians in differentiating benign and malignant thyroid nodules. <em>FRAI</em>, <em>8</em>, 1512438. (<a href='https://doi.org/10.3389/frai.2025.1512438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wei, Boxiong and Zhang, Xiumei and Shao, Yuhong and Sun, Xiuming and Chen, Luzeng},
  doi          = {10.3389/frai.2025.1512438},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1512438},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparison of the accuracy of GPT-4 and resident physicians in differentiating benign and malignant thyroid nodules},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMaze: An intuitive benchmark generator for fast prototyping of generalizable agents. <em>FRAI</em>, <em>8</em>, 1511712. (<a href='https://doi.org/10.3389/frai.2025.1511712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Godin-Dubois, Kevin and Miras, Karine and Kononova, Anna V.},
  doi          = {10.3389/frai.2025.1511712},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1511712},
  shortjournal = {Front. Artif. Intell.},
  title        = {AMaze: An intuitive benchmark generator for fast prototyping of generalizable agents},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoSViT: A lightweight vision transformer framework for efficient disease detection via precision attention mechanism. <em>FRAI</em>, <em>8</em>, 1498025. (<a href='https://doi.org/10.3389/frai.2025.1498025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Chen, Yuanqi and Wang, Aiping and Liu, Ziyang and Yue, Jie and Zhang, Enxu and Li, Fei and Zhang, Ning},
  doi          = {10.3389/frai.2025.1498025},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1498025},
  shortjournal = {Front. Artif. Intell.},
  title        = {MoSViT: A lightweight vision transformer framework for efficient disease detection via precision attention mechanism},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning analysis of exercise stress electrocardiography for identification of significant coronary artery disease. <em>FRAI</em>, <em>8</em>, 1496109. (<a href='https://doi.org/10.3389/frai.2025.1496109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Liang, Hsin-Yueh and Hsu, Kai-Cheng and Chien, Shang-Yu and Yeh, Chen-Yu and Sun, Ting-Hsuan and Liu, Meng-Hsuan and Ng, Kee Koon},
  doi          = {10.3389/frai.2025.1496109},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1496109},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning analysis of exercise stress electrocardiography for identification of significant coronary artery disease},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code generation system based on MDA and convolutional neural networks. <em>FRAI</em>, <em>8</em>, 1491958. (<a href='https://doi.org/10.3389/frai.2025.1491958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Vargas-Monroy, Gabriel and Gonzalez-Roldan, Daissi-Bibiana and Montenegro-Marín, Carlos Enrique and Daza-Corredor, Alejandro-Paolo and Leal-Lara, Daniel-David},
  doi          = {10.3389/frai.2025.1491958},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1491958},
  shortjournal = {Front. Artif. Intell.},
  title        = {Code generation system based on MDA and convolutional neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM services in the management of social communications. <em>FRAI</em>, <em>8</em>, 1474017. (<a href='https://doi.org/10.3389/frai.2025.1474017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Dyachenko, Yuriy and Humenna, Oleksandra and Soloviov, Oleg and Skarga-Bandurova, Inna and Nenkov, Nayden},
  doi          = {10.3389/frai.2025.1474017},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1474017},
  shortjournal = {Front. Artif. Intell.},
  title        = {LLM services in the management of social communications},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-stage registration pipeline for dynamic lung field of chest X-ray images based on convolutional neural networks. <em>FRAI</em>, <em>8</em>, 1466643. (<a href='https://doi.org/10.3389/frai.2025.1466643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yang, Yingjian and Zheng, Jie and Guo, Peng and Gao, Qi and Guo, Yingwei and Chen, Ziran and Liu, Chengcheng and Wu, Tianqi and Ouyang, Zhanglei and Chen, Huai and Kang, Yan},
  doi          = {10.3389/frai.2025.1466643},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1466643},
  shortjournal = {Front. Artif. Intell.},
  title        = {Three-stage registration pipeline for dynamic lung field of chest X-ray images based on convolutional neural networks},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mind the semantic gap: Semantic efficiency in human computer interfaces. <em>FRAI</em>, <em>8</em>, 1451865. (<a href='https://doi.org/10.3389/frai.2025.1451865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Horsley, James},
  doi          = {10.3389/frai.2025.1451865},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1451865},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mind the semantic gap: Semantic efficiency in human computer interfaces},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adapting emotional support in teams: Productivity, emotional stability, and conscientiousness. <em>FRAI</em>, <em>8</em>, 1449176. (<a href='https://doi.org/10.3389/frai.2025.1449176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Saccardi, Isabella and Masthoff, Judith},
  doi          = {10.3389/frai.2025.1449176},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1449176},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adapting emotional support in teams: Productivity, emotional stability, and conscientiousness},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of machine learning algorithms to predict viral load suppression among HIV patients in conakry (Guinea). <em>FRAI</em>, <em>8</em>, 1446876. (<a href='https://doi.org/10.3389/frai.2025.1446876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yehadji, Degninou and Gray, Geraldine and Vicente, Carlos Arias and Isaakidis, Petros and Diallo, Abdourahimi and Kamano, Saa Andre and Diallo, Thierno Saidou},
  doi          = {10.3389/frai.2025.1446876},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1446876},
  shortjournal = {Front. Artif. Intell.},
  title        = {Development of machine learning algorithms to predict viral load suppression among HIV patients in conakry (Guinea)},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing handwriting legibility through hand kinematics. <em>FRAI</em>, <em>8</em>, 1426455. (<a href='https://doi.org/10.3389/frai.2025.1426455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Babushkin, Vahan and Alsuradi, Haneen and Al-Khalil, Muhamed Osman and Eid, Mohamad},
  doi          = {10.3389/frai.2025.1426455},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {1426455},
  shortjournal = {Front. Artif. Intell.},
  title        = {Analyzing handwriting legibility through hand kinematics},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General SIR model for visible and hidden epidemic dynamics. <em>FRAI</em>, <em>8</em>, 1559880. (<a href='https://doi.org/10.3389/frai.2025.1559880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Nesteruk, Igor},
  doi          = {10.3389/frai.2025.1559880},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1559880},
  shortjournal = {Front. Artif. Intell.},
  title        = {General SIR model for visible and hidden epidemic dynamics},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting therapy dropout in chronic pain management: A machine learning approach to cannabis treatment. <em>FRAI</em>, <em>8</em>, 1557894. (<a href='https://doi.org/10.3389/frai.2025.1557894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Visibelli, Anna and Finetti, Rebecca and Roncaglia, Bianca and Poli, Paolo and Spiga, Ottavia and Santucci, Annalisa},
  doi          = {10.3389/frai.2025.1557894},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1557894},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting therapy dropout in chronic pain management: A machine learning approach to cannabis treatment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Role of artificial intelligence in smart grid – A mini review. <em>FRAI</em>, <em>8</em>, 1551661. (<a href='https://doi.org/10.3389/frai.2025.1551661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Balamurugan, M. and Narayanan, Kamala and Raghu, N. and Arjun Kumar, G. B. and Trupti, V. N.},
  doi          = {10.3389/frai.2025.1551661},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1551661},
  shortjournal = {Front. Artif. Intell.},
  title        = {Role of artificial intelligence in smart grid – A mini review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models generating synthetic clinical datasets: A feasibility and comparative analysis with real-world perioperative data. <em>FRAI</em>, <em>8</em>, 1533508. (<a href='https://doi.org/10.3389/frai.2025.1533508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Barr, Austin A. and Quan, Joshua and Guo, Eddie and Sezgin, Emre},
  doi          = {10.3389/frai.2025.1533508},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1533508},
  shortjournal = {Front. Artif. Intell.},
  title        = {Large language models generating synthetic clinical datasets: A feasibility and comparative analysis with real-world perioperative data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to indian bird species identification: Employing visual-acoustic fusion techniques for improved classification accuracy. <em>FRAI</em>, <em>8</em>, 1527299. (<a href='https://doi.org/10.3389/frai.2025.1527299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Gavali, Pralhad and Banu, J. Saira},
  doi          = {10.3389/frai.2025.1527299},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1527299},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel approach to indian bird species identification: Employing visual-acoustic fusion techniques for improved classification accuracy},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hype-adjusted probability measure for NLP stock return forecasting. <em>FRAI</em>, <em>8</em>, 1527180. (<a href='https://doi.org/10.3389/frai.2025.1527180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Cao, Zheng and Geman, Helyette},
  doi          = {10.3389/frai.2025.1527180},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1527180},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hype-adjusted probability measure for NLP stock return forecasting},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XAI-MRI: An ensemble dual-modality approach for 3D brain tumor segmentation using magnetic resonance imaging. <em>FRAI</em>, <em>8</em>, 1525240. (<a href='https://doi.org/10.3389/frai.2025.1525240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Farhan, Ahmeed Suliman and Khalid, Muhammad and Manzoor, Umar},
  doi          = {10.3389/frai.2025.1525240},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1525240},
  shortjournal = {Front. Artif. Intell.},
  title        = {XAI-MRI: An ensemble dual-modality approach for 3D brain tumor segmentation using magnetic resonance imaging},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neuro-fuzzy inference system guided objective function parameter optimization for inverse treatment planning. <em>FRAI</em>, <em>8</em>, 1523390. (<a href='https://doi.org/10.3389/frai.2025.1523390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Cisternas Jiménez, Eduardo and Yin, Fang-Fang},
  doi          = {10.3389/frai.2025.1523390},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1523390},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptive neuro-fuzzy inference system guided objective function parameter optimization for inverse treatment planning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determining the meter of classical arabic poetry using deep learning: A performance analysis. <em>FRAI</em>, <em>8</em>, 1523336. (<a href='https://doi.org/10.3389/frai.2025.1523336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mutawa, A. M. and Alrumaih, Ayshah},
  doi          = {10.3389/frai.2025.1523336},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1523336},
  shortjournal = {Front. Artif. Intell.},
  title        = {Determining the meter of classical arabic poetry using deep learning: A performance analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spherical model for minimalist machine learning paradigm in handling complex databases. <em>FRAI</em>, <em>8</em>, 1521063. (<a href='https://doi.org/10.3389/frai.2025.1521063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Jimenez-Cruz, Raúl and Yáñez-Márquez, Cornelio and Gonzalez-Mendoza, Miguel and Villuendas-Rey, Yenni and Monroy, Raúl},
  doi          = {10.3389/frai.2025.1521063},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1521063},
  shortjournal = {Front. Artif. Intell.},
  title        = {Spherical model for minimalist machine learning paradigm in handling complex databases},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating generative adversarial networks with IoT for adaptive AI-powered personalized elderly care in smart homes. <em>FRAI</em>, <em>8</em>, 1520592. (<a href='https://doi.org/10.3389/frai.2025.1520592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Naseer, Fawad and Addas, Abdullah and Tahir, Muhammad and Khan, Muhammad Nasir and Sattar, Noreen},
  doi          = {10.3389/frai.2025.1520592},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1520592},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrating generative adversarial networks with IoT for adaptive AI-powered personalized elderly care in smart homes},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced driving assistance integration in electric motorcycles: Road surface classification with a focus on gravel detection using deep learning. <em>FRAI</em>, <em>8</em>, 1520557. (<a href='https://doi.org/10.3389/frai.2025.1520557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Venancio, Ranan and Filipe, Vitor and Cerveira, Adelaide and Gonçalves, Lio},
  doi          = {10.3389/frai.2025.1520557},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1520557},
  shortjournal = {Front. Artif. Intell.},
  title        = {Advanced driving assistance integration in electric motorcycles: Road surface classification with a focus on gravel detection using deep learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontology-based prompt tuning for news article summarization. <em>FRAI</em>, <em>8</em>, 1520144. (<a href='https://doi.org/10.3389/frai.2025.1520144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Silva, A. R. S. and Priyadarshana, Y. H. P. P.},
  doi          = {10.3389/frai.2025.1520144},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1520144},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ontology-based prompt tuning for news article summarization},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing accuracy and user satisfaction: The role of prompt engineering in AI-driven healthcare solutions. <em>FRAI</em>, <em>8</em>, 1517918. (<a href='https://doi.org/10.3389/frai.2025.1517918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wang, Mini Han and Jiang, Xudong and Zeng, Peijin and Li, Xinyue and Chong, Kelvin Kam-Lung and Hou, Guanghui and Fang, Xiaoxiao and Yu, Yang and Yu, Xiangrong and Fang, Junbin and Pan, Yi},
  doi          = {10.3389/frai.2025.1517918},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1517918},
  shortjournal = {Front. Artif. Intell.},
  title        = {Balancing accuracy and user satisfaction: The role of prompt engineering in AI-driven healthcare solutions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Targeted generative data augmentation for automatic metastases detection from free-text radiology reports. <em>FRAI</em>, <em>8</em>, 1513674. (<a href='https://doi.org/10.3389/frai.2025.1513674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ashofteh Barabadi, Maede and Zhu, Xiaodan and Chan, Wai Yip and Simpson, Amber L. and Do, Richard K. G.},
  doi          = {10.3389/frai.2025.1513674},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1513674},
  shortjournal = {Front. Artif. Intell.},
  title        = {Targeted generative data augmentation for automatic metastases detection from free-text radiology reports},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clinical validation of an artificial intelligence algorithm for classifying tuberculosis and pulmonary findings in chest radiographs. <em>FRAI</em>, <em>8</em>, 1512910. (<a href='https://doi.org/10.3389/frai.2025.1512910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {de Camargo, Thiago Fellipe Ortiz and Ribeiro, Guilherme Alberto Sousa and da Silva, Maria Carolina Bueno and da Silva, Luan Oliveira and Torres, Pedro Paulo Teixeira e Silva and Rodrigues, Denise do Socorro da Silva and de Santos, Mayler Olombrada Nunes and Filho, William Salibe and Rosa, Marcela Emer Egypto and Novaes, Magdala de Araujo and Massarutto, Thiago Augusto and Junior, Osvaldo Landi and Yanata, Elaine and Reis, Marcio Rodrigues da Cunha and Szarf, Gilberto and Netto, Pedro Vieira Santana and de Paiva, Joselisa Peres Queiroz},
  doi          = {10.3389/frai.2025.1512910},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1512910},
  shortjournal = {Front. Artif. Intell.},
  title        = {Clinical validation of an artificial intelligence algorithm for classifying tuberculosis and pulmonary findings in chest radiographs},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of 3D and 2D area measurement of acute burn wounds with LiDAR technique and deep learning model. <em>FRAI</em>, <em>8</em>, 1510905. (<a href='https://doi.org/10.3389/frai.2025.1510905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Chang, Che Wei and Wang, Hanwei and Lai, Feipei and Christian, Mesakh and Chen Huang, Shih and Yi Tsai, Han},
  doi          = {10.3389/frai.2025.1510905},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1510905},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparison of 3D and 2D area measurement of acute burn wounds with LiDAR technique and deep learning model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning for predicting of gross domestic product growth based on remittance inflows using RNN-LSTM hybrid model: A case study of the gambia. <em>FRAI</em>, <em>8</em>, 1510341. (<a href='https://doi.org/10.3389/frai.2025.1510341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Jallow, Haruna and Mwangi, Ronald Waweru and Gibba, Alieu and Imboga, Herbert},
  doi          = {10.3389/frai.2025.1510341},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1510341},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transfer learning for predicting of gross domestic product growth based on remittance inflows using RNN-LSTM hybrid model: A case study of the gambia},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge computing for detection of ship and ship port from remote sensing images using YOLO. <em>FRAI</em>, <em>8</em>, 1508664. (<a href='https://doi.org/10.3389/frai.2025.1508664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Sanikommu, Vasavi and Marripudi, Sai Pravallika and Yekkanti, Harini Reddy and Divi, Revanth and Chandrakanth, R. and Mahindra, P.},
  doi          = {10.3389/frai.2025.1508664},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1508664},
  shortjournal = {Front. Artif. Intell.},
  title        = {Edge computing for detection of ship and ship port from remote sensing images using YOLO},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAD-onto: An ontology design for mobile app development. <em>FRAI</em>, <em>8</em>, 1508225. (<a href='https://doi.org/10.3389/frai.2025.1508225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Abu-Salih, Bilal and Al-Tawil, Marwan and Khoury, Ansar and Al-Qudah, Dana A. and Abu Zaid, Isra’a and Alabdale, Marwa and Azar, Dima},
  doi          = {10.3389/frai.2025.1508225},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1508225},
  shortjournal = {Front. Artif. Intell.},
  title        = {MAD-onto: An ontology design for mobile app development},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual feature-based and example-based explanation methods. <em>FRAI</em>, <em>8</em>, 1506074. (<a href='https://doi.org/10.3389/frai.2025.1506074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Konstantinov, Andrei and Kozlov, Boris and Kirpichenko, Stanislav and Utkin, Lev and Muliukha, Vladimir},
  doi          = {10.3389/frai.2025.1506074},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1506074},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dual feature-based and example-based explanation methods},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning-based hybrid VGG16-machine learning approach for heart disease detection with explainable artificial intelligence. <em>FRAI</em>, <em>8</em>, 1504281. (<a href='https://doi.org/10.3389/frai.2025.1504281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Addisu, Eshetie Gizachew and Yirga, Tahayu Gizachew and Yirga, Hailu Gizachew and Yehuala, Alemu Demeke},
  doi          = {10.3389/frai.2025.1504281},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1504281},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transfer learning-based hybrid VGG16-machine learning approach for heart disease detection with explainable artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconstructing signal during brain stimulation with stim-BERT: A self-supervised learning model trained on millions of iEEG files. <em>FRAI</em>, <em>8</em>, 1502504. (<a href='https://doi.org/10.3389/frai.2025.1502504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Menon, Karthik and Tcheng, Thomas and Seale, Cairn and Greene, David and Morrell, Martha and Desai, Sharanya Arcot},
  doi          = {10.3389/frai.2025.1502504},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1502504},
  shortjournal = {Front. Artif. Intell.},
  title        = {Reconstructing signal during brain stimulation with stim-BERT: A self-supervised learning model trained on millions of iEEG files},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced vehicle routing for medical waste management via hybrid deep reinforcement learning and optimization algorithms. <em>FRAI</em>, <em>8</em>, 1496653. (<a href='https://doi.org/10.3389/frai.2025.1496653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Khallaf, Norhan and Abd-El Rouf, Osama and Algarni, Abeer D. and Hadhoud, Mohy and Kafafy, Ahmed},
  doi          = {10.3389/frai.2025.1496653},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1496653},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhanced vehicle routing for medical waste management via hybrid deep reinforcement learning and optimization algorithms},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI, universal basic income, and power: Symbolic violence in the tech elite's narrative. <em>FRAI</em>, <em>8</em>, 1488457. (<a href='https://doi.org/10.3389/frai.2025.1488457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the concept of universal basic income (UBI) has gained significant attention, not from grassroots community organizations traditionally associated with social welfare advocacy (Jarow, 2023), but from some of the most powerful figures in the technology sector-AI tycoons elites (Shead, 2021). Prominent advocates like Elon Musk and Sam Altman argue that UBI is necessary to address the economic disruptions caused by artificial intelligence (AI) and automation (Crumley, 2024). They present UBI as a way to ensure that the benefits of AI are distributed across society, not just concentrated in the hands of a few. However, this seemingly benevolent narrative camouflages a deeper agenda: to seek out a social license to gain public acceptance for the omnipresence of AI in society, and the will to control under the guise of universal benefit.While economic, social, and normative analyses have been put forward in articles in Frontiers in Artificial Intelligence (Ernst, 2022;Huo et al., 2024;Merola, 2022), two key dimensions that remain underexplored in the UBI discussion are 1) the utilitarian calculation behind the AI-justified UBI narrative;, and 2) the associated concept of symbolic violence, as articulated by sociologist Pierre Bourdieu. I argue that UBI, while ostensibly a tool for social good, can may end up justifying even greater disparities in wealth and may entrench symbolic violence by reinforcing divisions between AI owners, those skilled or capacitated in using AI, and those who are merely recipients of its "benefits." This symbolic violence is particularly perverse as it perpetuates a narrative of AI as universally beneficial, when in reality, it risks exacerbating socio-economic inequalities and creating profound epistemic and symbolic injustices.The advocacy for UBI by AI tycoons elites is a relatively new phenomenon. Figures like Elon Musk, the CEO of Tesla, SpaceX, and X, and Sam Altman, the CEO of OpenAI, have positioned themselves as champions of UBI. Musk (2024) recently indicated about the rise of AI that "In a benign scenario, probably none of us will have a job. There would be universal high income. There would be no shortage of goods and services. The question will really be one of meaning: if a computer can do, and the robots can do, everything better than you, does your life have meaning? I do think there's perhaps still a role for humans in that we may give AI meaning." For his part, Altman (2016) indicated that "[he's] fairly confident that at some point in the future, as technology continues to eliminate traditional jobs and massive new wealth gets created, we're going to see some version of this at a national scale." AI Tycoons elites argue that as AI and automation increasingly replace human labor, UBI will be essential to prevent widespread economic dislocation and social unrest. This argument may be compelling, especially in a world where technological advancements threaten to render large segments of the workforce obsolete (Islam, 2024). However, the promotion of UBI by these tech magnates is not simply a philanthropic gesture; it is deeply intertwined with their interests in the expansion and dominance of AI technologies. Crane et al (2019) argue that corporate strategies often align with maintaining and enhancing power structures that benefit corporate elites. The advocacy for UBI by AI leaders can be seen as a strategic move to preemptively address potential backlash against AI-induced risk and negative externalities, such as job losses or job polarization (i.e., reducing middle wages, shifting demand towards low and high wages, see Goos and Savona (2024)), thereby securing a favorable business environment for continued AI development and deployment.Without going so far as to say that AI may be an existential risk (or X-Risk, a risk to the very viability of humanity)-as other movements such as the members of the effective altruism movement and the associated cause of longtermism may do (Jecker et al., 2024)-AI may pose significant economic and social risks if job losses are not offset. The narrative presented by these AI leaders suggests that UBI is a necessary adaptation to the inevitable rise of AI-a tool to ensure that everyone benefits from technological progress. Yet, this narrative serves to legitimize and reinforce the power dynamics that already exist in the AI industry. By advocating for UBI, these tycoons AI elites position themselves as benevolent visionaries who are concerned about the well-being of humanity. However, as Sadowski (2016) argues, promoting UBI can be a strategic way for AI elites to deflect criticism, maintaining control over narratives about AI's future while avoiding challenges to their profit motives. This framing distracts from the fact that the same individuals who are pushing for UBI are also those who stand to gain the most from the proliferation of AI technologies (Spencer, 2024). Bourdieu's concept of symbolic violence offers valuable insight into the deeper implications of UBI in the context of AI; however, it is important first to examine UBI from its utilitarian foundation.It is here that Bourdieu's concept of symbolic violence becomes crucial for understanding the true implications of UBI in the age of AI.This narrative aligns with a utilitarian view for assessing the benefits and risks of AI in society. AI tycoons elites apply a utilitarian calculation , evaluating the moral justification of replacing humans with AIs by weighing the potential to maximize societal well-being against the associated harms. From this eudemonic standpoint-focused on balancing well-being and harm, or even more simply pleasures and pains-they envision a future where AI's dominance across human-dominated fields leads to a society characterized by widespread leisure and, for some, heightened performance. In their view, this transformation is morally defensible if measures (such as UBI) are implemented to mitigate the negative effects and ensure distribution of certain benefits for allas they cast the replacing humans with AIs from a eudemonic standpoint (i.e., weighing up pleasures and pains). This allows them to arrive at a vision of the world where, despite AI's pervasive advances in fields dominated by humans, considering that this will result in a society of leisure (and, for a minority, of performance), then the calculation is worth the candle if subsidies (in the form of UBI) can be distributed to all. UBI is thus used to justify the possibility, and to demonstrate, that AI can provide for humanity's basic needs, while at the same time justifying that some can be ultra-wealthy and possess these technological tools of humanity's (apparent) sustenance (Islam, 2024). While it has not been directly invoked up to now, this is a curious application of John Rawls' principle of difference, which in his "Theory of Justice" states that social and economic inequalities are to be arranged so that they are to the greatest benefit of the least advantaged members of society, consistent with the just savings principle and the principle of fair equality of opportunity (Rawls, 1971). Arguably, providing UBI to all does not solve everything; it creates more equality amongst the less well-off, without acting to address inequalities and wealth gaps. Yes, this would be a first for humanity-an economic safe net from which all could benefit (which appears to be of a fixedbenefit nature, with no indication of adjustment to economic trends)-but this cannot justify the kind of leanness in which it seems to place the non-owners of AI (i.e., virtually the entire world population) compared to the AI tycoonselites. It is hard to make a convincing utilitarian claim that this is for the benefit of the less well-off. Furthermore, as Sen (2009) argues, a focus on utility maximization may neglect the distribution of capabilities and freedoms, which are essential for genuine social justice; something very plausible if like Musk (2024) is thinking that if "[computers and robots can be doing] everything better than [humans], does [human] life have meaning?" With AI potentially representing a X-risk (Jecker et al., 2024) or at the very least risking to lead to a "a shift in power towards actors with the capital and authority to deploy powerful AI systems, such as elites, corporations, and governments" (Dafoe, 2018), it is very unclear that AI will actually maximize utility and be for everyone's benefits.Unfortunately for AI-justified UBI proponents, a study funded by Altman has found that UBI is not a comprehensive solution to the economic challenges posed by AI-driven job loss (Ropek, 2024). The research, conducted by OpenResearch (2024) between 2020 and 2023, provided $1,000 a month to 1,000 low-income individuals, with a control group receiving $50 monthly. While UBI helped participants cover essential expenses like housing and groceries, it did not lead to significant improvements in employment quality, education, or overall health. The study concluded that while UBI can alleviate some immediate financial stress, it falls short of addressing deeper systemic issues such as healthcare access, job stability, and upward mobility. Thus, UBI alone is unlikely to mitigate the broader economic impacts of AI on the workforce. So, unfortunately, proponents' utilitarian calculation does not seem to be working as well as they would like. As a result, the impetus for supporting UBI seems more ideological and self-serving than beneficial.Here, Pierre Bourdieu's concept of "violence symbolique" can help deceive that AI elites' benevolent narrative. Symbolic violence, as this refers to a form of domination that is subtle and often imperceptible, yet profoundly effective in maintaining social hierarchies (Bourdieu & Wacquant, 1992). Symbolic violence operates through the imposition of meanings that are accepted as legitimate, even by those who are subordinated by them (Bourdieu, 1993). This form of violence is not physical, but it is deeply embedded in the social structures and cultural norms that shape our understanding of the world. With society's increased digitalization, Couldry and Mejias (2020) denote how data practices can constitute a new form of colonialism, reinforcing existing power structures through symbolic means. It is throughSuch symbolic violence that allows dominant groups can perpetuate their power without overt coercion, by making their worldview appear natural and inevitable.In the context of UBI and AI, symbolic violence manifests in the way that the narrative of AI, as a universal good, is constructed and disseminated. The AI tycoons' elites' promotion of UBI suggests that the best way to address the disruptions caused by AI is to provide people with a guaranteed basic income, thereby ensuring that everyone benefits from technological progress. However, this narrative obscures the deeper structural inequalities that are being reinforced by the same technologies that UBI is supposed to mitigate. Symbolic violence, Bourdieu and Wacquant (1992, p. 172) notes, "accomplishes itself through an act of cognition and of misrecognition that lies beyond-or beneath-the controls of consciousness and will." In the case of AI-justified UBI, public's acceptance of this proposal as a universal good would be a form of misrecognition that a symbolic violence is being perpetrated and instead considering that AI and UBI is are something normal and rather logical natural within the existing social order. This Such acceptance would be a legitimization of the power of the AI elite by presenting them UBI as the solution to the very problems their technologies create, thus reinforcing the existing social order.UBI, as promoted by AI tycoonselites, can be seen as a tool of symbolic violence in several ways. First, it reinforces the division between those who own and control AI technologies and those who are merely consumers of its benefits. The owners of AI-who are also the primary advocates of UBI-are positioned as the benevolent providers of a safety net for the masses. Meanwhile, the recipients of UBI are cast as passive beneficiaries of a system that they have little control over. This dynamic perpetuates the power of the AI elite, while simultaneously legitimizing their dominance by presenting them as the solution to the very problems that their technologies create.Moreover, UBI as a form of symbolic violence operates by masking the true nature of the inequalities that it purportedly seeks to address. By providing a basic income, the narrative suggests that the economic and social disruptions caused by AI can be managed and mitigated. However, this narrative ignores the fact that UBI does nothing to address the underlying power imbalances that give rise to these disruptions in the first place. Critics argue that UBI, without accompanying structural reforms, may fail to address underlying inequalities (Parijs & Vanderborght, 2017), just like the OpenResearch study hinted. As Jarow (2024) puts it, "hitching the case for basic income to fears of rapid AI progress makes it far more vulnerable than it needs to be." By linking UBI to AI, its advocates risk creating a policy that merely manages the symptoms of economic inequality without addressing the root causes. This approach perpetuates a superficial solution that maintains the status quo, allowing the AI elite to continue accumulating wealth and power while the majority remains dependent on the systems that marginalize them.The symbolic violence inherent in the promotion of UBI by AI tycoons elites is particularly perverse because it creates the illusion of inclusivity and fairness; (in an interesting way, values that are quite central to AI ethics (Victor et al., 2024)). The narrative of UBI as a universal good suggests that everyone stands to gain from the increased presence of AI in our societies. However, this narrative obscures the fact that the benefits of AI are not distributed equally, and that UBI, as currently envisioned, may actually entrench existing inequalities rather than alleviate them. By framing UBI as a necessary response to AI-induced unemployment, the AI tycoons elites are effectively shifting the focus away from the need for more equitable distribution of power and resources. The symbolic violence here lies in the way that UBI is presented as a panacea for the problems caused by AI, when in reality, it serves to reinforce the existing social order. Those who control AI technologies continue to benefit disproportionately, while those who are displaced dispossessed by these technologies are offered only a minimal safety net in return.Moreover, this symbolic violence has epistemic implications (Bourdieu, 1993), as it shapes our understanding of what is possible and desirable in a world increasingly dominated by AI. Musk (2016), almost a decade ago, said that "There's a pretty good chance we end up with a universal basic income, or something like that, due to automation. I'm not sure what else one would do. I think that is what would happen. People will have time to do other things, more complex things, more interesting things. Certainly more leisure time." The promotion of UBI by AI tycoons elites reinforces the idea that the best we can hope for is an AI-induced universal income, rather than a more radical rethinking of how wealth and power are distributed in society-nor seeing UBI as a way to enhancing people's capabilities (Endo & Choi, 2024). The loss of meaningful work can have profound psychological effects, as Jahoda (1982) highlights the role of employment in providing structure, social contacts, and a sense of purpose. Rubin (2024) presents it nicely in indicating that "The AI revolution is accentuating the flow of income and power to the owners of property, leaving a new class-the precariat-wallowing in insecurity and existential fear." Or as Jarow ( 2024) puts it "The basic income movement might be better off severing ties with speculations about AI altogether. Then, the conversation could focus on what basic income can actually be: an effective anti-poverty tool that would neither stave off dystopia nor usher in a leisurely paradise, but instead, just a world with less poverty." AI-justified UBI's narrative acts as symbolic violence and limits our collective imagination, making it harder to envision alternative futures where technology actually serves the common good rather than aiming to place populations in a state of indigence compared to the fortunes of those who control AI.Universal Basic Income, as promoted by AI tycoonselites, is not the straightforward solution to the disruptions caused by AI that it is often portrayed to be. Instead, it can be understood as a form of symbolic violence that reinforces existing power dynamics and socio-economic inequalities. Or as Bourdieu would put it, those in power "tend to seek social respectability" (Bourdieu & Passeron, 1970) and this can be achieved through the imposition of narratives and meanings presented as legitimate while concealing the power relations which are the basis of their force (Bourdieu, 1987). By presenting UBI as a benevolent response to AI-induced unemployment, the AI elite mask their own role in creating the very problems that UBI is supposed to solve. In doing so, they perpetuate a narrative that benefits them while marginalizing those who are most negatively affected by the rise of AI. Interestingly, what is being distributed is a basic economic safety net, without committing to providing basic and free access to AI itself. Recent statements by OpenAI suggested that free AI models may not be here to stay. The current idea is a freemium model with advertising to better monetize the models, development costs, and hosting (FT News Briefing, 2024). Dayan et al. (2024) demonstrated that older AI models tend to experience performance degradation over time, which, although the term "dementia" anthropomorphizes AI, effectively illustrates the decline of these models. Therefore, offering (un)restricted access to older AI models is not a viable solution to share more broadly the benefits of AI or promote computational justice. This is especially true since making such models widely available may not ensure equitable access, particularly when those who can afford newer models receive them significantly earlier than others.However, what is touted as benefits falls short of addressing structural inequities or advancing computational justice, which goes beyond mere access to AI. Computational justice emphasizes equitable access, representation, and outcomes in AI, ensuring that everyone-regardless of socioeconomic status or geography-can not only use AI but also participate in its development and governance. It requires addressing biases in algorithms, democratizing computational power (so actively supporting computational justice), and ensuring transparent, ethical governance. Such an approach could empower marginalized communities and provide tools to tackle systemic inequities. Instead, these economic models appear more focused on sustaining AI's pervasive presence in everyday life, potentially prioritizing corporate profit over the transformative potential of AI to create a more equitable digital society both economically for all and in making the AI tools accessible for all. By sidelining these principles, the freemium model risks cementing existing inequalities rather than challenging them, raising concerns about whether the AI-driven future will be one of inclusion or exploitation. this will lead to a state where people will receive a UBI as a justification for the increased presence of AIs in society and to compensate for the externalities this induces, then will either have to pay for the advanced models or watch advertising to access the basic models. To truly address the societal disruptions posed by AI, structural reforms are necessary, including policies that promote equitable distribution of wealth and power (Stiglitz, 2019). To truly address the societal disruptions posed by AI, s This framing of UBI as a panacea for AI-induced challenges reflects a broader strategy by AI elites to deflect criticism and maintain control over narratives about AI's future. As Schiff (2023) argues, the ethical aspirations embedded in AI policy often fall short in their translation to actionable solutions due to challenges like technical feasibility, value acceptability, and institutional constraints. By focusing on symbolic solutions like UBI, which align with their profit motives, AI elites can sidestep calls for deeper structural reforms that would redistribute wealth or power. Ethical principles, while rhetorically emphasized, are often narrowed or deprioritized when translated into sector-specific policies, reflecting institutional limitations and a preference for technical fixes over transformative socio-political solutions. This narrowing of ethical commitments not only limits meaningful progress but also exacerbates the phenomenon of AI ethics dumping, where ethical responsibilities are shifted from developers and regulators onto ill-equipped users and local communities (Bélisle-Pipon & Victor, 2024). AI-driven UBI serves as a key example of how symbolic solutions allow AI elites to divert attention from their complicity in creating structural inequalities. It enables them to project a narrative of benevolence while avoiding substantive changes that would challenge their profit motives or operational frameworks. Ethics dumping is particularly insidious in this context because it disguises systemic inequities under ethical innovation. Developers embed normative assumptions into AI systems, and high-level ethical guidelines fail to account for local contexts, leaving the most vulnerable communities to grapple with the downstream impacts of these technologies. The promotion of UBI thus reinforces a cycle where the burdens of AI-induced disruptions are offloaded onto those least equipped to address them, all while AI elites continue to benefit from an unchallenged status quo.Furthermore, UBI as a mitigating mechanism remains predominantly confined to the United States-or more specifically, to key regions where AI development and control are concentrated among AI elites-while failing to extend its scope to the global population. This narrow framing is highly problematic given that AI systems are trained on data sourced from diverse global populations and have profound, far-reaching effects not only on humanity as a whole but also on the environment (Crawford, 2021). Framing the benefits of AI within the privileged contexts of already-advantaged nations disregards the inequitable realities of the Global North and Global South divide (Birhane, 2021;Mohamed et al., 2020), particularly from the perspective of an AIdriven UBI. Such an exclusionary focus not only marginalizes billions of individuals who contribute to the ecosystems enabling AI but also underscores a critical flaw in the utilitarian logic underpinning the justification for AI development. The omission of global equity considerations exposes the ethical limitations of benefit-sharing mechanisms like UBI, raising serious questions about the moral defensibility of AI's promised benefits and the structural inequities they perpetuate.uperficial solutions offered by AI-funded UBI should not be touted as quick fixes to the deeper structural inequalities that underlie current increasingly automated world.Tackling the issues surrounding AI governance requires embedding ethical principles into practical frameworks that consider the broader socio-political context of technological innovation (Bélisle-Pipon et al., 2022). Policymakers must move beyond symbolic gestures, such as Universal Basic Income (UBI), and instead focus on participatory decision-making, context-specific solutions, and robust accountability mechanisms. These measures must seek to dismantle the structural inequalities perpetuated by prevailing AI narratives, ensuring that technological progress is guided by principles of justice and equity rather than being wielded as a tool for consolidating power and profit. The expanding influence of tech elites in governmental and political spheres, exemplified by figures like Elon Musk's involvement in federal policymaking and Sam Altman's forays into municipal politics, highlights a calculated effort to control AI's development and its societal implications. This trend aligns with concerns over an impending "AI regulation winter" (Bélisle-Pipon, 2024) scenario in which regulatory mechanisms are intentionally weakened to serve elite interests, further entrenching their dominance. This pervasive involvement across federal, municipal, and regulatory levels underscores a systematic strategy to shape society's future in ways that prioritize private power over public good.In this context, UBI risks becoming a superficial concession-a mechanism for placating the public while masking deeper systemic inequities. As such, it can function as a form of symbolic violence that reinforces structural injustices rather than addressing them. Framed merely as a token redistribution of wealth, UBI has the potential to serve as a veneer of reform, obscuring the underlying exploitation and inequity facilitated by unchecked AI expansion and aggravated computational injustices. Policymakers must reject deregulation or the outsourcing of AI governance to elites whose primary aim is to entrench their dominance. Instead, they should adopt comprehensive strategies that aim at providing social conditions that enable individuals and collectives to thrive (Lees-Marshment et al., 2020), which include progressive taxation to redistribute AI-generated wealth, substantial investment in education and workforce reskilling to equip individuals for an AI-driven economy, stringent labor regulations to protect workers from exploitation in automated industries, and ensure that AI is a commons rather than adding to socio-economic inequalities, a growing computational injustice. Critically, there must be a concerted effort to challenge the disproportionate influence of tech elites on public policy (Ricaurte, 2022), ensuring that governance frameworks are designed to serve collective well-being rather than elite agendas. Superficial solutions like AI-funded UBI must not be heralded as quick fixes for systemic inequalities. Instead, efforts must focus on addressing the root causes of these disparities, building a society where technological innovation supports justice, inclusion, and equity rather than perpetuating existing power imbalances.},
  archive      = {J_FRAI},
  author       = {Bélisle-Pipon, Jean-Christophe},
  doi          = {10.3389/frai.2025.1488457},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1488457},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI, universal basic income, and power: Symbolic violence in the tech elite's narrative},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the emergent capabilities of ChatGPT 4 to estimate personality traits. <em>FRAI</em>, <em>8</em>, 1484260. (<a href='https://doi.org/10.3389/frai.2025.1484260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Piastra, Marco and Catellani, Patrizia},
  doi          = {10.3389/frai.2025.1484260},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1484260},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the emergent capabilities of ChatGPT 4 to estimate personality traits},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of a prediction and visualization system for cognitive impairment in elderly COPD patients based on self-assigning feature weights and residual evolution model. <em>FRAI</em>, <em>8</em>, 1473223. (<a href='https://doi.org/10.3389/frai.2025.1473223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Cheng, Wenwen and Yu, Chen and Liu, Xiaohui},
  doi          = {10.3389/frai.2025.1473223},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1473223},
  shortjournal = {Front. Artif. Intell.},
  title        = {Construction of a prediction and visualization system for cognitive impairment in elderly COPD patients based on self-assigning feature weights and residual evolution model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPAR-RCNN: A multi-task network for multiple person detection with attribute recognition. <em>FRAI</em>, <em>8</em>, 1454488. (<a href='https://doi.org/10.3389/frai.2025.1454488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Raghavendra, S. and Abhilash, S. K. and Nookala, Venu Madhav and Shetty, Jayashree and Bharathi, Praveen Gurunath},
  doi          = {10.3389/frai.2025.1454488},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1454488},
  shortjournal = {Front. Artif. Intell.},
  title        = {MPAR-RCNN: A multi-task network for multiple person detection with attribute recognition},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic technological innovation through ChatMu: Transforming information accessibility in muhammadiyah. <em>FRAI</em>, <em>8</em>, 1446590. (<a href='https://doi.org/10.3389/frai.2025.1446590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Adhantoro, Muhammad Syahriandi and Gunawan, Dedi and Prayitno, Harun Joko and Riyanti, Rahayu Febri and Purnomo, Eko and Jufriansah, Adi},
  doi          = {10.3389/frai.2025.1446590},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1446590},
  shortjournal = {Front. Artif. Intell.},
  title        = {Strategic technological innovation through ChatMu: Transforming information accessibility in muhammadiyah},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in cache management: A review of machine learning innovations for enhanced performance and security. <em>FRAI</em>, <em>8</em>, 1441250. (<a href='https://doi.org/10.3389/frai.2025.1441250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Krishna, Keshav},
  doi          = {10.3389/frai.2025.1441250},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1441250},
  shortjournal = {Front. Artif. Intell.},
  title        = {Advancements in cache management: A review of machine learning innovations for enhanced performance and security},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in gonarthrosis classification: A comparative study of model architectures and single vs. multi-model methods. <em>FRAI</em>, <em>8</em>, 1413820. (<a href='https://doi.org/10.3389/frai.2025.1413820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yayli, Sahika Betul and Kılıç, Kutay and Beyaz, Salih},
  doi          = {10.3389/frai.2025.1413820},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1413820},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning in gonarthrosis classification: A comparative study of model architectures and single vs. multi-model methods},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From llama to language: Prompt-engineering allows general-purpose artificial intelligence to rate narratives like expert psychologists. <em>FRAI</em>, <em>8</em>, 1398885. (<a href='https://doi.org/10.3389/frai.2025.1398885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Dauphin, Barry and Siefert, Caleb},
  doi          = {10.3389/frai.2025.1398885},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1398885},
  shortjournal = {Front. Artif. Intell.},
  title        = {From llama to language: Prompt-engineering allows general-purpose artificial intelligence to rate narratives like expert psychologists},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE(3) group convolutional neural networks and a study on group convolutions and equivariance for DWI segmentation. <em>FRAI</em>, <em>8</em>, 1369717. (<a href='https://doi.org/10.3389/frai.2025.1369717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Liu, Renfei and Lauze, François and Bekkers, Erik J. and Darkner, Sune and Erleben, Kenny},
  doi          = {10.3389/frai.2025.1369717},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1369717},
  shortjournal = {Front. Artif. Intell.},
  title        = {SE(3) group convolutional neural networks and a study on group convolutions and equivariance for DWI segmentation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on the integration of explainable artificial intelligence in intrusion detection systems to enhancing transparency and interpretability in cybersecurity. <em>FRAI</em>, <em>8</em>, 1526221. (<a href='https://doi.org/10.3389/frai.2025.1526221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mohale, Vincent Zibi and Obagbuwa, Ibidun Christiana},
  doi          = {10.3389/frai.2025.1526221},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1526221},
  shortjournal = {Front. Artif. Intell.},
  title        = {A systematic review on the integration of explainable artificial intelligence in intrusion detection systems to enhancing transparency and interpretability in cybersecurity},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of human-in-the-loop hybrid augmented intelligence approach in security inspection system. <em>FRAI</em>, <em>8</em>, 1518850. (<a href='https://doi.org/10.3389/frai.2025.1518850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Huang, Ying and Wang, XiaoKan and Zhang, Yong and Chen, Li and Zhang, HongJi},
  doi          = {10.3389/frai.2025.1518850},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1518850},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of human-in-the-loop hybrid augmented intelligence approach in security inspection system},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benefits, limits, and risks of ChatGPT in medicine. <em>FRAI</em>, <em>8</em>, 1518049. (<a href='https://doi.org/10.3389/frai.2025.1518049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Tangsrivimol, Jonathan A. and Darzidehkalani, Erfan and Virk, Hafeez Ul Hassan and Wang, Zhen and Egger, Jan and Wang, Michelle and Hacking, Sean and Glicksberg, Benjamin S. and Strauss, Markus and Krittanawong, Chayakrit},
  doi          = {10.3389/frai.2025.1518049},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1518049},
  shortjournal = {Front. Artif. Intell.},
  title        = {Benefits, limits, and risks of ChatGPT in medicine},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process latent variable models-ANN based method for automatic features selection and dimensionality reduction for control of EMG-driven systems. <em>FRAI</em>, <em>8</em>, 1506042. (<a href='https://doi.org/10.3389/frai.2025.1506042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Nayab, Maham and Waris, Asim and Jawad Khan, Muhammad and AlQahtani, Dokhyl and Imran, Ahmed and Gilani, Syed Omer and Shah, Umer Hameed},
  doi          = {10.3389/frai.2025.1506042},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1506042},
  shortjournal = {Front. Artif. Intell.},
  title        = {Gaussian process latent variable models-ANN based method for automatic features selection and dimensionality reduction for control of EMG-driven systems},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the gap: A practical step-by-step approach to warrant safe implementation of large language models in healthcare. <em>FRAI</em>, <em>8</em>, 1504805. (<a href='https://doi.org/10.3389/frai.2025.1504805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Workum, Jessica D. and van de Sande, Davy and Gommers, Diederik and van Genderen, Michel E.},
  doi          = {10.3389/frai.2025.1504805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1504805},
  shortjournal = {Front. Artif. Intell.},
  title        = {Bridging the gap: A practical step-by-step approach to warrant safe implementation of large language models in healthcare},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning techniques for predicting neurodevelopmental impairments in premature infants: A systematic review. <em>FRAI</em>, <em>8</em>, 1481338. (<a href='https://doi.org/10.3389/frai.2025.1481338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ortega-Leon, Arantxa and Urda, Daniel and Turias, Ignacio J. and Lubián-López, Simón P. and Benavente-Fernández, Isabel},
  doi          = {10.3389/frai.2025.1481338},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1481338},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning techniques for predicting neurodevelopmental impairments in premature infants: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of argument structure constructions in the large language model BERT. <em>FRAI</em>, <em>8</em>, 1477246. (<a href='https://doi.org/10.3389/frai.2025.1477246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ramezani, Pegah and Schilling, Achim and Krauss, Patrick},
  doi          = {10.3389/frai.2025.1477246},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1477246},
  shortjournal = {Front. Artif. Intell.},
  title        = {Analysis of argument structure constructions in the large language model BERT},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence applied to diabetes complications: A bibliometric analysis. <em>FRAI</em>, <em>8</em>, 1455341. (<a href='https://doi.org/10.3389/frai.2025.1455341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Tao, Yukun and Hou, Jinzheng and Zhou, Guangxin and Zhang, Da},
  doi          = {10.3389/frai.2025.1455341},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1455341},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence applied to diabetes complications: A bibliometric analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How could fit between polychronicity and multitasking shape employees' self-leadership? the moderating role of AI-empowered task processing. <em>FRAI</em>, <em>8</em>, 1451944. (<a href='https://doi.org/10.3389/frai.2025.1451944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Zhou, Zhirui and Xiang, Shuting and Xie, Qingxin},
  doi          = {10.3389/frai.2025.1451944},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1451944},
  shortjournal = {Front. Artif. Intell.},
  title        = {How could fit between polychronicity and multitasking shape employees' self-leadership? the moderating role of AI-empowered task processing},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Population health management genomic new-born screens and multi-omics intercepts. <em>FRAI</em>, <em>7</em>, 1496942. (<a href='https://doi.org/10.3389/frai.2024.1496942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe Population Health Management (PHM) Genomic Newborn Screens (GNBS) and Multi-Omics Intercepts for Human Phenotype Ontology (HPO) using Federated Data Platforms (FDP) represent a groundbreaking innovation in global health. This reform, supported by the UK’s Genomic Medical Services (GMS) through “The Generation Study,” aims to significantly reduce infant mortality by identifying and managing over 200 rare diseases from birth, paving the way for personalised health planning.MethodsUsing an ecosystem approach, this study evaluates a diverse pangenome to predict health outcomes or confirm diagnoses prior to symptomatic manifestations. GNBS standardises care by integrating diagnostic techniques such as blood spot analysis and full blood cell diagnostics to stratify risk. The approach enhances the understanding of rare diseases in primary care medicine, with biomedical and haematology diagnoses re-evaluated. Scientific proof of concept and fit-for-purpose technology align multi-omics in pre-eXams (X = Gen AI).RecommendationsThe Digital Regulation Service (DRS) assembles an agile group of experts to enhance medical science through human phenotype ontology (HPO) for precise disease segmentation, scheduling accurate eXam intercepts where needed. This team strategically plans regulation services for digital HPO exam assurance and implements Higher Expert Medical Science Safety (HEMSS) frameworks. The DRS is responsible for overseeing gene, oligonucleotide, and recombinant protein intercepts; commissioning blood pathology HPO exam intercepts; and monitoring preliminary exams with advanced imaging techniques.DiscussionIn pursuit of excellence in PHM of HPO, HEMSS with Agile Group Development leverages the Genomic Newborn Screens (GNBS) and multi-omics to create personalised health plans integrated with NHS England Genomics and AI-driven DRS. The discourse extends to examining GNBS predictors and intercepts, focusing on their impact on public health and patient safety. Discussions encompass structured HPO knowledge addressing newborn health, ethical considerations, family privacy, and the benefits and limitations of pre-exam screenings and life exam intercepts. These debates involve stakeholders in adopting HPO-enhanced clinical pathways through Alliances for Health Systems Networking-Genomic Enterprise Partnerships (AHSN-GEP).Conclusion“The Generation Study” represents a paradigm in digital child health management using an HPO-X-Gen-AI framework, transitioning from trusted research to evidence-based discovery. This approach sets a standard for personalised healthcare practices, incorporating ontology risk stratification and future-ready analytics as outlined in the NHS Constitution. The discourse on higher expert medical science safety governance will continue in the forthcoming manuscript, “PHM Fit Lifecycles in Future Analytics,” which will further explore developing localised health solutions for “Our Future Health.”},
  archive      = {J_FRAI},
  author       = {Henry, James Andrew},
  doi          = {10.3389/frai.2024.1496942},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {1496942},
  shortjournal = {Front. Artif. Intell.},
  title        = {Population health management genomic new-born screens and multi-omics intercepts},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Small pre-trained model for background understanding in multi-round question answering. <em>FRAI</em>, <em>7</em>, 1308206. (<a href='https://doi.org/10.3389/frai.2024.1308206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-round Q&A based on background text needs to infer the answer to the question through the current question, historical Q&A pairs, and background text. The pre-trained model has proved its effectiveness in this task; however, the existing model has many problems such as too many parameters and high resource consumption. We propose a knowledge transfer method that combines knowledge distillation, co-learning of similar datasets, and fine-tuning of similar tasks. Through multi-knowledge cooperative training from large model to small model, between different data sets, and between different tasks, the performance of the small model with low resource consumption can match or surpass that of the large model.},
  archive      = {J_FRAI},
  author       = {Huang, Xin and Song, Hulin and Lu, Mingming},
  doi          = {10.3389/frai.2024.1308206},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {1308206},
  shortjournal = {Front. Artif. Intell.},
  title        = {Small pre-trained model for background understanding in multi-round question answering},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Environment sustainability with smart grid sensor. <em>FRAI</em>, <em>7</em>, 1510410. (<a href='https://doi.org/10.3389/frai.2024.1510410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mahadik, Sheetal and Gedam, Madhuri and Shah, Deven},
  doi          = {10.3389/frai.2024.1510410},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1510410},
  shortjournal = {Front. Artif. Intell.},
  title        = {Environment sustainability with smart grid sensor},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable correlation-based anomaly detection for industrial control systems. <em>FRAI</em>, <em>7</em>, 1508821. (<a href='https://doi.org/10.3389/frai.2024.1508821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Birihanu, Ermiyas and Lendák, Imre},
  doi          = {10.3389/frai.2024.1508821},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1508821},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable correlation-based anomaly detection for industrial control systems},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language writ large: LLMs, ChatGPT, meaning, and understanding. <em>FRAI</em>, <em>7</em>, 1490698. (<a href='https://doi.org/10.3389/frai.2024.1490698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Harnad, Stevan},
  doi          = {10.3389/frai.2024.1490698},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1490698},
  shortjournal = {Front. Artif. Intell.},
  title        = {Language writ large: LLMs, ChatGPT, meaning, and understanding},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factors influencing trust in algorithmic decision-making: An indirect scenario-based experiment. <em>FRAI</em>, <em>7</em>, 1465605. (<a href='https://doi.org/10.3389/frai.2024.1465605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Marmolejo-Ramos, Fernando and Marrone, Rebecca and Korolkiewicz, Malgorzata and Gabriel, Florence and Siemens, George and Joksimovic, Srecko and Yamada, Yuki and Mori, Yuki and Rahwan, Talal and Sahakyan, Maria and Sonna, Belona and Meirmanov, Assylbek and Bolatov, Aidos and Som, Bidisha and Ndukaihe, Izuchukwu and Arinze, Nwadiogo C. and Kundrát, Josef and Skanderová, Lenka and Ngo, Van-Giang and Nguyen, Giang and Lacia, Michelle and Kung, Chun-Chia and Irmayanti, Meiselina and Muktadir, Abdul and Samosir, Fransiska Timoria and Liuzza, Marco Tullio and Giorgini, Roberto and Khatin-Zadeh, Omid and Banaruee, Hassan and Özdoğru, Asil Ali and Ariyabuddhiphongs, Kris and Rakchai, Wachirawit and Trujillo, Natalia and Valencia, Stella Maris and Janyan, Armina and Kostov, Kiril and Montoro, Pedro R. and Hinojosa, Jose and Medeiros, Kelsey and Hunt, Thomas E. and Posada, Julian and Freitag, Raquel Meister Ko and Tejada, Julian},
  doi          = {10.3389/frai.2024.1465605},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1465605},
  shortjournal = {Front. Artif. Intell.},
  title        = {Factors influencing trust in algorithmic decision-making: An indirect scenario-based experiment},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning and explainable AI for classification of potato leaf diseases. <em>FRAI</em>, <em>7</em>, 1449329. (<a href='https://doi.org/10.3389/frai.2024.1449329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Alhammad, Sarah M. and Khafaga, Doaa Sami and El-hady, Walaa M. and Samy, Farid M. and Hosny, Khalid M.},
  doi          = {10.3389/frai.2024.1449329},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1449329},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning and explainable AI for classification of potato leaf diseases},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One size fits all: Enhanced zero-shot text classification for patient listening on social media. <em>FRAI</em>, <em>7</em>, 1397470. (<a href='https://doi.org/10.3389/frai.2024.1397470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Matoshi, Veton and De Vuono, Maria Carmela and Gaspari, Roberto and Kröll, Mark and Jantscher, Michael and Nicolardi, Sara Lucia and Mazzola, Giuseppe and Rauch, Manuela and Sabol, Vedran and Salhofer, Eileen and Mariani, Riccardo},
  doi          = {10.3389/frai.2024.1397470},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {1397470},
  shortjournal = {Front. Artif. Intell.},
  title        = {One size fits all: Enhanced zero-shot text classification for patient listening on social media},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum: Person-based design and evaluation of MIA, a digital medical interview assistant for radiology. <em>FRAI</em>, <em>7</em>, 1546421. (<a href='https://doi.org/10.3389/frai.2024.1546421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corrigendum on: Denecke K, Reichenpfader D, Willi D, Kennel K, Bonel H, Nairz K, Cihoric N, Papaux D and von Tengg-Kobligk H (2024) Person-based design and evaluation of MIA, a digital medical interview assistant for radiology. Front. Artif. Intell. 7:1431156. doi: 10.3389/frai.2024.1431156 In the published article, there was an error in the Data Availability statement. We were missing to add the links to the repositories mentioned in the paper. The correct Data Availability statement appears below.},
  archive      = {J_FRAI},
  author       = {Denecke, Kerstin and Reichenpfader, Daniel and Willi, Dominic and Kennel, Karin and Bonel, Harald and Nairz, Knud and Cihoric, Nikola and Papaux, Damien and von Tengg-Kobligk, Hendrik},
  doi          = {10.3389/frai.2024.1546421},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1546421},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Person-based design and evaluation of MIA, a digital medical interview assistant for radiology},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-based framework for early detection of heart disease using enhanced multilayer perceptron. <em>FRAI</em>, <em>7</em>, 1539588. (<a href='https://doi.org/10.3389/frai.2024.1539588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Abdullah, Monir},
  doi          = {10.3389/frai.2024.1539588},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1539588},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence-based framework for early detection of heart disease using enhanced multilayer perceptron},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of artificial intelligence automation in digital music streaming platforms for improving consumer subscription responses: A review. <em>FRAI</em>, <em>7</em>, 1515716. (<a href='https://doi.org/10.3389/frai.2024.1515716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mokoena, Nontokozo and Obagbuwa, Ibidun Christiana},
  doi          = {10.3389/frai.2024.1515716},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1515716},
  shortjournal = {Front. Artif. Intell.},
  title        = {An analysis of artificial intelligence automation in digital music streaming platforms for improving consumer subscription responses: A review},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating accuracy and reproducibility of large language model performance on critical care assessments in pharmacy education. <em>FRAI</em>, <em>7</em>, 1514896. (<a href='https://doi.org/10.3389/frai.2024.1514896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Yang, Huibo and Hu, Mengxuan and Most, Amoreena and Hawkins, W. Anthony and Murray, Brian and Smith, Susan E. and Li, Sheng and Sikora, Andrea},
  doi          = {10.3389/frai.2024.1514896},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1514896},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating accuracy and reproducibility of large language model performance on critical care assessments in pharmacy education},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced sleep disorder detection using multi-layered ensemble learning and advanced data balancing techniques. <em>FRAI</em>, <em>7</em>, 1506770. (<a href='https://doi.org/10.3389/frai.2024.1506770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mostafa Monowar, Muhammad and Nobel, S. M. Nuruzzaman and Afroj, Maharin and Hamid, Md Abdul and Uddin, Md Zia and Kabir, Md Mohsin and Mridha, M. F.},
  doi          = {10.3389/frai.2024.1506770},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1506770},
  shortjournal = {Front. Artif. Intell.},
  title        = {Advanced sleep disorder detection using multi-layered ensemble learning and advanced data balancing techniques},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visceral condition assessment through digital tongue image analysis. <em>FRAI</em>, <em>7</em>, 1501184. (<a href='https://doi.org/10.3389/frai.2024.1501184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ho, Siu Cheong and Chen, Yiliang and Xie, Yao Jie and Yeung, Wing-Fai and Chen, Shu-Cheng and Qin, Jing},
  doi          = {10.3389/frai.2024.1501184},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1501184},
  shortjournal = {Front. Artif. Intell.},
  title        = {Visceral condition assessment through digital tongue image analysis},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust predictive framework for diabetes classification using optimized machine learning on imbalanced datasets. <em>FRAI</em>, <em>7</em>, 1499530. (<a href='https://doi.org/10.3389/frai.2024.1499530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Abousaber, Inam and Abdallah, Haitham F. and El-Ghaish, Hany},
  doi          = {10.3389/frai.2024.1499530},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1499530},
  shortjournal = {Front. Artif. Intell.},
  title        = {Robust predictive framework for diabetes classification using optimized machine learning on imbalanced datasets},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-budget superpixel active learning for semantic segmentation. <em>FRAI</em>, <em>7</em>, 1498956. (<a href='https://doi.org/10.3389/frai.2024.1498956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wang, Yuemin and Stavness, Ian},
  doi          = {10.3389/frai.2024.1498956},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1498956},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dynamic-budget superpixel active learning for semantic segmentation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bird’s-eye view of the biological mechanism and machine learning prediction approaches for cell-penetrating peptides. <em>FRAI</em>, <em>7</em>, 1497307. (<a href='https://doi.org/10.3389/frai.2024.1497307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ramasundaram, Maduravani and Sohn, Honglae and Madhavan, Thirumurthy},
  doi          = {10.3389/frai.2024.1497307},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1497307},
  shortjournal = {Front. Artif. Intell.},
  title        = {A bird’s-eye view of the biological mechanism and machine learning prediction approaches for cell-penetrating peptides},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of pink eye infection to evaluate its medications: Group decision-making approach with 2-tuple linguistic T-spherical fuzzy WASPAS method. <em>FRAI</em>, <em>7</em>, 1496689. (<a href='https://doi.org/10.3389/frai.2024.1496689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rasheed, M. Waheed and Y. Saleh, Hind and Salih, Areen A. and Karamat, Jahangeer and Bilal, Muhammad},
  doi          = {10.3389/frai.2024.1496689},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1496689},
  shortjournal = {Front. Artif. Intell.},
  title        = {An overview of pink eye infection to evaluate its medications: Group decision-making approach with 2-tuple linguistic T-spherical fuzzy WASPAS method},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The technology acceptance model and adopter type analysis in the context of artificial intelligence. <em>FRAI</em>, <em>7</em>, 1496518. (<a href='https://doi.org/10.3389/frai.2024.1496518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ibrahim, Fabio and Münscher, Johann-Christoph and Daseking, Monika and Telle, Nils-Torge},
  doi          = {10.3389/frai.2024.1496518},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1496518},
  shortjournal = {Front. Artif. Intell.},
  title        = {The technology acceptance model and adopter type analysis in the context of artificial intelligence},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyberinfrastructure for machine learning applications in agriculture: Experiences, analysis, and vision. <em>FRAI</em>, <em>7</em>, 1496066. (<a href='https://doi.org/10.3389/frai.2024.1496066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Waltz, Lucas and Katari, Sushma and Hong, Chaeun and Anup, Adit and Colbert, Julian and Potlapally, Anirudh and Dill, Taylor and Porter, Canaan and Engle, John and Stewart, Christopher and Subramoni, Hari and Shearer, Scott and Machiraju, Raghu and Ortez, Osler and Lindsey, Laura and Nandi, Arnab and Khanal, Sami},
  doi          = {10.3389/frai.2024.1496066},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1496066},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cyberinfrastructure for machine learning applications in agriculture: Experiences, analysis, and vision},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-tuning a local LLaMA-3 large language model for automated privacy-preserving physician letter generation in radiation oncology. <em>FRAI</em>, <em>7</em>, 1493716. (<a href='https://doi.org/10.3389/frai.2024.1493716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hou, Yihao and Bert, Christoph and Gomaa, Ahmed and Lahmer, Godehard and Höfler, Daniel and Weissmann, Thomas and Voigt, Raphaela and Schubert, Philipp and Schmitter, Charlotte and Depardon, Alina and Semrau, Sabine and Maier, Andreas and Fietkau, Rainer and Huang, Yixing and Putz, Florian},
  doi          = {10.3389/frai.2024.1493716},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1493716},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fine-tuning a local LLaMA-3 large language model for automated privacy-preserving physician letter generation in radiation oncology},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Commentary: Implications of causality in artificial intelligence. why causal AI is easier said than done. <em>FRAI</em>, <em>7</em>, 1488359. (<a href='https://doi.org/10.3389/frai.2024.1488359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Luís Cavique's (2024) article, "Implications of Causality in Artificial Intelligence," presents a compelling case for the importance of causalAI. By focusing on cause-and-effect relationships rather than mere correlations, causalAI offers a pathway to more transparent, fair, and reliable AI systems. Cavique argues that causalAI is the least criticized approach compared to responsible AI, fair AI, and explainable AI, largely due to its scientific rigor and potential to reduce biases. However, despite its promise, causalAI is not without challenges. This commentary aims to assess some of these limitations and potential criticisms of causalAI as presented by Cavique, arguing that while it holds substantial promise, its implementation and practical application may be more complex and fraught with difficulties than the author suggests.One of the primary challenges with causalAI lies in its complexity. CausalAI requires a deep understanding of causal inference and advanced statistical techniques, making it less accessible to most AI developers (Cox Jr., 2023). Unlike correlation-based methods, which are widely understood and now relatively easy to implement, causal models demand a high level of expertise. Arguably, only a select group of experts can effectively design, implement, and interpret these models. This complexity can create barriers to entry for many organizations and individuals who might want to engage in developing or using causalAI for benefiting from the transparency and fairness that causalAI promises. This could exacerbate existing disparities in AI literacy, and capacitation, and epistemic justice, potentially leading to an increased form of AI elitism, where only those with advanced skills, knowledge, and wealth of resources can fully participate in or critique causalAI development. This situation could undermine the broader goal of making its benefits accessible to a wide audience.CausalAI's reliance on high-quality, detailed data presents another significant challenge. Establishing causal relationships requires data that not only captures correlations but also provides the context needed to infer causality (Vallverdú, 2024). In many real-world applications, such data is either unavailable or prohibitively expensive to obtain. Causal AI requires high-quality data that captures both correlations and context (Vallverdú, 2024). In practice, such data is often scarce or costly, posing challenges for establishing accurate causal relationships Additionally, even when data is available, it may be incomplete or biased in ways that could skew causal inferences. The assumptions underlying causal models also warrant critical examination. CausalAI models often assume that all relevant variables have been identified and correctly measured. However, in practice, unmeasured confounders-variables that influence both the cause and effect-can distort causal estimates, leading to incorrect conclusions and as Rawal et al (2024) put it there is a lack of ground truth for validation. This reliance on potentially faulty assumptions could result in AI systems that, while appearing transparent and fair, are actually based on flawed reasoning. Furthermore, the process of identifying and validating causal relationships can be resource intensive and time-consuming. This raises questions about the scalability of causalAI, particularly in dynamic environments where data is constantly evolving, and causal relationships may shift over time. The effort required to maintain accurate causal models could outweigh the benefits, especially in fast-paced industries where quick decision-making is critical.Scalability is a major challenge for causal AI, as building and validating models is complex and resource-intensive. These models often require tailored adjustments for new contexts, limiting their generalizability compared to correlation-based methods. Scalability is a crucial consideration in the deployment of AI systems, and causalAI may struggle in this area. The process of building and validating causal models is not only complex, but also resource-intensive. As Cavique rightly notes, causalAI requires meticulous identification of causal variables and relationships, which may not easily generalize across different contexts or applications, particularly in sectors requiring a major data curation effort (such as the healthcare sector). This limitation could hinder the practical application of causalAI in scenarios where scalability and adaptability are key. Specificity required by causal models may limit their ability to generalize across different datasets or environments. While correlation-based models can often be applied broadly with minimal adjustments, causal models may need to be tailored to the particularities of each new situation. This lack of generalizability could make causalAI less appealing in settings where adaptability is needed.CausalAI is lauded for its potential to improve fairness and transparency in AI systems, but these benefits are not guaranteed. The causal relationships identified by AI systems are not immune to the biases present in the underlying data. If the data reflects existing societal biases or power dynamics, the causal models derived from it may inadvertently reinforce these issues. Put more Even when accurately identifying cause-and-effect relationships, they may perpetuate societal biases, potentially reinforcing inequities if not designed inclusively.simply, a causal model trained on biased data might correctly identify a causal relationship but still perpetuate unjust outcomes. Moreover, the iInterpretation of causal models can be influenced by the subjective perspectives of those designing or using them (Mittelstadt et al., 2019)-especially if the design of CausalAI is not inclusive and transparent, allowing for the active participation of stakeholders. This subjectivity introduces another layer of potential bias, as different stakeholders may have different interpretations of what constitutes a fair or just causal relationship. Ensuring that causalAI models are both fair and transparent requires careful consideration of these ethical and interpretive challenges, which are not easily addressed through technical solutions alone (Bélisle-Pipon et al, 2021).The practical implementation of causalAI also raises significant concerns. Implementing causal AI often requires significant changes to workflows and data processes, leading to time and cost barriers. This can deter organizations, especially if benefits are not evident upfront. Integrating causal models into existing AI systems may require substantial changes to workflows, data pipelines, and decision-making processes. These changes come with associated costs, both in terms of time and resources. Organizations may be reluctant to adopt causalAI if the benefits are not immediately clear or if the costs outweigh the perceived advantages. Furthermore, the transition to causalAI could disrupt existing AI practices and lead to resistance from stakeholders who are comfortable with current methods. The need for specialized knowledge and expertise to implement and maintain causal models may further exacerbate these challenges, making the adoption of causalAI more difficult in practice than in theory.Finally, the focus on causality may introduces the increased risks of unintended (and undetected) consequences. Causal AI, if based on flawed models or data, can lead to unintended negative outcomes. Adjustments to causal variables might have unforeseen side effects, particularly in lessdocumented contexts or marginalized populations, leading to data-driven biases (Norori et al, 2019). While CausalAI aims to identify and leverage causal relationships to improve decisionmaking, if the underlying model is wrong, interventions based on these models could have unforeseen effects. For instance, intervening on a causal variable to achieve a desired outcome might inadvertently lead to negative side effects in other areas. These unintended consequences highlight the need for a cautious and nuanced approach to applying CausalAI in practice. Beyond that, CausalAI does not address the underlying issues of fairness, representation and power imbalance-because it's causal from a data and AI point of view does not mean it is true and representative of reality. So even a CausalAI that is capable of grasp cause-and-effect relationships will be wrong in relation to non-or under-documented realities. An important example of this is about rarer phenomena and especially marginalized populations, which will not be better represented by CausalAI, nor better understood or more fully taken into consideration.While Cavique's advocacy for causalAI is well-founded and highlights the approach's potential to address critical issues in AI, but significant challenges accompany this paradigm. The complexity, data requirements, scalability issues, and ethical considerations all pose substantial obstacles to the widespread adoption of causalAI. Moreover, the practical implementation of these models may involve significant costs and risks, which could limit their appeal. CausalAI represents an exciting and promising direction, but caution needs to be exercised and its potential benefits must be carefully weighed against the challenges it presents. In this context, further research into causal AI becomes not only desirable but essential. By shifting the focus from mere correlations to understanding why certain relationships exist, causal AI offers a promising path toward more robust, adaptable, and transparent AI systems. As pointed out by Cavique, Pearl and Mackenzie's (2018) approach, emphasizing the need for a framework that captures the underlying mechanisms of data, could be key to advancing AI beyond its current capabilities. While the complexity of causal inference presents challenges, such as the need for specialized expertise and high-quality data, the long-term potential of these methods suggests that they could redefine how we understand and achieve intelligence in AI systems. Moving forward, a focus on addressing the complexities, data requirements, and ethical considerations outlined will be crucial for realizing the full potential of causal AI in advancing the field beyond the limitations of correlation-based models.},
  archive      = {J_FRAI},
  author       = {Bélisle-Pipon, Jean-Christophe},
  doi          = {10.3389/frai.2024.1488359},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1488359},
  shortjournal = {Front. Artif. Intell.},
  title        = {Commentary: Implications of causality in artificial intelligence. why causal AI is easier said than done},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application progress of artificial intelligence in tumor diagnosis and treatment. <em>FRAI</em>, <em>7</em>, 1487207. (<a href='https://doi.org/10.3389/frai.2024.1487207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Sun, Fan and Zhang, Li and Tong, Zhongsheng},
  doi          = {10.3389/frai.2024.1487207},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1487207},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application progress of artificial intelligence in tumor diagnosis and treatment},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of machine learning and deep learning approaches in mexico: Challenges and opportunities. <em>FRAI</em>, <em>7</em>, 1479855. (<a href='https://doi.org/10.3389/frai.2024.1479855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Uc Castillo, José Luis and Marín Celestino, Ana Elizabeth and Martínez Cruz, Diego Armando and Tuxpan Vargas, José and Ramos Leal, José Alfredo and Morán Ramírez, Janete},
  doi          = {10.3389/frai.2024.1479855},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1479855},
  shortjournal = {Front. Artif. Intell.},
  title        = {A systematic review of machine learning and deep learning approaches in mexico: Challenges and opportunities},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phenology analysis for trait prediction using UAVs in a MAGIC rice population with different transplanting protocols. <em>FRAI</em>, <em>7</em>, 1477637. (<a href='https://doi.org/10.3389/frai.2024.1477637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Taniguchi, Shoji and Sakamoto, Toshihiro and Nakamura, Haruki and Nonoue, Yasunori and Guan, Di and Fukuda, Akari and Fukuda, Hirofumi and Wada, Kaede C. and Ishii, Takuro and Yonemaru, Jun-Ichi and Ogawa, Daisuke},
  doi          = {10.3389/frai.2024.1477637},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1477637},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phenology analysis for trait prediction using UAVs in a MAGIC rice population with different transplanting protocols},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Examining the integration of artificial intelligence in supply chain management from industry 4.0 to 6.0: A systematic literature review. <em>FRAI</em>, <em>7</em>, 1477044. (<a href='https://doi.org/10.3389/frai.2024.1477044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Samuels, Alexander},
  doi          = {10.3389/frai.2024.1477044},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1477044},
  shortjournal = {Front. Artif. Intell.},
  title        = {Examining the integration of artificial intelligence in supply chain management from industry 4.0 to 6.0: A systematic literature review},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Countering AI-powered disinformation through national regulation: Learning from the case of ukraine. <em>FRAI</em>, <em>7</em>, 1474034. (<a href='https://doi.org/10.3389/frai.2024.1474034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Marushchak, Anatolii and Petrov, Stanislav and Khoperiya, Anayit},
  doi          = {10.3389/frai.2024.1474034},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1474034},
  shortjournal = {Front. Artif. Intell.},
  title        = {Countering AI-powered disinformation through national regulation: Learning from the case of ukraine},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of outpatient rehabilitation patient preferences and optimization of graded diagnosis and treatment based on XGBoost machine learning algorithm. <em>FRAI</em>, <em>7</em>, 1473837. (<a href='https://doi.org/10.3389/frai.2024.1473837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Fan, Xuehui and Ye, Ruixue and Gao, Yan and Xue, Kaiwen and Zhang, Zeyu and Xu, Jing and Zhao, Jingpu and Feng, Jun and Wang, Yulong},
  doi          = {10.3389/frai.2024.1473837},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1473837},
  shortjournal = {Front. Artif. Intell.},
  title        = {Prediction of outpatient rehabilitation patient preferences and optimization of graded diagnosis and treatment based on XGBoost machine learning algorithm},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The sociolinguistic foundations of language modeling. <em>FRAI</em>, <em>7</em>, 1472411. (<a href='https://doi.org/10.3389/frai.2024.1472411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Grieve, Jack and Bartl, Sara and Fuoli, Matteo and Grafmiller, Jason and Huang, Weihang and Jawerbaum, Alejandro and Murakami, Akira and Perlman, Marcus and Roemling, Dana and Winter, Bodo},
  doi          = {10.3389/frai.2024.1472411},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1472411},
  shortjournal = {Front. Artif. Intell.},
  title        = {The sociolinguistic foundations of language modeling},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing africa’s agriculture and food systems through responsible and gender inclusive AI innovation: Insights from AI4AFS network. <em>FRAI</em>, <em>7</em>, 1472236. (<a href='https://doi.org/10.3389/frai.2024.1472236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ozor, Nicholas and Nwakaire, Joel and Nyambane, Alfred and Muhatiah, Wentland and Nwobodo, Cynthia},
  doi          = {10.3389/frai.2024.1472236},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1472236},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing africa’s agriculture and food systems through responsible and gender inclusive AI innovation: Insights from AI4AFS network},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPEMix: A lightweight method via superclass pseudo-label and efficient mixup for echocardiogram view classification. <em>FRAI</em>, <em>7</em>, 1467218. (<a href='https://doi.org/10.3389/frai.2024.1467218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Ma, Shizhou and Zhang, Yifeng and Li, Delong and Sun, Yixin and Qiu, Zhaowen and Wei, Lei and Dong, Suyu},
  doi          = {10.3389/frai.2024.1467218},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1467218},
  shortjournal = {Front. Artif. Intell.},
  title        = {SPEMix: A lightweight method via superclass pseudo-label and efficient mixup for echocardiogram view classification},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fostering effective hybrid human-LLM reasoning and decision making. <em>FRAI</em>, <em>7</em>, 1464690. (<a href='https://doi.org/10.3389/frai.2024.1464690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Passerini, Andrea and Gema, Aryo and Minervini, Pasquale and Sayin, Burcu and Tentori, Katya},
  doi          = {10.3389/frai.2024.1464690},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1464690},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fostering effective hybrid human-LLM reasoning and decision making},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SineKAN: Kolmogorov-arnold networks using sinusoidal activation functions. <em>FRAI</em>, <em>7</em>, 1462952. (<a href='https://doi.org/10.3389/frai.2024.1462952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Reinhardt, Eric and Ramakrishnan, Dinesh and Gleyzer, Sergei},
  doi          = {10.3389/frai.2024.1462952},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1462952},
  shortjournal = {Front. Artif. Intell.},
  title        = {SineKAN: Kolmogorov-arnold networks using sinusoidal activation functions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the role of generative AI and color patterns in the dissemination of war imagery and disinformation on social media. <em>FRAI</em>, <em>7</em>, 1457247. (<a href='https://doi.org/10.3389/frai.2024.1457247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {García-Huete, Estibaliz and Ignacio-Cerrato, Sara and Pacios, David and Vázquez-Poletti, José Luis and Pérez-Serrano, María José and Donofrio, Andrea and Cesarano, Clemente and Schetakis, Nikolaos and Di Iorio, Alessio},
  doi          = {10.3389/frai.2024.1457247},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1457247},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating the role of generative AI and color patterns in the dissemination of war imagery and disinformation on social media},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is synthetic data generation effective in maintaining clinical biomarkers? investigating diffusion models across diverse imaging modalities. <em>FRAI</em>, <em>7</em>, 1454441. (<a href='https://doi.org/10.3389/frai.2024.1454441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hosseini, Abdullah and Serag, Ahmed},
  doi          = {10.3389/frai.2024.1454441},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1454441},
  shortjournal = {Front. Artif. Intell.},
  title        = {Is synthetic data generation effective in maintaining clinical biomarkers? investigating diffusion models across diverse imaging modalities},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the effectiveness of prompt engineering for knowledge graph question answering. <em>FRAI</em>, <em>7</em>, 1454258. (<a href='https://doi.org/10.3389/frai.2024.1454258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Kosten, Catherine and Nooralahzadeh, Farhad and Stockinger, Kurt},
  doi          = {10.3389/frai.2024.1454258},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1454258},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluating the effectiveness of prompt engineering for knowledge graph question answering},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clinical entity-aware domain adaptation in low resource setting for inflammatory bowel disease. <em>FRAI</em>, <em>7</em>, 1450477. (<a href='https://doi.org/10.3389/frai.2024.1450477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Francis, Sumam and Crema Garcia, Fernando and Uma, Kanimozhi and Mestdagh, Willem and De Moor, Bart and Moens, Marie-Francine},
  doi          = {10.3389/frai.2024.1450477},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1450477},
  shortjournal = {Front. Artif. Intell.},
  title        = {Clinical entity-aware domain adaptation in low resource setting for inflammatory bowel disease},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing and validating a drug recommendation system based on tumor microenvironment and drug fingerprint. <em>FRAI</em>, <em>7</em>, 1444127. (<a href='https://doi.org/10.3389/frai.2024.1444127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Wang, Yan and Jin, Xiaoye and Qiu, Rui and Ma, Bo and Zhang, Sheng and Song, Xuyang and He, Jinxi},
  doi          = {10.3389/frai.2024.1444127},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1444127},
  shortjournal = {Front. Artif. Intell.},
  title        = {Developing and validating a drug recommendation system based on tumor microenvironment and drug fingerprint},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating computational fluid dynamics simulation of post-combustion carbon capture modeling with MeshGraphNets. <em>FRAI</em>, <em>7</em>, 1441985. (<a href='https://doi.org/10.3389/frai.2024.1441985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Lei, Bo and Fu, Yucheng and Cadena, Jose and Saini, Amar and Hu, Yeping and Bao, Jie and Xu, Zhijie and Ng, Brenda and Nguyen, Phan},
  doi          = {10.3389/frai.2024.1441985},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1441985},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accelerating computational fluid dynamics simulation of post-combustion carbon capture modeling with MeshGraphNets},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the potential of AI-driven food waste management strategies used in the hospitality industry for application in household settings. <em>FRAI</em>, <em>7</em>, 1429477. (<a href='https://doi.org/10.3389/frai.2024.1429477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Clark, Quintana M. and Kanavikar, Disha Basavaraja and Clark, Jason and Donnelly, Patrick J.},
  doi          = {10.3389/frai.2024.1429477},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1429477},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the potential of AI-driven food waste management strategies used in the hospitality industry for application in household settings},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ocular biometry OCR: A machine learning algorithm leveraging optical character recognition to extract intra ocular lens biometry measurements. <em>FRAI</em>, <em>7</em>, 1428716. (<a href='https://doi.org/10.3389/frai.2024.1428716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Salvi, Anish and Arnal, Leo and Ly, Kevin and Ferreira, Gabriel and Wang, Sophia Y. and Langlotz, Curtis and Mahajan, Vinit and Ludwig, Chase A.},
  doi          = {10.3389/frai.2024.1428716},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1428716},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ocular biometry OCR: A machine learning algorithm leveraging optical character recognition to extract intra ocular lens biometry measurements},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grammar-constrained decoding for structured information extraction with fine-tuned generative models applied to clinical trial abstracts. <em>FRAI</em>, <em>7</em>, 1406857. (<a href='https://doi.org/10.3389/frai.2024.1406857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Schmidt, David M. and Cimiano, Philipp},
  doi          = {10.3389/frai.2024.1406857},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1406857},
  shortjournal = {Front. Artif. Intell.},
  title        = {Grammar-constrained decoding for structured information extraction with fine-tuned generative models applied to clinical trial abstracts},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-trainable and adaptive sensor intelligence for selective data generation. <em>FRAI</em>, <em>7</em>, 1403187. (<a href='https://doi.org/10.3389/frai.2024.1403187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rezvani, Arghavan and Huang, Wenjun and Chen, Hanning and Ni, Yang and Imani, Mohsen},
  doi          = {10.3389/frai.2024.1403187},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1403187},
  shortjournal = {Front. Artif. Intell.},
  title        = {Self-trainable and adaptive sensor intelligence for selective data generation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting digital assets using an ontology based cyber situational awareness system. <em>FRAI</em>, <em>7</em>, 1394363. (<a href='https://doi.org/10.3389/frai.2024.1394363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Almoabady, Tariq Ammar and Alblawi, Yasser Mohammad and Albalawi, Ahmad Emad and Aborokbah, Majed M. and Manimurugan, S. and Aljuhani, Ahmed and Aldawood, Hussain and Karthikeyan, P.},
  doi          = {10.3389/frai.2024.1394363},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1394363},
  shortjournal = {Front. Artif. Intell.},
  title        = {Protecting digital assets using an ontology based cyber situational awareness system},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A conceptual ethical framework to preserve natural human presence in the use of AI systems in education. <em>FRAI</em>, <em>7</em>, 1377938. (<a href='https://doi.org/10.3389/frai.2024.1377938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Isop, Werner Alexander},
  doi          = {10.3389/frai.2024.1377938},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {1377938},
  shortjournal = {Front. Artif. Intell.},
  title        = {A conceptual ethical framework to preserve natural human presence in the use of AI systems in education},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
