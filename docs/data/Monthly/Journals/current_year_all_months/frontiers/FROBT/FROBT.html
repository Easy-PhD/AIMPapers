<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt">FROBT - 186</h2>
<ul>
<li><details>
<summary>
(2025). Correction: Understanding consumer attitudes towards second-hand robots for the home. <em>FROBT</em>, <em>12</em>, 1694690. (<a href='https://doi.org/10.3389/frobt.2025.1694690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {INTRODUCTION First published in 2015, the United Nations announced 17 Sustainable Development Goals [UN SDG] as part of their 2030 agenda for sustainable development providing a "plan of action for people, planet and prosperity" UN2 (2015). SDG 12 aims to "ensure sustainable production and consumption patterns" to tackle the impacts of open loop consumption UN2 (2015). These impacts include climate change, biodiversity loss and deforestation, and pollution which harms people, animals and habitats UN2 (2015); Dauvergne and Lister (2010); Carlisle and Hanlon (2007). With 80 percent of a product's environmental impact decided during the design and development phases of a product's life cycle Charter (2019) and human open-loop consumption impacting so heavily on climate change Łukasz Kurowski et al. (2022), building sustainable consumption patterns requires the buy-in and leadership of the product manufacturers to develop systems which are better suited to closed-loop consumption, also referred to as the 'Circular Economy'UKR (2021); Elzinga et al. (2020). Many electronic product manufacturers rely on the concept of recycling as a method to tackle open-loop consumption. However, across the globe, there is evidence of huge inefficiencies in the process of recycling. Globally, in 2019, only 17.4 percent of electronic waste created annually was recycled through formally managed systems Forti et al. (2020). Individuals living within the EU produce the highest levels of e-waste globally at 16.2kgs per capita per year Forti et al. (2020). Recycling rates are also highest in the EU, though rates only reach 42.5 percent Forti et al. (2020). In comparison, annually (in 2019), individuals in Oceania produce 16.1 kgs per capita and recycled 8.8 percent, in the Americas they produced 13.3 kg per capita and recycled 9.4 percent, Asia produced 5.6 kg per capita and formally recycled 11.7 percent, while in Africa per capita, e-waste production annually was 2.5 kg and recycling rates were 0.9 percent Forti et al. (2020). Consumer robots, generally being systems which require electrical current or electromagnetic fields to meet their functional purpose, could be considered as Electronic or Electrical Equipment [EEE] under the current standard accepted definition 200 (2003). Therefore, when a consumer robot reaches the end of its useful life it will also then be classed as Waste Electronic or Electrical Equipment [WEEE], also known as e-waste. And, taking the global data for recycling rates of other electronic products, it would be reasonable to assume that, without specific intervention from the robotics industry, recycling rates for robotic systems will be similarly low to those seen for other types of e-waste due to the consistently poor actions and habits of the general population in managing e-waste from the home. Alternatives to recycling and landfill for robotic systems are; repurposing, reusing, remanufacturing, reconditioning and repairing the systems at the end of their primary life. These options extend beyond the traditional 3 R's: Reduce, Reuse, Recycle HMG (2018), recognising the additional alternatives of Repair, Reconditioning, Remanufacturing and Repurposing. Reuse, recondition and repair are well-established processes; remanufacturing is a less common but well-documented method outside of the robotics industry for breaking down a system to component level and rebuilding it as new Nasr (2019); Steinhilper (1998); Steinhilper et al. (2017); while repurposing is a new concept for robotic systems which is under investigation by the authors of this paper McGloin et al. (2023). Each of these alternative methods to recycling aims to increase the working life of a product, which in turn reduces waste production by delaying the time until the system needs to be recycled or sent to landfill, and forms the basis of a circular economy (UN SDG #12). In addition to this, the forming of a circular economy for robotic products for domestic settings will also; increase accessibility to technology through opportunities for lower-cost second-hand systems (UN SDG #8); reduce deforestation of land used for mining materials needed for production (UN SDG #15) and reduce emissions associated with the production of electronic products such as robots (UN SDG #13). However, a critical element in making a circular economy viable lies in the participation of consumers in this business model and the ability to sell the resultant second-hand product to customers Elzinga et al. (2020). Consumers often require both push and pull influence factors to be in place to overcome established habits and be persuaded to purchase second-hand over new products Hazen et al. (2017). Push factors include the opportunity to purchase second-hand products at favourable rates to new ones, and the introduction of laws driving consumer habit changes. Pull factors might include tax breaks, government-or business-led incentives, and the purchaser's personal perspective on environmental issues Hazen et al. (2017); Łukasz Kurowski et al. (2022). Additionally, social media may create both push and pull influence factors for consumer purchasing habits. The aim of this study, therefore, was to assess the difference in consumer attitudes towards the purchase of new and second-hand robotic systems for domestic settings and to identify key factors which could progress or hinder the uptake of second-hand robots amongst potential users of robots for the home. This research was carried out using a survey method described in Section 2. Understanding potential consumer behaviours towards second-hand robotic systems provides an opportunity for researchers, developers and manufacturers of robots for the home to build more sustainable practices into the products they create before they become ubiquitous. Once in an accepted ubiquitous state, lock-in factors inhibit changes by both consumers and the Original Equipment Manufacturers from easily making more sustainable practice choices Aminoff and Sundqvist-Andberg (2021); Mac (2023). Additionally, the results of this research are part of a wider program which is also investigating the attitudes of the robotics industry towards sustainability, and the reuse and repurposing of robotic systems. The results of the industrial attitudes research will be presented in a separate paper. METHODOLOGY 2.1 Research Aim The aim of this research was to assess consumer interest in second-hand robots - such as those which have been reconditioned or repurposed, in comparison to new systems, and to identify key factors which could affect the uptake of second-hand systems. In order to meet the aims of the study, an appropriate research philosophy was selected (Section 2.2) which influenced the development of the study design (Section 2.3). Data was then collected (Section 3) and analysed (Section 4), with conclusions being presented in Section 5. 2.2 Research Methodology Saunders et al. (2019) present the 'research onion' (Figure 1) which summarises the methodological choices, strategies, data collection and analysis methods, which together form the widely accepted methodologies used in research strategies. The methodologies utilised in this research were; An Inductive research approach due to there being limited existing data available from the robotics field that could produce a theory which might, in turn, validate or invalidate a hypothesis based on the data collected. A survey method for data collection was selected as very few people already own robots, so observational data could not be collected for the purpose of this research. Instead, data collection relied on participants' opinions based on the information provided to them and utilised a Likert Scale system with free-text open-response questions for additional participant responses. Likert Scales were selected because they are easy for participants to use, resulting in increased response rates and reliability Jupp (2006). Quantitative analysis methods were selected for the Likert Scale survey data which was then transcribed from ordinal data to interval data during the analysis process. This transcription allows for the conversion of the opinions of participants into numerical-based data Fleetwood (2014). Figure 1. The 'research onion' (pg 130 Saunders et al. (2019). Source: Saunders MNK, Lewis P and Thornhill A (2019) Research methods for Business Students (8th edition) Harlow: Pearson: p 130. The research onion is © 2018 Mark Saunders, Philip Lewis and Adrian Thornhill and is reproduced in this article with their written permission Qualitative analysis methods were selected for the analysis of the free-text survey responses via Thematic analysis which aims to understand the core themes presented both in a participant's individual responses and also between participants' responses Bryman (2016). 2.3 Study Design Following the selection of the research methodology (Section 2.2), a survey was developed which was designed for access by the general public via the Qualtrics online platform. The survey was divided into the following sections: • Demographics and lifestyle factors - individuals were required to provide demographic data such as age range and country of residence, alongside a broad range of personal lifestyle indicator factors that the research team felt could influence the likelihood of uptake second-hand robotics. These lifestyle factors included attitudes to environmental topics, home ownership status, prior ownership of robotic systems in the home, uptake of internet-enabled technology devices in the home and previous purchasing decisions for home technology. In this survey, internet-enabled devices were defined as a device which requires connection to WiFi or mobile data in order to function, but does not include mobile phones, laptops, computers or tablets. All questions in this section provided participants with multiple-choice options for their responses. A concentration test question was also placed at the end of this section, to reduce the effect of random selection responses. • Purchasing attitudes - participants were presented with a variety of robot types that could possibly be purchased in the future via different purchasing conditions; new, second-hand with a guarantee, and second-hand without a guarantee. For each robot type, a short description was given, and examples were also provided (see Figure 2). Participants were then asked for their opinions on if they would or would not be inclined to purchase the robots in the different purchase conditions. The proposed robot types included; robots used to provide security, perform household chores, to have as pets, work Figure 2. Types of consumer robots presented to participants in the online survey, along with examples of each robot type. Note, graphic not used in survey, only wording. as personal assistants, and act as health and fitness instructors. Participants were asked to respond to questions using a 3-point Likert Scale to demonstrate their interest in a given system. • Concern factors - for each purchase condition, (new, second-hand with a guarantee and second-hand without a guarantee) participants were asked to rate their concern levels on a 5-point Likert scale for factors including cost, security, environmental impact and safety. The 5 -point Likert Scale gave participants the option to respond Very Concerned, Slightly Concerned, Neutral, Slightly Unconcerned and Unconcerned for a given factor. In addition to this, a free-text answer box was provided to collect additional comments from participants. Lastly, the participant survey design included the presentation of a downloadable participant information sheet and a data privacy policy. 2.4 Data collection and analysis procedure The participant study gained ethical approval through the University of West England. Following this, the study was shared through both social media platforms and via surveycircle - a website for finding survey participants. The survey was open to any individual who was over the age of 18 years old and consented to take part in the research. The responses submitted by participants were checked and rendered anonymous after 7 days. Excel was used to analyse the demographic and Likert scale data, while NViVo was utilised for the analysis of free-text responses. The Nvivo analysis followed a Thematic approach (as described in Section 2.2). The method to complete the thematic analysis within Nvivo was: • Phase I – Open Coding: this required the line-by-line analysis of raw data (from the survey free-text responses) to draw out concepts presented within the data Khaksar et al. (2015); Charmaz (2006). The purpose of this phase was to find meaning and actions behind the words given by the participant. Each concept was labelled (referred to as a code), to enable repeating concepts to be highlighted under the same code Hutchison et al. (2010). At this stage it was expected that as wide a range of coded concepts be identified as possible since fitting answers under pre-existing data labels would limit the analysis and stop new ideas from emerging Charmaz (2006)). The codes were considered provisional and could be amended at any time. The overall aim was to "make the codes fit the data" rather than "forcing the data to fit" the codes Charmaz (2006). • Phase II – Thematic framework: during this phase, codes were grouped into categories and sub-categories and the links between the codes which form categories were noted Khaksar et al. (2015). In this way, the data which was analysed at a line-for-line level in the open coding was brought back together and reassembled by identifying the connections between the codes Hutchison et al. (2010), thereby highlighting the key themes in the research. 2.5 Participant demographics and Lifestyle factors A total of 111 individuals responded to the online survey, including responses from 16 individuals who did not fully complete the survey and whose responses were removed from further data analysis. Of the remaining responses, 72 were from individuals in the UK and 23 were from individuals outside of the UK. Those responses from individuals outside of the UK covered 9 different countries and, for the purpose of the study presented within this paper, were not included in the data analysis set due to the small sample size. Age group (years) 18-25 26-35 36-45 46-55 56-65 66-75 76+ Survey Participants, n=72 13% 29% 21% 11% 18% 7% 1% UK Population Sta (2021) 11% 17% 16% 16% 16% 13% 12% Table 1. Percentage of population in each age group (listed in years) Of the 72 responses from UK residents carried forward for analysis, 60 percent of participants were female, compared to 51 percent of the UK populationGov (2018). A comparison of the age demographic of the survey participants versus the UK population is shown in Table 1. The age group with the greatest over-representation in comparison to the UK population was those aged 26-35, while the greatest underrepresentation was in the 76+ age group which highlights the limitation of using online platforms to both advertise and complete the survey. Additionally, the participants for the study represented the following demographics: • Home ownership rate - 67 percent of participants lived in owned (with or without a mortgage) accommodation, versus 63 percent of people in the UK Gov (2020). • At-home dependants - 29 percent of participants lived in homes with children under the age of 18 in them, compared to 45 percent of people in the UK living in households containing one or more dependant child ONS (2022). • Climate emergency beliefs - 96 percent of participants who completed the survey selected that they believe there is a climate emergency, versus 71 percent in the general UK population Booth-Dale (2022). RESULTS 3.1 Purchasing habits by consumers for non-robotic products To better understand the attitudes of participants towards second-hand robots, prior electronic purchasing habits were investigated as part of the participant demographics. Excluding mobile phones and laptops, Figure 3. Conditions which participants bought other electronic items participants were asked for the number of internet-enabled devices in their homes. The results of this are shown in table 2. Number of internet-enabled devices zero 1-3 4-6 7-9 10+ Percentage of participants (n=72) 15% 47% 21% 4% 13% Table 2. Numbers of Internet-enabled devices in the homes of participants The majority of participants (47 percent) owned one to three internet-enabled devices in their homes, while only 15 percent did not own any internet-enabled devices. Those without internet-enabled devices were generally women (23 percent of the women surveyed did not have internet-enabled devices in the home compared to 4 percent of men). Participants' willingness to purchase second-hand electronics was established through survey questions which required them to identify the condition in which they last bought a given type of electronic device (Figure 3). Purchase of electronics second-hand with guarantees was highest for the items in which there are multiple outlets available to make that type of purchase, such as mobile phones and laptops. Overall, second-hand purchases (with or without a guarantee) accounted for 23 percent of mobile phone purchases, 22 percent of TV or games console purchases, 18 percent of laptop or computer or tablet purchases, 10 percent of internet-enabled security devices and 9 percent of thermostat purchases. The only category where no participants had bought second-hand devices was the smart assistant devices (such as Amazon Echo or Google Home). Ownership levels for the different electronic devices varied, with all participants owning a mobile phone and only a single participant not owning a laptop, computer or tablet. 17 percent of respondents indicated they had not purchased a TV or games console, with 27, 59 and 70 percent of participants respectively indicating they had not purchased electronic thermostats, smart assistance devices and internet-enabled security devices. It should be noted though that TV ownership in the UK shows only 3 percent of households in the UK do not have a TV Sta (2022) compared to the 17 percent of survey participants. However, Sta (2022) statistics do highlight that only 70 percent of UK households own a smart TV. It is possible that either the participants had lower TV ownership than in comparison to the UK, or, more likely, that the writing of the survey did not highlight that the TV did not need to be internet-enabled and this requirement was assumed by participants due to the prior question on internet-enabled devices. Consumer attitudes towards purchasing of second-hand robots Across all robot types presented to participants, 27 percent of participants indicated they would purchase a robot new, 27 percent would purchase one second-hand with a guarantee but only 10 percent would purchase one without a guarantee. The specific type of consumer robot presented to the participants affected the indicated purchase rate, with the highest interest seen for household chores robots at 64 percent for a new system, and the least interest was shown for a second-hand pet robot without a guarantee at 3 percent of participants indicating they would be willing to purchase such a system. In Figure 4 the purchase indication rates for each robot type and condition are presented. Figure 4. Purchase indication by participants for a given robot type, based on the purchase conditions: New, Second-hand with guarantee [2nd w guarantee], Second-hand without guarantee [2nd w/o guarantee] For each demographic and lifestyle factor surveyed, the percentage of participants in each group indicating they would purchase a robot for a given sale condition is shown in Figure 5a, and is detailed in the Supplementary Material along with numbers for participants responding they were 'unsure' if they would purchase a robot of a given category. Women were more likely than men to indicate a positive response towards purchasing a robot, regardless of the condition, and those without children were also more likely to purchase a robot in all condition types. Interest in the purchase of new systems new generally decreased with age, with a 52 percent interest for those aged 18-25 years, down to 11 percent for those aged 66+. Only those aged 36-45 did not follow this trend, with their interest levels being 4 percent lower than for 56-65 year olds. Individuals were also more likely to select that they would purchase a new or second-hand robotic system if they already owned a robot in the home (such as a vacuum cleaner or lawn mower) compared to those who did not. Figure 5a. Participants responding positively to purchase a robot in a given condition Figure 5b. Combined responses for participants responding positively and unsure to purchase a robot in a given condition Figure 5. Effect of demographics on participants responding if they would purchase a robot based on the purchase conditions: New, Second-hand with guarantee, Second-hand without guarantee. Notes: [a] Prior ownership includes vacuum or mower-type robotic systems for the home. [b] Numbers of internet-enabled devices includes connected devices already in the home] Generally, a +/- 3 percent difference was seen when comparing the attitudes of participants to new robots, to second-hand robotic systems with guarantees. Exceptions to this were for those aged 18-25 which had a drop of 11 percent between new and second-hand with guarantee, the age category 66+ years which saw an 8 percent increase, prior ownership of robots which had a 7 percent increase and those with 7 or more internet-enabled devices in the home which had a 6 percent increase respectively. Across all factors and purchase conditions investigated the most popular type of robot was a robot for household chores, generally followed by robots for security systems. Only in the second-hand with no guarantee condition were robotic security systems not the second-place preference option. Instead no trends were found shown in the responses across demographic factors for this condition, beyond the initial preference by participants for household chore robots. Combining the positive and neutral responses (Figure 5) resulted in response rates of over 40 percent for new robots in all demographic categories except those aged 56-65 and 66+. The same trend was seen for second-hand robots with guarantees but with the addition of those who have 1-3 internet-enabled devices in the home having a response rate of 39 percent. 3.3 Concern factors for consumers when purchasing second-hand robots In addition to providing purchase indicators, concern factors recorded on a Likert scale were provided by participants. The response options were very concerned, slightly concerned, neutral, slightly unconcerned and unconcerned. Table 3 summarises the percentage of respondents selecting Very or Slightly concerned for each factor. The breakdown of the remaining Likert scale responses is given in the Supplementary Material. Purchase New Secondhand with guarantee Secondhand no guarantee Cost of purchase 90% 88% 76% Cost to maintain 83% 89% 92% Physical safety for people in the home 56% 67% 69% Physical damage to the home 58% 64% 71% Data security for people in the home 85% 90% 86% Manufacturing environmental impact 72% 63% 65% Environmental impact of disposal 82% 78% 72% Table 3. Percentage of participants selecting 'Very concerned' or 'Slightly concerned' for each factor described, based on a robot's sale condition Those who own robots were generally less concerned by these factors than those who did not own robots. The greatest difference in responses of very or slightly concerned to new, second-hand with guarantee, and second-hand without guarantee was for the factors: • Physical safety for people in the home (19, 32 and 35 percent difference respectively) • Physical damage to the home (22, 17, 24 percent difference respectively) The only instances where those who own robots had a greater level of concern shown than those who did not own robots were; the cost to maintain second-hand robots without guarantees (10 percent higher), the security of personal data and the environmental manufacturing impact on new robotic systems (6 and 8 percent higher). Figure 6. Graph of the number of coding references for each theme identified during the qualitative analysis Of the 72 participants in the study, 19 provided responses in the free-text sections of the survey requesting additional comments relating to concerns which had not been highlighted in the Likert Scale responses. Qualitative analysis of those free-text responses from participants identified over 32 additional areas of concern (codes), which together formed 8 key themes: • Concerns about the appearance of a robot • Concerns around the purchasing source and guarantees for robots • Concerns about the cost of a robot across its life-cycle • Negative effects of robots on people during the robots use • Concerns relating to the technical capability of robots • Concerns around data security and privacy for robot owners • People not wanting, or not able, to operate robots • Impacts on society of greater robot use Figure 6 summarises the number of references given for each of the themes identified, split by the condition of purchase. The theme with the greatest level of responses was those not wanting or not able to operate robots with comments from participants including; "I can't imagine a circumstance where I would buy a new robot for my home." [Participant #22], and concern about the purchase being "complicated operation or setting up of a unit" [Participant #25]. For new robots, the second greatest number of responses were related to the technical capability of the systems purchased. Comments within this theme included: "Could it cope with an old cottage with uneven floors" [Participant #18] and "How well would it actually do the job I purchased it to do?" [Participant #38]. For second-hand robots, both those with a guarantee and those without, respondents' key concern centred on the purchasing source, continued support for the systems and guarantees relating to the second-hand product. Examples included; "problems with robot not identified or lied about" [Participant #59, comments for second-hand robots with no guarantee], "Spares and support. Mobiles are only supported for a few years. Given the likely cost of a robot I'd want 15 years or more, like cars." [Participant #9, with guarantee], and "Credibility and viability of the organisation supporting product/guarantee" [Participant #56, with guarantee]. A variety of factors relating to cost were highlighted in the responses across all three robot conditions (new, second-hand and second-hand with guarantees), with concerns about ongoing maintenance, energy consumption and resale costs highlighted. Participants' comments relating to the cost of systems included; "whether I would use it enough to justify buying it" [Participant #19, new robots], "I could be spending a lot of money and have no means of refund or exchange if the robot went wrong or ceased to work." [Participant #38, second-hand no guarantee robots], "device energy consumption" [Participant #2 - new] and "cost of software updates" [Participant #20 - both new and second-hand with guarantee robots]. 3.4 Comparison of purchasing indications for robots to other electronic products Participant responses regarding concern levels for environmental issues were compared to robot purchasing conditions (shown in Figure 7). Those who indicated concern for e-waste levels were less likely to respond positively about purchasing new and second-hand robot products than those who indicated they were neutral towards concerns about e-waste. In comparison, those who were concerned about plastic waste levels were slightly more likely to respond positively about purchasing new and second-hand robot products than those who indicated they were neutral towards concerns about plastic waste levels. It was not possible to compare these results to responses about concern levels for the Climate Crisis, Deforestation and Pollution as the numbers responding neutral or unconcerned to these topics accounted for only 4 percent of the respondents (or 3 individual participants). Future surveys would need to address the recruitment and self-selection process found in this research that resulted in the majority of participants having high concern levels for topics such as the climate crisis, and therefore making sample sizes for those responding neutral or unconcerned too small to review. Figure 7 also presents how the response by the participant on the last condition they purchased a mobile phone, laptop and games console affected their purchasing indications for robots in a given condition. Participants who had bought games consoles second-hand without a guarantee were more likely to positively respond to purchasing a robot in any condition type, while the opposite was true for those buying laptops new who had a higher robot purchase indication rate than for those who bought laptops refurbished with guarantees. Supporting data for all figures included in section 3 is included in the Supplementary Data. DISCUSSION 4.1 Consumer attitudes towards purchasing of second-hand robots Consumer attitudes towards the purchase of second-hand robots with a guarantee matched interest levels for new systems at 27 percent, while only 10 percent of participants indicated a purchase possibility when there was no guarantee offered. Equal favourability for new and second-hand with guarantee robots does suggest that there is an opportunity for the sale of systems in both conditions. To enable the sale of second-hand systems though, vendors require the return of old systems at the end of their life requiring the industry to consider this in their business models. Elzinga et al. (2020) presents research into three business models for the electronics industry consumer circular economy; take-back management, product Figure 7. Effect of environmental lifestyle factors on participants responding if they would purchase a robot based on the purchase conditions: New, Second-hand with guarantee, Second-hand without guarantee. lease and pay-per-use, with take-back management the most popular option with consumers. The take-back management business model requires businesses to re-obtain ownership of products through collection points, with consumers incentivised to take part through payment schemes or fees Elzinga et al. (2020). This suggests that use of a take-back management scheme within the robotics industry will result in additional sales for robot manufacturers through the reconditioning and resale of second-hand systems, enabling a more circular economy. The success of a take-back management scheme for the robotics industry would require easily accessible return points and well-communicated returns processes. These are particularly important to the electronics industry, where long-term storage of small household electronics regularly occurs and is a key barrier to electronics recovery Wilson et al. (2017). This process, also referred to as the hibernation phase of electronics ownership Murakami et al. (2010), is a well-documented consumer behaviour in developed countries. 70 percent of consumer e-waste was placed in hibernation for three to five years by consumers in the US Babu et al. (2007), while consumers in the UK stored mobile phones for an average of 3 years Wilson et al. (2017), and in a study of residents in a city in Finland - 70 percent of participants retained their mobile phone for a period of time after they had no primary use for it in a study Yl¨a-Mella et al. (2015). When considering the different types of robots presented to participants, interest was highest for robots which were able to complete household chores, followed by robots performing security roles. Overall interest levels amongst participants for new and second-hand with guarantee robots for chores were 62 percent and 58 percent respectively, while security robots had interest levels of 37 and 32 percent respectively. These results are comparable with the Nitto et al. (2017) study found that 50 percent of consumers in the US were interested in robots that would help with either household chores or security. This study did find though that levels of interest varied by country of residents, with 34 percent of residents of Germany and only 19 percent of residents from Japan indicating they would be interested in purchasing a robot within the next 5 years. Robots used as pets were the least popular across all sale condition types, with a second-hand pet robot with no guarantee interesting only 3 percent of respondents. This was followed by robots for entertainment which had similar rates for new and second-hand with guarantee systems as pet robots, but a slightly higher interest in second-hand systems at 7 percent. Again, the Nitto et al. (2017) study noted that "when it comes to leisure, time spent with friends or caring for pets and children, American consumers are noticeably less interested in being involved with robots", confirming the findings of this study. Only robots used for entertainment, or for health & fitness, saw the rate of interest increase for a secondhand robot with a guarantee over a new robot, with the remaining categories seeing a decrease between the buying conditions. It is possible that due to the second-hand market for non-robotic technologies for both entertainment and fitness already being well established, there is a greater openness amongst participants to see second-hand robots in these sectors. Demographics which most influenced a survey participants' interest in purchasing new robots were age and prior ownership of robotic systems such as vacuums or mowers. 60 percent of those aged 18-25, and 37 percent of those previously owning a robotic system would purchase a robot new. Only those aged 66 and over were more likely to show an interest in purchasing a second-hand system (with or without a guarantee) rather than a new system. These results differed from those in the P´erez-Belis et al. (2017) study on consumer attitudes in Spain towards second-hand EEE purchases for the home which found that older consumers and women were more likely to repair small household EEE, while men and those from medium-income families were more likely to purchase second-hand small household EEE. To better understand participants' responses to second-hand robots, this survey also reviewed their prior purchasing habits of internet-enabled devices such as mobile phones, games consoles, personal assistant speakers and internet-enabled security doorbells or CCTV. For participants in this survey, 22 percent had owned a second-hand mobile phone and, of those who owned laptops, games consoles, and internet-enabled security systems, the percentage who had those products second-hand was 18, 22 and 10 percent respectively. These results are consistent with data and research into the second-hand market for mobile phones. In 2016 second-hand smartphones accounted for 7 percent of the global sales market and was expected to see increases in sales 4 to 5 times quicker than new phones Del (2016). In addition, it has been well-documented that mobile phones are passed on to friends and family members outside of global sales, adding to the total number of second-hand devices in use. Wieser and Tr¨oger (2016) summarises that 13 to 28 percent of all smartphones are passed onto family members or charity at their replacement point. In comparison, overall purchase rates of other second-hand small household electronics has been shown to be much lower. Overall the P´erez-Belis et al. (2017) study found only 0.75 percent of participants had bought second-hand small electronics for the home at any time where the electronics in the study included items such as vacuums, blenders, toasters and kettles. Therefore, recognising that consumer attitudes in this study showed equal interest in purchasing new robotic systems to second-hand robots with guarantees, it may be possible for the robotics industry to aim for the higher levels of second-hand device sales seen for internet-enabled devices such as mobile phones and game consoles than for the lower rates seen for standard electrical household goods. The results of this survey were not able to show a direct relation between participants who had previously bought other second-hand electronics, and those more willing to buy second-hand robots. This may be due to ownership levels of robots for the home being so low still that the responses of participants were not influenced by their attitudes towards other types of second-hand electronics. 4.2 Concern factors for consumers when purchasing second-hand robots In the Yl¨a-Mella et al. (2015) study of consumer perceptions towards second-hand mobile phones, concerns raised by participants as reasons for not purchasing second-hand mobile phones included reliability of the product (47 percent of respondents), short life-cycle (32 percent), availability of existing budget models (32 percent) and lack of warranty (16 percent). In comparison, this study yielded much higher concern rates, with concerns rates as high as 90 percent relating to the cost of purchasing new robots. Of the factors assessed by the Likert Scale responses in the survey, the lowest concern rate was still for robots carrying out physical damage to the home but this was still at 56 percent for new systems. Comparing ownership rates for consumer electronics within this survey only 14 percent of respondents owned a robot for the home, while 100 percent of respondents had a mobile phone. This disparity in ownership, and the relative newness of the robotics market will likely have affected concern levels for the robotic systems compared to other electronic devices. It should be noted though that even amongst robot owners in this survey, concern levels remained high, with their concern rate being 6, 8 and 10 percent higher than for those without prior robot ownership for factors of security of personal data (new), the environmental impact of manufacture (new) and cost of maintenance (2nd-hand without guarantee), highlighting the current realities of robot ownership. Participants of the survey indicated the same levels of concern toward cost for both new and second-hand systems. This suggests that consumers may need to recognise significant cost advantages in secondhand robots in order to purchase them over new. This is reflected in the findings of Hazen et al. (2017) which highlights the need for push factors to influence the uptake by consumers in purchasing of other manufactured technology goods. In addition to push factors affecting consumer choice in the purchase condition of electronics, pull factors such as the individual perception of environmental concerns can influence the uptake of second-hand goods Hazen et al. (2017). In this survey, 97 percent of the respondents agreed there was a climate emergency. This resulted in a too-small sample size for those that do not believe there is a climate emergency in order to compare the two demographics. However, across the survey participants, levels of concern decreased when participants considered the environmental impact involved in the manufacture of new to second-hand and second-hand without guarantee condition robots. Where consumers show a greater understanding of climate change and its impact, consumers are more likely to partake in a pro-climate consumer society Łukasz Kurowski et al. (2022). The results of this survey suggest highlighting the reduction in manufacturing impact through the reuse of robotic systems should result in positive consumer behaviour towards these second-hand products. It should be noted though that in comparison, concerns about the environmental impact of disposal increased across the purchase conditions. The researchers were not able to conclude from the data why this environmental concern had an opposite result to the manufacturing concern factor. Further investigation would be needed to understand this result. Further to the responses from the Likert Scale concern factors, the qualitative results raised additional concerns by participants around the performance of new and second-hand systems, maintainability of secondhand systems, and methods of insurance and liability of systems without a guarantee. The topics raised as additional areas of concern in the qualitative analysis revealed that some topics were universal to robots in the home, regardless of the purchasing condition. This included the performance of the robots, and more fundamentally, trust in any robotic system coming into the home. Much as Miglani and Hensman (2016) highlights the ethical and technical considerations for software used in robots in the home, participants of this survey raised concerns regarding data security. The number of such concerns increased for second-hand systems and included issues around software obsolescence, the introduction of viruses and access to prior owners' data. The theme of obsolescence was also raised in relation to the physical system, and the effect that buying a second-hand system might have on access to upgrades and the associated costs of upkeep. These concerns were in line with findings from research into other types of second-hand electronics. The P´erez-Belis et al. (2017) study found reasons for not purchasing second-hand electronics included cleanliness and hygiene concerns, minimal cost savings for second-hand systems over new, lack of knowledge of where to purchase second-hand devices, lack of repair guarantees and perceptions of low durability for second-hand systems. With many of these themes also appearing in this research, findings from other consumer electronic studies can be used to influence the robotics industry too. While this study has placed emphasis on the role of the robotics industry in creating and maintaining a circular economy for products, inaction by consumers must still be considered. P´erez-Belis et al. (2017) notes that while product ecodesign is central to a circular economy and requires manufacturers to design more 'durable, easier to repair, reuse or recycle products', attitudes of consumers towards electronics at the end of their primary life must also be tackled. General consumers will either dispose of the e-waste in the bin instead of through dedicated WEEE recycling bins or schemes due to the relatively small size of many EEE products, or they will store the e-waste at homeP´erez-Belis et al. (2017). This tendency for incorrect management of electronic waste at the end of its life was highlighted in the introduction to this paper (Section 1. The qualitative analysis highlighted a number of participants who registered no interest in purchasing any robotic system for the home, regardless of buying condition. It is inefficient to work towards creating solutions for those unlikely to ever purchase a robot, let alone a second-hand robot. Fiorini et al. (2022) describes how participant curiosity in the technology supports greater uptake of participants; addressing this in future studies, for this topic may provide a greater and more instructive yield in results. 4.3 Evaluation of the surveying process Reviewing the outcome of the participant demographics it was noted that participants with children in the home, those aged 66 and over, and those who do not believe there is a climate emergency were underrepresented in this survey in comparison to the UK population. This is a reflection that this survey partially relied on convenience sampling methods Bryman (2016) - where participants were those most available to the research team, in this case, through the publication of the request for participants via social media channels. This will likely have resulted in a more homogeneous demographic than a quota sampling system that would have produced Bryman (2016). Some effort was taken to widen the scope of participants through the use of the online Surveycircle platform, however, this platform is generally used by students and researchers, again resulting in some homogeneous traits and self-selection for participation based on interest in the topic. Results presented in Section 3 cannot, therefore, be generalised to be representative of the UK population, but do form indicating factors which was the requirement of the research process. There were higher response levels for comments for the new robot purchase condition than second-hand conditions, despite concern levels being higher in the Likert scales for second-hand. This suggests that either the Likert Scales better-encapsulated concern factors for participants or participants spent time considering responses for this category and may not have wanted to repeat themselves for the other conditions. Only in one example did the respondent choose to copy and paste their response from one robot condition to another. The survey design for the free-text component section of the data collection could have therefore been improved by providing participants with the option to indicate the responses additionally applied to other conditions of purchase. Additionally, with limited numbers of free-text responses, motivations for purchasing habits were not explored in great detail in this paper. Future surveys could utilise follow-up interviews or additional questioning to improve on the use of free-text comments in this survey design. While Likert Scales were used in the survey due to their ease of use and expected increased response rates, issues with using these types of scales include response acquiescence and social desirability. Acquiescence results in participants selecting results which they think are the correct answer, while social desirability causes users to select responses that make them look better for greater social acceptance Jupp (2006). Social desirability bias is often higher in surveys with an interviewer present which this research limited by utilising an online platform for data collection, however, topics around sustainability and the environment have known ethical and moral sensitivities Roxas and Lindsay (2012) which will likely have influenced participants responses. Lastly, due to the small number of participants who submitted survey data outside of the UK, only responses from those in the UK were carried forward. Bernotat and Eyssel (2018) highlighted the effect of different cultures (Japanese and German) on the perceptions of robots in the home and attitudes while Nitto et al. (2017) studies demonstrated the differences in projected purchasing habits for consumers in the US, Japan and Germany. Future studies should therefore compare attitudes to second-hand robots for participants outside of the UK. CONCLUSION Taking survey data from 72 UK participants, around a quarter indicated a positive interest in purchasing a new robot for the home. When presented with second-hand robots with guarantees, this figure did not change. However, when the option of second-hand robots without a guarantee was introduced this was reduced to 10 percent. This highlights the need for recognised certification methods or manufacturer warranties in order for robots to be successfully sold in the second-hand market. Young people aged 18-25 indicated a significantly higher interest in robotic systems than any other age group. Whether this is a factor of the participant's age at the time of the survey or the generation of which they are part is unclear from this single snapshot survey. However, paired with higher interest levels in the robots presented to those who have prior experience in ownership of robotic systems, this suggests an affinity for, and greater experience with, smarter devices in the home will form key drivers for individuals being willing to purchase a consumer robot. Current trends comparing second-hand purchases of household electronics to second-hand purchases of mobile phones suggest that the second-hand robotics market will be more similar to that of internet-enabled devices such as smartphones, than for household electronic devices - even where the robot will be used as a device for the home. By studying the growth of the second-hand mobile phone market and the challenges it has faced, the consumer robotics industry will be able to preempt the requirements that will likely be faced in trying to support the circular economy and tackle those at a time when it is cheaper in the technology maturity process to do so. However, it should be noted that the experience of prior ownership of other types of second-hand electronic devices (such as phones, laptops and game consoles) did not increase the participant's level of interest in second-hand robots. It is therefore possible that robotic technology for the home is too new or unknown for individuals to be able to make comparable decisions between purchasing the experience for other second-hand electronics to the projected experience of owning a robot. Instead, participants felt the initial purchase cost of any system was the greatest concern for new and second-hand robots, while the cost to maintain was the greatest concern for second-hand robots without guarantees. Additionally, attitudes to second-hand robots generally highlighted concerns for maintainability, verification and certification, technology obsolescence and liability in the event of damage to a person or home. In order to make the second-hand robot market attractive for consumers, these issues would need to be addressed and resolved, alongside a system to provide guarantees for second-hand systems. Even with these concerns though, individuals still indicated they were willing to purchase second-hand systems. Overall this survey is encouraging for the wider implementation of the circular economy and demonstrates that there is a market for second-hand robotic systems for the home. To enable this, processes must be in place to retain consumer robots at the end of their primary use, in order to bring them into the second-hand market. As demonstrated with other electronic devices, this may require incentivisation (such as buy-back schemes), and accessible methods for consumers to return used robotic systems. Manufacturers, retailers and public systems not supporting this process will likely result in the discarding of old robots as e-waste, adding considerable levels of waste already produced annually.},
  archive      = {J_FROBT},
  author       = {McGloin, Helen and Studley, Matthew and Mawle, Richard and Winfield, Alan Frank Thomas},
  doi          = {10.3389/frobt.2025.1694690},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1694690},
  shortjournal = {Front. Robot. AI},
  title        = {Correction: Understanding consumer attitudes towards second-hand robots for the home},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Advancements in vibration control for space manipulators: Actuators, algorithms, and material innovations. <em>FROBT</em>, <em>12</em>, 1681168. (<a href='https://doi.org/10.3389/frobt.2025.1681168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Editorial on Research Topic Space manipulators play a pivotal role in modern space missions, enabling satellite servicing, debris removal, and planetary exploration. However, their lightweight, long-reach designs and dynamic operational environments introduce significant vibration challenges that can compromise mission success. Addressing these challenges requires a multidisciplinary approach, integrating advancements in actuators, control algorithms, and material science. While conventional actuators (Liu et al., 2021; Tayebi et al., 2022; Mishra et al., 2018) and attitude control strategies (Ti et al., 2019; Tayebi et al., 2025; Xie et al., 2025) remain prevalent in spacecraft design, emerging solutions leveraging soft materials and AI-driven control architectures represent a rapidly evolving frontier in vibration mitigation research. This Research Topic provides the most recent developments in vibration mitigation techniques for space manipulators, including four important studies as result of the call. These studies cover several aspects of vibration through flexible dynamics estimation via quasi-static approximation, AI-enhanced guidance and control systems, bio-inspired soft actuation, and hybrid soft-rigid grasping architectures. Accurate measurement of elastic coordinates via sensors has historically posed significant challenges in controlling flexible space manipulators. Patel and Damaren addressed this by developing a model-based estimation framework, eliminating the need for direct vibration sensing. They proposed a quasi-static estimator that approximates elastic coordinates with joint torque data, enabling precise end-effector trajectory tracking. Their simulations on single and two-link manipulators demonstrate robust performance, even with large payloads and model uncertainties. Conventional spacecraft Guidance, Navigation, and Control (GNC) systems, designed for ground-commanded operations with limited autonomy, face significant challenges in adapting to the dynamic demands of on-orbit servicing missions. Addressing this gap, Hao et al. proposed an AI-enhanced visual GNC system as an intermediate solution between conventional architectures and future fully autonomous systems. Their approach combines a deep learning-based algorithm that estimates target pose from 2D images without requiring prior knowledge of the target's dynamics, and a learning-based motion planner that generates manipulator trajectories while minimizing spacecraft attitude disturbances. The visual GNC system is exemplified through simulation of a conceptual mission, involving a micro-satellite tasked with on-orbit manipulation of a non-cooperative CubeSat. Figure 1 illustrates the design of the intelligent orbital service spacecraft and delineates the conceptual mission framework for capturing and servicing a non-cooperative target. Their work demonstrates the potential of AI to enhance autonomy in space robotics, particularly for non-cooperative target capture. FIGURE 1 Left: The design of the intelligent orbital service spacecraft. Right: The conceptual mission framework (Hao et al.). Actuators play an important role in controlling of space manipulators. Ashby et al. introduced bio-inspired soft actuators using dielectric elastomer transducers (DETs) as lightweight artificial muscles for space applications. Inspired by the starfish podia as shown in Figure 2, their inflatable DET-based actuator combines deployable structures with proprioceptive capabilities, enabling compact stowage during launch and adaptive operation in zero-gravity environments. The study highlights the advantages of soft robotics in space, where mass and volume constraints are critical. These actuators show particular promise for applications requiring adaptable, mass-efficient systems in unstructured orbital environment. FIGURE 2 Left: The basic structure of a typical starfish's podium (tube foot). Right: Close-up of a starfish on the sea floor, with podia in active motion (Ashby et al.). Dontu et al. discussed the development of a hybrid soft gripper for delicate object manipulation, validated through real-world robotics competitions. Their vacuum-actuated design integrates soft fingers with rigid components, and task-specific modules, balancing compliance and precision. By refining the gripper through successive iterations, the work demonstrates the importance of adaptable, hybrid designs for handling diverse objects in unstructured environments. These studies collectively illustrated three essential developments in space manipulator design through model-based estimation overcoming sensing limitations in orbit, AI-driven autonomy enabling real-time adaptation, and material and actuation Innovations. Looking ahead, the field must address key challenges in technology readiness levels and orbital validation, particularly for soft robotic components in space environments.},
  archive      = {J_FROBT},
  author       = {Tayebi, Javad and Chen, Ti and Wu, Xiaofeng and Mishra, Anand Kumar},
  doi          = {10.3389/frobt.2025.1681168},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1681168},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advancements in vibration control for space manipulators: Actuators, algorithms, and material innovations},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Computer vision mechanisms for resource-constrained robotics applications. <em>FROBT</em>, <em>12</em>, 1680098. (<a href='https://doi.org/10.3389/frobt.2025.1680098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {KEY CONTRIBUTIONS IN THE SPECIAL ISSUE In the evolving landscape of robotics, the challenge of deploying intelligent systems in real-world environments under limited computational and energy budgets has become increasingly important. The special issue of Frontiers in Robotics and AI—"Computer Vision Mechanisms for Resource-Constrained Robotics Applications", gathers a series of innovative contributions that directly address this challenge. The collection not only reflects the state of the art in efficient robotic perception, but also channels bio-inspired models, minimal computing principles, and hardware-constrained innovation to define a compelling path forward. The premise of the issue is grounded in a vital observation: although computer vision has reached extraordinary levels of accuracy and generalization through deep learning and high-performance sensors, these solutions are often tethered to expensive and power-hungry hardware and computationally complex algorithms. Autonomous robots intended for field deployment—whether aerial drones, underwater vehicles, or mobile ground units—frequently face bandwidth, energy, and compute bottlenecks. Thus, vision mechanisms designed with constraint-awareness are not merely desirable, but necessary. One prominent contribution to the issue is Singh et al.'s framework on minimal perception, which seeks to enable robotic autonomy by reducing perceptual complexity to its essential components Singh et al. (2024). Drawing inspiration from ecological psychology and AI, the authors design systems where perception is not treated as a comprehensive reconstruction of the world, but rather as a dynamic filter tuned to task relevance. The approach is validated through simulation and robot experiments, demonstrating that sparse and compressed sensory signals can support goal-directed behaviors such as obstacle avoidance and navigation with minimal computational overhead. Another standout is Van Opstal et al.'s biomimetic robotic eye, which introduces a six-degree-of-freedom platform capable of replicating human-like saccadic movements. The design merges active vision control Rui Pimentel de Figueiredo et al. with neurophysiological plausibility, offering both an experimental platform for neuroscientific hypotheses and a roadmap for embodied perception in robotics Van Opstal et al. (2024). The project brings to life ideas proposed in earlier models of oculomotor control, notably by Robinson and Sparks, but with real-time hardware precision and active visual fixation. Kalou et al. contribute with their work on head-centric representation of 3D shapes, reformulating shape perception as a process guided by an embodied fixation system Kalou et al. (2022). Their compact encoding scheme capitalizes on spatial priors gained from head-centered visual exploration, echoing Gibson's ecological theory of vision Gibson (1979) and early active vision paradigms. On the sensor innovation front, Ribeiro-Gomes et al. advocate for event-based cameras as foundational tools in embedded robotics. Their integration of asynchronous feature tracking into a visual-inertial odometry (VIO) framework demonstrates improved latency and energy efficiency compared to conventional methods Ribeiro-Gomes et al. (2023). These contributions collectively reflect a growing interest in both algorithmic minimalism and bio-inspired adaptation. FUTURE DIRECTIONS AND EDITORIAL PERSPECTIVE The research compiled in this issue reflects a broader shift in the field: away from monolithic perception pipelines and toward adaptive, embodied, and task-sensitive vision systems. A key theme is the resurgence of the perception-action loop, long emphasized by ecological psychology and active vision pioneers such as Aloimonos et al. Aloimonos et al. (1988) and Gibson Gibson (1979), but now reinvigorated through hardware-aware and task-constrained implementations. First, there is a growing recognition of the need for perception systems that dynamically adapt their computational load. Runtime-adaptive pipelines—capable of modulating neural network size, activation depth, or sensor resolution in response to context—could become essential for sustained autonomy in resource-constrained environments. Second, spiking neural models and neuromorphic circuits represent a biologically plausible and energy-efficient alternative to dense convolutional networks. This trend aligns with broader developments in transprecision computing and event-driven processing Delbruck and Lichtsteiner (2007); Sze et al. (2017), offering pathways for ultra-low-power robotics. A third frontier lies in the development of learning-based attention strategies. While classical attention mechanisms in vision prioritize computational saliency, emerging work explores end-to-end learning of attention policies that guide both perception and action. Reinforcement learning, meta-learning, and unsupervised learning strategies may enable robots to allocate their limited perceptual resources more effectively—particularly when paired with real-time hardware feedback on power and latency. Finally, the field would benefit greatly from standardized benchmarks designed specifically for resource-constrained robotics. While robust datasets exist for general tasks like SLAM or autonomous driving, few evaluate performance under explicit constraints such as degraded sensing, memory limits, or energy caps. Establishing such benchmarks could spur more targeted innovation and help consolidate this rapidly growing subfield. In terms of real-world impact, the relevance of resource-constrained perception extends well beyond research labs. In industrial robotics, especially in domains such as manufacturing, logistics, and infrastructure inspection, there is a growing demand for agile and power-efficient robots that can operate reliably in bandwidth-limited and dynamic environments. Many of these applications involve mobile Rui Pimentel de Figueiredo et al. platforms or wearable systems where energy and compute budgets are tightly constrained. Vision systems that adaptively throttle processing, or that rely on asynchronous and event-based sensing, are particularly well-suited for tasks such as real-time anomaly detection, autonomous warehouse navigation, and human-robot collaboration on production lines. Moreover, the advances discussed in this issue intersect meaningfully with the development of bio-inspired and humanoid robots. Platforms modeled after human morphology benefit immensely from perception systems that mimic the selective, task-dependent nature of biological vision. For example, the implementation of saccadic control, head-centric representation, and embodied attention strategies aligns naturally with the perceptual architectures found in humanoid robots. Such robots—whether designed for eldercare, physical rehabilitation, or disaster response—require lightweight and efficient perception pipelines that can operate within strict power, latency, and mobility constraints dictated by their human-centric form and mission requirements. CONCLUSION From biologically inspired eye movements to minimal perception frameworks and event-based feature tracking, the contributions point toward a future where efficiency and embodiment are not peripheral concerns, but rather central pillars of robotic intelligence, particularly as robotics moves further into industrial, assistive, and human-interactive domains. This special issue offers a compelling survey of the innovations shaping vision for resource-constrained robotics. From biologically inspired eye movements to minimal perception frameworks and event-based feature tracking, the contributions point toward a future where efficiency and embodiment are not peripheral concerns, but rather central pillars of robotic intelligence.},
  archive      = {J_FROBT},
  author       = {Pimentel de Figueiredo, Rui and Limberg, Christian and Jamone, Lorenzo and Bernardino, Alexandre},
  doi          = {10.3389/frobt.2025.1680098},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1680098},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Computer vision mechanisms for resource-constrained robotics applications},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of hotel robots’ service quality on continuance intention: The moderating effect of personal innovation. <em>FROBT</em>, <em>12</em>, 1667123. (<a href='https://doi.org/10.3389/frobt.2025.1667123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As service robots are increasingly integrated into the hotel industry to enhance operational efficiency and customer experience, understanding consumers’ responses to robotic services has become a critical research agenda. However, empirical evidence on how customers evaluate the service quality of hotel robots and how these evaluations influence their continuance intention remains limited. Drawing on the SERVQUAL framework, this study redefines service quality in the context of AI-powered hotel robots through five dimensions: reliability, assurance, entertainment, anthropomorphism, and tangibles. Furthermore, the study explores the moderating role of personal innovativeness in the relationship between perceived service quality and continuance intention. Data were collected via an online survey from 400 Generation Z consumers in China who had prior experience with item-delivery robots in hotel settings. The results indicate that assurance, entertainment, anthropomorphism, and tangibles have significant positive effects on continuance intention, while reliability does not show a statistically significant impact. Moreover, personal innovativeness significantly moderates the effects of certain service quality dimensions, suggesting that individual differences in technology readiness shape consumer reactions to robotic services. This study contributes to the literature by extending traditional service quality theory into the domain of human–robot interaction and by highlighting the nuanced mechanisms through which robot-specific service attributes influence user loyalty. Practical implications are offered for hotel managers seeking to optimize robot deployment strategies and improve guest engagement in technology-enhanced service environments.},
  archive      = {J_FROBT},
  author       = {Shi, Yaru and Zhan, Weifang and Lin, Chengpeng},
  doi          = {10.3389/frobt.2025.1667123},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1667123},
  shortjournal = {Front. Robot. AI},
  title        = {The impact of hotel robots’ service quality on continuance intention: The moderating effect of personal innovation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Avoidance behaviours of farmed atlantic salmon (Salmo salar l.) to artificial sound and light: A case study of net-pen mariculture in norway. <em>FROBT</em>, <em>12</em>, 1657567. (<a href='https://doi.org/10.3389/frobt.2025.1657567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensive finfish aquaculture is increasingly relying on enabling technologies and solutions such as sensor systems, robotics, and other machinery. Together with conventional farming equipment, these systems may emanate acoustic noise and artificial light, impacting the pen environment. Farmed fish have been observed to respond behaviourally and/or physiologically to anthropogenic sounds and lights, indicating a stress reaction that could impair welfare and health. This study aimed to investigate how farmed Atlantic salmon respond to such stimuli, with direct implications for the design and operation of robotic and mechanised systems in sea pens. We conducted experiments where we systematically exposed adult farmed Atlantic salmon in commercial net pens to sounds of frequencies within the range common to farm equipment (100–1,000 Hz), and submerged lights at 8 and 12 m with four different intensities (600 lx–14,500 lx). Data was analysed using sonar data and a deep learning (DL) based method for processing that automatically identified fish distribution patterns and estimated the average avoidance distance to the sound/light source. The fish fled from the sound source while playing sounds of 400 Hz, while sounds at other frequencies did not elicit a response. The response to light intensity depended on deployment depth, with the fish moving closer to the source when intensity was increased at 8 m depth, but conversely moving further away with increasing density when it was placed at 12 m. These outcomes are important inputs for the design of equipment, autonomous vehicles, robotic interventions and operations at commercial farms to ensure that their sound and light emissions have minimal impact on the fish, thereby reducing the potential of induced stress.},
  archive      = {J_FROBT},
  author       = {Zhang, Qin and Bloecher, Nina and Evjemo, Linn Danielsen and Føre, Martin and Kelasidi, Eleni},
  doi          = {10.3389/frobt.2025.1657567},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1657567},
  shortjournal = {Front. Robot. AI},
  title        = {Avoidance behaviours of farmed atlantic salmon (Salmo salar l.) to artificial sound and light: A case study of net-pen mariculture in norway},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Towards HRI of everyday life. <em>FROBT</em>, <em>12</em>, 1657518. (<a href='https://doi.org/10.3389/frobt.2025.1657518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it is often assumed that, at least in principle, robots in general, and social robots in particular, have the potential to increase human well-being across a wide range of sectors and application areas. At the same time, efforts to introduce such systems into our everyday environments have had only limited success and it is yet to be seen whether the impact of social robots on our daily lives, professional and private, will actually be beneficial. Therefore, there is a need to systematically address and study the long-term use and presence of social robots in everyday environments, where humans not only interact with robots, but also have them integrated into the totality of their lived experiences in everyday life.One of the main ways to investigate human engagement with social robots in everyday environments is through HRI studies conducted “in-the-wild”. While such an approach has certainly been instrumental and increasingly used in HRI research, in this Research Topic we have proposed to further expand the underlying theoretical and methodological frameworks to address the notion of 'everyday life'. Such a notion is viewed here as an important sociological concept and an umbrella term that allows us to address, not only specific application domains for robots, but also the continuity and totality of human lived experiences that emerge through long-term engagement with social robots in everyday life contexts. This is in a situation where placing social robots in everyday settings has often been an explicit goal for robot development but the very notion of 'everyday life' has not been systematically analysed. Therefore, this Research Topic has brought together a wide range of disciplinary and interdisciplinary contributions to further develop the HRI domain. While the main audience of this Research Topic is the HRI community, we have welcomed contributions from any disciplinary, interdisciplinary, theoretical, or methodological perspective that would address the subject of 'everyday life' in HRI research. As a result, we have published eight articles centered on the themes of integration, acceptance and people’s attitudes towards robots in everyday life.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2023.1241519/full}{Kühne et al.} investigates the use of dialects in social robots and its impact on the perceived trustworthiness and competence of robots. This is part of a broader inquiry into design and contextual factors that affect people’s acceptance of robots as social interaction partners. In particular, the study involved playing a short online video featuring NAO the robot speaking either in the Berlin dialect or standard German and asking one hundred twenty native German speakers to evaluate robots through a survey. While the study resulted in observing a slight trend of higher trust and competence evaluation for the standard German-speaking robot compared to the robot that spoke the Berlin dialect, the difference was not statistically significant and the two robots received largely comparable ratings in terms of both competence and trustworthiness. Also, on the one hand, the study found a positive correlation between certain variables, e.g. between participants’ self-reported Berlin dialect proficiency and trustworthiness, and on the other hand, it also depicted a complex picture of people’s perceptions of robots being affected by a number of factors that go far beyond robot features such as demographic characteristics, or a type of device used to watch the video. \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1438912/full}{Zafrani et al.} focuses on the acceptance and assimilation of socially assistive robots (SARs) in everyday life of the elderly persons. It presents the study that examined the uses, constraints and outcomes of engaging with ‘Gymmy’ the robot in real-life conditions and over a long period of time, and their effect on the older adults Quality Evaluations of SARs. The study involved nineteen community-dwelling adults aged 75-97 who interacted with a personal training robot installed at their homes for a period of 6 weeks. The main findings of the study involved identifying two assimilation patterns among the participants who could be categorized either as ‘Fans’ or ‘Skeptics’ based on the type of experience they reported regarding the robot. These two groups differed in terms of the positive vs. negative experience as well as participants’ personal background, attitudes towards robots before and after using the robot in question, and actual user experience. Thus, the study has shown that assimilation and acceptance of SARs is far from being a homogenous process and requires and requires careful consideration of the older adults’ needs and concerns.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2023.1212034/full}{ Zawieska et al.} poses the basis for this Research Topic as it discusses the existing and possible conceptual frameworks for the study of ‘everyday life’ in the HRI research. The paper first provides an overview of the ways everyday life is typically addressed in the HRI studies, namely in terms of settings, activity, population and/or methodology. Subsequently, the paper proposes further conceptual developments towards a systematic study of everyday life in HRI as a topic in its own right. In the process, it follows Social Sciences and Humanities (SSH) and sociological perspectives that have a long tradition of studying the everyday. In search of possible synergies between the HRI and SSH approaches, the paper builds upon the notion of ‘lived experiences’, and depicts the everyday as an open-ended process. It also engages with a critique of the contemporary everyday life as it calls for challenging the underlying understanding of the everyday and the real-world as ‘natural’ and by doing do, widening the scope of HRI research to include ethico-political stances oriented towards the pursuit of a ‘good life’.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1363243/full}{Komatsu et al.} conducted participatory design workshops with middle‑to‑older adults in Japan—once during the COVID‑19 pandemic and again post‑pandemic—to explore how their needs and attitudes toward robot technologies evolved due to changing social circumstances. Drawing on Nowland et al.’s ``stimulation vs. disengagement'' framework, the study found a marked shift over time: during the pandemic, participants prioritized robot tools that enabled distanced communication and social sharing with family, aligning with the stimulation hypothesis. After pandemic restrictions lifted, their focus shifted inward—toward personal well-being, ease of use, and technologies that alleviate digital exclusion, reflecting the disengagement hypothesis. Throughout, the participants consistently emphasized the importance of user-friendly, multifunctional robotic solutions—citing familiarity, simplicity, and seamless integration into their daily routines (e.g., combining guidance with communication tools). The authors highlight that Japan’s super-aged context and rapid digitization during COVID‑19 exacerbated older adults’ digital exclusion, particularly disadvantaging those less tech‑savvy. They conclude with a strong call for inclusive co‑design approaches that address evolving social needs, from enabling connection during isolation to supporting personal well‑being in the post-pandemic era—ensuring robot technologies remain relevant and accessible across life stages and contexts.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1332110/full}{Hägglund et al.} explore young adults’ trust considerations when interacting with a socially assistive robot in a high-stakes pharmacy scenario—specifically, medication counseling on emergency contraceptive pills. Utilizing a co-creation methodology, they worked with participants to design a prototype application using the Furhat social robot platform. Through in-lab testing and subsequent interviews (six participants), they conducted an inductive, reflexive thematic analysis. The study produced five distinct ``tales of trust'', each represented as a persona embodying varying expectations and willingness to trust a robot in this sensitive domain. The research identifies six key factors that drive initial trust formation: physical position (spatial relation to the robot), perceived autonomy, interaction boundaries, feelings of shame, eye gaze, and conversational alignment. These factors shaped whether participants were open to consulting a robot about intimate health matters. By mapping a continuum from low to high trust expectations, the authors illuminate the nuanced interplay of affective, contextual, and design elements influencing user trust in socially assistive robots. The insights significantly inform the understanding of trust formation in HRI, especially in sensitive healthcare contexts, offering important design considerations for socially assistive robotics in the healthcare sector.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1289414/full}{Ostrowski et al.} present a year-long co‑design study involving 28 older adults, aimed at developing HRI guidelines that reflect seniors’ real-world needs. Participants engaged in a series of interviews, design sessions, and reflections to articulate the types of interactions they would want in daily life. These older co-designers expressed growing confidence over time, increasingly favoring transactional robot capabilities—like reminders and scheduling—while maintaining reservations about surveillance-related functions such as personal data tracking and monitoring. Beyond practical assistance, the study found measured enthusiasm for robots facilitating social connection, monitoring bodily signals, and supporting emotional well-being—all tempered by concerns over autonomy, privacy, and the ``naturalness'' of robotic interactions. Employing ethnographic decision-tree modeling, the authors demonstrated that simpler, non-intrusive features gained acceptance, whereas more invasive ones triggered sustained skepticism. They conclude by offering clear, user-driven guidelines for HRI design with older adults, and highlight several areas—such as ethical data practices, enhancing agency, and improving emotional realism—that warrant deeper investigation before broader deployment.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1347367/full}{Vetter et al.} conducted a study that explores integrating robotic technologies in the care sector, where such innovations are seen as solutions to labor shortages and aging populations. Their research applied an integrated approach combining value sensitive design and speculative design to explore the complexities of care environments, focusing on the diverse needs, goals, and socio-material arrangements that shape this space. Drawing on six interviews and six card workshops with Austrian care workers and residents, five key themes emerged: trust-building routines, stakeholder negotiations, reciprocal and affective care, caregiver self-care, and material mediation. To provoke reflection and discussion, six speculative vignettes were created, highlighting tensions that arise when technologies disrupt established care practices. The study offers valuable insights for robotic designers to understand care values and dynamics prior to developing interventions.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1363713/full}{Irfan et al.} conducted a participatory design study with 28 older adults to explore their expectations of conversational companion robots powered by models, such as large language models (LLMs). The study introduced a functioning robot prototype using LLMs in everyday life scenarios to prompt discussion. Through a thematic analysis process of the data, the findings revealed that older adults prefer robots that actively engage in conversations during isolation and passively accompany them in social settings. Key expectations included memory and personalization, privacy and control over data, useful reminders and information, support for social connections, and the expression of empathy and emotion. Based on the findings outlined, the study offers design recommendations for incorporating models (such as LLMs) into companion robots. The outcomes of the articles provide insights that extend beyond robotic agents and contribute broadly to the development of socially responsive conversational agents for older adults.We hope that with these contributions we have shed light on the importance of the notion of everyday life with robots, and the need for multifaceted HRI approaches that would consider a whole range of factors that together contribute to human lived experiences with robots. The next step is to further develop more nuanced and HRI-specific methods and approaches that would allow us to study a unique phenomenon of life with robots at is unfolds.},
  archive      = {J_FROBT},
  author       = {Zawieska, Karolina and Obaid, Mohammad and Johal, Wafa},
  doi          = {10.3389/frobt.2025.1657518},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1657518},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Towards HRI of everyday life},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing weed detection through knowledge distillation and attention mechanism. <em>FROBT</em>, <em>12</em>, 1654074. (<a href='https://doi.org/10.3389/frobt.2025.1654074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weeds pose a significant challenge in agriculture by competing with crops for essential resources, leading to reduced yields. To address this issue, researchers have increasingly adopted advanced machine learning techniques. Recently, Vision Transformers (ViT) have demonstrated remarkable success in various computer vision tasks, making their application to weed classification, detection, and segmentation more advantageous compared to traditional Convolutional Neural Networks (CNNs) due to their self-attention mechanism. However, the deployment of these models in agricultural robotics is hindered by resource limitations. Key challenges include high training costs, the absence of inductive biases, the extensive volume of data required for training, model size, and runtime memory constraints. This study proposes a knowledge distillation-based method for optimizing the ViT model. The approach aims to enhance the ViT model architecture while maintaining its performance for weed detection. To facilitate the training of the compacted ViT student model and enable parameter sharing and local receptive fields, knowledge was distilled from ResNet-50, which serves as the teacher model. Experimental results demonstrate significant enhancements and improvements in the student model, achieving a mean Average Precision (mAP) of 83.47%. Additionally, the model exhibits minimal computational expense, with only 5.7 million parameters. The proposed knowledge distillation framework successfully addresses the computational constraints associated with ViT deployment in agricultural robotics while preserving detection accuracy for weed detection applications.},
  archive      = {J_FROBT},
  author       = {El Alaoui, Ali and Mousannif, Hajar},
  doi          = {10.3389/frobt.2025.1654074},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1654074},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing weed detection through knowledge distillation and attention mechanism},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining vision and range sensors for AMCL localization in corridor environments with rectangular signs. <em>FROBT</em>, <em>12</em>, 1652251. (<a href='https://doi.org/10.3389/frobt.2025.1652251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization is widely recognized as a fundamental problem in mobile robotics. Even though robust localization methods do exist for many applications, it is difficult for them to succeed in complex environments and challenging situations. In particular, corridor-like environments present important issues for traditional range-based methods. The main contribution of this paper is the integration of new observation models into the popular AMCL ROS node, considering visual features obtained from the detection of rectangular landmarks. Visual rectangles are distinctive elements which are very common in man-made environments and should be detected and recognized in a robust manner. This hybrid approach is developed and evaluated both for the combination of an omnidirectional camera and a laser sensor (using artificial markers) and for RGB-D sensors (using natural rectangular features). For the latter, this work also introduces RIDGE, a novel algorithm for detecting projected quadrilaterals representing rectangles in images. Simulations and real world experiments are presented for both cases. As shown and discussed in the article, the proposed approach provides significant advantages for specific conditions and common scenarios such as long straight corridors.},
  archive      = {J_FROBT},
  author       = {de la Puente, Paloma and Vega-Martínez, Germán and Javierre, Patricia and Laserna, Javier and Martin-Arias, Elena},
  doi          = {10.3389/frobt.2025.1652251},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1652251},
  shortjournal = {Front. Robot. AI},
  title        = {Combining vision and range sensors for AMCL localization in corridor environments with rectangular signs},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GNV2-SLAM: Vision SLAM system for cowshed inspection robots. <em>FROBT</em>, <em>12</em>, 1648309. (<a href='https://doi.org/10.3389/frobt.2025.1648309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) has emerged as one of the foundational technologies enabling mobile robots to achieve autonomous navigation, garnering significant attention in recent years. To address the limitations inherent in traditional SLAM systems when operating within dynamic environments, this paper proposes a new SLAM system named GNV2-SLAM based on ORB-SLAM2, offering an innovative solution for the scenario of cowshed inspection. This innovative system incorporates a lightweight object detection network called GNV2 based on YOLOv8. Additionally, it employs GhostNetv2 as backbone network. The CBAM attention mechanism and SCDown downsampling module were introduced to reduce the model complexity while ensuring detection accuracy. Experimental results indicate that the GNV2 network achieves excellent model compression effects while maintaining high performance: mAP@0.5 increased by 1.04%, reaching a total of 95.19%; model parameters were decreased by 41.95%, computational cost reduced by 36.71%, and the model size shrunk by 40.44%. Moreover, the GNV2-SLAM system incorporates point and line feature extraction techniques, effectively mitigate issues reduced feature point extraction caused by excessive dynamic targets or blurred images. Testing on the TUM dataset demonstrate that GNV2-SLAM significantly outperforms the traditional ORB-SLAM2 system in terms of positioning accuracy and robustness within dynamic environments. Specifically, there was a remarkable reduction of 96.13% in root mean square error (RMSE) for absolute trajectory error (ATE), alongside decreases of 88.36% and 86.19% for translation and rotation drift in relative pose error (RPE), respectively. In terms of tracking evaluation, GNV2-SLAM successfully completes the tracking processing of a single frame image within 30 ms, demonstrating expressive real-time performance and competitiveness. Following the deployment of this system on inspection robots and subsequent experimental trials conducted in the cowshed environment, the results indicate that when the robot operates at speeds of 0.4 m/s and 0.6 m/s, the pose trajectory output by GNV2-SLAM is more consistent with the robot's actual movement trajectory. This study systematically validated the system's significant advantages in target recognition and positioning accuracy through experimental verification, thereby providing a new technical solution for the comprehensive automation of cattle barn inspection tasks.},
  archive      = {J_FROBT},
  author       = {Du, Xinwu and Li, Tingting and Jin, Xin and Yu, Xiufang and Xie, Xiaolin and Zhang, Chenglin},
  doi          = {10.3389/frobt.2025.1648309},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1648309},
  shortjournal = {Front. Robot. AI},
  title        = {GNV2-SLAM: Vision SLAM system for cowshed inspection robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A PSO–ML-LSTM-based IMU state estimation approach for manipulator teleoperation. <em>FROBT</em>, <em>12</em>, 1638853. (<a href='https://doi.org/10.3389/frobt.2025.1638853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulator teleoperation can liberate humans from hazardous tasks. Signal noise caused by environmental disturbances and the devices’ inherent characteristics may limit the teleoperation performance. This paper proposes an approach for inertial measurement unit (IMU) state estimation based on particle swarm optimization (PSO) and modulated long short-term memory (ML-LSTM) neural networks to mitigate the impact of IMU cumulative error on the robot teleoperation performance. A motion mapping model for the human arm and a seven-degree-of-freedom (7-DOF) robotic arm are first established based on global configuration parameters and a hybrid mapping method. This model is used to describe the impact of IMU cumulative error on the robot teleoperation performance. Subsequently, the IMU pose state estimation model is constructed using PSO and ML-LSTM neural networks. The initial data of multiple IMUs and handling handles are used for training the estimation model. Finally, comparative experiments are conducted to verify the performance of the proposed state estimation model. The results demonstrate that the PSO–ML-LSTM algorithm can effectively eliminate the impact of IMU cumulative errors on robot teleoperation.},
  archive      = {J_FROBT},
  author       = {Zhou, Renyi and Li, Yuanchong and Zhang, Aimin and Zhang, Tie and Guan, Yisheng and Zhao, Zhijia and Chen, Shouyan},
  doi          = {10.3389/frobt.2025.1638853},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1638853},
  shortjournal = {Front. Robot. AI},
  title        = {A PSO–ML-LSTM-based IMU state estimation approach for manipulator teleoperation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating emotional intelligence, memory architecture, and gestures to achieve empathetic humanoid robot interaction in an educational setting. <em>FROBT</em>, <em>12</em>, 1635419. (<a href='https://doi.org/10.3389/frobt.2025.1635419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of individual human traits into an empathetically adaptive educational robot tutor system designed to improve student engagement and learning outcomes with corresponding Engagement Vector measurements. While prior research in the field of Human-Robot Interaction (HRI) has examined the integration of the traits, such as emotional intelligence, memory-driven personalization, and non-verbal communication, by themselves, they have thus-far neglected to consider their synchronized integration into a cohesive, operational education framework. To address this gap, we customize a Multi-Modal Large Language Model (Llama 3.2 from Meta) deployed with modules for human-like traits (emotion, memory and gestures) into an AI-Agent framework. This constitutes the robot’s intelligent core that mimics the human emotional system, memory architecture and gesture controller to allow the robot to behave more empathetically while recognizing and responding appropriately to the student’s emotional state. It can also recall the student’s past learning record and adapt its style of interaction accordingly. This allows the robot tutor to react to the student in a more sympathetic manner by delivering personalized verbal feedback synchronized with relevant gestures. Our study suggests the extent of this effect through the introduction of Engagement Vector Model which can be a benchmark for judging the quality of HRI experience. Quantitative and qualitative results demonstrate that such an empathetic responsive approach significantly improves student engagement and learning outcomes compared with a baseline humanoid robot without these human-like traits. This indicates that robot tutors with empathetic capabilities can create a more supportive, interactive learning experience that ultimately leads to better outcomes for the student.},
  archive      = {J_FROBT},
  author       = {Sun, Fuze and Li, Lingyu and Meng, Shixiangyue and Teng, Xiaoming and Payne, Terry R. and Craig, Paul},
  doi          = {10.3389/frobt.2025.1635419},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1635419},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating emotional intelligence, memory architecture, and gestures to achieve empathetic humanoid robot interaction in an educational setting},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating large language models for intuitive robot navigation. <em>FROBT</em>, <em>12</em>, 1627937. (<a href='https://doi.org/10.3389/frobt.2025.1627937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home assistance robots face challenges in natural language interaction, object detection, and navigation, mainly when operating in resource-constrained home environments, which limits their practical deployment. In this study, we propose an AI agent framework based on Large Language Models (LLMs), which includes EnvNet, RoutePlanner, and AIBrain, to explore solutions for these issues. Utilizing quantized LLMs allows the system to operate on resource-limited devices while maintaining robust interaction capabilities. Our proposed method shows promising results in improving natural language understanding and navigation accuracy in home environments, also providing a valuable exploration for deploying home assistance robots.},
  archive      = {J_FROBT},
  author       = {Xue, Ziheng and Elksnis, Arturs and Wang, Ning},
  doi          = {10.3389/frobt.2025.1627937},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1627937},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating large language models for intuitive robot navigation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A projection-based inverse kinematic model for extensible continuum robots and hyper-redundant robots with an elbow joint. <em>FROBT</em>, <em>12</em>, 1627688. (<a href='https://doi.org/10.3389/frobt.2025.1627688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse kinematics is a core problem in robotics, involving the use of kinematic equations to calculate the joint configurations required to achieve a target pose. This study introduces a novel inverse kinematic model (IKM) for extensible (i.e., length-adjustable) continuum robots (CRs) and hyper-redundant robots (HRRs) featuring an elbow joint. This IKM numerically solves a set of equations representing geometric constraints (abbreviated as NSGC). NSGC can handle target poses Xt=[xt,yt,zt,ψt] in 3D space, which are projected onto a 2D plane and solved numerically. NSGC is capable of real-time operation and accounts for elbow joint limits. Extensive simulations and empirical tests confirm the reliability, performance, and practical applicability of NSGC.},
  archive      = {J_FROBT},
  author       = {Fritsch, Sven and Oberschmidt, Dirk},
  doi          = {10.3389/frobt.2025.1627688},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1627688},
  shortjournal = {Front. Robot. AI},
  title        = {A projection-based inverse kinematic model for extensible continuum robots and hyper-redundant robots with an elbow joint},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gödelian embodied self-referential genomic intelligence: Lessons for AI and AGI from the genomic blockchain. <em>FROBT</em>, <em>12</em>, 1624695. (<a href='https://doi.org/10.3389/frobt.2025.1624695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security of code-based digital records is a major concern of the 21st century. AI and artificial general intelligence (AGI) can be hacked to pieces by digital adversaries, and some AI objectives can lead to existential threats. The former arises from sitting duck problems that all software systems are vulnerable to, and the latter include control and misalignment problems. Blockchain technology, circa 2009, can address these problems: hashing algorithms rely on a consensus mechanism in manmade software systems to keep early blocks of software immutable and tamper-proof from digital malware, while new blocks can be added only if consistently aligned with original blocks. There is evidence that the ancient precedent of the genomic blockchain, underpinning the unbroken chain of life, uses a self-referential rather than a consensus-based hashing algorithm. Knowledge of self-codes permits biotic elements to achieve a hack-free agenda by self-reporting that they have been “negated,” or hacked, exactly implementing the Gödel sentence from foundational mathematics of Gödel, Turing, and Post (G–T–P). This results in an arms race in open-ended novelty to secure the primacy of original self-codes. Selfhood and autonomy are staples of neuroscience on complex self–other social cognition and increasingly of autonomous AGI agents capable of end-to-end programmed self-assembly. My perspective is that self-referential G–T–P information processing, first found in the adaptive immune system of jawed fish 500 mya and more recently in mirror neuron systems of humans, has enabled code-based self-organized intelligent systems like life to survive over 3.7 billion years. Some lessons for AGI can be gleaned from this discussion.},
  archive      = {J_FROBT},
  author       = {Markose, Sheri},
  doi          = {10.3389/frobt.2025.1624695},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1624695},
  shortjournal = {Front. Robot. AI},
  title        = {Gödelian embodied self-referential genomic intelligence: Lessons for AI and AGI from the genomic blockchain},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing reliability centered maintenance in automotive robotic welding machines for a tier 1 supplier. <em>FROBT</em>, <em>12</em>, 1620370. (<a href='https://doi.org/10.3389/frobt.2025.1620370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study highlights the effectiveness of FMEA in robotic spot-welding operations, providing a systematic approach to enhancing performance in an automotive assembly line. Robotic welding industries depend on mechanized, programmable tools to automate welding processes, ensuring efficiency, reliability, and effective material handling. In the automotive sector, Tier 1 suppliers utilize robotic welding machines to produce high volumes of welded assemblies, with daily output exceeding 450 units. However, frequent equipment downtime due to maintenance challenges disrupts productivity and impacts customer satisfaction. This study aims to develop a Reliability-Centered Maintenance (RCM) approach for robotic welding industries, optimizing machine uptime, enhancing product quality, and reducing financial losses caused by unexpected failures. A 3-year dataset was analysed to identify the primary causes of downtime and their associated costs. Failure Modes and Effects Analysis (FMEA) was applied to assess failure modes, determine root causes, and calculate Risk Priority Numbers (RPNs), thereby formulating corrective actions to mitigate recurring failures and enhance operational efficiency. Findings revealed that maintenance-related issues accounted for 79% of total downtime, resulting in financial losses of R2,281,508.82 over 3 years. The application of FMEA provided a structured framework for prioritizing critical failure modes and implementing targeted corrective measures to reduce downtime and enhance overall reliability. To sustain high productivity and quality, it is recommended that robotic welding industries adopt proactive maintenance strategies based on FMEA findings. Regular monitoring, predictive maintenance, and workforce training will help minimize machine failures and optimize operational efficiency.},
  archive      = {J_FROBT},
  author       = {Alaka, H. T. O. and Mpofu, K. and Ramatsetse, B. I. and Adegbola, T. A. and Adeoti, M. O.},
  doi          = {10.3389/frobt.2025.1620370},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1620370},
  shortjournal = {Front. Robot. AI},
  title        = {Developing reliability centered maintenance in automotive robotic welding machines for a tier 1 supplier},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion models for robotic manipulation: A survey. <em>FROBT</em>, <em>12</em>, 1606247. (<a href='https://doi.org/10.3389/frobt.2025.1606247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion generative models have demonstrated remarkable success in visual domains such as image and video generation. They have also recently emerged as a promising approach in robotics, especially in robot manipulations. Diffusion models leverage a probabilistic framework, and they stand out with their ability to model multi-modal distributions and their robustness to high-dimensional input and output spaces. This survey provides a comprehensive review of state-of-the-art diffusion models in robotic manipulation, including grasp learning, trajectory planning, and data augmentation. Diffusion models for scene and image augmentation lie at the intersection of robotics and computer vision for vision-based tasks to enhance generalizability and data scarcity. This paper also presents the two main frameworks of diffusion models and their integration with imitation learning and reinforcement learning. In addition, it discusses the common architectures and benchmarks and points out the challenges and advantages of current state-of-the-art diffusion-based methods.},
  archive      = {J_FROBT},
  author       = {Wolf, Rosa and Shi, Yitian and Liu, Sheng and Rayyes, Rania},
  doi          = {10.3389/frobt.2025.1606247},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1606247},
  shortjournal = {Front. Robot. AI},
  title        = {Diffusion models for robotic manipulation: A survey},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review and bibliometric analysis on collaborative robotics for industry: Safety emerging as a core focus. <em>FROBT</em>, <em>12</em>, 1605682. (<a href='https://doi.org/10.3389/frobt.2025.1605682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research organizations and academics often seek to map the development of scientific fields, identify research gaps, and guide the direction of future research. In cobot-related research, the scientific literature consulted does not propose any comprehensive research agenda. Moreover, cobots, industrial robots inherently designed to collaborate with humans, bring with them emerging issues. To solve them, interdisciplinary research is often essential (e.g., combination of engineering, ergonomics and biomechanics expertise to handle safety challenges). This paper proposes an exhaustive study that employs a scoping review and bibliometric analysis to provide a structured macro perspective on the developments, key topics, and trends in cobot research for industry. A total of 2,195 scientific publications were gained from the Web of Science database, and a thorough selection process narrowed them down to 532 papers for comprehensive analysis. Descriptive statistics were employed to analyze bibliometric measures, highlighting publication trends, leading journals, the most productive institutions, engaged countries, influential authors, and prominent research topics. Co-authorship and bibliographic couplings were also examined. Through a co-occurrence analysis of terms, the content and research objectives of the papers were systematically reviewed and lead to a univocal categorization framework. That categorization can support organizations or researchers in different cobotics (collaborative robotics) fields by understanding research developments and trends, identifying collaboration opportunities, selecting suitable publication venues, advancing the theoretical and experimental understanding of automatic collaborative systems, and identifying research directions and predicting the evolution of publication quantity in cobotics.},
  archive      = {J_FROBT},
  author       = {Haghighi, Aida and Cheraghi, Morteza and Pocachard, Jérôme and Botta-Genoulaz, Valérie and Jocelyn, Sabrina and Pourzarei, Hamidreza},
  doi          = {10.3389/frobt.2025.1605682},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1605682},
  shortjournal = {Front. Robot. AI},
  title        = {A comprehensive review and bibliometric analysis on collaborative robotics for industry: Safety emerging as a core focus},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomy in socially assistive robotics: A systematic review. <em>FROBT</em>, <em>12</em>, 1586473. (<a href='https://doi.org/10.3389/frobt.2025.1586473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Socially assistive robots are increasingly being researched and deployed in various domains such as education, healthcare, service, and even as collaborators in a variety of other workplaces. Similarly, SARs are also expected to interact in a socially acceptable manner with a wide audience, ranging from preschool children to the elderly. This diversity of application domains and target populations raises technical and social challenges that are yet to be overcome. While earlier works relied on the Wizard-of-Oz (WoZ) paradigm to give an illusion of interactivity and intelligence, a transition toward more autonomous robots can be observed. In this article, we present a systematic review, following the PRISMA method, of the last 5 years of Socially Assistive Robotics research, centered around SARs’ level of autonomy with a stronger focus on fully and semi-autonomous robots than non-autonomous ones. Specifically, to analyse SARs’ level of autonomy, the review identifies which sensing and actuation capabilities of SARs are typically automated and which ones are not, and how these capabilities are automated, with the aim of identifying potential gaps to be explored in future research. The review further explores whether SARs’ level of autonomy and capabilities are transparently communicated to the diverse target audiences above described and discusses the potential benefits and drawbacks of such transparency. Finally, with the aim of providing a more holistic view of SARs’ characteristics and application domains, the review also reports the embodiment and commonly envisioned role of SARs, as well as their interventions’ size, length and environment.},
  archive      = {J_FROBT},
  author       = {Maure, Romain and Bruno, Barbara},
  doi          = {10.3389/frobt.2025.1586473},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1586473},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomy in socially assistive robotics: A systematic review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Encouraging classroom activities for children using avatar robots: A field trial. <em>FROBT</em>, <em>12</em>, 1571804. (<a href='https://doi.org/10.3389/frobt.2025.1571804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational institutions are facing a critical shortage of teachers worldwide. Consequently, the trend of introducing interactive robots into educational sites is growing. However, most previous research focused on specific subjects or time slots, and only a few studies have introduced interactive robots to participate in whole classroom activities with children routinely. This study investigates the use of avatar robots operated by multiple remote operators in elementary school classrooms. Over nine days, a 5th-grade class was observed to assess the robot’s impact on student engagement, motivation, and peer interactions, and compared to classes where any avatar robots were not introduced. Key findings include improved student confidence in presentations, enhanced social interactions during recess, and positive feedback on the robot’s role in supporting classroom activities. The results suggest that avatar robots, with consistent remote operation, can provide valuable educational support without strong negative reactions from students.},
  archive      = {J_FROBT},
  author       = {Kawata, Megumi and Maeda, Masashi and Kumazaki, Hirokazu and Kamide, Hiroko and Baba, Jun and Matsuura, Naomi and Ishiguro, Hiroshi and Yoshikawa, Yuichiro},
  doi          = {10.3389/frobt.2025.1571804},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1571804},
  shortjournal = {Front. Robot. AI},
  title        = {Encouraging classroom activities for children using avatar robots: A field trial},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-specific CNN size reduction through content-specific pruning. <em>FROBT</em>, <em>12</em>, 1552068. (<a href='https://doi.org/10.3389/frobt.2025.1552068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread and growing use of flying unmanned aerial vehicles (UAVs) is attributed to their high spatial mobility, autonomous control, and lower cost compared to usual manned flying vehicles. Applications, such as surveying, searching, or scanning the environment with application-specific sensors, have made extensive use of UAVs in fields like agriculture, geography, forestry, and biology. However, due to the large number of applications and types of UAVs, limited power has to be taken into account when designing task-specific software for a target UAV. In particular, the power constraints of smaller UAVs will generally necessitate reducing power consumption by limiting functionality, decreasing their movement radius, or increasing their level of autonomy. Reducing the overhead of control and decision-making software onboard is one approach to increasing the autonomy of UAVs. Specifically, we can make the onboard control software more efficient and focused on specific tasks, which means it will need less computing power than a general-purpose algorithm. In this work, we focus on reducing the size of the computer vision object classification algorithm. We define different tasks by specifying which objects the UAV must recognize, and we construct a convolutional neural network (CNN) for each specific classification. However, rather than creating a custom CNN that requires its dataset, we begin with a pre-trained general-purpose classifier. We then choose specific groups of objects to recognize, and by using response-based pruning (RBP), we simplify the general-purpose CNN to fit our specific needs. We evaluate the pruned models in various scenarios. The results indicate that the evaluated task-specific pruning can reduce the size of the neural model and increase the accuracy of the classification tasks. For small UAVs intended for tasks with reduced visual content, the proposed method solves both the size reduction and individual model training problems.},
  archive      = {J_FROBT},
  author       = {Konyrbaev, Nurbek and Lukac, Martin and Ibadulla, Sabit and Diveev, Askhat and Sofronova, Elena and Galymzhankyzy, Asem},
  doi          = {10.3389/frobt.2025.1552068},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1552068},
  shortjournal = {Front. Robot. AI},
  title        = {Task-specific CNN size reduction through content-specific pruning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VIO-GO: Optimizing event-based SLAM parameters for robust performance in high dynamic range scenarios. <em>FROBT</em>, <em>12</em>, 1541017. (<a href='https://doi.org/10.3389/frobt.2025.1541017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a critical challenge in Industry 4.0 robotics by enhancing Visual Inertial Odometry (VIO) systems to operate effectively in dynamic and low-light industrial environments, which are common in sectors like warehousing, logistics, and manufacturing. Inspired by biological sensing mechanisms, we integrate bio-inspired event cameras to improve state estimation systems performance in both dynamic and low-light conditions, enabling reliable localization and mapping. The proposed state estimation framework integrates events, conventional video frames, and inertial data to achieve reliable and precise localization with specific emphasis on real-world challenges posed by high-speed and cluttered settings typical in Industry 4.0. Despite advancements in event-based sensing, there is a noteworthy gap in optimizing Event Simultaneous Localization and Mapping (SLAM) parameters for practical applications. To address this, we introduce a novel VIO-Gradient-based Optimization (VIO-GO) method that employs Batch Gradient Descent (BGD) for efficient parameter tuning. This automated approach determines optimal parameters for Event SLAM algorithms by using motion-compensated images to represent event data. Experimental validation on the Event Camera Dataset shows a remarkable 60% improvement in Mean Position Error (MPE) over fixed-parameter methods. Our results demonstrate that VIO-GO consistently identifies optimal parameters, enabling precise VIO performance in complex, dynamic scenarios essential for Industry 4.0 applications. Additionally, as parameter complexity scales, VIO-GO achieves a 24% reduction in MPE when using the most comprehensive parameter set (VIO-GO8) compared to a minimal set (VIO-GO2), highlighting the method’s scalability and robustness for adaptive robotic systems in challenging industrial environments.},
  archive      = {J_FROBT},
  author       = {Sakhrieh, Saber and Singh, Abhilasha and Mounsef , Jinane and Arain , Bilal and Maalouf , Noel},
  doi          = {10.3389/frobt.2025.1541017},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1541017},
  shortjournal = {Front. Robot. AI},
  title        = {VIO-GO: Optimizing event-based SLAM parameters for robust performance in high dynamic range scenarios},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Advancing soft, tactile, and haptic technologies: Recent developments for healthcare applications. <em>FROBT</em>, <em>12</em>, 1658613. (<a href='https://doi.org/10.3389/frobt.2025.1658613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in soft robotics, tactile sensing, and haptic technologies are opening new frontiers in healthcare, particularly in enhancing diagnostic precision, clinical training, patient monitoring, and human-robot interaction (Raman and Laschi, 2024;Othman et al., 2022, Zhu et al., 2022).Using soft and smart materials, robotic mechanisms and sensors become compliant and deformable, mimicking the flexibility and adaptability of natural organisms. These characteristics can advance tactile sensors and haptic systems to enable robots to perceive and interact with their environment through touch in a safer and seamless manner, while also elevating human-robot interaction to a nearnatural and intuitive experience (Yin et al., 2021;Zhou et al., 2024).There is potential to revolutionize healthcare via offering innovative solutions that improve patient outcomes, enhance healthcare professionals' skills, and provide personalized and adaptive care. Recent developments such as variable stiffness mechanisms (Fras et al., 2021) and compliant soft grippers for manipulation or safer and more flexible surgical procedures (Pagliarani et al., 2023) as well as sensor tuning techniques (Jenkinson et al., 2023) aim to enhance the capabilities of these technologies.This Research Topic explores the challenges and opportunities of these areas, highlighting state-of-theart methodologies and innovations in soft tactile sensors, wearable haptic devices, multimodal learning frameworks, and intelligent systems for healthcare. The contributions collectively demonstrate how soft tactile and haptic technologies are evolving to meet the demands of modern medicine through adaptive, accessible, and context-aware solutions.The study by Samain-Aupic et al. offers compelling insights for the field of soft, tactile, and haptic technologies in healthcare by revealing how tactile sensitivity evolves across the human lifespan and body. Showing that glabrous skin (e.g., of the fingertip) deteriorates with age while hairy skin (e.g., cheek and forearm) retains sensitivity, this paper highlights the importance of tailoring haptic interfaces to different skin types and age groups. These findings can directly inform the design of next-generation wearable sensors, prosthetics, and rehabilitation tools, ensuring they remain effective and perceptible for older users. As healthcare increasingly embraces tactile feedback systems, understanding the nuanced aging of touch becomes essential for creating inclusive, responsive, and human-centred technologies.Palpation is an essential skill also for clinicians and other medical professionals that aids diagnostics and physical examination of patients. High-fidelity human manikins are costly and not broadly available, especially for developing countries. Brown and Bello present the development of four particle-jamming-based tactile displays for simulating organic soft-tissue hardness of different properties. The authors describe electromechanical constriction and compression devices, a magnetbased design, and a vacuum approach. Notably, apart from the quantitative performance evaluation, they also consider non-functional characteristics such as size and cost, informing further development of the proposed innovation. The described tactile display systems provide insights for the development of low-cost palpation simulators, making realistic clinical skills practice accessible even in resourcelimited settings.A key topic in tactile sensing systems is their integration with other artificial sensory modalities such as vision. Li and Thuruthel introduce a self-supervised multimodal learning framework that fuses vision and tactile data to improve robotic interaction prediction in dynamic tasks. The system collects synchronized vision, tactile and action data and reveals the asymmetric and complementary roles of vision and touch, with tactile input proving especially valuable under visual occlusion. This offers important insights into how vision and tactile sensors could be combined for dexterous manipulation tasks, particularly in healthcare.The paper by Gandhi et al. presents an optical soft tactile sensing system designed for head motion tracking in radiotherapy settings, offering a non-metallic, MRI-compatible alternative to conventional vision-based systems. The authors develop and evaluate a Motion Capture Pillow that uses a fibrescope and optical flow algorithms (Lukas-Kanade) to detect head movements with high fidelity. This work enables contact-based tracking in electromagnetically sensitive healthcare environments. Kurogi et al. introduce a novel approach for Haptic Augmented Reality that augments the perceived stickiness of a physical object during adhesion-separation contact mode. The study hypothesises that the intensity of perceived stickiness depends on the duration required for the attached object to completely detach from the skin, rather than on the force exerted. A dielectric elastomer actuator based thin-film, soft wearable tactile display has been developed to introduce vibration and evoke the sensation of complete detachment of the object from the skin, thereby altering the perceived stickiness. The system has been assessed through two user experiments: the first aimed at investigating the modulation of perceived stickiness and the second to study various frequencies and presenting timings. They demonstrated that stickiness was perceived across all feedback conditions, and that realism and harmony of the experience were influenced by the frequency and presentation timing of the additional tactile feedback.L'Orsa et al. presents a leap forward in emergency medicine by transforming how needle decompression is performed with the aim of assisting operators in detecting needle entry into the pleural space while treating tension pneumothorax. By embedding high-pass filtering and diffuse reflectance sensing into instrumented needles, this paper presents a powerful synergy with data-driven puncture detection algorithms. The system improves detection precision by up to 5.1 times compared with traditional force-only methods, while it is a lightweight, portable solution ideal for high-stakes, prehospital scenarios. The evaluation of multimodal sensing and ensemble techniques showcases a compelling path toward smarter, safer, and more autonomous needle-based interventions.This collection underscores the transformative role of tactile and haptic technologies in healthcare, with a strong emphasis on personalization, accessibility, and multimodal integration. Central to these advancements is the adaptation of tactile systems to human variability, guiding the design of inclusive and responsive haptic interfaces. Affordable innovations are expanding access to high-fidelity clinical training and emergency care. The integration of tactile sensing with other modalities, particularly vision, enhances robotic dexterity and interaction prediction, especially in visually occluded environments. Progress in soft robotics and wearable haptics also contribute to patient-centred and patient-friendly care, offering non-invasive, MRI-compatible solutions for real-time monitoring. Collectively, these studies point to a shift toward adaptable, multimodal, and context-aware technologies poised to redefine clinical practice and patient experience.},
  archive      = {J_FROBT},
  author       = {Tzemanaki, Antonia and Ward-Cherrier, Benjamin and Cianchetti, Matteo and Konstantinova, Jelizaveta},
  doi          = {10.3389/frobt.2025.1658613},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1658613},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advancing soft, tactile, and haptic technologies: Recent developments for healthcare applications},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Human-robot interaction in industrial settings: New challenges and opportunities. <em>FROBT</em>, <em>12</em>, 1652426. (<a href='https://doi.org/10.3389/frobt.2025.1652426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of social robots in product advertising is gaining prominence, and their potential impact on sales is a subject of 42 interest. In Mizuho et al., the authors conducted a study in a grocery store to examine the manner customers remember advertised 43 products. The study compared the impact of physical robots and virtual agents. According to the researchers, there is a possibility 44 that customers would better remember content when hearing it from multiple agents. Further, the physical robots would elicit more},
  archive      = {J_FROBT},
  author       = {Bouraine, Sara and Ammi, Mehdi and Geihs, Kurt and Hentout, Abdelfetah and Maoudj, Abderraouf and Yacef, Fouad},
  doi          = {10.3389/frobt.2025.1652426},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1652426},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human-robot interaction in industrial settings: New challenges and opportunities},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design, development, and validation of a non-backdrivable active ankle-foot orthosis for the TWIN lower-limb exoskeleton. <em>FROBT</em>, <em>12</em>, 1647989. (<a href='https://doi.org/10.3389/frobt.2025.1647989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study’s primary objective was to develop an Active Ankle-Foot Orthosis (AAFO) specifically designed for integration into lower-limb exoskeletons. An analysis of human ankle motion is conducted to inform the development process, guiding the creation of an AAFO that aligns with specifics extrapolated by real data. The AAFO incorporates an electric motor with a non-backdrivable transmission system, engineered to reduce distal mass, minimize power consumption, and enable high-precision position control. Capable of generating up to 50 Nm of peak torque, the AAFO is designed to provide support throughout the walking cycle, targeting pathological conditions such as foot drop and toe drag. Performance was first validated through benchtop experiments under unloaded conditions. The AAFO was then integrated into the TWIN lower-limb exoskeleton, employing an optimal trajectory planning method to generate compatible reference trajectories. These trajectories are designed to help the user maintain ground contact during the support phase while ensuring safe toe clearance and minimizing jerk during the swing phase. Finally, the AAFO’s performance was assessed in real-world application conditions, with four healthy participants walking with the TWIN lower limb exoskeleton. The results suggest that the proposed AAFO efficiently reduces toe clearance, ensures stable control, and maintains low power consumption, highlighting its suitability for clinical applications.},
  archive      = {J_FROBT},
  author       = {Giannattasio, Raffaele and Boccardo, Nicolò and Vaccaro, Riccardo and Bhatt, Heeral and Maludrottu, Stefano and De Momi, Elena and Laffranchi, Matteo},
  doi          = {10.3389/frobt.2025.1647989},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1647989},
  shortjournal = {Front. Robot. AI},
  title        = {Design, development, and validation of a non-backdrivable active ankle-foot orthosis for the TWIN lower-limb exoskeleton},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent maneuver decision-making for UAVs using the TD3–LSTM reinforcement learning algorithm under uncertain information. <em>FROBT</em>, <em>12</em>, 1645927. (<a href='https://doi.org/10.3389/frobt.2025.1645927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to address the complexity and uncertainty of unmanned aerial vehicle (UAV) aerial confrontation, a twin delayed deep deterministic policy gradient (TD3)–long short-term memory (LSTM) reinforcement learning-based intelligent maneuver decision-making method is developed in this paper. A victory/defeat adjudication model is established, considering the operational capability of UAVs based on an aerial confrontation scenario and the 3-degree-of-freedom (3-DOF) UAV model. For the purpose of assisting UAVs in making maneuvering decisions in continuous action space, a model-driven state transition update mechanism is designed. The uncertainty is represented using the Wasserstein distance and memory nominal distribution methods to estimate the detection noise of the target. On the basis of TD3, an LSTM network is utilized to extract features from high-dimensional aerial confrontation situations with uncertainty. The effectiveness of the proposed method is verified by conducting four different aerial confrontation simulation experiments.},
  archive      = {J_FROBT},
  author       = {Zhou, Tongle and Liu, Ziyi and Jin , Wenxiao and Han, Zengliang},
  doi          = {10.3389/frobt.2025.1645927},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1645927},
  shortjournal = {Front. Robot. AI},
  title        = {Intelligent maneuver decision-making for UAVs using the TD3–LSTM reinforcement learning algorithm under uncertain information},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The robot that stayed: Understanding how children and families engage with a retired social robot. <em>FROBT</em>, <em>12</em>, 1628089. (<a href='https://doi.org/10.3389/frobt.2025.1628089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSocial robots are increasingly introduced into homes as short-term educational or entertainment tools for children. However, their physical presence and social roles may persist long after their intended use has ended. This study explores how families continue to engage with a child-focused educational robot years after its original deployment.MethodsWe conducted a retrospective follow-up study with 19 families who participated in a 2021 in-home deployment of a reading companion robot for preschool-aged children. In 2025, we revisited these families through in-depth interviews to investigate how the robot had been integrated, re-purposed, or preserved over time.ResultsDespite the children outgrowing the robot’s instructional content, 18 families had retained the robot. Families described transitions in its role—from an educational device to a symbolic household member—characterized by emotional attachment, care-taking behaviors, and affection. The robot was re-framed as a memory object, integrated into new routines, or passed on ceremonially, akin to a “retirement.”DiscussionOur findings reveal three key themes explaining the robot’s enduring presence: (1) emotional attachment and personification, (2) symbolic and nostalgic value, and (3) practical re-purposing within household routines. This study contributes to long-term human—robot interaction literature by extending domestication theory and emphasizing the importance of designing for the full life cycle of social robots—including end-of-life transitions. It underscores how social robots can become meaningful companions and enduring artifacts of family identity, long after their functional use has ended.},
  archive      = {J_FROBT},
  author       = {Zhao, Zhao and McEwen, Rhonda},
  doi          = {10.3389/frobt.2025.1628089},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1628089},
  shortjournal = {Front. Robot. AI},
  title        = {The robot that stayed: Understanding how children and families engage with a retired social robot},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEG-CLIP: Learning EEG representations from natural language descriptions. <em>FROBT</em>, <em>12</em>, 1625731. (<a href='https://doi.org/10.3389/frobt.2025.1625731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep networks for electroencephalogram (EEG) decoding are often only trained to solve one specific task, such as pathology or age decoding. A more general task-agnostic approach is to train deep networks to match a (clinical) EEG recording to its corresponding textual medical report and vice versa. This approach was pioneered in the computer vision domain matching images and their text captions and subsequently allowed to do successful zero-shot decoding using textual class prompts. In this work, we follow this approach and develop a contrastive learning framework, EEG-CLIP, that aligns the EEG time series and the descriptions of the corresponding clinical text in a shared embedding space. We investigated its potential for versatile EEG decoding, evaluating performance in a range of few-shot and zero-shot settings. Overall, we show that EEG-CLIP manages to non-trivially align text and EEG representations. Our work presents a promising approach to learn general EEG representations, which could enable easier analyses of diverse decoding questions through zero-shot decoding or training task-specific models from fewer training examples. The code for reproducing our results is available at https://github.com/tidiane-camaret/EEGClip.},
  archive      = {J_FROBT},
  author       = {Camaret Ndir, Tidiane and Schirrmeister , Robin T. and Ball , Tonio},
  doi          = {10.3389/frobt.2025.1625731},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1625731},
  shortjournal = {Front. Robot. AI},
  title        = {EEG-CLIP: Learning EEG representations from natural language descriptions},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing for flourishing: A conceptual model for enhancing older adults’ well-being with social robots. <em>FROBT</em>, <em>12</em>, 1607373. (<a href='https://doi.org/10.3389/frobt.2025.1607373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article gives a new perspective on designing robotic applications in elderly care with a special focus on socially assistive robots and seniors’ well-being. While various applications have been proposed there is currently no common conceptual model in designing interventions with social robots for seniors. Therefore, we propose a conceptual model that identifies five key domains for designing applications for socially interactive robots to enhance seniors’ well-being. We base our conceptual model on established theories from the social sciences. Namely, we propose that application design should consider integrating Self-Determination Theory by addressing the three basic psychological needs (autonomy, competence, and relatedness) to enhance seniors’ wellbeing. Furthermore, we recommend assessing the impact of social robots on well-being using the five building blocks of the PERMA framework: positive emotions, engagement, relationships, meaning, and accomplishment. By integrating these theoretical perspectives, researchers and developers gain a structured approach to designing social robot applications for cognitively healthy older adults and evaluating their effects.},
  archive      = {J_FROBT},
  author       = {Klier, Chantal and Lugrin, Birgit},
  doi          = {10.3389/frobt.2025.1607373},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1607373},
  shortjournal = {Front. Robot. AI},
  title        = {Designing for flourishing: A conceptual model for enhancing older adults’ well-being with social robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Train your robot in AR: Insights and challenges for humans and robots in continual teaching and learning. <em>FROBT</em>, <em>12</em>, 1605652. (<a href='https://doi.org/10.3389/frobt.2025.1605652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supportive robots that can be deployed in our homes will need to be understandable, operable, and teachable by non-expert users. This calls for an intuitive Human-Robot Interaction approach that is also safe and sustainable in the long term. Still, few studies have looked at interactive task learning in repeated, unscripted interactions within loosely supervised settings. In such cases the robot should incrementally learn from the user and consequentially expand its knowledge and abilities, a feature which presents the challenge of designing robots that interact and learn in real time. Here, we present a robotic system capable of continual learning from interaction, generalizing learned skills, and planning task execution based on the received training. We were interested in how interacting with such a system would impact the user experience and understanding. In an exploratory study, we assessed such dynamics with participants free to teach the robot simple tasks in Augmented Reality without supervision. Participants could access AR glasses spontaneously in a shared space and demonstrate physical skills in a virtual kitchen scene. A holographic robot gave feedback on its understanding and, after the demonstration, could ask questions to generalize the acquired task knowledge. The robot learned the semantic effects of the demonstrated actions and, upon request, could reproduce those on observed or novel objects through generalization. The results show that the users found the system engaging, understandable, and trustworthy, but with larger variance on the last two constructs. Participants who explored the scene more were able to expand the robot’s knowledge more effectively, and those who felt they understood the robot better were also more trusting toward it. No significant variation in the user experience or their teaching behavior was found across two interactions, yet the low return rate and free-form comments hint at critical lessons for interactive learning systems.},
  archive      = {J_FROBT},
  author       = {Belardinelli, Anna and Wang, Chao and Tanneberg, Daniel and Hasler, Stephan and Gienger, Michael},
  doi          = {10.3389/frobt.2025.1605652},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1605652},
  shortjournal = {Front. Robot. AI},
  title        = {Train your robot in AR: Insights and challenges for humans and robots in continual teaching and learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agentic LLM-based robotic systems for real-world applications: A review on their agenticness and ethics. <em>FROBT</em>, <em>12</em>, 1605405. (<a href='https://doi.org/10.3389/frobt.2025.1605405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic AI refers to autonomous systems that can perceive their environment, make decisions, and take actions to achieve goals with minimal or no human intervention. Recent advances in Large Language Models (LLMs) have opened new pathways to imbue robots with such “agentic” behaviors by leveraging the LLMs’ vast knowledge and reasoning capabilities for planning and control. This survey provides the first comprehensive exploration of LLM-based robotic systems integration into agentic behaviors that have been validated in real-world applications. We systematically categorized these systems across navigation, manipulation, multi-agent, and general-purpose multi-task robots, reflecting the range of applications explored. We introduce a novel, first-of-its-kind agenticness classification that evaluates existing LLM-driven robotic works based on their degree of autonomy, goal-directed behavior, adaptability, and decision-making. Additionally, central to our contribution is an evaluation framework explicitly addressing ethical, safety, and transparency principles—including bias mitigation, fairness, robustness, safety guardrails, human oversight, explainability, auditability, and regulatory compliance. By jointly mapping the landscape of agentic capabilities and ethical safeguards, we uncover key gaps, tensions, and design trade-offs in current approaches. We believe that this work serves as both a diagnostic and a call to action: as LLM-empowered robots grow more capable, ensuring they remain comprehensible, controllable, and aligned with societal norms is not optional—it is essential.},
  archive      = {J_FROBT},
  author       = {Raptis, Emmanuel K. and Kapoutsis, Athanasios Ch. and Kosmatopoulos, Elias B.},
  doi          = {10.3389/frobt.2025.1605405},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1605405},
  shortjournal = {Front. Robot. AI},
  title        = {Agentic LLM-based robotic systems for real-world applications: A review on their agenticness and ethics},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal perception-driven decision-making for human-robot interaction: A survey. <em>FROBT</em>, <em>12</em>, 1604472. (<a href='https://doi.org/10.3389/frobt.2025.1604472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal perception is essential for enabling robots to understand and interact with complex environments and human users by integrating diverse sensory data, such as vision, language, and tactile information. This capability plays a crucial role in decision-making in dynamic, complex environments. This survey provides a comprehensive review of advancements in multimodal perception and its integration with decision-making in robotics from year 2004–2024. We systematically summarize existing multimodal perception-driven decision-making (MPDDM) frameworks, highlighting their advantages in dynamic environments and the methodologies employed in human-robot interaction (HRI). Beyond reviewing these frameworks, we analyze key challenges in multimodal perception and decision-making, focusing on technical integration and sensor noise, adaptation, domain generalization, and safety and robustness. Finally, we outline future research directions, emphasizing the need for adaptive multimodal fusion techniques, more efficient learning paradigms, and human-trusted decision-making frameworks to advance the HRI field.},
  archive      = {J_FROBT},
  author       = {Zhao, Wenzheng and Gangaraju, Kruthika and Yuan, Fengpei},
  doi          = {10.3389/frobt.2025.1604472},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1604472},
  shortjournal = {Front. Robot. AI},
  title        = {Multimodal perception-driven decision-making for human-robot interaction: A survey},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AUSPEX: An integrated open-source decision-making framework for UAVs in rescue missions. <em>FROBT</em>, <em>12</em>, 1583479. (<a href='https://doi.org/10.3389/frobt.2025.1583479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have become paramount for search and rescue (SAR) missions due to their ability to access hazardous and challenging environments and to rapidly provide cost-effective aerial situational awareness. Nevertheless, current UAV systems are designed for specific tasks, often focusing on benchmarking use cases. Therefore, they offer limited adaptability for the diverse decision-making demands of SAR missions. Furthermore, commercially available integrated UAV systems are non-open-source, preventing further extension with state-of-the-art decision-making algorithms. In this paper, we introduce Automated Unmanned Aerial Swarm System for Planning and EXecution (AUSPEX), which is a holistic, modular, and open-source framework tailored specifically for enhancing the decision-making capabilities of UAV systems. AUSPEX integrates diverse capabilities for knowledge representation, perception, planning, and execution with state-of-the-art decision-making algorithms. Additionally, AUSPEX considers the heterogeneity of available UAV platforms and offers the possibility of including off-the-shelf and generic UAVs, with an open architecture into the AUSPEX ecosystem. The framework relies only on open-source components to ensure transparency, as well as system scalability and extensibility. We demonstrate AUSPEX’s integration with the Unreal Engine-based simulation framework REAP for software-in-the-loop validation and a platform-independent graphical user interface (AUGUR). We demonstrate how AUSPEX can be used for generic scenarios in SAR missions while highlighting its potential for future extensibility.},
  archive      = {J_FROBT},
  author       = {Döschl, Björn and Sommer, Kai and Kiam, Jane Jean},
  doi          = {10.3389/frobt.2025.1583479},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1583479},
  shortjournal = {Front. Robot. AI},
  title        = {AUSPEX: An integrated open-source decision-making framework for UAVs in rescue missions},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards fluid human-agent collaboration: From dynamic collaboration patterns to models of theory of mind reasoning. <em>FROBT</em>, <em>12</em>, 1532693. (<a href='https://doi.org/10.3389/frobt.2025.1532693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborating in real-life situations rarely follows predefined roles or plans, but is established on the fly and flexibly coordinated by the interacting agents. We introduce the notion of fluid collaboration (FC), marked by frequent changes of the tasks partners assume or the resources they consume in response to varying requirements or affordances of the environment, tasks, or other agents. FC thus necessitates dynamic, action-oriented Theory of Mind reasoning to enable agents to continuously infer and adapt to others’ intentions and beliefs in real-time. In this paper, we discuss how FC can be enabled in human-agent collaboration. We introduce Cooperative Cuisine, an interactive environment inspired by the game Overcooked! that facilitates human-human and human-agent collaboration in dynamic settings. We report results of an empirical study on human-human collaboration in CoCu, showing how FC can be measured empirically and that humans naturally engage in dynamically established collaboration patterns with minimal explicit communication and relying on efficient mentalizing. We then present an approach to develop artificial agents that can effectively participate in FC. Specifically, we argue for a model of dynamic mentalizing under computational constraints and integrated with action planning. We present first steps in this direction by addressing resource-rational and action-driven ToM reasoning.},
  archive      = {J_FROBT},
  author       = {Schröder, Florian and Heinrich, Fabian and Kopp, Stefan},
  doi          = {10.3389/frobt.2025.1532693},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1532693},
  shortjournal = {Front. Robot. AI},
  title        = {Towards fluid human-agent collaboration: From dynamic collaboration patterns to models of theory of mind reasoning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Merging symbolic and data-driven AI for robot autonomy. <em>FROBT</em>, <em>12</em>, 1662674. (<a href='https://doi.org/10.3389/frobt.2025.1662674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly being deployed to assist humans in many applications such as medicine, 11 navigation, and industrial automation. To truly collaborate with humans in complex 12 environments, robots require advanced cognitive capabilities, including the ability to reason with 13 domain-specific commonsense knowledge and the noisy observations obtained in the presence of 14 partial observability and non-deterministic action outcomes. In summary, the contributions to this topic highlight the importance of merging symbolic and 80 data-driven AI methods in the context of robotics (and AI). These papers demonstrate how such 81 hybrid frameworks enable robots to reason with complex cognitive theories and noisy 82 multimodal sensor observations to achieve reliable, efficient, and transparent scene 83 understanding, planning, diagnostics, and human-robot collaboration in complex simulated and 84},
  archive      = {J_FROBT},
  author       = {Meli, Daniele and Sridharan, Mohan and Perri, Simona and Katzouris, Nikos},
  doi          = {10.3389/frobt.2025.1662674},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1662674},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Merging symbolic and data-driven AI for robot autonomy},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid elastic-hyperelastic approach for simulating soft tactile sensors. <em>FROBT</em>, <em>12</em>, 1639524. (<a href='https://doi.org/10.3389/frobt.2025.1639524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient robotic grasping increasingly relies on artificial intelligence (AI) and tactile sensing technologies, which necessitate the acquisition of substantial data—a task that can often prove challenging. Consequently, the alternative of generating tactile data through precise and efficient simulations is becoming increasingly appealing. A significant challenge for simulating tactile sensors is balancing the trade-off between accuracy and processing time in simulation algorithms and models. To address this, we propose a hybrid approach that combines elastic and hyperelastic finite element simulations, complemented by convolutional neural networks (CNNs), to generate synthetic tactile maps of a soft capacitive tactile sensor. By leveraging a dataset of 53,400 real-world tactile maps, this methodology enables effective training, validation, and testing of each pipeline. This approach combines a fast elastic model for simple contact patches with a more detailed but slower hyperelastic model when greater precision is required. Our method automatically assesses contact patch complexity based on parameters associated with the object’s mesh to determine the most appropriate modeling technique by still ensuring accurate deformation simulation. Tested on a dataset of 12 unseen objects, our approach achieves up to 97% Structural Similarity Index Measure (SSIM) for the hyperelastic model and 90% for the elastic model. This hybrid strategy enables an adaptive balance between simulation speed and accuracy, making it suitable for generating synthetic tactile data across tasks with varying precision demands and object geometrical complexities.},
  archive      = {J_FROBT},
  author       = {De la Cruz Sánchez, Berith Atemoztli and Roberge, Jean-Philippe},
  doi          = {10.3389/frobt.2025.1639524},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1639524},
  shortjournal = {Front. Robot. AI},
  title        = {A hybrid elastic-hyperelastic approach for simulating soft tactile sensors},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer robotic controller for enhancing the safety of mobile robot navigation in human-centered indoor environments. <em>FROBT</em>, <em>12</em>, 1629931. (<a href='https://doi.org/10.3389/frobt.2025.1629931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a multi-layer navigation system for indoor mobile robots when they share space with vulnerable individuals. The primary objectives are increasing or maintaining safety measures and curtailing operational costs, emphasizing reducing reliance on intricate sensor technologies and computational resources. The developed system employs a three-tiered control approach, with each layer playing a pivotal role in the navigation process. The “online” control layer integrates a human-in-the-loop strategy, where the human operator detects missing obstacles or approaching danger through a user interface and sends a trigger to the robot’s controller. This trigger enables the system to estimate the coordinates of the danger and update the robot’s navigation path in real time, minimizing reliance on complex sensor systems. The “semi-online” control layer generates dynamic virtual barriers to restrict the robot’s navigation in specific areas during specific times. This ensures the robot avoids hazardous zones that could pose temporary risks to the human or robot. For example, areas with temporary obstructions or potential danger, such as kids’ play zones or during cleaning, are temporarily restricted from the robot’s path, ensuring safe navigation without relying solely on real-time sensor data. The “offline” control layer centers around the use of semantic information to control the robot’s behavior according to user-defined space management and safety requirements. By leveraging Building Information Models (BIM) as digital twins, this layer combines semantic and geometric data to comprehensively understand the environment. It enables the robot to navigate according to precise user requirements, utilizing the semantic context for path planning and behavior control. This layer obviates the need for a real-time sensor mapping process, making the system more efficient and adaptable to user needs. This research represents a significant step forward in enhancing the navigational capabilities of robots within human-centric indoor environments, with a core focus on safety, adaptability, and cost-effectiveness.},
  archive      = {J_FROBT},
  author       = {Omer, Karameldeen and Monteriù, Andrea},
  doi          = {10.3389/frobt.2025.1629931},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1629931},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-layer robotic controller for enhancing the safety of mobile robot navigation in human-centered indoor environments},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pivot joint steering mechanism for tip-everting soft growing robots. <em>FROBT</em>, <em>12</em>, 1627116. (<a href='https://doi.org/10.3389/frobt.2025.1627116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft growing robots (SGRs) navigate confined environments by everting material from the tip while keeping the rest of the body stationary, enabling frictionless navigation. This opens up huge potential for inspection, search, and rescue tasks. However, controlling the direction of tip growth is still a challenge because of the ever-changing tip of the robot during tip growth. This study presents a compact steering mechanism that integrates a tendon-driven pivot joint with a pressure-tunable internal bladder. By modulating friction between the pivot joint and the inner material, the mechanism switches between two states: decoupled (stationary for bending) and coupled (move forward together with robot’s inner material). This enables the robot to bend locally and then continue growing in the new direction, without using complex full-body actuation or external mechanisms. A robotic platform was developed to implement this mechanism, and its performance was characterized and validated through modeling and experiments. Experimental results confirm that the mechanism achieves reliable tip steering, closely matches kinematics models, and interacts gently with the environment. The proposed design offers a scalable and structurally simple solution for long-range navigation in soft growing robots.},
  archive      = {J_FROBT},
  author       = {Ji, Tianchen and Bi, Zheyuan and Cao, Lin},
  doi          = {10.3389/frobt.2025.1627116},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1627116},
  shortjournal = {Front. Robot. AI},
  title        = {A pivot joint steering mechanism for tip-everting soft growing robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model-driven natural language interaction control framework for single-operator bimanual teleoperation. <em>FROBT</em>, <em>12</em>, 1621033. (<a href='https://doi.org/10.3389/frobt.2025.1621033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bimanual teleoperation imposes cognitive and coordination demands on a single human operator tasked with simultaneously controlling two robotic arms. Although assigning each arm to a separate operator can distribute workload, it often leads to ambiguities in decision authority and degrades overall efficiency. To overcome these challenges, we propose a novel bimanual teleoperation large language model assistant (BTLA) framework, an intelligent co-pilot that augments a single operator’s motor control capabilities. In particular, BTLA enables operators to directly control one robotic arm through conventional teleoperation while directing a second assistive arm via simple voice commands, and therefore commanding two robotic arms simultaneously. By integrating the GPT-3.5-turbo model, BTLA interprets contextual voice instructions and autonomously selects among six predefined manipulation skills, including real-time mirroring, trajectory following, and autonomous object grasping. Experimental evaluations in bimanual object manipulation tasks demonstrate that BTLA increased task coverage by 76.1% and success rate by 240.8% relative to solo teleoperation, and outperformed dyadic control with a 19.4% gain in coverage and a 69.9% gain in success. Furthermore, NASA Task Load Index (NASA-TLX) assessments revealed a 38–52% reduction in operator mental workload, and 85% of participants rated the voice-based interaction as “natural” and “highly effective.”},
  archive      = {J_FROBT},
  author       = {Fei, Haolin and Xue, Tao and He, Yiyang and Lin, Sheng and Du, Guanglong and Guo, Yao and Wang, Ziwei},
  doi          = {10.3389/frobt.2025.1621033},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1621033},
  shortjournal = {Front. Robot. AI},
  title        = {Large language model-driven natural language interaction control framework for single-operator bimanual teleoperation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Project-based learning with arduino robots: Impact on undergraduate students’ achievement and task persistence in robotics programming. <em>FROBT</em>, <em>12</em>, 1615427. (<a href='https://doi.org/10.3389/frobt.2025.1615427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionProgramming is a fundamental skill in the 21st century, yet there is a global shortage of skilled programmers for high-tech jobs. This study determined the effects of Project-Based Arduino Robot Application (PARA) on undergraduate students’ achievement and task persistence in robotics programming.MethodsThe quasi-experimental research design was adopted for the study. A sample of 74 second-year computer and robotics education students from three intact classes in three tertiary institutions offering robotics programming II were selected forthe study.Results and DiscussionPARA improved the academic achievement of students in robotics programming (63.00 ± 16.81) more than the conventional method, which uses Interactive PowerPoint (IPP) (43.79 ± 12.07). PARA improved the task persistence of students in robotics programming (73.75 ± 13.46) more than the conventional method (40.00 ± 13.70). Male students taught robotics programming using PARA had a slightly higher mean achievement score (69.60 ± 11.50) than their female counterparts (52.00 ± 19.43). Female students taught robotics programming using PARA had a slightly higher mean task persistence score (78.67 ± 11.96) than their male counterparts (70.80 ± 14.02). There was a significant difference (p < 0.05) in students’ mean achievement scores based on the instruction method used in teaching robotics programming, among others. These findings have implications for instructing students who find robotics programming difficult and abstract.},
  archive      = {J_FROBT},
  author       = {Nannim, Fadip Audu and Ibezim, Nnenna E. and Mosia, Moeketsi and Oguguo, Basil C. E.},
  doi          = {10.3389/frobt.2025.1615427},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1615427},
  shortjournal = {Front. Robot. AI},
  title        = {Project-based learning with arduino robots: Impact on undergraduate students’ achievement and task persistence in robotics programming},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Responsible and adaptive robots in care home settings: An implementation framework analysis of a workshop with public and professionals. <em>FROBT</em>, <em>12</em>, 1610329. (<a href='https://doi.org/10.3389/frobt.2025.1610329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As populations grow, research looks to emerging adaptive technologies for the urgent challenge in providing suitable care for older adults. Drawing on implementation science, we conducted a holistic examination looking at broader, contextual factors relating to the acceptability of robotics and sensor technologies in care homes. We held a workshop that brought together members of the public and researchers with experience in care home, to try such technologies and discuss their application in different care home scenarios. Using the NASSS framework, we examine acceptability through the angles of technology, condition, adopters, value proposition, organisation, wider context, and sustainability. While both groups of participants share concerns about the negative impacts of robotics on the quality of care, we also uncovered additional areas of further consideration relating to tensions between stakeholders and constraints around material resources, culture, processes and regulatory considerations.},
  archive      = {J_FROBT},
  author       = {Boudouraki, Andriana and Waheed, Maria and Mestre, Rafael and Landowska, Aleksandra and Georgara, Athina and Deshmukh, Jayati and Singh, Lokesh and Abioye, Ayodeji O. and Viet Tuyen, Nguyen Tan and Dong, Yi and Ao, Shuang and Price, Dominic and Fischer, Joel and Bergin, Aislinn Gomez},
  doi          = {10.3389/frobt.2025.1610329},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1610329},
  shortjournal = {Front. Robot. AI},
  title        = {Responsible and adaptive robots in care home settings: An implementation framework analysis of a workshop with public and professionals},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous navigation of quadrupeds using coverage path planning with morphological skeleton maps. <em>FROBT</em>, <em>12</em>, 1601862. (<a href='https://doi.org/10.3389/frobt.2025.1601862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel method of coverage path planning for the purpose of scanning an unstructured environment autonomously. The method uses the morphological skeleton of a prior 2D navigation map via SLAM to generate a sequence of points of interest (POIs). This sequence is then ordered to create an optimal path based on the robot’s current position. To control the high-level operation, a finite state machine (FSM) is used to switch between two modes: navigating toward a POI using Nav2 and scanning the local surroundings. We validate the method in a leveled, indoor, obstacle-free, non-convex environment, evaluating time efficiency and reachability over five trials. The map reader and path planner can quickly process maps of widths and heights ranging between [196,225] pixels and [185,231] pixels in 2.52 ms and 1.7 ms, respectively. Their computation time increases with 22.0 ns/pixel and 8.17 μs/pixel, respectively. The robot managed to reach 86.5% of all waypoints across the five runs. The proposed method suffers from drift occurring in the 2D navigation map.},
  archive      = {J_FROBT},
  author       = {Becoy, Alexander James and Khomenko, Kseniia and Peternel, Luka and Rajan, Raj Thilak},
  doi          = {10.3389/frobt.2025.1601862},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1601862},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous navigation of quadrupeds using coverage path planning with morphological skeleton maps},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Bio-inspired legged robotics: Design, sensing and control. <em>FROBT</em>, <em>12</em>, 1600814. (<a href='https://doi.org/10.3389/frobt.2025.1600814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {1. INTRODUCTIONAs a result of more than millions of years' evolution, legged animals have showcased unrivaled sophisticated mobility, maneuverability and adaptation to complex environments, and have continuously inspired legged robot design. Bio-inspired legged robots have unique potential advantages in applications which require the transversal on rough terrain, exploration of unstructured environments and navigation in complex environments with obstacles that call for advanced maneuverability and control. In addition to the exceptional mobility, legged animals have established a complex sensing system with the environment that is significantly advantageous over the state-of-the-art robot sensation. With the impressive progress of artificial intelligence and sensing technologies in recent years, the bio-inspired legged robots have also experienced notable growth, accompanied by tremendous challenges though. This special collection aims to disseminate some of the latest advancements in the design, sensing and control of bioinspired legged robots.2. OVERVIEW OF THE PAPERS IN THIS SPECIAL ISSUEThe selected papers include theoretical and experimental research work on bicycleinspired balance control method for quadruped robots [1]; advancements of the understanding of the neural activity of robust robot locomotion control from computational neuroscience within deep reinforcement learning [2]; system design of a pneumatic-driven musculoskeletal bipedal robot with its sequential jumping experimental validation [3]; investigations on the postural stabilization for a musculoskeletal robot during rapid and powerful hopping actions through the emulation of biarticular thigh muscles activation, along with experimental validation [4]; and the exploration of unknown environments using generalized autonomous mobile robots within simultaneous learning of the environments and robot transversality [5].3. CONCLUSIONIn conclusion, this special issue covers a broad range in the design, sensing and control of bio-inspired legged robots, and represents a significant step forward in the latest bioinspired legged robot research. All papers in this issue present original, inspirational ideas, with a clear indication of problem formulation and methodologies, convincing experimental validations, potential applications, and proper paper organization. The achievements presented in these papers address some of the challenges and advance research on bio-inspired legged robot design, sensing and control. We hope this Special Issue will be helpful to enhance understanding and further research in this exciting field, and promote academic and industrial attention.4. ACKNOWLEDGEMENTWe thank all authors and all guest associate editors, review editors, and peer reviewers for their valuable contributions to the Special Issue ‘Bio-Inspired Legged Robotics: Design, Sensing and Control’.},
  archive      = {J_FROBT},
  author       = {Zou, Ting},
  doi          = {10.3389/frobt.2025.1600814},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1600814},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Bio-inspired legged robotics: Design, sensing and control},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentivising cooperation by judging a group’s performance by its weakest member in neuroevolution and reinforcement learning. <em>FROBT</em>, <em>12</em>, 1599676. (<a href='https://doi.org/10.3389/frobt.2025.1599676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAutonomous agents increasingly interact within social domains such as customer service, transportation, and healthcare, often acting collectively on behalf of humans. In many of these scenarios, individually greedy strategies can diminish overall performance, exemplified by phenomena such as stop-and-go traffic congestion or network service disruptions due to competing interests. Thus, there is a growing need to develop decision-making strategies for autonomous agents that balance individual efficiency with group equitability.MethodsWe propose a straightforward approach for rewarding groups of autonomous agents within evolutionary and reinforcement learning frameworks based explicitly on the performance of the weakest member of the group. Rather than optimizing each agent's individual rewards independently, we align incentives by using a “weakest-link” metric, thereby encouraging collective strategies that support equitable outcomes.ResultsOur results demonstrate that this weakest-member reward system effectively promotes equitable behavior among autonomous agents. Agents evolve or learn to balance collective benefit with individual performance, resulting in fairer outcomes for the entire group. Notably, the introduced approach improves overall efficiency, as equitably-minded agents collectively achieve greater stability and higher individual outcomes than agents pursuing purely selfish strategies.DiscussionThis methodology aligns closely with biological mechanisms observed in nature, specifically group-level selection and inclusive fitness theory. By tying the evolutionary and learning objectives to the group’s weakest member, we mimic natural processes that favor cooperative and equitable behaviors. Our findings highlight the importance of incentive structures that consider the collective well-being to optimize both group fairness and individual agent success. Future research should explore how this reward framework generalizes across broader domains and more complex agent interactions.},
  archive      = {J_FROBT},
  author       = {Schossau, Jory and Shirmohammadi, Bamshad and Hintze, Arend},
  doi          = {10.3389/frobt.2025.1599676},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1599676},
  shortjournal = {Front. Robot. AI},
  title        = {Incentivising cooperation by judging a group’s performance by its weakest member in neuroevolution and reinforcement learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The power of combined modalities in interactive robot learning. <em>FROBT</em>, <em>12</em>, 1598968. (<a href='https://doi.org/10.3389/frobt.2025.1598968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of Artificial intelligence (AI), robots as embodied intelligent systems are increasingly becoming more present in daily life like households or in elderly care. As a result, lay users are required to interact with these systems more frequently and teach them to meet individual needs. Human-in-the-loop reinforcement learning (HIL-RL) offers an effective way to realize this teaching. Studies show that various feedback modalities, such as preference, guidance, or demonstration can significantly enhance learning success, though their suitability varies among users expertise in robotics. Research also indicates that users apply different scaffolding strategies when teaching a robot, such as motivating it to explore actions that promise success. Thus, providing a collection of different feedback modalities allows users to choose the method that best suits their teaching strategy, and allows the system to individually support the user based on their interaction behavior. However, most state-of-the-art approaches provide users with only one feedback modality at a time. Investigating combined feedback modalities in interactive robot learning remains an open challenge. To address this, we conducted a study that combined common feedback modalities. Our research questions focused on whether these combinations improve learning outcomes, reveal user preferences, show differences in perceived effectiveness, and identify which modalities influence learning the most. The results show that combining the feedback modalities improves learning, with users perceiving the effectiveness of the modalities vary ways, and certain modalities directly impacting learning success. The study demonstrates that combining feedback modalities can support learning even in a simplified setting and suggests the potential for broader applicability, especially in robot learning scenarios with a focus on user interaction. Thus, this paper aims to motivate the use of combined feedback modalities in interactive imitation learning.},
  archive      = {J_FROBT},
  author       = {Beierling, Helen and Beierling, Robin and Vollmer, Anna-Lisa},
  doi          = {10.3389/frobt.2025.1598968},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1598968},
  shortjournal = {Front. Robot. AI},
  title        = {The power of combined modalities in interactive robot learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-based approach to automation of formal verification of ROS 2-based systems. <em>FROBT</em>, <em>12</em>, 1592523. (<a href='https://doi.org/10.3389/frobt.2025.1592523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal verification of robotic applications, particularly those based on ROS 2, is desirable for ensuring correctness and safety. However, the complexity of formal methods and the manual effort required for model creation and parameter extraction often hinder their adoption. This paper addresses these challenges by proposing a model-based methodology that automates the formal verification process using model-driven engineering techniques. We introduce a methodology which can be applied as a toolchain that automates the initialization of formal model templates in UPPAAL using system parameters derived from ROS 2 execution traces generated by the ROS2_tracing tool. The toolchain employs four model representations based on custom Eclipse Ecore metamodels to capture both structural and verification aspects of ROS 2 systems. The methodology supports both implemented and conceptual systems and enables iterative verification of timing and scheduling parameters through model-to-model and model-to-text transformations. A proof-of-concept implementation demonstrates the feasibility of the proposed approach. The designed toolchain supports verification using two types of UPPAAL models: one for individual node verification (e.g., callback latency and buffer overflow) and another for end-to-end latency analysis of ROS 2 processing chains. Experiments conducted on two implemented and one conceptual ROS 2 systems validate the correctness and adaptability of the toolchain. The results show that the toolchain can automate parameter extraction and model generation. The proposed methodology modularizes the verification process, allowing domain experts to focus on their areas of expertise. It targets to enhances traceability and reusability across different verification scenarios and formal models. The approach aims to make formal verification more accessible and practical to robotics developers.},
  archive      = {J_FROBT},
  author       = {Dust, Lukas and Gu, Rong and Mubeen, Saad and Ekström, Mikael and Seceleanu, Cristina},
  doi          = {10.3389/frobt.2025.1592523},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1592523},
  shortjournal = {Front. Robot. AI},
  title        = {A model-based approach to automation of formal verification of ROS 2-based systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-robot collaborative manipulation framework for dynamic and obstacle-dense environments: Integration of deep learning for real-time task execution. <em>FROBT</em>, <em>12</em>, 1585544. (<a href='https://doi.org/10.3389/frobt.2025.1585544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-robot collaborative manipulation framework, implemented in the Gazebo simulation environment, designed to enable the execution of autonomous tasks by mobile manipulators in dynamic environments and dense obstacles. The system consists of multiple mobile robot platforms, each equipped with a robotic manipulator, a simulated RGB-D camera, and a 2D LiDAR sensor on the mobile base, facilitating task coordination, object detection, and advanced collision avoidance within a simulated warehouse setting. A leader-follower architecture governs collaboration, allowing for the dynamic formation of teams to tackle tasks requiring combined effort, such as transporting heavy objects. Task allocation and control are achieved through a centralized control structure architecture in which the leader robot coordinates subordinate units based on high-level task assignments. The framework incorporates deep learning-based object detection (YOLOv2) to identify target objects using a simulated RGB-D camera mounted on the manipulator’s end-effector. Path planning is achieved through a sampling-based algorithm that is integrated with the LiDAR data to facilitate precise obstacle avoidance and localization. It also provides real-time path rerouting for safe navigation when dynamically moving obstacles, such as humans or other entities, intersect planned paths. This functionality ensures uninterrupted task execution and enhances safety in human-robot shared spaces. High-level task scheduling and control transitions are managed using MATLAB and Stateflow logic, while ROS facilitates data communication between MATLAB, Simulink, and Gazebo. This multirobot architecture is adaptable, allowing configuration of team size for collaborative tasks based on load requirements and environmental complexity. By integrating computer vision and deep learning for visual processing, and YOLOv2 for object detection, the system efficiently identifies, picks, and transports objects to designated locations, demonstrating the scalability of multi-robot framework for future applications in logistics automation, collaborative manufacturing, and dynamic human-robot interaction scenarios.},
  archive      = {J_FROBT},
  author       = {Adil, Afnan Ahmed and Sakhrieh, Saber and Mounsef, Jinane and Maalouf, Noel},
  doi          = {10.3389/frobt.2025.1585544},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1585544},
  shortjournal = {Front. Robot. AI},
  title        = {A multi-robot collaborative manipulation framework for dynamic and obstacle-dense environments: Integration of deep learning for real-time task execution},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Versatile kinematics-based constraint identification applied to robot task reproduction. <em>FROBT</em>, <em>12</em>, 1574110. (<a href='https://doi.org/10.3389/frobt.2025.1574110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying kinematic constraints between a robot and its environment can improve autonomous task execution, for example, in Learning from Demonstration. Constraint identification methods in the literature often require specific prior constraint models, geometry or noise estimates, or force measurements. Because such specific prior information or measurements are not always available, we propose a versatile kinematics-only method. We identify constraints using constraint reference frames, which are attached to a robot or ground body and may have zero-velocity constraints along their axes. Given measured kinematics, constraint frames are identified by minimizing a norm on the Cartesian components of the velocities expressed in that frame. Thereby, a minimal representation of the velocities is found, which represent the zero-velocity constraints we aim to find. In simulation experiments, we identified the geometry (position and orientation) of twelve different constraints including articulated contacts, polyhedral contacts, and contour following contacts. Accuracy was found to decrease linearly with sensor noise. In robot experiments, we identified constraint frames in various tasks and used them for task reproduction. Reproduction performance was similar when using our constraint identification method compared to methods from the literature. Our method can be applied to a large variety of robots in environments without prior constraint information, such as in everyday robot settings.},
  archive      = {J_FROBT},
  author       = {Overbeek, Alex H. G. and Dresscher, Douwe and van der Kooij, Herman and Vlutters, Mark},
  doi          = {10.3389/frobt.2025.1574110},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1574110},
  shortjournal = {Front. Robot. AI},
  title        = {Versatile kinematics-based constraint identification applied to robot task reproduction},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid intelligence systems for reliable automation: Advancing knowledge work and autonomous operations with scalable AI architectures. <em>FROBT</em>, <em>12</em>, 1566623. (<a href='https://doi.org/10.3389/frobt.2025.1566623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMission-critical automation demands decision-making that is explainable, adaptive, and scalable—attributes elusive to purely symbolic or data-driven approaches. We introduce a hybrid intelligence (H-I) system that fuses symbolic reasoning with advanced machine learning via a hierarchical architecture, inspired by cognitive frameworks like Global Workspace Theory (Baars, A Cognitive Theory of Consciousness, 1988).MethodsThis architecture operates across three levels to achieve autonomous, end-to-end workflows: Navigation: Using Vision Transformers, and graph-based neural networks, the system navigates file systems, databases, and software interfaces with precision. Discrete Actions: Multi-framework automated machine learning (AutoML) trains agents to execute discrete decisions, augmented by Transformers and Joint Embedding Predictive Architectures (JEPA) (Assran et al., 2023, 15619–15629) for complex time-series analysis, such as anomaly detection. Planning: Reinforcement learning, world model-based reinforcement learning, and model predictive control orchestrate adaptive workflows tailored to user requests or live system demands.ResultsThe system’s capabilities are demonstrated in two mission-critical applications: Space Domain Awareness, Satellite Behavior Detection: A graph-based JEPA paired with multi-agent reinforcement learning enables near real-time anomaly detection across 15,000 on-orbit objects, delivering a precision-recall score of 0.98. Autonomously Driven Simulation Setup: The system autonomously configures Computational Fluid Dynamics (CFD) setups, with an AutoML-driven optimizer enhancing the meshing step—boosting boundary layer capture propagation (BL-CP) from 8% to 98% and cutting geometry failure rates from 88% to 2% on novel aircraft geometries. Scalability is a cornerstone, with the distributed training pipeline achieving linear scaling across 2,000 compute nodes for AI model training, while secure model aggregation incurs less than 4% latency in cross-domain settings.DiscussionBy blending symbolic precision with data-driven adaptability, this hybrid intelligence system offers a robust, transferable framework for automating complex knowledge work in domains like space operations and engineering simulations—and adjacent applications such as autonomous energy and industrial facility operations, paving the way for next-generation industrial AI systems.},
  archive      = {J_FROBT},
  author       = {Grosvenor, Allan and Zemlyansky, Anton and Wahab, Abdul and Bohachov, Kyrylo and Dogan, Aras and Deighan, Dwyer},
  doi          = {10.3389/frobt.2025.1566623},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1566623},
  shortjournal = {Front. Robot. AI},
  title        = {Hybrid intelligence systems for reliable automation: Advancing knowledge work and autonomous operations with scalable AI architectures},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parametric modeling of deformable linear objects for robotic outfitting and maintenance of space systems. <em>FROBT</em>, <em>12</em>, 1565837. (<a href='https://doi.org/10.3389/frobt.2025.1565837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outfitting and maintenance are important to an in-space architecture consisting of long duration missions. During such missions, crew is not continuously present; robotic agents become essential to the construction, maintenance, and servicing of complicated space assets, requiring some degree of autonomy to plan and execute tasks. There has been significant research into manipulation planning for rigid elements for in-space assembly and servicing, but flexible electrical cables, which fall under the domain of Deformable Linear Objects (DLOs), have not received such attention despite being critical components of powered space systems. Cables often have a non-zero bend equilibrium configuration, which the majority of DLO research does not consider. This article implements a model-based optimization approach to estimate cable configuration, where a design parameter of the model’s discretization level enables trading model accuracy vs computational complexity. Observed 2D cable configurations are used to improve the model via parameter estimation. The parameter estimation is validated through comparing predicted configurations based on estimated parameters to that of a real cable. The incorporation of parameter estimation to the cable model is shown to reduce prediction errors by an order of magnitude. The results of this work demonstrate some of the challenges present with robotic cable manipulation, exploring the complexities of outfitting and maintenance operations of in-space facilities, and puts forth a method for reducing the size of the state space of a cable payload while accounting for non-zero equilibrium configurations.},
  archive      = {J_FROBT},
  author       = {Quartaro, Amy and Moser, Joshua and Cooper, John and Komendera, Erik},
  doi          = {10.3389/frobt.2025.1565837},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1565837},
  shortjournal = {Front. Robot. AI},
  title        = {Parametric modeling of deformable linear objects for robotic outfitting and maintenance of space systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot system assistant (RoSA): Evaluation of touch and speech input modalities for on-site HRI and telerobotics. <em>FROBT</em>, <em>12</em>, 1561188. (<a href='https://doi.org/10.3389/frobt.2025.1561188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future work scenarios envision increased collaboration between humans and robots, emphasizing the need for versatile interaction modalities. Robotic systems can support various use cases, including on-site operations and telerobotics. This study investigates a hybrid interaction model in which a single user engages with the same robot both on-site and remotely. Specifically, the Robot System Assistant (RoSA) framework is evaluated to assess the effectiveness of touch and speech input modalities in these contexts. The participants interact with two robots, Rosa and Ari, utilizing both input modalities. The results reveal that touch input excels in precision and task efficiency, while speech input is preferred for its intuitive and natural interaction flow. These findings contribute to understanding the complementary roles of touch and speech in hybrid systems and their potential for future telerobotic applications.},
  archive      = {J_FROBT},
  author       = {Strazdas, Dominykas and Busch, Matthias and Shaji, Rijin and Siegert, Ingo and Al-Hamadi, Ayoub},
  doi          = {10.3389/frobt.2025.1561188},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1561188},
  shortjournal = {Front. Robot. AI},
  title        = {Robot system assistant (RoSA): Evaluation of touch and speech input modalities for on-site HRI and telerobotics},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UpStory: The uppsala storytelling dataset. <em>FROBT</em>, <em>12</em>, 1547578. (<a href='https://doi.org/10.3389/frobt.2025.1547578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Friendship and rapport play an important role in the formation of constructive social interactions, and have been widely studied in education due to their impact on learning outcomes. Given the growing interest in automating the analysis of such phenomena through Machine Learning, access to annotated interaction datasets is highly valuable. However, no dataset on child-child interactions explicitly capturing rapport currently exists. Moreover, despite advances in the automatic analysis of human behavior, no previous work has addressed the prediction of rapport in child-child interactions in educational settings. We present UpStory — the Uppsala Storytelling dataset: a novel dataset of naturalistic dyadic interactions between primary school aged children, with an experimental manipulation of rapport. Pairs of children aged 8–10 participate in a task-oriented activity: designing a story together, while being allowed free movement within the play area. We promote balanced collection of different levels of rapport by using a within-subjects design: self-reported friendships are used to pair each child twice, either minimizing or maximizing pair separation in the friendship network. The dataset contains data for 35 pairs, totaling 3 h 40 m of audiovisual recordings. It includes two video sources, and separate voice recordings per child. An anonymized version of the dataset is made publicly available, containing per-frame head pose, body pose, and face features. Finally, we confirm the informative power of the UpStory dataset by establishing baselines for the prediction of rapport. A simple approach achieves 68% test accuracy using data from one child, and 70% test accuracy aggregating data from a pair.},
  archive      = {J_FROBT},
  author       = {Fraile, Marc and Calvo-Barajas, Natalia and Apeiron, Anastasia Sophia and Varni, Giovanna and Lindblad, Joakim and Sladoje, Nataša and Castellano, Ginevra},
  doi          = {10.3389/frobt.2025.1547578},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1547578},
  shortjournal = {Front. Robot. AI},
  title        = {UpStory: The uppsala storytelling dataset},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven modeling and identification of a bistable soft-robot element based on dielectric elastomer. <em>FROBT</em>, <em>12</em>, 1546945. (<a href='https://doi.org/10.3389/frobt.2025.1546945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the development and experimental validation of a hybrid modeling framework for a bistable soft robotic system driven by dielectric elastomer (DE) actuators. The proposed approach combines physics-based analytical modeling with data-driven radial basis function (RBF) networks to capture the nonlinear and dynamic behavior of the soft robots. The bistable DE system consists of a buckled beam structure and symmetric DE membranes to achieve rapid switching between two stable states. A physics-based model is first derived to describe the electromechanical coupling, energy functions, and dynamic behavior of the actuator. To address discrepancies between the analytical model and experimental data caused by geometric asymmetries and unmodeled effects, the model is augmented with RBF networks. The model is refined using experimental data and validated through analytical, numerical, and experimental investigation.},
  archive      = {J_FROBT},
  author       = {Masoud, Abd Elkarim and Maas, Jürgen},
  doi          = {10.3389/frobt.2025.1546945},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1546945},
  shortjournal = {Front. Robot. AI},
  title        = {Data-driven modeling and identification of a bistable soft-robot element based on dielectric elastomer},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Burrowing and unburrowing in submerged granular media through fluidization and shape-change. <em>FROBT</em>, <em>12</em>, 1546407. (<a href='https://doi.org/10.3389/frobt.2025.1546407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subterranean exploration in submerged granular media (GM) presents significant challenges for robotic systems due to high drag forces and the complex physics of GM. This paper introduces a robotic system that combines water-jet-based fluidization for self-burrowing in submerged environments and an untethered, volume-change mechanism for burrowing out. The water-based fluidization approach significantly reduces drag on the robot, allowing it to burrow into GM with minimal force. To burrow out, the robot uses a soft, inflatable bladder that undergoes periodic radial expansion, inspired by natural systems such as razor clams. Experimental results demonstrate that increased water flow rates accelerate the burrowing process, while the unburrowing mechanism is effective at varying depths. Comparisons between pneumatic and hydraulic untethered systems highlight trade-offs in terms of operational time and unburrowing speed. This work advances the capabilities of robots in underwater environments, with potential applications in environmental monitoring and underwater archaeology.},
  archive      = {J_FROBT},
  author       = {Nayak, Aniruddha and Seo, Hoseung and Gravish, Nick and Tolley, Michael T.},
  doi          = {10.3389/frobt.2025.1546407},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1546407},
  shortjournal = {Front. Robot. AI},
  title        = {Burrowing and unburrowing in submerged granular media through fluidization and shape-change},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building trust in the age of human-machine interaction: Insights, challenges, and future directions. <em>FROBT</em>, <em>12</em>, 1535082. (<a href='https://doi.org/10.3389/frobt.2025.1535082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is a foundation for human relationships, facilitating cooperation, collaboration, and social solidarity (Kramer, 1999). Trust in human relationships is generally based on factors like dependability, competence, generosity, and sincerity (Mayer et al., 1995; Lewicki & Bunker, 1996). Social norms, emotional intelligence, and the power of forecasting others' behaviors help create shared knowledge and mutual respect (Coleman, 1990; Rotter, 1980).As technology more and more becomes incorporated into everyday life, especially by means of artificial intelligence (AI) and robotics, the concept of trust has shifted paradigmatically (Lankton et al., 2015). In Human-Robot Interaction (HRI), trust does not derive from emotional familiarity or social intuition but rather from properties of the system itself, such as functionality, transparency, and predictability (Hancock et al., 2011). This invokes basic questions: Can humans ever trust machines? If they can, how is that trust established, sustained, or dissolved?There is growing evidence that humans can work with robots in various situations, such as search-and-rescue missions, education, and healthcare (Breazeal, 2003; Chen & Barnes, 2014; Nagpal et al., 2024; Nandanwar & Dutt, 2023). For instance, latest research utilizing Proximal Policy Optimization (PPO) and Generative Adversarial Imitation Learning (GAIL) identify that robots have the ability to excel over human peers in difficult search-and-retrieve tasks in a situation where trust is calibrated (Kapoor et al., 2024a; 2024b). In the same vein, emotionally responsive robots have demonstrated potential in improving language learning achievement in school children (Nagpal et al., 2024), whereas affective conversational agents assist in stress and anxiety reduction in patients (Nandanwar & Dutt, 2023).But embedding AI systems within fields such as autonomous driving, military action, and healthcare introduces novel trust challenges. These are the opacity of decision-making by algorithms, variable levels of autonomy, and cultural compatibility clashes in user expectations (Chen et al., 2018; Goodall, 2014; Schaefer et al., 2016). Even when AI is reliable, a lack of explainability will undermine user trust. Consequently, Explainable AI (XAI) is essential in closing the cognitive and affective space between humans and machines (Arrieta et al., 2020).However, trust in HRI is not always built. It differs by cultural environment, personality type, and task context. Although tremendous strides have been made in the modeling of trust as a system performance function, current models tend to overlook dynamic, emotional, and socio-cultural aspects (Eiband et al., 2018; Hoff & Bashir, 2015).This opinion paper contributes to the discussion by comparing the building blocks of trust in human-human and human-robot interaction. It presents the Trust-Affordance Adaptation Model (TAAM)—a theoretical framework that aligns trust-building tactics with domain requirements. We contend that emotional investment and functional openness need to be traded off depending on context, and we propose the incorporation of psycho-social cues, like biosensor information, into trust modeling. Through a synthesis of current literature and findings of recent empirical research, the paper provides a guide for developing reliable AI systems that are emotionally engaged, culturally adaptable, and context-sensitive.2. Trust in Human-Human InteractionSeveral basic disciplines, such as organizational behavior, psychology, and sociology, have thoroughly researched the interpersonal trust phenomena (Lewis & Weigert 1985; Rotter 1980). Based on Figure 1, it appears that there are many basic factors to consider that facilitate or sustain relationship trust. Establishing and maintaining trust is particularly difficult in business settings. Dependability is the primary trait, especially in firms where cooperation and production rely on one another (Mayer et al., 1995; Dirks & Ferrin, 2001). When individuals working in a team possess the appropriate level of confidence in their competence, they are capable of cooperating and actually achieving shared objectives. Figure 1. The primary elements of trust in human-machine relationships are transparency, predictability, autonomy and flexibility, user experience, and emotional engagement, while dependability, generosity, competence, and sincerity are the most significant elements in human-human relationships.The correspondences between human-human trust and human-machine trust is shown in Figure 1. These correspondences are based on well-established theoretical constructs for trust in automation and HRI. For instance, 'dependability' of human-human trust equates with 'transparency' of human-machine trust because both express reliability of intentions and actions (Muir, 1994). 'Generosity' translates into 'predictability', expressing anticipation of regular behavior that meets user requirements (Hancock et al., 2011). 'Competence' is a robot's 'autonomy and flexibility', which is its ability to accomplish tasks efficiently. ‘Sincerity’ parallels emotional involvement in robots, reflecting their perceived warmth and empathy in interactions (Nass & Moon, 2000). These parallels, illustrated in Figure 1, are conceptual and aimed at drawing meaningful bridges across social and technological domains of trust.Generosity, which refers to someone caring for you, facilitates the creation of trustful networks (Mayer et al., 1995). The element of human empathy maintains safeguarding as well as mutual respect for each other which comprises the basics of any relationship. In other extremities, people are even more willing to cooperate with others who strive to help them (Dirks & Ferrin, 2002). Another fundamental trait that brings about trust is competence, which is the ability to perform tasks in an effective manner with adequate resources which is particularly critical in the business arena (McAllister, 1995). In occupational groups, mutual trust between members and mutual trust in other members' competence improves collaboration in group work along with decision making, thus improving productivity (McNeese et al., 2021).Reciprocal trust can only be achieved through sincerity. One's integrity embraces honesty and fairness, which considers an individual's credibility and builds trust in the personal and organizational spheres (Mayer et al., 1995). Individual moral uniformity underwrites the founding base of trust. Furthermore, sincerity acts as the bedrock of moral relations that enhances cooperation and solidarity within a group.3. Trust in Human-Robot InteractionAs a component of HRI and like with all human interactions, trust is also an important factor that requires special attention. It is widely accepted that trust in systems is negatively impacted if there is a lack of system transparency or explainability (Hancock et al., 2011). Understanding what a robot is doing and how it arrives at its decisions influences trust, too. Explainable AI, or XAI, strives to make the reasoning behind automated systems’ decisions more understandable, which in turn enhances reliance and endorsement (Arrieta et al., 2020). Human-robot collaboration studies put forward transparency as an important factor for trust. In other cases, simple but reliable robots exceed humans’ performance in PPO search and retrieval. It has been proposed that the formation of trust and collaboration is enhanced when robots meet expectations and provide comprehensive explanations regarding their decisions (Kapoor et al., 2024a; 2024b). Another central dimension of HRI is predictability. Trust in robots, as with humans, relies on repetitive execution of the same tasks. It is a question of predictability: To what extent can the robot’s actions be anticipated? Dependable and consistent actions lead to trust, while erratic actions create suspicion (Hancock et al., 2011).The levels of trust in human-robot interaction are notably impacted by autonomy and flexibility. Trust in robots is developed when there is an effective adaptation to drastic changes in the environment while still performing optimally (Beer et al., 2014). Nandanwar and Dutt (2023) explain that robots portraying emotions such as tension and anxiety build user trust. Therefore, in order to build trust, highly autonomous robots should respond to novel requests in a timely manner aligned with user expectations.Furthermore, user experience and emotional engagement greatly impact trust in HRI positively. A robot’s emotive traits and emotionally evocative interactions can shape trust (Brave & Nass, 2002). This becomes important during nursing or companionship scenarios where forming emotional connections adds credibility to a robot’s actions (Breazeal, 2003). New studies show that emotionally responsive conversational robots can evaluate and mitigate adverse psychological states, support well-being, and create trust (Nandanwar & Dutt, 2023).4. Comparative Analysis: Human-Human versus Human-Robot TrustDespite some similarities, human-human trust and human-robot trust differ fundamentally at their core. The basis of trust among people stems from social ties or emotional connections (Lewis and Weigert, 1985), which is developed through experiences together and understanding one another (Rotter, 1980). Such interpersonal trust is usually boosted by ongoing interactions, which increases esteem and gratitude (Coleman, 1990). On the other hand, trust in HRI derives from clarity and predictability associated to functional performance. Generally, people tend to trust robots or AI systems due to their dependable and efficient execution of tasks (Hancock et al., 2011). Robotic systems are deemed reliable when they meet specific performance targets and explain their operational state accurately. Unlike humans, who may forgive occasional lapses of unreliable behavior due to emotional connections that exist between them, robots build trust through consistent delivery of expected tasks (Kapoor et al., 2024a,b). Within the research involving PPO and GAIL on intricate search tasks using diverse robots, the need for reliability and transparency in trustable machine performance is emphasized (Kapoor et al., 2024a, b). In the context of robots, trust becomes more transactional as it is determined by whether expectations rather than being influenced by relationships cultivated. The study of trust in human-robot interaction (HRI) is based on observable behaviors and outcomes of robots or AIs (Hancock et al., 2011). For trust to be built, actions and performance must be clearly demonstrable. Human trust, however, is subject to strong emotional bonds and can overlook some lapses in reliability.In the absence of affective history in HRI, even small failures by a robot can disproportionately reduce trust, supporting the need for real-time calibration of trust frameworks (Hoff & Bashir, 2015). For instance, healthcare or emergency response robots need to rise above passivity and actively detect user hesitation—providing explanations or reassurances for trust repair.Trust among humans develops over time as a result of interaction, shared experiences, and maintained communication (Lewicki & Bunker, 1996). This characteristic means that it can evolve positively or negatively based on social interaction. Trust can be strengthened by positive experiences, however, it can also be reconstructed through communication and reconciliation during crises (McAllister, 1995).Although trust concerning Human-Robot Interaction (HRI) may vary over time, at any specific moment it still relies upon the robot’s effectiveness or its clarity of communication (Hancock et al., 2011). People’s reliance on a robot’s capabilities in a certain field is contingent on how well the robot performs within a defined context. This type of variability requires that HRI be adjusted dynamically, which means that users need to evaluate the actions of the robot in real-time. In sensitive situations like healthcare and disaster response, adjusting levels of trust according to how well a robot performs is vital (Hoff & Bashir, 2015). Robots could best utilize biosignals like galvanic skin response or eye-tracking data to adjust to the user’s level of trust, which is a poorly developed area.Different cultures can affect trust in diverse societies and in turn affect human-human interactions differently than human-robot interactions. In human interactions, trust is affected by the cultural practices of collectivism or individualism, which impact the perception of loyalty, transparency, and autonomy as trust-relevant traits (Gelfand et al., 2007). Furthermore, in HRI, culture affects how users perceive and engage with robots within a specific context. There are countries that will embrace autonomous systems while others may be very suspicious or even hostile towards them. For example, users from collectivist cultures may expect robots to demonstrate relational behaviors while individualist cultures expect more emphasis on autonomy and control (Li et al., 2010). Thus, there is a need for cross cultural study which designs robotic systems that adapt to different cultures using social context adaptable trust framework.Although culture-specific trust structures have been described at a conceptual level, their translation into the real world is underdeveloped. Working practice might include culturally adaptive robot behavior, for example, adjusting verbal styles, proxemics, and interaction style according to background user. For instance, it has been indicated that Japanese users like robots that are humble and polite, but American users can like more assertive and autonomous robot behavior (Li et al., 2010; Rau et al., 2009). Robots can make their emotional expressiveness and engagement strategies more amenable to deeper trust building by incorporating culturally grounded preferences by training machine learning models on region-specific interaction data. Research in the future can try adaptive modules that tune robot attitude according to user nationality, linguistic orientation, or even religious traditions (Złotowski et al., 2015).5. DiscussionThe consideration of trust in human-robot interaction (HRI) has identified gaps that are critical for research and understanding how trust is built, sustained, and navigated within systems of HRI (Hancock et al., 2011). The impact AI explainability has on trust sets the starting point of a particular high-stakes domain. The urgency of the problem increases when it comes to defense, transportation, and healthcare (Miller, 2019). Users inevitably need to comprehend the rationale behind AI powered systems’ decisions that could drastically alter their circumstances. Trust can be greatly aided by mitigating the opacity of, and hence, the decision-making processes within AI systems (Arrieta et al., 2020). A promising area of future work is to design context-sensitive XAI models that have the ability to adjust modifications by changing the timing and detail of the explanation granted based on what the user requires.The integration of psychosocial elements into trust frameworks for human-robot interaction is a promising new direction for research. Trust is heavily influenced by previous encounters, preconceptions, biases, personality traits, and sociocultural contexts (Hoff & Bashir, 2015). While the majority of computational models attempt to address some of these variables, they do so in an inadequate manner. As an example, trust models aimed at predicting trajectories of trust across diverse user groups, need to incorporate more psychosocial elements and behavioral as well as physiological sensing— like thermographic imaging or GSR— to better adapt to various user groups. A case in point is from education, where it has been demonstrated that emotionally adaptive robots can bolster student learning by increasing trust via emotional alignment (Nagpal et al., 2024). For HRI systems, another equally important focus of research is trust recalibration in real time. Trust is always in need of new models that continuously gauge and adjust user trust in relation to evolving interactions and feedback loops (Schaefer et al., 2016). This becomes critical in more volatile settings like military operations or disaster response, where evaluation and readjustment of trust need to be incessantly done with respect to how well the robot is performing in the context of a constantly shifting environment (Chen & Barnes, 2016).While biosensors like galvanic skin response (GSR), thermography, or eye-tracking hold promising streams for real-time trust estimation, a number of methodological issues remain. These encompass signal noise, context-dependency, individuality, and the difficulty of establishing physiological responses to targeted trust dimensions (Calvo & D'Mello, 2010; Nourbakhsh et al., 2017). The dynamic and multi-dimensional character of trust also renders it difficult to extract signal components that capture trust exclusively, as opposed to associated constructs such as stress or engagement. In addition, longitudinal calibration to account for individual baselines is commonly necessary, yet another obstacle to real-time use. Overcoming these shortfalls necessitates inter-disciplinary approaches that merge psychological profiling with adaptive sensor fusion and machine learning pipelines to manage noisy and incomplete data (Pfeifer et al., 2023).Potential tools for calibrating trust may involve context-sensitive behavioral monitoring, real-time stress level assessment, or predictive algorithms for trust decay capable of enabling robots to preemptively engage in trust repair. For instance, in healthcare, conversational AIs are able to identify symptoms of anxiety and depression, providing real-time language or tone modulation which highlights the recalibration of trust in sensitive settings (Nandanwar & Dutt, 2023).To address these complexities, we propose the Trust-Affordance Adaptation Model (TAAM)—evolving a conceptual model which positions a domain’s specific affordances for trust building against its specific expectations. Unlike static models, TAAM posits that mechanisms of trust, such as emotional involvement, engagement, transparency, predictability, and personalization, are contextually relativized in their prominence. For example, in defense applications, trust may be rooted primarily in transparency and dependability, whereas in healthcare or education, emotional engagement and adaptive personalization may prevail.TAAM suggests that trust calibration needs to dynamically respond to context-dependent affordances. As an example, within a healthcare environment, a robot's affective responsiveness and individualized feedback could be more influential to user trust than transparency with regards to its internal algorithms. A defense robot deployed in high-risk environments, however, would have to trade off predictability and transparency to establish human confidence in a matter of milliseconds. In educational contexts, emotionally intelligent avatars that adjust tone and body language have been found to enhance learning participation and trust (Nagpal et al., 2024). These instances demonstrate that trust affordances might be operationalized in varying ways based on domain-specific user emotional needs and expectancies.TAAM’s trust prioritization within specific domains is illustrated on the radar chart in Figure 2. This model advocates for the creation of AI systems which are functionally robust and equally contextually and emotionally intelligent. Through adding biosensors and feedback loops, culturally-informed models, TAAM paves the way for real-time personalized trust recalibration in human-robot interaction.Values in Figure 2 are calculated based on our own integration of previous empirical and theoretical literature (e.g., Hancock et al., 2011; Kapoor et al., 2024a; Nandanwar & Dutt, 2023) and constitute relative importance of trust aspects within domains. For instance, transparency is paramount in defense environments, whereas emotional engagement prevails in education and social robotics. These domain-specific mappings serve to facilitate the TAAM model's flexibility. Figure 2. Conceptual radar chart showing the relative value of trust affordances—transparency, personalization, emotional engagement, and predictability—within four domains: defense, healthcare, education, and social robotics. The numeric values employed are hypothetical, not based on experimental data, and constitute domain-informed judgments aggregated from literature.In conclusion, addressing the gaps in cross-cultural research regarding trust in robots from diverse parts of the world is critical. Culture, as Li et al. (2010) indicates, is an important factor that influences trust and how users robotic systems. Some cultures may accept autonomous robots as efficient partners, while others may not accept or embrace them. It is through cross-cultural research that these differences may be discovered and used to automate robots that respect local customs and values. Culturally sensitive robotic systems as Gelfand et al. (2007) outlines, is what may likely ensure social trust and acceptance for the global deployment of robotic systems.},
  archive      = {J_FROBT},
  author       = {Chauhan, Sakshi and Kapoor, Shashank and Nagpal, Malika and Choudhary, Gitanshu and Dutt, Varun},
  doi          = {10.3389/frobt.2025.1535082},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1535082},
  shortjournal = {Front. Robot. AI},
  title        = {Building trust in the age of human-machine interaction: Insights, challenges, and future directions},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rehabilitation robotics and allied digital technologies: Opportunities, barriers and solutions for improving their clinical implementation. a position paper from the fit for medical robotics initiative. <em>FROBT</em>, <em>12</em>, 1531067. (<a href='https://doi.org/10.3389/frobt.2025.1531067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics has been proposed as a promising solution for treating individuals with motor, sensory, and/or cognitive disabilities. Despite the great technological effort put into this field, the translation of robots from the laboratory to the clinical environment is not a seamless and smooth process, and their real-world adoption remains limited. Several barriers to the introduction of robotics in clinical practice have been identified, including a lack of sufficient scientific evidence about its actual cost/effectiveness, resistance to adopting these technologies, and economic, ethical, and regulatory restraints. Fit for Medical Robotics (Fit4MedRob) is an ambitious Initiative designed to bridge the gap between technological innovation and clinical application. One of the main goals of the Initiative is to conduct large-scale pragmatic trials to evaluate the effectiveness and the sustainability of commercially available robotic solutions. To guide the design of these trials, different online surveys have been implemented and delivered to identify the needs of healthcare practitioners and patients at different phases of the disease (acute to chronic) and therapeutic settings (hospital to home care). The results of the Initiative will suggest new organizational models to effectively introduce robotics-assisted rehabilitation into clinical practice. The paper will report on the opportunities of robotics for rehabilitation, the barriers to their clinical implementation, and the proposal of Fit4MedRob to overcome such limitations and facilitate the effective clinical implementation of robotic solutions.},
  archive      = {J_FROBT},
  author       = {Aprile, Irene Giovanna and Quaglini, Silvana and Turchetti, Giuseppe and Pecchia, Leandro and Comandè, Giovanni and Gramatica, Furio and Gruppioni, Emanuele and Sgandurra, Giuseppina and Cipriani, Christian and , Fit4Mission1 group},
  doi          = {10.3389/frobt.2025.1531067},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1531067},
  shortjournal = {Front. Robot. AI},
  title        = {Rehabilitation robotics and allied digital technologies: Opportunities, barriers and solutions for improving their clinical implementation. a position paper from the fit for medical robotics initiative},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid disturbance observer and fuzzy logic controller for a new aerial manipulation system. <em>FROBT</em>, <em>12</em>, 1528415. (<a href='https://doi.org/10.3389/frobt.2025.1528415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial manipulation systems are highly attractive for various applications due to their distinctive features. However, the systems discussed in the literature are constrained by either a restricted number of end-effector degrees of freedom (DOFs) or low payload capability. In our previous research, we mounted a manipulator with a gripper on the underside of a quadrotor to enhance environmental interaction. This paper explores a quadrotor equipped with a 2-DOF manipulator featuring a distinctive topology that allows the end-effector to follow a specified 6-DOF trajectory with the least number of actuators required. An overview of the proposed manipulation system, along with its kinematic and dynamic analysis, is presented. Nevertheless, controlling this system presents significant challenges because of its considerable couplings, nonlinearities, and external disturbances. This paper employs a Disturbance Observer (DOb)-based linearization for an aerial manipulation robot. The DOb-based inner loop is responsible for estimating and compensating nonlinearities and disturbances, which simplifies the control problem into a more straightforward linear control algorithm. Subsequently, a fuzzy logic controller is incorporated into the outer loop to achieve the desired control objectives and closed-loop performance while minimizing computational load. Stability analysis of the proposed controller is introduced. Finally, the system is simulated using MATLAB/SIMULINK, and the results demonstrate tracking accuracy during 6-DOF maneuvers under many kinds of disturbances, with low computational load. The system maintains stability during payload exchanges while respecting all actuator constraints (rotor thrust less than 6 N, joint torques less than 0.7 and 0.4 N.m, respectively). These results demonstrate the effectiveness of the proposed control approach. Also, they show that the proposed controller outperforms the DOb-PD controller’s response.},
  archive      = {J_FROBT},
  author       = {Khalifa, Alaa and Shaaban, Shaaban M. and Khalifa, Ahmed},
  doi          = {10.3389/frobt.2025.1528415},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1528415},
  shortjournal = {Front. Robot. AI},
  title        = {Hybrid disturbance observer and fuzzy logic controller for a new aerial manipulation system},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A relevance model of human sparse communication in cooperation. <em>FROBT</em>, <em>12</em>, 1512099. (<a href='https://doi.org/10.3389/frobt.2025.1512099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human real-time communication creates a limitation on the flow of information, which requires the transfer of carefully chosen and condensed data in various situations. We introduce a model that explains how humans choose information for communication by utilizing the concept of “relevance” derived from decision-making theory and Theory of Mind (ToM). We evaluated the model by conducting experiments where human participants and an artificial intelligence (AI) agent assist each other to avoid multiple traps in a simulated navigation task. The relevance model accurately depicts how humans choose which trap to communicate. It also outperforms GPT-4, which participates in the same task by responding to prompts that describe the game settings and rules. Furthermore, we demonstrated that when humans received assisting information from an AI agent, they achieved a much higher performance and gave higher ratings to the AI when it utilized the relevance model compared to a heuristic model. Together, these findings provide compelling evidence that a relevance model rooted in decision theory and ToM can effectively capture the sparse and spontaneous nature of human communication.},
  archive      = {J_FROBT},
  author       = {Jiang, Kaiwen and Jiang, Boxuan and Sadaghdar, Anahita and Limb, Rebekah and Gao, Tao},
  doi          = {10.3389/frobt.2025.1512099},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1512099},
  shortjournal = {Front. Robot. AI},
  title        = {A relevance model of human sparse communication in cooperation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-based control for tendon-driven continuum robotic arms. <em>FROBT</em>, <em>12</em>, 1488869. (<a href='https://doi.org/10.3389/frobt.2025.1488869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-Driven Continuum Robots are widely recognized for their flexibility and adaptability in constrained environments, making them invaluable for most applications, such as medical surgery, industrial tasks, and so on. However, the inherent uncertainties and highly nonlinear dynamics of these manipulators pose significant challenges for classical model-based controllers. Addressing these challenges necessitates the development of advanced control strategies capable of adapting to diverse operational scenarios. This paper presents a centralized position control strategy using Deep Reinforcement Learning, with a particular focus on the Sim-to-Real transfer of control policies. The proposed method employs a customized Modified Transpose Jacobian control strategy for continuum arms, where its parameters are optimally tuned using the Deep Deterministic Policy Gradient algorithm. By integrating an optimal adaptive gain-tuning regulation, the research aims to develop a model-free controller that achieves superior performance compared to ideal model-based strategies. Both simulations and real-world experiments demonstrate that the proposed controller significantly enhances the trajectory-tracking performance of continuum manipulators. The proposed controller achieves robustness across various initial conditions and trajectories, making it a promising candidate for general-purpose applications.},
  archive      = {J_FROBT},
  author       = {Maghooli, Nima and Mahdizadeh, Omid and Bajelani, Mohammad and Moosavian, S. Ali A.},
  doi          = {10.3389/frobt.2025.1488869},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1488869},
  shortjournal = {Front. Robot. AI},
  title        = {Learning-based control for tendon-driven continuum robotic arms},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robots for learning: An exploration of teacher roles, perceptions, and challenges in robot-mediated learning. <em>FROBT</em>, <em>12</em>, 1441382. (<a href='https://doi.org/10.3389/frobt.2025.1441382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of robots for learning, many educational organizations are using telepresence robots for the purpose of remote education. However, as robot-mediated learning is important for the learning experiences of remote and local interactants, it is also important to understand teacher roles and robot design features needed to facilitate these roles in robot-mediated learning experiences. In this paper, we present findings from analysis of a national, multi-case study, where we explore how (N = 60) K-12 teachers perceive their roles in teaching hybrid classrooms where a remote learner used a robot to attend a physical classroom with in-person classmates. This paper presents a qualitative study of the perceived roles for teachers in hybrid classrooms where a remote learner uses a telepresence robot to participate in learning activities. In 46 semi-structured interviews (n = 46) and 6 focus group interviews (n = 2; n = 3; n = 2; n = 3; n = 2; n = 2), coded with a computer assisted qualitative data analysis software (i.e., ATLAS.ti), we captured adapted roles enacted by teachers in robot-mediated learning experiences. First, we present empirical data on educator perceptions of teacher roles as they interact with mobile telepresence robots embodied by remote learners. Specifically, we explore perceptions and roles during in-class learning activities, in-school social activities, and learning preparation activities. Findings from our work will inform novel teacher-centered robot and HRI design that facilitates teaching hybrid classrooms. Findings will also inform future interdisciplinary studies on robot-mediated learning.},
  archive      = {J_FROBT},
  author       = {Ahumada-Newhart, Veronica and Eccles, Jacquelynne S.},
  doi          = {10.3389/frobt.2025.1441382},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1441382},
  shortjournal = {Front. Robot. AI},
  title        = {Robots for learning: An exploration of teacher roles, perceptions, and challenges in robot-mediated learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and trajectory tracking of four- wheel steering trackless auxiliary transport robot via PID control. <em>FROBT</em>, <em>12</em>, 1617376. (<a href='https://doi.org/10.3389/frobt.2025.1617376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the complex working environment of underground coal mines, narrow road conditions and deviation in the driving path of autonomous trackless auxiliary transport robots can easily lead to collisions with walls or obstacles. This issue can be effectively solved by a four-wheel steering system, as it can reduce the turning radius of the robot at low speeds and improve its maneuverability at high speeds. Thus, a linear two-degree-of-freedom dynamics model of trackless auxiliary transport robot is established and the steady-state lateral critical speed of 16.6 km/h is obtained. Then a four wheel steering PID trajectory tracking strategy were constructed. Experiments on different steering modes at low and high speeds, which include stepped steering angles and circular path tracking, for the front-wheel steering mode and four-wheel steering mode of the robot are conducted under loaded conditions. The experimental results show that in the low-speed 10 km/h step steering angle input test, compared with the front-wheel steering mode, the turning radius of the robot is reduced by 32.2%, which ensures it easier to pass through narrow tunnels. Under the conditions of a 40 km/h high-speed step steering angle input test, the handling stability has been improved. The results of the circular trajectory tracking test show that at low speeds (10 km/h), the average radius error of the robot is 0.3%, while the radius error of the front-wheel steering robot reaches 2.12%. At high speeds (40 km/h), the average radius error is 2.4%, while the radius error of front-wheel steering mode is 8.74%. The robot maintains good track tracking ability, reducing the risk of collision with tunnel walls and improving robot operation safety.},
  archive      = {J_FROBT},
  author       = {Hao, Mingrui and Bi, Yueqi and Ren, Jie and Ma, Lisen and Li, Jiaran and Zhao, Sihai and Wu, Miao},
  doi          = {10.3389/frobt.2025.1617376},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1617376},
  shortjournal = {Front. Robot. AI},
  title        = {Stability and trajectory tracking of four- wheel steering trackless auxiliary transport robot via PID control},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Applications of AI in autonomous, surveillance, and robotic systems. <em>FROBT</em>, <em>12</em>, 1616634. (<a href='https://doi.org/10.3389/frobt.2025.1616634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of Artificial Intelligence (AI) has ushered in a new era of intelligent systems capable of autonomous decision-making, real-time perception, and adaptive learning. Across robotics, unmanned systems, and surveillance technologies, AI is transforming how machines interact with the world-enhancing precision, e iciency, and autonomy. This editorial provides an overview of key research contributions in this domain, highlighting the pivotal role of AI in shaping the future of autonomous navigation, robotic manipulation, and multi-agent surveillance systems.The selected papers in this issue address critical challenges in visual perception, swarm coordination, and secure data management, demonstrating how AI-driven solutions are pushing the boundaries of what autonomous systems can achieve. From Visual SLAM in robotics to blockchain-secured UAV swarms, these studies showcase both the current state of the art and future directions for research and deployment.AI in Autonomous Robotics: Perception, Navigation, and ManipulationThe paper "A Review of Visual SLAM for Robotics: Evolution, Properties, and Future Applications" provides a comprehensive survey of how Simultaneous Localization and Mapping (SLAM) has evolved with deep learning and computer vision. Traditional SLAM systems relied heavily on geometric algorithms, but modern AI-powered approaches leverage neural networks for feature extraction, dynamic object tracking, and semantic understanding. This shift enables robots to operate in complex, unstructured environments-from industrial warehouses to disaster zones. Future research directions include lightweight SLAM for edge devices and multi-agent collaborative mapping.In "Image-based Robot Navigation with Task Achievability," the authors explore AI-driven navigation strategies that go beyond simple path planning. By integrating reinforcement learning and vision-based perception, robots can assess environmental constraints and adjust their trajectories to ensure task completion. This is particularly valuable in logistics, where mobile robots must dynamically reroute around obstacles while maintaining operational e iciency.A major challenge in robotic manipulation is the discrepancy between simulated training data and real-world execution. The study "6IMPOSE: Bridging the Reality Gap in 6D Pose Estimation for Robotic Grasping" introduces a novel AI framework that improves 6D pose estimation-critical for precise grasping in industrial automation and healthcare robotics. By combining synthetic data augmentation with domain adaptation techniques, the proposed method significantly enhances robotic dexterity in unstructured settings.Unmanned Aerial Vehicles (UAVs) are increasingly used for surveillance, delivery, and infrastructure inspection, but their operational endurance is limited by battery life. The paper "Vision-based Safe Autonomous UAV Docking with Panoramic Sensors" presents an AI-powered docking system that allows UAVs to autonomously land on charging stations using panoramic vision. This innovation enhances mission longevity while reducing human intervention, paving the way for fully autonomous drone fleets.The integration of UAVs, Unmanned Ground Vehicles (UGVs), and Unmanned Marine Vehicles (UMVs) into a cohesive surveillance network is explored in "UAV-UGV-UMV Multi-Swarms for Cooperative Surveillance." AI-driven coordination enables these systems to share sensory data, optimize coverage, and adapt to dynamic threats. Applications range from border security to environmental monitoring, where multidomain swarms provide unparalleled situational awareness.As UAV swarms become more prevalent, ensuring data integrity and preventing cyber threats is paramount. "Towards a Blockchain-Based Multi-UAV Surveillance System" proposes a decentralized AI framework where blockchain technology secures communication between drones. This approach mitigates risks such as spoofing and data tampering, making autonomous surveillance systems more resilient in adversarial environments.While AI-powered autonomous systems o er immense potential, several challenges remain: Robustness in Real-World Conditions: AI models must generalize across diverse environments without excessive retraining. Human-AI Collaboration: Ensuring safe interaction between autonomous systems and human operators is crucial. Ethical and Privacy Concerns: Surveillance applications must balance security needs with individual privacy rights. Energy E iciency: Prolonging operational endurance for UAVs and robots remains a key hurdle.Future research should focus on explainable AI for autonomous decision-making, edge computing for real-time processing, and regulatory frameworks to govern AI deployment in sensitive applications.The papers featured in this issue demonstrate the transformative impact of AI on autonomous, surveillance, and robotic systems. From enhancing robotic perception to enabling secure multi-agent coordination, these innovations are setting the stage for smarter, more resilient autonomous technologies. As the field progresses, interdisciplinary collaboration-spanning AI, robotics, cybersecurity, and ethics-will be essential to realizing the full potential of these systems while addressing societal concerns.This editorial serves as a gateway to the cutting-edge research presented in this collection, inviting further exploration into how AI continues to redefine the boundaries of autonomy and intelligence in machines.},
  archive      = {J_FROBT},
  author       = {Sebastian, Patrick},
  doi          = {10.3389/frobt.2025.1616634},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1616634},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Applications of AI in autonomous, surveillance, and robotic systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging learned monocular depth prediction for pose estimation and mapping on unmanned underwater vehicles. <em>FROBT</em>, <em>12</em>, 1609765. (<a href='https://doi.org/10.3389/frobt.2025.1609765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a general framework that integrates visual and acoustic sensor data to enhance localization and mapping in complex, highly dynamic underwater environments, with a particular focus on fish farming. The pipeline enables net-relative pose estimation for Unmanned Underwater Vehicles (UUVs) and depth prediction within net pens solely from visual data by combining deep learning-based monocular depth prediction with sparse depth priors derived from a classical Fast Fourier Transform (FFT)-based method. We further introduce a method to estimate a UUV’s global pose by fusing these net-relative estimates with acoustic measurements, and demonstrate how the predicted depth images can be integrated into the wavemap mapping framework to generate detailed 3D maps in real-time. Extensive evaluations on datasets collected in industrial-scale fish farms confirm that the presented framework can be used to accurately estimate a UUV’s net-relative and global position in real-time, and provide 3D maps suitable for autonomous navigation and inspection.},
  archive      = {J_FROBT},
  author       = {Job, Marco and Botta, David and Reijgwart, Victor and Ebner, Luca and Studer, Andrej and Siegwart, Roland and Kelasidi, Eleni},
  doi          = {10.3389/frobt.2025.1609765},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1609765},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging learned monocular depth prediction for pose estimation and mapping on unmanned underwater vehicles},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards applied swarm robotics: Current limitations and enablers. <em>FROBT</em>, <em>12</em>, 1607978. (<a href='https://doi.org/10.3389/frobt.2025.1607978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm robotics addresses the design, deployment, and analysis of large groups of robots that collaborate to perform tasks in a decentralized manner. Research in this field has predominantly relied on simulations or small-scale robots with limited sensing, actuation, and computational capabilities. Consequently, despite significant advancements, swarm robotics has yet to see widespread commercial or industrial application. A major barrier to practical deployment is the lack of affordable, modern, and robust platforms suitable for real-world scenarios. Moreover, a narrow definition of what swarm robotics should be has restricted the scope of potential applications. In this paper, we argue that the development of more advanced robotic platforms—incorporating state-of-the-art technologies such as SLAM, computer vision, and reliable communication systems—and the adoption of a broader interpretation of swarm robotics could significantly expand its range of applicability. This would enable robot swarms to tackle a wider variety of real-world tasks and integrate more effectively with existing systems, ultimately paving the way for successful deployment.},
  archive      = {J_FROBT},
  author       = {Kegeleirs, Miquel and Birattari, Mauro},
  doi          = {10.3389/frobt.2025.1607978},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1607978},
  shortjournal = {Front. Robot. AI},
  title        = {Towards applied swarm robotics: Current limitations and enablers},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic optimization of powdered beverages leveraging computer vision and bayesian optimization. <em>FROBT</em>, <em>12</em>, 1603729. (<a href='https://doi.org/10.3389/frobt.2025.1603729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for innovative research in the food industry is driving the adoption of robots in large-scale experimentation, a shift that offers increased precision, repeatability, and efficiency in product manufacturing and evaluation. This paper addresses this need by introducing a robotic system that extends automation into optimization and closed-loop quality control, using powdered cappuccino preparation as a case study. By leveraging Bayesian Optimization and image analysis, the robot explores the parameter space to identify the ideal conditions for producing cappuccino with high foam quality. A computer vision-based feedback loop further improves the beverage by mimicking human-like corrections in preparation process. Findings demonstrate the effectiveness of robotic automation in achieving high repeatability and enabling extensive exploration of system parameters, paving the way for more advanced and reliable food product development.},
  archive      = {J_FROBT},
  author       = {Szymańska, Emilia and Hughes, Josie},
  doi          = {10.3389/frobt.2025.1603729},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1603729},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic optimization of powdered beverages leveraging computer vision and bayesian optimization},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of automatic insect-tracking robot system for measuring local activity changes in free walking. <em>FROBT</em>, <em>12</em>, 1602867. (<a href='https://doi.org/10.3389/frobt.2025.1602867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a robotic system that autonomously tracks insects during free walking to elucidate the relationship between olfactory sensory stimuli and behavioral changes in insects. The adaptability of organisms is defined by their ability to select appropriate behaviors based on sensory inputs in response to environmental changes, a capacity that insects exhibit through efficient adaptive behaviors despite their limited nervous systems. Consequently, new measurement techniques are needed to investigate the neuroethological processes in insects. Traditional behavioral observations of insects have been conducted using free-walking experiments and treadmill techniques; however, these methods face limitations in accurately measuring sensory stimuli and analyzing the factors contributing to detailed behavioral changes. In this study, a robotic system is employed to track free-walking insects while simultaneously recording electroantennogram (EAG) responses at the location of the antenna of the insect during movement, thus enabling the measurement of the relationship between olfactory reception and behavioral change. In this research, we focus on a male silk moth (Bombyxmori) as the target insect and measure its odor source localization behavior. The system comprises a high-speed camera to estimate the movement direction of the insect, a drive system, and instrumentation amplifiers to measure physiological responses. The robot tracks the insect with an error margin of less than 5 mm, recording the EAG responses associated with the olfactory reception during this process. An analysis of the relationship between EAG responses and behavior revealed that the silk moth exhibits a significant amplitude in its EAG responses during the initial odor source localization stage. This suggests that the moth does not necessarily move toward the strongest odor. Further information-theoretic analysis revealed that the moth might be moving in the direction most likely to lead to odor detection, depending on the timing of its olfactory reception. This approach allows for a more natural measurement of the connection between olfactory sensory stimuli and behavior during odor source localization. The study findings are expected to deepen our understanding of the adaptive behaviors of insects.},
  archive      = {J_FROBT},
  author       = {Sekiwa, Ryoko and Ibuki, Tatsuya and Shigaki, Shunsuke},
  doi          = {10.3389/frobt.2025.1602867},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1602867},
  shortjournal = {Front. Robot. AI},
  title        = {Development of automatic insect-tracking robot system for measuring local activity changes in free walking},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric line-of-sight guidance law with exponential switching sliding mode control for marine vehicles’ path following. <em>FROBT</em>, <em>12</em>, 1598982. (<a href='https://doi.org/10.3389/frobt.2025.1598982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine vehicle guidance and control technology serves as the core support for advancing marine development and enabling scientific exploration. Its accuracy, autonomy, and environmental adaptability directly determine a vehicle’s mission effectiveness in complex marine environments. This paper explores path following for marine vehicles in the horizontal plane. To tackle the limitation of a fixed look-ahead distance, we develop a novel geometric line-of-sight guidance law. It adapts to diverse compound paths by dynamically adjusting according to cross-track errors and local path curvature. Then, to enhance control performance, we present an improved exponential switching law for sliding mode control, enabling rapid convergence, disturbance rejection, and chatter reduction. Additionally, integral sliding mode control is integrated to stabilize yaw angular velocity, ensuring the system’s global asymptotic stability. Through a series of numerical simulations, the effectiveness, robustness, and adaptability of our proposed methods are verified.},
  archive      = {J_FROBT},
  author       = {Yuan, Chengren and Shuai, Changgeng and Zhang, Zhanshuo and Li, Buyun and Cheng, Yuqiang and Ma, Jianguo},
  doi          = {10.3389/frobt.2025.1598982},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1598982},
  shortjournal = {Front. Robot. AI},
  title        = {Geometric line-of-sight guidance law with exponential switching sliding mode control for marine vehicles’ path following},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward an active exoskeleton with full energy autonomy. <em>FROBT</em>, <em>12</em>, 1597271. (<a href='https://doi.org/10.3389/frobt.2025.1597271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons aim to enhance human performance and reduce physical fatigue. However, one major challenge for active exoskeletons is the need for a power source. This demand is typically met with batteries, which limit the device’s operational time. This study presents a novel solution to this challenge: a design that enables the generation of electricity during motions where the muscles work as brakes and absorb energy, with the energy stored and subsequently returned to assist when the muscles function as motors. To achieve this goal, a knee exoskeleton design with a direct drive and a novel electronic board was designed and manufactured to capture the energy generated by the wearer’s movements and convert it into electrical energy. The harvested energy is stored in a power bank, and later, during motion, this energy is used to power the exoskeleton motor. Further, the device has torque control and can change the assistive profile and magnitude as needed for different assistance scenarios. Sit-to-stand (STS) motion was chosen as a test case for the first exoskeleton prototype. It was found that, during lowering (from stand to sit), the exoskeleton provided up to 10 Nm and harvested 9.4 J. During rising (from sit to stand), it provided up to 7.6 Nm and was able to return 6.8 J of the harvested energy. Therefore, the cycle efficiency of the exoskeleton system (return divided by harvesting) is 72.3%. In summary, this study introduces the first active exoskeleton for STS that can generate its own electrical power. The results show that the full development of this technology could reduce exoskeletons’ need for external energy sources.},
  archive      = {J_FROBT},
  author       = {Knafo, Yakir and Zhou, Yinjie and Manor, Avi and Osovizky, Alon and Riemer, Raziel},
  doi          = {10.3389/frobt.2025.1597271},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1597271},
  shortjournal = {Front. Robot. AI},
  title        = {Toward an active exoskeleton with full energy autonomy},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is AI currently capable of identifying wild oysters? a comparison of human annotators against the AI model, ODYSSEE. <em>FROBT</em>, <em>12</em>, 1587033. (<a href='https://doi.org/10.3389/frobt.2025.1587033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oysters are ecologically and commercially important species that require frequent monitoring to track population demographics (e.g., abundance, growth, mortality). Current methods of monitoring oyster reefs often require destructive sampling methods and extensive manual effort. However, these methods are destructive and are suboptimal for small-scale or sensitive environments. A recent alternative, the ODYSSEE model, was developed to use deep learning techniques to identify live oysters using video or images taken in the field of oyster reefs to assess abundance. The validity of this model in identifying live oysters on a reef was compared to expert and non-expert annotators. In addition, we identified potential sources of prediction error. Although the model can make inferences significantly faster than expert and non-expert annotators (39.6 s, 2.34±0.61 h, 4.50±1.46 h, respectively), the model overpredicted the number of live oysters, achieving lower accuracy (63%) in identifying live oysters compared to experts (74%) and non-experts (75%) alike. Image quality was an important factor in determining the accuracy of the model and annotator. Better quality images improved human accuracy and worsened model accuracy. Although ODYSSEE was not sufficiently accurate, we anticipate that future training on higher-quality images, utilizing additional live imagery, and incorporating additional annotation training classes will greatly improve the model’s predictive power based on the results of this analysis. Future research should address methods that improve the detection of living vs dead oysters.},
  archive      = {J_FROBT},
  author       = {Campbell, Brendan and Williams, Alan and Baxevani, Kleio and Campbell, Alyssa and Dhoke, Rushabh and Hudock, Rileigh E. and Lin, Xiaomin and Mange, Vivek and Neuberger, Bernhard and Suresh, Arjun and Vera, Alhim and Trembanis, Arthur and Tanner, Herbert G. and Hale, Edward},
  doi          = {10.3389/frobt.2025.1587033},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1587033},
  shortjournal = {Front. Robot. AI},
  title        = {Is AI currently capable of identifying wild oysters? a comparison of human annotators against the AI model, ODYSSEE},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring LLM-powered multi-session human-robot interactions with university students. <em>FROBT</em>, <em>12</em>, 1585589. (<a href='https://doi.org/10.3389/frobt.2025.1585589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This exploratory study investigates how open-domain, multi-session interactions with a large language model (LLM)-powered social humanoid robot (SHR), EMAH, affect user perceptions and willingness for adoption in a university setting. Thirteen students (5 female, 8 male) engaged with EMAH across four weekly sessions, utilizing a compact open-source LLM (Flan-T5-Large) to facilitate multi-turn conversations. Mixed-method measures were employed, including subjective ratings, behavioral observations, and conversational analyses. Results revealed that perceptions of robot’s sociability, agency, and engagement remained stable over time, with engagement sustained despite repeated exposure. While perceived animacy increased with familiarity, disturbance ratings did not significantly decline, suggesting enhanced lifelikeness of SHR without reducing discomfort. Observational data showed a mid-study drop in conversation length and turn-taking, corresponding with technical challenges such as slower response generation and speech recognition errors. Although prior experience with robots weakly correlated with rapport, it did not significantly predict adoption willingness. Overall, the findings highlight the potential for LLM-powered robots to maintain open-domain interactions over time, but also underscore the need for improving technical robustness, adapting conversation strategies by personalization, and managing user expectations to foster long-term social engagement. This work provides actionable insights for advancing humanoid robot deployment in educational environments.},
  archive      = {J_FROBT},
  author       = {Mauliana, Mauliana and Ashok, Ashita and Czernochowski, Daniela and Berns, Karsten},
  doi          = {10.3389/frobt.2025.1585589},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1585589},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring LLM-powered multi-session human-robot interactions with university students},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preliminary investigation of the design space of geared magnetorheological actuators for safer robotic manipulators. <em>FROBT</em>, <em>12</em>, 1581651. (<a href='https://doi.org/10.3389/frobt.2025.1581651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geared magnetorheological (MR) actuators have the potential to provide safe and fast physical interactions between human and machine due to their low inertia and high bandwidth. The use of MR actuators in collaborative robotics serial manipulators is only emerging and the design space of this approach is unknown. This paper provides a preliminary understanding of this design space by studying how much gearing can be used between the MR actuators and the joint outputs while maintaining adequate safety levels for collaborative tasks. An analytical collision model is derived for a 6 degrees-of-freedom serial manipulator based on the geometry of the well-known UR5e robot. Model validity is confirmed by comparing predictions to experimental collision data from two robots, a UR5e and a MR5 equivalent. The model is then used to study the impact of gearing level on safety during eventual collisions with human. Results show that for both technologies, robot safety is governed by the balance between the reflected mass due to structural mass and actuator rotational inertia. Results show that, for the UR5e geometry studied in this paper, MR actuators have the potential to reduce the reflected mass in collisions by a factor ranging from 2 to 6 while keeping gearing ratios above 100:1. The paper also briefly studies the influence of robot shape on optimal gearing ratios showing that smaller robots with shorter range have lower structural mass and, thus, proportionally benefit even more of MR actuators. Delocalizing wrist actuators to the elbow has a similar impact since it also reduces structural mass. In all, this work suggests that MR actuators have a strong potential to improve the “hapticness” of collaborative robots while maintaining high gearing ratios.},
  archive      = {J_FROBT},
  author       = {Gingras, Samuel and St-Jean, Alexandre and Plante, Jean-Sébastien},
  doi          = {10.3389/frobt.2025.1581651},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1581651},
  shortjournal = {Front. Robot. AI},
  title        = {Preliminary investigation of the design space of geared magnetorheological actuators for safer robotic manipulators},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal sensing system for human-robot interaction through tactile and proximity data. <em>FROBT</em>, <em>12</em>, 1581154. (<a href='https://doi.org/10.3389/frobt.2025.1581154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe rapid advancement of collaborative robotics has driven significant interest in Human-Robot Interaction (HRI), particularly in scenarios where robots work alongside humans. This paper considers tasks where a human operator teaches the robot an operation that is then performed autonomously.MethodsA multi-modal approach employing tactile fingers and proximity sensors is proposed, where tactile fingers serve as an interface, while proximity sensors enable end-effector movements through contactless interactions and collision avoidance algorithms. In addition, the system is modular to make it adaptable to different tasks.ResultsDemonstrative tests show the effectiveness of the proposed system and algorithms. The results illustrate how the tactile and proximity sensors can be used separately or in a combined way to achieve human-robot collaboration.DiscussionThe paper demonstrates the use of the proposed system for tasks involving the manipulation of electrical wires. Further studies will investigate how it behaves with object of different shapes and in more complex tasks.},
  archive      = {J_FROBT},
  author       = {Laudante, Gianluca and Mirto, Michele and Pennacchio, Olga and Pirozzi, Salvatore},
  doi          = {10.3389/frobt.2025.1581154},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1581154},
  shortjournal = {Front. Robot. AI},
  title        = {A multi-modal sensing system for human-robot interaction through tactile and proximity data},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of intelligent robot service failures on customer responses --a perspective based on mind perception theory. <em>FROBT</em>, <em>12</em>, 1581083. (<a href='https://doi.org/10.3389/frobt.2025.1581083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As intelligent robots are widely applied in people’s work and daily life, intelligent robot service failures have drawn more attention from academics and practitioners. Under the scenarios of intelligent robot service failures, most existing studies focus on service providers’ remedies for the failures and customers’ psychological responses to such failures. However, few have systematically explored the impacts of intelligent robot service failures on customers and their internal psychological mechanisms. This paper adopts the framework of mind perception theory to systematically categorize the types of intelligent robot service failures and explores their impact on customer responses from the dimensions of agency and experience. By constructing a theoretical framework to analyze the effects of intelligent robot services on customers, it provides valuable theoretical insights for scholars in the field of intelligent marketing and sheds light on the psychological mechanisms of customers under intelligent robot service failure scenarios.},
  archive      = {J_FROBT},
  author       = {Gong, Mengting and Li, Aimei and Zhang, Junwei},
  doi          = {10.3389/frobt.2025.1581083},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1581083},
  shortjournal = {Front. Robot. AI},
  title        = {The impact of intelligent robot service failures on customer responses --a perspective based on mind perception theory},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving optimal prompt learning through multilayer fusion and latent dirichlet allocation. <em>FROBT</em>, <em>12</em>, 1579990. (<a href='https://doi.org/10.3389/frobt.2025.1579990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in few-shot learning have demonstrated the potential of prompt-based techniques with pre-trained models, eliminating the need for extensive fine-tuning. However, challenges such as obtaining optimal prompts and addressing data scarcity in specialized domains remain challenging. We introduce a novel framework incorporating a Global Attention Mechanism (GAM) that effectively integrates features from multiple layers of pre-trained language models, enhanced by Latent Dirichlet Allocation (LDA) generated topic features for prompt optimization. Extensive experiments on four datasets consistently show that our approach outperforms state of-the-art baselines. The strategic integration of GAM with layer-specific features and LDA topics proves particularly effective in extracting valuable latent information for few-shot learning scenarios, yielding significant improvements in specialized domains, as evidenced by enhanced performance in therapeutic dialogue classification within a Applied Behavior Analysis clinical dataset.},
  archive      = {J_FROBT},
  author       = {Chen, Qinghua and Korneder, Jessica and Rawashdeh, Osamah A. and Wang, Yanfeng and Louie, Wing-Yue Geoffrey},
  doi          = {10.3389/frobt.2025.1579990},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1579990},
  shortjournal = {Front. Robot. AI},
  title        = {Improving optimal prompt learning through multilayer fusion and latent dirichlet allocation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Role of haptic feedback technologies and novel engineering developments for surgical training and robot-assisted surgery. <em>FROBT</em>, <em>12</em>, 1567955. (<a href='https://doi.org/10.3389/frobt.2025.1567955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic feedback, or tactile perception, is presented by many authors as a technology that can greatly impact biomedical fields, such as minimally invasive surgeries. Laparoscopic interventions are considered the gold standard for many surgical interventions, providing recognized benefits, such as reduced recovery time and mortality rate. In addition to this, the advances in robotic engineering in the last few years have contributed to the increase in the number of robotic and tele-operated interventions, providing surgeons with fewer hand tremors and increased depth perception during surgery. However, currently, both techniques are totally or partially devoid of haptic feedback. This added to the fact that the skill acquisition process to be able to use these technologies shows a pronounced learning curve, has propelled biomedical engineers to aim to develop safe and realistic training programs using simulators to address surgical apprentices’ needs in safe environments for the patients. This review aims to present and summarize some of the latest engineering advances reported in the current literature related to the development of haptic feedback systems in surgical simulators and robotic surgical systems, as well as highlight the benefits that these technologies provide in medical settings for surgical training and preoperative rehearsal.},
  archive      = {J_FROBT},
  author       = {Laga Boul-Atarass, Imán and Rubio Manzanares Dorado, Mercedes and Padillo-Eguía, Andrés and Racero-Moreno, Jesús and Eguía-Salinas, Ignacio and Pereira-Arenas, Sheila and Jiménez-Rodríguez, Rosa María and Padillo-Ruiz, Javier},
  doi          = {10.3389/frobt.2025.1567955},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1567955},
  shortjournal = {Front. Robot. AI},
  title        = {Role of haptic feedback technologies and novel engineering developments for surgical training and robot-assisted surgery},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric scale non-fixed obstacles distance estimation using a 3D map and a monocular camera. <em>FROBT</em>, <em>12</em>, 1560342. (<a href='https://doi.org/10.3389/frobt.2025.1560342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle avoidance is important for autonomous driving. Metric scale obstacle detection using a monocular camera for obstacle avoidance has been studied. In this study, metric scale obstacle detection means detecting obstacles and measuring the distance to them with a metric scale. We have already developed PMOD-Net, which realizes metric scale obstacle detection by using a monocular camera and a 3D map for autonomous driving. However, PMOD-Net’s distance error of non-fixed obstacles that do not exist on the 3D map is large. Accordingly, this study deals with the problem of improving distance estimation of non-fixed obstacles for obstacle avoidance. To solve the problem, we focused on the fact that PMOD-Net simultaneously performed object detection and distance estimation. We have developed a new loss function called “DifSeg.” DifSeg is calculated from the distance estimation results on the non-fixed obstacle region, which is defined based on the object detection results. Therefore, DifSeg makes PMOD-Net focus on non-fixed obstacles during training. We evaluated the effect of DifSeg by using CARLA simulator, KITTI, and an original indoor dataset. The evaluation results showed that the distance estimation accuracy was improved on all datasets. Especially in the case of KITTI, the distance estimation error of our method was 2.42 m, which was 2.14 m less than that of the latest monocular depth estimation method.},
  archive      = {J_FROBT},
  author       = {Higashi, Daijiro and Fukuta, Naoki and Tasaki, Tsuyoshi},
  doi          = {10.3389/frobt.2025.1560342},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1560342},
  shortjournal = {Front. Robot. AI},
  title        = {Metric scale non-fixed obstacles distance estimation using a 3D map and a monocular camera},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic survey: Role of deep learning-based image anomaly detection in industrial inspection contexts. <em>FROBT</em>, <em>12</em>, 1554196. (<a href='https://doi.org/10.3389/frobt.2025.1554196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial automation is rapidly evolving, encompassing tasks from initial assembly to final product quality inspection. Accurate anomaly detection is crucial for ensuring the reliability and robustness of automated systems. The intelligence of an industrial automation system is directly linked to its ability to detect and rectify abnormalities, thereby maintaining optimal performance. To advance intelligent manufacturing, sophisticated methods for high-quality process inspection are indispensable. This paper presents a systematic review of existing deep learning methodologies specifically designed for image anomaly detection in the context of industrial manufacturing. Through a comprehensive comparison, traditional techniques are evaluated against state-of-the-art advancements in deep learning-based anomaly detection methodologies, including supervised, unsupervised, and semi-supervised learning methods. Addressing inherent challenges such as real-time processing constraints and imbalanced datasets, this review offers a systematic analysis and mitigation strategies. Additionally, we explore popular anomaly detection datasets for surface defect detection and industrial anomaly detection, along with a critical examination of common evaluation metrics used in image anomaly detection. This review includes an analysis of the performance of current anomaly detection methods on various datasets, elucidating strengths and limitations across different scenarios. Moreover, we delve into the domain of drone-based, manipulator-based and AGV-based anomaly detections using deep learning techniques, highlighting the innovative applications of these methodologies. Lastly, the paper offers scholarly rigor and foresight by addressing emerging challenges and charting a course for future research opportunities, providing valuable insights to researchers in the field of deep learning-based surface defect detection and industrial image anomaly detection.},
  archive      = {J_FROBT},
  author       = {Shukla, Vinita and Shukla, Amit and S. K., Surya Prakash and Shukla, Shraddha},
  doi          = {10.3389/frobt.2025.1554196},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1554196},
  shortjournal = {Front. Robot. AI},
  title        = {A systematic survey: Role of deep learning-based image anomaly detection in industrial inspection contexts},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SuperTac - Tactile data super-resolution via dimensionality reduction. <em>FROBT</em>, <em>12</em>, 1552922. (<a href='https://doi.org/10.3389/frobt.2025.1552922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of tactile sensing in robotics and prosthetics is constrained by the trade-off between spatial and temporal resolution in artificial tactile sensors. To address this limitation, we propose SuperTac, a novel tactile super-resolution framework that enhances tactile perception beyond the sensor’s inherent resolution. Unlike existing approaches, SuperTac combines dimensionality reduction and advanced upsampling to deliver high-resolution tactile information without compromising the performance. Drawing inspiration from the spatiotemporal processing of mechanoreceptors in human tactile systems, SuperTac bridges the gap between sensor limitations and practical applications. In this study, an in-house-built active robotic finger system equipped with a 4 × 4 tactile sensor array was used to palpate textured surfaces. The system, comprising a tactile sensor array mounted on a spring-loaded robotic finger connected to a 3D printer nozzle for precise spatial control, generated spatiotemporal tactile maps. These maps were processed by SuperTac, which integrates a Variational Autoencoder for dimensionality reduction and Residual-In-Residual Blocks (RIRB) for high-quality upsampling. The framework produces super-resolved tactile images (16 × 16), achieving a fourfold improvement in spatial resolution while maintaining computational efficiency for real-time use. Experimental results demonstrate that texture classification accuracy improves by 17% when using super-resolved tactile data compared to raw sensor data. This significant enhancement in classification accuracy highlights the potential of SuperTac for applications in robotic manipulation, object recognition, and haptic exploration. By enabling robots to perceive and interpret high-resolution tactile data, SuperTac marks a step toward bridging the gap between human and robotic tactile capabilities, advancing robotic perception in real-world scenarios.},
  archive      = {J_FROBT},
  author       = {Patel, Neel and Rana, Rwik and Kumar, Deepesh and Thakor, Nitish V.},
  doi          = {10.3389/frobt.2025.1552922},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1552922},
  shortjournal = {Front. Robot. AI},
  title        = {SuperTac - Tactile data super-resolution via dimensionality reduction},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized nonlinear model predictive control-based flock navigation with real-time obstacle avoidance in unknown obstructed environments. <em>FROBT</em>, <em>12</em>, 1540808. (<a href='https://doi.org/10.3389/frobt.2025.1540808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends our prior work on the distributed nonlinear model predictive control (NMPC) for navigating a robot fleet following a certain flocking behavior in unknown obstructed environments with a more realistic local obstacle-avoidance strategy. More specifically, we integrate the local obstacle-avoidance constraint using point clouds into the NMPC framework. Here, each agent relies on data from its local sensor to perceive and respond to nearby obstacles. A point cloud processing technique is presented for both two-dimensional and three-dimensional point clouds to minimize the computational burden during the optimization. The process consists of directional filtering and down-sampling that significantly reduce the number of data points. The algorithm’s performance is validated through realistic 3D simulations in Gazebo, and its practical feasibility is further explored via hardware-in-the-loop (HIL) simulations on embedded platforms. The results demonstrate that the agents can safely navigate through obstructed environments, and the HIL simulation confirms the feasibility of deploying this scheme on an embedded computer. These results suggest that the proposed NMPC scheme is suitable for real-world robotics deployment in decentralized robotic systems operating in complex environments.},
  archive      = {J_FROBT},
  author       = {Gerdpratoom, Nuthasith and Yamamoto, Kaoru},
  doi          = {10.3389/frobt.2025.1540808},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1540808},
  shortjournal = {Front. Robot. AI},
  title        = {Decentralized nonlinear model predictive control-based flock navigation with real-time obstacle avoidance in unknown obstructed environments},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation theory of mind for heterogeneous human-robot teams. <em>FROBT</em>, <em>12</em>, 1533054. (<a href='https://doi.org/10.3389/frobt.2025.1533054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of collaborative task execution by teams comprising of people and multiple heterogeneous robots. In particular, the problem is motivated by the need for the team members to dynamically coordinate their execution, in order to avoid overlapping actions (i.e. multiple team members working on the same part of the task) and to ensure a correct execution of the task. This paper expands on our own prior work on collaborative task execution by single human-robot and single robot-robot teams, by taking an approach inspired by simulation Theory of Mind (ToM) to develop a real-time distributed architecture that enables collaborative execution of tasks with hierarchical representations and multiple types of execution constraints by teams of people and multiple robots with variable heterogeneity. First, the architecture presents a novel approach for concurrent coordination of task execution with both human and robot teammates. Second, a novel pipeline is developed in order to handle automatic grasping of objects with unknown initial locations. Furthermore, the architecture relies on a novel continuous-valued metric which accounts for a robot’s capability to perform tasks during the dynamic, on-line task allocation process. To assess the proposed approach, the architecture is validated with: 1) a heterogeneous team of two humanoid robots and 2) a heterogeneous team of one human and two humanoid robots, performing a household task in different environmental conditions. The results support the proposed approach, as different environmental conditions result in different and continuously changing values for the robots’ task execution abilities. Thus, the proposed architecture enables adaptive, real-time collaborative task execution through dynamic task allocation by a heterogeneous human-robot team, for tasks with hierarchical representations and multiple types of constraints.},
  archive      = {J_FROBT},
  author       = {Nicolescu, Monica and Blankenburg, Janelle and Anima, Bashira Akter and Zagainova, Mariya and Hoseini, Pourya and Nicolescu, Mircea and Feil-Seifer, David},
  doi          = {10.3389/frobt.2025.1533054},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1533054},
  shortjournal = {Front. Robot. AI},
  title        = {Simulation theory of mind for heterogeneous human-robot teams},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Translating human information into robot tasks: Action sequence recognition and robot control based on human motions. <em>FROBT</em>, <em>12</em>, 1462833. (<a href='https://doi.org/10.3389/frobt.2025.1462833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term use and highly reliable batteries are essential for wearable cyborgs including Hybrid Assistive Limb and wearable vital sensing devices. Consequently, there is ongoing research and development aimed at creating safer next-generation batteries. Researchers, leveraging advanced specialized knowledge and skills, bring products to completion through trial-and-error processes that involve modifying materials, shapes, work protocols, and procedures. When robots can undertake the tedious, repetitive, and attention-demanding tasks currently performed by researchers within facility environments, it will reduce the workload on researchers and ensure reproducibility. In this study, aiming to reduce the workload on researchers and ensure reproducibility in trial-and-error tasks, we proposed and developed a system that collects human motion data, recognizes action sequences, and transfers both physical information (including skeletal coordinates) and task information to a robot. This enables the robot to perform sequential tasks that are traditionally performed by humans. The proposed system employs a non-contact method to acquire three-dimensional skeletal information over time, allowing for quantitative analysis without interfering with sequential tasks. In addition, we developed an action sequence recognition model based on skeletal information and object detection results, which operated independent of background information. This model can adapt to changes in work processes and environments. By translating the human information including the physical and semantic information of a sequential task performed by humans into a robot, the robot can perform the same task. An experiment was conducted to verify this capability using the proposed system. The proposed action sequence recognition method demonstrated high accuracy in recognizing human-performed tasks with an average Edit score of 95.39 and an average F1@10 score of 0.951. In two out of the four trials, the robot adapted to changes in work processes without misrecognizing action sequences and seamlessly executed the sequential task performed by the human. In conclusion, we confirmed the feasibility of using the proposed system.},
  archive      = {J_FROBT},
  author       = {Obinata, Taichi and Baba, Kazutomo and Uehara, Akira and Kawamoto, Hiroaki and Sankai, Yoshiyuki},
  doi          = {10.3389/frobt.2025.1462833},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1462833},
  shortjournal = {Front. Robot. AI},
  title        = {Translating human information into robot tasks: Action sequence recognition and robot control based on human motions},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Advances in modern intelligent surgery: From computer-aided diagnosis to medical robotics. <em>FROBT</em>, <em>12</em>, 1620551. (<a href='https://doi.org/10.3389/frobt.2025.1620551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical robots enable accurate, safe and minimally invasive treatments of patients in modern operating rooms, through surgical navigation that spans the entire surgical flow, encompassing the pre-operative surgical planning, intraoperative guidance, and postoperative evaluation (Ciuti et al., 2025;Li et al. 2024). Researchers have investigated all relevant aspects towards this goal (Zhang et al., 2024;Min et al. 2021;Min et., 2023). In addition, deep-learning techniques have recently demonstrated good performances for various tasks in the intelligent surgical/medical robotic systems, including medical image segmentation (Min et al., 2024a), computer-assisted diagnosis (Yan et al., 2025), medical image registration (Du et al., 2024;Zhang et al., 2024), surgical instrument segmentation, surgical step recognition, etc.In this Research Topic, we aim to present the latest developments and advances in the intelligent modern surgical system, including computer-assisted diagnosis, surgical navigation and medical robotics. As a result of the call for participation, five papers were finally accepted and collected in this Research Topic. The articles collected in this Research Topic provide good demonstrations of how medical imaging and intelligent algorithms could benefit the surgical robotic systems and surgical procedures at the end of the day. Despite the achieved significant progress, several challenges still remain in the on-going research development of intelligent surgical robotic systems. For example, to enable accurate navigation and further robot control for robot-assisted soft-tissue surgery, the real-time deformation of soft tissues need to be accurately modelled and the deformable registration between the preoperative and intraoperative spaces is needed (Min et., 2024b).},
  archive      = {J_FROBT},
  author       = {Min, Zhe and Song, Rui and Li, Changsheng and Luo, Jax},
  doi          = {10.3389/frobt.2025.1620551},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1620551},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advances in modern intelligent surgery: From computer-aided diagnosis to medical robotics},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Advancements in AI-driven multimodal interfaces for robot-aided rehabilitation. <em>FROBT</em>, <em>12</em>, 1605418. (<a href='https://doi.org/10.3389/frobt.2025.1605418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a rapid evolution in the field of robot-aided rehabilitation, with transformative innovations being developed with the aim of supporting the recovery of individuals with motor impairments \cite{mohebbi2020human}. A particularly promising area of research is the development of Artificial Intelligence (AI)-driven multimodal interfaces, which have the capability to collect and interpret heterogeneous information from the patient and the environment \cite{ai2021machine}. By integrating signals from vision, force, motion, and physiological sensors, these interfaces enable a more objective, fine-grained, and dynamic understanding of motor performance and engagement during therapy \cite{zhao2023multimodal}. When coupled with AI, such systems can drive adaptive and personalized interventions, aligning robot behavior with the patient's residual abilities and rehabilitation goals \cite{adans2020enabling}.This Research Topic explores the growing potential of multimodal sensor fusion, AI algorithms, and personalized control strategies to build intelligent rehabilitation platforms. The issue includes four contributions: three literature reviews, and one original research article, each offering a unique perspective on the integration of AI and multimodal monitoring in robot-aided rehabilitation. The articles demonstrate how innovations in sensor design, signal interpretation, and patient modeling can lead to more responsive and effective robot-mediated therapies, enhancing patient outcomes while promoting evidence-based practice and large-scale data-driven insights.\href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.745018/full}{Dalla Gasperina et al.}'s review establishes the basis for comprehending the potential of human-robot physical interaction in the design of effective and cooperative rehabilitation strategies. Their multidisciplinary framework reviews the literature according to the various high-level training modalities, low-level control strategies, and hardware implementation proposed in the literature, emphasizing the necessity for control strategies that respond to the patient's volitional effort and motor state.In a complementary manner, the work of \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2022.1068413/full}{Vanmechelen et al.} presents a comprehensive review of methodologies that can be used to assess upper limb movement disorders using wearable sensors. The study analyses wearable sensor technologies in different pathologies, highlighting how standardized protocols and sensitive sensor characteristics can support objective assessment of movement disorders and treatment monitoring. The work emphasizes the importance of real, non-intrusive monitoring to achieve meaningful rehabilitation results.Furthermore, the contribution of \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1341580/full}{Coser et al.} concentrates on the lower limb domain, providing a comprehensive overview of the AI-based methods that can be utilized in exoskeleton-assisted rehabilitation. By systematically analyzing the application of AI models in robot control, intention detection, and locomotion classification, the authors emphasize the role of AI in facilitating task- and user-specific adaptation, with potential applications extending from clinical centers to telerehabilitation and home-based care. It is noteworthy that this paper was recognized among the top 11 publications of 2024 by Frontiers in Robotics and AI, signifying its significance and impact within the research community \cite{2025frontiers}.Complementing these literature analyses, \href{https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1441955/full}{Arora et al.} propose an approach grounded on the use of a socially assistive robot to deliver neurorehabilitation training. Their work introduces an empathetic virtual coaching system integrated with a robotic device, designed to enhance patient engagement by sensing affective states and adapting the robot-therapy interaction accordingly. This novel combination of affective computing and socially interactive agents reintroduces the human-like relational dimension into robotic neurorehabilitation, which is critical especially in out-of-clinic settings.The studies included in this Research Topic provide a solid foundation for guiding future research and development of novel AI-driven multimodal interfaces for rehabilitation robotics. The comprehensive reviews of the literature offer valuable references for researchers and practitioners in the field. Rather than focusing solely on technological innovation, these contributions help delineate key directions to be pursued to design truly effective and impactful rehabilitation systems. Furthermore, the original contribution underscores the nascent strides towards the integration of such technologies, encompassing artificial intelligence and multimodal patient monitoring within the clinical rehabilitation milieu.A recurrent theme in the papers collected in this Research Topic is the significance of acquiring and integrating diverse data modalities to facilitate a more comprehensive and detailed comprehension of the patient's motor and cognitive condition. This multimodal approach is pivotal to fostering personalization and adaptability in robot-assisted therapy. In addition, all contributions underscore the necessity for rigorous future clinical validation of AI-based methods, emphasizing that technological robustness alone is insufficient. It is imperative to demonstrate real-world utility and therapeutic impact for the effective integration of these innovations in clinical practice. Furthermore, all contributions converge on the importance of placing the patient at the center of the rehabilitation process. The promotion of active engagement is not only a matter of user experience but also a key factor in enhancing neuroplasticity and improving long-term outcomes.By consolidating these insights, this Research Topic delineates a conceptual and methodological roadmap for future work, thereby fostering the development of intelligent, human-centered, and clinically meaningful solutions in robot-aided rehabilitation.},
  archive      = {J_FROBT},
  author       = {Tamantini, Christian and Patrice Langlois, Kevin and Cianca, David Rodriguez and Zollo, Loredana},
  doi          = {10.3389/frobt.2025.1605418},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1605418},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advancements in AI-driven multimodal interfaces for robot-aided rehabilitation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-design methodology for rapid prototyping of modular robots in care settings. <em>FROBT</em>, <em>12</em>, 1581506. (<a href='https://doi.org/10.3389/frobt.2025.1581506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis paper introduces a structured co-design methodology for developing modular robotic solutions for the care sector. Despite the widespread adoption of co-design in robotics, existing frameworks often lack clear and systematic processes to effectively incorporate user requirements into tangible robotic designs.MethodTo address this gap, the present work proposes an iterative, modular co-design methodology that captures, organises, and translates user insights into practical robotic modules. The methodology employs Design Research (DR) methods combined with Design for Additive Manufacturing (DfAM) principles, enabling rapid prototyping and iterative refinement based on continuous user feedback. The proposed approach was applied in the development of Robobrico, a modular robot created collaboratively with care home users.ResultsOutcomes from this study demonstrate that this structured process effectively aligns robot functionality with user expectations, enhances adaptability, and facilitates practical integration of modular robotic platforms in real-world care environments.DiscussionThis paper details the proposed methodology, the tools developed to support it, and key insights derived from its implementation.},
  archive      = {J_FROBT},
  author       = {Colle, Alexandre and Donaldson, Karen and Dragone, Mauro},
  doi          = {10.3389/frobt.2025.1581506},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1581506},
  shortjournal = {Front. Robot. AI},
  title        = {Co-design methodology for rapid prototyping of modular robots in care settings},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From text to motion: Grounding GPT-4 in a humanoid robot “Alter3”. <em>FROBT</em>, <em>12</em>, 1581110. (<a href='https://doi.org/10.3389/frobt.2025.1581110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Alter3, a humanoid robot that demonstrates spontaneous motion generation through the integration of GPT-4, a cutting-edge Large Language Model (LLM). This integration overcomes the challenge of applying LLMs to direct robot control, which typically struggles with the hardware-specific nuances of robotic operation. By translating linguistic descriptions of human actions into robotic movements via programming, Alter3 can autonomously perform a diverse range of actions, such as adopting a “selfie” pose or simulating a “ghost.” This approach not only shows Alter3’s few-shot learning capabilities but also its adaptability to verbal feedback for pose adjustments without manual fine-tuning. This research advances the field of humanoid robotics by bridging linguistic concepts with physical embodiment and opens new avenues for exploring spontaneity in humanoid robots.},
  archive      = {J_FROBT},
  author       = {Yoshida, Takahide and Masumori, Atsushi and Ikegami, Takashi},
  doi          = {10.3389/frobt.2025.1581110},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1581110},
  shortjournal = {Front. Robot. AI},
  title        = {From text to motion: Grounding GPT-4 in a humanoid robot “Alter3”},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous text and gesture generation for social robots with small language models. <em>FROBT</em>, <em>12</em>, 1581024. (<a href='https://doi.org/10.3389/frobt.2025.1581024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs social robots gain advanced communication capabilities, users increasingly expect coherent verbal and non-verbal behaviours. Recent work has shown that Large Language Models (LLMs) can support autonomous generation of such multimodal behaviours. However, current LLM-based approaches to non-verbal behaviour often involve multi-step reasoning with large, closed-source models-resulting in significant computational overhead and limiting their feasibility in low-resource or privacy-constrained environments.MethodsTo address these limitations, we propose a novel method for simultaneous generation of text and gestures with minimal computational overhead compared to plain text generation. Our system does not produce low-level joint trajectories, but instead predicts high-level communicative intentions, which are mapped to platform-specific expressions. Central to our approach is the introduction of lightweight, robot-specific “gesture heads” derived from the LLM’s architecture, requiring no pose-based datasets and enabling generalisability across platforms.ResultsWe evaluate our method on two distinct robot platforms: Furhat (facial expressions) and Pepper (bodily gestures). Experimental results demonstrate that our method maintains behavioural quality while introducing negligible computational and memory overhead. Furthermore, the gesture heads operate in parallel with the language generation component, ensuring scalability and responsiveness even on small or locally deployed models.DiscussionOur approach supports the use of Small Language Models for multimodal generation, offering an effective alternative to existing high-resource methods. By abstracting gesture generation and eliminating reliance on platform-specific motion data, we enable broader applicability in real-world, low-resource, and privacy-sensitive HRI settings.},
  archive      = {J_FROBT},
  author       = {Galatolo, Alessio and Winkle, Katie},
  doi          = {10.3389/frobt.2025.1581024},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1581024},
  shortjournal = {Front. Robot. AI},
  title        = {Simultaneous text and gesture generation for social robots with small language models},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human interactions with delivery drones in public spaces: Design recommendations from recipient and bystander perspectives. <em>FROBT</em>, <em>12</em>, 1580289. (<a href='https://doi.org/10.3389/frobt.2025.1580289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones will likely deliver packages in public spaces, where humans interact as recipients of the package and as bystanders passing by. Understanding the human needs and uncertainties that may arise during these interactions is crucial to ensure safety. This user-centered design study employed twelve interviews and four focus groups to identify key requirements for recipients and bystanders interacting with delivery drones in public spaces. Findings demonstrate different information needs and preferred interface modalities between recipients and bystanders across various interaction stages, from ordering a package to the drone’s retraction after delivery. This paper highlights essential design features and offers concrete design recommendations based on the interaction requirements. These recommendations can inform the standardization and customization of design features for each interaction stage, enhancing safety and facilitating natural human-drone interaction. Future research should build on these recommendations and validate the design concepts through experimental user studies involving human interactions with delivery drones in public spaces.},
  archive      = {J_FROBT},
  author       = {Lingam, Shiva Nischal and Verstegen, Rutger and Petermeijer, Sebastiaan M. and Martens, Marieke},
  doi          = {10.3389/frobt.2025.1580289},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1580289},
  shortjournal = {Front. Robot. AI},
  title        = {Human interactions with delivery drones in public spaces: Design recommendations from recipient and bystander perspectives},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of robotic and automated systems in meat processing. <em>FROBT</em>, <em>12</em>, 1578318. (<a href='https://doi.org/10.3389/frobt.2025.1578318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tasks in the meat processing sector are physically challenging, repetitive, and prone to worker scarcity. Therefore, the imperative adoption of mechanization and automation within the domain of meat processing is underscored by its key role in mitigating labor-intensive processes while concurrently enhancing productivity, safety, and operator wellbeing. This review paper gives an overview of the current research for robotic and automated systems in meat processing. The modules of a robotic system are introduced and afterward, the robotic tasks are divided into three sections with the features of processing targets including livestock, poultry, and seafood. Furthermore, we analyze the technical details of whole meat processing, including skinning, gutting, abdomen cutting, and half-carcass cutting, and discuss these systems in performance and industrial feasibility. The review also refers to some commercialized products for automation in the meat processing industry. Finally, we conclude the review and discuss potential challenges for further robotization and automation in meat processing.},
  archive      = {J_FROBT},
  author       = {Lyu, Yining and Wu, Fan and Wang, Qingyu and Liu, Guanyu and Zhang, Yingqi and Jiang, Huanyu and Zhou, Mingchuan},
  doi          = {10.3389/frobt.2025.1578318},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1578318},
  shortjournal = {Front. Robot. AI},
  title        = {A review of robotic and automated systems in meat processing},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid tendon-driven continuum robot that avoids torsion under external load. <em>FROBT</em>, <em>12</em>, 1576209. (<a href='https://doi.org/10.3389/frobt.2025.1576209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-driven continuum robots usually consists of several actuators and cables pulling a flexible backbone. The tendon path alongside the backbone allows to perform complex movements with high dexterity. Yet, the integration of multiple tendons adds complexity and the lack of rigidity makes continuum robots susceptible to torsion whenever an external force or load is applied. This paper proposes a reduced complexity, hybrid tendon-driven continuum robot (HTDCR) that avoids undesired torsion under external load. Bending of the HTDCR is achieved from a single tendon with lateral joints alongside the backbone acting as mechanical constraint on the bending plane. A rotary base then provides an additional degree of freedom by allowing full rotation of the arm. We developed a robot prototype with control law based on a constant curvature model and validated it experimentally with various loads on the tip. Body deviation outside the bending plane is negligible (mm range), thereby demonstrating no torsional deformation. Tip deflection within the bending plane is smaller than the one obtained with a 4-tendon driven continuum robot. Moreover, tip deflection can be accurately estimated from the load and motor input which paves the way to possible compensation. All together, the experiments demonstrate the efficiency of the HTDCR with 450 g payload which makes it suitable in agricultural tasks such as fruit and vegetable harvesting.},
  archive      = {J_FROBT},
  author       = {Huertas Niño, Maria Paula and Boutayeb, Mohamed and Martinez, Dominique},
  doi          = {10.3389/frobt.2025.1576209},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1576209},
  shortjournal = {Front. Robot. AI},
  title        = {A hybrid tendon-driven continuum robot that avoids torsion under external load},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning computer-aided manufacturing from demonstration: A case study with probabilistic movement primitives in robot wood carving. <em>FROBT</em>, <em>12</em>, 1569476. (<a href='https://doi.org/10.3389/frobt.2025.1569476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schäle, Daniel and Stoelen, Martin F. and Kyrkjebø, Erik},
  doi          = {10.3389/frobt.2025.1569476},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1569476},
  shortjournal = {Front. Robot. AI},
  title        = {Learning computer-aided manufacturing from demonstration: A case study with probabilistic movement primitives in robot wood carving},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consideration of communication in human–machine interaction for cooperative trajectory planning. <em>FROBT</em>, <em>12</em>, 1568402. (<a href='https://doi.org/10.3389/frobt.2025.1568402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schneider, Julian and Varga, Balint and Hohmann, Sören},
  doi          = {10.3389/frobt.2025.1568402},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1568402},
  shortjournal = {Front. Robot. AI},
  title        = {Consideration of communication in human–machine interaction for cooperative trajectory planning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How multimodal narrative and visual representations of human-like service robots shape attitudes and social connection. <em>FROBT</em>, <em>12</em>, 1568146. (<a href='https://doi.org/10.3389/frobt.2025.1568146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPublic attitudes toward service robots are critical to their acceptance across various industries. Previous research suggests that human-like features and behaviours perceived as empathetic may reduce negative perceptions and enhance emotional engagement. However, there is limited empirical evidence on how structured multimodal interventions influence these responses.MethodsA partially mixed experimental design was employed, featuring one between-subjects factor (group: experimental vs. control) and one within-subjects factor (time: pre-intervention vs. post-intervention), applied only to the experimental group. Two hundred twenty-eight adults (aged 18–65) were randomly assigned to either the experimental or control condition. The intervention included images, video demonstrations of human-like service robots performing socially meaningful gestures, and a narrative vignette depicting human–robot interaction. The control group completed the same assessment measures without the intervention. Outcomes included negative attitudes toward robots (Negative Attitudes Toward Robots Scale, NARS), affect (Positive and Negative Affect Schedule, PANAS), and perceived interpersonal connection (Inclusion of Other in the Self scale, IOS).ResultsThe experimental group demonstrated a significant reduction in negative attitudes (p < 0.001, Cohen’s d = 0.37), as well as lower negative affect and a greater perceived interpersonal connection with the robots (both p < 0.001). Age moderated baseline attitudes, with younger participants reporting more positive initial views; gender was not a significant factor.DiscussionThese findings suggest that multimodal portrayals of human-like service robots can improve attitudes, affective responses, and interpersonal connection, offering practical insights for robot design, marketing, and public engagement strategies.},
  archive      = {J_FROBT},
  author       = {Daruwala, Neil Anthony},
  doi          = {10.3389/frobt.2025.1568146},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1568146},
  shortjournal = {Front. Robot. AI},
  title        = {How multimodal narrative and visual representations of human-like service robots shape attitudes and social connection},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-assessment in machines boosts human trust. <em>FROBT</em>, <em>12</em>, 1557075. (<a href='https://doi.org/10.3389/frobt.2025.1557075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low trust in autonomous systems remains a significant barrier to adoption and performance. To effectively increase trust in these systems, machines must perform actions to calibrate human trust based on an accurate assessment of both their capability and human trust in real time. Existing efforts demonstrate the value of trust calibration in improving team performance but overlook the importance of machine self-assessment capabilities in the trust calibration process. In our work, we develop a closed-loop trust calibration system for a human-machine collaboration task to classify images and demonstrate about 40% improvement in human trust and 5% improvement in team performance with trained machine self-assessment compared to the baseline, despite the same machine performance level between them. Our trust calibration system applies to any semi-autonomous application requiring human-machine collaboration.},
  archive      = {J_FROBT},
  author       = {Warmsley, Dana and Choudhary , Krishna and Rego , Jocelyn and Viani , Emma and Pilly , Praveen K.},
  doi          = {10.3389/frobt.2025.1557075},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1557075},
  shortjournal = {Front. Robot. AI},
  title        = {Self-assessment in machines boosts human trust},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “All things equal”: Ethical principles governing why autonomous vehicle experts change or retain their opinions in trolley problems—a qualitative study. <em>FROBT</em>, <em>12</em>, 1544272. (<a href='https://doi.org/10.3389/frobt.2025.1544272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAutonomous vehicles (AVs) are already being featured on some public roads. However, there is evidence suggesting that the general public remains particularly concerned and skeptical regarding the ethics of collision scenarios.MethodsThis study presents the findings of the first qualitative research into the ethical opinions of experts responsible for the design, deployment, and regulation of AVs. A total of 46 experts were interviewed in this study and presented with two trolley-problem-like vignettes. The experts were asked for an initial opinion on the basis of which the parameters of the vignettes were changed to gauge the principles that would result in either changing or retaining an ethical opinion. Much research has been conducted on public opinion, but there are no available research findings on the ethical opinions of AV experts.ResultsFollowing reflective thematic analysis, four important findings were deduced: 1) although the expert opinions are broadly utilitarian, they are nuanced in significant ways to focus on the impacts of collision scenarios on the community as a whole. 2) Obeying the rules of the road remains a significantly strong ethical opinion. 3) Responsibility and risk play important roles in how AVs should handle collision situations. 4) Egoistic opinions were present to a limited extent.DiscussionThe findings show that the ethics of AVs still pose a serious challenge; furthermore, while utilitarianism appears to be a driving ethical principle on the surface, along with the need for both AVs and vulnerable road users to obey the rules, questions concerning community impacts and risk vs. responsibility remain strong influences among AV experts.},
  archive      = {J_FROBT},
  author       = {Milford, Stephen R. and Malgir, B. Zara and Elger, Bernice S. and Shaw, David M.},
  doi          = {10.3389/frobt.2025.1544272},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1544272},
  shortjournal = {Front. Robot. AI},
  title        = {“All things equal”: Ethical principles governing why autonomous vehicle experts change or retain their opinions in trolley problems—a qualitative study},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to suppress tremors: A deep reinforcement learning-enabled soft exoskeleton for parkinson’s patients. <em>FROBT</em>, <em>12</em>, 1537470. (<a href='https://doi.org/10.3389/frobt.2025.1537470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionNeurological tremors, prevalent among a large population, are one of the most rampant movement disorders. Biomechanical loading and exoskeletons show promise in enhancing patient well-being, but traditional control algorithms limit their efficacy in dynamic movements and personalized interventions. Furthermore, a pressing need exists for more comprehensive and robust validation methods to ensure the effectiveness and generalizability of proposed solutions.MethodsThis paper proposes a physical simulation approach modeling multiple arm joints and tremor propagation. This study also introduces a novel adaptable reinforcement learning environment tailored for disorders with tremors. We present a deep reinforcement learning-based encoder-actor controller for Parkinson’s tremors in various shoulder and elbow joint axes displayed in dynamic movements.ResultsOur findings suggest that such a control strategy offers a viable solution for tremor suppression in real-world scenarios.DiscussionBy overcoming the limitations of traditional control algorithms, this work takes a new step in adapting biomechanical loading into the everyday life of patients. This work also opens avenues for more adaptive and personalized interventions in managing movement disorders.},
  archive      = {J_FROBT},
  author       = {Endrei, Tamás and Földi, Sándor and Makk, Ádám and Cserey, György},
  doi          = {10.3389/frobt.2025.1537470},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1537470},
  shortjournal = {Front. Robot. AI},
  title        = {Learning to suppress tremors: A deep reinforcement learning-enabled soft exoskeleton for parkinson’s patients},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AcoustoBots: A swarm of robots for acoustophoretic multimodal interactions. <em>FROBT</em>, <em>12</em>, 1537101. (<a href='https://doi.org/10.3389/frobt.2025.1537101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAcoustophoresis has enabled novel interaction capabilities, such as levitation, volumetric displays, mid-air haptic feedback, and directional sound generation, to open new forms of multimodal interactions. However, its traditional implementation as a singular static unit limits its dynamic range and application versatility.MethodsThis paper introduces “AcoustoBots” — a novel convergence of acoustophoresis with a movable and reconfigurable phased array of transducers for enhanced application versatility. We mount a phased array of transducers on a swarm of robots to harness the benefits of multiple mobile acoustophoretic units. This offers a more flexible and interactive platform that enables a swarm of acoustophoretic multimodal interactions. Our novel AcoustoBots design includes a hinge actuation system that controls the orientation of the mounted phased array of transducers to achieve high flexibility in a swarm of acoustophoretic multimodal interactions. In addition, we designed a BeadDispenserBot that can deliver particles to trapping locations, which automates the acoustic levitation interaction.ResultsThese attributes allow AcoustoBots to independently work for a common cause and interchange between modalities, allowing for novel augmentations (e.g., a swarm of haptics, audio, and levitation) and bilateral interactions with users in an expanded interaction area.DiscussionWe detail our design considerations, challenges, and methodological approach to extend acoustophoretic central control in distributed settings. This work demonstrates a scalable acoustic control framework with two mobile robots, laying the groundwork for future deployment in larger robotic swarms. Finally, we characterize the performance of our AcoustoBots and explore the potential interactive scenarios they can enable.},
  archive      = {J_FROBT},
  author       = {Kemsaram, Narsimlu and Hardwick, James and Wang, Jincheng and Gautam, Bonot and Besevli, Ceylan and Christopoulos, Giorgos and Dogra, Sourabh and Gao, Lei and Delibasi, Akin and Plasencia, Diego Martinez and Georgiou, Orestis and Obrist, Marianna and Hirayama, Ryuji and Subramanian, Sriram},
  doi          = {10.3389/frobt.2025.1537101},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1537101},
  shortjournal = {Front. Robot. AI},
  title        = {AcoustoBots: A swarm of robots for acoustophoretic multimodal interactions},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROSA: A knowledge-based solution for robot self-adaptation. <em>FROBT</em>, <em>12</em>, 1531743. (<a href='https://doi.org/10.3389/frobt.2025.1531743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots must operate in diverse environments and handle multiple tasks despite uncertainties. This creates challenges in designing software architectures and task decision-making algorithms, as different contexts may require distinct task logic and architectural configurations. To address this, robotic systems can be designed as self-adaptive systems capable of adapting their task execution and software architecture at runtime based on their context. This paper introduces ROSA, a novel knowledge-based framework for RObot Self-Adaptation, which enables task-and-architecture co-adaptation (TACA) in robotic systems. ROSA achieves this by providing a knowledge model that captures all application-specific knowledge required for adaptation and by reasoning over this knowledge at runtime to determine when and how adaptation should occur. In addition to a conceptual framework, this work provides an open-source ROS 2-based reference implementation of ROSA and evaluates its feasibility and performance in an underwater robotics application. Experimental results highlight ROSA’s advantages in reusability and development effort for designing self-adaptive robotic systems.},
  archive      = {J_FROBT},
  author       = {Rezende Silva, Gustavo and Päßler, Juliane and Tapia Tarifa, S. Lizeth and Johnsen, Einar Broch and Hernández Corbato, Carlos},
  doi          = {10.3389/frobt.2025.1531743},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1531743},
  shortjournal = {Front. Robot. AI},
  title        = {ROSA: A knowledge-based solution for robot self-adaptation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exoskeletons for the rehabilitation of temporomandibular disorders: A comprehensive review. <em>FROBT</em>, <em>12</em>, 1492275. (<a href='https://doi.org/10.3389/frobt.2025.1492275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Müller, Paul-Otto and Sader, Robert and von Stryk, Oskar},
  doi          = {10.3389/frobt.2025.1492275},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1492275},
  shortjournal = {Front. Robot. AI},
  title        = {Exoskeletons for the rehabilitation of temporomandibular disorders: A comprehensive review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neurotechnology for enhancing human operation of robotic and semi-autonomous systems. <em>FROBT</em>, <em>12</em>, 1491494. (<a href='https://doi.org/10.3389/frobt.2025.1491494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human operators of remote and semi-autonomous systems must have a high level of executive function to safely and efficiently conduct operations. These operators face unique cognitive challenges when monitoring and controlling robotic machines, such as vehicles, drones, and construction equipment. The development of safe and experienced human operators of remote machines requires structured training and credentialing programs. This review critically evaluates the potential for incorporating neurotechnology into remote systems operator training and work to enhance human-machine interactions, performance, and safety. Recent evidence demonstrating that different noninvasive neuromodulation and neurofeedback methods can improve critical executive functions such as attention, learning, memory, and cognitive control is reviewed. We further describe how these approaches can be used to improve training outcomes, as well as teleoperator vigilance and decision-making. We also describe how neuromodulation can help remote operators during complex or high-risk tasks by mitigating impulsive decision-making and cognitive errors. While our review advocates for incorporating neurotechnology into remote operator training programs, continued research is required to evaluate the how these approaches will impact industrial safety and workforce readiness.},
  archive      = {J_FROBT},
  author       = {Tyler, William J. and Adavikottu, Anusha and Blanco, Christian Lopez and Mysore, Archana and Blais, Christopher and Santello, Marco and Unnikrishnan, Avinash},
  doi          = {10.3389/frobt.2025.1491494},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1491494},
  shortjournal = {Front. Robot. AI},
  title        = {Neurotechnology for enhancing human operation of robotic and semi-autonomous systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bat optimization of hybrid neural network-FOPID controllers for robust robot manipulator control. <em>FROBT</em>, <em>12</em>, 1487844. (<a href='https://doi.org/10.3389/frobt.2025.1487844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Oleiwi, Bashra Kadhim and Jasim, Mohamed and Azar, Ahmad Taher and Ahmed, Saim and Mahlous, Ahmed Redha},
  doi          = {10.3389/frobt.2025.1487844},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1487844},
  shortjournal = {Front. Robot. AI},
  title        = {Bat optimization of hybrid neural network-FOPID controllers for robust robot manipulator control},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing needle puncture detection using high-pass filtering and diffuse reflectance. <em>FROBT</em>, <em>12</em>, 1429327. (<a href='https://doi.org/10.3389/frobt.2025.1429327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {L’Orsa, Rachael and Bisht, Anupam and Yu, Linhui and Murari, Kartikeya and Sutherland, Garnette R. and Westwick, David T. and Kuchenbecker, Katherine J.},
  doi          = {10.3389/frobt.2025.1429327},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1429327},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing needle puncture detection using high-pass filtering and diffuse reflectance},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Intelligent robots for agriculture -- Ag-robot development, navigation, and information perception. <em>FROBT</em>, <em>12</em>, 1597912. (<a href='https://doi.org/10.3389/frobt.2025.1597912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic platforms tailored for agricultural environments require adaptability to diverse terrains, robustness in operation, and the ability to handle complex tasks. Zhang et al. (2024) present a bionic hexapod robot designed for agricultural field scouting, equipped with adaptive gait control for improved mobility across uneven terrains. Their study demonstrates the potential of legged robots in agricultural applications, showing enhanced stability and energy efficiency compared to traditional wheeled platforms. Balabantaray et al. (2024) contribute to precision weed management by integrating deep learning with robotics. Their study introduces a YOLOv7-powered robotic system for targeted spraying of Palmer amaranth, significantly reducing herbicide usage while increasing accuracy in weed identification. The system demonstrates how AI-driven robotics can enhance environmental sustainability in modern agriculture.Autonomous navigation is a fundamental requirement for agricultural robots, enabling precise field operations. Mwitta and Rains (2024) explore the integration of GPS and visual navigation for Ackerman-steering mobile robots in cotton fields. Their research highlights the synergy between GPS-based global planning and deep learning-based local navigation using semantic segmentation, enhancing real-time adaptability in row-based crop navigation.The combination of multiple sensor technologies, including LiDAR, RGB-D cameras, and GNSS, has been shown to improve the accuracy and robustness of robotic navigation in unstructured environments. Such multi-sensor fusion approaches allow agricultural robots to operate in dynamic field conditions with reduced reliance on human intervention. These advances represent a crucial step toward fully autonomous robotic farming systems capable of performing complex tasks such as seeding, fertilizing, and crop monitoring.Artificial intelligence (AI) plays a pivotal role in advancing agricultural robotics, particularly in perception, decision-making, and control. Mahmoudi et al. ( 2024) provide a comprehensive survey on the role of imitation learning in agricultural robotics, demonstrating how robots can learn from human demonstrations to improve automation in complex agricultural tasks. Their work emphasizes the importance of machine learning in enabling robots to adapt to dynamic environments, enhancing their operational effectiveness in diverse agricultural settings.Beyond imitation learning, AI-based models, including reinforcement learning and deep neural networks, are increasingly used to optimize robotic behaviors in agricultural environments. These technologies enable autonomous decision-making, allowing robots to adjust their actions based on real-time environmental feedback. The continued development of AI-driven agricultural robotics is expected to yield significant improvements in efficiency, scalability, and adaptability across various farming applications.By advancing robotic design, AI-driven decision-making, and autonomous navigation, these studies pave the way for a future where robotics plays a central role in ensuring global food security and sustainable farming practices. Future research should focus on improving the generalizability of robotic solutions across different agricultural domains, enhancing robot perception capabilities through multi-modal sensor fusion, and addressing cost-effectiveness for broader adoption. Moreover, ethical and regulatory considerations in AI-driven agriculture need further exploration to ensure responsible and sustainable deployment.},
  archive      = {J_FROBT},
  author       = {Young, Sierra N.},
  doi          = {10.3389/frobt.2025.1597912},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1597912},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Intelligent robots for agriculture -- Ag-robot development, navigation, and information perception},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum: Editorial: Advanced motion control and navigation of robots in extreme environments. <em>FROBT</em>, <em>12</em>, 1593019. (<a href='https://doi.org/10.3389/frobt.2025.1593019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {• please read through all the templates before choosing • pick the most relevant text template(s) from the following page and delete all others.• edit the text as necessary, ensuring that the original incorrect text is included for the record, please see the below. • please do not use any extra formatting when editing the templates, and only modify the red text unless absolutely necessary • submit to Frontiers following the instructions on this page.When the original text contained incorrect information, to preserve the scientific record, please include that text when editing the below templates. For example:There was a mistake in the Funding statement, an incorrect number was used. The correct number is "2015C03Bd051.". The publisher apologizes for this mistake.The original version of this article has been updated.In the published article, there was a mistake in the Funding statement.},
  archive      = {J_FROBT},
  author       = {Montazeri, Allahyar and Sadeghzadeh-Nokhodberiz, Nargess and Shojaei, Khoshnam and Althoefer, Kaspar},
  doi          = {10.3389/frobt.2025.1593019},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1593019},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Editorial: Advanced motion control and navigation of robots in extreme environments},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Advances in robots for learning. <em>FROBT</em>, <em>12</em>, 1584122. (<a href='https://doi.org/10.3389/frobt.2025.1584122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly demonstrating significant potential as learning and teaching companions for children in classrooms or at home, for elderly people to help maintain their cognitive and physical abilities, and for learners with deficiencies by facilitating personalized instruction by adapting content to their specific needs. Robots show the potential to improve individual adaptation by learning from and with the user.Currently, several research projects aim to apply HRI to education and learning across a broader range of disciplines beyond STEM, such as language and handwriting. These projects also extend beyond imparting domain-specific skills, like computational thinking, to fostering collaborative skills and addressing diverse end-users, including children (neurotypical and neurodivergent), adults, and the elderly (both healthy and cognitively challenged).Since the first Research Topic in this series explored how HRI can push the boundaries of education in various ways, a follow-up Research Topic would be valuable in understanding how advancements in the field are progressing, particularly in light of the rapid growth of AI over the past decade.Therefore, the current Research Topic highlights advancements in social robotics, particularly exploring innovative algorithms and computational models within learning environments. Emphasis was placed on contributions introducing new theories, models, and methodologies for learning alongside robots while keeping the user and other stake-holders in the design process. Additionally, original technical research showcasing robot-centric systems, algorithms, and computational techniques designed specifically for real-time learner-robot interactions was encouraged. A key focus was to distinguish the unique aspects of learner-robot interaction from traditional human-robot interaction frameworks.This Research Topic emerged from a series of workshops and research projects involving the editors, Dr Daniel Tozadore, Dr Jauwairia Nasir, A/Prof. Wafa Johal, and A/Prof Michelle M. Neumann. Individually, we were captivated by the opportunities and challenges of integrating robots into education, and collectively, we shared a deep enthusiasm for their potential to revolutionize social robotics in meaningful ways.The paper Time-dependant Bayesian knowledge tracing-Robots that model user skills over time Salomons and Scassellati (2024), from Salomons and Scassellati, focuses on user skill modeling for Intelligent Tutoring Systems (ITS) and robotic tutors, particularly for complex tasks like programming and engineering. It introduces Time-Dependent Bayesian Knowledge Tracing (TD-BKT), an algorithm that continuously tracks user skills and provides more accurate teaching interventions. A user study demonstrated that a robot using TD-BKT effectively taught electronic circuit tasks, leading to significant skill improvements among participants.Personalized learning is key to improving student engagement, yet traditional adaptive tutoring systems rely heavily on digital platforms and lack real-world social interaction. Socially assistive robots offer a promising alternative by integrating AI-driven assessments with real-time embodied social interactions. Mounsef et al (2025) Mounsef et al. (2024) present a tutor robot that personalizes education using facial expression analysis, subjective feedback, and performance metrics to classify students into tailored learning categories. The system employs the XGBoost algorithm to predict proficiency levels with high accuracy and dynamically adjust learning content. The results show that the students using the AIpowered robotic tutor demonstrated significant improvement in learning outcomes compared to a control group that interacted with a human teacher.Educational social robots typically focus on domain knowledge, which is challenging as it requires either autonomous learning or frequent reprogramming. An alternative approach is designing robots that understand student behaviors linked to learning, rather than domain knowledge. In their paper, titled Social robots as skilled ignorant peers for supporting learning, Nasir et al introduce skilled ignorant peer robots, which foster productive engagement Nasir et al. (2024) using behavioral insights rather than domain expertise and formally investigate the relationship between (i) the robot interventions and students' engagement, and (ii) students' engagement and learning. A user study with 136 students compared two versions of such robots in real-time: Harry (focused on what to suggest) and Hermione (also considered when and why to intervene). While both robots led to similar learning gains, Hermione's well-timed interventions were deemed more useful and indeed influenced students productive engagement state, highlighting the importance of timing in educational robot interactions.In their paper titled Fostering children's creativity through LLM-driven storytelling with a social robot, Elgarf et al. Elgarf et al. (2024) explore how a social robot could be used to stimulate children's creativity by manipulating the level of creativity of a co-storyteller social robot. Through two user studies, with a total of 141 children, authors show that social robots prototyping creative behaviour can help children be more fluent and detailed in their idea generation. They demonstrate how LLMs can be used to scaffold the way children collaborate with social robot in a learning context.Unlocking the full potential of telepresence robots for teaching in remote and local classroom environments is essential due to the changing nature of education and learning. Telepresence robots do not fully live up to the expectation of teachers and designers for supporting robot-mediated learning. In the paper Robots for learning: An exploration of teacher roles, perceptions, and challenges in robot-mediated learning Ahumada-Newhart and Eccles (2024), Ahumada-Newhart et al. explore teachers' experiences and perceptions of using telepresence robots for robot-mediated learning and provides valuable insights for best practice and highlights recommendations for technology designers.Similarly, in their paper Multiuser design of an architecture for social robots in education: teachers, students, and researchers perspectives Tozadore and Romero (2024), Tozadore and Romero present the findings of an Interactive Design study exploring the challenges of integrating social assistive robots in classrooms, addressing both technical limitations and human factors such as teacher workload and stakeholder communication. It builds teachers and researchers experiences on the robotic architecture R-CASTLE, developed through extensive assessments with teachers and students, featuring an intuitive graphical interface designed for educators. Findings reveal that teachers can effortlessly incorporate their daily activities into the system without prior experience with social robots, demonstrating its usability and potential for classroom adoption.Social robots have a wide application in special education as well. In the paper entitled Managing social-educational robotics for students with autism spectrum disorder through business model canvas and customer discovery, Anshu et al. Arora et al. (2024) investigate the role of social-educational robotics, particularly humanoid robots like NAO, in supporting ASD students through social and collaborative interactions. It introduces a triad framework involving ASD students, teachers, and social robots while utilizing the Business Model Canvas (BMC) for robot design and curriculum development. Through customer discovery interviews, the study bridges academic research and industry, resulting in eight core propositions that enhance learning environments for ASD students and prepare them for future educational and workforce opportunities.To assist the therapists in robot assisted therapy, this study by Stolarz et al. Stolarz et al. (2024) explores increasing the autonomy of robots by developing a learning-based behavior model using reinforcement learning. The authors tested different reward functions to optimize user engagement and activity performance and what they demonstrate is that strategies like policy transfer and learning from expert feedback help improve the learning process. A smallscale study with six users suggests that learning from guidance yields the most effective policies.Advancements in the field of educational robotics follow the natural trajectory of technological development by proposing new algorithms for robot behavior regulation, human modeling to understand students' cognitive states for robot mediation, and machine learning techniques to equip robots with convincing social behaviors. More interestingly, these advancements also consider external factors in their design, such as stakeholders' opinions, students' feedback and limitations, as well as business interests.Finally, while the first editorial explores the broader role of robots in education, emphasizing stakeholder perspectives, social-emotional concerns, and diverse learning contexts, the second edition of the special issue leans towards AI-driven personalization, adaptive learning, and industry applications. Together, they highlight the evolution of educational robotics towards data-driven, personalized learning experiences and highlight several unique and important facets of robots for education.},
  archive      = {J_FROBT},
  author       = {Tozadore, Daniel and Nasir, Jauwairia and Johal, Wafa and Neumann, Michelle M.},
  doi          = {10.3389/frobt.2025.1584122},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1584122},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advances in robots for learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and preliminary evaluation of a track-based robotic colonoscope with a shape-adaptable tip for propulsion. <em>FROBT</em>, <em>12</em>, 1580692. (<a href='https://doi.org/10.3389/frobt.2025.1580692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Du, Jiayang and Cao, Lin and Dogramadzi, Sanja},
  doi          = {10.3389/frobt.2025.1580692},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1580692},
  shortjournal = {Front. Robot. AI},
  title        = {Design and preliminary evaluation of a track-based robotic colonoscope with a shape-adaptable tip for propulsion},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing supermarket robot interaction: An equitable multi-level LLM conversational interface for handling diverse customer intents. <em>FROBT</em>, <em>12</em>, 1576348. (<a href='https://doi.org/10.3389/frobt.2025.1576348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nandkumar, Chandran and Peternel, Luka},
  doi          = {10.3389/frobt.2025.1576348},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1576348},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing supermarket robot interaction: An equitable multi-level LLM conversational interface for handling diverse customer intents},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy adaptive fault-tolerant control for an unmanned surface vehicle with prescribed tracking performance. <em>FROBT</em>, <em>12</em>, 1576171. (<a href='https://doi.org/10.3389/frobt.2025.1576171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bao, Yunuo and Gao, Ji and Peng, Peng},
  doi          = {10.3389/frobt.2025.1576171},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1576171},
  shortjournal = {Front. Robot. AI},
  title        = {Fuzzy adaptive fault-tolerant control for an unmanned surface vehicle with prescribed tracking performance},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision farming in aquaculture: Non-invasive monitoring of atlantic salmon (Salmo salar) behaviour in response to environmental conditions in commercial sea cages for health and welfare assessment. <em>FROBT</em>, <em>12</em>, 1574161. (<a href='https://doi.org/10.3389/frobt.2025.1574161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Burke, Meredith and Nikolic, Dragana and Fabry, Pieter and Rishi, Hemang and Telfer, Trevor and Rey Planellas, Sonia},
  doi          = {10.3389/frobt.2025.1574161},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1574161},
  shortjournal = {Front. Robot. AI},
  title        = {Precision farming in aquaculture: Non-invasive monitoring of atlantic salmon (Salmo salar) behaviour in response to environmental conditions in commercial sea cages for health and welfare assessment},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous mission planning for planetary surface exploration using a team of micro rovers. <em>FROBT</em>, <em>12</em>, 1565173. (<a href='https://doi.org/10.3389/frobt.2025.1565173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Swinton, Sarah and Ewers, Jan-Hendrik and McGookin, Euan and Anderson, David and Thomson, Douglas},
  doi          = {10.3389/frobt.2025.1565173},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1565173},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous mission planning for planetary surface exploration using a team of micro rovers},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Who will you imitate? studying reciprocal influence in children-robot groups during an imitation game. <em>FROBT</em>, <em>12</em>, 1563923. (<a href='https://doi.org/10.3389/frobt.2025.1563923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pusceddu, Giulia and Cocchella, Francesca and Bogliolo, Michela and Belgiovine, Giulia and Lastrico, Linda and Rea, Francesco and Casadio, Maura and Sciutti, Alessandra},
  doi          = {10.3389/frobt.2025.1563923},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1563923},
  shortjournal = {Front. Robot. AI},
  title        = {Who will you imitate? studying reciprocal influence in children-robot groups during an imitation game},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of angulation and distance deviation for robot-guided laser osteotomy – A follow-up study on digital high-tech procedures. <em>FROBT</em>, <em>12</em>, 1559483. (<a href='https://doi.org/10.3389/frobt.2025.1559483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Msallem, Bilal and Veronesi, Lara and Halbeisen, Florian Samuel and Beyer, Michel and Dragu, Adrian and Thieringer, Florian Markus},
  doi          = {10.3389/frobt.2025.1559483},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1559483},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of angulation and distance deviation for robot-guided laser osteotomy – A follow-up study on digital high-tech procedures},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficiency in ROS communication: A comparison across programming languages and workloads. <em>FROBT</em>, <em>12</em>, 1548250. (<a href='https://doi.org/10.3389/frobt.2025.1548250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Albonico, Michel and Cannizza, Manuela Bechara and Wortmann, Andreas},
  doi          = {10.3389/frobt.2025.1548250},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1548250},
  shortjournal = {Front. Robot. AI},
  title        = {Energy efficiency in ROS communication: A comparison across programming languages and workloads},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TED-culture: Culturally inclusive co-speech gesture generation for embodied social agents. <em>FROBT</em>, <em>12</em>, 1546765. (<a href='https://doi.org/10.3389/frobt.2025.1546765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Shen, Yixin and Johal, Wafa},
  doi          = {10.3389/frobt.2025.1546765},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1546765},
  shortjournal = {Front. Robot. AI},
  title        = {TED-culture: Culturally inclusive co-speech gesture generation for embodied social agents},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic support for older adults with cognitive and mobility impairments. <em>FROBT</em>, <em>12</em>, 1545733. (<a href='https://doi.org/10.3389/frobt.2025.1545733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Olatunji, Samuel A. and Shim, James S. and Syed, Adam and Tsai, Yao-Lin and Pereira, April E. and Mahajan, Harshal P. and Mudar, Raksha A. and Rogers, Wendy A.},
  doi          = {10.3389/frobt.2025.1545733},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1545733},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic support for older adults with cognitive and mobility impairments},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seamless multi-skill learning: Learning and transitioning non-similar skills in quadruped robots with limited data. <em>FROBT</em>, <em>12</em>, 1542692. (<a href='https://doi.org/10.3389/frobt.2025.1542692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tu, Jiaxin and Zhai, Peng and Zhang, Yueqi and Wei, Xiaoyi and Dong, Zhiyan and Zhang, Lihua},
  doi          = {10.3389/frobt.2025.1542692},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1542692},
  shortjournal = {Front. Robot. AI},
  title        = {Seamless multi-skill learning: Learning and transitioning non-similar skills in quadruped robots with limited data},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a neural efficiency metric to assess human-exoskeleton adaptations. <em>FROBT</em>, <em>12</em>, 1541963. (<a href='https://doi.org/10.3389/frobt.2025.1541963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mehta, Ranjana K. and Zhu, Yibo and Weston, Eric B. and Marras, William S.},
  doi          = {10.3389/frobt.2025.1541963},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1541963},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a neural efficiency metric to assess human-exoskeleton adaptations},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How the presence of others shapes the user experience of service robots. <em>FROBT</em>, <em>12</em>, 1538711. (<a href='https://doi.org/10.3389/frobt.2025.1538711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tretter, Stefan and von Terzi, Pia and Diefenbach, Sarah},
  doi          = {10.3389/frobt.2025.1538711},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1538711},
  shortjournal = {Front. Robot. AI},
  title        = {How the presence of others shapes the user experience of service robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Making social robots adaptable and to some extent educable by a marketplace for the selection and adjustment of different interaction characters living inside a single robot. <em>FROBT</em>, <em>12</em>, 1534346. (<a href='https://doi.org/10.3389/frobt.2025.1534346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Reitelshöfer, Sebastian and Merz, Nina and Garcia, Gabriela and Wei, Yuqiang and Franke, Jörg},
  doi          = {10.3389/frobt.2025.1534346},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1534346},
  shortjournal = {Front. Robot. AI},
  title        = {Making social robots adaptable and to some extent educable by a marketplace for the selection and adjustment of different interaction characters living inside a single robot},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factors influencing subjective opinion attribution to conversational robots. <em>FROBT</em>, <em>12</em>, 1521169. (<a href='https://doi.org/10.3389/frobt.2025.1521169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sakamoto, Yuki and Uchida, Takahisa and Ban, Midori and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2025.1521169},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1521169},
  shortjournal = {Front. Robot. AI},
  title        = {Factors influencing subjective opinion attribution to conversational robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The anthro-thumb: A biomimetic hybrid soft robotic carpometacarpal saddle joint for the thumb. <em>FROBT</em>, <em>12</em>, 1496073. (<a href='https://doi.org/10.3389/frobt.2025.1496073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Symes, Declan and Rose, Michael and Nunez Sardinha, Emanuel David and Jafari, Aghil and Hussain, Javeed and Etoundi, Appolinaire},
  doi          = {10.3389/frobt.2025.1496073},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1496073},
  shortjournal = {Front. Robot. AI},
  title        = {The anthro-thumb: A biomimetic hybrid soft robotic carpometacarpal saddle joint for the thumb},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monitoring pilots’ mental workload in real flight conditions using multinomial logistic regression with a ridge estimator. <em>FROBT</em>, <em>12</em>, 1441801. (<a href='https://doi.org/10.3389/frobt.2025.1441801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Haseeb, Muhammad and Nadeem, Rashid and Sultana, Nazia and Naseer, Noman and Nazeer, Hammad and Dehais, Frédéric},
  doi          = {10.3389/frobt.2025.1441801},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1441801},
  shortjournal = {Front. Robot. AI},
  title        = {Monitoring pilots’ mental workload in real flight conditions using multinomial logistic regression with a ridge estimator},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An open-source reproducible chess robot for human-robot interaction research. <em>FROBT</em>, <em>12</em>, 1436674. (<a href='https://doi.org/10.3389/frobt.2025.1436674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zhang, Renchi and de Winter, Joost and Dodou, Dimitra and Seyffert, Harleigh and Eisma, Yke Bauke},
  doi          = {10.3389/frobt.2025.1436674},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1436674},
  shortjournal = {Front. Robot. AI},
  title        = {An open-source reproducible chess robot for human-robot interaction research},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation of the conditions for continuous information conveyance by two autonomous conversational agents. <em>FROBT</em>, <em>12</em>, 1417488. (<a href='https://doi.org/10.3389/frobt.2025.1417488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Isowa, Takamichi and Ogawa, Kohei and Sato, Satoshi and Kubota, Tomonori and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2025.1417488},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1417488},
  shortjournal = {Front. Robot. AI},
  title        = {Investigation of the conditions for continuous information conveyance by two autonomous conversational agents},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effects of gentle and rude vitality forms in social robots on humans during cognitive multitasking. <em>FROBT</em>, <em>12</em>, 1305685. (<a href='https://doi.org/10.3389/frobt.2025.1305685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Aoki, Motonobu and Rea, Francesco and Di Cesare, Giuseppe and Sandini, Giulio and Yanagi, Takura and Takamatsu, Atsushi and Yamamura, Tomohiro},
  doi          = {10.3389/frobt.2025.1305685},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1305685},
  shortjournal = {Front. Robot. AI},
  title        = {Effects of gentle and rude vitality forms in social robots on humans during cognitive multitasking},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Failures and repairs in human-robot communication. <em>FROBT</em>, <em>12</em>, 1583911. (<a href='https://doi.org/10.3389/frobt.2025.1583911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research topic arose on the back of the WTF workshop series (Förster et al., 2022(Förster et al., 2023a) ) that brought 2 together an interdisciplinary group of researchers ranging from roboticists and computational linguists to 3 conversation analysts and cognitive scientists to openly and frankly discuss failures of (robotic) speech 4 interfaces they experienced when deploying these in their studies. Some of the issues discussed in the 5 workshops are elaborated in the contributed articles below, more pointers can be found in the workshop 6 summary article by Förster et al. (2023b).This research topic contributes towards two main objectives: Firstly, we provide a platform for reporting 8 commonly occurring communicative failures in human-robot interaction (HRI). Secondly, this topic aims Galbraith (2024) investigate how virtual assistants deal with the interactionally highly relevant and 28 frequent 'huh?', an other-initiated, and likely universal repair marker (cf. Dingemanse et al., 2015). They further investigate what repair strategies these assistants utilise when encountering unintelligible speech, 30 and how native speakers judge these different repair strategies. In their study, two different virtual assistants, 31 Google Assistant and Apple's Siri, are compared across two different languages (English and Spanish).Galbraith finds that neither assistant actively produces 'huh?' but rather employs more specific repair 33 strategies when confronted with unintelligible speech. The assistants frequently have trouble dealing with a 34 'huh?' produced by human users, and some of the repair strategies employed by the two assistants were 35 rated negatively by human judges. While these insights were gained by interacting with virtual assistants, 36 we expect some of these to apply to SDS more generally (cf. Lopez et al., 2022).},
  archive      = {J_FROBT},
  author       = {Förster, Frank and Holthaus, Patrick},
  doi          = {10.3389/frobt.2025.1583911},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1583911},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Failures and repairs in human-robot communication},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Smart endorobots for endoluminal procedures: Design, ethics and future trends. <em>FROBT</em>, <em>12</em>, 1581829. (<a href='https://doi.org/10.3389/frobt.2025.1581829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of smart endorobots is transforming the field of minimally invasive procedures by introducing novel solutions for diagnosis and treatment within the human body. These advanced robotic systems enable enhanced manoeuvrability, improved precision, and greater patient safety. Clinicians are increasingly supported by endorobots to perform diagnosis and treatment of difficult-toreach organs through small incisions or natural orifices. New technologies have provided a tool to improve the design of such devices (e.g., reducing size, improving dexterity, and reducing stress and fatigue, while AI and ML algorithms are providing a tool to support clinical judgment (Manfredi, 2021(Manfredi, 2022)). This new generation of endorobots is not only capable of mimicking users' movements but also performing tasks at different levels of autonomy. Their design requires a multidisciplinary team that involves experts in various research areas, including actuators, sensors, control, mechanics, Artificial Intelligence (AI) & Machine Learning (ML), and imaging. The increased level of autonomy introduces ethical concerns regarding responsibility, regulatory compliance, and ensuring safety while avoiding limitations on technological advancements.The design of endorobots for endoluminal applications requires a multidisciplinary approach covering different research aspects. The goal of this research topic was to gather contributions from various disciplines into one collection, offering readers a comprehensive overview of the field.This research topic includes a collection of articles and reviews that can be summarized into three main themes: i)},
  archive      = {J_FROBT},
  author       = {Manfredi, Luigi and Sánchez-Margallo, Juan A. and Wurdemann, Helge Arne and Melzer, Andreas},
  doi          = {10.3389/frobt.2025.1581829},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1581829},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Smart endorobots for endoluminal procedures: Design, ethics and future trends},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutualisms as a framework for multi-robot collaboration. <em>FROBT</em>, <em>12</em>, 1566452. (<a href='https://doi.org/10.3389/frobt.2025.1566452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nguyen, Alexander A. and Rodriguez Curras, Mauriel and Egerstedt, Magnus and Pauli, Jonathan N.},
  doi          = {10.3389/frobt.2025.1566452},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1566452},
  shortjournal = {Front. Robot. AI},
  title        = {Mutualisms as a framework for multi-robot collaboration},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ethical considerations in the use of social robots for supporting mental health and wellbeing in older adults in long-term care. <em>FROBT</em>, <em>12</em>, 1560214. (<a href='https://doi.org/10.3389/frobt.2025.1560214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hung, Lillian and Zhao, Yong and Alfares, Hadil and Shafiekhani, Parsa},
  doi          = {10.3389/frobt.2025.1560214},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1560214},
  shortjournal = {Front. Robot. AI},
  title        = {Ethical considerations in the use of social robots for supporting mental health and wellbeing in older adults in long-term care},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and evaluation of new user control devices for improved ergonomics in flexible robotic endoscopy. <em>FROBT</em>, <em>12</em>, 1559574. (<a href='https://doi.org/10.3389/frobt.2025.1559574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Heisterberg, Leander and Manfredi, Luigi and Wichmann, Dörte and Maier, Thomas and Pott, Peter P.},
  doi          = {10.3389/frobt.2025.1559574},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1559574},
  shortjournal = {Front. Robot. AI},
  title        = {Design and evaluation of new user control devices for improved ergonomics in flexible robotic endoscopy},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ultrasound visual servoing dual-arm robotics system for needle placement in brachytherapy treatment. <em>FROBT</em>, <em>12</em>, 1558182. (<a href='https://doi.org/10.3389/frobt.2025.1558182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Li, Yanlei and Lu, Zhenyu and Tzemanaki, Antonia and Bahl, Amit and Persad, Raj and Melhuish, Chris and Yang, Chenguang},
  doi          = {10.3389/frobt.2025.1558182},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1558182},
  shortjournal = {Front. Robot. AI},
  title        = {An ultrasound visual servoing dual-arm robotics system for needle placement in brachytherapy treatment},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intuitive BIM-aided robotic navigation and assets localization with semantic user interfaces. <em>FROBT</em>, <em>12</em>, 1548684. (<a href='https://doi.org/10.3389/frobt.2025.1548684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Braga, Rafael Gomes and Tahir, Muhammad Owais and Karimi, Sina and Dah-Achinanon, Ulrich and Iordanova, Ivanka and St-Onge, David},
  doi          = {10.3389/frobt.2025.1548684},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1548684},
  shortjournal = {Front. Robot. AI},
  title        = {Intuitive BIM-aided robotic navigation and assets localization with semantic user interfaces},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A field study to explore user experiences with socially assistive robots for older adults: Emphasizing the need for more interactivity and personalisation. <em>FROBT</em>, <em>12</em>, 1537272. (<a href='https://doi.org/10.3389/frobt.2025.1537272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hofstede, Bob M. and Askari, Sima Ipakchian and Lukkien, Dirk and Gosetto, La├½titia and Alberts, Janna W. and Tesfay, Ephrem and Stal, Minke ter and van Hoesel, Tom and Cuijpers, Raymond H. and Vastenburg, Martijn H. and Bevilacqua, Roberta and Amabili, Giulio and Margaritini, Arianna and Benadduci, Marco and Guebey, Julie and Trabelsi, Mohamed Amine and Ciuffreda, Ilaria and Casaccia, Sara and IJsselsteijn, Wijnand and Revel, Gian Marco and Nap, Henk Herman},
  doi          = {10.3389/frobt.2025.1537272},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1537272},
  shortjournal = {Front. Robot. AI},
  title        = {A field study to explore user experiences with socially assistive robots for older adults: Emphasizing the need for more interactivity and personalisation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A projection-based approach for clarifying interaction partners in human-robot communication. <em>FROBT</em>, <em>12</em>, 1534060. (<a href='https://doi.org/10.3389/frobt.2025.1534060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sone, Suguru and Kishi, Tsubasa and Ikeda, Tetsushi},
  doi          = {10.3389/frobt.2025.1534060},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1534060},
  shortjournal = {Front. Robot. AI},
  title        = {A projection-based approach for clarifying interaction partners in human-robot communication},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliding-mode control based on prescribed performance function and its application to a SEA-based lower limb exoskeleton. <em>FROBT</em>, <em>12</em>, 1534040. (<a href='https://doi.org/10.3389/frobt.2025.1534040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zhang, Feilong and Wang, Tian and Zhang, Liang and Shi, Enming and Wang, Chengchao and Li, Ning and Lu, Yu and Zhang, Bi},
  doi          = {10.3389/frobt.2025.1534040},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1534040},
  shortjournal = {Front. Robot. AI},
  title        = {Sliding-mode control based on prescribed performance function and its application to a SEA-based lower limb exoskeleton},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A child-robot theater afterschool program can promote children’s conceptualization of social robots’ mental capacities and engagement in learning. <em>FROBT</em>, <em>12</em>, 1529421. (<a href='https://doi.org/10.3389/frobt.2025.1529421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dong, Jiayuan and Yu, Shuqi and Choi, Koeun and Jeon, Myounghoon},
  doi          = {10.3389/frobt.2025.1529421},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1529421},
  shortjournal = {Front. Robot. AI},
  title        = {A child-robot theater afterschool program can promote children’s conceptualization of social robots’ mental capacities and engagement in learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stiffness evaluation of continuum robots based on the energy method and castigliano’s second theorem. <em>FROBT</em>, <em>12</em>, 1523619. (<a href='https://doi.org/10.3389/frobt.2025.1523619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Yang, Mengxue and An, Zhicheng and Lin, Zechen and Wang, Yuhang and Pang, Tongtao and Du, Fuxin},
  doi          = {10.3389/frobt.2025.1523619},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1523619},
  shortjournal = {Front. Robot. AI},
  title        = {Stiffness evaluation of continuum robots based on the energy method and castigliano’s second theorem},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible transoral swab sampling robot system with visual-tactile fusion approach. <em>FROBT</em>, <em>12</em>, 1520374. (<a href='https://doi.org/10.3389/frobt.2025.1520374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dong, Jiaxiang and Li, Peng and Liu, Quanquan and Liu, Qi and Wang, Chunbao and Zhao, Xuezhi and Hu, Xiping},
  doi          = {10.3389/frobt.2025.1520374},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1520374},
  shortjournal = {Front. Robot. AI},
  title        = {A flexible transoral swab sampling robot system with visual-tactile fusion approach},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-centered design and early evaluation of an interface for mobile-manipulator-mediated pediatric occupational therapy. <em>FROBT</em>, <em>12</em>, 1520216. (<a href='https://doi.org/10.3389/frobt.2025.1520216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Morales Mayoral, Rafael and Logan, Samuel W. and Fitter, Naomi T.},
  doi          = {10.3389/frobt.2025.1520216},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1520216},
  shortjournal = {Front. Robot. AI},
  title        = {Human-centered design and early evaluation of an interface for mobile-manipulator-mediated pediatric occupational therapy},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of model compression techniques: Past, present, and future. <em>FROBT</em>, <em>12</em>, 1518965. (<a href='https://doi.org/10.3389/frobt.2025.1518965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Liu, Defu and Zhu, Yixiao and Liu, Zhe and Liu, Yi and Han, Changlin and Tian, Jinkai and Li, Ruihao and Yi, Wei},
  doi          = {10.3389/frobt.2025.1518965},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1518965},
  shortjournal = {Front. Robot. AI},
  title        = {A survey of model compression techniques: Past, present, and future},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human preferences for cognitive and emotional capabilities in robots across different application domains. <em>FROBT</em>, <em>12</em>, 1511549. (<a href='https://doi.org/10.3389/frobt.2025.1511549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nääs, Hilda and Thellman, Sam and Ziemke, Tom},
  doi          = {10.3389/frobt.2025.1511549},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1511549},
  shortjournal = {Front. Robot. AI},
  title        = {Human preferences for cognitive and emotional capabilities in robots across different application domains},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based dynamic field exploration and reconstruction using multi-robot systems for environmental monitoring. <em>FROBT</em>, <em>12</em>, 1492526. (<a href='https://doi.org/10.3389/frobt.2025.1492526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lu, Thinh and Sobti, Divyam and Talwar, Deepak and Wu, Wencen},
  doi          = {10.3389/frobt.2025.1492526},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1492526},
  shortjournal = {Front. Robot. AI},
  title        = {Reinforcement learning-based dynamic field exploration and reconstruction using multi-robot systems for environmental monitoring},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trauma-informed care approach in developing companion robots: A preliminary observational study. <em>FROBT</em>, <em>12</em>, 1476063. (<a href='https://doi.org/10.3389/frobt.2025.1476063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mazuz, Keren and Yamazaki, Ryuji},
  doi          = {10.3389/frobt.2025.1476063},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1476063},
  shortjournal = {Front. Robot. AI},
  title        = {Trauma-informed care approach in developing companion robots: A preliminary observational study},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of human-collaborative robots to perform daily tasks based on multimodal vital information with cybernics space. <em>FROBT</em>, <em>12</em>, 1462243. (<a href='https://doi.org/10.3389/frobt.2025.1462243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Uehara, Akira and Kawamoto, Hiroaki and Sankai, Yoshiyuki},
  doi          = {10.3389/frobt.2025.1462243},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1462243},
  shortjournal = {Front. Robot. AI},
  title        = {Development of human-collaborative robots to perform daily tasks based on multimodal vital information with cybernics space},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operators and their human–robot interdependencies: Implications of distinct job decision latitudes for sustainable work and high performance. <em>FROBT</em>, <em>12</em>, 1442319. (<a href='https://doi.org/10.3389/frobt.2025.1442319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wolffgramm, Milan R. and Corporaal, Stephan and Groen, Aard J.},
  doi          = {10.3389/frobt.2025.1442319},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1442319},
  shortjournal = {Front. Robot. AI},
  title        = {Operators and their human–robot interdependencies: Implications of distinct job decision latitudes for sustainable work and high performance},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: AI-powered musical and entertainment robotics. <em>FROBT</em>, <em>12</em>, 1572828. (<a href='https://doi.org/10.3389/frobt.2025.1572828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of robotics and artificial intelligence (AI) is revolutionizing the field of music and entertainment. Robots are evolving from performing traditional service-oriented tasks to enabling advanced human-robot interaction (HRI) with potential emotional engagement. The pursuit of robotic expressiveness presents new challenges and opportunities in the modeling, design and control of musical and entertainment robots. Current studies mainly work on the design and physical implementation of robots capable of manipulating various musical instruments \cite{wang2022data,lim2012towards}, while the development of socially intelligent robots for real-time HRI remains underexplored. With advancements in AI, robots can now compose and improvise, as well as interpret and respond to human affective states during HRI \cite{mccoll2016survey, wang2024human}.This research topic was initiated to present the latest developments of AI-powered musical and entertainment robots. As a result of the call, six papers have been accepted and collected in this research topic. These articles provide a comprehensive exploration of diverse artistic forms including singing, dancing and musical performance on instruments such as the piano, violin, guitar, drum and marimba. Figure \ref{fig:overview} shows an overview of the musical robots investigated in these studies.Among the contributed works, two articles focused on dexterous manipulation and sensorimotor coordination. \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1463744/full}{Gilday et al.} introduced a general-purpose system featuring a parametric hand capable of playing both the piano and performing guitar pick strumming. Unlike existing bespoke robotic musical systems, the proposed hand was designed as a single-piece 3D-printed structure, demonstrating potential for enhanced expressiveness in entertainment applications through the modulation of mechanical properties and actuation modes. The study highlighted that leveraging system-environment interactions enabled diverse, multi-instrument functionalities and variable playing styles with simplified control. Instead of musical instrument playing, \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1450177/full}{Twomey et al.} investigated dance performance using wearable soft sensors on the arm to explore whether such devices could enhance artistic expression. Dance movements were modeled as colliders within virtual mass-spring-damper systems, and limb segments were analyzed in local frames to avoid drift issues commonly associated with IMUs. The authors proposed a parallel algorithm to detect improvisational dance movements and control soft wearable actuators which can change size and lighting in response to detected motions. This work exemplified sensorimotor coordination and demonstrated how traditional dance and aesthetics could be enriched by spontaneous wearable-driven movements.Robot learning and control represent one of the biggest challenges in musical and entertainment robotics, particularly for acquiring manipulation skills and robotic expressiveness. \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1439629/full}{Horigome and Shibuya} developed a RL-based controller for a violin-playing robot, a 7-DoF dual-arm system actuated by DC motors. The system mimics human performance with the left arm handling fingering and the right arm controlling bowing movements. The right arm regulates multiple parameters including bowing speed, pressure, sounding point and direction. Analysis of the target sound pressure demonstrated that the robot successfully learned violin-playing techniques and enables expressive performance variations. The robot was automated to play the violin based on musical scores, demonstrating its ability to interpret and execute complex musical tasks. Similarly, \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1450097/full}{Karbasi et al.} explored robotic drumming using a two-DoF robotic arm with flexible grippers, which is referred to as ZRob. They employed an RL-based algorithm with a Deep Deterministic Policy Gradient (DDPG) architecture, incorporating both extrinsic and intrinsic reward signals. The results showed that intrinsic rewards triggered the emergence of novel rhythmic patterns. Additionally, the robot's physical dynamics—embodied intelligence—were found to influence the learning algorithm due to the physical constraints of the drumming setup. This study highlights the interplay between robotic hardware and learning algorithms in achieving expressive musical performance. It can be seen that reinforcement learning continues to be a powerful and widely utilized approach for enabling robots to acquire complex manipulation and expressive skills. The aforementioned studies have investigated both hardware and software advancements. However, the interaction between these robots and humans has not been explored. \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1461615/full}{Gao et al.} investigated synchronization between human musicians and Shimon, a robotic marimba player capable of head and arm movements. Their study revealed that ancillary and social gestures, particularly head movements, significantly enhance temporal synchronization between humans and robots. Through experiments with human participants, the results demonstrated positive social engagement when collaborating with robots in artistic performances. The study also found that social head gestures improved synchronicity slightly more than ancillary or instrumental gestures, providing quantitative insights into the role of non-verbal cues in HRI. Similarly, \href{https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2024.1463477/full}{Nishiyama and Nonaka} investigated the concept of "togetherness" in a singing scenario, where human participants coordinated their voices with either another human or a machine (Vocaloid) under non-visual conditions. The study highlighted that human-to-human cooperation achieved higher similarity and anticipatory synchronization compared to human-machine interaction. These findings highlight the critical role of embodiment in enabling natural and effective collaboration, demonstrating how physical presence and human-like traits shape interaction dynamics.In conclusion, reinforcement learning holds strong potential in tackling the key challenges of equipping musical robots with advanced skills. Current AI-driven robotic systems have demonstrated the feasibility of achieving robotic expressiveness in various musical instruments. However, human-robot interaction presents a more complex research topic that requires interdisciplinary collaboration across fields such as robotics, materials science, computer science, psychology, musicology, sociology and ethics.},
  archive      = {J_FROBT},
  author       = {Wang, Huijiang and Hughes, Josie and Nonaka, Tetsushi and Abdulali, Arsen and Lalitharatne, Thilina Dulantha and Iida, Fumiya},
  doi          = {10.3389/frobt.2025.1572828},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1572828},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: AI-powered musical and entertainment robotics},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Human factors and cognitive ergonomics in advanced industrial human-robot interaction. <em>FROBT</em>, <em>12</em>, 1564948. (<a href='https://doi.org/10.3389/frobt.2025.1564948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robotics is a very promising technology for many industrial processes, including e.g., manufacturing, logistics, or construction. This new technology are also changing the environment for workers in industry. Research on human-robot interaction (HRI) will be crucial for enhancing the operator's work conditions and well-being, as well as production performance. In that regard, human factors, with a special emphasis on cognitive ergonomics are fundamental to implementing safe, fluent, and efficient collaborative applications. This Research Topic gathers a range of contributions on the study of Human Factors and Cognitive ergonomics in user-centered and collaborative applications in industrial settings. Here, we summarize these studies from the perspective of three pivotal areas impacted by collaborative robotics: workers' safety, performance, and well-being. The Reseach Topic provides a timely analysis of the changing landscape of industrial HRI as we stand on the cusp of a new era in industrial automation, defined by the fusion of human ingenuity and robotic efficiency. The contributions within offer practical insights and forwardthinking perspectives on how collaborative robotics can transform industrial workspaces in the future, in addition to reflecting state-of-the-art research in the field. A different aspect of this intricate relationship is covered by each article in this issue, from the social and psychological effects of incorporating robots into human-centered work environments to the complexities of design and implementation. Developing solutions that are both technologically sophisticated and human-centered requires a holistic approach, which is crucial for comprehending the complex nature of HRI.Before delving into the particulars of each contribution, we invite the reader to this brief summary, briefly presenting each contribution to the research topic through the lenses of safety, performance, and well-being.We hope that this will support reflections on the wider societal implications of HRC development, in addition to their technical and ergonomic aspects. A harmonious balance between human needs and machine capabilities will be key to the future of industry.In the field of Human Factors and Cognitive Ergonomics, introducing advanced collaborative robotic systems in production environments necessitates reevaluating safety from different perspectives, namely safety perceptions of workers, safety behaviours and mechanical safety. Integrating this technology in various industrial environments, such as manufacturing and logistics, prompts a critical examination of the interplay of the different elements interacting in the socio-technical system. As with any human-system interaction in the work context, a more ergonomic and anthropocentric system (characteristics that can be measured through optimisation of associated cognitive factors) implies greater safety in terms of prevention and mitigation of potential mechanical risk (understood as collisions, crushing, entrapment, etc.) and psychosocial risk as defined by Occupational Safety and Health Administration (OSHA) such as excessive workload, lack of control, job insecurity or insufficient communication .The present special issue includes diverse studies, each exploring different aspects of safety in human-robot collaboration.The contribution by Mirnig et al. (2023) constitutes an excellent opening to the special issue. While focusing on automated material handling vehicles, Mirnig et al. discuss many design aspects that are applicable also to HRI more broadly, including contextual factors such as purpose and context of use, and many aspects of the interaction itself. The study by Onnasch et al. (2023) investigates how directing a worker's attention to specific targets with gaze communication can improve safety in humanrobot interaction by, first of all, suggesting how robotic eye design could affect operator attention and perceived cognitive workload. Furthermore, the paper indirectly suggests how robotic eyes could potentially prevent mechanical risks like collisions and entrapments. According to research, an operator's situational awareness and capacity to anticipate and respond to possible hazards are enhanced when they focus on anthropomorphic robot eyes. This study highlights anthropomorphism's contribution to improving operator safety and attention, leading to safer and more conscious HRIs in industrial settings. On the effect of anthropomorphic features in collaborative robots, the paper by Roesler (2023) examines the impact of anthropomorphic versus technical framing of robots on operators' trust, particularly in the context of robot failures. The study concludes that although the general levels of trust between technically framed and anthropomorphically framed robots did not significantly differ, people perceived the anthropomorphically framed robots as being more transparent, particularly after understandable failures. Because it improves operators' awareness and skill in anticipating and responding to potential mechanical risks like collisions or entrapments, this increased perceived transparency and positive perception in the event of understandable failures by potentially contributing to increased safety in HRIs. In a complementary way, Freire et al. (2024) also addresses the importance of safety in human-robot collaboration, but through a different mechanism.Their proposed cognitive architecture incorporates a "Socially Adaptive Safety Engine," which dynamically adjusts safety parameters like distance and robot speed based on the worker's trust level and preferences. While Roesler's study emphasizes how transparency in robot behavior following failures can enhance safety, Freire et al. go further by actively modifying robot behavior in real-time to adapt to each worker's trust and comfort, creating a more personalized and context-sensitive safety environment. Together, these articles suggest that fostering both transparency and adaptability in robots-through anthropomorphic design and context-aware systems-can significantly enhance operator safety and well-being in industrial environments.In a comprehensive perspective, Heinold et al. (2023) discusses various occupational safety and health (OSH) risks and benefits associated with the integration of robotic systems in industrial settings. These include both physical risks, such as collisions and mechanical failures, and psychosocial risks, including mental stress and job insecurity, which can arise from the use of advanced robotics in workplaces. The study also explores opportunities, such as the potential for reducing physical strain and improving longterm physical health by automating physically demanding tasks. The peculiarity of this manuscript lies in its comprehensive analysis of both physical and psychosocial OSH risks and opportunities, uniquely incorporating workers' expectations alongside evidence from the literature, offering a dual perspective on the safety implications of HRI. On a similar note, also addressing logistics and agricultural domains in addition to the manufacturing one, Pietrantoni et al. (2024) investigated experts' opinions regarding collaborative robotics safety considerations. Their study emphasized the critical role of tailored safety protocols, highlighting the need for advanced collision avoidance systems, failsafe mechanisms, and emergency stop protocols. Key aspects in agriculture include stability control and navigation on uneven ground for the safety and efficiency of workers. This sectoral approach completes the dual perspective taken by Heinold et al. in that it details how diverse industrial working contexts require tailor-made safety solutions to address both physical risks and ergonomic challenges and further promote the safe integration of robotics into complex work environments.The impact of human autonomy and robot work pace on job quality in collaborative settings is examined by Van Dijk et al. (2023). They find that higher human autonomy levels correlate with lower perceived workloads. The present article generally addresses some of the main working conditions leading to psychosocial risks according to OSHA, namely excessive workloads, lack of involvement in making decisions that affect the worker, and lack of influence over the way the job is done. This study shows that increasing human autonomy and modifying robot work pace can effectively reduce cognitive and temporal demands on workers. It compares scenarios of human-led work, fast-paced robot-led work, and slow-paced robot-led work. According to these results, reducing workload is linked to a lower mechanical risk because there is a lower probability of mistakes in HRI. This suggests that such measures optimise perceived workload and improve safety in collaborative scenarios.In the context of an industrial defect inspection task, the article of Cymek et al. (2023) examines the phenomenon of decreased individual effort and attention in human-robot collaborative tasks. The study finds that individuals searching for defects with a robot partner may have been less focused and exerted more mental energy than those searching alone, who on average, found more defects. Because less alert workers may be more likely to overlook safety hazards in their environment. This lower level of attentiveness and operational performance in human-robot teams affects productivity and may increase exposure to mechanical risks.workload. The article's relevance is critical, considering that collaborative robotics is one of the most promising technology for retaining the ageing workforce and maintaining an appropriate quality of work. It finds that senior workers have a strong acceptance of technology and positive experiences during increased cognitive demand. As a result of increased mental demand during dual-task collaboration, the study found that task errors and duration increased despite these favourable perceptions. This might have detrimental effects on safety behaviours. While senior workers are generally open to working with robots, this increased cognitive workload-as indicated by eye tracking and cardiac activity-indicates that overburdening from collaboration may result in overwork and increase the mechanical risks in the workplace.For human-robot interaction to be considered successful, assessing and supporting the performance of the system as a whole is of utmost importance. In fact, one might even say that successful performance of the system is a necessary requisite when arguing for its existence. Successful performance can be defined in many different ways but in essence it is the combination of two things; doing things accurately (effective), and being efficient while doing it. In the context of collaborative human-robot settings, this research topic investigates relations between human-factors and performance in terms of temporal performance and cognitive load (Van Dijk et al., 2023;Pluchino et al., 2023), collaborative setting and error rate (Cymek et al., 2023), as well as collaborative setting and perceived workload (Van Dijk et al., 2023). While all these papers are mentioned above in relation to safety, they also bring relevant results in relation to performance. Van Dijk et al. (2023) show a positive correlation between temporal performance and cognitive load, comparing two conditions with a fast vs slow scheduling for the HRC setup. Pluchino et al. ( 2023) analyze the performance in terms of errors and time on task of senior workers engaged in a sequential collaborative manufacturing task together with a cobot. A dual task condition where the subjects were challenged with a secondary mathematical assignment is compared to a single task (control) condition. Results show that the dual task condition lead to increases in both errors and time spent on task, which corresponded with higher levels of perceived mental effort. However, no differences in perceived performance, as assessed by the NASA-TLX questionnaire, were found between the conditions. Cymek et al. (2023) compares two versions of an inspection task, one collaborative where a human operator is working together with a robot, and one individual where the operator is working alone. Results show lower performance for the collaborative setting in terms of fewer identified defects during inspection, indicating an reduction in cognitive load compared to the individual condition.As previously discussed, the effects on performance of different types of collaborative queues are investigated by Onnasch et al. (2023). An indirect argument is made for faster reallocation of attention as a result of naturalistic attentional queues leading to increased performance. This paper also provides a brief argumentation that some queues used to improve collaboration, e.g., legible motion, may directly impact performance in a negative way, while robot eyes does not.Finally, in their study of technical expert's opinions of HRC also mentioned earlier, Pietrantoni et al. (2024) found that the introduction of collaborative robots is expected to bring improved efficiency and better worker conditions, e.g. as a result of automation of physically demanding operations. While the participants in the study generally held a positive attitude towards collaborative robots, the increased efficiency was also linked to concerns of job displacement and the need for reskilling.A key concern of cognitive ergonomics is to reduce negative effects of work. This also specifically refers to deployed technologies at the workplace, like advanced robotic systems. However, a truly humancentered approach to workplace and technology design aims at developing a person's personality and fostering individual and organizational health in its broadest sense. A holistic understanding of health goes beyond the physical safety of humans, but includes mental and social well-being of humans. In the everevolving landscape of human-robot interaction, the integration of advanced robotics to different workplaces, raises critical questions about how the well-being of individuals might be affected. This research topic includes different publications, each shedding light on different facets of human-robot-interaction and its implications for the human experience thus potentially leading to well-being in the long-term.As mentioned earlier, Heinold et al. (2023) address the question which psycho-social consequences are associated with a close interaction between humans and robots. By combining scientific perspectives through a literature review and insights from workers' expectations, the study provides a holistic view of the implications of task automation via robotic systems. The findings highlight the psycho-social impacts advanced robotics may have on workers. It becomes clear, that the aspects of task design and function allocation as well as the specific interactions design of systems as well as operation and supervision design are relevant sources potentially affecting the specific user experience and the well-being of workers in the long run.When further considering potential psychological effects, assessing traditional workplace factors can be beneficial. From human factors research it is well understood, that the level of job control or autonomy within a given task is a strong determinant for job quality and well-being (Van Der Doef and Maes, 1999). This also applies to industrial tasks (Rosen and Wischniewski, 2019). As working tasks are newly allocated between humans and robots, human autonomy levels can change. The investigation of human autonomy and robotic work pace by Van Dijk et al. (2023) discussed earlier is also relevant from a well-being perspective.The research underscores the significance of autonomy and work pace in shaping job quality, emphasizing the importance of designing collaborative scenarios that prioritize human autonomy and adjustments to the robot's work pace to optimize workload and enhance overall well-being.Exploring psycho-social effects more on a team level in this research topic is done by Cymek and colleagues. Their contribution focuses on the well-studied phenomenon of social loafing (Cymek et al., 2023). Using a visual-search task, the presented study investigates whether reduced individual effort, the phenomenon in question, which is commonly observed in human teams, also occurs in human-robot teams.The findings suggest that working with a robot team partner may lead to less attentive task execution, highlighting the need to address mental effort and attention allocation in human-robot collaboration to ensure optimal performance and, consequently, well-being.A human-centred technology design can contribute to a positive human-robot interaction and thus ensure a seamless workflow. One very relevant aspect of robot design which is touched upon in research is the application of anthropomorphic design features (Roesler et al., 2021). Two papers of this research topic explore the unique effects of anthropomorphic features in human-robot-interaction on different aspect of the distinct interaction quality and user experience. As mentioned earlier, Onnasch et al. (2023) examine how the design of predictive robot eyes influences human attention. The results indicate that anthropomorphic features contribute to a smooth interaction experience. Anthropomorphic robotic eyes trigger reflexive attention reallocation, hinting at a social and automatic processing of artificial stimuli, emphasizing the emotional and cognitive impact of such interactions on well-being. Through their analysis of anthropomorphic framing discussed earlier, Roesler (2023) show that an adequate level of trust within human-robot-interaction is also an important element contributing to a smooth interaction and a humancentered design. In this paper the perceived transparency of anthropomorphic robots emerges as a key factor, underscoring its role in shaping individuals' well-being.A novel design approach in order to facilitate socially adaptive robot behaviour in industrial settings is presented by Freire and colleaguesFreire et al. (2024). The authors present a theoretical cognitive architecture for robotic actions control, highlighting modules that among others take into account human preferences and situational awareness and by thus can adapt to human needs. The presented cognitive architecture is integrated into a recycling plant use case for disassembly tasks showcasing the basic functionalities of the systems. In the piloted use cases, the architecture demonstrated key Frontiers},
  archive      = {J_FROBT},
  author       = {Billing, Erik and Fraboni, Federico and Gualtieri, Luca and Rosen, Patricia Helen and Thorvald, Peter},
  doi          = {10.3389/frobt.2025.1564948},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1564948},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human factors and cognitive ergonomics in advanced industrial human-robot interaction},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised semantic label generation in agricultural fields. <em>FROBT</em>, <em>12</em>, 1548143. (<a href='https://doi.org/10.3389/frobt.2025.1548143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Roggiolani, Gianmarco and Rückin, Julius and Popović, Marija and Behley, Jens and Stachniss, Cyrill},
  doi          = {10.3389/frobt.2025.1548143},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1548143},
  shortjournal = {Front. Robot. AI},
  title        = {Unsupervised semantic label generation in agricultural fields},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On realizing autonomous transport services in multi story buildings with doors and elevators. <em>FROBT</em>, <em>12</em>, 1546894. (<a href='https://doi.org/10.3389/frobt.2025.1546894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schulze, Paul Robert and Müller, Steffen and Müller, Tristan and Gross, Horst-Michael},
  doi          = {10.3389/frobt.2025.1546894},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1546894},
  shortjournal = {Front. Robot. AI},
  title        = {On realizing autonomous transport services in multi story buildings with doors and elevators},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mini-review on mobile manipulators with variable autonomy. <em>FROBT</em>, <em>12</em>, 1540476. (<a href='https://doi.org/10.3389/frobt.2025.1540476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Contreras, Cesar Alan and Rastegarpanah, Alireza and Chiou, Manolis and Stolkin, Rustam},
  doi          = {10.3389/frobt.2025.1540476},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1540476},
  shortjournal = {Front. Robot. AI},
  title        = {A mini-review on mobile manipulators with variable autonomy},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OpenSEA: A 3D printed planetary gear series elastic actuator for a compliant elbow joint exoskeleton. <em>FROBT</em>, <em>12</em>, 1528266. (<a href='https://doi.org/10.3389/frobt.2025.1528266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jenks, Benjamin and Levan, Hailey and Stefanovic, Filip},
  doi          = {10.3389/frobt.2025.1528266},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1528266},
  shortjournal = {Front. Robot. AI},
  title        = {OpenSEA: A 3D printed planetary gear series elastic actuator for a compliant elbow joint exoskeleton},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous robotic ultrasound scanning system: A key to enhancing image analysis reproducibility and observer consistency in ultrasound imaging. <em>FROBT</em>, <em>12</em>, 1527686. (<a href='https://doi.org/10.3389/frobt.2025.1527686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lin, Xin-Xin and Li, Ming-De and Ruan, Si-Min and Ke, Wei-Ping and Zhang, Hao-Ruo and Huang, Hui and Wu, Shao-Hong and Cheng, Mei-Qing and Tong, Wen-Juan and Hu, Hang-Tong and He, Dan-Ni and Lu, Rui-Fang and Lin, Ya-Dan and Kuang, Ming and Lu, Ming-De and Chen, Li-Da and Huang, Qing-Hua and Wang, Wei},
  doi          = {10.3389/frobt.2025.1527686},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1527686},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous robotic ultrasound scanning system: A key to enhancing image analysis reproducibility and observer consistency in ultrasound imaging},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grand challenges for burrowing soft robots. <em>FROBT</em>, <em>12</em>, 1525186. (<a href='https://doi.org/10.3389/frobt.2025.1525186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Le, Caitlin L. and Yirmibesoglu, Osman Dogan and Even, Sean and Buckner, Trevor and Ozkan-Aydin, Yasemin and Kramer-Bottiglio, Rebecca},
  doi          = {10.3389/frobt.2025.1525186},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1525186},
  shortjournal = {Front. Robot. AI},
  title        = {Grand challenges for burrowing soft robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of the role of different levels of exchange of explicit information in human–robot cooperation. <em>FROBT</em>, <em>12</em>, 1511619. (<a href='https://doi.org/10.3389/frobt.2025.1511619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {San Martin, Ane and Kildal, Johan and Lazkano, Elena},
  doi          = {10.3389/frobt.2025.1511619},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1511619},
  shortjournal = {Front. Robot. AI},
  title        = {An analysis of the role of different levels of exchange of explicit information in human–robot cooperation},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive perspective on electric vehicles as evolutionary robots. <em>FROBT</em>, <em>12</em>, 1499215. (<a href='https://doi.org/10.3389/frobt.2025.1499215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Che, Haoyang and Wang, Shaolin and Yao, Lei and Gu, Ying},
  doi          = {10.3389/frobt.2025.1499215},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1499215},
  shortjournal = {Front. Robot. AI},
  title        = {A comprehensive perspective on electric vehicles as evolutionary robots},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial social intelligence in teamwork: How team traits influence human-AI dynamics in complex tasks. <em>FROBT</em>, <em>12</em>, 1487883. (<a href='https://doi.org/10.3389/frobt.2025.1487883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bendell, Rhyse and Williams, Jessica and Fiore, Stephen M. and Jentsch, Florian},
  doi          = {10.3389/frobt.2025.1487883},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1487883},
  shortjournal = {Front. Robot. AI},
  title        = {Artificial social intelligence in teamwork: How team traits influence human-AI dynamics in complex tasks},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CARE: Towards customized assistive robot-based education. <em>FROBT</em>, <em>12</em>, 1474741. (<a href='https://doi.org/10.3389/frobt.2025.1474741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Maaz, Nafisa and Mounsef, Jinane and Maalouf, Noel},
  doi          = {10.3389/frobt.2025.1474741},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1474741},
  shortjournal = {Front. Robot. AI},
  title        = {CARE: Towards customized assistive robot-based education},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From traditional robotic deployments towards assisted robotic deployments in nuclear decommissioning. <em>FROBT</em>, <em>12</em>, 1432845. (<a href='https://doi.org/10.3389/frobt.2025.1432845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lopez Pulgarin, Erwin Jose and Hopper, Dave and Montgomerie, Jon and Kell, James and Carrasco, Joaquin and Herrmann, Guido and Lanzon, Alexander and Lennox, Barry},
  doi          = {10.3389/frobt.2025.1432845},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1432845},
  shortjournal = {Front. Robot. AI},
  title        = {From traditional robotic deployments towards assisted robotic deployments in nuclear decommissioning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The italian version of the unified theory of acceptance and use of technology questionnaire: A pilot validation study. <em>FROBT</em>, <em>12</em>, 1371583. (<a href='https://doi.org/10.3389/frobt.2025.1371583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {D’Iorio, Alfonsina and Garramone, Federica and Rossi, Silvia and Baiano, Chiara and Santangelo, Gabriella},
  doi          = {10.3389/frobt.2025.1371583},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1371583},
  shortjournal = {Front. Robot. AI},
  title        = {The italian version of the unified theory of acceptance and use of technology questionnaire: A pilot validation study},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Haptic training simulation, volume III. <em>FROBT</em>, <em>12</em>, 1550392. (<a href='https://doi.org/10.3389/frobt.2025.1550392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual Users. Another way to make use of haptic devices for enhancing hands-on training is illustrated in Zhang et al. In this study, the haptic devices are not used to interact with the objects in a virtual world as in González-Mena and Neri et al., but to reproduce the expert gestures on the hands of the trainees. More precisely, the surgical tools handled by the expert are connected to individual haptic devices, each one recording in real time its connected tool trajectory. These trajectories are sent to the trainees' devices, which, in turn, guide the tools of the trainees. Thus, trainees can follow in their hands the expert tool trajectories, instead of only watching them and reproducing them on their own as usual. This experimental study suggests that haptic feedback superimposed on the trainee's motions can facilitate the performance of novice operators experiencing moments of difficulty, which was something that was already observed in other works (see the discussion of Zhang et al. for references). Even if the small sample size and use of a simple task limit the generalizability of their findings, this study illustrates that haptic training can be realized without any 3D virtual world, which requires accurate modeling for realistic haptic rendering of a complex task. Tactile Feedback. In Ratschat et al., the authors designed a shape exploration experiment to evaluate the effectiveness of multimodal tactile and kinesthetic feedback on shape perception. Sixteen participants were involved to reproduce different two-dimensional shapes with diverse characteristics in free space after exploring the shapes with two haptic feedback conditions: 1) kinesthetic feedback only and 2) kinesthetic plus tactile feedback. The kinesthetic feedback mechanism was implemented through an adapted single-degree-of-freedom SenseGlove Nova mechanism with an integrated electromagnetic brake. And tactile feedback was provided with a cable-driven platform mounted on the fingertip. To measure the participants' ability to perceive and reproduce the rendered shapes, the authors recorded the time participants spent exploring and reproducing the shapes and the error between the rendered and reproduced shapes after exploration and assessed the workload and motivation with questionnaires. Experimental results show that in a virtual shape exploration task without visual feedback, providing tactile and kinesthetic feedback is associated with more accurate and careful shape reproduction compared to exploring shapes with only kinesthetic feedback. Besides, the addition of tactile feedback does not seem to reduce the time spent during exploration, nor does it have an effect on motivation or workload. Thus, combining haptic and kinesthetic feedback could create more realistic virtual environments that may lead to better training results and easier transfer to real-world tasks, having implications across a variety of applications and training scenarios.Vibrotactile. Similarly, in Boutin et al . , the authors combined haptic (vibrotactile) feedback through the use of a haptic glove with a VR simulator for mixed-reality surgical training. They specifically focused on the potential for enhanced sensory feedback within VR. The authors chose to investigate External Ventricular Drain Placement (EVD), a common neurosurgery procedure, as a starting point. Experimental results demonstrated the simulator's accuracy, even though one major limitation was a lack of kinesthetic feedback. Like Ratschat et al., this work shows the potential to create more realistic mixed-reality environments that could extend beyond surgical applications.Kinesthetic. Force feedback plays a vital role in developing surgical skills, yet many virtual reality simulators lack this feature, creating a significant disparity between physical trainers and their digital counterparts, potentially limiting their effectiveness. In Abinaya and Manivannan, the authors take a different approach and use haptic feedback as an assessment metric for surgical training, focussing on laparoscopic surgery using a virtual reality simulator. By incorporating haptic feedback, they replicate the forces between the tool and the tissue, which directly correlate to tissue trauma. A virtual laparoscopic force model is incorporated into the simulator and used to determine the just noticeable differences of the laparoscopic grasping force. The results suggest that a simple linear model is sufficient for gripper force feedback, and a non-linear model does not affect the force perception. Expert laparoscopic surgeons agree that haptic feedback improves learning performance, and the force model improves the accuracy of object interaction during the gripping task.Innovative approaches to enhance surgical training must foster motor and sensory skills while reducing cognitive burden, lowering costs, and being conducive to faster design processes. This collection, the third on the topic of Haptic Training Simulation, underscores the potential of hapticenabled virtual reality tools in shaping the future of surgical education and improving patient outcomes.},
  archive      = {J_FROBT},
  author       = {Rossa, Carlos and Chen, Xiaojun and McDaniel, Troy and Leleve, Arnaud},
  doi          = {10.3389/frobt.2025.1550392},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1550392},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Haptic training simulation, volume III},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Latest trends in bio-inspired medical robotics: Structural design, manufacturing, sensing, actuation and control. <em>FROBT</em>, <em>12</em>, 1544097. (<a href='https://doi.org/10.3389/frobt.2025.1544097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {1 INTRODUCTIONOver the past few decades, robotic technologies have been widely introduced into different medical applications, such as surgical operation and rehabilitation engineering, to improve the efficiency and quality of medical treatment. However, those robots usually need to interact with humans and manipulate their complex structure and internal organs via small openings, which presents a big challenge for the current sensing, actuation and control strategies (Muscolo and Fiorini, 2023; Sun and Lueth, 2023b). To solve these problems, many researchers have introduced biologically inspired techniques into medical robots. For example, snake-like soft robots are used to achieve flexible in minimally invasive surgery (Burgner-Kahrs et al., 2015; Lin et al., 2024; Cianchetti et al., 2018; Ashuri et al., 2020; Sun et al., 2020; Sun and Lueth, 2023a), while insect-inspired exoskeleton robots can provide walking assistance to patients with disabilities (Shi et al., 2019; Yang et al., 2023; Liao et al., 2023).In this Research Topic, we aim to present the latest developments and achievements of bio-inspired technologies for supporting the future research directions within the field of medical robotics, including structural design, modeling, manufacturing, sensing, actuation and control. As a result of the call for participation, seven papers were finally accepted and collected in this Research Topic.2 OVERVIEW OF THE CONTENTS OF THE RESEARCH TOPICThe first two articles are focusing on the structural design of robotic systems for medical robots. In the paper ”A compact motorized end-effector for ankle rehabilitation training” by Wu et al., the authors presented the design and development of an end-effector ankle rehabilitation robot called CEARR to support range of motion ankle rehabilitation. The CEARR employed a bilaterally symmetrical structure with three degrees of freedom per side, driven by independent actuators, and integrated a real-time voluntary-triggered control (VTC) strategy using surface electromyography (sEMG) and torque signals to enhance rehabilitation outcomes. The proposed VTC strategy could be more cost-effective than neural-network-based algorithms, as it can be executed on a single microcontroller with fewer computational resources. In the paper ”Optimization and fabrication of programmable domains for soft magnetic robots: A review” by Bacchetti et al., the authors reviewed the current state of the art of programmable magnetic soft robots, focusing on bio-inspired structural optimization and fabrication. The paper indicated that significant further developments of programmable magnetic soft robots could be achieved by increasing the computational power of novel optimization methods, combined with advances in computational resolution, material options and automation of fabrication methods.The contribution in ”Novel bio-inspired soft actuators for upper-limb exoskeletons: design, fabrication and feasibility study” by Zhang et al. analyzes the actuator design for medical robots. In that paper, two kinds of soft actuators were developed for upper-limb exoskeletons: the Lobster-Inspired Silicone Pneumatic Robot (LISPER) for the elbow and the Scallop-Shaped Pneumatic Robot (SCASPER) for the shoulder. Experimental results showed that, by using position control and gravity compensation mode, an upper-limb exoskeleton equipped with the proposed actuators can stably track the desired trajectory and maintain the desired position.Other two contributions address the topic of tactile sensor design for medical robots. The paper ”Validations of various in-hand object manipulation strategies employing a novel tactile sensor developed for an under-actuated robot hand” by Singh et al. presented an opto-electronic-based tactile sensor, which was integrated into an under-actuated prosthetic hand (Prisma Hand II) to realize complex in-hand object manipulation. Based on the voltage value from the tactile sensor, deep learning methods were developed to calculate the grasping forces and torques for object manipulation. The paper ”Abraded optical fibre-based dynamic range force sensor for tissue palpation” by Dawood et al., on the other hand, introduced a variable-stiffness dynamic range force sensor based on abraded optical fibre, which can be used to provide remote haptic feedback. By adjusting the stiffness of the sensor, the measurement range of touching force can be modified.The last two articles are focusing on the motion control of medical robots. In the paper ”Integrating computer vision to prosthetic hand control with sEMG: Preliminary results in grasp classification” by Wang et al., the authors investigated the feasibility of integrating sEMG signals with visual information to improve the accuracy of prosthetic hand control. Results showed that, during the early reaching phase, a higher accuracy of grasp pattern classification could be achieved with the integrated vision data. Based on this knowledge, more vision-based methods could be developed in the future to enhance the motion control accuracy of myoelectric prosthetic hands. In the paper ”Adaptive approach for tracking movements of biological targets: application to robot-based intervention for prostate cancer” by Smahi et al., the authors presented a robotic system for Brachytherapy in prostate cancer treatment. By utilizing a deep learning framework based on Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) to predict the position of prostate, the proposed system can precisely deliver the radioactive drug to the cancer tissues and hence, improve the patient experience in prostate cancer Brachytherapy.3 CONCLUSIONThe articles collected in this Research Topic provide a good demonstration of how bio-inspired techniques could improve the performance of medical robots. Despite the significant progress, several challenges still remain in the future development of bio-inspired medical robots. For instance, in soft medical robots, innovative solutions are needed to protect delicate electronic components from damage during large deformations of the robot body. Additionally, onboard computation for AI-based control of medical robots still faces limitations due to weight and power constraints. From this perspective, more collaboration between clinicians, roboticists, biologists and mechanical engineers should be encouraged in the future to further promote the development of medical robotics.},
  archive      = {J_FROBT},
  author       = {Sun, Yilun and Dai, Houde and Song, Shuang and Faragasso, Angela and Abad Guaman, Sara-Adela},
  doi          = {10.3389/frobt.2025.1544097},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1544097},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Latest trends in bio-inspired medical robotics: Structural design, manufacturing, sensing, actuation and control},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based manipulation of transparent plastic bags in industrial setups. <em>FROBT</em>, <em>12</em>, 1506290. (<a href='https://doi.org/10.3389/frobt.2025.1506290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Adetunji, F. and Karukayil, A. and Samant, P. and Shabana, S. and Varghese, F. and Upadhyay, U. and Yadav, R. A. and Partridge, A. and Pendleton, E. and Plant, R. and Petillot, Y. R. and Koskinopoulou, M.},
  doi          = {10.3389/frobt.2025.1506290},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1506290},
  shortjournal = {Front. Robot. AI},
  title        = {Vision-based manipulation of transparent plastic bags in industrial setups},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of behaviorally anthropomorphic service robots on customers’ variety-seeking behavior: An analytical examination of social presence and decision-making context. <em>FROBT</em>, <em>12</em>, 1503622. (<a href='https://doi.org/10.3389/frobt.2025.1503622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Liu, Wenchao and Xin, Xin and Zheng, Chenyu},
  doi          = {10.3389/frobt.2025.1503622},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1503622},
  shortjournal = {Front. Robot. AI},
  title        = {The effect of behaviorally anthropomorphic service robots on customers’ variety-seeking behavior: An analytical examination of social presence and decision-making context},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for time-critical wilderness search and rescue using drones. <em>FROBT</em>, <em>11</em>, 1527095. (<a href='https://doi.org/10.3389/frobt.2024.1527095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  doi          = {10.3389/frobt.2024.1527095},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1527095},
  shortjournal = {Front. Robot. AI},
  title        = {Deep reinforcement learning for time-critical wilderness search and rescue using drones},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive formation learning control for cooperative AUVs under complete uncertainty. <em>FROBT</em>, <em>11</em>, 1491907. (<a href='https://doi.org/10.3389/frobt.2024.1491907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jandaghi, Emadodin and Zhou, Mingxi and Stegagno, Paolo and Yuan, Chengzhi},
  doi          = {10.3389/frobt.2024.1491907},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1491907},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive formation learning control for cooperative AUVs under complete uncertainty},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HPRS: Hierarchical potential-based reward shaping from task specifications. <em>FROBT</em>, <em>11</em>, 1444188. (<a href='https://doi.org/10.3389/frobt.2024.1444188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Berducci, Luigi and Aguilar, Edgar A. and Ničković, Dejan and Grosu, Radu},
  doi          = {10.3389/frobt.2024.1444188},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1444188},
  shortjournal = {Front. Robot. AI},
  title        = {HPRS: Hierarchical potential-based reward shaping from task specifications},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Creative approaches to appropriation and design: Novel robotic systems for heterogeneous contexts. <em>FROBT</em>, <em>11</em>, 1531132. (<a href='https://doi.org/10.3389/frobt.2024.1531132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discourse on robotic systems in care is shifting. While the debates have focused on the varying degrees of use of robotic systems in care, and whether or how the work of carers can be substituted by robots (Dalton-Brown, 2020), the focus is now on the practical implementation of robotic systems in care (Mahmoudi Asl et al., 2022). Concerns among carers about job losses due to replacement have diminished, while the demographic trends in Europe contributing to the shortage of staff and the growing number of people expected to need care have been highlighted (The Impact of Demographic Change in Europe - European Commission, 2023). In the future, the focus will be more on how to establish adequate human-technology interaction in the care sector and on the appropriation of technology by care staff and other stakeholders from a human-centered perspective (Paluch et al. 2022). Appropriation is a process in which technical artifacts are used and integrated into users’ specific contexts and practices, adapting them to their needs and reinterpreting their purpose beyond the original design intentions. In addition, appropriation is a creative and dynamic process that is mediated by context and emerges in collaboration with others. The objective is not to dictate technological solutions but to engage users that are actively using the technology, with the aim of facilitating mutual learning about how users adapt to technology and shaping its design to be meaningful and relevant to their needs. The focus is on long-term use and the creative and playful appropriation of technologies. Thus, this process is about working democratically to explore how the technologies best fit the context. This should create anchor points in people's lives that enable meaningful appropriation (Stevens & Pipek, 2018).With regard to robots for care settings, a socio-informatics perspective is particularly interesting, as it provides sensitizing concepts that enable the investigation of such questions in different practical contexts (Stevens et al., 2018). However, there is still a need to clarify the practicalities of using robots and how people in different care settings can appropriate them long-term (Carros et al., 2022; Paluch & Müller, 2022; Paluch et al. 2024). This question has been explored in several research projects, the findings of which are presented in this special issue. It became evident that a focus was placed on emotions in a multitude of research dimensions. Additionally, it was established that the entertainment value of a robot and its capacity to respond to humor are significant aspects (Oliveira et al., 2021). Interaction with robots can be challenging due to their potential unfamiliarity. In care settings, it can be helpful that robotic systems are developed with a participatory design element and that the robots are adapted to the specific local needs (Carros et al., 2020; Carros et al., 2023). If caregivers and care recipients are taken seriously in the development process, robotic systems can be designed that are used creatively to assist and enhance the wellbeing of those in need of care. Only then, we believe, an appropriation of the robotic systems is possible, which would otherwise be constrained by rigid usage requirements.Overall, we selected five papers for this special issue that take into account the multidisciplinary needs of developing such robotic systems and that observed the appropriation from the users of their devices:The article by Graf et al. entitled 'Distributed agency in HRI - an exploratory study of a narrative robot design' presents a plant watering robot. The study investigated how the robot's agency is experienced in different contexts, how this affects the attribution of the robot's behavior, and whether it increases the enjoyment of users. Appropriation processes were observed in situ, and particular attention was paid to people's reactions. The examples relate to a university campus, focusing on younger users, and a nursing home where people with dementia are cared for.The article 'What helps, what hinders? - Focus group findings on barriers and facilitators for mobile service robot use in a psychosocial group therapy for people with dementia' by Wasic et al. discusses the use of robotic systems to support therapists in dementia therapy. An important aspect is the promotion of appropriation processes to support the use of robots. As part of the study, four focus groups were conducted over a period of two years to accompany the use of the Scitos G5 robot. The focus groups generated suggestions for the use of the robot, which were then evaluated and assessed in a therapy session. Ethical issues were also discussed. A total of 13 applications were implemented in this way, which proved to be helpful for the therapeutic work. In addition to time, financial resources, or the certainty of expectations when using the robot, humor was also mentioned, especially with regard to ethical aspects. Jokes and humor are beneficial for human-robot interaction in therapy. In their article ‘HoLLiECares – Development of a multi-functional robot for professional care’, Schneider et al. refer to a robot called HoLLiE that is used in two hospitals. Six of its functions are examined (1. pushing wheelchairs; 2. escorting patients to examination rooms; 3. body movement instructions; 4. documenting wounds; 5. storing medication, and 6. handling limp objects). In this context, the perspectives of carers and patients were included to assess the acquisition of the functions. By considering individual functionalities, it is easier to decide how to scale the use of robots appropriately. It becomes clearer when interaction with a carer is required and when robots can be used. The analysis covers a range of possible applications along a continuum from human interaction to robot-assisted support. In their article 'Nature redux: interrogating biomorphism and soft robot aesthetics through generative AI', Christiansen et al. discuss the potential of generative AI. One focus is on the AI software used for image generation. Here, biologically inspired ideas for soft robotics are examined. One example is biomorphic aspects, which are said to have an optimizing effect on human-robot interaction. The inclusion of AI image generation techniques allows different stakeholders to participate in the design process, including those without design expertise. This can contribute to a democratization of robotic design and at the same time promote the reflection of different cultural views on the biomorphic aesthetics of robotic systems. This work is dedicated to the investigation of the limits and possibilities of AI image generation for creative processes in robot design. Furthermore, the results are analyzed in terms of how the design of soft robots can be mediated. This knowledge can be used for the participatory design of robotic systems.Finally, in the article by Ushijima et al. ‘Predicting humor effectiveness of robots for human line cutting’, the authors discuss a security robot that prevents people from queue-jumping. The idea is that by telling jokes, the robot will react in such a way that people behave according to expectations and follow the rules. The authors began by creating a data set and developing a predictor of the effectiveness of humorous statements. They then simulated 13,000 situations in which people cut in line and collected 500 phrases via crowdsourcing that could be described as humorous. The most humorous phrases related to queue-jumping were systematically identified and compared with non-humorous phrases in video experiments. The video experiments simulated the situation to record viewers' reactions. The humorous phrases proved to be more effective than the non-humorous phrases in preventing rule-breaking.In conclusion, there is a strong case for looking closely at appropriation processes, namely what happens when a robotic system is put into practice and what can be learned from this. An ethnographic appropriation perspective offers the development team as well as caregivers and care recipients an additional perspective. The selected contributions focus on the possibilities that complex robotic systems open up for care, emphasizing aspects such as humor and democratization. From a praxeological standpoint, it is crucial to examine how these aspects manifest themselves in the respective situations and to draw conclusions regarding the design process. In the cases presented here, this applies both to the technical features of a robot and to how the different perspectives of the stakeholders can be integrated for collaboration.},
  archive      = {J_FROBT},
  author       = {Paluch, Richard and Carros, Felix and Volkova, Galina and Obaid, Mohammad and Müller, Claudia},
  doi          = {10.3389/frobt.2024.1531132},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1531132},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Creative approaches to appropriation and design: Novel robotic systems for heterogeneous contexts},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pig tongue soft robot mimicking intrinsic tongue muscle structure. <em>FROBT</em>, <em>11</em>, 1511422. (<a href='https://doi.org/10.3389/frobt.2024.1511422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ishikawa, Yuta and Nabae, Hiroyuki and Gunji, Megu and Endo, Gen and Suzumori, Koichi},
  doi          = {10.3389/frobt.2024.1511422},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1511422},
  shortjournal = {Front. Robot. AI},
  title        = {Pig tongue soft robot mimicking intrinsic tongue muscle structure},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Versatile graceful degradation framework for bio-inspired proprioception with redundant soft sensors. <em>FROBT</em>, <em>11</em>, 1504651. (<a href='https://doi.org/10.3389/frobt.2024.1504651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sugiyama, Taku and Kutsuzawa, Kyo and Owaki, Dai and Almanzor, Elijah and Iida, Fumiya and Hayashibe, Mitsuhiro},
  doi          = {10.3389/frobt.2024.1504651},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1504651},
  shortjournal = {Front. Robot. AI},
  title        = {Versatile graceful degradation framework for bio-inspired proprioception with redundant soft sensors},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From construction machines to remote construction robots: Control, interfaces, and usability of the cranebot. <em>FROBT</em>, <em>11</em>, 1504317. (<a href='https://doi.org/10.3389/frobt.2024.1504317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Duz, Alessandra and Negrello, Francesca and Rucodainii, Alexandr and Lanzoni, Daniel and Corsanici, Mario and Iapichino, Angelo and Vitali, Andrea and Regazzoni, Daniele and Birolini, Valentino and Signori, Roberto and Ceresoli, Rossano and Grioli, Giorgio and Bicchi, Antonio and Catalano, Manuel G.},
  doi          = {10.3389/frobt.2024.1504317},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1504317},
  shortjournal = {Front. Robot. AI},
  title        = {From construction machines to remote construction robots: Control, interfaces, and usability of the cranebot},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced robotics for automated EV battery testing using electrochemical impedance spectroscopy. <em>FROBT</em>, <em>11</em>, 1493869. (<a href='https://doi.org/10.3389/frobt.2024.1493869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Rastegarpanah, Alireza and Contreras, Cesar Alan and Ahmeid, Mohamed and Asif, Mohammed Eesa and Villagrossi, Enrico and Stolkin, Rustam},
  doi          = {10.3389/frobt.2024.1493869},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1493869},
  shortjournal = {Front. Robot. AI},
  title        = {Advanced robotics for automated EV battery testing using electrochemical impedance spectroscopy},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding-based pair generation for contrastive representation learning in audio-visual surveillance data. <em>FROBT</em>, <em>11</em>, 1490718. (<a href='https://doi.org/10.3389/frobt.2024.1490718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wang, Wei-Cheng and De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  doi          = {10.3389/frobt.2024.1490718},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1490718},
  shortjournal = {Front. Robot. AI},
  title        = {Embedding-based pair generation for contrastive representation learning in audio-visual surveillance data},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WearMoCap: Multimodal pose tracking for ubiquitous robot control using a smartwatch. <em>FROBT</em>, <em>11</em>, 1478016. (<a href='https://doi.org/10.3389/frobt.2024.1478016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Weigend, Fabian C. and Kumar, Neelesh and Aran, Oya and Ben Amor, Heni},
  doi          = {10.3389/frobt.2024.1478016},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1478016},
  shortjournal = {Front. Robot. AI},
  title        = {WearMoCap: Multimodal pose tracking for ubiquitous robot control using a smartwatch},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicycle-inspired simple balance control method for quadruped robots in high-speed running. <em>FROBT</em>, <em>11</em>, 1473628. (<a href='https://doi.org/10.3389/frobt.2024.1473628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hattori, Shoei and Suzuki , Shura and Fukuhara , Akira and Kano , Takeshi and Ishiguro , Akio},
  doi          = {10.3389/frobt.2024.1473628},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1473628},
  shortjournal = {Front. Robot. AI},
  title        = {Bicycle-inspired simple balance control method for quadruped robots in high-speed running},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global progress in competitive co-evolution: A systematic comparison of alternative methods. <em>FROBT</em>, <em>11</em>, 1470886. (<a href='https://doi.org/10.3389/frobt.2024.1470886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nolfi, Stefano and Pagliuca, Paolo},
  doi          = {10.3389/frobt.2024.1470886},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1470886},
  shortjournal = {Front. Robot. AI},
  title        = {Global progress in competitive co-evolution: A systematic comparison of alternative methods},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Android avatar improves educational effects by embodied anthropomorphization. <em>FROBT</em>, <em>11</em>, 1469626. (<a href='https://doi.org/10.3389/frobt.2024.1469626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kodani, Naoki and Uchida, Takahisa and Kameo, Nahoko and Sakai, Kurima and Funayama, Tomo and Minato, Takashi and Kikuchi, Akane and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2024.1469626},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1469626},
  shortjournal = {Front. Robot. AI},
  title        = {Android avatar improves educational effects by embodied anthropomorphization},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable and robust robotic handling of microplates via computer vision and touch feedback. <em>FROBT</em>, <em>11</em>, 1462717. (<a href='https://doi.org/10.3389/frobt.2024.1462717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Scamarcio, Vincenzo and Tan, Jasper and Stellacci, Francesco and Hughes, Josie},
  doi          = {10.3389/frobt.2024.1462717},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1462717},
  shortjournal = {Front. Robot. AI},
  title        = {Reliable and robust robotic handling of microplates via computer vision and touch feedback},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic segmentation using synthetic images of underwater marine-growth. <em>FROBT</em>, <em>11</em>, 1459570. (<a href='https://doi.org/10.3389/frobt.2024.1459570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mai, Christian and Liniger, Jesper and Pedersen, Simon},
  doi          = {10.3389/frobt.2024.1459570},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1459570},
  shortjournal = {Front. Robot. AI},
  title        = {Semantic segmentation using synthetic images of underwater marine-growth},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Informed circular fields: A global reactive obstacle avoidance framework for robotic manipulators. <em>FROBT</em>, <em>11</em>, 1447351. (<a href='https://doi.org/10.3389/frobt.2024.1447351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Becker, Marvin and Caspers, Philipp and Lilge, Torsten and Haddadin, Sami and Müller, Matthias A.},
  doi          = {10.3389/frobt.2024.1447351},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1447351},
  shortjournal = {Front. Robot. AI},
  title        = {Informed circular fields: A global reactive obstacle avoidance framework for robotic manipulators},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximising the wrench capability of mobile manipulators with experiments on a UVMS. <em>FROBT</em>, <em>11</em>, 1442813. (<a href='https://doi.org/10.3389/frobt.2024.1442813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Marais, Wilhelm J. and Pizarro, Oscar and Williams, Stefan B.},
  doi          = {10.3389/frobt.2024.1442813},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1442813},
  shortjournal = {Front. Robot. AI},
  title        = {Maximising the wrench capability of mobile manipulators with experiments on a UVMS},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spiking neural network for active efficient coding. <em>FROBT</em>, <em>11</em>, 1435197. (<a href='https://doi.org/10.3389/frobt.2024.1435197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Barbier, Thomas and Teulière, Céline and Triesch, Jochen},
  doi          = {10.3389/frobt.2024.1435197},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1435197},
  shortjournal = {Front. Robot. AI},
  title        = {A spiking neural network for active efficient coding},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative psychological evaluation of a robotic avatar in dubai and japan. <em>FROBT</em>, <em>11</em>, 1426717. (<a href='https://doi.org/10.3389/frobt.2024.1426717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kamide, Hiroko and Horikawa, Yukiko and Sato, Moe and Toyoda, Atsushi and Sakai, Kurima and Minato, Takashi and Miyashita, Takahiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2024.1426717},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1426717},
  shortjournal = {Front. Robot. AI},
  title        = {A comparative psychological evaluation of a robotic avatar in dubai and japan},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous foraging swarms can be better. <em>FROBT</em>, <em>11</em>, 1426282. (<a href='https://doi.org/10.3389/frobt.2024.1426282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kaminka, Gal A. and Douchan, Yinon},
  doi          = {10.3389/frobt.2024.1426282},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1426282},
  shortjournal = {Front. Robot. AI},
  title        = {Heterogeneous foraging swarms can be better},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast monocular 6D pose estimation method for textureless objects based on perceptual hashing and template matching. <em>FROBT</em>, <em>11</em>, 1424036. (<a href='https://doi.org/10.3389/frobt.2024.1424036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Araya-Martinez, Jose Moises and Matthiesen, Vinicius Soares and Bøgh, Simon and Lambrecht, Jens and Pimentel de Figueiredo, Rui},
  doi          = {10.3389/frobt.2024.1424036},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1424036},
  shortjournal = {Front. Robot. AI},
  title        = {A fast monocular 6D pose estimation method for textureless objects based on perceptual hashing and template matching},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Socially interactive industrial robots: A PAD model of flow for emotional co-regulation. <em>FROBT</em>, <em>11</em>, 1418677. (<a href='https://doi.org/10.3389/frobt.2024.1418677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nunnari, Fabrizio and Tsovaltzi , Dimitra and Lavit Nicora , Matteo and Beyrodt , Sebastian and Prajod , Pooja and Chehayeb , Lara and Brdar , Ingrid and Delle Fave , Antonella and Negri , Luca and André, Elisabeth and Gebhard , Patrick and Malosio , Matteo},
  doi          = {10.3389/frobt.2024.1418677},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1418677},
  shortjournal = {Front. Robot. AI},
  title        = {Socially interactive industrial robots: A PAD model of flow for emotional co-regulation},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EzSkiROS: Enhancing robot skill composition with embedded DSL for early error detection. <em>FROBT</em>, <em>11</em>, 1363443. (<a href='https://doi.org/10.3389/frobt.2024.1363443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Rizwan, Momina and Reichenbach, Christoph and Caldas, Ricardo and Mayr, Matthias and Krueger, Volker},
  doi          = {10.3389/frobt.2024.1363443},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1363443},
  shortjournal = {Front. Robot. AI},
  title        = {EzSkiROS: Enhancing robot skill composition with embedded DSL for early error detection},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic composition of robotic solver algorithms on graph structures. <em>FROBT</em>, <em>11</em>, 1363150. (<a href='https://doi.org/10.3389/frobt.2024.1363150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schneider, Sven and Hochgeschwender, Nico and Bruyninckx, Herman},
  doi          = {10.3389/frobt.2024.1363150},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1363150},
  shortjournal = {Front. Robot. AI},
  title        = {Semantic composition of robotic solver algorithms on graph structures},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building for speech: Designing the next-generation of social robots for audio interaction. <em>FROBT</em>, <em>11</em>, 1356477. (<a href='https://doi.org/10.3389/frobt.2024.1356477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Addlesee, Angus and Papaioannou, Ioannis},
  doi          = {10.3389/frobt.2024.1356477},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1356477},
  shortjournal = {Front. Robot. AI},
  title        = {Building for speech: Designing the next-generation of social robots for audio interaction},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
