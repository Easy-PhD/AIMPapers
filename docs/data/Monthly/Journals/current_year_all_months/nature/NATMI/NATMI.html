<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NATMI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="natmi">NATMI - 135</h2>
<ul>
<li><details>
<summary>
(2025). Electron-density-informed effective and reliable de novo molecular design and optimization with ED2Mol. <em>NATMI</em>, <em>7</em>(8), 1355-1368. (<a href='https://doi.org/10.1038/s42256-025-01095-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative drug design opens avenues for discovering novel compounds within the vast chemical space rather than conventional screening against limited libraries. However, the practical utility of the generated molecules is frequently constrained, as many designs prioritize a narrow range of pharmacological properties and neglect physical reliability, which hinders the success rate of subsequent wet-laboratory evaluations. Here, to address this, we propose ED2Mol, a deep learning-based approach that leverages fundamental electron density information to improve de novo molecular generation and optimization. The extensive evaluations across multiple benchmarks demonstrate that ED2Mol surpasses existing methods in terms of the generation success rate and &gt;97% physical reliability. It also facilitates automated hit optimization that is not fully implemented by other methods using fragment-based strategies. Furthermore, ED2Mol exhibits generalizability to more challenging, unseen allosteric pocket benchmarks, attaining consistent performance. More importantly, ED2Mol has been applied to various real-world essential targets, successfully identifying wet-laboratory-validated bioactive compounds, ranging from FGFR3 orthosteric inhibitors to CDC42 allosteric inhibitors, GCK and GPRC5A allosteric activators. The directly generated binding modes of these compounds are close to predictions through molecular docking and further validated via the X-ray co-crystal structure. All these results highlight ED2Mol’s potential as a useful tool in drug design with enhanced effectiveness, physical reliability and practical applicability. A deep generative model is developed for de novo molecular design and optimization by leveraging electron density. Wet-laboratory assays validated its reliability to generate diverse bioactive molecules—orthosteric and allosteric, inhibitors and activators.},
  archive      = {J_NATMI},
  author       = {Li, Mingyu and Song, Kun and He, Jixiao and Zhao, Mingzhu and You, Gengshu and Zhong, Jie and Zhao, Mengxi and Li, Arong and Chen, Yu and Li, Guobin and Kong, Ying and Wei, Jiacheng and Wang, Zhaofu and Zhou, Jiamin and Yang, Hongbing and Ma, Shichao and Zhang, Hailong and Mélita, Irakoze Loïca and Lin, Weidong and Lu, Yuhang and Yu, Zhengtian and Lu, Xun and Zhao, Yujun and Zhang, Jian},
  doi          = {10.1038/s42256-025-01095-7},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1355-1368},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Electron-density-informed effective and reliable de novo molecular design and optimization with ED2Mol},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kolmogorov–Arnold graph neural networks for molecular property prediction. <em>NATMI</em>, <em>7</em>(8), 1346-1354. (<a href='https://doi.org/10.1038/s42256-025-01087-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown remarkable success in molecular property prediction as key models in geometric deep learning. Meanwhile, Kolmogorov–Arnold networks (KANs) have emerged as powerful alternatives to multi-layer perceptrons, offering improved expressivity, parameter efficiency and interpretability. To combine the strengths of both frameworks, we propose Kolmogorov–Arnold GNNs (KA-GNNs), which integrate KAN modules into the three fundamental components of GNNs: node embedding, message passing and readout. We further introduce Fourier-series-based univariate functions within KAN to enhance function approximation and provide theoretical analysis to support their expressiveness. Two architectural variants, KA-graph convolutional networks and KA-augmented graph attention networks, are developed and evaluated across seven molecular benchmarks. Experimental results show that KA-GNNs consistently outperform conventional GNNs in terms of both prediction accuracy and computational efficiency. Moreover, our models exhibit improved interpretability by highlighting chemically meaningful substructures. These findings demonstrate that KA-GNNs offer a powerful and generalizable framework for molecular data modelling, drug discovery and beyond. Li et al. developed KA-GNNs, graph neural network architectures enhanced by Kolmogorov–Arnold networks, which improve accuracy and interpretability in molecular property prediction and extend geometric deep learning to scientific domains.},
  archive      = {J_NATMI},
  author       = {Li, Longlong and Zhang, Yipeng and Wang, Guanghui and Xia, Kelin},
  doi          = {10.1038/s42256-025-01087-7},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1346-1354},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Kolmogorov–Arnold graph neural networks for molecular property prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based prediction of the selection factors for quantifying selection in immune receptor repertoires. <em>NATMI</em>, <em>7</em>(8), 1331-1345. (<a href='https://doi.org/10.1038/s42256-025-01085-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T cell selection is a vital process in which precursor T cells mature into functional cells. Accurately modelling and quantifying T cell selection utilizing high-throughput T cell receptor (TCR) sequencing data presents an important computational challenge in immunology. Statistical modelling of TCR repertoires allows the assessment of selection force through the selection factor that bridges the pre- and post-selection distributions. Current tools derive the principles underlying this selection factor through weakly supervised learning, limiting the effective use of available data. To overcome this shortcoming, we introduce TCRsep, a deep learning framework designed to directly learn the selection factor in a supervised training context. The performance and advantage of TCRsep were extensively validated across various scenarios using both simulated and real datasets. By applying TCRsep to over 1,500 repertoire samples, we elucidate the correlation between selection and repertoire diversities in aging, explore the stability and individuality of selection over short time frames, investigate the role of selection in defining TCR sharing profiles and demonstrate its efficiency in identifying candidate-disease-associated TCRs based on their sharing profiles. In particular, these identified TCRs were further utilized for diagnosing cytomegalovirus infection, achieving high predictive accuracy. In conclusion, TCRsep substantially improves the selection factor prediction and serves as a valuable discovery tool for clinical applications. TCRsep, a deep learning model for predicting selection factors that quantifies the T cell selection process, is introduced. Also, various benchmarks are designed to evaluate the selection models, demonstrating that TCRsep outperforms state-of-the-art models.},
  archive      = {J_NATMI},
  author       = {Jiang, Yuepeng and Zhang, Pingping and Huo, Miaozhe and Li, Shuai Cheng},
  doi          = {10.1038/s42256-025-01085-9},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1331-1345},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning-based prediction of the selection factors for quantifying selection in immune receptor repertoires},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards generalizable and interpretable three-dimensional tracking with inverse neural rendering. <em>NATMI</em>, <em>7</em>(8), 1322-1330. (<a href='https://doi.org/10.1038/s42256-025-01083-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, the most successful methods for image-understanding tasks rely on feed-forward neural networks. Although this approach offers empirical accuracy, efficiency and task adaptation through fine-tuning, it also comes with fundamental disadvantages. Existing networks often struggle to generalize across different datasets, even on the same task. By design, these networks ultimately reason about high-dimensional scene features, which are challenging to analyse. This is true especially when attempting to predict three-dimensional (3D) information based on two-dimensional images. We propose to recast vision problems with RGB inputs as an inverse rendering problem by optimizing through a differentiable rendering pipeline over the latent space of pretrained 3D object representations and retrieving latents that best represent object instances in a given input image. Specifically, we solve the task of 3D multi-object tracking by optimizing an image loss over generative latent spaces that inherently disentangle shape and appearance properties. Not only do we investigate an alternative take on tracking but our method also enables us to examine the generated objects, reason about failure situations and resolve ambiguous cases. We validate the generalization and scaling capabilities of our method by learning the generative prior exclusively from synthetic data and assessing camera-based 3D tracking on two large-scale autonomous robot datasets. Both datasets are completely unseen to our method and do not require fine-tuning. Ost et al. present a method that recasts vision problems with RGB inputs as an inverse rendering problem, optimizing over the latent variables of pretrained three-dimensional object models through a differentiable rendering pipeline.},
  archive      = {J_NATMI},
  author       = {Ost, Julian and Banerjee, Tanushree and Bijelic, Mario and Heide, Felix},
  doi          = {10.1038/s42256-025-01083-x},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1322-1330},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards generalizable and interpretable three-dimensional tracking with inverse neural rendering},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protein–peptide docking with a rational and accurate diffusion generative model. <em>NATMI</em>, <em>7</em>(8), 1308-1321. (<a href='https://doi.org/10.1038/s42256-025-01077-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Therapeutic peptides represent the forefront of drug discovery, offering potent and safe alternatives to traditional small molecules. However, their weak and context-dependent nature complicates the efficient virtual screening and structural characterization of protein–peptide patterns. Here we introduce RAPiDock, a diffusion generative model designed for rational, accurate and rapid protein–peptide docking at an all-atomic level. RAPiDock efficiently reduces the sampling space by incorporating physical constraints and uses a bi-scale graph to effectively capture multidimensional structural information while balancing efficiency. In addition, the model uses a Clebsch–Gordan tensor product-based architecture to ensure physical symmetry. RAPiDock outperforms existing tools in prediction of protein–peptide-binding patterns, achieving a 93.7% success rate at top-25 predictions (13.4% higher than AlphaFold2-Multimer), with an execution speed of 0.35 seconds per complex (~270 times faster than AlphaFold2-Multimer). Extensive experiments demonstrate RAPiDock’s remarkable ability to handle 92 types of residue including posttranslational modifications, accurately predict subtle docking patterns, successfully identify multiple potential peptide-binding sites in global docking and serve as a powerful tool for high-throughput virtual screening with structural precision. All these push the boundaries of efficient protein–peptide docking in multiple real-application scenarios. Zhao et al. present RAPiDock, an all-atom diffusion model that predicts peptide–protein binding patterns across 92 amino acid types, enabling high-throughput virtual screening for advancing therapeutic peptide design.},
  archive      = {J_NATMI},
  author       = {Zhao, Huifeng and Zhang, Odin and Jiang, Dejun and Wu, Zhenxing and Du, Hongyan and Wang, Xiaorui and Zhao, Yihao and Huang, Yuansheng and Ge, Jingxuan and Hou, Tingjun and Kang, Yu},
  doi          = {10.1038/s42256-025-01077-9},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1308-1321},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Protein–peptide docking with a rational and accurate diffusion generative model},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Histopathology-based protein multiplex generation using deep learning. <em>NATMI</em>, <em>7</em>(8), 1292-1307. (<a href='https://doi.org/10.1038/s42256-025-01074-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplexed protein imaging offers valuable insights into interactions between tumours and their surrounding tumour microenvironment, but its widespread use is limited by cost, time and tissue availability. Here we present HistoPlexer, a deep learning framework that generates spatially resolved protein multiplexes directly from standard haematoxylin and eosin (H&amp;E) histopathology images. HistoPlexer jointly predicts multiple tumour and immune markers using a conditional generative adversarial architecture with custom loss functions designed to ensure pixel- and embedding-level similarity while mitigating slice-to-slice variations. A comprehensive evaluation of metastatic melanoma samples demonstrates that HistoPlexer-generated protein maps closely resemble real maps, as validated by expert assessment. They preserve crucial biological relationships by capturing spatial co-localization patterns among proteins. The spatial distribution of immune infiltration from HistoPlexer-generated protein multiplex enables stratification of tumours into immune subtypes. In an independent cohort, integration of HistoPlexer-derived features into predictive models enhances performance in survival prediction and immune subtype classification compared to models using H&amp;E features alone. To assess broader applicability, we benchmarked HistoPlexer on publicly available pixel-aligned datasets from different cancer types. In all settings, HistoPlexer consistently outperformed baseline methods, demonstrating robustness across diverse tissue types and imaging conditions. By enabling whole-slide protein multiplex generation from routine H&amp;E images, HistoPlexer offers a cost- and time-efficient approach to tumour microenvironment characterization with strong potential to advance precision oncology. HistoPlexer, a deep learning model, generates multiplexed protein expression maps from H&amp;E images, capturing tumour–immune cell interactions. It outperforms baselines, enhances immune subtyping and survival prediction and offers a cost-effective tool for precision oncology.},
  archive      = {J_NATMI},
  author       = {Andani, Sonali and Chen, Boqi and Ficek-Pascual, Joanna and Heinke, Simon and Casanova, Ruben and Hild, Bernard Friedrich and Sobottka, Bettina and Bodenmiller, Bernd and Koelzer, Viktor H. and Rätsch, Gunnar},
  doi          = {10.1038/s42256-025-01074-y},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1292-1307},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Histopathology-based protein multiplex generation using deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Type II mechanoreceptors and cuneate spiking neuronal network enable touch localization on a large-area e-skin. <em>NATMI</em>, <em>7</em>(8), 1278-1291. (<a href='https://doi.org/10.1038/s42256-025-01076-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sense of touch is essential for humans to perceive, locate and react to physical stimuli. Notwithstanding the substantial advancements in e-skin research and related applications with collaborative robots and bionic prostheses, biomimetic intelligence remains a challenge in the attempt to understand and mimic somatosensory processing schemes. In this work, we present a large-area e-skin embedded with photonic fibre Bragg gratings, capable of decoding touch localization through a bioinspired two-layered spiking neuronal network. The implemented biomimicry of slowly adapting and fast-adapting type II primary afferents, cuneate neurons with overlapping receptive fields and neuroplasticity, enable unsupervised learning in localizing tactile stimuli with an error lower than 10 mm, and two-point discrimination thresholds matching human psychophysical thresholds in the forearm. These results align with biological findings and offer a promising step towards the development of bionic systems, opening new avenues for both practical applications and scientific explorations of somatosensation. Tactile sensing is essential for interacting with the environment. A bioinspired spiking neuronal network and large-area e-skin is presented, which enables unsupervised learning of touch localization and two-point discrimination.},
  archive      = {J_NATMI},
  author       = {Pereira Resende da Costa, Ana Clara and Filosa, Mariangela and Barbosa Soares, Alcimar and Oddo, Calogero Maria},
  doi          = {10.1038/s42256-025-01076-w},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1278-1291},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Type II mechanoreceptors and cuneate spiking neuronal network enable touch localization on a large-area e-skin},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-learning-aided dismantling of interdependent networks. <em>NATMI</em>, <em>7</em>(8), 1266-1277. (<a href='https://doi.org/10.1038/s42256-025-01070-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the minimal set of nodes whose removal breaks a complex network apart, also referred as the network dismantling problem, is a highly non-trivial task with applications in multiple domains. Whereas network dismantling has been extensively studied over the past decade, research has primarily focused on the optimization problem for single-layer networks, neglecting that many, if not all, real networks display multiple layers of interdependent interactions. In such networks, the optimization problem is fundamentally different as the effect of removing nodes propagates within and across layers in a way that can not be predicted using a single-layer perspective. Here we propose a dismantling algorithm named MultiDismantler, which leverages multiplex network representation and deep reinforcement learning to optimally dismantle multilayer interdependent networks. MultiDismantler is trained on small synthetic graphs; when applied to large, either real or synthetic, networks, it displays exceptional dismantling performance, clearly outperforming all existing benchmark algorithms. We show that MultiDismantler is effective in guiding strategies for the containment of diseases in social networks characterized by multiple layers of social interactions. Also, we show that MultiDismantler is useful in the design of protocols aimed at delaying the onset of cascading failures in interdependent critical infrastructures. The dismantling problem of removing the smallest set of nodes so that a given network breaks into disconnected components is hard to solve exactly. Gu and colleagues use deep reinforcement learning and a multiplex network representation to avoid the heavy computational cost.},
  archive      = {J_NATMI},
  author       = {Gu, Weiwei and Yang, Chen and Li, Lei and Hou, Jinqiang and Radicchi, Filippo},
  doi          = {10.1038/s42256-025-01070-2},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1266-1277},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep-learning-aided dismantling of interdependent networks},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-iterative multiple-instance learning enables the prediction of CD4+ t cell immunogenic epitopes. <em>NATMI</em>, <em>7</em>(8), 1250-1265. (<a href='https://doi.org/10.1038/s42256-025-01073-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of antigen presentation to CD4+ T cells and subsequent induction of immune response are fundamentally important for vaccine development, autoimmune disease treatment and cancer neoepitope discovery. In immunopeptidomics, single-allelic data offer high specificity but limited allele coverage, whereas multi-allelic data provide broader representation at the expense of weak labelling. Current computational approaches either overlook the abundance of multi-allelic data or suffer from label ambiguity due to inadequate modelling strategies. To address these limitations, we present ImmuScope, a weakly supervised deep learning framework that integrates major histocompatibility complex class II (MHC-II) antigen presentation, CD4+ T cell epitopes and immunogenicity assessment. ImmuScope leverages self-iterative multiple-instance learning with positive-anchor triplet loss to decipher peptide-MHC-II binding from weakly labelled multi-allelic data and high-confidence single-allelic data. The training dataset comprises over 600,000 ligands across 142 alleles. Additionally, ImmuScope enables the interpretation of MHC-II binding specificity and motif deconvolution of immunopeptidomics data. We successfully applied ImmuScope to identify melanoma neoantigens, uncovering mutation-driven variations in peptide-MHC-II binding and immunogenicity. Furthermore, we employed ImmuScope to evaluate the effects of SARS-CoV-2 epitope mutations associated with immune escape, with predictions well aligned with experimentally observed immune escape dynamics. Overall, by offering a unified solution for CD4+ T cell antigen recognition and immunogenicity assessment, ImmuScope holds substantial promise for accelerating vaccine design and advancing personalized immunotherapy. ImmuScope, a weakly supervised deep learning model capable of analysing multi- and single-allelic data, is introduced, facilitating interpretable neoantigen discovery and immune escape analysis.},
  archive      = {J_NATMI},
  author       = {Shen, Long-Chen and Zhang, Yumeng and Wang, Zhikang and Littler, Dene R. and Liu, Yan and Tang, Jinhui and Rossjohn, Jamie and Yu, Dong-Jun and Song, Jiangning},
  doi          = {10.1038/s42256-025-01073-z},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1250-1265},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-iterative multiple-instance learning enables the prediction of CD4+ t cell immunogenic epitopes},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic-enhanced multi-modal remote sensing foundation model for earth observation. <em>NATMI</em>, <em>7</em>(8), 1235-1249. (<a href='https://doi.org/10.1038/s42256-025-01078-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing foundation models, pretrained on massive remote sensing data, have shown impressive performance in several Earth observation (EO) tasks. These models usually use single-modal temporal data for pretraining, which is insufficient for multi-modal applications. Moreover, these models require a considerable number of samples for fine-tuning in downstream tasks, posing challenges in time-sensitive scenarios, such as rapid flood mapping. We present SkySense++, a multi-modal remote sensing foundation model for diverse EO tasks. SkySense++ has a factorized architecture to accommodate multi-modal images acquired by diverse sensors. We adopt progressive pretraining, which involves two stages, on meticulously curated datasets of 27 million multi-modal remote sensing images. The first representation-enhanced pretraining stage uses multi-granularity contrastive learning to obtain general representations. The second semantic-enhanced pretraining stage leverages masked semantic learning to learn semantically enriched representations, enabling few-shot capabilities. This ability allows the model to handle unseen tasks with minimal labelled data, alleviating the need for fine-tuning on extensive annotated data. SkySense++ demonstrates consistent improvements in classification, detection and segmentation over previous state-of-the-art models across 12 EO tasks in 7 domains: agriculture, forestry, oceanography, atmosphere, biology, land surveying and disaster management. This generalizability may lead to a new chapter of remote sensing foundation model applications for EO tasks at scale. Wu et al. developed SkySense++, a multi-modal remote sensing foundation model pretrained on 27 million multi-modal images, which achieved robust generalization and few-shot capabilities across several Earth observation tasks and domains, including agriculture and disaster management.},
  archive      = {J_NATMI},
  author       = {Wu, Kang and Zhang, Yingying and Ru, Lixiang and Dang, Bo and Lao, Jiangwei and Yu, Lei and Luo, Junwei and Zhu, Zifan and Sun, Yue and Zhang, Jiahao and Zhu, Qi and Wang, Jian and Yang, Ming and Chen, Jingdong and Zhang, Yongjun and Li, Yansheng},
  doi          = {10.1038/s42256-025-01078-8},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1235-1249},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A semantic-enhanced multi-modal remote sensing foundation model for earth observation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-level visual representations in the human brain are aligned with large language models. <em>NATMI</em>, <em>7</em>(8), 1220-1234. (<a href='https://doi.org/10.1038/s42256-025-01072-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain extracts complex information from visual inputs, including objects, their spatial and semantic interrelations, and their interactions with the environment. However, a quantitative approach for studying this information remains elusive. Here we test whether the contextual information encoded in large language models (LLMs) is beneficial for modelling the complex visual information extracted by the brain from natural scenes. We show that LLM embeddings of scene captions successfully characterize brain activity evoked by viewing the natural scenes. This mapping captures selectivities of different brain areas and is sufficiently robust that accurate scene captions can be reconstructed from brain activity. Using carefully controlled model comparisons, we then proceed to show that the accuracy with which LLM representations match brain representations derives from the ability of LLMs to integrate complex information contained in scene captions beyond that conveyed by individual words. Finally, we train deep neural network models to transform image inputs into LLM representations. Remarkably, these networks learn representations that are better aligned with brain representations than a large number of state-of-the-art alternative models, despite being trained on orders-of-magnitude less data. Overall, our results suggest that LLM embeddings of scene captions provide a representational format that accounts for complex information extracted by the brain from visual inputs. Doerig, Kietzmann and colleagues show that the brain’s response to visual scenes can be modelled using language-based AI representations. By linking brain activity to caption-based embeddings from large language models, the study reveals a way to quantify complex visual understanding.},
  archive      = {J_NATMI},
  author       = {Doerig, Adrien and Kietzmann, Tim C. and Allen, Emily and Wu, Yihan and Naselaris, Thomas and Kay, Kendrick and Charest, Ian},
  doi          = {10.1038/s42256-025-01072-0},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1220-1234},
  shortjournal = {Nat. Mach. Intell.},
  title        = {High-level visual representations in the human brain are aligned with large language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training data composition determines machine learning generalization and biological rule discovery. <em>NATMI</em>, <em>7</em>(8), 1206-1219. (<a href='https://doi.org/10.1038/s42256-025-01089-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised machine learning models depend on training datasets containing positive and negative examples: dataset composition directly impacts model performance and bias. Given the importance of machine learning for immunotherapeutic design, we examined how different negative class definitions affect model generalization and rule discovery for antibody–antigen binding. Using synthetic-structure-based binding data, we evaluated models trained with various definitions of negative sets. Our findings reveal that high out-of-distribution performance can be achieved when the negative dataset contains more similar samples to the positive dataset, despite lower in-distribution performance. Furthermore, by leveraging ground-truth information, we show that binding rules associated with positive data change based on the negative data used. Validation on experimental data supported simulation-based observations. This work underscores the role of dataset composition in creating robust, generalizable and biology-aware sequence-based ML models. Negative data composition critically shapes machine learning robustness in sequence-based biological tasks. Training data composition and its implications are investigated on biological rule discoveries.},
  archive      = {J_NATMI},
  author       = {Ursu, Eugen and Minnegalieva, Aygul and Rawat, Puneet and Chernigovskaya, Maria and Tacutu, Robi and Sandve, Geir Kjetil and Robert, Philippe A. and Greiff, Victor},
  doi          = {10.1038/s42256-025-01089-5},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1206-1219},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Training data composition determines machine learning generalization and biological rule discovery},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying artificial intelligence through algorithmic generalization. <em>NATMI</em>, <em>7</em>(8), 1195-1205. (<a href='https://doi.org/10.1038/s42256-025-01092-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning—a glaring limitation, given the necessity for interpretable and reliable technology. Despite a surge in reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory—the study of algebraic expressions as circuit models—is a natural framework for studying the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements for solving a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science. Despite impressive performances of current large AI models, symbolic and abstract reasoning tasks often elicit failure modes in these systems. In this Perspective, Ito et al. propose to make use of computational complexity theory, formulating algebraic problems as computable circuits to address the challenge of mathematical and symbolic reasoning in AI systems.},
  archive      = {J_NATMI},
  author       = {Ito, Takuya and Campbell, Murray and Horesh, Lior and Klinger, Tim and Ram, Parikshit},
  doi          = {10.1038/s42256-025-01092-w},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1195-1205},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Quantifying artificial intelligence through algorithmic generalization},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The importance of negative training data for robust antibody binding prediction. <em>NATMI</em>, <em>7</em>(8), 1192-1194. (<a href='https://doi.org/10.1038/s42256-025-01080-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thoughtfully designed negative training datasets may hold the key to more robust machine learning models. Ursu et al. reveal how negative training data composition shapes antibody prediction models and their generalizability. Sometimes, the best way to get better is to train harder.},
  archive      = {J_NATMI},
  author       = {Ta, Wesley and Stokes, Jonathan M.},
  doi          = {10.1038/s42256-025-01080-0},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1192-1194},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The importance of negative training data for robust antibody binding prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mapping t helper cell targets with deep learning. <em>NATMI</em>, <em>7</em>(8), 1190-1191. (<a href='https://doi.org/10.1038/s42256-025-01081-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By integrating multi-dimensional data with deep learning, a new method known as ImmuScope predicts both major histocompatibility complex class II (MHC-II) presentation and T helper cell immunogenicity. ImmuScope shows potential to accelerate neoantigen discovery and vaccine design.},
  archive      = {J_NATMI},
  author       = {Liu, Yuan and Han, Leng},
  doi          = {10.1038/s42256-025-01081-z},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1190-1191},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mapping t helper cell targets with deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards responsible geospatial foundation models. <em>NATMI</em>, <em>7</em>(8), 1189. (<a href='https://doi.org/10.1038/s42256-025-01106-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen a surge in geospatial artificial intelligence models, with promising applications in ecological and environmental monitoring tasks. Further work should also focus on the sustainable development of such models.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01106-7},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {1189},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards responsible geospatial foundation models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Author correction: End-to-end cryo-EM complex structure determination with high accuracy and ultra-fast speed. <em>NATMI</em>, <em>7</em>(7), 1187. (<a href='https://doi.org/10.1038/s42256-025-01094-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Wang, Jue and Tan, Cheng and Gao, Zhangyang and Zhang, Guijun and Zhang, Yang and Li, Stan Z.},
  doi          = {10.1038/s42256-025-01094-8},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1187},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: End-to-end cryo-EM complex structure determination with high accuracy and ultra-fast speed},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying multi-sample network inference from prior knowledge and omics data with CORNETO. <em>NATMI</em>, <em>7</em>(7), 1168-1186. (<a href='https://doi.org/10.1038/s42256-025-01069-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding biological systems requires methods that extract interpretable insights from omics data. Networks offer a natural abstraction by representing molecules as vertices and their interactions as edges, providing a foundation for constructing context-specific models tailored to particular conditions—an essential step in many biological analyses. Most existing approaches fall into one of two categories: machine learning methods, which offer strong predictive power but lack interpretability and require large datasets, and knowledge-based methods, which are more interpretable but designed for analysing individual samples and difficult to generalize. Here we present CORNETO, a unified mathematical framework that generalizes a wide variety of methods that learn biological networks from omics data and prior knowledge. CORNETO reformulates these methods as mixed-integer optimization problems using network flows and structured sparsity, enabling joint inference across multiple samples. This improves the discovery of both shared and sample-specific molecular mechanisms while yielding sparser, more interpretable solutions. CORNETO supports a range of prior knowledge structures, including undirected, directed and signed (hyper)graphs. It extends a broad class of approaches, ranging from Steiner trees to flux balance analysis, within a unified optimization-based interface. We demonstrate CORNETO’s utility across diverse biological contexts, including signalling, metabolism and integration with biologically informed deep learning. We provide CORNETO as an open-source Python library for flexible network modelling. CORNETO is a unified mathematical framework and software that integrates prior knowledge with omics data to jointly infer context-specific signalling, metabolic and protein networks across multiple samples, boosting interpretability and accuracy.},
  archive      = {J_NATMI},
  author       = {Rodriguez-Mier, Pablo and Garrido-Rodriguez, Martin and Gabor, Attila and Saez-Rodriguez, Julio},
  doi          = {10.1038/s42256-025-01069-9},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1168-1186},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Unifying multi-sample network inference from prior knowledge and omics data with CORNETO},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing biomolecular understanding and design following human instructions. <em>NATMI</em>, <em>7</em>(7), 1154-1167. (<a href='https://doi.org/10.1038/s42256-025-01064-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and designing biomolecules, such as proteins and small molecules, is central to advancing drug discovery, synthetic biology and enzyme engineering. Recent breakthroughs in artificial intelligence have revolutionized biomolecular research, achieving remarkable accuracy in biomolecular prediction and design. However, a critical gap remains between artificial intelligence’s computational capabilities and researchers’ intuitive goals, particularly in using natural language to bridge complex tasks with human intentions. Large language models have shown potential to interpret human intentions, yet their application to biomolecular research remains nascent due to challenges including specialized knowledge requirements, multimodal data integration, and semantic alignment between natural language and biomolecules. To address these limitations, we present InstructBioMol, a large language model designed to bridge natural language and biomolecules through a comprehensive any-to-any alignment of natural language, molecules and proteins. This model can integrate multimodal biomolecules as the input, and enable researchers to articulate design goals in natural language, providing biomolecular outputs that meet precise biological needs. Experimental results demonstrate that InstructBioMol can understand and design biomolecules following human instructions. In particular, it can generate drug molecules with a 10% improvement in binding affinity and design enzymes that achieve an enzyme–substrate pair prediction score of 70.4. This highlights its potential to transform real-world biomolecular research. InstructBioMol, a multimodal large language model that achieves any-to-any alignment between human instructions and biomolecules, can effectively leverage natural language to connect complex biomolecular tasks with human intentions.},
  archive      = {J_NATMI},
  author       = {Zhuang, Xiang and Ding, Keyan and Lyu, Tianwen and Jiang, Yinuo and Li, Xiaotong and Xiang, Zhuoyi and Wang, Zeyuan and Qin, Ming and Feng, Kehua and Wang, Jike and Zhang, Qiang and Chen, Huajun},
  doi          = {10.1038/s42256-025-01064-0},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1154-1167},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Advancing biomolecular understanding and design following human instructions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to adapt through bio-inspired gait strategies for versatile quadruped locomotion. <em>NATMI</em>, <em>7</em>(7), 1141-1153. (<a href='https://doi.org/10.1038/s42256-025-01065-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots must adapt their gait to navigate unpredictable environments, a challenge that animals master with ease. However, most deep reinforcement learning (DRL) approaches to quadruped locomotion rely on a fixed gait, limiting adaptability to changes in terrain and dynamic state. Here we show that integrating three core principles of animal locomotion-gait transition strategies, gait memory and real-time motion adjustments enables a DRL control framework to fluidly switch among multiple gaits and recover from instability, all without external sensing. Our framework is guided by biomechanics-inspired metrics that capture efficiency, stability and system limits, which are unified to inform optimal gait selection. The resulting framework achieves blind zero-shot deployment across diverse, real-world terrains and substantially outperforms baseline controllers. By embedding biological principles into data-driven control, this work marks a step towards robust, efficient and versatile robotic locomotion, highlighting how animal motor intelligence can shape the next generation of adaptive machines. Humphreys and Zhou present a learning-based robot control framework inspired by animal gait mechanisms that enables quadruped robots to generalize to diverse real-world terrains, transition between gaits and recover from instability.},
  archive      = {J_NATMI},
  author       = {Humphreys, Joseph and Zhou, Chengxu},
  doi          = {10.1038/s42256-025-01065-z},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1141-1153},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning to adapt through bio-inspired gait strategies for versatile quadruped locomotion},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing deep learning-based field reconstruction with a differentiable learning framework. <em>NATMI</em>, <em>7</em>(7), 1129-1140. (<a href='https://doi.org/10.1038/s42256-025-01063-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accurate reconstructions of complex high-dimensional fields from sparse sensors remains a long-standing challenge. Frequently, reconstruction performance is mainly constrained by models and placement. The placement of sparse and prohibitive experimental sensors restricts information quality, resulting in formidable reconstruction tasks. Despite deep learning-based models having made strides, they typically lack the ability to co-optimize sensor placement. The joint optimization of high-dimensional neural network parameters versus low-dimensional sensor placement further poses significant difficulties. Here we present a general bilevel differentiable learning framework that effectively integrates models with sensor placement optimization (DSPO), enabling the dynamical search for the placement and accurate global field reconstruction. Within this framework, models are complemented with a differentiable operator to achieve the differentiability of placement. A gradient-based optimizer further empowers models by dynamically updating placement. The alternating optimization strategy is adopted to efficiently solve the joint optimization. We demonstrate the efficiency and generalizability of the DSPO on baseline models across various scenarios, including periodic and acyclic physical fields, regular and irregular grid datasets, and noisy and noiseless observations. Our results show that the DSPO significantly improves the reconstruction accuracy of models and robustness and advances baseline models comparable with the state-of-the-art performance. Our framework provides a new and general paradigm for the practical use of neural networks and placement optimization techniques for real-world applications. Accurate reconstruction of complex high-dimensional fields from sparse sensors remains a challenge. A differentiable learning framework is introduced, which enables sensor placement optimization and enhanced field reconstruction.},
  archive      = {J_NATMI},
  author       = {Liu, Xu and Peng, Wei and Zhang, Xiaoya and Zhao, Xiaoyu and Zhou, Weien and Yao, Wen and Chen, Xiaoqian},
  doi          = {10.1038/s42256-025-01063-1},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1129-1140},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Enhancing deep learning-based field reconstruction with a differentiable learning framework},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioinspired trajectory modulation for effective slip control in robot manipulation. <em>NATMI</em>, <em>7</em>(7), 1119-1128. (<a href='https://doi.org/10.1038/s42256-025-01062-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring a stable grasp during robotic manipulation is essential for dexterous and reliable performance. Traditionally, slip control has relied on grip force modulation. Here we show that trajectory modulation provides an effective alternative for slip prevention in certain robotic manipulation tasks. We develop and compare a slip control policy based on trajectory modulation with a conventional grip-force-based approach. Our results demonstrate that trajectory modulation can significantly outperform grip force control in specific scenarios, highlighting its potential as a robust slip control strategy. Furthermore, we show that, similar to humans, incorporating a data-driven action-conditioned forward model within a model predictive control framework is key to optimizing trajectory modulation for slip prevention. These findings introduce a predictive control framework leveraging trajectory adaptation, offering a new perspective on slip mitigation. This approach enhances grasp stability in dynamic and unstructured environments, improving the adaptability of robotic systems across various applications. When a robot grips and moves a delicate object, it can slip from grasp. Instead of gripping the object with more force, a method is proposed here to move the object in a way that prevents slippage.},
  archive      = {J_NATMI},
  author       = {Nazari, Kiyanoush and Mandil, Willow and Santello, Marco and Park, Seongjun and Ghalamzan-E, Amir},
  doi          = {10.1038/s42256-025-01062-2},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1119-1128},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bioinspired trajectory modulation for effective slip control in robot manipulation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving diffusion-based protein backbone generation with global-geometry-aware latent encoding. <em>NATMI</em>, <em>7</em>(7), 1104-1118. (<a href='https://doi.org/10.1038/s42256-025-01059-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global structural properties of a protein, such as shape, fold and topology, strongly affect its function. Although recent breakthroughs in diffusion-based generative models have greatly advanced de novo protein design, particularly in generating diverse and realistic structures, it remains challenging to design proteins of specific geometries without residue-level control over the topological details. A more practical, top-down approach is needed for prescribing the overall geometric arrangements of secondary structure elements in the generated protein structures. In response, we propose TopoDiff, an unsupervised framework that learns and exploits a global-geometry-aware latent representation, enabling both unconditional and controllable diffusion-based protein generation. Trained on the Protein Data Bank and CATH datasets, the structure encoder embeds protein global geometries into a 32-dimensional latent space, from which latent codes sampled by the latent sampler serve as informative conditions for the diffusion-based backbone decoder. In benchmarks against existing baselines, TopoDiff demonstrates comparable performance on established metrics including designability, diversity and novelty, as well as markedly improves coverage over the fold types of natural proteins in the CATH dataset. Moreover, latent conditioning enables versatile manipulations at the global-geometry level to control the generated protein structures, through which we derived a number of novel folds of mainly beta proteins with comprehensive experimental validation. A variational-autoencoder-based diffusion architecture that enables topological controls on the diffusion-based protein structure generation is proposed. As a result, novel folds of mainly beta proteins can be designed with experimental validation.},
  archive      = {J_NATMI},
  author       = {Zhang, Yuyang and Liu, Yuhang and Ma, Zinnia and Li, Min and Xu, Chunfu and Gong, Haipeng},
  doi          = {10.1038/s42256-025-01059-x},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1104-1118},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Improving diffusion-based protein backbone generation with global-geometry-aware latent encoding},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end cryo-EM complex structure determination with high accuracy and ultra-fast speed. <em>NATMI</em>, <em>7</em>(7), 1091-1103. (<a href='https://doi.org/10.1038/s42256-025-01056-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While cryogenic-electron microscopy yields high-resolution density maps for complex structures, accurate determination of the corresponding atomic structures still necessitates significant expertise and labour-intensive manual interpretation. Recently, artificial intelligence-based methods have emerged to streamline this process; however, several challenges persist. First, existing methods typically require multi-stage training and inference, causing inefficiencies and inconsistency. Second, these approaches often encounter bias and incur substantial computational costs in aligning predicted atomic coordinates with sequence. Last, due to the limitations of available datasets, previous studies struggle to generalize effectively to complicated and unseen test data. Here, in response to these challenges, we introduce end-to-end and efficient CryoFold (E3-CryoFold), a deep learning method that enables end-to-end training and one-shot inference. E3-CryoFold uses three-dimensional and sequence transformers to extract features from density maps and sequences, using cross-attention modules to integrate the two modalities. Additionally, it uses an SE(3) graph neural network to construct atomic structures based on extracted features. E3-CryoFold incorporates a pretraining stage, during which models are trained on simulated density maps derived from Protein Data Bank structures. Empirical results demonstrate that E3-CryoFold improves the average template modelling score of the generated structures by 400% as compared to Cryo2Struct and significantly outperforms ModelAngelo, while achieving this huge improvement using merely one-thousandth of the inference time required by these methods. Thus, E3-CryoFold represents a robust, streamlined and cohesive framework for cryogenic-electron microscopy structure determination. Wang et al. present E3-CryoFold, a deep learning method for cryo-EM structure determination that enables end-to-end training and one-shot inference This method reduces inference times while boosting template modelling scores against comparable methods.},
  archive      = {J_NATMI},
  author       = {Wang, Jue and Tan, Cheng and Gao, Zhangyang and Zhang, Guijun and Zhang, Yang and Li, Stan Z.},
  doi          = {10.1038/s42256-025-01056-0},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1091-1103},
  shortjournal = {Nat. Mach. Intell.},
  title        = {End-to-end cryo-EM complex structure determination with high accuracy and ultra-fast speed},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based reinforcement learning for ultrasound-driven autonomous microrobots. <em>NATMI</em>, <em>7</em>(7), 1076-1090. (<a href='https://doi.org/10.1038/s42256-025-01054-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is emerging as a powerful tool for microrobots control, as it enables autonomous navigation in environments where classical control approaches fall short. However, applying reinforcement learning to microrobotics is difficult due to the need for large training datasets, the slow convergence in physical systems and poor generalizability across environments. These challenges are amplified in ultrasound-actuated microrobots, which require rapid, precise adjustments in high-dimensional action space, which are often too complex for human operators. Addressing these challenges requires sample-efficient algorithms that adapt from limited data while managing complex physical interactions. To meet these challenges, we implemented model-based reinforcement learning for autonomous control of an ultrasound-driven microrobot, which learns from recurrent imagined environments. Our non-invasive, AI-controlled microrobot offers precise propulsion and efficiently learns from images in data-scarce environments. On transitioning from a pretrained simulation environment, we achieved sample-efficient collision avoidance and channel navigation, reaching a 90% success rate in target navigation across various channels within an hour of fine-tuning. Moreover, our model initially generalized successfully in 50% of tasks in new environments, improving to over 90% with 30 min of further training. We further demonstrated real-time manipulation of microrobots in complex vasculatures under both static and flow conditions, thus underscoring the potential of AI to revolutionize microrobotics in biomedical applications. Medany et al. present AI-driven microrobots that use ultrasound propulsion to learn how to navigate complex environments. These microrobots achieve 90% success after minimal training and adapt rapidly, showing promise for biomedical applications.},
  archive      = {J_NATMI},
  author       = {Medany, Mahmoud and Piglia, Lorenzo and Achenbach, Liam and Mukkavilli, S. Karthik and Ahmed, Daniel},
  doi          = {10.1038/s42256-025-01054-2},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1076-1090},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Model-based reinforcement learning for ultrasound-driven autonomous microrobots},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating multimodal cancer data using deep latent variable path modelling. <em>NATMI</em>, <em>7</em>(7), 1053-1075. (<a href='https://doi.org/10.1038/s42256-025-01052-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancers are commonly characterized by a complex pathology encompassing genetic, microscopic and macroscopic features, which can be probed individually using imaging and omics technologies. Integrating these data to obtain a full understanding of pathology remains challenging. We introduce a method called deep latent variable path modelling, which combines the representational power of deep learning with the capacity of path modelling to identify relationships between interacting elements in a complex system. To evaluate the capabilities of deep latent variable path modelling, we initially trained a model to map dependencies between single-nucleotide variant, methylation profiles, microRNA sequencing, RNA sequencing and histological data using breast cancer data from The Cancer Genome Atlas. This method exhibited superior performance in mapping associations between data types compared with classical path modelling. We additionally performed successful applications of the model to stratify single-cell data, identify synthetic lethal interactions using CRISPR–Cas9 screens derived from cell lines and detect histologic–transcriptional associations using spatial transcriptomic data. Results from each of these data types can then be understood with reference to the same holistic model of illness. Cancers have complex genetic, microscopic and macroscopic features analysed using imaging and omics technologies, but integrating these data is challenging. A framework combining deep learning and path modelling to integrate imaging and omics data is presented, producing a unified model of disease.},
  archive      = {J_NATMI},
  author       = {Ing, Alex and Andrades, Alvaro and Cosenza, Marco Raffaele and Korbel, Jan O.},
  doi          = {10.1038/s42256-025-01052-4},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1053-1075},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Integrating multimodal cancer data using deep latent variable path modelling},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning modelling for multi-order human visual motion processing. <em>NATMI</em>, <em>7</em>(7), 1037-1052. (<a href='https://doi.org/10.1038/s42256-025-01068-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual motion perception is a key function for agents interacting with their environment. Although recent advances in optical flow estimation using deep neural networks have surpassed human-level accuracy, a notable disparity remains. In addition to limitations in luminance-based first-order motion perception, humans can perceive motions in higher-order features—an ability lacking in conventional optical flow models that rely on intensity conservation law. To address this, we propose a dual-pathway model that mimics the cortical V1-MT motion processing pathway. It uses a trainable motion energy sensor bank and a recurrent graph network to process luminance-based motion and incorporates an additional sensing pathway with nonlinear preprocessing using a multilayer 3D CNN block to capture higher-order motion signals. We hypothesize that higher-order mechanisms are critical for estimating robust object motion in natural environments that contain complex optical fluctuations, for example, highlights on glossy surfaces. By training on motion datasets with varying material properties of moving objects, our dual-pathway model naturally developed the capacity to perceive multi-order motion as humans do. The resulting model effectively aligns with biological systems while generalizing both luminance-based and higher-order motion phenomena in natural scenes. Sun and colleagues present a brain-inspired dual-pathway model that learns to perceive both first- (luminance-based) and second-order (feature-based) motion, achieving human-like performance through training on naturalistic environments and diverse materials.},
  archive      = {J_NATMI},
  author       = {Sun, Zitang and Chen, Yen-Ju and Yang, Yung-Hao and Li, Yuan and Nishida, Shin’ya},
  doi          = {10.1038/s42256-025-01068-w},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1037-1052},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning modelling for multi-order human visual motion processing},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing metamaterials with programmable nonlinear responses and geometric constraints in graph space. <em>NATMI</em>, <em>7</em>(7), 1023-1036. (<a href='https://doi.org/10.1038/s42256-025-01067-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in data-driven design and additive manufacturing have substantially accelerated the development of truss metamaterials—three-dimensional truss networks—offering exceptional mechanical properties at a fraction of the weight of conventional solids. While existing design approaches can generate metamaterials with target linear properties, such as elasticity, they struggle to capture complex nonlinear behaviours and to incorporate geometric and manufacturing constraints—including defects—crucial for engineering applications. Here we present GraphMetaMat, an autoregressive graph-based framework capable of designing three-dimensional truss metamaterials with programmable nonlinear responses, originating from hard-to-capture physics such as buckling, frictional contact and wave propagation, along with arbitrary geometric constraints and defect tolerance. Integrating graph neural networks, physics biases, imitation learning, reinforcement learning and tree search, we show that GraphMetaMat can target stress–strain curves across four orders of magnitude and vibration transmission responses with varying attenuation gaps, unattainable by previous methods. We further demonstrate the use of GraphMetaMat for the inverse design of novel material topologies with tailorable high-energy absorption and vibration damping that outperform existing polymeric foams and phononic crystals, potentially suitable for protective equipment and electric vehicles. This work sets the stage for the automatic design of manufacturable, defect-tolerant materials with on-demand functionalities. Maurizi et al. introduce GraphMetaMat, a graph-based AI framework for designing 3D metamaterials with programmable nonlinear responses, enabling the inverse design of new structural and acoustic behaviours despite fabrication defects and limits.},
  archive      = {J_NATMI},
  author       = {Maurizi, Marco and Xu, Derek and Wang, Yu-Tong and Yao, Desheng and Hahn, David and Oudich, Mourad and Satpati, Anish and Bauchy, Mathieu and Wang, Wei and Sun, Yizhou and Jing, Yun and Zheng, Xiaoyu Rayne},
  doi          = {10.1038/s42256-025-01067-x},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1023-1036},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Designing metamaterials with programmable nonlinear responses and geometric constraints in graph space},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models to accelerate organic chemistry synthesis. <em>NATMI</em>, <em>7</em>(7), 1010-1022. (<a href='https://doi.org/10.1038/s42256-025-01066-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical synthesis, as a foundational methodology in the creation of transformative molecules, exerts substantial influence across diverse sectors from life sciences to materials and energy. Current chemical synthesis practices emphasize laborious and costly trial-and-error workflows, underscoring the urgent needs for advanced AI assistants. Recently, large language models, typified by GPT-4, have been introduced as an efficient tool to facilitate scientific research. Here we present Chemma, a fully fine-tuned large language model with 1.28 million pairs of questions and answers about reactions, as an assistant to accelerate organic chemistry synthesis. Chemma surpasses the best-known results in multiple chemical tasks, for example, single-step retrosynthesis and yield prediction, which highlights the potential of general artificial intelligence for organic chemistry. By predicting yields across the experimental reaction space, Chemma significantly improves the reaction exploration capability of Bayesian optimization. More importantly, integrated in an active learning framework, Chemma exhibits advanced potentials of autonomously experimental exploration and optimization in open reaction spaces. For an unreported Suzuki–Miyaura cross-coupling reaction of cyclic aminoboronates and aryl halides for the synthesis of α-aryl N-heterocycles, the human–artificial intelligence collaboration successfully explored a suitable ligand (tri(1-adamantyl)phosphine) and solvent (1,4-dioxane) within only 15 runs, achieving an isolated yield of 67%. These results reveal that, without quantum-chemical calculations, Chemma can comprehend and extract chemical insights from reaction data, in a manner akin to human experts. This work opens avenues for accelerating organic chemistry synthesis with adapted large language models. Large language models (LLMs) can be useful tools for science, but they often lack expert understanding of complex domains that they were not trained on. Zhang and colleagues fine-tuned a LLaMA-2-7b-based LLM with questions on organic chemistry reactions.},
  archive      = {J_NATMI},
  author       = {Zhang, Yu and Han, Yang and Chen, Shuai and Yu, Ruijie and Zhao, Xin and Liu, Xianbin and Zeng, Kaipeng and Yu, Mengdi and Tian, Jidong and Zhu, Feng and Yang, Xiaokang and Jin, Yaohui and Xu, Yanyan},
  doi          = {10.1038/s42256-025-01066-y},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {1010-1022},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models to accelerate organic chemistry synthesis},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining grasping and rotation with a spherical robot hand mechanism. <em>NATMI</em>, <em>7</em>(7), 999-1009. (<a href='https://doi.org/10.1038/s42256-025-01039-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object reorientation is a key functionality in dexterous manipulation tasks, such as turning a doorknob. This is usually done on robot arms with a simple gripper and a three-degrees-of-freedom wrist. However, wrists are mechanically complex, and the wrist axes are often far away from the grasped object, resulting in coupled translations that need to be compensated with awkward whole-arm motions. We present a robot hand mechanism based on a spherical parallel architecture that can both grasp and rotate a wide range of objects in all three axes, combining much of the function of traditional wrists and grippers. The hand mechanism allows for pure spherical rotations of the grasped object about a known fixed point close to the object, thereby avoiding parasitic translations and inefficient arm motions. This point also stays fixed with respect to the hand, and is independent of the object shape, pose or initial grasp. We detail the spherical parallel design and workspace model of the wrist-like Sphinx hand, validate its performance for lower-degrees-of-freedom robot arms without traditional wrists and show that it can accurately rotate the grasped objects over large angles with basic open-loop control. Developing robot hands for unstructured human environments is a major challenge. A robotic hand that combines grasping and wrist-like rotation in one mechanism for more efficient and versatile object manipulation is presented.},
  archive      = {J_NATMI},
  author       = {Patel, Vatsal V. and Dollar, Aaron M.},
  doi          = {10.1038/s42256-025-01039-1},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {999-1009},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Combining grasping and rotation with a spherical robot hand mechanism},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling large language models for real-world materials discovery. <em>NATMI</em>, <em>7</em>(7), 991-998. (<a href='https://doi.org/10.1038/s42256-025-01058-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) create exciting possibilities to accelerate scientific discovery and knowledge dissemination in materials science. While LLMs have been successfully applied to select scientific problems and rudimentary challenges, they currently fall short of being practical materials science tools. In this Perspective, we show relevant failure cases of LLMs in materials science that reveal the current limitations of LLMs related to comprehending and reasoning over complex, interconnected materials science knowledge. Given these shortcomings, we outline a framework for developing materials science LLMs (MatSci-LLMs) that are grounded in domain knowledge, which can enable hypothesis generation followed by hypothesis testing for impactful materials science challenges. The path to attaining performant MatSci-LLMs rests, in large part, on building high-quality, multimodal datasets sourced from scientific literature, where various information extraction challenges persist. As such, we describe key materials science information extraction challenges that need to be overcome to build large-scale, multimodal datasets that capture valuable materials science principles and broader knowledge. Miret and Krishnan discuss the promise of large language models (LLMs) to revolutionize materials discovery via automated processing of complex, interconnected, multimodal materials data. They also consider critical limitations and research opportunities needed to unblock LLMs for breakthroughs in materials science.},
  archive      = {J_NATMI},
  author       = {Miret, Santiago and Krishnan, N. M. Anoop},
  doi          = {10.1038/s42256-025-01058-y},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {991-998},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Enabling large language models for real-world materials discovery},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new eye on inherited retinal disease. <em>NATMI</em>, <em>7</em>(7), 989-990. (<a href='https://doi.org/10.1038/s42256-025-01079-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inherited retinal diseases are both numerous and diverse, but all arise from genetic mutations leading to retinal degeneration. Through the use of modern diagnostic tools, accurate genotype prediction is now possible using high-resolution imaging techniques alone, facilitating improved screening and genetic variant prioritization.},
  archive      = {J_NATMI},
  author       = {Fenner, Beau J. and Cheng, Ching-Yu},
  doi          = {10.1038/s42256-025-01079-7},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {989-990},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A new eye on inherited retinal disease},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data meets prior knowledge for interpretable mechanistic inference in biology. <em>NATMI</em>, <em>7</em>(7), 987-988. (<a href='https://doi.org/10.1038/s42256-025-01075-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A unified optimization framework, CORNETO, introduces a versatile approach to knowledge-driven biological network inference, bringing machine learning sensibilities to systems biology.},
  archive      = {J_NATMI},
  author       = {Gomez-Cabrero, David and Tegnér, Jesper N.},
  doi          = {10.1038/s42256-025-01075-x},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {987-988},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Data meets prior knowledge for interpretable mechanistic inference in biology},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal interatomic potentials shine in finding crystal structures. <em>NATMI</em>, <em>7</em>(7), 985-986. (<a href='https://doi.org/10.1038/s42256-025-01061-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various machine learning models have been developed in recent years for the discovery of crystal structures. Matbench Discovery, a new benchmark, offers an efficient way to identify the most promising architectures.},
  archive      = {J_NATMI},
  author       = {Li, Ju},
  doi          = {10.1038/s42256-025-01061-3},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {985-986},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Universal interatomic potentials shine in finding crystal structures},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predictive framework for liquid electrolytes takes root with BAMBOO. <em>NATMI</em>, <em>7</em>(7), 983-984. (<a href='https://doi.org/10.1038/s42256-025-01071-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the macroscopic properties of molecular liquids from first principles is a major challenge owing to the disordered nature of liquids and the weak link between microscopic forces and thermodynamic observables. A new workflow called BAMBOO produces accurate and transferable machine learning interatomic potential simulations of liquid electrolytes.},
  archive      = {J_NATMI},
  author       = {Magdău, Ioan-Bogdan and Csányi, Gábor},
  doi          = {10.1038/s42256-025-01071-1},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {983-984},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A predictive framework for liquid electrolytes takes root with BAMBOO},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emotional risks of AI companions demand attention. <em>NATMI</em>, <em>7</em>(7), 981-982. (<a href='https://doi.org/10.1038/s42256-025-01093-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of AI into mental health and wellness domains has outpaced regulation and research.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01093-9},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {981-982},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Emotional risks of AI companions demand attention},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Why design choices matter in recommender systems. <em>NATMI</em>, <em>7</em>(6), 979-980. (<a href='https://doi.org/10.1038/s42256-025-01043-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the RecSys ’24 Challenge, participants tackled news recommendations using a large-scale Danish dataset. Although the top-performing models achieved similar accuracy scores, they produced markedly different results on beyond-accuracy metrics, highlighting the need for further research into the normative alignment of recommender systems.},
  archive      = {J_NATMI},
  author       = {Kruse, Johannes and Lindskow, Kasper and Andersen, Michael Riis and Frellsen, Jes},
  doi          = {10.1038/s42256-025-01043-5},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {979-980},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Why design choices matter in recommender systems},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next-generation phenotyping of inherited retinal diseases from multimodal imaging with Eye2Gene. <em>NATMI</em>, <em>7</em>(6), 967-978. (<a href='https://doi.org/10.1038/s42256-025-01040-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare eye diseases such as inherited retinal diseases (IRDs) are challenging to diagnose genetically. IRDs are typically monogenic disorders and represent a leading cause of blindness in children and working-age adults worldwide. A growing number are now being targeted in clinical trials, with approved treatments increasingly available. However, access requires a genetic diagnosis to be established sufficiently early. Critically, the timely identification of a genetic cause remains challenging. We demonstrate that a deep learning algorithm, Eye2Gene, trained on a large multimodal imaging dataset of individuals with IRDs (n = 2,451) and externally validated on data provided by five different clinical centres, provides better-than-expert-level top-five accuracy of 83.9% for supporting genetic diagnosis for the 63 most common genetic causes. We demonstrate that Eye2Gene’s next-generation phenotyping can increase diagnostic yield by improving screening for IRDs, phenotype-driven variant prioritization and automatic similarity matching in phenotypic space to identify new genes. Eye2Gene is accessible online ( app.eye2gene.com ) for research purposes. Eye2Gene’s next-generation phenotyping of multimodal images increases diagnostic yield for inherited retinal diseases by improving screening, phenotype-driven variant prioritization and automatic similarity matching in phenotypic space to drive gene discovery.},
  archive      = {J_NATMI},
  author       = {Pontikos, Nikolas and Woof, William A. and Lin, Siying and Ghoshal, Biraja and Mendes, Bernardo S. and Veturi, Advaith and Nguyen, Quang and Javanmardi, Behnam and Georgiou, Michalis and Hustinx, Alexander and Ibarra-Arellano, Miguel A. and Moghul, Ismail and Liu, Yichen and Pfau, Kristina and Pfau, Maximilian and Shah, Mital and Yu, Jing and Al-Khuzaei, Saoud and Wagner, Siegfried K. and Daich Varela, Malena and Cabral de Guimarães, Thales Antonio and Sen, Sagnik and Naik, Gunjan and Sumodhee, Dayyanah and Fu, Dun Jack and Kabiri, Nathaniel and Furman, Jennifer and Liefers, Bart and Lee, Aaron Y. and De Silva, Samantha R. and Marques, Caio and Motta, Fabiana and Fujinami-Yokokawa, Yu and Hardcastle, Alison J. and Arno, Gavin and Lorenz, Birgit and Herrmann, Philipp and Fujinami, Kaoru and Sallum, Juliana and Madhusudhan, Savita and Downes, Susan M. and Holz, Frank G. and Balaskas, Konstantinos and Webster, Andrew R. and Mahroo, Omar A. and Krawitz, Peter M. and Michaelides, Michel},
  doi          = {10.1038/s42256-025-01040-8},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {967-978},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Next-generation phenotyping of inherited retinal diseases from multimodal imaging with Eye2Gene},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning vision-based agile flight via differentiable physics. <em>NATMI</em>, <em>7</em>(6), 954-966. (<a href='https://doi.org/10.1038/s42256-025-01048-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous aerial robot swarms promise transformative applications, from planetary exploration to search and rescue in complex environments. However, navigating these swarms efficiently in unknown and cluttered spaces without bulky sensors, heavy computation or constant communication between robots remains a major research problem. This paper introduces an end-to-end approach that combines deep learning with first-principles physics through differentiable simulation to enable autonomous navigation by several aerial robots through complex environments at high speed. Our approach directly optimizes a neural network control policy by backpropagating loss gradients through the robot simulation using a simple point-mass physics model. Despite this simplicity, our method excels in both multi-agent and single-agent applications. In multi-agent scenarios, our system demonstrates self-organized behaviour, which enables autonomous coordination without communication or centralized planning. In single-agent scenarios, our system achieved a 90% success rate in navigating through complex unknown environments and demonstrated enhanced robustness compared to previous state-of-the-art approaches. Our system can operate without state estimation and adapt to dynamic obstacles. In real-world forest environments, it navigates at speeds of up to 20 m s−1, doubling the speed of previous imitation-learning-based solutions. Notably, all these capabilities are deployed on a budget-friendly US$21 computer, which costs less than 5% of the GPU-equipped board used in existing systems. Zhang et al. present a differentiable-physics simulation approach that enables autonomous aerial robot swarms to navigate complex environments. High-speed navigation and robust performance in both multi-agent and single-agent scenarios are demonstrated with low-cost hardware platforms.},
  archive      = {J_NATMI},
  author       = {Zhang, Yuang and Hu, Yu and Song, Yunlong and Zou, Danping and Lin, Weiyao},
  doi          = {10.1038/s42256-025-01048-0},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {954-966},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning vision-based agile flight via differentiable physics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized biological foundation model with unified nucleic acid and protein language. <em>NATMI</em>, <em>7</em>(6), 942-953. (<a href='https://doi.org/10.1038/s42256-025-01044-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The language of biology, encoded in DNA, RNA and proteins, forms the foundation of life but remains challenging to decode owing to its complexity. Traditional computational methods often struggle to integrate information across these molecules, limiting a comprehensive understanding of biological systems. Advances in natural language processing with pre-trained models offer possibilities for interpreting biological language. Here we introduce LucaOne, a pre-trained foundation model trained on nucleic acid and protein sequences from 169,861 species. Through large-scale data integration and semi-supervised learning, LucaOne shows an understanding of key biological principles, such as DNA–protein translation. Using few-shot learning, it effectively comprehends the central dogma of molecular biology and performs competitively on tasks involving DNA, RNA or protein inputs. Our results highlight the potential of unified foundation models to address complex biological questions, providing an adaptable framework for bioinformatics research and enhancing the interpretation of life’s complexity. He and colleagues develop LucaOne, a biological foundation model pre-trained on nucleic acid and protein sequences from 169,861 species. It shows an emerging understanding of molecular biology’s central dogma, enhancing bioinformatics analysis and helping explore unknown aspects of molecular biology.},
  archive      = {J_NATMI},
  author       = {He, Yong and Fang, Pan and Shan, Yongtao and Pan, Yuanfei and Wei, Yanhong and Chen, Yichang and Chen, Yihao and Liu, Yi and Zeng, Zhenyu and Zhou, Zhan and Zhu, Feng and Holmes, Edward C. and Ye, Jieping and Li, Jun and Shu, Yuelong and Shi, Mang and Li, Zhaorong},
  doi          = {10.1038/s42256-025-01044-4},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {942-953},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generalized biological foundation model with unified nucleic acid and protein language},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal conversational agent for DNA, RNA and protein tasks. <em>NATMI</em>, <em>7</em>(6), 928-941. (<a href='https://doi.org/10.1038/s42256-025-01047-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models are thriving, powering conversational agents that assist and empower humans to solve a number of tasks. Recently, these models were extended to support additional modalities including vision, audio and video, demonstrating impressive capabilities across multiple domains, including healthcare. Still, conversational agents remain limited in biology as they cannot yet fully comprehend biological sequences. Meanwhile, high-performance foundation models for biological sequences have been built through self-supervision over sequencing data, but these need to be fine-tuned for each specific application, preventing generalization between tasks. In addition, these models are not conversational, which limits their utility to users with coding capabilities. Here we propose to bridge the gap between biology foundation models and conversational agents by introducing ChatNT, a multimodal conversational agent with an advanced understanding of biological sequences. ChatNT achieves new state-of-the-art results on the Nucleotide Transformer benchmark while being able to solve all tasks at once, in English, and to generalize to unseen questions. In addition, we have curated a set of more biologically relevant instruction tasks from DNA, RNA and proteins, spanning multiple species, tissues and biological processes. ChatNT reaches performance on par with state-of-the-art specialized methods on those tasks. We also present a perplexity-based technique to help calibrate the confidence of our model predictions. By applying attribution methods through the English decoder and DNA encoder, we demonstrate that ChatNT’s answers are based on biologically coherent features such as detecting the promoter TATA motif or splice site dinucleotides. Our framework for genomics instruction tuning can be extended to more tasks and data modalities (for example, structure and imaging), making it a widely applicable tool for biology. ChatNT provides a potential direction for building generally capable agents that understand biology from first principles while being accessible to users with no coding background. De Almeida, Richard and colleagues leverage transfer learning to create ChatNT, a multimodal conversational agent for DNA, RNA and protein sequences that can be instructed in natural language.},
  archive      = {J_NATMI},
  author       = {de Almeida, Bernardo P. and Richard, Guillaume and Dalla-Torre, Hugo and Blum, Christopher and Hexemer, Lorenz and Pandey, Priyanka and Laurent, Stefan and Rajesh, Chandana and Lopez, Marie and Laterre, Alexandre and Lang, Maren and Şahin, Uğur and Beguir, Karim and Pierrot, Thomas},
  doi          = {10.1038/s42256-025-01047-1},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {928-941},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A multimodal conversational agent for DNA, RNA and protein tasks},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A process-centric manipulation taxonomy for the organization, classification and synthesis of tactile robot skills. <em>NATMI</em>, <em>7</em>(6), 916-927. (<a href='https://doi.org/10.1038/s42256-025-01045-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite decades of research in robotic manipulation, only a few autonomous manipulation skills are currently used. Traditional and machine-learning-based end-to-end solutions have shown substantial progress but still struggle to generate reliable manipulation skills for difficult processes like insertion or bending material. To facilitate the deployment and learning of tactile robot manipulation skills, we introduce here a taxonomy based on formal process specifications provided by experts, which assigns a suitable skill to a given process. We validated the inherent scalability of the taxonomy on 28 different skills from industrial application domains. The experimental results had success rates close to 100%, even under goal pose disturbances, with high performance attained by the skill models in terms of execution times and contact moments in partially known environments. The basic elements of the models are reusable and facilitate skill-learning to optimize control performance. Like established curricula for human trainees, this framework could provide a comprehensive platform that enables robots to acquire relevant manipulation skills and act as a catalyst to propel automation beyond its current capabilities. Despite decades of research, autonomous robotic manipulation skills remain limited, especially for complex tasks such as insertion or bending of materials. Johannsmeier et al. introduce a taxonomy of manipulation skills that synthesizes tactile behaviours from process specifications, achieving high robustness and performance with minimal learning time.},
  archive      = {J_NATMI},
  author       = {Johannsmeier, Lars and Schneider, Samuel and Li, Yanan and Burdet, Etienne and Haddadin, Sami},
  doi          = {10.1038/s42256-025-01045-3},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {916-927},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A process-centric manipulation taxonomy for the organization, classification and synthesis of tactile robot skills},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust virtual staining of landmark organelles with cytoland. <em>NATMI</em>, <em>7</em>(6), 901-915. (<a href='https://doi.org/10.1038/s42256-025-01046-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlative live-cell imaging of landmark organelles—such as nuclei, nucleoli, cell membranes, nuclear envelope and lipid droplets—is critical for systems cell biology and drug discovery. However, achieving this with molecular labels alone remains challenging. Virtual staining of multiple organelles and cell states from label-free images with deep neural networks is an emerging solution. Virtual staining frees the light spectrum for imaging molecular sensors, photomanipulation or other tasks. Current methods for virtual staining of landmark organelles often fail in the presence of nuisance variations in imaging, culture conditions and cell types. Here we address this with Cytoland, a collection of models for robust virtual staining of landmark organelles across diverse imaging parameters, cell states and types. These models were trained with self-supervised and supervised pre-training using a flexible convolutional architecture (UNeXt2) and augmentations inspired by image formation of light microscopes. Cytoland models enable virtual staining of nuclei and membranes across multiple cell types—including human cell lines, zebrafish neuromasts, induced pluripotent stem cells (iPSCs) and iPSC-derived neurons—under a range of imaging conditions. We assess models using intensity, segmentation and application-specific measurements obtained from virtually and experimentally stained nuclei and membranes. These models rescue missing labels, correct non-uniform labelling and mitigate photobleaching. We share multiple pre-trained models, open-source software (VisCy) for training, inference and deployment, and the datasets. Ziwen Liu et al. report Cytoland, an approach to train robust models to virtually stain landmark organelles of cells and address the generalization gap of current models. The training pipeline, models and datasets are shared under open-source permissive licences.},
  archive      = {J_NATMI},
  author       = {Liu, Ziwen and Hirata-Miyasaki, Eduardo and Pradeep, Soorya and Rahm, Johanna V. and Foley, Christian and Chandler, Talon and Ivanov, Ivan E. and Woosley, Hunter O. and Lee, See-Chi and Khadka, Sudip and Lao, Tiger and Balasubramanian, Akilandeswari and Marreiros, Rita and Liu, Chad and Januel, Camille and Leonetti, Manuel D. and Aviner, Ranen and Arias, Carolina and Jacobo, Adrian and Mehta, Shalin B.},
  doi          = {10.1038/s42256-025-01046-2},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {901-915},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Robust virtual staining of landmark organelles with cytoland},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding high-resolution touch across robotic hands enables adaptive human-like grasping. <em>NATMI</em>, <em>7</em>(6), 889-900. (<a href='https://doi.org/10.1038/s42256-025-01053-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing robotic hands that adapt to real-world dynamics remains a fundamental challenge in robotics and machine intelligence. Despite notable advances in replicating human-hand kinematics and control algorithms, robotic systems still struggle to match human capabilities in dynamic environments, primarily due to inadequate tactile feedback. To bridge this gap, we present F-TAC Hand, a biomimetic hand featuring high-resolution tactile sensing (0.1-mm spatial resolution) across 70% of its surface area. Through optimized hand design, we overcome traditional challenges in integrating high-resolution tactile sensors while preserving the full range of motion. The hand, powered by our generative algorithm that synthesizes human-like hand configurations, demonstrates robust grasping capabilities in dynamic real-world conditions. Extensive evaluation across 600 real-world trials demonstrates that this tactile-embodied system significantly outperforms non-tactile-informed alternatives in complex manipulation tasks (P &lt; 0.0001). These results provide empirical evidence for the critical role of rich tactile embodiment in developing advanced robotic intelligence, offering promising perspectives on the relationship between physical sensing capabilities and intelligent behaviour. Developing robotic hands that can adapt to real-world dynamics remains a substantial challenge. The authors present an AI system that mimics human-like grasping using full-hand tactile sensing and a sensory–motor feedback mechanism.},
  archive      = {J_NATMI},
  author       = {Zhao, Zihang and Li, Wanlin and Li, Yuyang and Liu, Tengyu and Li, Boren and Wang, Meng and Du, Kai and Liu, Hangxin and Zhu, Yixin and Wang, Qining and Althoefer, Kaspar and Zhu, Song-Chun},
  doi          = {10.1038/s42256-025-01053-3},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {889-900},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Embedding high-resolution touch across robotic hands enables adaptive human-like grasping},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mask-prior-guided denoising diffusion improves inverse protein folding. <em>NATMI</em>, <em>7</em>(6), 876-888. (<a href='https://doi.org/10.1038/s42256-025-01042-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse protein folding generates valid amino acid sequences that can fold into a desired protein structure, with recent deep learning advances showing strong potential and competitive performance. However, challenges remain, such as predicting elements with high structural uncertainty, including disordered regions. To tackle such low-confidence residue prediction, we propose a mask-prior-guided denoising diffusion (MapDiff) framework that accurately captures both structural information and residue interactions for inverse protein folding. MapDiff is a discrete diffusion probabilistic model that iteratively generates amino acid sequences with reduced noise, conditioned on a given protein backbone. To incorporate structural information and residue interactions, we have developed a graph-based denoising network with a mask-prior pretraining strategy. Moreover, in the generative process, we combine the denoising diffusion implicit model with Monte-Carlo dropout to reduce uncertainty. Evaluation on four challenging sequence design benchmarks shows that MapDiff substantially outperforms state-of-the-art methods. Furthermore, the in silico sequences generated by MapDiff closely resemble the physico-chemical and structural characteristics of native proteins across different protein families and architectures. Bai and colleagues present MapDiff, a discrete diffusion-based framework for generating amino acid sequences conditioned on a target protein structure, with strong performance in predicting uncertain regions and achieving high in silico foldability.},
  archive      = {J_NATMI},
  author       = {Bai, Peizhen and Miljković, Filip and Liu, Xianyuan and De Maria, Leonardo and Croasdale-Wood, Rebecca and Rackham, Owen and Lu, Haiping},
  doi          = {10.1038/s42256-025-01042-6},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {876-888},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mask-prior-guided denoising diffusion improves inverse protein folding},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-like object concept representations emerge naturally in multimodal large language models. <em>NATMI</em>, <em>7</em>(6), 860-875. (<a href='https://doi.org/10.1038/s42256-025-01049-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how humans conceptualize and categorize natural objects offers critical insights into perception and cognition. With the advent of large language models (LLMs), a key question arises: can these models develop human-like object representations from linguistic and multimodal data? Here we combined behavioural and neuroimaging analyses to explore the relationship between object concept representations in LLMs and human cognition. We collected 4.7 million triplet judgements from LLMs and multimodal LLMs to derive low-dimensional embeddings that capture the similarity structure of 1,854 natural objects. The resulting 66-dimensional embeddings were stable, predictive and exhibited semantic clustering similar to human mental representations. Remarkably, the dimensions underlying these embeddings were interpretable, suggesting that LLMs and multimodal LLMs develop human-like conceptual representations of objects. Further analysis showed strong alignment between model embeddings and neural activity patterns in brain regions such as the extrastriate body area, parahippocampal place area, retrosplenial cortex and fusiform face area. This provides compelling evidence that the object representations in LLMs, although not identical to human ones, share fundamental similarities that reflect key aspects of human conceptual knowledge. Our findings advance the understanding of machine intelligence and inform the development of more human-like artificial cognitive systems. Multimodal large language models are shown to develop object concept representations similar to those of humans. These representations closely align with neural activity in brain regions involved in object recognition, revealing similarities between artificial intelligence and human cognition.},
  archive      = {J_NATMI},
  author       = {Du, Changde and Fu, Kaicheng and Wen, Bincheng and Sun, Yi and Peng, Jie and Wei, Wei and Gao, Ying and Wang, Shengpei and Zhang, Chuncheng and Li, Jinpeng and Qiu, Shuang and Chang, Le and He, Huiguang},
  doi          = {10.1038/s42256-025-01049-z},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {860-875},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Human-like object concept representations emerge naturally in multimodal large language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimensions underlying the representational alignment of deep neural networks with humans. <em>NATMI</em>, <em>7</em>(6), 848-859. (<a href='https://doi.org/10.1038/s42256-025-01041-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the similarities and differences between humans and artificial intelligence (AI) is an important goal in both computational cognitive neuroscience and machine learning, promising a deeper understanding of human cognition and safer, more reliable AI systems. Much previous work comparing representations in humans and AI has relied on global, scalar measures to quantify their alignment. However, without explicit hypotheses, these measures only inform us about the degree of alignment, not the factors that determine it. To address this challenge, we propose a generic framework to compare human and AI representations, based on identifying latent representational dimensions underlying the same behaviour in both domains. Applying this framework to humans and a deep neural network (DNN) model of natural images revealed a low-dimensional DNN embedding of both visual and semantic dimensions. In contrast to humans, DNNs exhibited a clear dominance of visual over semantic properties, indicating divergent strategies for representing images. Although in silico experiments showed seemingly consistent interpretability of DNN dimensions, a direct comparison between human and DNN representations revealed substantial differences in how they process images. By making representations directly comparable, our results reveal important challenges for representational alignment and offer a means for improving their comparability. An interpretability framework that compares how humans and deep neural networks process images has been presented. Their findings reveal that, unlike humans, deep neural networks focus more on visual properties than semantic ones, highlighting divergent representational strategies.},
  archive      = {J_NATMI},
  author       = {Mahner, Florian P. and Muttenthaler, Lukas and Güçlü, Umut and Hebart, Martin N.},
  doi          = {10.1038/s42256-025-01041-7},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {848-859},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Dimensions underlying the representational alignment of deep neural networks with humans},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework to evaluate machine learning crystal stability predictions. <em>NATMI</em>, <em>7</em>(6), 836-847. (<a href='https://doi.org/10.1038/s42256-025-01055-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid adoption of machine learning in various scientific domains calls for the development of best practices and community agreed-upon benchmarking tasks and metrics. We present Matbench Discovery as an example evaluation framework for machine learning energy models, here applied as pre-filters to first-principles computed data in a high-throughput search for stable inorganic crystals. We address the disconnect between (1) thermodynamic stability and formation energy and (2) retrospective and prospective benchmarking for materials discovery. Alongside this paper, we publish a Python package to aid with future model submissions and a growing online leaderboard with adaptive user-defined weighting of various performance metrics allowing researchers to prioritize the metrics they value most. To answer the question of which machine learning methodology performs best at materials discovery, our initial release includes random forests, graph neural networks, one-shot predictors, iterative Bayesian optimizers and universal interatomic potentials. We highlight a misalignment between commonly used regression metrics and more task-relevant classification metrics for materials discovery. Accurate regressors are susceptible to unexpectedly high false-positive rates if those accurate predictions lie close to the decision boundary at 0 eV per atom above the convex hull. The benchmark results demonstrate that universal interatomic potentials have advanced sufficiently to effectively and cheaply pre-screen thermodynamic stable hypothetical materials in future expansions of high-throughput materials databases. Riebesell et al. introduce Matbench Discovery, a framework to compare machine learning models used to identify stable crystals. Out of several architectures, they find that universal interatomic potentials perform best in the competition.},
  archive      = {J_NATMI},
  author       = {Riebesell, Janosh and Goodall, Rhys E. A. and Benner, Philipp and Chiang, Yuan and Deng, Bowen and Ceder, Gerbrand and Asta, Mark and Lee, Alpha A. and Jain, Anubhav and Persson, Kristin A.},
  doi          = {10.1038/s42256-025-01055-1},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {836-847},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A framework to evaluate machine learning crystal stability predictions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The future of open human feedback. <em>NATMI</em>, <em>7</em>(6), 825-835. (<a href='https://doi.org/10.1038/s42256-025-01038-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human feedback on conversations with language models is central to how these systems learn about the world, improve their capabilities and are steered towards desirable and safe behaviours. However, this feedback is mostly collected by frontier artificial intelligence labs and kept behind closed doors. Here we bring together interdisciplinary experts to assess the opportunities and challenges to realizing an open ecosystem of human feedback for artificial intelligence. We first look for successful practices in the peer-production, open-source and citizen-science communities. We then characterize the main challenges for open human feedback. For each, we survey current approaches and offer recommendations. We end by envisioning the components needed to underpin a sustainable and open human feedback ecosystem. In the centre of this ecosystem are mutually beneficial feedback loops, between users and specialized models, incentivizing a diverse stakeholder community of model trainers and feedback providers to support a general open feedback pool. Don-Yehiya et al. explore creating an open ecosystem for human feedback on large language models, drawing from peer-production, open-source and citizen-science practices, and addressing key challenges to establish sustainable feedback loops between users and specialized models.},
  archive      = {J_NATMI},
  author       = {Don-Yehiya, Shachar and Burtenshaw, Ben and Fernandez Astudillo, Ramon and Osborne, Cailean and Jaiswal, Mimansa and Kuo, Tzu-Sheng and Zhao, Wenting and Shenfeld, Idan and Peng, Andi and Yurochkin, Mikhail and Kasirzadeh, Atoosa and Huang, Yangsibo and Hashimoto, Tatsunori and Jernite, Yacine and Vila-Suero, Daniel and Abend, Omri and Ding, Jennifer and Hooker, Sara and Rose Kirk, Hannah and Choshen, Leshem},
  doi          = {10.1038/s42256-025-01038-2},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {825-835},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The future of open human feedback},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A roadmap for AI in robotics. <em>NATMI</em>, <em>7</em>(6), 818-824. (<a href='https://doi.org/10.1038/s42256-025-01050-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing excitement about the potential of leveraging artificial intelligence (AI) to tackle some of the outstanding barriers to the full deployment of robots in daily lives. However, action and sensing in the physical world pose greater and different challenges for AI than analysing data in isolation and it is important to reflect on which AI approaches are most likely to be successfully applied to robots. Questions to address, among others, are how AI models can be adapted to specific robot designs, tasks and environments. This Perspective offers an assessment of what AI has achieved for robotics since the 1990s and proposes a research roadmap with challenges and promises. These range from keeping up-to-date large datasets, representatives of a diversity of tasks that robots may have to perform, and of environments they may encounter, to designing AI algorithms tailored specifically to robotics problems but generic enough to apply to a wide range of applications and transfer easily to a variety of robotic platforms. For robots to collaborate effectively with humans, they must predict human behaviour without relying on bias-based profiling. Explainability and transparency in AI-driven robot control are essential for building trust, preventing misuse and attributing responsibility in accidents. We close with describing what are, in our view, primary long-term challenges, namely, designing robots capable of lifelong learning, and guaranteeing safe deployment and usage, as well as sustainable development. AI technologies are advancing rapidly, offering new solutions for autonomous robot operation in complex environments. Aude Billard et al. discuss the need to identify and adapt AI technologies for robotics, proposing a research roadmap to address key challenges and opportunities.},
  archive      = {J_NATMI},
  author       = {Billard, Aude and Albu-Schaeffer, Alin and Beetz, Michael and Burgard, Wolfram and Corke, Peter and Ciocarlie, Matei and Dahiya, Ravinder and Kragic, Danica and Goldberg, Ken and Nagai, Yukie and Scaramuzza, Davide},
  doi          = {10.1038/s42256-025-01050-6},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {818-824},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A roadmap for AI in robotics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new perspective on the simulation of stochastic problems in fluid mechanics with diffusion models. <em>NATMI</em>, <em>7</em>(6), 816-817. (<a href='https://doi.org/10.1038/s42256-025-01060-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative deep learning models offer a fundamentally new approach for simulating stochastic processes in turbulent flows.},
  archive      = {J_NATMI},
  author       = {Guastoni, Luca and Vinuesa, Ricardo},
  doi          = {10.1038/s42256-025-01060-4},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {816-817},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A new perspective on the simulation of stochastic problems in fluid mechanics with diffusion models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unregulated emotional risks of AI wellness apps. <em>NATMI</em>, <em>7</em>(6), 813-815. (<a href='https://doi.org/10.1038/s42256-025-01051-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose that AI-driven wellness apps powered by large language models can foster extreme emotional attachments and dependencies akin to human relationships — posing risks such as ambiguous loss and dysfunctional dependence — that challenge current regulatory frameworks and necessitate safeguards and informed interventions within these platforms.},
  archive      = {J_NATMI},
  author       = {De Freitas, Julian and Cohen, I. Glenn},
  doi          = {10.1038/s42256-025-01051-5},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {813-815},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Unregulated emotional risks of AI wellness apps},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A personalized time-resolved 3D mesh generative model for unveiling normal heart dynamics. <em>NATMI</em>, <em>7</em>(5), 800-811. (<a href='https://doi.org/10.1038/s42256-025-01035-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the structure and motion of the heart is crucial for diagnosing and managing cardiovascular diseases, the leading cause of global death. There is wide variation in cardiac shape and motion patterns, influenced by demographic, anthropometric and disease factors. Unravelling normal patterns of shape and motion, and understanding how each individual deviates from the norm, would facilitate accurate diagnosis and personalized treatment strategies. Here, to this end, we developed a conditional generative model, MeshHeart, to learn the distribution of shape and motion patterns for the left and right ventricles of the heart. To model the high-dimensional spatio-temporal mesh data, MeshHeart uses a geometric encoder to represent cardiac meshes in a latent space and a temporal transformer to model the motion dynamics of latent representations. Based on MeshHeart, we investigate the latent space of 3D + t cardiac mesh sequences and propose a distance metric, latent delta, which quantifies the deviation of a real heart from its personalized normative pattern. Here, 3D + t refers to three-dimensional data evolving over time. In experiments using a large cardiac magnetic resonance image dataset of 38,309 participants from the UK Biobank, MeshHeart demonstrates high performance in cardiac mesh sequence reconstruction and generation. Latent space features are discriminative for cardiac disease classification, whereas latent delta exhibits strong correlations with clinical phenotypes in phenome-wide association studies. MeshHeart, a conditional generative model for time-resolved 3D heart mesh generation, is proposed by Qiao et al. to unravel heart motion patterns. Their findings could advance diagnosis and treatment strategies for cardiovascular diseases.},
  archive      = {J_NATMI},
  author       = {Qiao, Mengyun and McGurk, Kathryn A. and Wang, Shuo and Matthews, Paul M. and O’Regan, Declan P. and Bai, Wenjia},
  doi          = {10.1038/s42256-025-01035-5},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {800-811},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A personalized time-resolved 3D mesh generative model for unveiling normal heart dynamics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lossless data compression by large models. <em>NATMI</em>, <em>7</em>(5), 794-799. (<a href='https://doi.org/10.1038/s42256-025-01033-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data compression is a fundamental technology that enables efficient storage and transmission of information. However, traditional compression methods are approaching their theoretical limits after 80 years of research and development. At the same time, large artificial intelligence models have emerged, which, trained on vast amounts of data, are able to ‘understand’ various semantics. Intuitively, semantics conveys the meaning of data concisely, so large models hold the potential to revolutionize compression technology. Here we present LMCompress, a new method that leverages large models to compress data. LMCompress shatters all previous lossless compression records on four media types: text, images, video and audio. It halves the compression rates of JPEG-XL for images, FLAC for audio and H.264 for video, and it achieves nearly one-third of the compression rates of zpaq for text. Our results demonstrate that the better a model understands the data, the more effectively it can compress it, suggesting a deep connection between understanding and compression. Effective lossless compression requires that frequent patterns in the data can be identified. Li et al. explore using deep learning models to more effectively compress text, audio and video data.},
  archive      = {J_NATMI},
  author       = {Li, Ziguang and Huang, Chao and Wang, Xuliang and Hu, Haibo and Wyeth, Cole and Bu, Dongbo and Yu, Quan and Gao, Wen and Liu, Xingwu and Li, Ming},
  doi          = {10.1038/s42256-025-01033-7},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {794-799},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Lossless data compression by large models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging chemistry and artificial intelligence by a reaction description language. <em>NATMI</em>, <em>7</em>(5), 782-793. (<a href='https://doi.org/10.1038/s42256-025-01032-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast-paced development of artificial intelligence, large language models are increasingly used to tackle various scientific challenges. A critical step in this process is converting domain-specific data into a sequence of tokens for language modelling. In chemistry, molecules are often represented by molecular linear notations, and chemical reactions are depicted as sequence pairs of reactants and products. However, this approach does not capture atomic and bond changes during reactions. Here, we present ReactSeq, a reaction description language that defines molecular editing operations for step-by-step chemical transformation. Based on ReactSeq, language models for retrosynthesis prediction may consistently excel in all benchmark tests, and demonstrate promising emergent abilities in the human-in-the-loop and explainable artificial intelligence. Moreover, ReactSeq has allowed us to obtain universal and reliable representations of chemical reactions, which enable navigation of the reaction space and aid in the recommendation of experimental procedures and prediction of reaction yields. We foresee that ReactSeq can serve as a bridge to narrow the gap between chemistry and artificial intelligence. Xiong et al. introduce ReactSeq, a reaction description language that captures molecular editing operations in chemical reactions. It enables language models to excel in retrosynthesis prediction and reaction representation.},
  archive      = {J_NATMI},
  author       = {Xiong, Jiacheng and Zhang, Wei and Wang, Yinquan and Huang, Jiatao and Shi, Yuqi and Xu, Mingyan and Li, Manjia and Fu, Zunyun and Kong, Xiangtai and Wang, Yitian and Xiong, Zhaoping and Zheng, Mingyue},
  doi          = {10.1038/s42256-025-01032-8},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {782-793},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging chemistry and artificial intelligence by a reaction description language},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing molecular machine learning representations with stereoelectronics-infused molecular graphs. <em>NATMI</em>, <em>7</em>(5), 771-781. (<a href='https://doi.org/10.1038/s42256-025-01031-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular representation is a critical element in our understanding of the physical world and the foundation for modern molecular machine learning. Previous molecular machine learning models have used strings, fingerprints, global features and simple molecular graphs that are inherently information-sparse representations. However, as the complexity of prediction tasks increases, the molecular representation needs to encode higher fidelity information. This work introduces a new approach to infusing quantum-chemical-rich information into molecular graphs via stereoelectronic effects, enhancing expressivity and interpretability. Learning to predict the stereoelectronics-infused representation with a tailored double graph neural network workflow enables its application to any downstream molecular machine learning task without expensive quantum-chemical calculations. We show that the explicit addition of stereoelectronic information substantially improves the performance of message-passing two-dimensional machine learning models for molecular property prediction. We show that the learned representations trained on small molecules can accurately extrapolate to much larger molecular structures, yielding chemical insight into orbital interactions for previously intractable systems, such as entire proteins, opening new avenues of molecular design. Finally, we have developed a web application (simg.cheme.cmu.edu) where users can rapidly explore stereoelectronic information for their own molecular systems. Boiko et al. enhance expressiveness and interpretability of molecular representation in graph neural networks by including quantum-chemical-rich information into molecular graphs.},
  archive      = {J_NATMI},
  author       = {Boiko, Daniil A. and Reschützegger, Thiago and Sanchez-Lengeling, Benjamin and Blau, Samuel M. and Gomes, Gabe},
  doi          = {10.1038/s42256-025-01031-9},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {771-781},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Advancing molecular machine learning representations with stereoelectronics-infused molecular graphs},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating 3D small binding molecules using shape-conditioned diffusion models with guidance. <em>NATMI</em>, <em>7</em>(5), 758-770. (<a href='https://doi.org/10.1038/s42256-025-01030-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug development is a critical but notoriously resource- and time-consuming process. Traditional methods, such as high-throughput screening, rely on opportunistic trial and error and cannot ensure optimal precision design. To overcome these challenges, generative artificial intelligence methods have emerged to directly design molecules with desired properties. Here we develop a generative artificial intelligence method DiffSMol for drug discovery that generates 3D small binding molecules based on known ligand shapes. DiffSMol encapsulates ligand shape details within pretrained, expressive shape embeddings and generates binding molecules through a diffusion model. DiffSMol further modifies the generated 3D structures iteratively using shape guidance to better resemble ligand shapes, and protein pocket guidance to optimize binding affinities. We show that DiffSMol outperforms state-of-the-art methods on benchmark datasets. When generating binding molecules resembling ligand shapes, DiffSMol with shape guidance achieves a success rate 61.4%, substantially outperforming the best baseline (11.2%), meanwhile producing molecules with de novo graph structures. DiffSMol with pocket guidance also outperforms the best baseline in binding affinities by 13.2%, and even by 17.7% when combined with shape guidance. Case studies for two critical drug targets demonstrate very favourable physicochemical and pharmacokinetic properties of generated molecules, highlighting the potential of DiffSMol in developing promising drug candidates. Chen et al. introduce an AI-driven method that generates 3D small-molecule drug candidates and outperforms existing approaches by leveraging ligand shape information.},
  archive      = {J_NATMI},
  author       = {Chen, Ziqi and Peng, Bo and Zhai, Tianhua and Adu-Ampratwum, Daniel and Ning, Xia},
  doi          = {10.1038/s42256-025-01030-w},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {758-770},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generating 3D small binding molecules using shape-conditioned diffusion models with guidance},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep spectral component filtering as a foundation model for spectral analysis demonstrated in metabolic profiling. <em>NATMI</em>, <em>7</em>(5), 743-757. (<a href='https://doi.org/10.1038/s42256-025-01027-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysing metabolites in bioliquids through various spectroscopic methods provides valuable insights into the metabolic phenotypes. Deciphering spectral data has greatly benefited from deep-learning methods; however, data-driven solutions often struggle with data dependence on different devices, samples and spectral modalities. Most current task-specific methods have limited generalizability to different spectral analysis problems, including preprocessing, quantification and interpretation. Here, we developed a pretrained foundation model, termed deep-spectral component filtering (DSCF) through a self-supervised approach termed spectral component resolvable learning. By acquiring general spectral knowledge, DSCF achieved state-of-the-art performance for five distinct spectral analysis tasks on 11 datasets. Notably, the general pretraining led to zero-shot spectral denoising and trace-level quantification in complex mixtures. DSCF achieved molecule-level interpretation of surface-enhanced Raman spectra and mapped serum metabolic profiles from nearly 600 individuals for various diseases, including stroke, Alzheimer’s disease and prostate cancer. Overall, the proposed foundation model illustrates promising generalizability for spectral analysis and offers a clear and feasible pathway for general spectral analysis. Xue et al. develop a foundation model for spectral analysis. It excels in multiple tasks, such as denoising spectra and quantifying trace molecules, and is especially promising in identifying metabolic biomarkers of diseases such as stroke, Alzheimer’s disease and prostate cancer.},
  archive      = {J_NATMI},
  author       = {Xue, Bingsen and Bi, Xinyuan and Dong, Zheyi and Xu, Yunzhe and Liang, Minghui and Fang, Xin and Yuan, Yizhe and Wang, Ruoxi and Liu, Shuyu and Jiao, Rushi and Chen, Yuze and Zu, Weitao and Wang, Chengxiang and Zhang, Jianhao and Liu, Jiang and Zhang, Qin and Yuan, Ye and Xu, Midie and Zhang, Ya and Wang, Yanfeng and Ye, Jian and Jin, Cheng},
  doi          = {10.1038/s42256-025-01027-5},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {743-757},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep spectral component filtering as a foundation model for spectral analysis demonstrated in metabolic profiling},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and transferable three-dimensional dynamic vascular reconstruction for instantaneous diagnosis. <em>NATMI</em>, <em>7</em>(5), 730-742. (<a href='https://doi.org/10.1038/s42256-025-01025-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) structural information of cardiac vessels is crucial for the diagnosis and treatment of cardiovascular disease. In clinical practice, interventionalists have to empirically infer 3D cardiovascular topology from multi-view X-ray angiography images, which is time-consuming and requires extensive experience. Owing to the dynamic nature of heartbeats and sparse-view observations in clinical practice, accurate and efficient reconstruction of 3D cardiovascular structures from X-ray angiography images remains challenging. Here we introduce AutoCAR, a fully automated transfer learning-based algorithm for dynamic 3D cardiovascular reconstruction. AutoCAR comprises three main components: pose domain adaptation, sparse backwards projection and vascular graph optimization. By merging the X-ray angiography imaging parameter statistics of over 1,000 clinical cases into synthetic data generation, and exploiting the intrinsic spatial sparsity of cardiac vessels for computational design, AutoCAR outperforms state-of-the-art methods in both qualitative and quantitative evaluations, enabling dynamic cardiovascular reconstruction in real-world clinical settings. We envision that AutoCAR will facilitate current diagnostic and intervention procedures and pave the way for real-time visual guidance and autonomous catheter navigation in cardiac intervention. Yinheng Zhu et al. present AutoCAR, an automated algorithm for reconstructing three-dimensional cardiovascular structures from X-ray images. It uses transfer learning and vascular graph optimization to achieve high efficiency and accuracy, with the goal to enable medical procedures and diagnosis in real-world settings.},
  archive      = {J_NATMI},
  author       = {Zhu, Yinheng and Wang, Yong and Di, Chunxia and Liu, Hanghang and Liao, Fangzhou and Ma, Shaohua},
  doi          = {10.1038/s42256-025-01025-7},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {730-742},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Sparse and transferable three-dimensional dynamic vascular reconstruction for instantaneous diagnosis},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning prediction of enzyme optimum pH. <em>NATMI</em>, <em>7</em>(5), 716-729. (<a href='https://doi.org/10.1038/s42256-025-01026-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between pH and enzyme catalytic activity, especially the optimal pH (pHopt) at which enzymes function, is critical for biotechnological applications. Hence, computational methods to predict pHopt will enhance enzyme discovery and design by facilitating accurate identification of enzymes that function optimally at specific pH levels, and by elucidating sequence–function relationships. Here we proposed and evaluated various machine learning methods for predicting pHopt, conducting extensive hyperparameter optimization and training over 11,000 model instances. Our results demonstrate that models utilizing language model embeddings markedly outperform other methods in predicting pHopt. We present EpHod, the best-performing model, to predict pHopt, making it publicly available to researchers. From sequence data, EpHod directly learns structural and biophysical features that relate to pHopt, including proximity of residues to the catalytic centre and the accessibility of solvent molecules. Overall, EpHod presents a promising advancement in pHopt prediction and will potentially speed up the development of enzyme technologies. Accurately predicting the optimal pH level for enzyme activity is challenging due to the complex relationship between enzyme structure and function. Gado and colleagues show that a language model can effectively learn the structural and biophysical features to predict the optimal pH for enzyme activity.},
  archive      = {J_NATMI},
  author       = {Gado, Japheth E. and Knotts, Matthew and Shaw, Ada Y. and Marks, Debora and Gauthier, Nicholas P. and Sander, Chris and Beckham, Gregg T.},
  doi          = {10.1038/s42256-025-01026-6},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {716-729},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning prediction of enzyme optimum pH},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming machines capable of continuous 3D shape morphing and locking. <em>NATMI</em>, <em>7</em>(5), 703-715. (<a href='https://doi.org/10.1038/s42256-025-01028-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by natural species that leverage morphological changes to realize multiple locomotion modes, diverse multimodal robots have been reported. While developments of small-scale actuators with continuous shape morphing and locking capabilities controlled by the same energy source are crucial for miniaturization of untethered multimodal robots, it remains elusive. We introduce a synergistic design concept of small-scale continuously morphable actuators (CMAs) that harness precisely programmable actuation deformation of liquid crystal elastomer to achieve continuous shape morphing and high stiffness variation of shape memory polymer to lock geometric configuration, both through electrothermal control. Lego-inspired design strategy allows customized construction of complexly shaped CMAs (for example, ‘transformer’, ‘aircraft’ and ‘turtle’) through rational assembly of elementary actuator units with different ranges of accessible geometric configurations. The powerful shape morphing and locking capabilities, as well as the relatively high load-bearing capacity of the CMAs, allow for developments of versatile exoskeletons that can integrate a diversity of functional components. Demonstrations of unique small-scale transforming machines, such as morphable displays with a rich diversity of three-dimensional geometries, a wheeled microrobot capable of transformation among ‘sports car’, ‘winged car’ and ‘van’, and a lightweight untethered terrestrial–aerial microrobot, suggest a broad spectrum of applications. Continuous shape morphing for small robots can offer advantages, but it is difficult to perform tasks if they are not stiff enough. Xu et al. present here a design combining liquid crystal elastomers and shape memory polymers to lock morphable elements in place.},
  archive      = {J_NATMI},
  author       = {Xu, Shiwei and Hu, Xiaonan and Yang, Ruoxi and Zang, Chuanqi and Li, Lei and Xiao, Yue and Liu, Wenbo and Tian, Bocheng and Pang, Wenbo and Bo, Renheng and Liu, Qing and Yang, Youzhou and Lai, Yuchen and Wu, Jun and Zhao, Huichan and Wen, Li and Zhang, Yihui},
  doi          = {10.1038/s42256-025-01028-4},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {703-715},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Transforming machines capable of continuous 3D shape morphing and locking},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositional pretraining improves computational efficiency and matches animal behaviour on complex tasks. <em>NATMI</em>, <em>7</em>(5), 689-702. (<a href='https://doi.org/10.1038/s42256-025-01029-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are ubiquitously used in neuroscience to capture both neural dynamics and behaviours of living systems. However, when it comes to complex cognitive tasks, training RNNs with traditional methods can prove difficult and fall short of capturing crucial aspects of animal behaviour. Here we propose a principled approach for identifying and incorporating compositional tasks as part of RNN training. Taking as the target a temporal wagering task previously studied in rats, we design a pretraining curriculum of simpler cognitive tasks that reflect relevant subcomputations, which we term ‘kindergarten curriculum learning’. We show that this pretraining substantially improves learning efficacy and is critical for RNNs to adopt similar strategies as rats, including long-timescale inference of latent states, which conventional pretraining approaches fail to capture. Mechanistically, our pretraining supports the development of slow dynamical systems features needed for implementing both inference and value-based decision making. Overall, our approach helps endow RNNs with relevant inductive biases, which is important when modelling complex behaviours that rely on multiple cognitive functions. Hocker et al. demonstrate a method for training recurrent neural networks, which they call ‘kindergarten curriculum learning’, involving pretraining on simple cognitive tasks to improve learning efficiency. This approach helps recurrent neural networks to mimic animal behaviour in solving complex tasks.},
  archive      = {J_NATMI},
  author       = {Hocker, David and Constantinople, Christine M. and Savin, Cristina},
  doi          = {10.1038/s42256-025-01029-3},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {689-702},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Compositional pretraining improves computational efficiency and matches animal behaviour on complex tasks},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Back to recurrent processing at the crossroad of transformers and state-space models. <em>NATMI</em>, <em>7</em>(5), 678-688. (<a href='https://doi.org/10.1038/s42256-025-01034-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a longstanding challenge for the machine learning community to develop models that are capable of processing and learning from long sequences of data. The exceptional results of transformer-based approaches, such as large language models, promote the idea of parallel attention as the key to succeed in such a challenge, temporarily obscuring the role of classic sequential processing of recurrent models. However, in the past few years, a new generation of neural models has emerged, combining transformers and recurrent networks motivated by concerns over the quadratic complexity of self-attention. Meanwhile, (deep) state-space models have also emerged as robust approaches to function approximation over time, thus opening a new perspective in learning from sequential data. Here we provide an overview of these trends unified under the umbrella of recurrent models, and discuss their likely crucial impact in the development of future architectures for large generative models. While transformers and large language models excel at efficiently processing long sequences, new approaches have been proposed that incorporate recurrence to overcome the quadratic cost of self-attention. Tiezzi et al. discuss recurrent and state-space models and the promise they hold for future sequence processing networks.},
  archive      = {J_NATMI},
  author       = {Tiezzi, Matteo and Casoni, Michele and Betti, Alessandro and Guidi, Tommaso and Gori, Marco and Melacci, Stefano},
  doi          = {10.1038/s42256-025-01034-6},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {678-688},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Back to recurrent processing at the crossroad of transformers and state-space models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Firefighting robots should be made responsibly. <em>NATMI</em>, <em>7</em>(5), 676-677. (<a href='https://doi.org/10.1038/s42256-025-01037-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {van Manen, Benjamin R. and Fosch-Villaronga, Eduard and Smits, Merlijn},
  doi          = {10.1038/s42256-025-01037-3},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {676-677},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Firefighting robots should be made responsibly},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Localizing AI in the global south. <em>NATMI</em>, <em>7</em>(5), 675. (<a href='https://doi.org/10.1038/s42256-025-01057-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countries in the global south stand to benefit considerably from AI developments and are taking the lead in determining the direction of inclusive AI research efforts.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01057-z},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {675},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Localizing AI in the global south},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Author correction: A machine learning approach to leveraging electronic health records for enhanced omics analysis. <em>NATMI</em>, <em>7</em>(4), 673. (<a href='https://doi.org/10.1038/s42256-025-01021-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Mataraso, Samson J. and Espinosa, Camilo A. and Seong, David and Reincke, S. Momsen and Berson, Eloise and Reiss, Jonathan D. and Kim, Yeasul and Ghanem, Marc and Shu, Chi-Hung and James, Tomin and Tan, Yuqi and Shome, Sayane and Stelzer, Ina A. and Feyaerts, Dorien and Wong, Ronald J. and Shaw, Gary M. and Angst, Martin S. and Gaudilliere, Brice and Stevenson, David K. and Aghaeepour, Nima},
  doi          = {10.1038/s42256-025-01021-x},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {673},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: A machine learning approach to leveraging electronic health records for enhanced omics analysis},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Author correction: Coordinate-based neural representations for computational adaptive optics in widefield microscopy. <em>NATMI</em>, <em>7</em>(4), 672. (<a href='https://doi.org/10.1038/s42256-025-01022-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Kang, Iksung and Zhang, Qinrong and Yu, Stella X. and Ji, Na},
  doi          = {10.1038/s42256-025-01022-w},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {672},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Coordinate-based neural representations for computational adaptive optics in widefield microscopy},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A disease-specific language model for variant pathogenicity in cardiac and regulatory genomics. <em>NATMI</em>, <em>7</em>(4), 661-671. (<a href='https://doi.org/10.1038/s42256-025-01016-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical variant classification of pathogenic versus benign genetic variants remains a challenge in genetics. Current genomic foundation models have enhanced variant effect prediction (VEP) accuracy through weakly supervised or unsupervised training, yet these models lack disease specificity. Here, to address this, we propose DYNA (disease-specificity fine-tuning via a Siamese neural network), broadly applicable to all genomic foundation models for more effective VEPs in disease contexts. We applied DYNA to the coding VEP in cardiovascular diseases and the non-coding VEP of RNA splicing regulation. These two tasks cover a wide range of specific disease–gene relationships and disease-causing regulatory mechanisms; therefore, their performance will inform the general utility of DYNA. In both cases, DYNA fine-tunes various pretrained genomic foundation models on small rare-variant sets. The DYNA fine-tuned models show superior performance in held-out rare-variant test sets and are further replicated in large, clinically relevant variant annotations in ClinVar. Importantly, we observed that different genomic foundation models excel at different downstream VEP tasks, necessitating a universal tool such as DYNA to fully harness the power of genomic foundation models. Thus, DYNA offers a potent disease-specific VEP method for clinical variant interpretation. DYNA fine-tunes genomic foundation models with disease specificity using a Siamese network. It generalizes to rare-variant test sets and replicates results in ClinVar, advancing variant effect prediction for cardiovascular diseases and RNA splicing.},
  archive      = {J_NATMI},
  author       = {Zhan, Huixin and Moore, Jason H. and Zhang, Zijun},
  doi          = {10.1038/s42256-025-01016-8},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {661-671},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A disease-specific language model for variant pathogenicity in cardiac and regulatory genomics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified deep framework for peptide–major histocompatibility complex–T cell receptor binding prediction. <em>NATMI</em>, <em>7</em>(4), 650-660. (<a href='https://doi.org/10.1038/s42256-025-01002-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antigen peptides that are presented by a major histocompatibility complex (MHC) and recognized by a T cell receptor (TCR) have an essential role in immunotherapy. Although substantial progress has been made in predicting MHC presentation, accurately predicting the binding interactions between antigen peptides, MHCs and TCRs remains a major computational challenge. In this paper, we propose a unified deep framework (called UniPMT) for peptide, MHC and TCR binding prediction to predict the binding between the peptide and the CDR3 of TCR β in general, presented by class I MHCs. UniPMT is comprehensively validated by a series of experiments and achieved state-of-the-art performance in the peptide–MHC–TCR, peptide–MHC and peptide–TCR binding prediction tasks with up to 15% improvements in area under the precision–recall curve taking the peptide–MHC–TCR binding prediction task as an example. In practical applications, UniPMT shows strong predictive power, correlates well with T cell clonal expansion and outperforms existing methods in neoantigen-specific binding prediction with up to 17.62% improvements in area under the precision–recall curve on experimentally validated datasets. Moreover, UniPMT provides interpretable insights into the identification of key binding sites and the quantification of peptide–MHC–TCR binding probabilities. In summary, UniPMT shows great potential to serve as a useful tool for antigen peptide discovery, disease immunotherapy and neoantigen vaccine design. UniPMT, a multitask learning model, is presented, which integrates three key biological relationships into a unified framework for accurate peptide–MHC–TCR binding prediction.},
  archive      = {J_NATMI},
  author       = {Zhao, Yunxiang and Yu, Jijun and Su, Yixin and Shu, You and Ma, Enhao and Wang, Jing and Jiang, Shuyang and Wei, Congwen and Li, Dongsheng and Huang, Zhen and Cheng, Gong and Ren, Hongguang and Feng, Jiannan},
  doi          = {10.1038/s42256-025-01002-0},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {650-660},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A unified deep framework for peptide–major histocompatibility complex–T cell receptor binding prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable and robust DNA-based storage via coding theory and deep learning. <em>NATMI</em>, <em>7</em>(4), 639-649. (<a href='https://doi.org/10.1038/s42256-025-01003-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global data sphere is expanding exponentially, projected to hit 180 zettabytes by 2025, whereas current technologies are not anticipated to scale at nearly the same rate. DNA-based storage emerges as a crucial solution to this gap, enabling digital information to be archived in DNA molecules. This method enjoys major advantages over magnetic and optical storage solutions such as exceptional information density, enhanced data durability and negligible power consumption to maintain data integrity. To access the data, an information retrieval process is employed, where some of the main bottlenecks are the scalability and accuracy, which have a natural tradeoff between the two. Here we show a modular and holistic approach that combines deep neural networks trained on simulated data, tensor product-based error-correcting codes and a safety margin mechanism into a single coherent pipeline. We demonstrated our solution on 3.1 MB of information using two different sequencing technologies. Our work improves upon the current leading solutions with a 3,200× increase in speed and a 40% improvement in accuracy and offers a code rate of 1.6 bits per base in a high-noise regime. In a broader sense, our work shows a viable path to commercial DNA storage solutions hindered by current information retrieval processes. Bar-Lev et al. propose a high-efficiency DNA-based storage pipeline that integrates deep neural networks, error-correcting codes and safety margins, achieving a 3,200× speed improvement and a 40% accuracy gain, paving the way for commercially viable DNA data storage.},
  archive      = {J_NATMI},
  author       = {Bar-Lev, Daniella and Orr, Itai and Sabary, Omer and Etzion, Tuvi and Yaakobi, Eitan},
  doi          = {10.1038/s42256-025-01003-z},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {639-649},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Scalable and robust DNA-based storage via coding theory and deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-centred design and fabrication of a wearable multimodal visual assistance system. <em>NATMI</em>, <em>7</em>(4), 627-638. (<a href='https://doi.org/10.1038/s42256-025-01018-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-powered wearable electronic systems offer promising solutions for non-invasive visual assistance. However, state-of-the-art systems have not sufficiently considered human adaptation, resulting in a low adoption rate among blind people. Here we present a human-centred, multimodal wearable system that advances usability by blending software and hardware innovations. For software, we customize the artificial intelligence algorithm to match the requirements of application scenario and human behaviours. For hardware, we improve the wearability by developing stretchable sensory-motor artificial skins to complement the audio feedback and visual tasks. Self-powered triboelectric smart insoles align real users with virtual avatars, supporting effective training in carefully designed scenarios. The harmonious corporation of visual, audio and haptic senses enables significant improvements in navigation and postnavigation tasks, which are experimentally evidenced by humanoid robots and participants with visual impairment in both virtual and real environments. Postexperiment surveys highlight the system’s reliable functionality and high usability. This research paves the way for user-friendly visual assistance systems, offering alternative avenues to enhance the quality of life for people with visual impairment. The development of artificial vision for blind people has been a long-standing endeavour. Tang et al. create a wearable multimodal visual assistance system with a human-centred design, blending software and hardware innovations to enhance usability.},
  archive      = {J_NATMI},
  author       = {Tang, Jian and Zhu, Yi and Jiang, Gai and Xiao, Lin and Ren, Wei and Zhou, Yu and Gu, Qinying and Yan, Biao and Zhang, Jiayi and Bi, Hengchang and Wu, Xing and Fan, Zhiyong and Gu, Leilei},
  doi          = {10.1038/s42256-025-01018-6},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {627-638},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Human-centred design and fabrication of a wearable multimodal visual assistance system},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport for generating transition states in chemical reactions. <em>NATMI</em>, <em>7</em>(4), 615-626. (<a href='https://doi.org/10.1038/s42256-025-01010-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transition states (TSs) are transient structures that are key to understanding reaction mechanisms and designing catalysts but challenging to capture in experiments. Many optimization algorithms have been developed to search for TSs computationally. Yet, the cost of these algorithms driven by quantum chemistry methods (usually density functional theory) is still high, posing challenges for their applications in building large reaction networks for reaction exploration. Here we developed React-OT, an optimal transport approach for generating unique TS structures from reactants and products. React-OT generates highly accurate TS structures with a median structural root mean square deviation of 0.053 Å and median barrier height error of 1.06 kcal mol−1 requiring only 0.4 s per reaction. The root mean square deviation and barrier height error are further improved by roughly 25% through pretraining React-OT on a large reaction dataset obtained with a lower level of theory, GFN2-xTB. We envision that the remarkable accuracy and rapid inference of React-OT will be highly useful when integrated with the current high-throughput TS search workflow. This integration will facilitate the exploration of chemical reactions with unknown mechanisms. Duan et al. introduce an optimal transport approach to generate transition states, surpassing diffusion models in precision and speed. This method can facilitate the study of chemical reactions with unknown mechanisms.},
  archive      = {J_NATMI},
  author       = {Duan, Chenru and Liu, Guan-Horng and Du, Yuanqi and Chen, Tianrong and Zhao, Qiyuan and Jia, Haojun and Gomes, Carla P. and Theodorou, Evangelos A. and Kulik, Heather J.},
  doi          = {10.1038/s42256-025-01010-0},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {615-626},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Optimal transport for generating transition states in chemical reactions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive large-scale biomedical knowledge graph for AI-powered data-driven biomedical research. <em>NATMI</em>, <em>7</em>(4), 602-614. (<a href='https://doi.org/10.1038/s42256-025-01014-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the rapid growth of scientific publications and data in biomedical research, knowledge graphs (KGs) have become a critical tool for integrating large volumes of heterogeneous data to enable efficient information retrieval and automated knowledge discovery. However, transforming unstructured scientific literature into KGs remains a significant challenge, with previous methods unable to achieve human-level accuracy. Here we used an information extraction pipeline that won first place in the LitCoin Natural Language Processing Challenge (2022) to construct a large-scale KG named iKraph using all PubMed abstracts. The extracted information matches human expert annotations and significantly exceeds the content of manually curated public databases. To enhance the KG’s comprehensiveness, we integrated relation data from 40 public databases and relation information inferred from high-throughput genomics data. This KG facilitates rigorous performance evaluation of automated knowledge discovery, which was infeasible in previous studies. We designed an interpretable, probabilistic-based inference method to identify indirect causal relations and applied it to real-time COVID-19 drug repurposing from March 2020 to May 2023. Our method identified around 1,200 candidate drugs in the first 4 months, with one-third of those discovered in the first 2 months later supported by clinical trials or PubMed publications. These outcomes are very challenging to attain through alternative approaches that lack a thorough understanding of the existing literature. A cloud-based platform ( https://biokde.insilicom.com ) was developed for academic users to access this rich structured data and associated tools. This study presents iKraph, a large-scale biomedical knowledge graph built using an award-winning natural language processing pipeline with expert-level accuracy. Using probabilistic semantic reasoning, iKraph enables automated knowledge discovery with excellent performance.},
  archive      = {J_NATMI},
  author       = {Zhang, Yuan and Sui, Xin and Pan, Feng and Yu, Kaixian and Li, Keqiao and Tian, Shubo and Erdengasileng, Arslan and Han, Qing and Wang, Wanjing and Wang, Jianan and Wang, Jian and Sun, Donghu and Chung, Henry and Zhou, Jun and Zhou, Eric and Lee, Ben and Zhang, Peili and Qiu, Xing and Zhao, Tingting and Zhang, Jinfeng},
  doi          = {10.1038/s42256-025-01014-w},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {602-614},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A comprehensive large-scale biomedical knowledge graph for AI-powered data-driven biomedical research},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embodied large language models enable robots to complete complex tasks in unpredictable environments. <em>NATMI</em>, <em>7</em>(4), 592-601. (<a href='https://doi.org/10.1038/s42256-025-01005-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Completing complex tasks in unpredictable settings challenges robotic systems, requiring a step change in machine intelligence. Sensorimotor abilities are considered integral to human intelligence. Thus, biologically inspired machine intelligence might usefully combine artificial intelligence with robotic sensorimotor capabilities. Here we report an embodied large-language-model-enabled robot (ELLMER) framework, utilizing GPT-4 and a retrieval-augmented generation infrastructure, to enable robots to complete long-horizon tasks in unpredictable settings. The method extracts contextually relevant examples from a knowledge base, producing action plans that incorporate force and visual feedback and enabling adaptation to changing conditions. We tested ELLMER on a robot tasked with coffee making and plate decoration; these tasks consist of a sequence of sub-tasks from drawer opening to pouring, each benefiting from distinct feedback types and methods. We show that the ELLMER framework allows the robot to complete the tasks. This demonstration marks progress towards scalable, efficient and ‘intelligent robots’ able to complete complex tasks in uncertain environments. To function in the real world, autonomous robots will have to respond to unanticipated situations. A vision-language-model-based approach is proposed to solve long-horizon robotic tasks, which can adapt to a dynamic environment.},
  archive      = {J_NATMI},
  author       = {Mon-Williams, Ruaridh and Li, Gen and Long, Ran and Du, Wenqian and Lucas, Christopher G.},
  doi          = {10.1038/s42256-025-01005-x},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {592-601},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Embodied large language models enable robots to complete complex tasks in unpredictable environments},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A text-guided protein design framework. <em>NATMI</em>, <em>7</em>(4), 580-591. (<a href='https://doi.org/10.1038/s42256-025-01011-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current AI-assisted protein design utilizes mainly protein sequential and structural information. Meanwhile, there exists tremendous knowledge curated by humans in text format describing proteins’ high-level functionalities, yet whether the incorporation of such text data can help in protein design tasks has not been explored. To bridge this gap, we propose ProteinDT, a multimodal framework that leverages textual descriptions for protein design. ProteinDT consists of three consecutive steps: ProteinCLAP, which aligns the representation of two modalities, a facilitator that generates the protein representation from the text modality and a decoder that creates the protein sequences from the representation. To train ProteinDT, we construct a large dataset, SwissProtCLAP, with 441,000 text and protein pairs. We quantitatively verify the effectiveness of ProteinDT on three challenging tasks: (1) over 90% accuracy for text-guided protein generation; (2) best hit ratio on 12 zero-shot text-guided protein editing tasks; (3) superior performance on four out of six protein property prediction benchmarks. Shengchao Liu et al. present ProteinDT, a deep learning approach that can incorporate domain knowledge from textual descriptions into protein representation on a large scale.},
  archive      = {J_NATMI},
  author       = {Liu, Shengchao and Li, Yanjing and Li, Zhuoxinran and Gitter, Anthony and Zhu, Yutao and Lu, Jiarui and Xu, Zhao and Nie, Weili and Ramanathan, Arvind and Xiao, Chaowei and Tang, Jian and Guo, Hongyu and Anandkumar, Anima},
  doi          = {10.1038/s42256-025-01011-z},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {580-591},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A text-guided protein design framework},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments. <em>NATMI</em>, <em>7</em>(4), 565-579. (<a href='https://doi.org/10.1038/s42256-025-01019-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mass spectrometry-based proteomics focuses on identifying the peptide that generates a tandem mass spectrum. Traditional methods rely on protein databases but are often limited or inapplicable in certain contexts. De novo peptide sequencing, which assigns peptide sequences to spectra without prior information, is valuable for diverse biological applications; however, owing to a lack of accuracy, it remains challenging to apply. Here we introduce InstaNovo, a transformer model that translates fragment ion peaks into peptide sequences. We demonstrate that InstaNovo outperforms state-of-the-art methods and showcase its utility in several applications. We also introduce InstaNovo+, a diffusion model that improves performance through iterative refinement of predicted sequences. Using these models, we achieve improved therapeutic sequencing coverage, discover novel peptides and detect unreported organisms in diverse datasets, thereby expanding the scope and detection rate of proteomics searches. Our models unlock opportunities across domains such as direct protein sequencing, immunopeptidomics and exploration of the dark proteome. InstaNovo, a transformer-based model, and InstaNovo+, a multinomial diffusion model, enhance de novo peptide sequencing, enabling discovery of novel peptides, improved therapeutics sequencing coverage and detection of unreported organisms in proteomics studies},
  archive      = {J_NATMI},
  author       = {Eloff, Kevin and Kalogeropoulos, Konstantinos and Mabona, Amandla and Morell, Oliver and Catzel, Rachel and Rivera-de-Torre, Esperanza and Berg Jespersen, Jakob and Williams, Wesley and van Beljouw, Sam P. B. and Skwark, Marcin J. and Laustsen, Andreas Hougaard and Brouns, Stan J. J. and Ljungars, Anne and Schoof, Erwin M. and Van Goey, Jeroen and auf dem Keller, Ulrich and Beguir, Karim and Lopez Carranza, Nicolas and Jenkins, Timothy P.},
  doi          = {10.1038/s42256-025-01019-5},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {565-579},
  shortjournal = {Nat. Mach. Intell.},
  title        = {InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active exploration and reconstruction of vascular networks using microrobot swarms. <em>NATMI</em>, <em>7</em>(4), 553-564. (<a href='https://doi.org/10.1038/s42256-025-01012-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Angiography is essential in interventional operations to image the vascular network. Passive contrast agents applied in angiography highly rely on the flow direction, making the imaging of upstream regions and embolic branches challenging. Active imaging is demanded for the accurate localization of blockages and lesions in vascular networks. Here an active exploration and reconstruction strategy is proposed, enabling full imaging of three-dimensional (3D) vascular networks with flow and blockage. The strategy implements magnetic particle swarms as active agents, which can be guided on demand towards the desired directions. An image processing unit is developed to capture the 3D position of the swarm inside the vessel. A simultaneous mapping and exploration sequence is proposed to realize the exploration, and the entire structure of the 3D vascular network is reconstructed after obtaining the position data. The proposed strategy is validated in vascular networks with different structures and conditions, and it enables the thorough exploration and reconstruction of regions that cannot be accessed by passive contrast agents. This strategy is promising in locating stenoses, thrombi and fistulae in vascular systems. Vascular imaging of upstream branches and obstructed flow is challenging. Here Du and colleagues present an active exploration strategy to explore and reconstruct three-dimensional vascular networks.},
  archive      = {J_NATMI},
  author       = {Du, Xingzhou and Wang, Yibin and Law, Junhui and Fang, Kaiwen and Chen, Hui and Liu, Yuezhen and Yu, Jiangfan},
  doi          = {10.1038/s42256-025-01012-y},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {553-564},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Active exploration and reconstruction of vascular networks using microrobot swarms},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predictive machine learning force-field framework for liquid electrolyte development. <em>NATMI</em>, <em>7</em>(4), 543-552. (<a href='https://doi.org/10.1038/s42256-025-01009-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread applications of machine learning force fields (MLFFs) in solids and small molecules, there is a notable gap in applying MLFFs to simulate liquid electrolytes—a critical component of current commercial lithium-ion batteries. Here we introduce ByteDance Artificial intelligence Molecular simulation Booster (BAMBOO), a predictive framework for molecular dynamics simulations, with a demonstration of its capability in the context of liquid electrolytes for lithium batteries. We design a physics-inspired graph equivariant transformer architecture as the backbone of BAMBOO to learn from quantum mechanical simulations. Additionally, we introduce an ensemble knowledge distillation approach and apply it to MLFFs to reduce the fluctuation of observations from molecular dynamics simulations. Finally, we propose a density alignment algorithm to align BAMBOO with experimental measurements. BAMBOO demonstrates state-of-the-art accuracy in predicting key electrolyte properties such as density, viscosity and ionic conductivity across various solvents and salt combinations. The current model, trained on more than 15 chemical species, achieves an average density error of 0.01 g cm−3 on various compositions compared with experiment. A machine learning force-field framework is proposed to predict the density, viscosity and ionic conductivity of liquid electrolytes with accuracy that is higher than classical force fields.},
  archive      = {J_NATMI},
  author       = {Gong, Sheng and Zhang, Yumin and Mu, Zhenliang and Pu, Zhichen and Wang, Hongyi and Han, Xu and Yu, Zhiao and Chen, Mengyi and Zheng, Tianze and Wang, Zhi and Chen, Lifei and Yang, Zhenze and Wu, Xiaojie and Shi, Shaochen and Gao, Weihao and Yan, Wen and Xiang, Liang},
  doi          = {10.1038/s42256-025-01009-7},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {543-552},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A predictive machine learning force-field framework for liquid electrolyte development},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI safety for everyone. <em>NATMI</em>, <em>7</em>(4), 531-542. (<a href='https://doi.org/10.1038/s42256-025-01020-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent discussions and research in artificial intelligence (AI) safety have increasingly emphasized the deep connection between AI safety and existential risk from advanced AI systems, suggesting that work on AI safety necessarily entails serious consideration of potential existential threats. However, this framing has three potential drawbacks: it may exclude researchers and practitioners who are committed to AI safety but approach the field from different angles; it could lead the public to mistakenly view AI safety as focused solely on existential scenarios rather than addressing a wide spectrum of safety challenges; and it risks creating resistance to safety measures among those who disagree with predictions of existential AI risks. Here, through a systematic literature review of primarily peer-reviewed research, we find a vast array of concrete safety work that addresses immediate and practical concerns with current AI systems. This includes crucial areas such as adversarial robustness and interpretability, highlighting how AI safety research naturally extends existing technological and systems safety concerns and practices. Our findings suggest the need for an epistemically inclusive and pluralistic conception of AI safety that can accommodate the full range of safety considerations, motivations and perspectives that currently shape the field. A systematic review of peer-reviewed AI safety research reveals extensive work on practical and immediate concerns. The findings advocate for an inclusive approach to AI safety that embraces diverse motivations and perspectives.},
  archive      = {J_NATMI},
  author       = {Gyevnár, Bálint and Kasirzadeh, Atoosa},
  doi          = {10.1038/s42256-025-01020-y},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {531-542},
  shortjournal = {Nat. Mach. Intell.},
  title        = {AI safety for everyone},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized uncertainty quantification in artificial intelligence. <em>NATMI</em>, <em>7</em>(4), 522-530. (<a href='https://doi.org/10.1038/s42256-025-01024-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) tools are increasingly being used to help make consequential decisions about individuals. While AI models may be accurate on average, they can simultaneously be highly uncertain about outcomes associated with specific individuals or groups of individuals. For high-stakes applications (such as healthcare and medicine, defence and security, banking and finance), AI decision-support systems must be able to make personalized assessments of uncertainty in a rigorous manner. However, the statistical frameworks needed to do so are currently incomplete. Here, we outline current approaches to personalized uncertainty quantification (PUQ) and define a set of grand challenges associated with the development and use of PUQ in a range of areas, including multimodal AI, explainable AI, generative AI and AI fairness. AI tools are increasingly used for important decisions, but they can be uncertain about specific individuals or groups. Chakraborty et al. discuss the need for better methods to assess uncertainty in high-stakes applications such as healthcare and finance, and outline a set of main challenges to provide practical guidance for AI researchers.},
  archive      = {J_NATMI},
  author       = {Chakraborti, Tapabrata and Banerji, Christopher R. S. and Marandon, Ariane and Hellon, Vicky and Mitra, Robin and Lehmann, Brieuc and Bräuninger, Leandra and McGough, Sarah and Turkay, Cagatay and Frangi, Alejandro F. and Bianconi, Ginestra and Li, Weizi and Rackham, Owen and Parashar, Deepak and Harbron, Chris and MacArthur, Ben},
  doi          = {10.1038/s42256-025-01024-8},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {522-530},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Personalized uncertainty quantification in artificial intelligence},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot planning with LLMs. <em>NATMI</em>, <em>7</em>(4), 521. (<a href='https://doi.org/10.1038/s42256-025-01036-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long horizon planning in robotics can benefit from combining classic control methods with the real-world knowledge capabilities of large language models.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01036-4},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {521},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Robot planning with LLMs},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking AI-powered docking methods from the perspective of virtual screening. <em>NATMI</em>, <em>7</em>(3), 509-520. (<a href='https://doi.org/10.1038/s42256-025-00993-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many artificial intelligence (AI)-powered protein–ligand docking and scoring methods have been developed, demonstrating impressive speed and accuracy. However, these methods often neglected the physical plausibility of the docked complexes and their efficacy in virtual screening (VS) projects. Therefore, we conducted a comprehensive benchmark analysis of four AI-powered and four physics-based docking tools and two AI-enhanced rescoring methods. We initially constructed the TrueDecoy set, a dataset on which the redocking experiments revealed that KarmaDock and CarsiDock surpassed all physics-based tools in docking accuracy, whereas all physics-based tools notably outperformed AI-based methods in structural rationality. The low physical plausibility of docked structures generated by the top AI method, CarsiDock, mainly stems from insufficient intermolecular validity. The VS results on the TrueDecoy set highlight the effectiveness of RTMScore as a rescore function, and Glide-based methods achieved the highest enrichment factors among all docking tools. Furthermore, we created the RandomDecoy set, a dataset that more closely resembles real-world VS scenarios, where AI-based tools obviously outperformed Glide. Additionally, we found that the employed ligand-based postprocessing methods had a weak or even negative impact on optimizing the conformations of docked complexes and enhancing VS performance. Finally, we proposed a hierarchical VS strategy that could efficiently and accurately enrich active molecules in large-scale VS projects. Artificial intelligence (AI)-based docking and scoring methods demonstrate considerable potential for virtual drug screening. Gu et al. go further by assessing the structural rationality of AI-predicted complex conformations from various sources.},
  archive      = {J_NATMI},
  author       = {Gu, Shukai and Shen, Chao and Zhang, Xujun and Sun, Huiyong and Cai, Heng and Luo, Hao and Zhao, Huifeng and Liu, Bo and Du, Hongyan and Zhao, Yihao and Fu, Chenggong and Zhai, Silong and Deng, Yafeng and Liu, Huanxiang and Hou, Tingjun and Kang, Yu},
  doi          = {10.1038/s42256-025-00993-0},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {509-520},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Benchmarking AI-powered docking methods from the perspective of virtual screening},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a more inductive world for drug repurposing approaches. <em>NATMI</em>, <em>7</em>(3), 495-508. (<a href='https://doi.org/10.1038/s42256-025-00987-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction is a challenging albeit essential task in drug repurposing. Learning on graph models has drawn special attention as they can substantially reduce drug repurposing costs and time commitment. However, many current approaches require high-demand additional information besides DTIs that complicates their evaluation process and usability. Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking. In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process and show that DTI methods based on transductive models lack generalization and lead to inflated performance when traditionally evaluated, making them unsuitable for drug repurposing. We then propose a biologically driven strategy for negative-edge subsampling and uncovered previously unknown interactions via in vitro validation, missed by traditional subsampling. Finally, we provide a toolbox from all generated resources, crucial for fair benchmarking and robust model design. The authors address the challenge of predicting drug–target interactions, which is crucial for drug repurposing, by introducing a robust benchmarking framework. Using a biologically driven strategy, they uncover previously unknown interactions.},
  archive      = {J_NATMI},
  author       = {de la Fuente, Jesus and Serrano, Guillermo and Veleiro, Uxía and Casals, Mikel and Vera, Laura and Pizurica, Marija and Gómez-Cebrián, Nuria and Puchades-Carrasco, Leonor and Pineda-Lucena, Antonio and Ochoa, Idoia and Vicent, Silve and Gevaert, Olivier and Hernaez, Mikel},
  doi          = {10.1038/s42256-025-00987-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {495-508},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards a more inductive world for drug repurposing approaches},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teaching robots to build simulations of themselves. <em>NATMI</em>, <em>7</em>(3), 484-494. (<a href='https://doi.org/10.1038/s42256-025-01006-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of vision catalysed a pivotal evolutionary advancement, enabling organisms not only to perceive but also to interact intelligently with their environment. This transformation is mirrored by the evolution of robotic systems, where the ability to leverage vision to simulate and predict their own dynamics marks a leap towards autonomy and self-awareness. Humans utilize vision to record experiences and internally simulate potential actions. For example, we can imagine that, if we stand up and raise our arms, the body will form a ‘T’ shape without physical movement. Similarly, simulation allows robots to plan and predict the outcomes of potential actions without execution. Here we introduce a self-supervised learning framework to enable robots to model and predict their morphology, kinematics and motor control using only brief raw video data, eliminating the need for extensive real-world data collection and kinematic priors. By observing their own movements, akin to humans watching their reflection in a mirror, robots learn an ability to simulate themselves and predict their spatial motion for various tasks. Our results demonstrate that this self-learned simulation not only enables accurate motion planning but also allows the robot to detect abnormalities and recover from damage. Motion planning for a robot generally requires full knowledge of its structure. Here Hu and colleagues present a method for inferring the structure of a robot from visual information.},
  archive      = {J_NATMI},
  author       = {Hu, Yuhang and Lin, Jiong and Lipson, Hod},
  doi          = {10.1038/s42256-025-01006-w},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {484-494},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Teaching robots to build simulations of themselves},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards unveiling sensitive and decisive patterns in explainable AI with a case study in geometric deep learning. <em>NATMI</em>, <em>7</em>(3), 471-483. (<a href='https://doi.org/10.1038/s42256-025-00998-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interpretability of machine learning models has gained increasing attention, particularly in scientific domains where high precision and accountability are crucial. This research focuses on distinguishing between two critical data patterns—sensitive patterns (model related) and decisive patterns (task related)—which are commonly used as model interpretations but often lead to confusion. Specifically, this study compares the effectiveness of two main streams of interpretation methods: post-hoc methods and self-interpretable methods, in detecting these patterns. Recently, geometric deep learning (GDL) has shown superior predictive performance in various scientific applications, creating an urgent need for principled interpretation methods. Here, therefore, we conduct our study using several representative GDL applications as case studies. We evaluate 13 interpretation methods applied to 3 major GDL backbone models, using 4 scientific datasets to assess how well these methods identify sensitive and decisive patterns. Our findings indicate that post-hoc methods tend to provide interpretations better aligned with sensitive patterns, whereas certain self-interpretable methods exhibit strong and stable performance in detecting decisive patterns. Moreover, our study offers valuable insights into improving the reliability of these interpretation methods. For example, ensembling post-hoc interpretations from multiple models trained on the same task can effectively uncover the task’s decisive patterns. Interpreting decisions made by machine learning systems remains difficult. Here Zhu et al. test interpretability methods on their ability to identify model-related and task-related patterns.},
  archive      = {J_NATMI},
  author       = {Zhu, Jiajun and Miao, Siqi and Ying, Rex and Li, Pan},
  doi          = {10.1038/s42256-025-00998-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {471-483},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards unveiling sensitive and decisive patterns in explainable AI with a case study in geometric deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Categorizing robots by performance fitness into the tree of robots. <em>NATMI</em>, <em>7</em>(3), 459-470. (<a href='https://doi.org/10.1038/s42256-025-00995-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are typically classified based on specific morphological features, like their kinematic structure. However, a complex interplay between morphology and intelligence shapes how well a robot performs processes. Just as delicate surgical procedures demand high dexterity and tactile precision, manual warehouse or construction work requires strength and endurance. These process requirements necessitate robot systems that provide a level of performance fitting the process. In this work, we introduce the tree of robots as a taxonomy to bridge the gap between morphological classification and process-based performance. It classifies robots based on their fitness to perform, for example, physical interaction processes. Using 11 industrial manipulators, we constructed the first part of the tree of robots based on a carefully deduced set of metrics reflecting fundamental robot capabilities for various industrial physical interaction processes. Through significance analysis, we identified substantial differences between the systems, grouping them via an expectation-maximization algorithm to create a fitness-based robot classification that is open for contributions and accessible. It is challenging to compare how well robots perform a task, as the evaluation depends on the process and skills required. It is proposed to group robots into a taxonomy based on their performance on a set of embodied skill benchmarks.},
  archive      = {J_NATMI},
  author       = {Kirschner, Robin Jeanne and Karacan, Kübra and Melone, Alessandro and Haddadin, Sami},
  doi          = {10.1038/s42256-025-00995-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {459-470},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Categorizing robots by performance fitness into the tree of robots},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep lead optimization enveloped in protein pocket and its application in designing potent and selective ligands targeting LTK protein. <em>NATMI</em>, <em>7</em>(3), 448-458. (<a href='https://doi.org/10.1038/s42256-025-00997-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the chemical structure of promising drug candidates through systematic modifications to improve potency and physiochemical properties is a vital step in the drug discovery pipeline. In contrast to the well-established de novo generation schemes, computational methods specifically tailored for lead optimization remain largely underexplored. Prior models are often limited to addressing specific subtasks, such as generating two-dimensional molecular structures, while neglecting crucial protein–ligand interactions in three-dimensional space. To overcome these challenges, we propose Delete (Deep lead optimization enveloped in protein pocket), a one-stop solution for lead optimization by combining generative artificial intelligence and structure-based approaches. Our model can handle all subtasks of lead optimization through a unified deleting (masking) strategy, and it accounts for intricate pocket–ligand interactions through an equivariant network design. Statistical assessments and retrospective studies across individual subtasks demonstrate that Delete has an outstanding ability to craft molecules with superior protein-binding energy and reasonable drug-likeness using given fragments or atoms. Subsequently, we utilize Delete to design inhibitors targeting the previously identified LTK protein. Among the ligands designed by Delete, CA-B-1 is successfully validated as a potent (1.36 nM) and selective inhibitor by in vitro and in vivo experiments. This work represents a successful implementation of the powerful structure-based lead optimization model, Delete, for rapid and controllable rational drug design. Chen et al. present a deep learning-based lead optimization model that combines generative artificial intelligence with structure-based approaches. The method is successfully applied to the design of drug-like molecules targeting the recently identified LTK protein target with high potency and selectivity.},
  archive      = {J_NATMI},
  author       = {Chen, Shicheng and Zhang, Odin and Jiang, Chenran and Zhao, Huifeng and Zhang, Xujun and Chen, Mengting and Liu, Yun and Su, Qun and Wu, Zhenxing and Wang, Xinyue and Qu, Wanglin and Ye, Yuanyi and Chai, Xin and Wang, Ning and Wang, Tianyue and An, Yuan and Wu, Guanlin and Yang, Qianqian and Chen, Jiean and Xie, Wei and Lin, Haitao and Li, Dan and Hsieh, Chang-Yu and Huang, Yong and Kang, Yu and Hou, Tingjun and Pan, Peichen},
  doi          = {10.1038/s42256-025-00997-w},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {448-458},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep lead optimization enveloped in protein pocket and its application in designing potent and selective ligands targeting LTK protein},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for scientific discovery in molecular property prediction. <em>NATMI</em>, <em>7</em>(3), 437-447. (<a href='https://doi.org/10.1038/s42256-025-00994-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are a form of artificial intelligence system encapsulating vast knowledge in the form of natural language. These systems are adept at numerous complex tasks including creative writing, storytelling, translation, question-answering, summarization and computer code generation. Although LLMs have seen initial applications in natural sciences, their potential for driving scientific discovery remains largely unexplored. In this work, we introduce LLM4SD, a framework designed to harness LLMs for driving scientific discovery in molecular property prediction by synthesizing knowledge from literature and inferring knowledge from scientific data. LLMs synthesize knowledge by extracting established information from scientific literature, such as molecular weight being key to predicting solubility. For inference, LLMs identify patterns in molecular data, particularly in Simplified Molecular Input Line Entry System-encoded structures, such as halogen-containing molecules being more likely to cross the blood–brain barrier. This information is presented as interpretable knowledge, enabling the transformation of molecules into feature vectors. By using these features with interpretable models such as random forest, LLM4SD can outperform the current state of the art across a range of benchmark tasks for predicting molecular properties. We foresee it providing interpretable and potentially new insights, aiding scientific discovery in molecular property prediction. Zheng et al. developed LLM4SD, a framework using large language models to predict molecular properties. The method leverages the ability of large language models to synthesize knowledge from literature and to reason about scientific data with domain expertise.},
  archive      = {J_NATMI},
  author       = {Zheng, Yizhen and Koh, Huan Yee and Ju, Jiaxin and Nguyen, Anh T. N. and May, Lauren T. and Webb, Geoffrey I. and Pan, Shirui},
  doi          = {10.1038/s42256-025-00994-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {437-447},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models for scientific discovery in molecular property prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven federated learning in drug discovery with knowledge distillation. <em>NATMI</em>, <em>7</em>(3), 423-436. (<a href='https://doi.org/10.1038/s42256-025-00991-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A main challenge for artificial intelligence in scientific research is ensuring access to sufficient, high-quality data for the development of impactful models. Despite the abundance of public data, the most valuable knowledge often remains embedded within confidential corporate data silos. Although industries are increasingly open to sharing non-competitive insights, such collaboration is often constrained by the confidentiality of the underlying data. Federated learning makes it possible to share knowledge without compromising data privacy, but it has notable limitations. Here, we introduce FLuID (federated learning using information distillation), a data-centric application of federated distillation tailored to drug discovery aiming to preserve data privacy. We validate FLuID in two experiments, first involving public data simulating a virtual consortium and second in a real-world research collaboration between eight pharmaceutical companies. Although the alignment of the models with the partner specific domain remains challenging, the data-driven nature of FLuID offers several avenues to mitigate domain shift. FLuID fosters knowledge sharing among pharmaceutical organizations, paving the way for a new generation of models with enhanced performance and an expanded applicability domain in biological activity predictions. FLuID enables privacy-preserving knowledge sharing in drug discovery using knowledge distillation. The results show that the approach expands applicability domains and fosters collaboration across organizations without compromising data privacy or security.},
  archive      = {J_NATMI},
  author       = {Hanser, Thierry and Ahlberg, Ernst and Amberg, Alexander and Anger, Lennart T. and Barber, Chris and Brennan, Richard J. and Brigo, Alessandro and Delaunois, Annie and Glowienke, Susanne and Greene, Nigel and Johnston, Laura and Kuhn, Daniel and Kuhnke, Lara and Marchaland, Jean-François and Muster, Wolfgang and Plante, Jeffrey and Rippmann, Friedrich and Sabnis, Yogesh and Schmidt, Friedemann and van Deursen, Ruud and Werner, Stéphane and White, Angela and Wichard, Joerg and Yukawa, Tomoya},
  doi          = {10.1038/s42256-025-00991-2},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {423-436},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Data-driven federated learning in drug discovery with knowledge distillation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable AI reveals clever hans effects in unsupervised learning models. <em>NATMI</em>, <em>7</em>(3), 412-422. (<a href='https://doi.org/10.1038/s42256-025-01000-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised learning has become an essential building block of artifical intelligence systems. The representations it produces, for example, in foundation models, are critical to a wide variety of downstream applications. It is therefore important to carefully examine unsupervised models to ensure not only that they produce accurate predictions on the available data but also that these accurate predictions do not arise from a Clever Hans (CH) effect. Here, using specially developed explainable artifical intelligence techniques and applying them to popular representation learning and anomaly detection models for image data, we show that CH effects are widespread in unsupervised learning. In particular, through use cases on medical and industrial inspection data, we demonstrate that CH effects systematically lead to significant performance loss of downstream models under plausible dataset shifts or reweighting of different data subgroups. Our empirical findings are enriched by theoretical insights, which point to inductive biases in the unsupervised learning machine as a primary source of CH effects. Overall, our work sheds light on unexplored risks associated with practical applications of unsupervised learning and suggests ways to systematically mitigate CH effects, thereby making unsupervised learning more robust. Building on recent explainable AI techniques, this Article highlights the pervasiveness of Clever Hans effects in unsupervised learning and the substantial risks associated with these effects in terms of the prediction accuracy on new data.},
  archive      = {J_NATMI},
  author       = {Kauffmann, Jacob and Dippel, Jonas and Ruff, Lukas and Samek, Wojciech and Müller, Klaus-Robert and Montavon, Grégoire},
  doi          = {10.1038/s42256-025-01000-2},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {412-422},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Explainable AI reveals clever hans effects in unsupervised learning models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models that replace human participants can harmfully misportray and flatten identity groups. <em>NATMI</em>, <em>7</em>(3), 400-411. (<a href='https://doi.org/10.1038/s42256-025-00986-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are increasing in capability and popularity, propelling their application in new domains—including as replacements for human participants in computational social science, user testing, annotation tasks and so on. In many settings, researchers seek to distribute their surveys to a sample of participants that are representative of the underlying human population of interest. This means that to be a suitable replacement, LLMs will need to be able to capture the influence of positionality (that is, the relevance of social identities like gender and race). However, we show that there are two inherent limitations in the way current LLMs are trained that prevent this. We argue analytically for why LLMs are likely to both misportray and flatten the representations of demographic groups, and then empirically show this on four LLMs through a series of human studies with 3,200 participants across 16 demographic identities. We also discuss a third limitation about how identity prompts can essentialize identities. Throughout, we connect each limitation to a pernicious history of epistemic injustice against the value of lived experiences that explains why replacement is harmful for marginalized demographic groups. Overall, we urge caution in use cases in which LLMs are intended to replace human participants whose identities are relevant to the task at hand. At the same time, in cases where the benefits of LLM replacement are determined to outweigh the harms (for example, engaging human participants may cause them harm, or the goal is to supplement rather than fully replace), we empirically demonstrate that our inference-time techniques reduce—but do not remove—these harms. Large language models are being considered to simulate responses from participants of different backgrounds in computational social science experiments. Here it is shown that this practice can misportray and flatten demographic groups in distinctively harmful ways.},
  archive      = {J_NATMI},
  author       = {Wang, Angelina and Morgenstern, Jamie and Dickerson, John P.},
  doi          = {10.1038/s42256-025-00986-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {400-411},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models that replace human participants can harmfully misportray and flatten identity groups},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergy-based robotic quadruped leveraging passivity for natural intelligence and behavioural diversity. <em>NATMI</em>, <em>7</em>(3), 386-399. (<a href='https://doi.org/10.1038/s42256-025-00988-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadrupedal animals show remarkable capabilities in traversing diverse terrains and display a range of behaviours and gait patterns. Achieving similar performance by exploiting the natural dynamics of the system is a key goal for robotics researchers. Here we show a bioinspired approach to the design of quadrupeds that seeks to exploit the body and the passive properties of the robot while maintaining active controllability on the system through minimal actuation. Utilizing an end-to-end computational design pipeline, neuromechanical couplings recorded in biological quadrupeds are translated into motor synergies, allowing minimal actuation to control the full structure via multijoint compliant mechanical couplings. Using this approach, we develop PAWS, a passive automata with synergies. By leveraging the principles of motor synergies, the design incorporates variable stiffness, anatomical insights and self-organization to simplify control while maximizing its capabilities. The resulting synergy-based quadruped requires only four actuators and exhibits emergent, animal-like dynamical responses, including passive robustness to environmental perturbations and a wide range of actuated behaviours. The finding contributes to the development of machine physical intelligence and provides robots with more efficient and natural-looking robotic locomotion by combining synergistic actuation, compliant body properties and embodied compensatory strategies. Stella, Achkar and colleagues present a bio-inspired quadruped robot that uses passive dynamics, motor synergies, variable stiffness and self-organization to achieve robust, adaptive, animal-like movement with just four actuators.},
  archive      = {J_NATMI},
  author       = {Stella, Francesco and Achkar, Mickaël M. and Della Santina, Cosimo and Hughes, Josie},
  doi          = {10.1038/s42256-025-00988-x},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {386-399},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Synergy-based robotic quadruped leveraging passivity for natural intelligence and behavioural diversity},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum circuit optimization with AlphaTensor. <em>NATMI</em>, <em>7</em>(3), 374-385. (<a href='https://doi.org/10.1038/s42256-025-01001-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in realizing fault-tolerant quantum computers is circuit optimization. Focusing on the most expensive gates in fault-tolerant quantum computation (namely, the T gates), we address the problem of T-count optimization, that is, minimizing the number of T gates needed to implement a given circuit. To achieve this, we develop AlphaTensor-Quantum, a method based on deep reinforcement learning that exploits the relationship between optimizing the T-count and tensor decomposition. Unlike existing methods for T-count optimization, AlphaTensor-Quantum can incorporate domain-specific knowledge about quantum computation and leverage gadgets, which substantially reduces the T-count of the optimized circuits. AlphaTensor-Quantum outperforms the existing methods for T-count optimization on a set of arithmetic benchmarks (even when compared without using gadgets). Remarkably, it discovers an efficient algorithm akin to Karatsuba’s method for multiplication in finite fields. AlphaTensor-Quantum also finds the best human-designed solutions for relevant arithmetic computations used in Shor’s algorithm and for quantum chemistry simulation, thus demonstrating that it can save hundreds of hours of research by optimizing relevant quantum circuits in a fully automated way. Ruiz and colleagues introduce AlphaTensor-Quantum, a deep reinforcement learning method for optimizing quantum circuits. It outperforms existing methods and is capable of finding the best human-designed solutions for relevant quantum computations in a fully automated way.},
  archive      = {J_NATMI},
  author       = {Ruiz, Francisco J. R. and Laakkonen, Tuomas and Bausch, Johannes and Balog, Matej and Barekatain, Mohammadamin and Heras, Francisco J. H. and Novikov, Alexander and Fitzpatrick, Nathan and Romera-Paredes, Bernardino and van de Wetering, John and Fawzi, Alhussein and Meichanetzidis, Konstantinos and Kohli, Pushmeet},
  doi          = {10.1038/s42256-025-01001-1},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {374-385},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Quantum circuit optimization with AlphaTensor},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast, scale-adaptive and uncertainty-aware downscaling of earth system model fields with generative machine learning. <em>NATMI</em>, <em>7</em>(3), 363-373. (<a href='https://doi.org/10.1038/s42256-025-00980-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and high-resolution Earth system model (ESM) simulations are essential to assess the ecological and socioeconomic impacts of anthropogenic climate change, but are computationally too expensive to be run at sufficiently high spatial resolution. Recent machine learning approaches have shown promising results in downscaling ESM simulations, outperforming state-of-the-art statistical approaches. However, existing methods require computationally costly retraining for each ESM and extrapolate poorly to climates unseen during training. We address these shortcomings by learning a consistency model that efficiently and accurately downscales arbitrary ESM simulations without retraining in a zero-shot manner. Our approach yields probabilistic downscaled fields at a resolution only limited by the observational reference data. We show that the consistency model outperforms state-of-the-art diffusion models at a fraction of the computational cost and maintains high controllability on the downscaling task. Further, our method generalizes to climate states unseen during training without explicitly formulated physical constraints. A generative machine learning approach is proposed to improve the resolution of Earth system models in an efficient, adaptive and uncertainty-aware manner.},
  archive      = {J_NATMI},
  author       = {Hess, Philipp and Aich, Michael and Pan, Baoxiang and Boers, Niklas},
  doi          = {10.1038/s42256-025-00980-5},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {363-373},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Fast, scale-adaptive and uncertainty-aware downscaling of earth system model fields with generative machine learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformers and genome language models. <em>NATMI</em>, <em>7</em>(3), 346-362. (<a href='https://doi.org/10.1038/s42256-025-01007-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models based on the transformer deep learning architecture have revolutionized natural language processing. Motivated by the analogy between human language and the genome’s biological code, researchers have begun to develop genome language models (gLMs) based on transformers and related architectures. This Review explores the use of transformers and language models in genomics. We survey open questions in genomics amenable to the use of gLMs, and motivate the use of gLMs and the transformer architecture for these problems. We discuss the potential of gLMs for modelling the genome using unsupervised pretraining tasks, specifically focusing on the power of zero- and few-shot learning. We explore the strengths and limitations of the transformer architecture, as well as the strengths and limitations of current gLMs more broadly. Additionally, we contemplate the future of genomic modelling beyond the transformer architecture, based on current trends in research. This Review serves as a guide for computational biologists and computer scientists interested in transformers and language models for genomic data. Micaela Consens et al. discuss and review the recent rise of transformer-based and large language models in genomics. They also highlight promising directions for genome language models beyond the transformer architecture.},
  archive      = {J_NATMI},
  author       = {Consens, Micaela E. and Dufault, Cameron and Wainberg, Michael and Forster, Duncan and Karimzadeh, Mehran and Goodarzi, Hani and Theis, Fabian J. and Moses, Alan and Wang, Bo},
  doi          = {10.1038/s42256-025-01007-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {346-362},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Transformers and genome language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Materiality and risk in the age of pervasive AI sensors. <em>NATMI</em>, <em>7</em>(3), 334-345. (<a href='https://doi.org/10.1038/s42256-025-01017-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) systems connected to sensor-laden devices are becoming pervasive, which has notable implications for a range of AI risks, including to privacy, the environment, autonomy and more. There is therefore a growing need for increased accountability around the responsible development and deployment of these technologies. Here we highlight the dimensions of risk associated with AI systems that arise from the material affordances of sensors and their underlying calculative models. We propose a sensor-sensitive framework for diagnosing these risks, complementing existing approaches such as the US National Institute of Standards and Technology AI Risk Management Framework and the European Union AI Act, and discuss its implementation. We conclude by advocating for increased attention to the materiality of algorithmic systems, and of on-device AI sensors in particular, and highlight the need for development of a sensor design paradigm that empowers users and communities and leads to a future of increased fairness, accountability and transparency. Sloane and colleagues review emerging new dimensions of risks associated with materiality and AI algorithms run on pervasive sensors.},
  archive      = {J_NATMI},
  author       = {Sloane, Mona and Moss, Emanuel and Kennedy, Susan and Stewart, Matthew and Warden, Pete and Plancher, Brian and Reddi, Vijay Janapa},
  doi          = {10.1038/s42256-025-01017-7},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {334-345},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Materiality and risk in the age of pervasive AI sensors},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From data chaos to precision medicine. <em>NATMI</em>, <em>7</em>(3), 332-333. (<a href='https://doi.org/10.1038/s42256-025-01015-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 30 years have passed since the advent of omics technologies revolutionized biological and medical research. Research now highlights the unique opportunity to integrate and decode complex biological mechanisms for health and diseases with machine learning.},
  archive      = {J_NATMI},
  author       = {Schönhuth, Alexander},
  doi          = {10.1038/s42256-025-01015-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {332-333},
  shortjournal = {Nat. Mach. Intell.},
  title        = {From data chaos to precision medicine},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the gap between machine confidence and human perceptions. <em>NATMI</em>, <em>7</em>(3), 330-331. (<a href='https://doi.org/10.1038/s42256-025-01013-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users often overestimate the accuracy of large language models (LLMs). A new approach examines user perceptions and finds that aligning LLM explanations with the models’ internal confidence improves user perception.},
  archive      = {J_NATMI},
  author       = {Yin, Ming},
  doi          = {10.1038/s42256-025-01013-x},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {330-331},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging the gap between machine confidence and human perceptions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transparency (in training data) is what we want. <em>NATMI</em>, <em>7</em>(3), 329. (<a href='https://doi.org/10.1038/s42256-025-01023-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As more powerful generative AI tools appear on the market, legal debates about the use of copyrighted content to develop such tools are intensifying. To resolve these issues, transparency regarding which copyrighted data have been used and where in the AI training pipeline needs to be a starting point.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01023-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {329},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Transparency (in training data) is what we want},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Author correction: Kernel approximation using analogue in-memory computing. <em>NATMI</em>, <em>7</em>(2), 328. (<a href='https://doi.org/10.1038/s42256-025-00996-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Büchel, Julian and Camposampiero, Giacomo and Vasilopoulos, Athanasios and Lammie, Corey and Le Gallo, Manuel and Rahimi, Abbas and Sebastian, Abu},
  doi          = {10.1038/s42256-025-00996-x},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {328},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Kernel approximation using analogue in-memory computing},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantitative analysis of knowledge-learning preferences in large language models in molecular science. <em>NATMI</em>, <em>7</em>(2), 315-327. (<a href='https://doi.org/10.1038/s42256-024-00977-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has significantly advanced molecular modelling and design, enabling an efficient understanding and discovery of novel molecules. In particular, large language models introduce a fresh research paradigm to tackle scientific problems from a natural language processing perspective. Large language models significantly enhance our understanding and generation of molecules, often surpassing existing methods with their capabilities to decode and synthesize complex molecular patterns. However, two key issues remain: how to quantify the match between model and data modalities and how to identify the knowledge-learning preferences of models. To address these challenges, we propose a multimodal benchmark, named ChEBI-20-MM, and perform 1,263 experiments to assess the model’s compatibility with data modalities and knowledge acquisition. Through the modal transition probability matrix, we provide insights into the most suitable modalities for tasks. Furthermore, we introduce a statistically interpretable approach to discover context-specific knowledge mapping by localized feature filtering. Our analysis offers an exploration of the learning mechanism and paves the way for advancing large language models in molecular science. Large language models promise substantial advances in molecular modelling and design. A multimodal benchmark is proposed to analyse performance, and 1,263 experiments are conducted to examine the compatibility of a large language model with data modalities and knowledge acquisition.},
  archive      = {J_NATMI},
  author       = {Liu, Pengfei and Tao, Jun and Ren, Zhixiang},
  doi          = {10.1038/s42256-024-00977-6},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {315-327},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A quantitative analysis of knowledge-learning preferences in large language models in molecular science},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering fully semantic representations via centroid- and orientation-aware feature learning. <em>NATMI</em>, <em>7</em>(2), 307-314. (<a href='https://doi.org/10.1038/s42256-024-00978-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning meaningful representations of images in scientific domains that are robust to variations in centroids and orientations remains an important challenge. Here we introduce centroid- and orientation-aware disentangling autoencoder (CODAE), an encoder–decoder-based neural network that learns meaningful content of objects in a latent space. Specifically, a combination of a translation- and rotation-equivariant encoder, Euler encoding and an image moment loss enables CODAE to extract features invariant to positions and orientations of objects of interest from randomly translated and rotated images. We evaluate this approach on several publicly available scientific datasets, including protein images from life sciences, four-dimensional scanning transmission electron microscopy data from material science and galaxy images from astronomy. The evaluation shows that CODAE learns centroids, orientations and their invariant features and outputs, as well as aligned reconstructions and the exact view reconstructions of the input images with high quality. Cha and colleagues present a translation- and rotation-equivariant autoencoder-based method for robust image recognition, which they demonstrate on diverse tasks from bioinformatics, material science and astronomy.},
  archive      = {J_NATMI},
  author       = {Cha, Jaehoon and Park, Jinhae and Pinilla, Samuel and Morris, Kyle L. and Allen, Christopher S. and Wilkinson, Mark I. and Thiyagalingam, Jeyan},
  doi          = {10.1038/s42256-024-00978-5},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {307-314},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Discovering fully semantic representations via centroid- and orientation-aware feature learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A machine learning approach to leveraging electronic health records for enhanced omics analysis. <em>NATMI</em>, <em>7</em>(2), 293-306. (<a href='https://doi.org/10.1038/s42256-024-00974-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Omics studies produce a large number of measurements, enabling the development, validation and interpretation of systems-level biological models. Large cohorts are required to power these complex models; yet, the cohort size remains limited due to clinical and budgetary constraints. We introduce clinical and omics multimodal analysis enhanced with transfer learning (COMET), a machine learning framework that incorporates large, observational electronic health record databases and transfer learning to improve the analysis of small datasets from omics studies. By pretraining on electronic health record data and adaptively blending both early and late fusion strategies, COMET overcomes the limitations of existing multimodal machine learning methods. Using two independent datasets, we showed that COMET improved the predictive modelling performance and biological discovery compared with the analysis of omics data with traditional methods. By incorporating electronic health record data into omics analyses, COMET enables more precise patient classifications, beyond the simplistic binary reduction to cases and controls. This framework can be broadly applied to the analysis of multimodal omics studies and reveals more powerful biological insights from limited cohort sizes. COMET, an artificial intelligence method that improves the analysis of small medical studies using large clinical databases, has been created. COMET can help develop better artificial intelligence tools and identify key biomarkers across many diseases, potentially changing medical research.},
  archive      = {J_NATMI},
  author       = {Mataraso, Samson J. and Espinosa, Camilo A. and Seong, David and Reincke, S. Momsen and Berson, Eloise and Reiss, Jonathan D. and Kim, Yeasul and Ghanem, Marc and Shu, Chi-Hung and James, Tomin and Tan, Yuqi and Shome, Sayane and Stelzer, Ina A. and Feyaerts, Dorien and Wong, Ronald J. and Shaw, Gary M. and Angst, Martin S. and Gaudilliere, Brice and Stevenson, David K. and Aghaeepour, Nima},
  doi          = {10.1038/s42256-024-00974-9},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {293-306},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A machine learning approach to leveraging electronic health records for enhanced omics analysis},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified cross-attention model for predicting antigen binding specificity to both HLA and TCR molecules. <em>NATMI</em>, <em>7</em>(2), 278-292. (<a href='https://doi.org/10.1038/s42256-024-00973-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immune checkpoint inhibitors have demonstrated promising clinical efficacy across various tumour types, yet the percentage of patients who benefit from them remains low. The bindings between tumour antigens and human leukocyte antigen class I/T cell receptor molecules determine the antigen presentation and T cell activation, thereby playing an important role in the immunotherapy response. In this paper, we propose UnifyImmun, a unified cross-attention transformer model designed to simultaneously predict the bindings of peptides to both receptors, providing more comprehensive evaluation of antigen immunogenicity. We devise a two-phase strategy using virtual adversarial training that enables these two tasks to reinforce each other mutually, by compelling the encoders to extract more expressive features. Our method demonstrates superior performance in predicting both peptide-HLA and peptide-TCR binding on multiple independent and external test sets. Notably, on a large-scale COVID-19 peptide-TCR binding test set without any seen peptide in the training set, our method outperforms the current state-of-the-art methods by more than 10%. The predicted binding scores significantly correlate with the immunotherapy response and clinical outcomes on two clinical cohorts. Furthermore, the cross-attention scores and integrated gradients reveal the amino acid sites critical for peptide binding to receptors. In essence, our approach marks an essential step towards comprehensive evaluation of antigen immunogenicity. This work proposes a deep learning model based on the cross-attention mechanism to simultaneously predict peptide–HLA and peptide–TCR bindings. Experiments verify that its performance for both prediction tasks on multiple test sets compares favourably with previous methods.},
  archive      = {J_NATMI},
  author       = {Yu, Chenpeng and Fang, Xing and Tian, Shiye and Liu, Hui},
  doi          = {10.1038/s42256-024-00973-w},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {278-292},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A unified cross-attention model for predicting antigen binding specificity to both HLA and TCR molecules},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Battery lifetime prediction across diverse ageing conditions with inter-cell deep learning. <em>NATMI</em>, <em>7</em>(2), 270-277. (<a href='https://doi.org/10.1038/s42256-024-00972-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting battery lifetime in early cycles holds tremendous value in real-world applications. However, this task poses significant challenges due to diverse factors influencing complex battery capacity degradation, such as cycling protocols, ambient temperatures and electrode materials. Moreover, cycling under specific conditions is both resource-intensive and time-consuming. Existing predictive models, primarily developed and validated within a restricted set of ageing conditions, thus raise doubts regarding their extensive applicability. Here we introduce BatLiNet, a deep learning framework tailored to predict battery lifetime reliably across a variety of ageing conditions. The distinctive design is integrating an inter-cell learning mechanism to predict the lifetime differences between two battery cells. This mechanism, when combined with conventional single-cell learning, enhances the stability of lifetime predictions for a target cell under varied ageing conditions. Our experimental results, derived from a broad spectrum of ageing conditions, demonstrate BatLiNet’s superior accuracy and robustness compared to existing models. BatLiNet also exhibits transferring capabilities across different battery chemistries, benefitting scenarios with limited resources. We expect this study could promote exploration of cross-cell insights and facilitate battery research across comprehensive ageing factors. Zhang and colleagues introduce an inter-cell learning mechanism to predict battery lifetime in the presence of diverse ageing conditions.},
  archive      = {J_NATMI},
  author       = {Zhang, Han and Li, Yuqi and Zheng, Shun and Lu, Ziheng and Gui, Xiaofan and Xu, Wei and Bian, Jiang},
  doi          = {10.1038/s42256-024-00972-x},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {270-277},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Battery lifetime prediction across diverse ageing conditions with inter-cell deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preserving and combining knowledge in robotic lifelong reinforcement learning. <em>NATMI</em>, <em>7</em>(2), 256-269. (<a href='https://doi.org/10.1038/s42256-025-00983-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can continually accumulate knowledge and develop increasingly complex behaviours and skills throughout their lives, which is a capability known as ‘lifelong learning’. Although this lifelong learning capability is considered an essential mechanism that makes up general intelligence, recent advancements in artificial intelligence predominantly excel in narrow, specialized domains and generally lack this lifelong learning capability. Here we introduce a robotic lifelong reinforcement learning framework that addresses this gap by developing a knowledge space inspired by the Bayesian non-parametric domain. In addition, we enhance the agent’s semantic understanding of tasks by integrating language embeddings into the framework. Our proposed embodied agent can consistently accumulate knowledge from a continuous stream of one-time feeding tasks. Furthermore, our agent can tackle challenging real-world long-horizon tasks by combining and reapplying its acquired knowledge from the original tasks stream. The proposed framework advances our understanding of the robotic lifelong learning process and may inspire the development of more broadly applicable intelligence. Humans continuously acquire knowledge and develop complex behaviours. Meng, Bing, Yao and colleagues present a robotic lifelong learning framework using a Bayesian non-parametric knowledge space, enabling agents to dynamically preserve and integrate knowledge from sequential tasks, enhancing adaptability.},
  archive      = {J_NATMI},
  author       = {Meng, Yuan and Bing, Zhenshan and Yao, Xiangtong and Chen, Kejia and Huang, Kai and Gao, Yang and Sun, Fuchun and Knoll, Alois},
  doi          = {10.1038/s42256-025-00983-2},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {256-269},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Preserving and combining knowledge in robotic lifelong reinforcement learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image-based generation for molecule design with SketchMol. <em>NATMI</em>, <em>7</em>(2), 244-255. (<a href='https://doi.org/10.1038/s42256-025-00982-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient molecular design methods are crucial for accelerating early stage drug discovery, potentially saving years of development time and billions of dollars in costs. Current molecular design methods rely on sequence-based or graph-based representations, emphasizing local features such as bonds and atoms but lacking a comprehensive depiction of the overall molecular topology. Here we introduce SketchMol, an image-based molecular generation framework that combines visual understanding with molecular design. SketchMol leverages diffusion models and applies a refinement technique called reinforcement learning from molecular experts to improve the generation of viable molecules. It creates molecules through a painting-like approach that simultaneously depicts local structures and global layout of the molecule. By visualizing molecular structures, various design tasks are unified within a single image-based framework. De novo design becomes sketching new molecular images, whereas editing tasks transform into filling partially drawn images. Through extensive experiments, we demonstrated that SketchMol effectively handles a variety of molecular design tasks. SketchMol is a model that explores the feasibility of incorporating image generation techniques into the field of small-molecule design.},
  archive      = {J_NATMI},
  author       = {Wang, Zixu and Chen, Yangyang and Ma, Pengsen and Yu, Zhou and Wang, Jianmin and Liu, Yuansheng and Ye, Xiucai and Sakurai, Tetsuya and Zeng, Xiangxiang},
  doi          = {10.1038/s42256-025-00982-3},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {244-255},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Image-based generation for molecule design with SketchMol},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning enhances the prediction of HLA class I-presented CD8+ t cell epitopes in foreign pathogens. <em>NATMI</em>, <em>7</em>(2), 232-243. (<a href='https://doi.org/10.1038/s42256-024-00971-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate in silico determination of CD8+ T cell epitopes would greatly enhance T cell-based vaccine development, but current prediction models are not reliably successful. Here, motivated by recent successes applying machine learning to complex biology, we curated a dataset of 651,237 unique human leukocyte antigen class I (HLA-I) ligands and developed MUNIS, a deep learning model that identifies peptides presented by HLA-I alleles. MUNIS shows improved performance compared with existing models in predicting peptide presentation and CD8+ T cell epitope immunodominance hierarchies. Moreover, application of MUNIS to proteins from Epstein–Barr virus led to successful identification of both established and novel HLA-I epitopes which were experimentally validated by in vitro HLA-I-peptide stability and T cell immunogenicity assays. MUNIS performs comparably to an experimental stability assay in terms of immunogenicity prediction, suggesting that deep learning can reduce experimental burden and accelerate identification of CD8+ T cell epitopes for rapid T cell vaccine development. Accurate prediction of immunogenic CD8+ T cell epitopes would greatly accelerate T cell vaccine development. A new deep learning model, MUNIS, can rapidly identify HLA-binding, immunogenic and immunodominant peptides in foreign pathogens.},
  archive      = {J_NATMI},
  author       = {Wohlwend, Jeremy and Nathan, Anusha and Shalon, Nitan and Crain, Charles R. and Tano-Menka, Rhoda and Goldberg, Benjamin and Richards, Emma and Gaiha, Gaurav D. and Barzilay, Regina},
  doi          = {10.1038/s42256-024-00971-y},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {232-243},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning enhances the prediction of HLA class I-presented CD8+ t cell epitopes in foreign pathogens},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What large language models know and what people think they know. <em>NATMI</em>, <em>7</em>(2), 221-231. (<a href='https://doi.org/10.1038/s42256-024-00976-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence systems, particularly large language models (LLMs), become increasingly integrated into decision-making processes, the ability to trust their outputs is crucial. To earn human trust, LLMs must be well calibrated such that they can accurately assess and communicate the likelihood of their predictions being correct. Whereas recent work has focused on LLMs’ internal confidence, less is understood about how effectively they convey uncertainty to users. Here we explore the calibration gap, which refers to the difference between human confidence in LLM-generated answers and the models’ actual confidence, and the discrimination gap, which reflects how well humans and models can distinguish between correct and incorrect answers. Our experiments with multiple-choice and short-answer questions reveal that users tend to overestimate the accuracy of LLM responses when provided with default explanations. Moreover, longer explanations increased user confidence, even when the extra length did not improve answer accuracy. By adjusting LLM explanations to better reflect the models’ internal confidence, both the calibration gap and the discrimination gap narrowed, significantly improving user perception of LLM accuracy. These findings underscore the importance of accurate uncertainty communication and highlight the effect of explanation length in influencing user trust in artificial-intelligence-assisted decision-making environments. Understanding how people perceive and interpret uncertainty from large language models (LLMs) is crucial, as users often overestimate LLM accuracy, especially with default explanations. Steyvers et al. show that aligning LLM explanations with their internal confidence improves user perception.},
  archive      = {J_NATMI},
  author       = {Steyvers, Mark and Tejeda, Heliodoro and Kumar, Aakriti and Belem, Catarina and Karny, Sheer and Hu, Xinyue and Mayer, Lukas W. and Smyth, Padhraic},
  doi          = {10.1038/s42256-024-00976-7},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {221-231},
  shortjournal = {Nat. Mach. Intell.},
  title        = {What large language models know and what people think they know},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goals as reward-producing programs. <em>NATMI</em>, <em>7</em>(2), 205-220. (<a href='https://doi.org/10.1038/s42256-025-00981-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are remarkably capable of generating their own goals, beginning with child’s play and continuing into adulthood. Despite considerable empirical and computational work on goals and goal-oriented behaviour, models are still far from capturing the richness of everyday human goals. Here we bridge this gap by collecting a dataset of human-generated playful goals (in the form of scorable, single-player games), modelling them as reward-producing programs and generating novel human-like goals through program synthesis. Reward-producing programs capture the rich semantics of goals through symbolic operations that compose, add temporal constraints and allow program execution on behavioural traces to evaluate progress. To build a generative model of goals, we learn a fitness function over the infinite set of possible goal programs and sample novel goals with a quality-diversity algorithm. Human evaluators found that model-generated goals, when sampled from partitions of program space occupied by human examples, were indistinguishable from human-created games. We also discovered that our model’s internal fitness scores predict games that are evaluated as more fun to play and more human-like. To enable artificial agents to generate human-like goals, a model must capture the complexity and diversity of human goals. Davidson et al. model playful goals from a naturalistic experiment as reward-producing programs, mapping an agent’s behaviour to goal success. They then develop a computational model to generate diverse human-like goals.},
  archive      = {J_NATMI},
  author       = {Davidson, Guy and Todd, Graham and Togelius, Julian and Gureckis, Todd M. and Lake, Brenden M.},
  doi          = {10.1038/s42256-025-00981-4},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {205-220},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Goals as reward-producing programs},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary optimization of model merging recipes. <em>NATMI</em>, <em>7</em>(2), 195-204. (<a href='https://doi.org/10.1038/s42256-024-00975-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have become increasingly capable, but their development often requires substantial computational resources. Although model merging has emerged as a cost-effective promising approach for creating new models by combining existing ones, it currently relies on human intuition and domain knowledge, limiting its potential. Here we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models such as a Japanese LLM with math reasoning capabilities. Surprisingly, our Japanese math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with substantially more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally aware Japanese vision–language model generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese vision–language models. This work not only contributes new state-of-the-art models back to the open-source community but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development. Akiba et al. developed an evolutionary approach to automatically merge artificial intelligence models, creating powerful hybrid models without extensive training. The method produces models with enhanced mathematical and visual capabilities that outperform larger models.},
  archive      = {J_NATMI},
  author       = {Akiba, Takuya and Shing, Makoto and Tang, Yujin and Sun, Qi and Ha, David},
  doi          = {10.1038/s42256-024-00975-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {195-204},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Evolutionary optimization of model merging recipes},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking machine unlearning for large language models. <em>NATMI</em>, <em>7</em>(2), 181-194. (<a href='https://doi.org/10.1038/s42256-025-00985-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore machine unlearning in the domain of large language models (LLMs), referred to as LLM unlearning. This initiative aims to eliminate undesirable data influence (for example, sensitive or illegal information) and the associated model capabilities, while maintaining the integrity of essential knowledge generation and not affecting causally unrelated information. We envision LLM unlearning becoming a pivotal element in the life-cycle management of LLMs, potentially standing as an essential foundation for developing generative artificial intelligence that is not only safe, secure and trustworthy but also resource-efficient without the need for full retraining. We navigate the unlearning landscape in LLMs from conceptual formulation, methodologies, metrics and applications. In particular, we highlight the often-overlooked aspects of existing LLM unlearning research, for example, unlearning scope, data–model interaction and multifaceted efficacy assessment. We also draw connections between LLM unlearning and related areas such as model editing, influence functions, model explanation, adversarial training and reinforcement learning. Furthermore, we outline an effective assessment framework for LLM unlearning and explore its applications in copyright and privacy safeguards and sociotechnical harm reduction. Machine unlearning techniques remove undesirable data and associated model capabilities while preserving essential knowledge, so that machine learning models can be updated without costly retraining. Liu et al. review recent advances and opportunities in machine unlearning in LLMs, revisiting methodologies and overlooked principles for future improvements and exploring emerging applications in copyright and privacy safeguards and in reducing sociotechnical harms.},
  archive      = {J_NATMI},
  author       = {Liu, Sijia and Yao, Yuanshun and Jia, Jinghan and Casper, Stephen and Baracaldo, Nathalie and Hase, Peter and Yao, Yuguang and Liu, Chris Yuhao and Xu, Xiaojun and Li, Hang and Varshney, Kush R. and Bansal, Mohit and Koyejo, Sanmi and Liu, Yang},
  doi          = {10.1038/s42256-025-00985-0},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {181-194},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Rethinking machine unlearning for large language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the caveats of AI autophagy. <em>NATMI</em>, <em>7</em>(2), 172-180. (<a href='https://doi.org/10.1038/s42256-025-00984-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence (AI) technologies and large models are producing realistic outputs across various domains, such as images, text, speech and music. Creating these advanced generative models requires significant resources, particularly large and high-quality datasets. To minimize training expenses, many algorithm developers use data created by the models themselves as a cost-effective training solution. However, not all synthetic data effectively improve model performance, necessitating a strategic balance in the use of real versus synthetic data to optimize outcomes. Currently, the previously well-controlled integration of real and synthetic data is becoming uncontrollable. The widespread and unregulated dissemination of synthetic data online leads to the contamination of datasets traditionally compiled through web scraping, now mixed with unlabelled synthetic data. This trend, known as the AI autophagy phenomenon, suggests a future where generative AI systems may increasingly consume their own outputs without discernment, raising concerns about model performance, reliability and ethical implications. What will happen if generative AI continuously consumes itself without discernment? What measures can we take to mitigate the potential adverse effects? To address these research questions, this Perspective examines the existing literature, delving into the consequences of AI autophagy, analysing the associated risks and exploring strategies to mitigate its impact. Our aim is to provide a comprehensive perspective on this phenomenon advocating for a balanced approach that promotes the sustainable development of generative AI technologies in the era of large models. With widespread generation and availability of synthetic data, AI systems are increasingly trained on their own outputs, leading to various technical and ethical challenges. The authors analyse this development and discuss measures to mitigate the potential adverse effects of ‘AI eating itself’.},
  archive      = {J_NATMI},
  author       = {Xing, Xiaodan and Shi, Fadong and Huang, Jiahao and Wu, Yinzhe and Nan, Yang and Zhang, Sheng and Fang, Yingying and Roberts, Michael and Schönlieb, Carola-Bibiane and Del Ser, Javier and Yang, Guang},
  doi          = {10.1038/s42256-025-00984-1},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {172-180},
  shortjournal = {Nat. Mach. Intell.},
  title        = {On the caveats of AI autophagy},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging peptide presentation and t cell recognition with multi-task learning. <em>NATMI</em>, <em>7</em>(2), 170-171. (<a href='https://doi.org/10.1038/s42256-025-01004-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immunogenic binding interactions of antigens are complex and interconnected. A new transformer-based model can simultaneously predict the bindings of antigens to two main receptors.},
  archive      = {J_NATMI},
  author       = {Su, Li and Wang, Duolin and Xu, Dong},
  doi          = {10.1038/s42256-025-01004-y},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {170-171},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging peptide presentation and t cell recognition with multi-task learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On board with COMET to improve omics prediction models. <em>NATMI</em>, <em>7</em>(2), 168-169. (<a href='https://doi.org/10.1038/s42256-025-00990-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of omics prediction models can be significantly improved by combining limited patient proteomic data with widely available electronic health records.},
  archive      = {J_NATMI},
  author       = {Fogel, Paul and Luta, George},
  doi          = {10.1038/s42256-025-00990-3},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {168-169},
  shortjournal = {Nat. Mach. Intell.},
  title        = {On board with COMET to improve omics prediction models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical benchmarks for testing algorithms. <em>NATMI</em>, <em>7</em>(2), 166-167. (<a href='https://doi.org/10.1038/s42256-025-00999-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of comprehensive benchmarks to assess the performance of algorithms on causal tasks is an important, emerging area. The introduction of two physical ‘causal chamber’ systems serves as a firm step towards future, more reliable benchmarks in the field.},
  archive      = {J_NATMI},
  author       = {Zeitler, Jakob},
  doi          = {10.1038/s42256-025-00999-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {166-167},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Physical benchmarks for testing algorithms},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Why the carbon footprint of generative large language models alone will not help us assess their sustainability. <em>NATMI</em>, <em>7</em>(2), 164-165. (<a href='https://doi.org/10.1038/s42256-025-00979-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing awareness of the substantial environmental costs of large language models (LLMs), but discussing the sustainability of LLMs only in terms of CO2 emissions is not enough. This Comment emphasizes the need to take into account the social and ecological costs and benefits of LLMs as well.},
  archive      = {J_NATMI},
  author       = {Bossert, Leonie N. and Loh, Wulf},
  doi          = {10.1038/s42256-025-00979-y},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {164-165},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Why the carbon footprint of generative large language models alone will not help us assess their sustainability},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The promise of generative AI for suicide prevention in india. <em>NATMI</em>, <em>7</em>(2), 162-163. (<a href='https://doi.org/10.1038/s42256-025-00992-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Chakraborty, Tanmoy and Sinha Deb, Koushik and Kulkarni, Himanshu and Masud, Sarah and Math, Suresh Bada and Oke, Gayatri and Sagar, Rajesh and Sharma, Mona},
  doi          = {10.1038/s42256-025-00992-1},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {162-163},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The promise of generative AI for suicide prevention in india},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seeking visions for sustainable AI. <em>NATMI</em>, <em>7</em>(2), 161. (<a href='https://doi.org/10.1038/s42256-025-01008-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As countries around the world heavily invest in artificial intelligence (AI) and related infrastructure, the sustainable development of AI technology needs to be higher on the global agenda.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01008-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {161},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Seeking visions for sustainable AI},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating machine moral judgement through the delphi experiment. <em>NATMI</em>, <em>7</em>(1), 145-160. (<a href='https://doi.org/10.1038/s42256-024-00969-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As our society adopts increasingly powerful artificial intelligence (AI) systems for pervasive use, there are growing concerns about machine morality—or lack thereof. Millions of users already rely on the outputs of AI systems, such as chatbots, as decision aids. Meanwhile, AI researchers continue to grapple with the challenge of aligning these systems with human morality and values. In response to this challenge, we build and test Delphi, an open-source AI system trained to predict the moral judgements of US participants. The computational framework of Delphi is grounded in the framework proposed by the prominent moral philosopher John Rawls. Our results speak to the promises and limits of teaching machines about human morality. Delphi demonstrates improved generalization capabilities over those exhibited by off-the-shelf neural language models. At the same time, Delphi’s failures also underscore important challenges in this arena. For instance, Delphi has limited cultural awareness and is susceptible to pervasive biases. Despite these shortcomings, we demonstrate several compelling use cases of Delphi, including its incorporation as a component within an ensemble of AI systems. Finally, we computationally demonstrate the potential of Rawls’s prospect of hybrid approaches for reliable moral reasoning, inspiring future research in computational morality. Aligning artificial intelligence systems with human morality poses scientific, societal and ethical challenges. Delphi, an artificial intelligence system designed to predict human moral judgements based on John Rawls’s philosophical framework, is developed and tested, highlighting its potential for ethical applications and emphasizing the need to address its limitations and biases.},
  archive      = {J_NATMI},
  author       = {Jiang, Liwei and Hwang, Jena D. and Bhagavatula, Chandra and Bras, Ronan Le and Liang, Jenny T. and Levine, Sydney and Dodge, Jesse and Sakaguchi, Keisuke and Forbes, Maxwell and Hessel, Jack and Borchardt, Jon and Sorensen, Taylor and Gabriel, Saadia and Tsvetkov, Yulia and Etzioni, Oren and Sap, Maarten and Rini, Regina and Choi, Yejin},
  doi          = {10.1038/s42256-024-00969-6},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {145-160},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Investigating machine moral judgement through the delphi experiment},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified evolution-driven deep learning framework for virus variation driver prediction. <em>NATMI</em>, <em>7</em>(1), 131-144. (<a href='https://doi.org/10.1038/s42256-024-00966-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing frequency of emerging viral infections necessitates a rapid human response, highlighting the cost-effectiveness of computational methods. However, existing computational approaches are limited by their input forms or incomplete functionalities, preventing a unified prediction of diverse virus variation drivers and hindering in-depth applications. To address this issue, we propose a unified evolution-driven framework for predicting virus variation drivers, named Evolution-driven Virus Variation Driver prediction (E2VD), which is guided by virus evolutionary traits. With evolution-inspired design, E2VD comprehensively and significantly outperforms state-of-the-art methods across various virus mutational driver prediction tasks. Moreover, E2VD effectively captures the fundamental patterns of virus evolution. It not only distinguishes different types of mutations but also accurately identifies rare beneficial mutations that are critical for viruses to survive, while maintaining generalization capabilities across different lineages of SARS-CoV-2 and different types of viruses. Importantly, with predicted biological drivers, E2VD perceives virus evolutionary trends in which potential high-risk mutation sites are accurately recommended. Overall, E2VD represents a unified, structure-free and interpretable approach for analysing and predicting viral evolutionary fitness, providing an ideal alternative to costly wet-lab measurements to accelerate responses to emerging viral infections. A unified evolution-driven deep learning framework is presented, which outperforms state-of-the-art methods across various virus mutational driver predictions, and which captures fundamental patterns of virus evolution.},
  archive      = {J_NATMI},
  author       = {Nie, Zhiwei and Liu, Xudong and Chen, Jie and Wang, Zhennan and Liu, Yutian and Si, Haorui and Dong, Tianyi and Xu, Fan and Song, Guoli and Wang, Yu and Zhou, Peng and Gao, Wen and Tian, Yonghong},
  doi          = {10.1038/s42256-024-00966-9},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {131-144},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A unified evolution-driven deep learning framework for virus variation driver prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring scalable medical image encoders beyond text supervision. <em>NATMI</em>, <em>7</em>(1), 119-130. (<a href='https://doi.org/10.1038/s42256-024-00965-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language-supervised pretraining has proven to be a valuable method for extracting semantically meaningful features from images, serving as a foundational element in multimodal systems within the computer vision and medical imaging domains. However, the computed features are limited by the information contained in the text, which is particularly problematic in medical imaging, in which the findings described by radiologists focus on specific observations. This challenge is compounded by the scarcity of paired imaging–text data due to concerns over the leakage of personal health information. In this work, we fundamentally challenge the prevailing reliance on language supervision for learning general-purpose biomedical imaging encoders. We introduce RAD-DINO, a biomedical image encoder pretrained solely on unimodal biomedical imaging data that obtains similar or greater performance than state-of-the-art biomedical-language-supervised models on a diverse range of benchmarks. Specifically, the quality of learned representations is evaluated on standard imaging tasks (classification and semantic segmentation), and a vision–language alignment task (text report generation from images). To further demonstrate the drawback of language supervision, we show that features from RAD-DINO correlate with other medical records (for example, sex or age) better than language-supervised models, which are generally not mentioned in radiology reports. Finally, we conduct a series of ablations determining the factors in RAD-DINO’s performance. In particular, we observe that RAD-DINO’s downstream performance scales well with the quantity and diversity of training data, demonstrating that image-only supervision is a scalable approach for training a foundational biomedical image encoder. Reliance on text supervision for biomedical image encoders is investigated. The proposed RAD-DINO, pretrained solely on unimodal data, achieves similar or greater performance than state-of-the-art multimodal models on various benchmarks.},
  archive      = {J_NATMI},
  author       = {Pérez-García, Fernando and Sharma, Harshita and Bond-Taylor, Sam and Bouzid, Kenza and Salvatelli, Valentina and Ilse, Maximilian and Bannur, Shruthi and Castro, Daniel C. and Schwaighofer, Anton and Lungren, Matthew P. and Wetscherek, Maria Teodora and Codella, Noel and Hyland, Stephanie L. and Alvarez-Valle, Javier and Oktay, Ozan},
  doi          = {10.1038/s42256-024-00965-w},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {119-130},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Exploring scalable medical image encoders beyond text supervision},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal chambers as a real-world physical testbed for AI methodology. <em>NATMI</em>, <em>7</em>(1), 107-118. (<a href='https://doi.org/10.1038/s42256-024-00964-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some fields of artificial intelligence, machine learning and statistics, the validation of new methods and algorithms is often hindered by the scarcity of suitable real-world datasets. Researchers must often turn to simulated data, which yields limited information about the applicability of the proposed methods to real problems. As a step forward, we have constructed two devices that allow us to quickly and inexpensively produce large datasets from non-trivial but well-understood physical systems. The devices, which we call causal chambers, are computer-controlled laboratories that allow us to manipulate and measure an array of variables from these physical systems, providing a rich testbed for algorithms from a variety of fields. We illustrate potential applications through a series of case studies in fields such as causal discovery, out-of-distribution generalization, change point detection, independent component analysis and symbolic regression. For applications to causal inference, the chambers allow us to carefully perform interventions. We also provide and empirically validate a causal model of each chamber, which can be used as ground truth for different tasks. The hardware and software are made open source, and the datasets are publicly available at causalchamber.org or through the Python package causalchamber . Two devices are constructed to manipulate and collect data from non-trivial but well-understood physical systems. The devices serve as a flexible real-world testbed for artificial intelligence algorithms.},
  archive      = {J_NATMI},
  author       = {Gamella, Juan L. and Peters, Jonas and Bühlmann, Peter},
  doi          = {10.1038/s42256-024-00964-x},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {107-118},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Causal chambers as a real-world physical testbed for AI methodology},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual cognition in multimodal large language models. <em>NATMI</em>, <em>7</em>(1), 96-106. (<a href='https://doi.org/10.1038/s42256-024-00963-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models’ limitations in the domains of causal reasoning, intuitive physics and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships and intuitive understanding of others’ preferences. Our findings reveal that, while some of these models demonstrate a notable proficiency in processing and interpreting visual data, they still fall short of human capabilities in these areas. Our results emphasize the need for integrating more robust mechanisms for understanding causality, physical dynamics and social cognition into modern-day, vision-based language models, and point out the importance of cognitively inspired benchmarks. Modern vision-based language models face challenges with complex physical interactions, causal reasoning and intuitive psychology. Schulze Buschoff and colleagues demonstrate that while some models exhibit proficient visual data processing capabilities, they fall short of human performance in these cognitive domains.},
  archive      = {J_NATMI},
  author       = {Schulze Buschoff, Luca M. and Akata, Elif and Bethge, Matthias and Schulz, Eric},
  doi          = {10.1038/s42256-024-00963-y},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {96-106},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Visual cognition in multimodal large language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards highly sensitive deep learning-based end-to-end database search for tandem mass spectrometry. <em>NATMI</em>, <em>7</em>(1), 85-95. (<a href='https://doi.org/10.1038/s42256-024-00960-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peptide identification in mass spectrometry-based proteomics is crucial for understanding protein function and dynamics. Traditional database search methods, though widely used, rely on heuristic scoring functions, and statistical estimations must be introduced to achieve a higher identification rate. Here we introduce DeepSearch, a deep learning-based end-to-end database search method for tandem mass spectrometry. DeepSearch leverages a modified transformer-based encoder–decoder architecture under the contrastive learning framework. Unlike conventional methods, which rely on ion-to-ion matching, DeepSearch adopts a data-driven approach to score peptide–spectrum matches. DeepSearch can also profile variable post-translational modifications in a zero-shot manner. We show that DeepSearch’s scoring scheme expresses less bias and does not require any statistical estimation. We validate DeepSearch’s accuracy and robustness across various datasets, including those from species with diverse protein compositions and a modification-enriched dataset. DeepSearch sheds new light on database search methods in tandem mass spectrometry. Yu and Li present DeepSearch, a deep learning-based method for peptide identification in mass spectrometry, offering unbiased, data-driven scoring without statistical estimation. It accurately profiles post-translational modifications in a zero-shot manner.},
  archive      = {J_NATMI},
  author       = {Yu, Yonghan and Li, Ming},
  doi          = {10.1038/s42256-024-00960-1},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {85-95},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards highly sensitive deep learning-based end-to-end database search for tandem mass spectrometry},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reusability report: Deep learning-based analysis of images and spectroscopy data with AtomAI. <em>NATMI</em>, <em>7</em>(1), 79-84. (<a href='https://doi.org/10.1038/s42256-024-00958-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) techniques are gaining traction for materials image processing applications. In this context, Ziatdinov et al. developed AtomAI, a user-friendly and comprehensive Python library designed for a wide range of materials imaging tasks, including image segmentation, denoising, image generation, image-to-spectrum mapping (and vice versa) and subsequent atomistic modelling of image-resolved structures. Given its broad applicability, this report aims to reproduce key aspects of the authors’ original work, extend its capabilities to new materials datasets and enhance certain features to improve model performance. We have not only successfully replicated parts of the original study, but also developed improved ML models for multiple datasets across different image processing tasks. The AtomAI library was found to be easy to use and extensible for custom applications. We believe that AtomAI holds significant potential for the microscopy and spectroscopy communities, and further development—such as semi-automated image segmentation—could broaden its utility and impact. Vashishtha and colleagues test and reuse AtomAI, a machine learning framework developed for analysing microscopy data, for a range of materials characterization tasks.},
  archive      = {J_NATMI},
  author       = {Vashishtha, Pragalbh and Kattamuri, Hitesh Gupta and Thawari, Nikhil and Amirthalingam, Murugaiyan and Batra, Rohit},
  doi          = {10.1038/s42256-024-00958-9},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {79-84},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Deep learning-based analysis of images and spectroscopy data with AtomAI},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Delineating the effective use of self-supervised learning in single-cell genomics. <em>NATMI</em>, <em>7</em>(1), 68-78. (<a href='https://doi.org/10.1038/s42256-024-00934-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has emerged as a powerful method for extracting meaningful representations from vast, unlabelled datasets, transforming computer vision and natural language processing. In single-cell genomics (SCG), representation learning offers insights into the complex biological data, especially with emerging foundation models. However, identifying scenarios in SCG where SSL outperforms traditional learning methods remains a nuanced challenge. Furthermore, selecting the most effective pretext tasks within the SSL framework for SCG is a critical yet unresolved question. Here we address this gap by adapting and benchmarking SSL methods in SCG, including masked autoencoders with multiple masking strategies and contrastive learning methods. Models trained on over 20 million cells were examined across multiple downstream tasks, including cell-type prediction, gene-expression reconstruction, cross-modality prediction and data integration. Our empirical analyses underscore the nuanced role of SSL, namely, in transfer learning scenarios leveraging auxiliary data or analysing unseen datasets. Masked autoencoders excel over contrastive methods in SCG, diverging from computer vision trends. Moreover, our findings reveal the notable capabilities of SSL in zero-shot settings and its potential in cross-modality prediction and data integration. In summary, we study SSL methods in SCG on fully connected networks and benchmark their utility across key representation learning scenarios. Self-supervised learning techniques are powerful assets for enabling deep insights into complex, unlabelled single-cell genomic data. Richter et al. here benchmark the applicability of self-supervised architectures into key downstream representation learning scenarios.},
  archive      = {J_NATMI},
  author       = {Richter, Till and Bahrami, Mojtaba and Xia, Yufan and Fischer, David S. and Theis, Fabian J.},
  doi          = {10.1038/s42256-024-00934-3},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {68-78},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Delineating the effective use of self-supervised learning in single-cell genomics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The design space of e(3)-equivariant atom-centred interatomic potentials. <em>NATMI</em>, <em>7</em>(1), 56-67. (<a href='https://doi.org/10.1038/s42256-024-00956-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular dynamics simulation is an important tool in computational materials science and chemistry, and in the past decade it has been revolutionized by machine learning. This rapid progress in machine learning interatomic potentials has produced a number of new architectures in just the past few years. Particularly notable among these are the atomic cluster expansion, which unified many of the earlier ideas around atom-density-based descriptors, and Neural Equivariant Interatomic Potentials (NequIP), a message-passing neural network with equivariant features that exhibited state-of-the-art accuracy at the time. Here we construct a mathematical framework that unifies these models: atomic cluster expansion is extended and recast as one layer of a multi-layer architecture, while the linearized version of NequIP is understood as a particular sparsification of a much larger polynomial model. Our framework also provides a practical tool for systematically probing different choices in this unified design space. An ablation study of NequIP, via a set of experiments looking at in- and out-of-domain accuracy and smooth extrapolation very far from the training data, sheds some light on which design choices are critical to achieving high accuracy. A much-simplified version of NequIP, which we call BOTnet (for body-ordered tensor network), has an interpretable architecture and maintains its accuracy on benchmark datasets. Batatia and colleagues introduce a computational framework that combines message-passing networks with the atomic cluster expansion architecture and incorporates a many-body description of the geometry of molecular structures. The resulting models are interpretable and accurate.},
  archive      = {J_NATMI},
  author       = {Batatia, Ilyes and Batzner, Simon and Kovács, Dávid Péter and Musaelian, Albert and Simm, Gregor N. C. and Drautz, Ralf and Ortner, Christoph and Kozinsky, Boris and Csányi, Gábor},
  doi          = {10.1038/s42256-024-00956-x},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {56-67},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The design space of e(3)-equivariant atom-centred interatomic potentials},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential memory improves sample and memory efficiency in episodic control. <em>NATMI</em>, <em>7</em>(1), 43-55. (<a href='https://doi.org/10.1038/s42256-024-00950-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning algorithms are known for their sample inefficiency, requiring extensive episodes to reach optimal performance. Episodic reinforcement learning algorithms aim to overcome this issue by using extended memory systems to leverage past experiences. However, these memory augmentations are often used as mere buffers, from which isolated events are resampled for offline learning (for example, replay). In this Article, we introduce Sequential Episodic Control (SEC), a hippocampal-inspired model that stores entire event sequences in their temporal order and employs a sequential bias in their retrieval to guide actions. We evaluate SEC across various benchmarks from the Animal-AI testbed, demonstrating its superior performance and sample efficiency compared to several state-of-the-art models, including Model-Free Episodic Control, Deep Q-Network and Episodic Reinforcement Learning with Associative Memory. Our experiments show that SEC achieves higher rewards and faster policy convergence in tasks requiring memory and decision-making. Additionally, we investigate the effects of memory constraints and forgetting mechanisms, revealing that prioritized forgetting enhances both performance and policy stability. Further, ablation studies demonstrate the critical role of the sequential memory component in SEC. Finally, we discuss how fast, sequential hippocampal-like episodic memory systems could support both habit formation and deliberation in artificial and biological systems. Previous studies have explored the integration of episodic memory into reinforcement learning and control. Inspired by hippocampal memory, Freire et al. develop a model that improves learning speed and stability by storing experiences as sequences, demonstrating resilience and efficiency under memory constraints.},
  archive      = {J_NATMI},
  author       = {Freire, Ismael T. and Amil, Adrián F. and Verschure, Paul F. M. J.},
  doi          = {10.1038/s42256-024-00950-3},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {43-55},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Sequential memory improves sample and memory efficiency in episodic control},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moving towards genome-wide data integration for patient stratification with integrate any omics. <em>NATMI</em>, <em>7</em>(1), 29-42. (<a href='https://doi.org/10.1038/s42256-024-00942-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-throughput omics profiling advancements have greatly enhanced cancer patient stratification. However, incomplete data in multi-omics integration present a substantial challenge, as traditional methods like sample exclusion or imputation often compromise biological diversity and dependencies. Furthermore, the critical task of accurately classifying new patients with partial omics data into existing subtypes is commonly overlooked. To address these issues, we introduce Integrate Any Omics (IntegrAO), an unsupervised framework for integrating incomplete multi-omics data and classifying new samples. IntegrAO first combines partially overlapping patient graphs from diverse omics sources and utilizes graph neural networks to produce unified patient embeddings. Our systematic evaluation across five cancer cohorts involving six omics modalities demonstrates IntegrAO’s robustness to missing data and its accuracy in classifying new samples with partial profiles. An acute myeloid leukaemia case study further validates its capability to uncover biological and clinical heterogeneities in incomplete datasets. IntegrAO’s ability to handle heterogeneous and incomplete data makes it an essential tool for precision oncology, offering a holistic approach to patient characterization. Integrating incomplete multi-omics data remains a key challenge in precision oncology. IntegrAO, an unsupervised framework that integrates diverse omics, enables accurate patient classification even with incomplete datasets.},
  archive      = {J_NATMI},
  author       = {Ma, Shihao and Zeng, Andy G. X. and Haibe-Kains, Benjamin and Goldenberg, Anna and Dick, John E. and Wang, Bo},
  doi          = {10.1038/s42256-024-00942-3},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {29-42},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Moving towards genome-wide data integration for patient stratification with integrate any omics},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARNLE model identifies prevalence potential of SARS-CoV-2 variants. <em>NATMI</em>, <em>7</em>(1), 18-28. (<a href='https://doi.org/10.1038/s42256-024-00919-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SARS-CoV-2 mutations accumulated during the COVID-19 pandemic, posing significant challenges for immune prevention. An optimistic perspective suggests that SARS-CoV-2 will become more tropic to humans with weaker virulence and stronger infectivity. However, tracing a quantified trajectory of this process remains difficult. Here we introduce an attentional recurrent network based on language embedding (ARNLE) framework to analyse the shift in SARS-CoV-2 host tropism towards humans. ARNLE incorporates a language model for self-supervised learning to capture the features of amino acid sequences, alongside a supervised bidirectional long-short-term-memory-based network to discern the relationship between mutations and host tropism among coronaviruses. We identified a shift in SARS-CoV-2 tropism from weak to strong, transitioning from an approximate Chiroptera coronavirus to a primate-tropic coronavirus. Delta variants were closer to other common primate coronaviruses than previous SARS-CoV-2 variants. A similar phenomenon was observed among the Omicron variants. We employed a Bayesian-based post hoc explanation method to analyse key mutations influencing the human tropism of SARS-CoV-2. ARNLE identified pivotal mutations in the spike proteins, including T478K, L452R, G142D and so on, as the top determinants of human tropism. Our findings suggest that language models like ARNLE will significantly facilitate the identification of potentially prevalent variants and provide important support for screening key mutations, aiding in timely update of vaccines to protect against future emerging SARS-CoV-2 variants. Liu et al. developed a framework called ARNLE to explore host tropism of SARS-CoV-2 and found a shift from weak to strong primate tropism. Key mutations involved in this shift can be analysed to advance research on emerging viruses.},
  archive      = {J_NATMI},
  author       = {Liu, Yuqi and Li, Jing and Li, Peihan and Yang, Yehong and Wang, Kaiying and Li, Jinhui and Yang, Lang and Liu, Jiangfeng and Jia, Leili and Wu, Aiping and Yang, Juntao and Li, Peng and Song, Hongbin},
  doi          = {10.1038/s42256-024-00919-2},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {18-28},
  shortjournal = {Nat. Mach. Intell.},
  title        = {ARNLE model identifies prevalence potential of SARS-CoV-2 variants},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from models beyond fine-tuning. <em>NATMI</em>, <em>7</em>(1), 6-17. (<a href='https://doi.org/10.1038/s42256-024-00961-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models have demonstrated remarkable performance across various tasks, primarily due to their abilities to comprehend instructions and access extensive, high-quality data. These capabilities showcase the effectiveness of current foundation models and suggest a promising trajectory. Owing to multiple constraints, such as the extreme scarcity or inaccessibility of raw data used to train foundation models and the high cost of training large-scale foundation models from scratch, the use of pre-existing foundation models or application programming interfaces for downstream tasks has become a new research trend, which we call Learn from Model (LFM). LFM involves extracting and leveraging prior knowledge from foundation models through fine-tuning, editing and fusion methods and applying it to downstream tasks. We emphasize that maximizing the use of parametric knowledge in data-scarce scenarios is critical to LFM. Analysing the LFM paradigm can guide the selection of the most appropriate technology in a given scenario to minimize parameter storage and computational costs while improving the performance of foundation models on new tasks. This Review provides a comprehensive overview of current methods based on foundation models from the perspective of LFM. Large general-purpose models are becoming more prevalent and useful, but also harder to train and find suitable training data for. Zheng et al. discuss how models can be used to train other models.},
  archive      = {J_NATMI},
  author       = {Zheng, Hongling and Shen, Li and Tang, Anke and Luo, Yong and Hu, Han and Du, Bo and Wen, Yonggang and Tao, Dacheng},
  doi          = {10.1038/s42256-024-00961-0},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {6-17},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning from models beyond fine-tuning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modern maxims for an AI oracle. <em>NATMI</em>, <em>7</em>(1), 4-5. (<a href='https://doi.org/10.1038/s42256-024-00970-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As powerful institutions increasingly promote AI systems, efforts to align those systems with human morality have grown. An open-source AI system aims to predict human moral judgments across a broad spectrum of everyday situations expressed in natural language. Identifying the limitations of such systems offers important insights for future work.},
  archive      = {J_NATMI},
  author       = {Crockett, M. J.},
  doi          = {10.1038/s42256-024-00970-z},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {4-5},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Modern maxims for an AI oracle},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Envisioning better benchmarks for machine learning PDE solvers. <em>NATMI</em>, <em>7</em>(1), 2-3. (<a href='https://doi.org/10.1038/s42256-024-00962-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tackling partial differential equations with machine learning solvers is a promising direction, but recent analysis reveals challenges with making fair comparisons to previous methods. Stronger benchmark problems are needed for the field to advance.},
  archive      = {J_NATMI},
  author       = {Brandstetter, Johannes},
  doi          = {10.1038/s42256-024-00962-z},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {2-3},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Envisioning better benchmarks for machine learning PDE solvers},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning solutions looking for PDE problems. <em>NATMI</em>, <em>7</em>(1), 1. (<a href='https://doi.org/10.1038/s42256-025-00989-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are promising approaches to tackle partial differential equations, which are foundational descriptions of many scientific and engineering problems. However, in speaking with several experts about progress in the area, questions are emerging over what realistic advantages machine learning models have and how their performance should be evaluated.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-00989-w},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning solutions looking for PDE problems},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
