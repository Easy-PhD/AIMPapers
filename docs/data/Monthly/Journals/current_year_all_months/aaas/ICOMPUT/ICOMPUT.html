<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICOMPUT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icomput">ICOMPUT - 22</h2>
<ul>
<li><details>
<summary>
(2025). Graph-enhanced spatiotemporal trajectory similarity learning. <em>ICOMPUT</em>, <em>4</em>, 0169. (<a href='https://doi.org/10.34133/icomputing.0169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of location information platforms based on global positioning systems has led to a proliferation of spatiotemporal trajectory data, which has, in turn, made the analysis of such data available to a broad range of applications, including traffic prediction, route planning, and trajectory similarity computation. Traditional methods for calculating trajectory similarity often suffer from high computational costs due to quadratic time complexity, particularly when dealing with large datasets. To this end, deep learning-based approaches to trajectory similarity learning have been proposed, with a view to offering enhanced efficiency and adaptability in comparison with traditional methods. However, these methods primarily focus on spatial trajectory similarity and fail to capture important temporal periodicity. Moreover, most of them directly use recurrent neural networks to obtain trajectory representations, while ignoring the spatial proximity information between neighboring regions. To address these limitations, we propose a graph-enhanced spatiotemporal trajectory network, named GST, which integrates both spatial and temporal information to effectively learn trajectory similarity. Specifically, our model incorporates a graph neural network to capture the spatial proximity relationships and a time-embedding module to model the temporal periodicity information, thereby providing a more comprehensive spatiotemporal trajectory representation learning paradigm. Extensive experiments on 2 real-life datasets demonstrate that our model outperforms existing state-of-the-art methods in terms of accuracy. In addition, ablation studies demonstrate the effectiveness of the proposed spatiotemporal learning mechanism.},
  archive      = {J_ICOMPUT},
  author       = {Xijuan Liu and Zhangyi Xu and Haobo Wei and Peilun Yang},
  doi          = {10.34133/icomputing.0169},
  journal      = {Intelligent Computing},
  month        = {9},
  pages        = {0169},
  shortjournal = {Intell. Comput.},
  title        = {Graph-enhanced spatiotemporal trajectory similarity learning},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the component process model of emotions using interactive virtual reality games. <em>ICOMPUT</em>, <em>4</em>, 0161. (<a href='https://doi.org/10.34133/icomputing.0161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions are complex phenomena that shape our perception, behavior, and interactions. While discrete and dimensional models have been extensively studied, neuroscientific evidence better aligns with the component process model (CPM), which comprises 5 interconnected components. Despite its relevance, the CPM has received limited attention. To explore emotion processes more thoroughly, we adopted a data-driven approach using virtual reality (VR) games and collected multimodal data from 39 participants. Machine learning was employed to examine the unique contributions of each component to emotion differentiation. Our results highlight the important role of these components, with models incorporating all of them showing the strongest effects. We conclude that at least 5 dimensions are essential to represent emotions and underscore VR’s potential for emotion research.},
  archive      = {J_ICOMPUT},
  author       = {Rukshani Somarathna and Gelareh Mohammadi},
  doi          = {10.34133/icomputing.0161},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0161},
  shortjournal = {Intell. Comput.},
  title        = {Exploring the component process model of emotions using interactive virtual reality games},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the impact of color and Daytime/Nighttime on visual memory in virtual reality teaching environments using explainable machine learning. <em>ICOMPUT</em>, <em>4</em>, 0155. (<a href='https://doi.org/10.34133/icomputing.0155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality (VR) has proven to be effective in creating immersive learning experiences for both teachers and students. Notwithstanding the evident utility of VR teaching environments, there is a notable paucity of research investigating the impact of environmental factors on learning tasks. This study compares the effects of visual memory among learners in a VR classroom environment with different environments. A visual memory experiment was conducted with 46 participants, in which the influence of color and daytime/nighttime on memory was investigated. The results demonstrated that learners exhibited significantly enhanced visual memory reaction time under daytime environments compared to nighttime, particularly with yellow color ( t = 2.784, P = 0.011) backgrounds. The average reaction time reaches 1.223 s, and the accuracy reaches 98.4%. This highlights the pivotal role of color in optimizing memory effects. In contrast, the impact of color on memory tasks is comparatively diminished in nighttime, with no significant difference in learners’ memory capabilities observed under different color temperatures. Furthermore, we employ machine learning techniques to predict the average response time based on facial features. Results show that the XGBoost model has the best performance (mean absolute error: 0.14, mean squared error: 0.06, R 2 : 0.05). An explainable machine learning model, the SHapley Additive exPlanations (SHAP) algorithm, was employed to identify the importance and influence direction of each feature. The results demonstrated that lip movement and eye fixation direction exhibited the most indicative effect on reaction time. In light of these findings, recommendations are provided for enhancing the VR teaching environment and corresponding indicators for detecting learner focus.},
  archive      = {J_ICOMPUT},
  author       = {Feng Liu and Jingyi Hu and Qijian Zheng},
  doi          = {10.34133/icomputing.0155},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0155},
  shortjournal = {Intell. Comput.},
  title        = {Exploring the impact of color and Daytime/Nighttime on visual memory in virtual reality teaching environments using explainable machine learning},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-demand inverse design of metamaterials using deep neural networks with bayesian optimization. <em>ICOMPUT</em>, <em>4</em>, 0139. (<a href='https://doi.org/10.34133/icomputing.0139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in metamaterial design highlight methodologies tailoring metamaterials to achieve target behaviors in specific applications. This investigation presents a data-driven design approach using deep neural networks for the on-demand inverse design of metamaterials to address limitations inherent in traditional methods. We propose an efficient Bayesian optimization framework for deep neural network hyperparameter optimization. The desired properties being the target bandgap width and bandgap midfrequency, the design model proposes candidate unit cell topologies. The methodology demonstrates exceptional accuracy in both the forward prediction and inverse design of 2-dimensional metamaterial structures, with particular emphasis on bandgap characteristics. Statistical analysis reveals R 2 coefficients exceeding 0.99, validating the model’s predictive capabilities. The demonstrated framework represents a substantial advancement in computational metamaterial design, offering potential applications across multiple materials science and engineering domains.},
  archive      = {J_ICOMPUT},
  author       = {Than V. Tran and S. S. Nanthakumar and Timon Rabczuk and Xiaoying Zhuang},
  doi          = {10.34133/icomputing.0139},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0139},
  shortjournal = {Intell. Comput.},
  title        = {On-demand inverse design of metamaterials using deep neural networks with bayesian optimization},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian active learning for accelerated design of broadband polarization-insensitive metasurfaces. <em>ICOMPUT</em>, <em>4</em>, 0135. (<a href='https://doi.org/10.34133/icomputing.0135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electromagnetic metamaterials are suitable for a wide variety of civil and military applications because they are thin and lightweight and have strong absorption, tunable frequencies, and adjustable electromagnetic parameters. However, due to the large number of degrees of freedom in design and complex objectives, it is difficult to develop metamaterials quickly and efficiently by empirical trial and error. Here, we propose an active learning strategy combining Bayesian optimization and electromagnetic simulation to accelerate the design of lightweight broadband metasurfaces. With only 36 initial data points, the proposed method takes only 5 iterations to determine the optimal structure from over 11 million candidates. Broadband absorption is achieved with an absorption rate greater than 90% from 6.37 to 18 GHz at normal incidence (while the relative bandwidth reaches 95%), a rate 16% higher than that of the best built-in optimization. Both electromagnetic simulation and experimental validation confirm broadband absorption, polarization insensitivity, and wide-incident-angle absorption. Importantly, by using a resistive indium tin oxide film and a dielectric polymethacrylimide foam sheet, the entire structure is ultralight, with a weight of only 60 g per square meter. This study opens up a new avenue for the rational design of high-performance microwave metasurfaces and can be easily extended to promote the discovery of terahertz, infrared, and visible-light metamaterials.},
  archive      = {J_ICOMPUT},
  author       = {Jiwei Liu and Gangjie Lian and Wenbin You and Ruixuan Zhang and Yifeng Cheng and Chang Zhang and Renchao Che},
  doi          = {10.34133/icomputing.0135},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0135},
  shortjournal = {Intell. Comput.},
  title        = {Bayesian active learning for accelerated design of broadband polarization-insensitive metasurfaces},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verifiable blockchain-empowered federated learning for secure data sharing in the internet of medical things. <em>ICOMPUT</em>, <em>4</em>, 0132. (<a href='https://doi.org/10.34133/icomputing.0132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing amount of data produced by medical devices in the Internet of Medical Things creates new opportunities to improve the quality of medical services through data sharing in medical institutions. However, data sharing risks both external attacks and unauthorized internal personnel access to private data. Unauthorized access can lead to severe consequences beyond financial loss for the providers. This paper proposes a verifiable blockchain-empowered federated learning framework to address privacy and aggregation verification challenges in data sharing. An efficient verification mechanism is developed using a validation committee to filter out inadequate training results and maliciously uploaded gradients, thereby preventing Byzantine attacks and improving the security and efficiency of global model aggregation. Additionally, a contribution-based weighted aggregation scheme is proposed, which assigns coefficients based on participant contributions, providing a more thoughtful approach than the traditional federated averaging algorithm. To tackle node selection for global model aggregation and federated learning updates, a proof of contribution consensus mechanism is introduced. Theoretical assessments and performance metrics indicate that the proposed method is both efficient and secure, considerably enhancing the accuracy of the global model.},
  archive      = {J_ICOMPUT},
  author       = {Ping Guo and Shuilong Xu and Wenfeng Liang},
  doi          = {10.34133/icomputing.0132},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0132},
  shortjournal = {Intell. Comput.},
  title        = {Verifiable blockchain-empowered federated learning for secure data sharing in the internet of medical things},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating streaming subgraph matching via vector databases. <em>ICOMPUT</em>, <em>4</em>, 0131. (<a href='https://doi.org/10.34133/icomputing.0131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widely used in applications such as social network analysis, bioinformatics, and recommendation systems to represent relationships and complex dependencies. Subgraph matching, which involves finding instances of a query subgraph within a larger graph, is crucial for tasks such as fraud detection, pattern recognition, and semantic search. The streaming subgraph matching problem, an extension of this task, aims to efficiently process queries in a stream with minimal latency. This is particularly important in real-time applications such as dynamic monitoring and network anomaly detection, where quick query responses are essential. To address streaming subgraph matching, existing methods incorporate precomputed indices, such as tree structures. However, these approaches often fail to scale efficiently under high query arrival rates or for large graphs due to limitations in caching, query reuse, and indexing performance. In this paper, we adopt a framework that leverages a subgraph index based on graph embeddings, enabling effective caching and reuse of query results. Building on this foundation, we perform k -nearest neighbor search on high-dimensional vectors by using a vector database for indexing. Inverted file and product quantization techniques within the vector database were employed to accelerate the process. Experimental evaluations on 16 diverse real-world datasets show that our approach reduces processing time by an average of 87.7% compared to the state-of-the-art method, achieves cache hit rates ranging from 70% to 90%, and demonstrates robustness and consistency across varying batch sizes and datasets.},
  archive      = {J_ICOMPUT},
  author       = {Liuyi Chen and Yi Ding and Xushuo Tang and Fangyue Chen and Siyuan Gong and Xu Zhou and Zhengyi Yang},
  doi          = {10.34133/icomputing.0131},
  journal      = {Intelligent Computing},
  month        = {8},
  pages        = {0131},
  shortjournal = {Intell. Comput.},
  title        = {Accelerating streaming subgraph matching via vector databases},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving strategies in the internet of medical things using reinforcement learning and blockchain. <em>ICOMPUT</em>, <em>4</em>, 0133. (<a href='https://doi.org/10.34133/icomputing.0133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of the Internet of Things has markedly influenced the development of the Internet of Medical Things, enabling healthcare services to manage substantial amounts of sensitive private data. However, the increased generation of data raises critical concerns regarding the security and privacy of information transmitted within these systems. Current traditional security solutions are not designed to dynamically adapt to the evolving nature of cyber threats and, therefore, do not adequately meet the modern requirements of healthcare. In this paper, we propose a security framework based on blockchain technology and distributed reinforcement learning to effectively address these vulnerabilities. A decentralized cognitive blockchain network is utilized to ensure that data are stored securely and transmitted reliably while minimizing resource utilization. Furthermore, distributed reinforcement learning is integrated to enable security measures to adapt to changing threat patterns and enhance system resilience against attacks. Performance evaluations using the Address Resolution Protocol man-in-the-middle and Mirai botnet datasets demonstrated the framework’s ability to enhance Internet of Medical Things security compared to the ability of existing methods, resulting in memory consumption and transaction latency, while maintaining high data throughput. By bolstering the security of medical cyber-physical systems against various threats, this approach offers a promising solution to enhance operational efficiency and optimize the security of medical data in an interconnected environment.},
  archive      = {J_ICOMPUT},
  author       = {Dounia Doha and Ping Guo and Wenfeng Liang},
  doi          = {10.34133/icomputing.0133},
  journal      = {Intelligent Computing},
  month        = {7},
  pages        = {0133},
  shortjournal = {Intell. Comput.},
  title        = {Privacy-preserving strategies in the internet of medical things using reinforcement learning and blockchain},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding video transformers: A review on key strategies for feature learning and performance optimization. <em>ICOMPUT</em>, <em>4</em>, 0143. (<a href='https://doi.org/10.34133/icomputing.0143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video transformer model, a deep learning tool relying on the self-attention mechanism, is capable of efficiently capturing and processing spatiotemporal information in videos through effective spatiotemporal modeling, thereby enabling deep analysis and precise understanding of video content. It has become a focal point of academic attention. This paper first reviews the classic model architectures and notable achievements of the transformer in the domains of natural language processing (NLP) and image processing. It then explores performance enhancement strategies and video feature learning methods for the video transformer, considering 4 key dimensions: input module optimization, internal structure innovation, overall framework design, and hybrid model construction. Finally, it summarizes the latest advancements of the video transformer in cutting-edge application areas such as video classification, action recognition, video object detection, and video object segmentation. A comprehensive outlook on the future research trends and potential challenges of the video transformer is also provided as a reference for subsequent studies.},
  archive      = {J_ICOMPUT},
  author       = {Nan Chen and Tie Xu and Mingrui Sun and Chenggui Yao and Dongping Yang},
  doi          = {10.34133/icomputing.0143},
  journal      = {Intelligent Computing},
  month        = {6},
  pages        = {0143},
  shortjournal = {Intell. Comput.},
  title        = {Understanding video transformers: A review on key strategies for feature learning and performance optimization},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action-curiosity-based deep reinforcement learning algorithm for path planning in a nondeterministic environment. <em>ICOMPUT</em>, <em>4</em>, 0140. (<a href='https://doi.org/10.34133/icomputing.0140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of path planning, the efficiency and effectiveness of deep reinforcement learning (DRL) methods are often constrained by the algorithms’ exploration capabilities, particularly in dynamic and nondeterministic environments. This paper introduces a novel DRL optimization approach predicated on an action curiosity mechanism, designed to enhance both performance and efficiency in uncertain settings. By incentivizing agents to explore their surroundings more effectively, the action curiosity module amplifies learning efficiency and curtails training duration. The method’s adaptability and stability in intricate or dynamic scenarios are augmented through a dynamically adjusted reward mechanism. To mitigate the issue of strategy degradation stemming from excessive exploration, we incorporate a cosine annealing strategy that finesses parameter adjustments in real time. Extensive experimentation reveals that our enhanced algorithm outperforms conventional methods markedly in terms of success rate and average reward, among other metrics. These experimental outcomes corroborate the proposed method’s robustness and efficacy, laying a solid groundwork for efficient adaptive autonomous path planning within complex and nondeterministic environments.},
  archive      = {J_ICOMPUT},
  author       = {Junxiao Xue and Jinpu Chen and Shiwen Zhang},
  doi          = {10.34133/icomputing.0140},
  journal      = {Intelligent Computing},
  month        = {6},
  pages        = {0140},
  shortjournal = {Intell. Comput.},
  title        = {Action-curiosity-based deep reinforcement learning algorithm for path planning in a nondeterministic environment},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regional explanations and diverse molecular representations in cheminformatics: A comparative study. <em>ICOMPUT</em>, <em>4</em>, 0126. (<a href='https://doi.org/10.34133/icomputing.0126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cheminformatics, the explainability of machine learning models is important for interpreting complex chemical data, deriving new chemical insights, and building trust in predictive models. However, cheminformatics datasets often exhibit clustered distributions, while traditional explanation methods might overlook intra-cluster variations and complicate the extraction of meaningful explanations. Additionally, diverse representations (tabular, sequence, image, and graph) yield divergent explanations. To address these issues, we propose a novel approach termed regional explanation, designed as an intermediate-level interpretability method that bridges the gap between local and global explanations. This approach systematically reveals how explanations and feature importance vary across data clusters. Using 2 public datasets, a graphene oxide nanoflakes dataset and QM9, with natural clustering properties, we comprehensively evaluate 4 molecular representations through tabular, sequence, image, and graph regional explanation, providing practical guidelines for representation selection. Our analysis illuminates complex, nonlinear relationships between molecular structures and predicted properties within clusters; explores the interplay among molecular features, feature importance, and target properties across distinct regions of chemical space; and advances the interpretability of machine learning models for complex molecular systems.},
  archive      = {J_ICOMPUT},
  author       = {Xin Wang and Amanda S. Barnard and Sichao Li},
  doi          = {10.34133/icomputing.0126},
  journal      = {Intelligent Computing},
  month        = {6},
  pages        = {0126},
  shortjournal = {Intell. Comput.},
  title        = {Regional explanations and diverse molecular representations in cheminformatics: A comparative study},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph-based learning framework for compiler loop auto-vectorization. <em>ICOMPUT</em>, <em>4</em>, 0113. (<a href='https://doi.org/10.34133/icomputing.0113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single instruction multiple data (SIMD) capability in modern processors is critical to improving the performance of current compute-intensive programs. Modern compilers use vectorization techniques to exploit the SIMD capability, by detecting data parallelism in scalar source code and transforming a group of scalar instructions into vector-based instructions. In this study, we focus on one of the most common vectorization techniques, a technique called loop-based vectorization, which targets loops and optimizes their performance by grouping multiple occurrences of the same operation across loop iterations into a single SIMD instruction. We propose a data-driven graph-based learning framework for automatic vectorization, called autograph , which takes an input program, extracts the loops, and then learns a structured representation to automatically predict the correct vectorization and interleaving factors. Our proposed framework utilizes deep reinforcement learning to learn an optimal policy (observations to actions) from an intelligent agent in a SIMD environment, and automatically injects the predicted vectorization pragmas into the input program. We conducted an extensive evaluation on multiple benchmark datasets and comparisons with state-of-the-art baselines. Our results show that autograph achieves on average 2.49× performance improvement for Polybench compared to NeuroVectorizer and 3.69× compared to the baseline -O3.},
  archive      = {J_ICOMPUT},
  author       = {Yao Xiao and Nesreen K. Ahmed and Mihai Capotă and Guixiang Ma and Theodore L. Willke and Shahin Nazarian and Paul Bogdan},
  doi          = {10.34133/icomputing.0113},
  journal      = {Intelligent Computing},
  month        = {6},
  pages        = {0113},
  shortjournal = {Intell. Comput.},
  title        = {A graph-based learning framework for compiler loop auto-vectorization},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of task planning with large language models. <em>ICOMPUT</em>, <em>4</em>, 0124. (<a href='https://doi.org/10.34133/icomputing.0124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive survey of the current status and opportunities for large language models (LLMs) in task planning, a sophisticated process of reasoning and decision-making that organizes a sequence of actions to accomplish predefined goals. Task planning centers on identifying suitable solutions for a task, with a specific emphasis on ensuring its successful completion. Although task planning plays a crucial role in enabling systems to function effectively in dynamic and complex environments, there is a lack of systematic reviews on this topic. We explore the theories, methodologies, and applications related to task planning with LLMs, highlighting the burgeoning development in this field and the interdisciplinary approaches that enhance their ability to complete tasks. This survey aims to systematize and clarify the fragmented literature, provide a systematic review that underscores the importance of task planning as a critical capability, and offer insights into future research directions and potential improvements. We hope to help researchers gain a clear understanding of the field and spark greater interest in this highly impactful research direction. A continuously updated resource is available in our GitHub repository at https://github.com/ZhaiWenShuo/Survey-of-Task-Planning .},
  archive      = {J_ICOMPUT},
  author       = {Wenshuo Zhai and Jinzhi Liao and Ziyang Chen and Bolun Su and Xiang Zhao},
  doi          = {10.34133/icomputing.0124},
  journal      = {Intelligent Computing},
  month        = {5},
  pages        = {0124},
  shortjournal = {Intell. Comput.},
  title        = {A survey of task planning with large language models},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressing neural networks using tensor networks with exponentially fewer variational parameters. <em>ICOMPUT</em>, <em>4</em>, 0123. (<a href='https://doi.org/10.34133/icomputing.0123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural network (NN) designed for challenging machine learning tasks is in general a highly nonlinear mapping that contains numerous variational parameters. The complexity of NNs, if unbounded or unconstrained, might unpredictably cause severe issues including overfitting, loss of generalization power, and excessive cost of hardware. In this study, we propose a general compression scheme that considerably reduces the variational parameters of NNs, regardless of their specific types (linear, convolutional, etc.), by encoding them into deep automatically differentiable tensor networks (ADTNs) that contain exponentially fewer free parameters. The superior compression performance of our scheme is demonstrated on several widely recognized NNs (FC-2, LeNet-5, AlexNet, ZFNet, and VGG-16) and datasets (MNIST, CIFAR-10, and CIFAR-100). For instance, we compress 2 linear layers in VGG-16 with approximately 10 7 parameters to 2 ADTNs with only 424 parameters, improving the testing accuracy on CIFAR-10 from 90.17% to 91.74%. We argue that the deep structure of the ADTN is an essential reason for its remarkable compression performance compared to existing compression schemes, which are mainly based on tensor decompositions/factorization and shallow TNs. Our study suggests that the deep TN is an exceptionally efficient mathematical structure for representing the variational parameters of NNs, one that exhibits better compressibility than the commonly used matrices and multiway arrays.},
  archive      = {J_ICOMPUT},
  author       = {Yong Qing and Ke Li and Peng-Fei Zhou and Shi-Ju Ran},
  doi          = {10.34133/icomputing.0123},
  journal      = {Intelligent Computing},
  month        = {5},
  pages        = {0123},
  shortjournal = {Intell. Comput.},
  title        = {Compressing neural networks using tensor networks with exponentially fewer variational parameters},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage end-to-end deep learning approach for predicting astrochemical reactions. <em>ICOMPUT</em>, <em>4</em>, 0118. (<a href='https://doi.org/10.34133/icomputing.0118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the astronomical evolution of celestial regions necessitates reconstructing evolutionary pathways within dynamic physical environments, which heavily relies on precise and comprehensive astrochemical reaction networks. Traditional methods rely on expert knowledge and incur substantial time and cost. In this study, we introduce a novel 2-stage end-to-end deep learning approach for predicting astrochemical reaction products, marking the first application of these techniques in this field. Our method comprises 2 primary phases: a generative phase leveraging a graph encoder and transformer architecture for the generation of potential reaction products, and a contrastive learning-based phase for re-ranking the potential products. We rigorously evaluated the performance of our approach using the ChemiVerse dataset. Experimental results show notable accuracy rates of 82.4% (Top-1), 91.4% (Top-3), 93.0% (Top-5), and 93.7% (Top-10). This study demonstrates the feasibility and effectiveness of using advanced deep learning techniques for end-to-end astrochemical reaction prediction.},
  archive      = {J_ICOMPUT},
  author       = {Jiawei Wang and Yanan Zhang and Haili Bu and Yang Lu and Manni Duan and Donghui Quan and Peng Qiu},
  doi          = {10.34133/icomputing.0118},
  journal      = {Intelligent Computing},
  month        = {5},
  pages        = {0118},
  shortjournal = {Intell. Comput.},
  title        = {A two-stage end-to-end deep learning approach for predicting astrochemical reactions},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative artificial intelligence for advancing discovery and design in biomateriomics. <em>ICOMPUT</em>, <em>4</em>, 0117. (<a href='https://doi.org/10.34133/icomputing.0117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review explores the transformative impact of generative artificial intelligence (AI) on the field of biomateriomics, an emerging interdisciplinary area that integrates materials science, biology, and engineering to study and design materials inspired by biological systems. We examine how generative AI techniques are revolutionizing the discovery, design, property prediction, and optimization of biomaterials across multiple scales and applications, particularly in tissue engineering, regenerative medicine, and drug discovery. Furthermore, we discuss the synergies between generative AI and other cutting-edge technologies, such as high-throughput 3-dimensional bioprinting, highlighting how these integrations are accelerating progress in the field. We also address the challenges and limitations of applying generative AI to biomateriomics, including issues related to data quality and availability, model interpretability, validation of AI-generated designs, and ethical considerations. Looking forward, future advancements, including multimodal AI systems and quantum–AI hybrids, promise to further expand the potential of biomateriomics, fostering innovation in sustainable materials, personalized medicine, and environmental applications. We hope that this comprehensive review, by providing insights into the current state of the field and future directions for innovation, will serve as a valuable resource for researchers, engineers, and policymakers working at the intersection of AI and biomateriomics.},
  archive      = {J_ICOMPUT},
  author       = {Raffaele Pugliese and Silvia Badini and Emanuele Frontoni and Stefano Regondi},
  doi          = {10.34133/icomputing.0117},
  journal      = {Intelligent Computing},
  month        = {5},
  pages        = {0117},
  shortjournal = {Intell. Comput.},
  title        = {Generative artificial intelligence for advancing discovery and design in biomateriomics},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-electron spin qubits in silicon for quantum computing. <em>ICOMPUT</em>, <em>4</em>, 0115. (<a href='https://doi.org/10.34133/icomputing.0115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent decade has witnessed substantial advancements in silicon quantum computing. Important milestones include demonstrations of quantum gates exceeding the fault-tolerance threshold, high-fidelity single-shot spin readout, hot quantum bits (hot qubits), and compact scalable spin arrays. Silicon qubits hold promise to leverage semiconductor industry technologies into scalable qubit manufacturing. Both the academic and industry communities are striving to push this advantage into reality. However, formidable challenges persist in the quest to develop a fully operational universal quantum computer. This review focuses on single-spin qubits in silicon. First, we start with foundational spin qubit theory. Then, we discuss gate-defined quantum dots and donor dot systems, with a particular emphasis on two-qubit gate operations and the scalability of qubit arrays. Lastly, we address long-distance coupling, highlighting key areas for future research and potential scale-up strategies for this rapidly evolving field.},
  archive      = {J_ICOMPUT},
  author       = {Guangchong Hu and Wei Wister Huang and Ranran Cai and Lin Wang and Chih Hwan Yang and Gang Cao and Xiao Xue and Peihao Huang and Yu He},
  doi          = {10.34133/icomputing.0115},
  journal      = {Intelligent Computing},
  month        = {5},
  pages        = {0115},
  shortjournal = {Intell. Comput.},
  title        = {Single-electron spin qubits in silicon for quantum computing},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Erratum to “Metric-independent mitigation of unpredefined bias in machine classification”. <em>ICOMPUT</em>, <em>4</em>, 0125. (<a href='https://doi.org/10.34133/icomputing.0125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Research Article “Metric-Independent Mitigation of Unpredefined Bias in Machine Classification,” the funding information was inadvertently omitted from the Acknowledgments section [1]. The funding statement has now been added to the original publication and is also provided below:},
  archive      = {J_ICOMPUT},
  author       = {Zhoufei Tang and Tao Lu and Tianyi Li},
  doi          = {10.34133/icomputing.0125},
  journal      = {Intelligent Computing},
  month        = {4},
  pages        = {0125},
  shortjournal = {Intell. Comput.},
  title        = {Erratum to “Metric-independent mitigation of unpredefined bias in machine classification”},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From the test tube to the cell: A homecoming for DNA computing circuits?. <em>ICOMPUT</em>, <em>4</em>, 0112. (<a href='https://doi.org/10.34133/icomputing.0112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review article poses the overarching question: Can complex dynamic DNA nanodevices based on strand displacement reactions be operated within, and can they interoperate with living cells? Reviewing recent literature from DNA nanotechnology and molecular computing, we explore the background, state of the art, and current challenges toward intracellular strand displacement reactions. We first introduce the underlying principles, seminal achievements, and current limitations of DNA strand displacement circuits. We discuss the potential for biological molecules to serve as inputs to DNA nanocircuits. This comprises cellular nucleic acids such as messenger RNA and microRNA, as well as other biological molecules that can trigger DNA nanodevices through the aid of aptamer binding. We investigate challenges and recent successes of operating DNA strand displacement devices in cellular lysates as well as delivering or integrating DNA nanodevices into cells. Finally, we discuss biocompatible models of computation, with particular emphasis on molecular neural networks, which can be seamlessly mapped onto DNA strand displacement networks and offer promise to mimic the self-organizing, adaptive, and fault-tolerant nature of living organisms. Taking the efforts of numerous research groups in DNA nanotechnology and molecular computing together, the review identifies remaining challenges and future directions toward the creation of programmable intracellular DNA nanomachines able to interrogate biological signals, perform complex computation over acquired information, and, in response, actuate on their biological environment—similar to the interactions of a robot with its environment.},
  archive      = {J_ICOMPUT},
  author       = {Hyeyun Jung and Ethan Collinson and Alexander Patrick Hawes and Harold Fellermann},
  doi          = {10.34133/icomputing.0112},
  journal      = {Intelligent Computing},
  month        = {3},
  pages        = {0112},
  shortjournal = {Intell. Comput.},
  title        = {From the test tube to the cell: A homecoming for DNA computing circuits?},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Super virus machines: Faster virus transmission, more efficiency using superchannels. <em>ICOMPUT</em>, <em>4</em>, 0103. (<a href='https://doi.org/10.34133/icomputing.0103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surpassing the classical computing architecture is one of the great challenges of computer science today. The branch that approaches it from a theoretical point of view, inspired by nature, is called natural computation. Within this field, a paradigm arises, called virus machines (VMs), inspired by the propagation and replication of the biological structure of viruses. This work introduces a novel extension to the young computing paradigm of VMs, the super VMs. This extension can develop models with a new kind of channel called superchannel. In addition, several VMs are constructed to generate natural number sets and compute basic arithmetic functions, improving the basic VMs in both time and memory cost (such as hosts and instructions).},
  archive      = {J_ICOMPUT},
  author       = {Antonio Ramírez-de-Arellano-Marrero and Luis Valencia-Cabrera and David Orellana-Martín and Mario J. Pérez-Jiménez},
  doi          = {10.34133/icomputing.0103},
  journal      = {Intelligent Computing},
  month        = {3},
  pages        = {0103},
  shortjournal = {Intell. Comput.},
  title        = {Super virus machines: Faster virus transmission, more efficiency using superchannels},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning and methods based on large language models applied to stellar light curve classification. <em>ICOMPUT</em>, <em>4</em>, 0110. (<a href='https://doi.org/10.34133/icomputing.0110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light curves serve as a valuable source of information on stellar formation and evolution. With the rapid advancement of machine learning techniques, they can be effectively processed to extract astronomical patterns and information. In this study, we present a comprehensive evaluation of models based on deep learning and large language models (LLMs) for the automatic classification of variable star light curves, using large datasets from the Kepler and K2 missions. Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries, examining the influence of observational cadence and phase distribution on classification precision. Employing automated deep learning optimization, we achieve striking performance using 2 architectures: one that combines one-dimensional convolution (Conv1D) with bidirectional long short-term memory (BiLSTM) and another called the Swin Transformer. These achieved accuracies of 94% and 99%, respectively, with the latter demonstrating a notable 83% accuracy in discerning the elusive type II Cepheids that comprise merely 0.02% of the total dataset. We unveil StarWhisper LightCurve (LC), a series of 3 LLM models based on an LLM, a multimodal large language model (MLLM), and a large audio language model (LALM). Each model is fine-tuned with strategic prompt engineering and customized training methods to explore the emergent abilities of these models for astronomical data. Remarkably, StarWhisper LC series models exhibit high accuracies of around 90%, considerably reducing the need for explicit feature engineering, thereby paving the way for streamlined parallel data processing and the progression of multifaceted multimodal models in astronomical applications. The study furnishes 2 detailed catalogs illustrating the impacts of phase and sampling intervals on deep learning classification accuracy, showing that a substantial decrease of up to 14% in observation duration and 21% in sampling points can be realized without compromising accuracy by more than 10%.},
  archive      = {J_ICOMPUT},
  author       = {Yu-Yang Li and Yu Bai and Cunshi Wang and Mengwei Qu and Ziteng Lu and Roberto Soria and Jifeng Liu},
  doi          = {10.34133/icomputing.0110},
  journal      = {Intelligent Computing},
  month        = {2},
  pages        = {0110},
  shortjournal = {Intell. Comput.},
  title        = {Deep learning and methods based on large language models applied to stellar light curve classification},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of DNA cryptography. <em>ICOMPUT</em>, <em>4</em>, 0106. (<a href='https://doi.org/10.34133/icomputing.0106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deoxyribonucleic acid (DNA), the oldest natural storage medium, offers a highly promising mode for information computing and storage with its high information density, low maintenance costs, and the ability to do parallel processing. DNA cryptography is an emerging discipline focused on achieving information security within this new paradigm. In this paper, we first present the foundational concepts of cryptography and biological technologies involved in DNA cryptography. We then comprehensively review 2 types of DNA cryptography: pseudo-DNA cryptography and natural DNA cryptography. After summarizing and discussing the security foundations of these cryptographic methods, we highlight the main challenges relating to measurability, standard protocols, robustness, and operability. Finally, we outline future directions for DNA cryptography, hoping to facilitate the evolution of this nascent field.},
  archive      = {J_ICOMPUT},
  author       = {Ling Chu and Yanqing Su and Xiangyu Yao and Peng Xu and Wenbin Liu},
  doi          = {10.34133/icomputing.0106},
  journal      = {Intelligent Computing},
  month        = {1},
  pages        = {0106},
  shortjournal = {Intell. Comput.},
  title        = {A review of DNA cryptography},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
