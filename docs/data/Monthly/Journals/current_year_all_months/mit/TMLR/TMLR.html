<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMLR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmlr">TMLR - 1040</h2>
<ul>
<li><details>
<summary>
(2025). MoReact: Generating reactive motion from textual descriptions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4zuT73heqm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and generating human reactions poses a significant challenge with broad applications for computer vision and human-computer interaction. Existing methods either treat multiple individuals as a single entity, directly generating interactions, or rely solely on one person's motion to generate the other's reaction, failing to integrate the rich semantic information that underpins human interactions. Yet, these methods often fall short in adaptive responsiveness, \ie, the ability to accurately respond to diverse and dynamic interaction scenarios. Recognizing this gap, our work introduces an approach tailored to address the limitations of existing models by focusing on text-driven human reaction generation. Our model specifically generates realistic motion sequences for individuals that responding to the other's actions based on a descriptive text of the interaction scenario. The goal is to produce motion sequences that not only complement the opponent's movements but also semantically fit the described interactions. To achieve this, we present MoReact, a diffusion-based method designed to disentangle the generation of global trajectories and local motions sequentially. This approach stems from the observation that generating global trajectories first is crucial for guiding local motion, ensuring better alignment with given action and text. Furthermore, we introduce a novel interaction loss to enhance the realism of generated close interactions. Our experiments, utilizing data adapted from a two-person motion dataset, demonstrate the efficacy of our approach for this novel task, which is capable of producing realistic, diverse, and controllable reactions that not only closely match the movements of the counterpart but also adhere to the textual guidance. Please find our webpage at https://xiyan-xu.github.io/MoReactWebPage.},
  archive      = {J_TMLR},
  author       = {Xiyan Xu and Sirui Xu and Yu-Xiong Wang and Liangyan Gui},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MoReact: Generating reactive motion from textual descriptions},
  url          = {https://openreview.net/forum?id=4zuT73heqm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning equivalence classes of bayesian network structures with GFlowNet. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FAcc7oAdaa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the causal graph underlying a system is essential for enabling causal inference, particularly in fields such as medicine and genetics. Identifying a causal Directed Acyclic Graph (DAG) from observational data alone is challenging because multiple DAGs can encode the same set of conditional independencies. These equivalent DAGs form a Markov Equivalence Class (MEC), which is represented by a Completed Partially Directed Acyclic Graph (CPDAG). Effectively approximating the CPDAG is crucial because it facilitates narrowing down the set of possible causal graphs underlying the data. We introduce CPDAG-GFN, a novel approach that uses a Generative Flow Network (GFlowNet) to learn a posterior distribution over CPDAGs. From this distribution, we sample high-reward CPDAG candidates that approximate the ground truth, with rewards determined by a score function that quantifies how well each graph fits the data. Additionally, CPDAG-GFN incorporates a sparsity-preferring filter to enhance the set of CPDAG candidates and improve their alignment with the ground truth. Experimental results on both simulated and real-world datasets demonstrate that CPDAG-GFN performs competitively with established methods for learning CPDAG candidates from observational data.},
  archive      = {J_TMLR},
  author       = {Michelle Liu and Zhaocheng Zhu and Olexa Bilaniuk and Emmanuel Bengio},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning equivalence classes of bayesian network structures with GFlowNet},
  url          = {https://openreview.net/forum?id=FAcc7oAdaa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SELU: Self-learning embodied multimodal large language models in unknown environments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=G5gROx8AVi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multimodal large language models (MLLMs) have demonstrated strong visual understanding and decision-making capabilities, enabling the exploration of autonomously improving MLLMs in unknown environments. However, external feedback like human or environmental feedback is not always available. To address this challenge, existing methods primarily focus on enhancing the decision-making capabilities of MLLMs through voting and scoring mechanisms, while little effort has been paid to improving the environmental comprehension of MLLMs in unknown environments. To fully unleash the self-learning potential of MLLMs, we propose a novel actor-critic self-learning paradigm, dubbed SELU, inspired by the actor-critic paradigm in reinforcement learning. The critic employs self-asking and hindsight relabeling to extract knowledge from interaction trajectories collected by the actor, thereby augmenting its environmental comprehension. Simultaneously, the actor is improved by the self-feedback provided by the critic, enhancing its decision-making. We evaluate our method in the AI2-THOR and VirtualHome environments, and SELU achieves critic improvements of approximately 28% and 30%, and actor improvements of about 20% and 24% via self-learning.},
  archive      = {J_TMLR},
  author       = {Boyu Li and Haobin Jiang and Ziluo Ding and Xinrun Xu and Haoran Li and Dongbin Zhao and Zongqing Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SELU: Self-learning embodied multimodal large language models in unknown environments},
  url          = {https://openreview.net/forum?id=G5gROx8AVi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behaviour discovery and attribution for explainable reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JbHtpOIH9l'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building trust in reinforcement learning (RL) agents requires understanding why they make certain decisions, especially in high-stakes applications like robotics, healthcare, and finance. Existing explainability methods often focus on single states or entire trajectories, either providing only local, step-wise insights or attributing decisions to coarse, episodelevel summaries. Both approaches miss the recurring strategies and temporally extended patterns that actually drive agent behavior across multiple decisions. We address this gap by proposing a fully offline, reward-free framework for behavior discovery and segmentation, enabling the attribution of actions to meaningful and interpretable behavior segments that capture recurring patterns appearing across multiple trajectories. Our method identifies coherent behavior clusters from state-action sequences and attributes individual actions to these clusters for fine-grained, behavior-centric explanations. Evaluations on four diverse offline RL environments show that our approach discovers meaningful behaviors and outperforms trajectory-level baselines in fidelity, human preference, and cluster coherence. Our code is publicly available.},
  archive      = {J_TMLR},
  author       = {Rishav Rishav and Somjit Nath and Vincent Michalski and Samira Ebrahimi Kahou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Behaviour discovery and attribution for explainable reinforcement learning},
  url          = {https://openreview.net/forum?id=JbHtpOIH9l},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowBench: Benchmarking optical flow estimation methods for reliability and generalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Kh4bj6YDNm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow estimation is a crucial computer vision task often applied to safety-critical real-world scenarios like autonomous driving and medical imaging. While optical flow estimation accuracy has greatly benefited from the emergence of deep learning, learning-based methods are also known for their lack of generalization and reliability. However, reliability is paramount when optical flow methods are employed in the real world, where safety is essential. Furthermore, a deeper understanding of the robustness and reliability of learning-based optical flow estimation methods is still lacking, hindering the research community from building methods safe for real-world deployment. Thus, we propose FlowBench, a robustness benchmark and evaluation tool for learning-based optical flow methods. FlowBench facilitates streamlined research into the reliability of optical flow methods by benchmarking their robustness to adversarial attacks and out-of-distribution samples. With FlowBench, we benchmark 57 checkpoints across 3 datasets under 9 diverse adversarial attacks and 23 established common corruptions, making it the most comprehensive robustness analysis of optical flow methods to date. Across this wide range of methods, we consistently find that methods with state-of-the-art performance on established standard benchmarks lack reliability and generalization ability. Moreover, we find interesting correlations between the performance, reliability, and generalization ability of optical flow estimation methods, under various lenses such as design choices used, number of parameters, etc. The open-source code and weights for FlowBench are available in this GitHub repository: https://github.com/shashankskagnihotri/FlowBench.},
  archive      = {J_TMLR},
  author       = {Shashank Agnihotri and Julian Yuya Caspary and Luca Schwarz and Xinyan Gao and Jenny Schmalfuss and Andres Bruhn and Margret Keuper},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlowBench: Benchmarking optical flow estimation methods for reliability and generalization},
  url          = {https://openreview.net/forum?id=Kh4bj6YDNm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication cost reduction for subgraph counting under local differential privacy via hash functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=N1J236mepp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suggest the use of hash functions to cut down the communication costs when counting subgraphs under edge local differential privacy. While various algorithms exist for computing graph statistics --- including the count of subgraphs --- under the edge local differential privacy, many suffer with high communication costs, making them less efficient for large graphs. Though data compression is a typical approach in differential privacy, its application in local differential privacy requires a form of compression that every node can reproduce. In our study, we introduce linear congruence hashing. Leveraging amplification by sub-sampling, with a sampling size of $s$, our method can cut communication costs by a factor of $s^2$, albeit at the cost of increasing variance in the published graph statistic by a factor of $s$. The experimental results indicate that, when matched for communication costs, our method achieves a reduction in the $\ell_2$-error by up to 1000 times for triangle counts and by up to $10^3$ times for 4-cycles counts compared to the performance of leading algorithms.},
  archive      = {J_TMLR},
  author       = {Quentin Hillebrand and Vorapong Suppakitpaisarn and Tetsuo Shibuya},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Communication cost reduction for subgraph counting under local differential privacy via hash functions},
  url          = {https://openreview.net/forum?id=N1J236mepp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging fully-observable solutions for improved partially-observable offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=e9p4TDPy6A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) is a popular learning framework for control problems where online interactions with the environment are expensive, risky, or otherwise impractical. Existing offline RL methods commonly assume full observability of the state, and therefore there is a lack of offline RL methods that are specialized for the more general case of partially-observable control. To address this gap, we propose Cross-Observability Conservative Q-Learning (CO-CQL), an offline RL algorithm for partially-observable control that leverages fully-observable expert policies in an asymmetric learning setting. To motivate the use of fully-observable experts for partially-observable control, we formalize Cross-Observability Optimality Ratio (COOR), a theoretical measure of cross-observability that quantifies the benefit of learning asymmetrically from a fully-observable expert, and Cross-Observability Approximation Ratio (COAR), an estimation of COOR computable from trained policies. Our empirical evaluation on a wide variety of partially-observable challenges demonstrates that CO-CQL is able to exploit the guidance of fully-observable experts to outperform other state-of-the-art offline algorithms.},
  archive      = {J_TMLR},
  author       = {Chulabhaya Wijesundara and Andrea Baisero and Gregory David Castanon and Alan S Carlin and Robert Platt and Christopher Amato},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging fully-observable solutions for improved partially-observable offline reinforcement learning},
  url          = {https://openreview.net/forum?id=e9p4TDPy6A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased loss functions for multilabel classification with missing labels. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hMq1hUhLqp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers binary and multilabel classification problems in a setting where labels are missing independently and with a known rate. Missing labels are a ubiquitous phenomenon in extreme multi-label classification (XMC) tasks, such as matching Wikipedia articles to a small subset out of the hundreds of thousands of possible tags, where no human annotator can possibly check the validity of all the negative samples. For this reason, propensity-scored precision---an unbiased estimate for precision-at-k under a known noise model---has become one of the standard metrics in XMC. Few methods take this problem into account already during the training phase, and all of these are limited to loss functions that can be decomposed into a sum of contributions from each individual label. A typical approach to training is to reduce the multilabel problem into a series of binary or multiclass problems, and it has been shown that if the surrogate task should be consistent for optimizing recall, the resulting loss function is not decomposable over labels. Therefore, this paper develops unbiased estimators for generic, potentially non-decomposable loss functions. These estimators suffer from increased variance and may lead to ill-posed optimization problems, which we address by switching to convex upper-bounds. The theoretical considerations are further supplemented by an experimental study showing that the switch to unbiased estimators significantly alters the bias-variance trade-off and thus requires stronger regularization.},
  archive      = {J_TMLR},
  author       = {Erik Schultheis and Rohit Babbar},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unbiased loss functions for multilabel classification with missing labels},
  url          = {https://openreview.net/forum?id=hMq1hUhLqp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical test for saliency maps of graph neural networks via selective inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5NkXTCVa7F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have gained prominence for their ability to process graph-structured data across various domains. However, interpreting GNN decisions remains a significant challenge, leading to the adoption of saliency maps for identifying salient subgraphs composed of influential nodes and edges. Despite their utility, the reliability of GNN saliency maps has been questioned, particularly in terms of their robustness to input noise. In this study, we propose a statistical testing framework to rigorously evaluate the significance of saliency maps. Our main contribution lies in addressing the inflation of the Type I error rate caused by double-dipping of data, leveraging the framework of Selective Inference. Our method provides statistically valid $p$-values while controlling the Type I error rate, ensuring that identified salient subgraphs contain meaningful information rather than random artifacts. The method is applicable to a variety of saliency methods with piecewise linearity (e.g., Class Activation Mapping). We validate our method on synthetic and real-world datasets, demonstrating its capability in assessing the reliability of GNN interpretations.},
  archive      = {J_TMLR},
  author       = {Shuichi Nishino and Tomohiro Shiraishi and Teruyuki Katsuoka and Ichiro Takeuchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Statistical test for saliency maps of graph neural networks via selective inference},
  url          = {https://openreview.net/forum?id=5NkXTCVa7F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certified robustness to data poisoning in gradient-based training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9WHifn9ZVX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning pipelines leverage large amounts of public data, making it infeasible to guarantee data quality and leaving models open to poisoning and backdoor attacks. Provably bounding the behavior of learning algorithms under such attacks remains an open problem. In this work, we address this challenge by developing the first framework providing provable guarantees on the behavior of models trained with potentially manipulated data without modifying the model or learning algorithm. In particular, our framework certifies robustness against untargeted and targeted poisoning, as well as backdoor attacks, for bounded and unbounded manipulations of the training inputs and labels. Our method leverages convex relaxations to over-approximate the set of all possible parameter updates for a given poisoning threat model, allowing us to bound the set of all reachable parameters for any gradient-based learning algorithm. Given this set of parameters, we provide bounds on worst-case behavior, including model performance and backdoor success rate. We demonstrate our approach on multiple real-world datasets from applications including energy consumption, medical imaging, and autonomous driving.},
  archive      = {J_TMLR},
  author       = {Philip Sosnin and Mark Niklas Mueller and Maximilian Baader and Calvin Tsay and Matthew Robert Wicker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Certified robustness to data poisoning in gradient-based training},
  url          = {https://openreview.net/forum?id=9WHifn9ZVX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HalluEntity: Benchmarking and understanding entity-level hallucination detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=494k7e9R5D'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the impact of hallucination nature of LLMs, many studies propose detecting hallucinated generation through uncertainty estimation. However, these approaches predominantly operate at the sentence or paragraph level, failing to pinpoint specific spans or entities responsible for hallucinated content. This lack of granularity is especially problematic for long-form outputs that mix accurate and fabricated information. To address this limitation, we explore entity-level hallucination detection. We propose a new data set, HalluEntity, which annotates hallucination at the entity level. Based on the dataset, we comprehensively evaluate uncertainty-based hallucination detection approaches across 17 modern LLMs. Our experimental results show that uncertainty estimation approaches focusing on individual token probabilities tend to over-predict hallucinations, while context-aware methods show better but still suboptimal performance. Through an in-depth qualitative study, we identify relationships between hallucination tendencies and linguistic properties and highlight important directions for future research. HalluEntity: https://huggingface.co/datasets/samuelyeh/HalluEntity},
  archive      = {J_TMLR},
  author       = {Min-Hsuan Yeh and Max Kamachee and Seongheon Park and Yixuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HalluEntity: Benchmarking and understanding entity-level hallucination detection},
  url          = {https://openreview.net/forum?id=494k7e9R5D},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System-2 mathematical reasoning via enriched instruction tuning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Cl9Uox031k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving complex mathematical problems via system-2 reasoning is a natural human skill, yet it remains a significant challenge for current large language models (LLMs). We identify the scarcity of deliberate multi-step reasoning data as a primary limiting factor. To this end, we introduce Enriched Instruction Tuning (EIT), a method that enriches existing human-annotated mathematical datasets by augmenting human-annotated data with AI-generated feedback to create fine-grained reasoning trajectories. These datasets are then used to fine-tune open-source LLMs, enhancing their mathematical reasoning abilities without reliance on any symbolic verification program. Concretely, EIT is composed of two critical steps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step (ERS). The former generates a high-level plan that breaks down complex instructions into a sequence of simpler objectives, while ERS fills in reasoning contexts often overlooked by human annotators, creating a smoother reasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods that generate reasoning chains only depending on LLM's internal knowledge, our method leverages human-annotated initial answers as ``meta-knowledge'' to help LLMs generate more detailed and precise reasoning processes, leading to a more trustworthy LLM expert for complex mathematical problems. In experiments, EIT achieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing state-of-the-art fine-tuning and prompting methods, and even matching the performance of tool-augmented methods.},
  archive      = {J_TMLR},
  author       = {Huanqia Cai and Yijun Yang and Zhifeng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {System-2 mathematical reasoning via enriched instruction tuning},
  url          = {https://openreview.net/forum?id=Cl9Uox031k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning from human feedback with active queries. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EScatQaRxz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ instance-dependent regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to fine-tuning LLMs. Our experiments show that ADPO, while only making about half of queries for human preference, matches the performance of DPO, establishing it as a data-efficient alternative to DPO. The codes are available at https://github.com/jkx19/ActiveQuery.},
  archive      = {J_TMLR},
  author       = {Kaixuan Ji and Jiafan He and Quanquan Gu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning from human feedback with active queries},
  url          = {https://openreview.net/forum?id=EScatQaRxz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree search for language model agents. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QF0N3x2XVm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation. However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks. Towards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments. Our approach is a form of best-first tree search that operates within the actual environment space, and is complementary with most existing state-of-the-art agents. It is the first tree search algorithm for LM agents that shows effectiveness on realistic web tasks. On the challenging VisualWebArena benchmark, applying our search algorithm on top of a GPT-4o agent yields a 39.7% relative increase in success rate compared to the same baseline without search, setting a state-of-the-art success rate of 26.4%. On WebArena, search also yields a 28.0% relative improvement over a baseline agent, setting a competitive success rate of 19.2%. Our experiments showcase the effectiveness of search for web agents, and we demonstrate that performance scales with increased test-time compute.},
  archive      = {J_TMLR},
  author       = {Jing Yu Koh and Stephen Marcus McAleer and Daniel Fried and Ruslan Salakhutdinov},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tree search for language model agents},
  url          = {https://openreview.net/forum?id=QF0N3x2XVm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of random learning rate: Theoretical analysis of SGD dynamics in non-convex optimization via stationary distribution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RPtKkNx9ZK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variant of the stochastic gradient descent (SGD) with a random learning rate and reveal its convergence properties. SGD is a widely used stochastic optimization algorithm in machine learning, especially deep learning. Numerous studies reveal the convergence properties of SGD and its theoretically favorable variants. Among these, the analysis of convergence using a stationary distribution of updated parameters provides generalizable results. However, to obtain a stationary distribution, the update direction of the parameters must not degenerate, which limits the applicable variants of SGD. In this study, we consider a novel SGD variant, Poisson SGD, which has degenerated parameter update directions and instead utilizes a random learning rate. Consequently, we demonstrate that a distribution of a parameter updated by Poisson SGD converges to a stationary distribution under weak assumptions on a loss function. Based on this, we further show that Poisson SGD finds global minima in non-convex optimization problems and also evaluate the generalization error using this method. As a proof technique, we approximate the distribution by Poisson SGD with that of the bouncy particle sampler (BPS) and derive its stationary distribution, using the theoretical advance of the piece-wise deterministic Markov process (PDMP).},
  archive      = {J_TMLR},
  author       = {Naoki Yoshida and Shogo Nakakita and Masaaki Imaizumi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Effect of random learning rate: Theoretical analysis of SGD dynamics in non-convex optimization via stationary distribution},
  url          = {https://openreview.net/forum?id=RPtKkNx9ZK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning the language of protein structure. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SRRPQIOS4w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning and \emph{de novo} generation of proteins are pivotal computational biology tasks. Whilst natural language processing (NLP) techniques have proven highly effective for protein sequence modelling, structure modelling presents a complex challenge, primarily due to its continuous and three-dimensional nature. Motivated by this discrepancy, we introduce an approach using a vector-quantized autoencoder that effectively tokenizes protein structures into discrete representations. This method transforms the continuous, complex space of protein structures into a manageable, discrete format with a codebook ranging from 4096 to 64000 tokens, achieving high-fidelity reconstructions with backbone root mean square deviations (RMSD) of approximately 1-4 \AA. To demonstrate the efficacy of our learned representations, we show that a simple GPT model trained on our codebooks can generate novel, diverse, and designable protein structures. Our approach not only provides representations of protein structure, but also mitigates the challenges of disparate modal representations and sets a foundation for seamless, multi-modal integration, enhancing the capabilities of computational methods in protein design.},
  archive      = {J_TMLR},
  author       = {Jérémie DONA and Benoit Gaujac and Timothy Atkinson and Liviu Copoiu and Thomas Pierrot and Thomas D Barrett},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning the language of protein structure},
  url          = {https://openreview.net/forum?id=SRRPQIOS4w},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond ordinary lipschitz constraints: Differentially private optimization with TNC. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SZCygcrGng'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Stochastic Convex Optimization in Differential Privacy model (DP-SCO). Unlike previous studies, here we assume the population risk function satisfies the Tsybakov Noise Condition (TNC) with some parameter $\theta>1$, where the Lipschitz constant of the loss could be extremely large or even unbounded, but the $\ell_2$-norm gradient of the loss has bounded $k$-th moment with $k\geq 2$. For the Lipschitz case with $\theta\geq 2$, we first propose an $(\epsilon, \delta)$-DP algorithms whose utility bound is $\tilde{O}\left(\left(\tilde{r}_{2k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\epsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ in high probability, where $n$ is the sample size, $d$ is the model dimension, and $\tilde{r}_{2k}$ is a term that only depends on the $2k$-th moment of the gradient. It is notable that such an upper bound is independent of the Lipschitz constant. We then extend to the case where $\theta\geq \bar{\theta}> 1$ for some known constant $\bar{\theta}$. Moreover, when the privacy budget $\epsilon$ is small enough, we show an upper bound of $\tilde{O}\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\epsilon}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$ even if the loss function is not Lipschitz. For the lower bound, we show that for any $\theta\geq 2$, the private minimax rate for $\rho$-zero Concentrated Differential Privacy is lower bounded by $\Omega\left(\left(\tilde{r}_{k}(\frac{1}{\sqrt{n}}+(\frac{\sqrt{d}}{n\sqrt{\rho}}))^\frac{k-1}{k}\right)^\frac{\theta}{\theta-1}\right)$.},
  archive      = {J_TMLR},
  author       = {Difei Xu and Meng Ding and Zihang Xiang and Jinhui Xu and Di Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond ordinary lipschitz constraints: Differentially private optimization with TNC},
  url          = {https://openreview.net/forum?id=SZCygcrGng},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complementarity: Toward better metrics and optimizing data efficiency in LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=feAbrMXGMh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalist Large Language Models (LLMs) are trained with an immense amount of data from across different domains. However, not all data contribute to model performance equally, and prioritizing data quality can improve domain-specific performance. We suggest that quality is not merely an independent feature of datasets, but rather the manner in which data samples interfere with or complement one another. Furthermore, existing performance metrics for language models are computationally expensive, while also frequently suffering from being mathematically ill-defined and poorly suited to generative AI. Toward improving general performance while reducing the amount of training data, and quantifying how data contributes to downstream tasks vis-a-vis their relation with other data, we introduce a new metric, Complementarity. We first establish a strong correlation between Complementarity and domain-specific task performance. Without reliance on heavy instruction-tuning and text scraping, Complementarity is significantly less expensive to compute and is applicable to a wide variety of potential target domains. Most interestingly, we demonstrate that the Complementarity taken over a training validation set provides a better predictor of generalization to future test sets than directly measuring performance on a test validation set. With this, we introduce an algorithm that carefully selects the data to fine-tune upon, leading to a high-performing fine-tuned generalist model while using only a fraction of the data, and without requiring data from the test domain. Overall, Complementarity may serve as a key metric in future analysis of data utility and design of datasets, and help facilitate the goal of a truly generalist model.},
  archive      = {J_TMLR},
  author       = {Roy Siegelmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Complementarity: Toward better metrics and optimizing data efficiency in LLMs},
  url          = {https://openreview.net/forum?id=feAbrMXGMh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the limitations of layer synchronization in spiking neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mfmAVwtMIk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural-network processing in machine learning applications relies on layer synchronization. This is practiced even in artificial Spiking Neural Networks (SNNs), which are touted as consistent with neurobiology, in spite of processing in the brain being in fact asynchronous. A truly asynchronous system however would allow all neurons to evaluate concurrently their threshold and emit spikes upon receiving any presynaptic current. Omitting layer synchronization is potentially beneficial, for latency and energy efficiency, but asynchronous execution of models previously trained with layer synchronization may entail a mismatch in network dynamics and performance. We present and quantify this problem, and show that models trained with layer synchronization either perform poorly in absence of the synchronization, or fail to benefit from any energy and latency reduction, when such a mechanism is in place. We then explore a potential solution direction, based on a generalization of backpropagation-based training that integrates knowledge about an asynchronous execution scheduling strategy, for learning models suitable for asynchronous processing. We experiment with 2 asynchronous neuron execution scheduling strategies in datasets that encode spatial and temporal information, and we show the potential of asynchronous processing to use less spikes (up to 50\%), complete inference faster (up to 2x), and achieve competitive or even better accuracy (up to $\sim$10\% higher). Our exploration affirms that asynchronous event-based AI processing can be indeed more efficient, but we need to rethink how we train our SNN models to benefit from it. (Source code available at: \url{https://github.com/RoelMK/asynctorch})},
  archive      = {J_TMLR},
  author       = {Roel Koopman and Amirreza Yousefzadeh and Mahyar Shahsavari and Guangzhi Tang and Manolis Sifalakis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring the limitations of layer synchronization in spiking neural networks},
  url          = {https://openreview.net/forum?id=mfmAVwtMIk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple noises in diffusion model for semi-supervised multi-domain translation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vYdT26kDYM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the challenge of multi-domain translation, where the objective is to learn mappings between arbitrary configurations of domains within a defined set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for three domains) without the need for separate models for each specific translation configuration, enabling more efficient and flexible domain translation. We introduce Multi-Domain Diffusion (MDD), a method with dual purposes: i) reconstructing any missing views for new data objects, and ii) enabling learning in semi-supervised contexts with arbitrary supervision configurations. MDD achieves these objectives by exploiting the noise formulation of diffusion models, specifically modeling one noise level per domain. Similar to existing domain translation approaches, MDD learns the translation between any combination of domains. However, unlike prior work, our formulation inherently handles semi-supervised learning without modification by representing missing views as noise in the diffusion process. We evaluate our approach through domain translation experiments on BL3NDT, a multi-domain synthetic dataset designed for challenging semantic domain inversion, the BraTS2020 dataset, and the CelebAMask-HQ dataset.},
  archive      = {J_TMLR},
  author       = {Tsiry Mayet and Simon Bernard and Romain HÉRAULT and Clement Chatelain},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiple noises in diffusion model for semi-supervised multi-domain translation},
  url          = {https://openreview.net/forum?id=vYdT26kDYM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous language model interpolation yields dynamic and controllable text generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xD9Nu2Wah4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large language models (LLMs) have gained popularity for a variety of use cases, making them adaptable and controllable has become increasingly important, especially for user-facing applications. In particular, linear interpolation between model parameters forms the backbone for many recent approaches to adapting models to user preferences. While the existing literature on LLM adaptation primarily focuses on finding methods that optimize for some set of performance criteria or user preferences, here we instead seek to better understand and characterize the behavior of dense, continuous interpolation between models. Specifically, we use low-rank updates to fine-tune a base model to various different domains, yielding a set of anchor models with distinct generation profiles. Then, we use the weight updates of these anchor models to parametrize the entire (infinite) class of models contained within their convex hull. We empirically show that varying the interpolation weights yields predictable and consistent change in the model outputs with respect to all of the controlled attributes simultaneously. We find that there is little entanglement between most attributes and identify and discuss the pairs of attributes for which this is not the case. Our results suggest that parameter merging facilitates flexible model adaptation due to its predictable behavior within the full interpolation region.},
  archive      = {J_TMLR},
  author       = {Sara Kangaslahti and David Alvarez-Melis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continuous language model interpolation yields dynamic and controllable text generation},
  url          = {https://openreview.net/forum?id=xD9Nu2Wah4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-regressive vs flow-matching: A comparative study of modeling paradigms for text-to-music generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xXc5DeaBYw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in text-to-music generation has enabled models to synthesize high-quality musical segments, full compositions, and even respond to fine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA) systems differ significantly in many dimensions, such as training datasets, modeling paradigms, and architectural choices. This diversity complicates efforts to evaluate models fairly and identify which design choices influence performance the most. While factors like data and architecture are important, in this study we focus exclusively on the modeling paradigm. We conduct a systematic empirical analysis to isolate its effects, offering insights into associated trade-offs and emergent behaviors that can guide future text-to-music generation systems. Specifically, we compare the two arguably most common modeling paradigms: auto-regressive decoding and conditional flow-matching. We conduct a controlled comparison by training all models from scratch using identical datasets, training configurations, and similar backbone architectures. Performance is evaluated across multiple axes, including generation quality, robustness to inference configurations, scalability, adherence to both textual and temporally aligned conditioning, and editing capabilities in the form of audio inpainting. This comparative study sheds light on distinct strengths and limitations of each paradigm, providing actionable insights that can inform future architectural and training decisions in the evolving landscape of text-to-music generation. Audio sampled examples are available at: https://huggingface.co/spaces/ortal1602/ARvsFM},
  archive      = {J_TMLR},
  author       = {Or Tal and Felix Kreuk and Yossi Adi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Auto-regressive vs flow-matching: A comparative study of modeling paradigms for text-to-music generation},
  url          = {https://openreview.net/forum?id=xXc5DeaBYw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean-field RL for large-scale unit-capacity pickup-and-delivery problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=E8JRswdyDR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving large-scale vehicle routing problems (VRPs) is NP-hard and poses a computational challenge in numerous applications such as logistics. Meanwhile, mean-field control (MFC) provides a tractable and rigorous approach to controlling many agents. We provide a solution to pickup-and-delivery VRPs via scalable MFC. In combination with reinforcement learning (RL) and clustering, our MFC approach efficiently scales to large-scale VRPs. We perform a theoretical analysis of our MFC-based approximation, giving convergence results for large VRP instances and error bounds for clustering-based approximations. We verify our algorithms on different datasets and compare them against solutions such as OR-Tools, PyVRP and heuristics, showing scalability in terms of speed for mean-field methods, for the first time in discrete optimization. Overall, our work establishes a novel synthesis of MFC-based RL techniques, vehicle routing problems and clustering approximations, to solve a hard discrete optimization problem of practical use in a scalable way.},
  archive      = {J_TMLR},
  author       = {Kai Cui and Sharif Azem and Christian Fabian and Kirill Kuroptev and Ramin Khalili and Osama Abboud and Florian Steinke and Heinz Koeppl},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mean-field RL for large-scale unit-capacity pickup-and-delivery problems},
  url          = {https://openreview.net/forum?id=E8JRswdyDR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Doubly robust uncertainty quantification for quantile treatment effects in sequential decision making. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F0BwbieVws'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multi-stage sequential decision making, where the treatment at any stage may depend on the subject’s entire treatment and covariate history. We introduce a general framework for doubly robust uncertainty quantification for the quantiles of cumulative outcomes under a sequential treatment rule. While previous studies focused on mean effects, quantile effects offer unique insights into the distributional properties and are more robust for heavy-tailed outcomes. It is known that, doubly robust inference is significantly more challenging and largely unexplored for quantile treatment effects. More importantly, for mean effects, doubly robust estimation does not ensure doubly robust inference. Our approach first provides a doubly robust estimator for any quantile of interest based on pre-collected data, achieving semi-parametric efficiency. We then propose a novel doubly robust estimator for the asymptotic variance, enabling the construction of a doubly robust confidence interval. To overcome the challenges in parameter-dependent nuisance functions, we leverage deep conditional generative learning techniques. We demonstrate advantages of our approach via both simulation and real data from a short video platform. Additionally, we observe that our proposed approach leads to another mean effect estimator that outperforms existing estimators with heavy-tailed outcomes.},
  archive      = {J_TMLR},
  author       = {Yang Xu and Chengchun Shi and Shikai Luo and Lan Wang and Rui Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Doubly robust uncertainty quantification for quantile treatment effects in sequential decision making},
  url          = {https://openreview.net/forum?id=F0BwbieVws},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The overcooked generalisation challenge: Evaluating cooperation with novel partners in unknown environments using unsupervised environment design. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=K2KtcMlW6j'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Overcooked Generalisation Challenge (OGC) – a new benchmark for evaluating reinforcement learning (RL) agents on their ability to cooperate with unknown partners in unfamiliar environments. Existing work typically evaluated cooperative RL only in their training environment or with their training partners, thus seriously limiting our ability to understand agents’ generalisation capacity – an essential requirement for future collaboration with humans. The OGC extends Overcooked-AI to support dual curriculum design (DCD). It is fully GPU-accelerated, open-source, and integrated into the minimax DCD benchmark suite. Compared to prior DCD benchmarks, where designers manipulate only minimal elements of the environment, OGC introduces a significantly richer design space: full kitchen layouts with multiple objects that require the designer to account for interaction dynamics between agents. We evaluate state-of-the-art DCD algorithms alongside scalable neural architectures and find that current methods fail to produce agents that generalise effectively to novel layouts and unfamiliar partners. Our results indicate that both agents and curriculum designers struggle with the joint challenge of partner and environment generalisation. These findings establish OGC as a demanding testbed for cooperative generalisation and highlight key directions for future research. We open-source our code.},
  archive      = {J_TMLR},
  author       = {Constantin Ruhdorfer and Matteo Bortoletto and Anna Penzkofer and Andreas Bulling},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The overcooked generalisation challenge: Evaluating cooperation with novel partners in unknown environments using unsupervised environment design},
  url          = {https://openreview.net/forum?id=K2KtcMlW6j},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving inverse problems using diffusion with iterative colored renoising. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RZv8FcQDPW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models, but doing so requires approximating the gradient of the measurement-conditional score function in the diffusion reverse process. We show that the approximations produced by existing methods are relatively poor, especially early in the reverse process, and so we propose a new approach that iteratively reestimates and ``renoises'' the estimate several times per diffusion step. This iterative approach, which we call Fast Iterative REnoising (FIRE), injects colored noise that is shaped to ensure that the pre-trained diffusion model always sees white noise, in accordance with how it was trained. We then embed FIRE into the DDIM reverse process and show that the resulting ``DDfire'' offers state-of-the-art accuracy and runtime on several linear inverse problems, as well as phase retrieval.},
  archive      = {J_TMLR},
  author       = {Matthew C Bendel and Saurav K Shastri and Rizwan Ahmad and Philip Schniter},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving inverse problems using diffusion with iterative colored renoising},
  url          = {https://openreview.net/forum?id=RZv8FcQDPW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COMMA: A communicative multimodal multi-agent benchmark. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TIGQIem1na'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advances of multimodal agents built on large foundation models have largely overlooked their potential for language-based communication between agents in collaborative tasks. This oversight presents a critical gap in understanding their effectiveness in real-world deployments, particularly when communicating with humans. Existing agentic benchmarks fail to address key aspects of inter-agent communication and collaboration, particularly in scenarios where agents have unequal access to information and must work together to achieve tasks beyond the scope of individual capabilities. To fill this gap, we introduce COMMA: a novel puzzle benchmark designed to evaluate the collaborative performance of multimodal multi-agent systems through language communication. Our benchmark features a variety of multimodal puzzles, providing a comprehensive evaluation across four key categories of agentic capability in a communicative collaboration setting. Our findings reveal surprising weaknesses in state-of-the-art models, including strong proprietary models like GPT-4o and reasoning models like o4-mini. Many chain of thought reasoning models such as R1-Onevision and LLaVA-CoT struggle to outperform even a random baseline in agent-agent collaboration, indicating a potential growth area in their communication abilities.},
  archive      = {J_TMLR},
  author       = {Timothy Ossowski and Danyal Maqbool and Jixuan Chen and Zefan Cai and Tyler J. Bradshaw and Junjie Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {COMMA: A communicative multimodal multi-agent benchmark},
  url          = {https://openreview.net/forum?id=TIGQIem1na},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-positive multi-label learning with label cardinality. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XEPPXH2nKu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study learning a multi-label classifier from partially labeled data, where each instance has only a single positive label. We explain how auxiliary information available on the label cardinality, the number of positive labels per instance, can be used for improving such methods. We consider auxiliary information of varying granularity, ranging from knowing just the maximum number of labels over all instances to knowledge on the distribution of label cardinalities and even the exact cardinality of each instance. We introduce methods leveraging the different types of auxiliary information, study how close to the fully labeled accuracy we can get under different scenarios, and show that an easy-to-implement method only assuming the knowledge of the maximum cardinality is comparable to the state-of-the-art single-positive multi-label learning methods when using the same base model. Our implementation is publicly available at https://github.com/shayangharib/SPMLL_with_Label_Cardinality.},
  archive      = {J_TMLR},
  author       = {Shayan Gharib and Pierre-Alexandre Murena and Arto Klami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Single-positive multi-label learning with label cardinality},
  url          = {https://openreview.net/forum?id=XEPPXH2nKu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text to stealthy adversarial face masks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XYqCx026AI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that modern facial recognition systems, which are based on deep neural networks, are vulnerable to adversarial attacks, including the use of accessories, makeup patterns, or precision lighting. However, developing attacks that are both robust (resilient to changes in viewing angles and environmental conditions) and stealthy (do not attract suspicion by, for example, incorporating obvious facial features) remains a significant challenge. In this context, we introduce a novel diffusion-based method (DAFR) capable of generating robust and stealthy face masks for dodging recognition systems (where the system fails to identify the attacker). Specifically our approach is capable of producing high-fidelity printable textures using the guidance of textual prompts to determine the style. This method can also be adapted for impersonation purposes, where the system misidentifies the attacker as a specific other individual. Finally, we address a gap in the existing literature by presenting a comprehensive benchmark (FAAB) for evaluating adversarial accessories in three dimensions, assessing their robustness and stealthiness.},
  archive      = {J_TMLR},
  author       = {Ben Lewis and Thomas Moyse and James Parkinson and Elizabeth Telford and Callum Whitfield and Ranko Lazic},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Text to stealthy adversarial face masks},
  url          = {https://openreview.net/forum?id=XYqCx026AI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAPP: Large language model feedback for preference-driven reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cq76wx7T9F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Large Language Model-Assisted Preference Prediction (LAPP), a novel framework for robot learning that enables efficient, customizable, and expressive behavior acquisition with minimum human effort. Unlike prior approaches that rely heavily on reward engineering, human demonstrations, motion capture, or expensive pairwise preference labels, LAPP leverages large language models (LLMs) to automatically generate preference labels from raw state-action trajectories collected during reinforcement learning (RL). These labels are used to train an online preference predictor, which in turn guides the policy optimization process toward satisfying high-level behavioral specifications provided by humans. Our key technical contribution is the integration of LLMs into the RL feedback loop through trajectory-level preference prediction, enabling robots to acquire complex skills including subtle control over gait patterns and rhythmic timing. We evaluate LAPP on a diverse set of quadruped locomotion and dexterous manipulation tasks and show that it achieves efficient learning, higher final performance, faster adaptation, and precise control of high-level behaviors. Notably, LAPP enables robots to master highly dynamic and expressive tasks such as quadruped backflips, which remain out of reach for standard LLM-generated or handcrafted rewards. Our results highlight LAPP as a promising direction for scalable preference-driven robot learning.},
  archive      = {J_TMLR},
  author       = {Pingcheng Jian and Xiao Wei and Yanbaihui Liu and Samuel A. Moore and Michael M. Zavlanos and Boyuan Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LAPP: Large language model feedback for preference-driven reinforcement learning},
  url          = {https://openreview.net/forum?id=cq76wx7T9F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Studying memorization of large language models using answers to stack overflow questions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ddocn44Kaq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are capable of answering many software related questions and supporting developers by generating code snippets. These capabilities originate from training on massive amounts of data from the Internet, including information from Stack Overflow. This raises the question whether answers to software related questions are simply memorized from the training data, which might raise problems as this often requires attribution (e.g., CC-BY license), sharing with a similar license (e.g., GPL licenses) or may even be prohibited (proprietary license). To study this, we compare responses to questions from Stack Overflow for questions that were known during LLM pre-training and questions that were not included in the pre-training data. We then calculate the overlap both with answers marked as accepted on Stack Overflow as well as other texts we can find on the internet. We further explore the impact of the popularity of programming languages, the complexity of the prompts used, and the randomization of the text generation process on the memorization of answers to Stack Overflow. We find that many generated answers are to some degree collages of memorized content and that this does not dependent on whether the questions were seen during training or not. However, many of the memorized snippets are common phrases or code and, therefore, not copyrightable. Still, we also have clear evidence that copyright violation happens and is likely when LLMs are used at large scales.},
  archive      = {J_TMLR},
  author       = {Laura Caspari and Alexander Trautsch and Michael Granitzer and Steffen Herbold},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Studying memorization of large language models using answers to stack overflow questions},
  url          = {https://openreview.net/forum?id=ddocn44Kaq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HandsOnVLM: Vision-language models for hand-object interaction prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ehhMFjKnWm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we predict future interaction trajectories of human hands in a scene given high-level colloquial task specifications in the form of natural language? In this paper, we extend the classic hand trajectory prediction task to several tasks involving explicit and implicit language queries. Our proposed tasks require extensive understanding of human daily activities and reasoning abilities about what is happening next given cues from the current scene. We also develop new benchmarks to evaluate the proposed two tasks, Vanilla Hand Prediction (VHP) and Reasoning-Based Hand Prediction (RBHP). We enable solving these tasks by integrating high-level world knowledge and reasoning capabilities of Vision-Language Models (VLMs) with the auto-regressive nature of low-level ego-centric hand trajectories. Our model, HandsOnVLM is a novel VLM that can generate textual responses and produce future hand trajectories through natural-language conversations. Our experiments show that HandsOnVLM outperforms existing task-specific methods and other VLM baselines on proposed tasks, and demonstrates its ability to effectively utilize world knowledge for reasoning about low-level human hand trajectories based on the provided context. More details can be found at https://www.chenbao.tech/handsonvlm/.},
  archive      = {J_TMLR},
  author       = {Chen Bao and Jiarui Xu and Xiaolong Wang and Abhinav Gupta and Homanga Bharadhwaj},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HandsOnVLM: Vision-language models for hand-object interaction prediction},
  url          = {https://openreview.net/forum?id=ehhMFjKnWm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete audio tokens: More than a survey!. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eqNchtvc6v'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete audio tokens are compact representations that aim to preserve perceptual quality, phonetic content, and speaker characteristics while enabling efficient storage and inference, as well as competitive performance across diverse downstream tasks. They provide a practical alternative to continuous features, enabling the integration of speech and audio into modern large language models (LLMs). As interest in token-based audio processing grows, various tokenization methods have emerged, and several surveys have reviewed the latest progress in the field. However, existing studies often focus on specific domains or tasks and lack a unified comparison across various benchmarks. This paper presents a systematic review and benchmark of discrete audio tokenizers, covering three domains: speech, music, and general audio. We propose a taxonomy of tokenization approaches based on encoder-decoder, quantization techniques, training paradigm, streamability, and application domains. We evaluate tokenizers on multiple benchmarks for reconstruction, downstream performance, and acoustic language modeling, and analyze trade-offs through controlled ablation studies. Our findings highlight key limitations, practical considerations, and open challenges, providing insight and guidance for future research in this rapidly evolving area. For more information, including our main results and tokenizer database, please refer to our website: https://poonehmousavi.github.io/dates-website/.},
  archive      = {J_TMLR},
  author       = {Pooneh Mousavi and Gallil Maimon and Adel Moumen and Darius Petermann and Jiatong Shi and Haibin Wu and Haici Yang and Anastasia Kuznetsova and Artem Ploujnikov and Ricard Marxer and Bhuvana Ramabhadran and Benjamin Elizalde and Loren Lugosch and Jinyu Li and Cem Subakan and Phil Woodland and Minje Kim and Hung-yi Lee and Shinji Watanabe and Yossi Adi and Mirco Ravanelli},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Discrete audio tokens: More than a survey!},
  url          = {https://openreview.net/forum?id=eqNchtvc6v},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the learned look-ahead behavior of chess neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=np4Bg2zIxL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. (2024) by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems.},
  archive      = {J_TMLR},
  author       = {Diogo Cruz},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding the learned look-ahead behavior of chess neural networks},
  url          = {https://openreview.net/forum?id=np4Bg2zIxL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowKac: An efficient neural fokker-planck solver using temporal normalizing flows and the feynman-kac formula. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=paeyQFa5or'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the Fokker-Planck equation for high-dimensional complex dynamical systems remains a pivotal yet challenging task due to the intractability of analytical solutions and the limitations of traditional numerical methods. In this work, we present FlowKac, a novel approach that reformulates the Fokker-Planck equation using the Feynman-Kac formula, allowing to query the solution at a given point via the expected values of stochastic paths. A key innovation of FlowKac lies in its adaptive stochastic sampling scheme which significantly reduces the computational complexity while maintaining high accuracy. This sampling technique, coupled with a time-indexed normalizing flow, designed for capturing time-evolving probability densities, enables robust sampling of collocation points, resulting in a flexible and mesh-free solver. This formulation mitigates the curse of dimensionality and enhances computational efficiency and accuracy, which is particularly crucial for applications that inherently require dimensions beyond the conventional three. We validate the robustness and scalability of our method through various experiments on a range of stochastic differential equations, demonstrating significant improvements over existing techniques.},
  archive      = {J_TMLR},
  author       = {Naoufal EL BEKRI and Lucas Drumetz and Franck Vermet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlowKac: An efficient neural fokker-planck solver using temporal normalizing flows and the feynman-kac formula},
  url          = {https://openreview.net/forum?id=paeyQFa5or},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient object-centric representation learning using masked generative modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=t9KvOYPeL3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning object-centric representations from visual inputs in an unsupervised manner has drawn focus to solve more complex tasks, such as reasoning and reinforcement learning. However, current state-of-the-art methods, relying on autoregressive transformers or diffusion models to generate scenes from object-centric representations, suffer from computational inefficiency due to their sequential or iterative nature. This computational bottleneck limits their practical application and hinders scaling to more complex downstream tasks. To overcome this, we propose MOGENT, an efficient object-centric learning framework based on masked generative modeling. MOGENT conditions a masked bidirectional transformer on learned object slots and employs a parallel iterative decoding scheme to generate scenes, enabling efficient compositional generation. Experiments show that MOGENT significantly improves computational efficiency, accelerating the generation process by up to 67x and 17x compared to autoregressive models and diffusion-based models, respectively. Importantly, the efficiency is attained while maintaining strong or competitive performance on object segmentation and compositional generation tasks.},
  archive      = {J_TMLR},
  author       = {Akihiro Nakano and Masahiro Suzuki and Yutaka Matsuo},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient object-centric representation learning using masked generative modeling},
  url          = {https://openreview.net/forum?id=t9KvOYPeL3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedComLoc: Communication-efficient distributed training of sparse and quantized models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vYQPLytQsj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is Local Training, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative Scaffnew algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into Scaffnew to further enhance communication efficiency. Extensive experiments, using the popular Top-K compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heterogeneous settings.},
  archive      = {J_TMLR},
  author       = {Kai Yi and Georg Meinhardt and Laurent Condat and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedComLoc: Communication-efficient distributed training of sparse and quantized models},
  url          = {https://openreview.net/forum?id=vYQPLytQsj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label embedding via low-coherence matrices. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vrcWXcr4On'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label embedding is a framework for multiclass classification problems where each label is represented by a distinct vector of some fixed dimension, and training involves matching model output to the vector representing the correct label. While label embedding has been successfully applied in extreme classification and zero-shot learning, and offers both computational and statistical advantages, its theoretical foundations remain poorly understood. This work presents an analysis of label embedding in the context of extreme multiclass classification, where the number of classes $C$ is very large. We present an excess risk bound that reveals a trade-off between computational and statistical efficiency, quantified via the coherence of the embedding matrix. We further show that under the Massart noise condition, the statistical penalty for label embedding vanishes with sufficiently low coherence. Our analysis supports an algorithm that is simple, scalable, and easily parallelizable, and experimental results demonstrate its effectiveness in large-scale applications.},
  archive      = {J_TMLR},
  author       = {Jianxin Zhang and Clayton Scott},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label embedding via low-coherence matrices},
  url          = {https://openreview.net/forum?id=vrcWXcr4On},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNR-pruning: Sparsity-aware pruning via dying neuron reactivation in convolutional neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ymUjGCNPYa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we challenge the conventional view of dead neurons—neurons that cease to activate—during deep neural network training. Traditionally regarded as problematic due to their association with optimization challenges and reduced model adaptability over training epochs, dead neurons are often seen as a hindrance. However, we present a novel perspective, demonstrating that they can be effectively leveraged to enhance network sparsity. Specifically, we propose DNR-Pruning, dying neuron reactivation based sparsity-aware pruning approach for convolutional neural networks (CNNs) that exploits the behavior of individual neurons during training. Through a systematic exploration of hyperparameter configurations, we show that dying neurons can be harnessed to improve pruning algorithms. Our method dynamically monitors the occurrence of dying neurons, enabling adaptive sparsification throughout CNN training. Extensive experiments on diverse datasets demonstrate that DNR-Pruning outperforms existing sparsity-aware pruning techniques while achieving competitive results compared to state-of-the-art methods. These findings suggest that dying neurons can serve as an efficient mechanism for network compression and resource optimization in CNNs, opening new avenues for more efficient and high-performance deep learning models.},
  archive      = {J_TMLR},
  author       = {Boyuan Wang and Richard Jiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DNR-pruning: Sparsity-aware pruning via dying neuron reactivation in convolutional neural networks},
  url          = {https://openreview.net/forum?id=ymUjGCNPYa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information-theoretic lower bound on the generalization error of autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0esF0M467w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the limitations of classical neural network architectures is a critically underexplored area of machine learning research. Deriving lower bounds on the optimal performance of these architectures can facilitate improved neural architecture search and overfitting detection. We present an information-theoretic lower bound on the generalization mean squared error of autoencoders with sigmoid activation functions. Through the Estimation Error and Differential Entropy (EEDE) inequality for continuous random vectors, we derive this lower bound, which provides a new perspective on the inherent limitations and capabilities of autoencoders. Our analysis extends to the examination of how this lower bound is influenced by various architectural features and data distribution characteristics. This study enriches our theoretical understanding of autoencoders and has substantial practical implications for their design, optimization, and application in the field of deep learning.},
  archive      = {J_TMLR},
  author       = {Shyam Venkatasubramanian and Sean Moushegian and Ahmed Aloui and Vahid Tarokh},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An information-theoretic lower bound on the generalization error of autoencoders},
  url          = {https://openreview.net/forum?id=0esF0M467w},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Min-max optimisation for nonconvex-nonconcave functions using a random zeroth-order extragradient algorithm. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1bxY1uAXyr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the performance of the random Gaussian smoothing Zeroth-Order ExtraGradient (ZO-EG) scheme considering deterministic min-max optimisation problems with possibly NonConvex-NonConcave (NC-NC) objective functions. We consider both unconstrained and constrained, differentiable and non-differentiable settings. We discuss the min-max problem from the point of view of variational inequalities. For the unconstrained problem, we establish the convergence of the ZO-EG algorithm to the neighbourhood of an $\epsilon$-stationary point of the NC-NC objective function, whose radius can be controlled under a variance reduction scheme, along with its complexity. For the constrained problem, we introduce the new notion of proximal variational inequalities and give examples of functions satisfying this property. Moreover, we prove analogous results to the unconstrained case for the constrained problem. For the non-differentiable case, we prove the convergence of the ZO-EG algorithm to a neighbourhood of an $\epsilon$-stationary point of the smoothed version of the objective function, where the radius of the neighbourhood can be controlled, which can be related to the ($\delta,\epsilon$)-Goldstein stationary point of the original objective function.},
  archive      = {J_TMLR},
  author       = {Amir Ali Farzin and Yuen-Man Pun and Philipp Braun and Antoine Lesage-Landry and Youssef Diouane and Iman Shames},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Min-max optimisation for nonconvex-nonconcave functions using a random zeroth-order extragradient algorithm},
  url          = {https://openreview.net/forum?id=1bxY1uAXyr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey of video diffusion models: Foundations, implementations, and applications. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2ODDBObKjH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in diffusion models have revolutionized video generation, offering superior temporal consistency and visual quality compared to traditional generative adversarial networks-based approaches. While this emerging field shows tremendous promise in applications, it faces significant challenges in motion consistency, computational efficiency, and ethical considerations. This survey provides a comprehensive review of diffusion-based video generation, examining its evolution, technical foundations, and practical applications. We present a systematic taxonomy of current methodologies, analyze architectural innovations and optimization strategies, and investigate applications across low-level vision tasks such as denoising and super-resolution. Additionally, we explore the synergies between diffusion-based video generation and related domains, including video representation learning, question answering, and retrieval. Compared to the existing surveys (Lei et al., 2024a;b; Melniket al., 2024; Cao et al., 2023; Xing et al., 2024c) which focus on specific aspects of video generation, such as human video synthesis (Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our work provides a broader, more updated, and more fine-grained perspective on diffusion-based approaches with a special section for evaluation metrics, industry solutions, and training engineering techniques in video generation. This survey serves as a foundational resource for researchers and practitioners working at the intersection of diffusion models and video generation, providing insights into both the theoretical frameworks and practical implementations that drive this rapidly evolving field.},
  archive      = {J_TMLR},
  author       = {Yimu Wang and Xuye Liu and Wei Pang and Li Ma and Shuai Yuan and Paul Debevec and Ning Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Survey of video diffusion models: Foundations, implementations, and applications},
  url          = {https://openreview.net/forum?id=2ODDBObKjH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GROOD: GRadient-aware out-of-distribution detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2V7itvvMVJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) detection is crucial for ensuring the reliability of deep learning models in real-world applications. Existing methods typically focus on feature representations or output-space analysis, often assuming a distribution over these spaces or leveraging gradient norms with respect to model parameters. However, these approaches struggle to distinguish near-OOD samples and often require extensive hyper-parameter tuning, limiting their practicality. In this work, we propose GRadient-aware Out-Of-Distribution detection (GROOD), a method that derives an OOD prototype from synthetic samples and computes class prototypes directly from In-distribution (ID) training data. By analyzing the gradients of a nearest-class-prototype loss function concerning an artificial OOD prototype, our approach achieves a clear separation between in-distribution and OOD samples. Experimental evaluations demonstrate that gradients computed from the OOD prototype enhance the distinction between ID and OOD data, surpassing established baselines in robustness, particularly on ImageNet-1k. These findings highlight the potential of gradient-based methods and prototype-driven approaches in advancing OOD detection within deep neural networks.},
  archive      = {J_TMLR},
  author       = {Mostafa ElAraby and Sabyasachi Sahoo and Yann Pequignot and Paul Novello and Liam Paull},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GROOD: GRadient-aware out-of-distribution detection},
  url          = {https://openreview.net/forum?id=2V7itvvMVJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust representations for visual reinforcement learning via task-relevant mask sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2rxNDxHwtn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans excel at isolating relevant information from noisy data to predict the behavior of dynamic systems, effectively disregarding non-informative, temporally-correlated noise. In contrast, existing visual reinforcement learning algorithms face challenges in generating noise-free predictions within high-dimensional, noise-saturated environments, especially when trained on world models featuring realistic background noise extracted from natural video streams. We propose Task Relevant Mask Sampling (TRMS), a novel approach for identifying task-specific and reward-relevant masks. TRMS utilizes existing segmentation models as a masking prior, which is subsequently followed by a mask selector that dynamically identifies subset of masks at each timestep, selecting those most probable to contribute to task-specific rewards. To mitigate the high computational cost associated with these masking priors, a lightweight student network is trained in parallel. This network learns to perform masking independently and replaces the Segment Anything Model~(SAM)-based teacher network after a brief initial phase (<10-25% of total training). TRMS enhances the generalization capabilities of Soft Actor-Critic agents under distractions, achieves better performance on the RL-Vigen benchmark, which includes challenging variants of the DeepMind Control Suite, Dexterous Manipulation and Quadruped Locomotion tasks.},
  archive      = {J_TMLR},
  author       = {Vedant Dave and Ozan Özdenizci and Elmar Rueckert},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning robust representations for visual reinforcement learning via task-relevant mask sampling},
  url          = {https://openreview.net/forum?id=2rxNDxHwtn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LIT-LVM: Structured regularization for interaction terms in linear predictors using latent variable models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3uW5nxESu1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some of the simplest, yet most frequently used predictors in statistics and machine learning use weighted linear combinations of features. Such linear predictors can model non-linear relationships between features by adding interaction terms corresponding to the products of all pairs of features. We consider the problem of accurately estimating coefficients for interaction terms in linear predictors. We hypothesize that the coefficients for different interaction terms have an approximate low-dimensional structure and represent each feature by a latent vector in a low-dimensional space. This low-dimensional representation can be viewed as a structured regularization approach that further mitigates overfitting in high-dimensional settings beyond standard regularizers such as the lasso and elastic net. We demonstrate that our approach, called LIT-LVM, achieves superior prediction accuracy compared to the elastic net, hierarchical lasso, and factorization machines on a wide variety of simulated and real data, particularly when the number of interaction terms is high compared to the number of samples. LIT-LVM also provides low-dimensional latent representations for features that are useful for visualizing and analyzing their relationships.},
  archive      = {J_TMLR},
  author       = {Mohammadreza Nemati and Zhipeng Huang and Kevin S. Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LIT-LVM: Structured regularization for interaction terms in linear predictors using latent variable models},
  url          = {https://openreview.net/forum?id=3uW5nxESu1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double machine learning based structure identification from temporal data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4iHAoFVM2K'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the causes of time-series data is a fundamental task in many applications, spanning from finance to earth sciences or bio-medical applications. Common approaches for this task are based on vector auto-regression, and they do not take into account unknown confounding between potential causes. However, in settings with many potential causes and noisy data, these approaches may be substantially biased. Furthermore, potential causes may be correlated in practical applications or even contain cycles. To address these challenges, we propose a new double machine learning based method for structure identification from temporal data (DR-SIT). We provide theoretical guarantees, showing that our method asymptotically recovers the true underlying causal structure. Our analysis extends to cases where the potential causes have cycles, and they may even be confounded. We further perform extensive experiments to showcase the superior performance of our method. Code: https://github.com/sdi1100041/TMLR_submission_DR_SIT},
  archive      = {J_TMLR},
  author       = {Emmanouil Angelis and Francesco Quinzan and Ashkan Soleymani and Patrick Jaillet and Stefan Bauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Double machine learning based structure identification from temporal data},
  url          = {https://openreview.net/forum?id=4iHAoFVM2K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Byzantine-robust and hessian-free federated bilevel optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5trmyvtkeo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, Byzantine robust algorithms to solve a minimization problem in the Federated setup have received significant attention. Most of the existing works consider the problem of byzantine-robustness for single-level optimization or consider the federated bilevel optimization without Byzantine nodes. However, problem formulation such as federated bilevel optimization in the presence of byzantine nodes is unexplored. Recognizing the gap, for the first time, we propose a computationally efficient and robust algorithm for solving Federated Bilevel Optimization with Byzantine (FedBOB) nodes that: \One Work under the assumption that the data across nodes are heterogeneous (non-iid), \2 Consider the lower-level objective is non-convex and satisfies the Polyak-\L ojasiewicz (PL)-inequality, and \3 Is fully first-order and does not rely on second order information. We achieve this by reformulating the federated bilevel problem into a single penalty problem. We provide the theoretical performance of the proposed algorithm and experimentally corroborate our theoretical findings.},
  archive      = {J_TMLR},
  author       = {Shruti P Maralappanavar and Bharath B N},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Byzantine-robust and hessian-free federated bilevel optimization},
  url          = {https://openreview.net/forum?id=5trmyvtkeo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate bayesian neural operators: Uncertainty quantification for parametric PDEs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6WvIkYsMA8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators are a type of deep architecture that learns to solve (i.e. learns the nonlinear solution operator of) partial differential equations (PDEs). The current state of the art for these models does not provide explicit uncertainty quantification. This is arguably even more of a problem for this kind of tasks than elsewhere in machine learning, because the dynamical systems typically described by PDEs often exhibit subtle, multiscale structure that makes errors hard to spot by humans. In this work, we first provide a mathematically detailed Bayesian formulation of the ``shallow'' (linear) version of neural operators in the formalism of Gaussian processes. We then extend this analytic treatment to general deep neural operators—specifically, graph neural operators—using approximate methods from Bayesian deep learning, enabling them to incorporate uncertainty quantification. As a result, our approach is able to identify cases, and provide structured uncertainty estimates, where the neural operator fails to predict well.},
  archive      = {J_TMLR},
  author       = {Emilia Magnani and Nicholas Krämer and Runa Eschenhagen and Lorenzo Rosasco and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximate bayesian neural operators: Uncertainty quantification for parametric PDEs},
  url          = {https://openreview.net/forum?id=6WvIkYsMA8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding emergent in-context learning from a kernel regression perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6rD50Q6yYz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have initiated a paradigm shift in transfer learning. In contrast to the classic pretraining-then-finetuning procedure, in order to use LLMs for downstream prediction tasks, one only needs to provide a few demonstrations, known as in-context examples, without adding more or updating existing model parameters. This in-context learning (ICL) capability of LLMs is intriguing, and it is not yet fully understood how pretrained LLMs acquire such capabilities. In this paper, we investigate the reason why a transformer-based language model can accomplish in-context learning after pre-training on a general language corpus by proposing a kernel-regression perspective of understanding LLMs' ICL behaviors when faced with in-context examples. More concretely, we first prove that Bayesian inference on in-context prompts can be asymptotically understood as kernel regression $\hat y = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$ as the number of in-context demonstrations grows. Then, we empirically investigate the in-context behaviors of language models. We find that during ICL, the attention and hidden features in LLMs match the behaviors of a kernel regression. Finally, our theory provides insights into multiple phenomena observed in the ICL field: why retrieving demonstrative samples similar to test samples can help, why ICL performance is sensitive to the output formats, and why ICL accuracy benefits from selecting in-distribution and representative samples.},
  archive      = {J_TMLR},
  author       = {Chi Han and Ziqi Wang and Han Zhao and Heng Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding emergent in-context learning from a kernel regression perspective},
  url          = {https://openreview.net/forum?id=6rD50Q6yYz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-asynchronous local SGD: Robust and efficient data-parallel training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8VTrvS5vN7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following AI scaling trends, frontier models continue to grow in size and continue to be trained on larger datasets. Training these models requires huge investments in exascale computational resources, which has in turn driven developtment of distributed deep learning methods. Data parallelism is an essential approach to speed up training, but it requires frequent global communication between workers, which can bottleneck training at the largest scales. In this work, we propose a method called Pseudo-Asynchronous Local SGD (PALSGD) to improve the efficiency of data-parallel training. PALSGD is an extension of Local SGD (Stich, 2018) and DiLoCo (Douillard et al., 2023), designed to further reduce communication frequency by introducing a pseudo-synchronization mechanism. PALSGD allows the use of longer synchronization intervals compared to standard Local SGD. Despite the reduced communication frequency, the pseudo-synchronization approach ensures that model consistency is maintained, leading to performance results comparable to those achieved with more frequent synchronization. Furthermore, we provide a theoretical analysis of PALSGD, establishing its convergence and deriving its convergence rate. This analysis offers insights into the algorithm's behavior and performance guarantees. We evaluated PALSGD on image classification and language modeling tasks. Our results show that PALSGD achieves better performance in less time compared to existing methods like Distributed Data Parallel (DDP), and DiLoCo. Notably, PALSGD trains 18.4% faster than DDP on ImageNet-1K with ResNet-50, 24.4% faster than DDP on TinyStories with GPT-Neo-125M, and 21.1% faster than DDP on TinyStories with GPT-Neo-8M.},
  archive      = {J_TMLR},
  author       = {Hiroki Naganuma and Xinzhi Zhang and Man-Chung Yue and Ioannis Mitliagkas and Russell J. Hewett and Philipp Andre Witte and Yin Tat Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pseudo-asynchronous local SGD: Robust and efficient data-parallel training},
  url          = {https://openreview.net/forum?id=8VTrvS5vN7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural causal circuits: Probabilistic circuits climbing all rungs of pearl's ladder of causation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=25XyUTICdZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and vastness of our world can require large models with numerous variables. Unfortunately, coming up with a model that is both accurate and able to provide predictions in a reasonable amount of time can prove difficult. One possibility to help overcome such problems is sum-product networks (SPNs), probabilistic models with the ability to tractably perform inference in linear time. In this paper, we extend SPNs' capabilities to the field of causality and introduce the family of structural causal circuits (SCCs), a type of SPNs capable of answering causal questions. Starting from conventional SPNs, we ``climb the ladder of causation'' and show how SCCs can represent not only observational but also interventional and counterfactual problems. We demonstrate successful application in different settings, ranging from simple binary variables to physics-based simulations.},
  archive      = {J_TMLR},
  author       = {Florian Peter Busch and Moritz Willig and Matej Zečević and Kristian Kersting and Devendra Singh Dhami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Structural causal circuits: Probabilistic circuits climbing all rungs of pearl's ladder of causation},
  url          = {https://openreview.net/forum?id=25XyUTICdZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open problems in mechanistic interpretability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=91H76m9Z94'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.},
  archive      = {J_TMLR},
  author       = {Lee Sharkey and Bilal Chughtai and Joshua Batson and Jack Lindsey and Jeffrey Wu and Lucius Bushnaq and Nicholas Goldowsky-Dill and Stefan Heimersheim and Alejandro Ortega and Joseph Isaac Bloom and Stella Biderman and Adrià Garriga-Alonso and Arthur Conmy and Neel Nanda and Jessica Mary Rumbelow and Martin Wattenberg and Nandi Schoots and Joseph Miller and William Saunders and Eric J Michaud and Stephen Casper and Max Tegmark and David Bau and Eric Todd and Atticus Geiger and Mor Geva and Jesse Hoogland and Daniel Murfet and Thomas McGrath},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Open problems in mechanistic interpretability},
  url          = {https://openreview.net/forum?id=91H76m9Z94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model guidance via robust feature attribution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AVAHxDSqUu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the patterns a model learns is essential to preventing reliance on irrelevant or misleading features. Such reliance on irrelevant features, often called shortcut features, has been observed across domains, including medical imaging and natural language processing, where it may lead to real-world harms. A common mitigation strategy leverages annotations (provided by humans or machines) indicating which features are relevant or irrelevant. These annotations are compared to model explanations, typically in the form of feature salience, and used to guide the loss function during training. Unfortunately, recent works have demonstrated that feature salience methods are unreliable and therefore offer a poor signal to optimize. In this work, we propose a simplified objective that simultaneously optimizes for explanation robustness and mitigation of shortcut learning. Unlike prior objectives with similar aims, we demonstrate theoretically why our approach ought to be more effective. Across a comprehensive series of experiments, we show that our approach consistently reduces test-time misclassifications by 20\% compared to state-of-the-art methods. We also extend prior experimental settings to include natural language processing tasks. Additionally, we conduct novel ablations that yield practical insights, including the relative importance of annotation quality over quantity. Code for our method and experiments is available at: https://github.com/Mihneaghitu/ModelGuidanceViaRobustFeatureAttribution.},
  archive      = {J_TMLR},
  author       = {Mihnea Ghitu and Vihari Piratla and Matthew Robert Wicker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Model guidance via robust feature attribution},
  url          = {https://openreview.net/forum?id=AVAHxDSqUu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two is better than one: Aligned representation pairs for anomaly detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Bt0zdsnWYc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection focuses on identifying samples that deviate from the norm. Discovering informative representations of normal samples is crucial to detecting anomalies effectively. Recent self-supervised methods have successfully learned such representations by employing prior knowledge about anomalies to create synthetic outliers during training. However, we often do not know what to expect from unseen data in specialized real-world applications. In this work, we address this limitation with our new approach, Con2, which leverages prior knowledge about symmetries in normal samples to observe the data in different contexts. Con2 consists of two parts: Context Contrasting clusters representations according to their context, while Content Alignment encourages the model to capture semantic information by aligning the positions of normal samples across clusters. The resulting representation space allows us to detect anomalies as outliers of the learned context clusters. We demonstrate the benefit of this approach in extensive experiments on specialized medical datasets, outperforming competitive baselines based on self-supervised learning and pretrained models and presenting competitive performance on natural imaging benchmarks.},
  archive      = {J_TMLR},
  author       = {Alain Ryser and Thomas M. Sutter and Alexander Marx and Julia E Vogt},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Two is better than one: Aligned representation pairs for anomaly detection},
  url          = {https://openreview.net/forum?id=Bt0zdsnWYc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling multiple descents in unsupervised autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FqfHDs6unx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of double descent has challenged the traditional bias-variance trade-off in supervised learning but remains unexplored in unsupervised learning, with some studies arguing for its absence. In this study, we first demonstrate analytically that double descent does not occur in linear unsupervised autoencoders (AEs). In contrast, we show for the first time that both double and triple descent can be observed with nonlinear AEs across various data models and architectural designs. We examine the effects of partial sample and feature noise and highlight the critical role of bottleneck size in shaping the double descent curve. Through extensive experiments on both synthetic and real datasets, we uncover model-wise, epoch-wise, and sample-wise double descent across several data types and architectures. Our findings indicate that over-parameterized models not only improve reconstruction but also enhance performance in downstream tasks such as anomaly detection and domain adaptation, highlighting their practical value in complex real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Kobi Rahimi and Yehonathan Refael and Tom Tirer and Ofir Lindenbaum},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unveiling multiple descents in unsupervised autoencoders},
  url          = {https://openreview.net/forum?id=FqfHDs6unx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifi3D: A study on 3D representations for generation and reconstruction in a common framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GQpTWpXILA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following rapid advancements in text and image generation, research has increasingly shifted towards 3D generation. Unlike the well-established pixel-based representation in images, 3D representations remain diverse and fragmented, encompassing a wide variety of approaches such as voxel grids, neural radiance fields, signed distance functions, point clouds, or octrees, each offering distinct advantages and limitations. In this work, we present a unified evaluation framework designed to assess the performance of 3D representations in reconstruction and generation. We compare these representations based on multiple criteria: quality, computational efficiency, and generalization performance. Beyond standard model benchmarking, our experiments aim to derive best practices over all steps involved in the 3D generation pipeline, including preprocessing, mesh reconstruction, compression with autoencoders, and generation. Our findings highlight that reconstruction errors significantly impact overall performance, underscoring the need to evaluate generation and reconstruction jointly. We provide insights that can inform the selection of suitable 3D models for various applications, facilitating the development of more robust and application-specific solutions in 3D generation. The code for our framework is available at https://github.com/isl-org/unifi3d.},
  archive      = {J_TMLR},
  author       = {Nina Wiedemann and Sainan Liu and Quentin Leboutet and Katelyn Gao and Benjamin Ummenhofer and Michael Paulitsch and Kai Yuan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unifi3D: A study on 3D representations for generation and reconstruction in a common framework},
  url          = {https://openreview.net/forum?id=GQpTWpXILA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-1-to-G: Taming pretrained 2D diffusion model for direct 3D generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GVizav9Zf8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in 2D image generation have achieved remarkable quality, largely driven by the capacity of diffusion models and the availability of large-scale datasets. However, direct 3D generation is still constrained by the scarcity and lower fidelity of 3D datasets. In this paper, we introduce Zero-1-to-G, a novel approach that addresses this problem by enabling direct single-view generation on Gaussian splats using pretrained 2D diffusion models. Our key insight is that Gaussian splats, a 3D representation, can be decomposed into multi-view images encoding different attributes. This reframes the challenging task of direct 3D generation within a 2D diffusion framework, allowing us to leverage the rich priors of pretrained 2D diffusion models. To incorporate 3D awareness, we introduce cross-view and cross-attribute attention layers, which capture complex correlations and enforce 3D consistency across generated splats. This makes Zero-1-to-G the first direct image-to-3D generative model to effectively utilize pretrained 2D diffusion priors, enabling efficient training and improved generalization to unseen objects. Extensive experiments on both synthetic and in-the-wild datasets demonstrate superior performance in 3D object generation, offering a new approach to high-quality 3D generation.},
  archive      = {J_TMLR},
  author       = {Xuyi Meng and Chen Wang and Jiahui Lei and Kostas Daniilidis and Jiatao Gu and Lingjie Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Zero-1-to-G: Taming pretrained 2D diffusion model for direct 3D generation},
  url          = {https://openreview.net/forum?id=GVizav9Zf8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low compute unlearning via sparse representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GyKXzmk43s'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning, which involves erasing knowledge about a \emph{forget set} from a trained model, can prove to be costly and infeasible using existing techniques. We propose a low-compute unlearning technique based on a discrete representational bottleneck. We show that the proposed technique efficiently unlearns the forget set and incurs negligible damage to the model's performance on the rest of the dataset. We evaluate the proposed technique on the problem of class unlearning using four datasets: CIFAR-10, CIFAR-100, LACUNA-100 and ImageNet-1k. We compare the proposed technique to SCRUB, a state-of-the-art approach which uses knowledge distillation for unlearning. Across all four datasets, the proposed technique performs as well as, if not better than SCRUB while incurring almost no computational cost.},
  archive      = {J_TMLR},
  author       = {Vedant Shah and Frederik Träuble and Ashish Malik and Hugo Larochelle and Michael Curtis Mozer and Sanjeev Arora and Yoshua Bengio and Anirudh Goyal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Low compute unlearning via sparse representations},
  url          = {https://openreview.net/forum?id=GyKXzmk43s},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRDT3: Diffusion-refined decision test-time training model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=I6zjLhIzgh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision Transformer (DT), a trajectory modelling method, has shown competitive performance compared to traditional offline reinforcement learning (RL) approaches on various classic control tasks. However, it struggles to learn optimal policies from suboptimal, reward-labelled trajectories. In this study, we explore the use of conditional generative modelling to facilitate trajectory stitching given its high-quality data generation ability. Additionally, recent advancements in Recurrent Neural Networks (RNNs) have shown their linear complexity and competitive sequence modelling performance over Transformers. We leverage the Test-Time Training (TTT) layer, an RNN that updates hidden states during testing, to model trajectories in the form of DT. We introduce a unified framework, called Diffusion-Refined Decision TTT (DRDT3), to achieve performance beyond DT models. Specifically, we propose the Decision TTT (DT3) module, which harnesses the sequence modelling strengths of both self-attention and the TTT layer to capture recent contextual information and make coarse action predictions. DRDT3 iteratively refines the coarse action predictions through the generative diffusion model, progressively moving closer to the optimal actions. We further integrate DT3 with the diffusion model using a unified optimization objective. With experiments on multiple tasks in the D4RL benchmark, our DT3 model without diffusion refinement demonstrates improved performance over standard DT, while DRDT3 further achieves superior results compared to state-of-the-art DT-based and offline RL methods.},
  archive      = {J_TMLR},
  author       = {Xingshuai Huang and Di Wu and Benoit Boulet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DRDT3: Diffusion-refined decision test-time training model},
  url          = {https://openreview.net/forum?id=I6zjLhIzgh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification in retrieval augmented question answering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JLkgI0h7wy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval augmented Question Answering (QA) helps QA models overcome knowledge gaps by incorporating retrieved evidence, typically a set of passages, alongside the question at test time. Previous studies show that this approach improves QA performance and reduces hallucinations, without, however, assessing whether the retrieved passages are indeed useful at answering correctly. In this work, we propose to quantify the uncertainty of a QA model via estimating the utility of the passages it is provided with. We train a lightweight neural model to predict passage utility for a target QA model and show that while simple information theoretic metrics can predict answer correctness up to a certain extent, our approach efficiently approximates or outperforms more expensive sampling-based methods.},
  archive      = {J_TMLR},
  author       = {Laura Perez-Beltrachini and Mirella Lapata},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty quantification in retrieval augmented question answering},
  url          = {https://openreview.net/forum?id=JLkgI0h7wy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Amdahl’s law for LLMs: A throughput-centric analysis of extreme LLM quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JtrQJJQYpP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of 1-bit large language models (LLMs) has sparked significant interest, promising substantial efficiency gains through extreme quantization. However, these benefits are inherently limited by the portion of the model that can be quantized. Specifically, 1-bit quantization typically targets only the projection layers, while the attention mechanisms remain in higher precision, potentially creating significant throughput bottlenecks. To address this, we present an adaptation of Amdahl's Law specifically tailored to the LLMs, offering a quantitative framework for understanding the throughput limits of extreme quantization. Our analysis reveals how improvements in quantization can deliver substantial throughput gains, but only to the extent that they address critical throughput-constrained sections of the model. Through extensive experiments across diverse model architectures and hardware platforms, we highlight key trade-offs and performance ceilings, providing a roadmap for future research aimed at maximizing LLM throughput through more holistic quantization strategies.},
  archive      = {J_TMLR},
  author       = {Jinendra Malekar and Ramtin Zand},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Amdahl’s law for LLMs: A throughput-centric analysis of extreme LLM quantization},
  url          = {https://openreview.net/forum?id=JtrQJJQYpP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous imagination: Closed-loop decomposition of visual-to-textual conversion in visual reasoning for multimodal large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MI4yIBLprs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under pure textual modality, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning tasks by decomposing them into simpler sub-problems. However, Multimodal Large Language Models (MLLMs) still struggle with some seemingly straightforward visual tasks, such as counting and solving jigsaw puzzles. We argue that these tasks challenge the ability of {\it visual-to-textual conversion}, where MLLMs convert visual information perceived from the input scene, to textual information for further reasoning and generating the answer. If the complexity of the visual input is beyond the perceptual capability of the MLLMs, without decomposing this conversion process, simply scaling inference-time reasoning cannot solve the task because it repeatedly encounters the same perceptual bottleneck. We propose an approach, {\it autonomous imagination}, to enable MLLMs to iteratively modify visual inputs (e.g. isolating objects, rearranging puzzle pieces) into intermediate visual states, decomposing visual-to-textual conversion into closed-loop visual modification steps. We show that, without any retraining, MLLMs can now solve tasks initially beyond their perceptual capability, highlighting that closed-loop visual modification can be an effective way of decomposing the visual reasoning task into solvable substeps. Our code and data are released at https://future-item.github.io/autoimagine-site/.},
  archive      = {J_TMLR},
  author       = {Jingming Liu and Yumeng Li and Boyuan Xiao and Yichang Jian and Ziang Qin and Tianjia Shao and Yao-Xiang Ding and Kun Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Autonomous imagination: Closed-loop decomposition of visual-to-textual conversion in visual reasoning for multimodal large language models},
  url          = {https://openreview.net/forum?id=MI4yIBLprs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A noise-corrected langevin algorithm and sampling by half-denoising. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QGtXn5GtfK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Langevin algorithm is a classic method for sampling from a given pdf in a real space. In its basic version, it only requires knowledge of the gradient of the log-density, also called the score function. However, in deep learning, it is often easier to learn the so-called "noisy-data score function", i.e. the gradient of the log-density of noisy data, more precisely when Gaussian noise is added to the data. Such an estimate is biased and complicates the use of the Langevin method. Here, we propose a noise-corrected version of the Langevin algorithm, where the bias due to noisy data is removed, at least regarding first-order terms. Unlike diffusion models, our algorithm only needs to know the noisy-data score function for one single noise level. We further propose a simple special case which has an interesting intuitive interpretation of iteratively adding noise the data and then attempting to remove half of that noise.},
  archive      = {J_TMLR},
  author       = {Aapo Hyvarinen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A noise-corrected langevin algorithm and sampling by half-denoising},
  url          = {https://openreview.net/forum?id=QGtXn5GtfK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RouteFinder: Towards foundation models for vehicle routing problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QzGLoaOPiY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces RouteFinder, a comprehensive foundation model framework to tackle different Vehicle Routing Problem (VRP) variants. Our core idea is that a foundation model for VRPs should be able to represent variants by treating each as a subset of a generalized problem equipped with different attributes. We propose a unified VRP environment capable of efficiently handling any combination of these attributes. The RouteFinder model leverages a modern transformer-based encoder and global attribute embeddings to improve task representation. Additionally, we introduce two reinforcement learning techniques to enhance multi-task performance: mixed batch training, which enables training on different variants at once, and multi-variant reward normalization to balance different reward scales. Finally, we propose efficient adapter layers that enable fine-tuning for new variants with unseen attributes. Extensive experiments on 48 VRP variants show RouteFinder outperforms recent state-of-the-art learning methods. Our code is publicly available at https://github.com/ai4co/routefinder.},
  archive      = {J_TMLR},
  author       = {Federico Berto and Chuanbo Hua and Nayeli Gast Zepeda and André Hottung and Niels Wouda and Leon Lan and Junyoung Park and Kevin Tierney and Jinkyoo Park},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RouteFinder: Towards foundation models for vehicle routing problems},
  url          = {https://openreview.net/forum?id=QzGLoaOPiY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M4GN: Mesh-based multi-segment hierarchical graph network for dynamic simulations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=R3vDbqWa1v'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mesh-based graph neural networks (GNNs) have become effective surrogates for PDE simulations, yet their deep message passing incurs high cost and over‑smoothing on large, long‑range meshes; hierarchical GNNs shorten propagation paths but still face two key obstacles: (i) building coarse graphs that respect mesh topology, geometry, and physical discontinuities, and (ii) maintaining fine-scale accuracy without sacrificing the speed gained from coarsening. We tackle these challenges with M4GN—a three‑tier, segment‑centric hierarchical network. M4GN begins with a hybrid segmentation strategy that pairs a fast graph partitioner with a superpixel‑style refinement guided by modal‑decomposition features, producing contiguous segments of dynamically consistent nodes. These segments are encoded by a permutation‑invariant aggregator, avoiding the order sensitivity and quadratic cost of aggregation approaches used in prior works. The resulting information bridges a micro‑level GNN—which captures local dynamics—and a macro‑level transformer that reasons efficiently across segments, achieving a principled balance between accuracy and efficiency. Evaluated on multiple representative benchmark datasets, M4GN improves prediction accuracy by up to 56\% while achieving up to 22\% faster inference than state‑of‑the‑art baselines.},
  archive      = {J_TMLR},
  author       = {Bo Lei and Victor M Castillo and Yeping Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {M4GN: Mesh-based multi-segment hierarchical graph network for dynamic simulations},
  url          = {https://openreview.net/forum?id=R3vDbqWa1v},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoNNect: Connectivity-based regularization for structural pruning of neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RIZCe7BuEp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning encompasses a range of techniques aimed at increasing the sparsity of neural networks (NNs). These techniques can generally be framed as minimizing a loss function subject to an $L_0$ norm constraint. This paper introduces CoNNect, a novel differentiable regularizer for sparse NN training that ensures connectivity between input and output layers. We prove that CoNNect approximates $L_0$ regularization, while preserving essential network structure and preventing the emergence of fragmented or poorly connected subnetworks. Moreover, CoNNect is easily integrated within established structural pruning strategies. Numerical experiments demonstrate that CoNNect can improve classical pruning strategies and enhance state-of-the-art one-shot pruners, such as DepGraph and LLM-pruner.},
  archive      = {J_TMLR},
  author       = {Christian P.C. Franssen and Jinyang Jiang and Yijie Peng and Bernd Heidergott},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CoNNect: Connectivity-based regularization for structural pruning of neural networks},
  url          = {https://openreview.net/forum?id=RIZCe7BuEp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to rank with top-$K$ fairness. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SSPCc39XvO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness in ranking models is crucial, as disparities in exposure can disproportionately affect protected groups. Most fairness-aware ranking systems focus on ensuring comparable average exposure for groups across the entire ranked list, which may not fully address real-world concerns. For example, when a ranking model is used for allocating resources among candidates or disaster hotspots, decision-makers often prioritize only the top-$K$ ranked items, while the ranking beyond top-$K$ becomes less relevant. In this paper, we propose a list-wise learning-to-rank framework that addresses the issues of inequalities in top-$K$ rankings at training time. Specifically, we propose a top-$K$ exposure disparity measure that extends the classic exposure disparity metric in a ranked list. We then learn a ranker to balance relevance and fairness in top-$K$ rankings. Since direct top-$K$ selection is computationally expensive for a large number of items, we transform the non-differentiable selection process into a differentiable objective function and develop efficient stochastic optimization algorithms to achieve both high accuracy and sufficient fairness. Extensive experiments demonstrate that our method outperforms existing methods.},
  archive      = {J_TMLR},
  author       = {Boyang Zhang and Quanqi Hu and Mingxuan Sun and Qihang Lin and Tianbao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning to rank with top-$K$ fairness},
  url          = {https://openreview.net/forum?id=SSPCc39XvO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution augmentation for ARC problems using GFlowNet: A probabilistic exploration approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ULCOhBgGzy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the core challenges in building general reasoning systems lies in generating diverse, human-aligned solution trajectories—different yet valid paths by which a problem can be solved. Prior approaches often rely on handcrafted templates, rule-based augmentations, or human demonstrations, which are limited in scalability and stylistic diversity. To address this, we explore the use of Generative Flow Networks (GFlowNets) for automated solution augmentation in reasoning tasks. We propose a framework that learns to generate diverse reasoning trajectories with probabilities proportional to their quality, guided by a human-inspired reward function and a novel geometric forward policy. This enables the generation of multiple plausible solution paths without relying on manual supervision. Moreover, our method supports efficient test-time augmentation from input-output examples alone, without access to ground-truth programs or external demonstrations—making it suitable for zero-shot settings. We evaluate our framework on the Abstraction and Reasoning Corpus (ARC-AGI), a benchmark designed to test compositional and abstract reasoning. Our results show that GFlowNets can effectively explore the space of valid reasoning processes, producing a variety of plausible reasoning trajectories, similar to how different individuals might solve the same problem using different intermediate steps. These trajectories are generated at scale-over 100k per task in under an hour, and follow a logarithmic yield trend, enabling practical tradeoffs between augmentation volume and novelty. Furthermore, fine-tuning a large language model (LLaMA 3.1 Instruct 8B) on these synthetic trajectories leads to a 28.6% improvement in reasoning accuracy on ARC tasks, demonstrating the downstream utility of our method. These findings suggest that GFlowNets offer a promising foundation for modeling structured reasoning in automated trajectory generation. Our code is here: https://github.com/GIST-DSLab/GFN_to_ARC},
  archive      = {J_TMLR},
  author       = {Sanha Hwang and Seungpil Lee and Sejin Kim and Sundong Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solution augmentation for ARC problems using GFlowNet: A probabilistic exploration approach},
  url          = {https://openreview.net/forum?id=ULCOhBgGzy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wolf: Dense video captioning with a world summarization framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Z1dH7hao7p'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Wolf, a WOrLd summarization Framework for accurate video captioning. Wolf is an automated captioning framework that adopts a mixture-of-experts approach, leveraging complementary strengths of Vision Language Models (VLMs). By utilizing both image and video models, our framework captures different levels of information and summarizes them efficiently. Our approach can be applied to enhance video understanding, auto-labeling, and captioning. To evaluate caption quality, we introduce CapScore, an LLM-based metric to assess the similarity and quality of generated captions compared to the ground truth captions. We further build four human-annotated datasets in three domains: autonomous driving, general scenes, and robotics, to facilitate comprehensive comparisons. We show that Wolf achieves superior captioning performance compared to state-of-the-art approaches from the research community (VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For instance, in comparison with GPT-4V, Wolf improves CapScore (caption quality) by 55.6% and CapScore (caption similarity) by 77.4% on challenging driving videos. Finally, we establish a benchmark for video captioning and introduce a leaderboard, aiming to accelerate advancements in video understanding, captioning, and data alignment.},
  archive      = {J_TMLR},
  author       = {Boyi Li and Ligeng Zhu and Ran Tian and Shuhan Tan and Yuxiao Chen and Yao Lu and Yin Cui and Sushant Veer and Max Ehrlich and Jonah Philion and Xinshuo Weng and Fuzhao Xue and Linxi Fan and Yuke Zhu and Jan Kautz and Andrew Tao and Ming-Yu Liu and Sanja Fidler and Boris Ivanovic and Trevor Darrell and Jitendra Malik and Song Han and Marco Pavone},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wolf: Dense video captioning with a world summarization framework},
  url          = {https://openreview.net/forum?id=Z1dH7hao7p},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeedleBench: Evaluating LLM retrieval and reasoning across varying information densities. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cEvmIKsRw0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of large language models to handle long-context information plays a crucial role across various real-world applications. Existing methods for evaluating long-context abilities often rely either on real-world long texts, making it difficult to exclude the influence of models' inherent knowledge, or introduce large amounts of irrelevant filler content to artificially reach target lengths, reducing the relevance and effectiveness of assessments. To address these limitations, we introduce NeedleBench, a comprehensive synthetic framework designed to assess retrieval and reasoning performance in bilingual long-context tasks with adaptive context lengths (e.g., 32k, 128k, and beyond). NeedleBench systematically embeds key data points at varying depths to rigorously test models' capabilities in diverse settings. Tasks within NeedleBench are categorized into two distinct scenarios: information-sparse, characterized by minimal relevant details embedded within extensive irrelevant text to simulate simpler real-world retrieval tasks; and information-dense, implemented as the Ancestral Trace Challenge, where relevant information is continuously distributed throughout the context to simulate more complex real-world reasoning tasks. Our experiments show that, while recent reasoning models such as Deepseek-R1 and OpenAI's o3 have demonstrated strong performance on mathematical reasoning benchmarks, they still struggle to generalize their reasoning abilities and perform poorly on our information-dense tasks, frequently encountering difficulties with continuous retrieval and reasoning even at relatively shorter context lengths.Furthermore, we identify and characterize a phenomenon termed `under-thinking', wherein models prematurely conclude their reasoning processes despite the availability of relevant information. NeedleBench thus provides critical insights and targeted evaluation tools essential for understanding and improving the long-context capabilities of LLMs. All codes and resources are publicly available at https://github.com/open-compass/opencompass.},
  archive      = {J_TMLR},
  author       = {Mo Li and Songyang Zhang and Taolin Zhang and Haodong Duan and Yunxin Liu and Kai Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NeedleBench: Evaluating LLM retrieval and reasoning across varying information densities},
  url          = {https://openreview.net/forum?id=cEvmIKsRw0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaGFN: Exploring distant modes with adapted metadynamics for continuous GFlowNets. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dtyNeemB7A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Flow Networks (GFlowNets) are a class of generative models that sample objects in proportion to a specified reward function through a learned policy. They can be trained either on-policy or off-policy, needing a balance between exploration and exploitation for fast convergence to a target distribution. While exploration strategies for discrete GFlowNets have been studied, exploration in the continuous case remains to be investigated, despite the potential for novel exploration algorithms due to the local connectedness of continuous domains. Here, we introduce Adapted Metadynamics, a variant of metadynamics that can be applied to arbitrary black-box reward functions on continuous domains. We use Adapted Metadynamics as an exploration strategy for continuous GFlowNets. We show several continuous domains where the resulting algorithm, MetaGFN, accelerates convergence to the target distribution and discovers more distant reward modes than previous off-policy exploration strategies used for training GFlowNets.},
  archive      = {J_TMLR},
  author       = {Dominic Phillips and Flaviu Cipcigan},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MetaGFN: Exploring distant modes with adapted metadynamics for continuous GFlowNets},
  url          = {https://openreview.net/forum?id=dtyNeemB7A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplifying knowledge transfer in pretrained models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eQ9AVtDaP3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained models are ubiquitous in the current deep learning landscape, offering strong results on a broad range of tasks. Recent works have shown that models differing in various design choices exhibit categorically diverse generalization behavior, resulting in one model grasping distinct data-specific insights unavailable to the other. In this paper, we propose to leverage large publicly available model repositories as an auxiliary source of model improvements. We introduce a data partitioning strategy where pretrained models autonomously adopt either the role of a student, seeking knowledge, or that of a teacher, imparting knowledge. Experiments across various tasks demonstrate the effectiveness of our proposed approach. In image classification, we improved the performance of ViT-B by approximately 1.4\% through bidirectional knowledge transfer with ViT-T. For semantic segmentation, our method boosted all evaluation metrics by enabling knowledge transfer both within and across backbone architectures. In video saliency prediction, our approach achieved a new state-of-the-art. We further extend our approach to knowledge transfer between multiple models, leading to considerable performance improvements for all model participants.},
  archive      = {J_TMLR},
  author       = {Siddharth Jain and Shyamgopal Karthik and Vineet Gandhi},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simplifying knowledge transfer in pretrained models},
  url          = {https://openreview.net/forum?id=eQ9AVtDaP3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hallucination detection on a budget: Efficient bayesian estimation of semantic entropy. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=j2N2RuNdbC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting whether an LLM hallucinates is an important research challenge. One promising way of doing so is to estimate the semantic entropy (Farquhar et al., 2024) of the distribution of generated sequences. We propose a new algorithm for doing that, with two main advantages. First, due to us taking the Bayesian approach, we achieve a much better quality of semantic entropy estimates for a given budget of samples from the LLM. Second, we are able to tune the number of samples adaptively so that `harder' contexts receive more samples. We demonstrate empirically that our approach systematically beats the baselines, requiring only 53% of samples used by Farquhar et al. (2024) to achieve the same quality of hallucination detection as measured by AUROC. Moreover, quite counterintuitively, our estimator is useful even with just one sample from the LLM.},
  archive      = {J_TMLR},
  author       = {Kamil Ciosek and Nicolò Felicioni and Sina Ghiassian},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hallucination detection on a budget: Efficient bayesian estimation of semantic entropy},
  url          = {https://openreview.net/forum?id=j2N2RuNdbC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing vision backbones for dense prediction with dense attentive probing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=neMAx4uBlh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm of pretraining a backbone on a large set of (often unlabeled) images has gained popularity. The quality of the resulting features is commonly measured by freezing the backbone and training different task heads on top of it. However, current evaluations cover only classifications of whole images or require complex dense task heads which introduce a large number of parameters and add their own inductive biases. In this work, we propose dense attentive probing, a parameter-efficient readout method for dense prediction on arbitrary backbones – independent of the size and resolution of their feature volume. To this end, we extend cross-attention with distance-based masks of learnable sizes. We employ this method to evaluate 18 common backbones on dense predictions tasks in three dimensions: instance awareness, local semantics and spatial understanding. We find that DINOv2 outperforms all other backbones tested – including those supervised with masks and language – across all three task categories. Furthermore, our analysis suggests that self-supervised pretraining tends to yield features that separate object instances better than vision-language models. Code is available at http://eckerlab.org/code/deap.},
  archive      = {J_TMLR},
  author       = {Timo Lüddecke and Alexander S. Ecker},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Characterizing vision backbones for dense prediction with dense attentive probing},
  url          = {https://openreview.net/forum?id=neMAx4uBlh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global optimization algorithm through high-resolution sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=r3VEA1AWY5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose said global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.},
  archive      = {J_TMLR},
  author       = {Daniel Cortild and Claire Delplancke and Nadia Oudjane and Juan Peypouquet},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global optimization algorithm through high-resolution sampling},
  url          = {https://openreview.net/forum?id=r3VEA1AWY5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mutual information perspective on multiple latent variable generative models for positive view generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uaj8ZL2PtK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image generation, Multiple Latent Variable Generative Models (MLVGMs) employ multiple latent variables to gradually shape the final images, from global characteristics to finer and local details (e.g., StyleGAN, NVAE), emerging as powerful tools for diverse applications. Yet their generative dynamics remain only empirically observed, without a systematic understanding of each latent variable's impact. In this work, we propose a novel framework that quantifies the contribution of each latent variable using Mutual Information (MI) as a metric. Our analysis reveals that current MLVGMs often underutilize some latent variables, and provides actionable insights for their use in downstream applications. With this foundation, we introduce a method for generating synthetic data for Self-Supervised Contrastive Representation Learning (SSCRL). By leveraging the hierarchical and disentangled variables of MLVGMs, our approach produces diverse and semantically meaningful views without the need for real image data. Additionally, we introduce a Continuous Sampling (CS) strategy, where the generator dynamically creates new samples during SSCRL training, greatly increasing data variability. Our comprehensive experiments demonstrate the effectiveness of these contributions, showing that MLVGMs' generated views compete on par with or even surpass views generated from real data. This work establishes a principled approach to understanding and exploiting MLVGMs, advancing both generative modeling and self-supervised learning. Code and pre-trained models at: https://github.com/SerezD/mi_ml_gen},
  archive      = {J_TMLR},
  author       = {Dario Serez and Marco Cristani and Alessio Del Bue and Vittorio Murino and Pietro Morerio},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A mutual information perspective on multiple latent variable generative models for positive view generation},
  url          = {https://openreview.net/forum?id=uaj8ZL2PtK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond instance consistency: Investigating view diversity in self-supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=urWCU3YMA0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) conventionally relies on the instance consistency paradigm, assuming that different views of the same image can be treated as positive pairs. However, this assumption breaks down for non-iconic data, where different views may contain distinct objects or semantic information. In this paper, we investigate the effectiveness of SSL when instance consistency is not guaranteed. Through extensive ablation studies, we demonstrate that SSL can still learn meaningful representations even when positive pairs lack strict instance consistency. Furthermore, our analysis further reveals that increasing view diversity, by enforcing zero overlapping or using smaller crop scales, can enhance downstream performance on classification and dense prediction tasks. However, excessive diversity is found to reduce effectiveness, suggesting an optimal range for view diversity. To quantify this, we adopt the Earth Mover’s Distance (EMD) as an estimator to measure mutual information between views, finding that moderate EMD values correlate with improved SSL learning, providing insights for future SSL framework design. We validate our findings across a range of settings, highlighting their robustness and applicability on diverse data sources.},
  archive      = {J_TMLR},
  author       = {Huaiyuan Qin and Muli Yang and Siyuan Hu and Peng Hu and Yu Zhang and Chen Gong and Hongyuan Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond instance consistency: Investigating view diversity in self-supervised learning},
  url          = {https://openreview.net/forum?id=urWCU3YMA0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein convergence of score-based generative models under semiconvexity and discontinuous gradients. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vS9iVRB7XF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based Generative Models (SGMs) approximate a data distribution by perturbing it with Gaussian noise and subsequently denoising it via a learned reverse diffusion process. These models excel at modeling complex data distributions and generating diverse samples, achieving state-of-the-art performance across domains such as computer vision, audio generation, reinforcement learning, and computational biology. Despite their empirical success, existing Wasserstein-2 convergence analysis typically assume strong regularity conditions--such as smoothness or strict log-concavity of the data distribution--that are rarely satisfied in practice. In this work, we establish the first non-asymptotic Wasserstein-2 convergence guarantees for SGMs targeting semiconvex distributions with potentially discontinuous gradients. Our upper bounds are explicit and sharp in key parameters, achieving optimal dependence of $O(\sqrt{d})$ on the data dimension $d$ and convergence rate of order one. The framework accommodates a wide class of practically relevant distributions, including symmetric modified half-normal distributions, Gaussian mixtures, double-well potentials, and elastic net potentials. By leveraging semiconvexity without requiring smoothness assumptions on the potential such as differentiability, our results substantially broaden the theoretical foundations of SGMs, bridging the gap between empirical success and rigorous guarantees in non-smooth, complex data regimes.},
  archive      = {J_TMLR},
  author       = {Stefano Bruno and Sotirios Sabanis},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wasserstein convergence of score-based generative models under semiconvexity and discontinuous gradients},
  url          = {https://openreview.net/forum?id=vS9iVRB7XF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taxonomy, opportunities, and challenges of representation engineering for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2U1KIfmaU9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation Engineering (RepE) is a novel paradigm for controlling the behavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune the model, RepE directly manipulates the model's internal representations. As a result, it may offer more effective, interpretable, data-efficient, and flexible control over models' behavior. We present the first comprehensive survey of RepE for LLMs, reviewing the rapidly growing literature to address key questions: What RepE methods exist and how do they differ? For what concepts and problems has RepE been applied? What are the strengths and weaknesses of RepE compared to other methods? To answer these, we propose a unified framework describing RepE as a pipeline comprising representation identification, operationalization, and control. We posit that while RepE methods offer significant potential, challenges remain, including managing multiple concepts, ensuring reliability, and preserving models' performance. Towards improving RepE, we identify opportunities for experimental and methodological improvements and construct a guide for best practices.},
  archive      = {J_TMLR},
  author       = {Jan Wehner and Sahar Abdelnabi and Daniel Chee Hian Tan and David Krueger and Mario Fritz},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Taxonomy, opportunities, and challenges of representation engineering for large language models},
  url          = {https://openreview.net/forum?id=2U1KIfmaU9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local distribution-based adaptive oversampling for imbalanced regression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6qYTR9iJdm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced regression occurs when continuous target variables have skewed distributions, creating sparse regions that are difficult for machine learning models to predict accurately. This issue particularly affects neural networks, which often struggle with imbalanced data. While class imbalance in classification has been extensively studied, imbalanced regression remains relatively unexplored, with few effective solutions. Existing approaches often rely on arbitrary thresholds to categorize samples as rare or frequent, ignoring the continuous nature of target distributions. These methods can produce synthetic samples that fail to improve model performance and may discard valuable information through undersampling. To address these limitations, we propose LDAO (Local Distribution-based Adaptive Oversampling), a novel data-level approach that avoids categorizing individual samples as rare or frequent. Instead, LDAO learns the global distribution structure by decomposing the dataset into a mixture of local distributions, each preserving its statistical characteristics. LDAO then models and samples from each local distribution independently before merging them into a balanced training set. LDAO achieves a balanced representation across the entire target range while preserving the inherent statistical structure within each local distribution. In extensive evaluations on 45 imbalanced datasets, LDAO outperforms state-of-the-art oversampling methods on both frequent and rare target values, demonstrating its effectiveness for addressing the challenge of imbalanced regression.},
  archive      = {J_TMLR},
  author       = {Shayan Alahyari and Mike Domaratzki},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Local distribution-based adaptive oversampling for imbalanced regression},
  url          = {https://openreview.net/forum?id=6qYTR9iJdm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized orders of magnitude for scalable, parallel, high-dynamic-range computation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SUuzb0SOGu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many domains, from deep learning to finance, require compounding real numbers over long sequences, often leading to catastrophic numerical underflow or overflow. We introduce generalized orders of magnitude (GOOMs), a principled extension of traditional orders of magnitude that incorporates floating-point numbers as a special case, and which in practice enables stable computation over significantly larger dynamic ranges of real numbers than previously possible. We implement GOOMs, along with an efficient custom parallel prefix scan, to support native execution on parallel hardware such as GPUs. We demonstrate that our implementation of GOOMs outperforms traditional approaches with three representative experiments, all of which were previously considered impractical or impossible, and now become possible and practical: (1) compounding real matrix products {\em far} beyond standard floating-point limits; (2) estimating spectra of Lyapunov exponents in parallel, {\em orders of magnitude faster} than with previous methods, applying a novel selective-resetting method to prevent state colinearity; and (3) capturing long-range dependencies in deep recurrent neural networks with {\em non-diagonal recurrent states, computed in parallel via a prefix scan, without requiring any form of stabilization}. Our results show that our implementation of GOOMs, combined with efficient parallel scanning, offers a scalable and numerically robust alternative to conventional floating-point numbers for high-dynamic-range applications.},
  archive      = {J_TMLR},
  author       = {Franz A. Heinsen and Leo Kozachkov},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized orders of magnitude for scalable, parallel, high-dynamic-range computation},
  url          = {https://openreview.net/forum?id=SUuzb0SOGu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMs can learn self-restraint through iterative self-reflection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SvKPfchVKX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to be deployed safely, Large Language Models (LLMs) must be capable of dynamically adapting their behavior based on their level of knowledge and uncertainty associated with specific topics. This adaptive behavior, which we refer to as self-restraint, is non-trivial to teach since it depends on the internal knowledge of an LLM. By default, LLMs are trained to maximize the next token likelihood, which does not teach the model to modulate its answer based on its level of uncertainty. In order to learn self-restraint, we devise a utility function that can encourage the model to produce responses only when its level of confidence is above a user-specified target accuracy $\rho^*$. This utility function can be used to score generation of different length and abstention. To optimize this function, we introduce ReSearch, a process of ``self-reflection'' consisting of iterative self-prompting and self-evaluation. We use the ReSearch algorithm to generate synthetic data on which we finetune our models. ReSearch elegantly incorporates the ability to abstain by augmenting the samples generated by the model during the search procedure with an answer expressing abstention. Compared to their original versions, our resulting models generate fewer hallucinations overall at no additional inference cost, for both known and unknown topics, as the model learns to selectively restrain itself. In addition, we show that our iterative search is more efficient as a function of tokens than naive search. Finally, we show that by modifying the target accuracy $\rho^*$, our trained models exhibit different behaviors.},
  archive      = {J_TMLR},
  author       = {Alexandre Piché and Aristides Milios and Dzmitry Bahdanau and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLMs can learn self-restraint through iterative self-reflection},
  url          = {https://openreview.net/forum?id=SvKPfchVKX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmenting text and learning their rewards for improved RLHF in language model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YhLlqD0UNi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning from human feedback (RLHF) has been widely adopted to align language models (LMs) with human preference. Previous RLHF works typically take a bandit formulation, which, though intuitive, ignores the sequential nature of LM generation and can suffer from the sparse reward issue. While recent works propose dense token-level RLHF, treating each token as an action may be oversubtle to proper reward assignment. In this paper, we seek to get the best of both by training and utilizing a segment-level reward model, which assigns a reward to each semantically complete text segment that spans over a short sequence of tokens. For reward learning, our method allows dynamic text segmentation and compatibility with standard sequence-preference datasets. For effective RL-based LM training against segment reward, we generalize the classical scalar bandit reward normalizers into location-aware normalizer functions and interpolate the segment reward for further densification. Our method performs competitively on three popular RLHF benchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation studies are conducted to further demonstrate our method.},
  archive      = {J_TMLR},
  author       = {Yueqin Yin and Shentao Yang and Yujia Xie and Ziyi Yang and Yuting Sun and Hany Hassan Awadalla and Weizhu Chen and Mingyuan Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Segmenting text and learning their rewards for improved RLHF in language model},
  url          = {https://openreview.net/forum?id=YhLlqD0UNi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VColRL: Learn to solve the vertex coloring problem using reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=a9AQRieTne'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vertex Coloring Problem (VCP) is a fundamental NP-hard problem with applications in wireless networks, compiler design, scheduling, etc. We present VColRL, a deep reinforcement learning (DRL) framework that learns to color graphs quickly by leveraging a reduction-based approach that progressively reduces the graph at each step. The core novelty of VColRL is a new Markov Decision Process (MDP) formulation tailored for VCP that assigns colors to multiple vertices at each step, incorporates a rollback mechanism to revert all conflicting vertices to the undecided state, and employs a reward function designed to minimize the highest-indexed color used. Experiments on synthetic and benchmark graphs show that VColRL improves color usage over optimization solvers and prior learning-based methods, remains competitive with search-based heuristics and metaheuristics, and achieves fast runtime, while generalizing well to diverse graph families despite being trained only on synthetic graphs from a single family.},
  archive      = {J_TMLR},
  author       = {Abhinav Anand and Subrahmanya Swamy Peruru and Amitangshu Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {VColRL: Learn to solve the vertex coloring problem using reinforcement learning},
  url          = {https://openreview.net/forum?id=a9AQRieTne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curvature diversity-driven deformation and domain alignment for point cloud. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ePXWnH7rGk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation is crucial for point cloud learning due to geometric variations across different generation methods and sensors. To tackle this challenge, we propose Curvature Diversity-Driven Nuclear-Norm Wasserstein Domain Alignment (CDND). We first introduce a Curvature Diversity-driven Deformation Reconstruction (CurvRec) task, enabling the model to extract salient features from semantically rich regions of a given point cloud. We then propose a theoretical framework for Deformation-based Nuclear-norm Wasserstein Discrepancy (D-NWD), extending the Nuclear-norm Wasserstein Discrepancy to original and deformed samples. Our theoretical analysis demonstrates that D-NWD is effective for any deformation method. Empirical experiment results show that our CDND achieves state-of-the-art performance by a noticeable margin over existing approaches.},
  archive      = {J_TMLR},
  author       = {Mengxi Wu and Hao Huang and Yi Fang and Mohammad Rostami},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Curvature diversity-driven deformation and domain alignment for point cloud},
  url          = {https://openreview.net/forum?id=ePXWnH7rGk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple and nearly-optimal sampling for rank-1 tensor completion via gauss-jordan. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ggAphfUt1J'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the sample and computational complexity of the rank-1 tensor completion problem in $\otimes_{i=1}^{N} \mathbb{R}^{d}$, given a uniformly sampled subset of entries. We present a characterization of the problem which reduces to solving a pair of random linear systems. For example, when $N$ is a constant, we prove it requires no more than $m = O(d^2 \log d)$ samples and runtime $O(md^2)$. Moreover, we show that a broad class of algorithms require $\Omega(d\log d)$ samples, even under higher rank scenarios. In contrast, existing upper bounds on the sample complexity are at least as large as $d^{1.5} \mu^{\Omega(1)} \log^{\Omega(1)} d$, where $\mu$ can be $\Theta(d)$ in the worst case. Prior work obtained these looser guarantees in higher rank versions of our problem, and tend to involve more complicated algorithms.},
  archive      = {J_TMLR},
  author       = {Alejandro Gomez-Leos and Oscar Lopez},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simple and nearly-optimal sampling for rank-1 tensor completion via gauss-jordan},
  url          = {https://openreview.net/forum?id=ggAphfUt1J},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain graph anomaly detection via test-time training with homophily-guided self-supervision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sB3LqdOlNb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present GADT3, a novel test-time training framework for cross-domain GAD. GADT3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that GADT3 significantly outperforms existing approaches, achieving average improvements of over 8.2\% in AUROC and AUPRC compared to the best competing model.},
  archive      = {J_TMLR},
  author       = {Delaram Pirhayatifard and Arlei Silva},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross-domain graph anomaly detection via test-time training with homophily-guided self-supervision},
  url          = {https://openreview.net/forum?id=sB3LqdOlNb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The accuracy cost of weakness: A theoretical analysis of fixed-segment weak labeling for events in time. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tTw8wXBQ18'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate labels are critical for deriving robust machine learning models. Labels are used to train supervised learning models and to evaluate most machine learning paradigms. In this paper, we model the accuracy and cost of a common weak labeling process where annotators assign presence or absence labels to fixed-length data segments for a given event class. The annotator labels a segment as "present" if it sufficiently covers an event from that class, e.g., a birdsong sound event in audio data. We analyze how the segment length affects the label accuracy and the required number of annotations, and compare this fixed-length labeling approach with an oracle method that uses the true event activations to construct the segments. Furthermore, we quantify the gap between these methods and verify that in most realistic scenarios the oracle method is better than the fixed-length labeling method in both accuracy and cost. Our findings provide a theoretical justification for adaptive weak labeling strategies that mimic the oracle process, and a foundation for optimizing weak labeling processes in sequence labeling tasks.},
  archive      = {J_TMLR},
  author       = {John Martinsson and Olof Mogren and Tuomas Virtanen and Maria Sandsten},
  journal      = {Transactions on Machine Learning Research},
  month        = {9},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The accuracy cost of weakness: A theoretical analysis of fixed-segment weak labeling for events in time},
  url          = {https://openreview.net/forum?id=tTw8wXBQ18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Client-only distributed markov chain monte carlo sampling over a network. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1bZ2rLfKwu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aim to sample from a target $\exp\left(-\sum_{i=1}^n f_i(x|\mathcal{D}_i\right))$ where each client $f_i$ only has access to local data $\mathcal{D}_i$. We present a fully distributed Markov Chain Monte Carlo (MCMC) sampler that operates through client-to-client communication, eliminating the need for additional centralized servers. Unlike MCMC algorithms that rely on server-client structures, our proposed sampler is entirely distributed, enhancing security and robustness through decentralized communication. In contrast to limited decentralized algorithms arising from Langevin dynamics, our sampler utilizes blocked Gibbs sampling on an augmented distribution. Furthermore, we establish a non-asymptotic analysis of our sampler, employing innovative techniques. This study contributes to one of the initial analyses of the non-asymptotic behavior of a fully distributed sampler arising from Gibbs sampling.},
  archive      = {J_TMLR},
  author       = {Bo Yuan and Jiaojiao Fan and Jiaming Liang and Yongxin Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Client-only distributed markov chain monte carlo sampling over a network},
  url          = {https://openreview.net/forum?id=1bZ2rLfKwu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy and responsible AI for human-centric autonomous decision-making systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1k833OTHpI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has paved the way for revolutionary decision-making processes, which, if harnessed appropriately, can contribute to advancements in various sectors, from healthcare to economics. However, its black box nature presents significant ethical challenges related to bias and transparency. AI applications are hugely impacted by biases, presenting inconsistent and unreliable findings, leading to significant costs and consequences, highlighting and perpetuating inequalities and unequal access to resources. Hence, developing safe, reliable, ethical, and Trustworthy AI systems is essential. Our interdisciplinary team of researchers focuses on Trustworthy and Responsible AI, including fairness, bias mitigation, reproducibility, generalization, interpretability, explainability, and authenticity. In this paper, we review and discuss the intricacies of AI biases, definitions, methods of detection and mitigation, and metrics for evaluating bias. We also discuss open challenges with regard to the trustworthiness and widespread application of AI across diverse domains of humancentric decision making, as well as guidelines to foster Responsible and Trustworthy AI models.},
  archive      = {J_TMLR},
  author       = {Farzaneh Dehghani and Mahsa Dibaji and Fahim Anzum and Lily Dey and Alican Basdemir and Sayeh Bayat and Jean-Christophe Boucher and Steve Drew and Sarah Elaine Eaton and Richard Frayne and Gouri Ginde and Ashley D. Harris and Yani Ioannou and Catherine A Lebel and John T. Lysack and Leslie Salgado and Emma A.M. Stanley and Roberto Souza and Ronnie de Souza Santos and Lana Wells and Tyler Williamson and Matthias Wilms and Mark Ungrin and Marina Gavrilova and Mariana Bento},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Trustworthy and responsible AI for human-centric autonomous decision-making systems},
  url          = {https://openreview.net/forum?id=1k833OTHpI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust and efficient fine-tuning of LLMs with bayesian reparameterization of low-rank adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2HFmicB8kh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are highly resource-intensive to fine-tune due to their enormous size. While low-rank adaptation is a prominent parameter-efficient fine-tuning approach, it suffers from sensitivity to hyperparameter choices, leading to instability in model performance on fine-tuning downstream tasks. This paper highlights the importance of effective parameterization in low-rank fine-tuning to reduce estimator variance and enhance the stability of final model outputs. We propose MonteCLoRA, an efficient fine-tuning technique that employs Monte Carlo estimation to learn an unbiased posterior estimation of low-rank parameters with low expected variance, stabilizing fine-tuned LLMs with only $\mathcal{O}(r)$ additional parameters, for a given rank $r$. MonteCLoRA shows significant improvements in accuracy and robustness, achieving up to $3.8$% higher accuracy and $8.6$% greater robustness than existing efficient fine-tuning methods on natural language understanding tasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with pre-trained LLaMA-1-7B and LLaMA-3.2-3B-Instruct, MonteCLoRA demonstrates robust performance with $50\%$ and $62\%$ lower spreads, respectively, than the contemporary, efficient fine-tuning methods. The theoretical and empirical results presented in the paper underscore how parameterization and hyperpriors balance exploration-exploitation in the low-rank parametric space, therefore leading to more optimal and robust parameter estimation during efficient fine-tuning.},
  archive      = {J_TMLR},
  author       = {Vaibhav Seth and Ayan Sengupta and Arinjay Pathak and Aastha A K Verma and Natraj Raman and Sriram Gopalakrishnan and Niladri Chatterjee and Tanmoy Chakraborty},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust and efficient fine-tuning of LLMs with bayesian reparameterization of low-rank adaptation},
  url          = {https://openreview.net/forum?id=2HFmicB8kh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffCLIP: Differential attention meets CLIP. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2I2fTehry2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose DiffCLIP, a novel vision-language model that extends the differential attention mechanism to CLIP architectures. Differential attention was originally developed for large language models to amplify relevant context while canceling out noisy information. In this work, we integrate this mechanism into CLIP's dual encoder (image and text) framework. With minimal additional parameters, DiffCLIP achieves superior performance on image-text understanding tasks. Across zero-shot classification, retrieval, and robustness benchmarks, DiffCLIP consistently outperforms baseline CLIP models. Notably, these gains come with negligible computational overhead, demonstrating that differential attention can significantly enhance multi-modal representations without sacrificing efficiency.},
  archive      = {J_TMLR},
  author       = {Hasan Abed Al Kader Hammoud and Bernard Ghanem},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DiffCLIP: Differential attention meets CLIP},
  url          = {https://openreview.net/forum?id=2I2fTehry2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint generative modeling of grounded scene graphs and images via diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2cxxZI2LOL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A grounded scene graph represents a visual scene as a graph, where nodes denote objects (including labels and spatial locations) and directed edges encode relations among them. In this paper, we introduce a novel framework for joint grounded scene graph - image generation, a challenging task involving high-dimensional, multi-modal structured data. To effectively model this complex joint distribution, we adopt a factorized approach: first generating a grounded scene graph, followed by image generation conditioned on the generated grounded scene graph. While conditional image generation has been widely explored in the literature, our primary focus is on the generation of grounded scene graphs from noise, which provides efficient and interpretable control over the image generation process. This task requires generating plausible grounded scene graphs with heterogeneous attributes for both nodes (objects) and edges (relations among objects), encompassing continuous attributes (e.g., object bounding boxes) and discrete attributes (e.g., object and relation categories). To address this challenge, we introduce DiffuseSG, a novel diffusion model that jointly models the heterogeneous node and edge attributes. We explore different encoding strategies to effectively handle the categorical data. Leveraging a graph transformer as the denoiser, DiffuseSG progressively refines grounded scene graph representations in a continuous space before discretizing them to generate structured outputs. Additionally, we introduce an IoU-based regularization term to enhance empirical performance. Our model outperforms existing methods in grounded scene graph generation on the Visual Genome and COCO-Stuff datasets, excelling in both standard and newly introduced metrics that more accurately capture the task’s complexity. Furthermore, we demonstrate the broader applicability of DiffuseSG in two important downstream tasks: (1) achieving superior results in a range of grounded scene graph completion tasks, and (2) enhancing grounded scene graph detection models by leveraging additional training samples generated by DiffuseSG. Code is available at https://github.com/ubc-vision/DiffuseSG.},
  archive      = {J_TMLR},
  author       = {Bicheng Xu and Qi Yan and Renjie Liao and Lele Wang and Leonid Sigal},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Joint generative modeling of grounded scene graphs and images via diffusion models},
  url          = {https://openreview.net/forum?id=2cxxZI2LOL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LumiNet: Perception-driven knowledge distillation via statistical logit calibration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3rU1lp9w2l'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the knowledge distillation literature, feature-based methods have dominated due to their ability to effectively tap into extensive teacher models. In contrast, logit-based approaches, which aim to distill `dark knowledge' from teachers, typically exhibit inferior performance compared to feature-based methods. To bridge this gap, we present LumiNet, a novel knowledge distillation algorithm designed to enhance logit-based distillation. We introduce the concept of `perception', aiming to calibrate logits based on the model's representation capability. This concept addresses overconfidence issues in the logit-based distillation method while also introducing a novel method to distill knowledge from the teacher. It reconstructs the logits of a sample/instances by considering relationships with other samples in the batch. LumiNet excels on benchmarks like CIFAR-100, ImageNet, and MSCOCO, outperforming the leading feature-based methods, e.g., compared to KD with ResNet18 and MobileNetV2 on ImageNet, it shows improvements of 1.5\% and 2.05\%, respectively.},
  archive      = {J_TMLR},
  author       = {Md. Ismail Hossain and M M Lutfe Elahi and Sameera Ramasinghe and Ali Cheraghian and Fuad Rahman and Nabeel Mohammed and Shafin Rahman},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LumiNet: Perception-driven knowledge distillation via statistical logit calibration},
  url          = {https://openreview.net/forum?id=3rU1lp9w2l},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent neural network mechanisms for generalization to objects in novel orientations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4wBQTZVSHU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of Deep Neural Networks (DNNs) to recognize objects in orientations outside the training data distribution is not well understood. We investigate the limitations of DNNs’ generalization capacities by systematically inspecting DNNs' patterns of success and failure across out-of-distribution (OoD) orientations. We present evidence that DNNs (across architecture types, including convolutional neural networks and transformers) are capable of generalizing to objects in novel orientations, and we describe their generalization behaviors. Specifically, generalization strengthens when training the DNN with an increasing number of familiar objects, but only in orientations that involve 2D rotations of familiar orientations. We also hypothesize how this generalization behavior emerges from internal neural mechanisms – that neurons tuned to common features between familiar and unfamiliar objects enable out of distribution generalization – and present supporting data for this theory. The reproducibility of our findings across model architectures, as well as analogous prior studies on the brain, suggests that these orientation generalization behaviors, as well as the neural mechanisms that drive them, may be a feature of neural networks in general.},
  archive      = {J_TMLR},
  author       = {Avi Cooper and Daniel Harari and Tomotake Sasaki and Spandan Madan and Hanspeter Pfister and Pawan Sinha and Xavier Boix},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent neural network mechanisms for generalization to objects in novel orientations},
  url          = {https://openreview.net/forum?id=4wBQTZVSHU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Keep your distance: Learning dispersed embeddings on $\mathbb{S}_{m}$. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5JIQE6HcTd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning well-separated features in high-dimensional spaces, such as text or image embeddings, is crucial for many machine learning applications. Achieving such separation can be effectively accomplished through the dispersion of embeddings, where unrelated vectors are pushed apart as much as possible. By constraining features to be on a hypersphere, we can connect dispersion to well-studied problems in mathematics and physics, where optimal solutions are known for limited low-dimensional cases. However, in representation learning we typically deal with a large number of features in high-dimensional space, and moreover, dispersion is usually traded off with some other task-oriented training objective, making existing theoretical and numerical solutions inapplicable. Therefore, it is common to rely on gradient-based methods to encourage dispersion, usually by minimizing some function of the pairwise distances. In this work, we first give an overview of existing methods from disconnected literature, making new connections and highlighting similarities. Next, we introduce some new angles. We propose to reinterpret pairwise dispersion using a maximum mean discrepancy (MMD) motivation. We then propose an online variant of the celebrated Lloyd’s algorithm, of K-Means fame, as an effective alternative regularizer for dispersion on generic domains. Finally, we revise and empirically assess sliced regularizers that directly exploit properties of the hypersphere, proposing a new, simple but effective one. Our experiments show the importance of dispersion in image classification and natural language processing tasks, and how algorithms exhibit different trade-offs in different regimes},
  archive      = {J_TMLR},
  author       = {Evgeniia Tokarchuk and Hua Chang Bakker and Vlad Niculae},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Keep your distance: Learning dispersed embeddings on $\mathbb{S}_{m}$},
  url          = {https://openreview.net/forum?id=5JIQE6HcTd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Registers in small vision transformers: A reproducibility study of vision transformers need registers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5JflRlCt3Q'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has shown that Vision Transformers (ViTs) can produce “high-norm” artifact tokens in attention maps. These artifacts disproportionately accumulate global information, can degrade performance, and reduce interpretability in these models. Darcet et al. (2024) proposed registers—auxiliary learnable tokens—to mitigate these artifacts. In this reproducibility study, we verify whether these improvements extend to smaller ViTs. Specifically, we examine whether high-norm tokens appear in a DeiT-III Small model, whether registers reduce these artifacts, and how registers influence local and global feature representation. Our results confirm that smaller ViTs also exhibit high-norm tokens and registers partially alleviate them, improving interpretability. Although the overall performance gains are modest, these findings reinforce the utility of registers in enhancing ViTs while highlighting open questions about their varying effectiveness across different inputs and tasks. Our code is available at https://github.com/SnorrenanxD/regs-small-vits.},
  archive      = {J_TMLR},
  author       = {Linus Ruben Bach and Emma Bakker and Rénan van Dijk and Jip de Vries and Konrad Szewczyk},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Registers in small vision transformers: A reproducibility study of vision transformers need registers},
  url          = {https://openreview.net/forum?id=5JflRlCt3Q},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). L2G: Repurposing language models for genomics tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5NM4guc90N'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained language models have transformed the field of natural language processing (NLP), and their success has inspired efforts in genomics to develop domain-specific foundation models (FMs). However, creating high-quality genomic FMs from scratch is resource-intensive, requiring significant computational power and high-quality pre-training data. The success of large language models (LLMs) in NLP has largely been driven by industrial-scale efforts leveraging vast, diverse corpora and massive computing infrastructure. In this work, we aim to bypass the data and computational bottlenecks of creating genomic FMs from scratch and instead propose repurposing existing LLMs for genomics tasks. Inspired by the recently observed 'cross-modal transfer' phenomenon -- where transformers pre-trained on natural language can generalize to other modalities -- we introduce L2G, which adapts a pre-trained LLM architecture for genomics using neural architecture search and a novel three-stage training procedure. Remarkably, without requiring extensive pre-training on DNA sequence data, L2G achieves superior performance to fine-tuned genomic FMs and task-specific models on more than half of tasks across multiple genomics benchmarks. In an enhancer activity prediction task, L2G further demonstrates its capacity to identify significant transcription factor motifs. Our work not only highlights the generalizability and efficacy of language models in out-of-domain tasks such as genomics, but also opens new avenues for more efficient and less resource-intensive methodologies in genomic research.},
  archive      = {J_TMLR},
  author       = {Wenduo Cheng and Junhong Shen and Mikhail Khodak and Jian Ma and Ameet Talwalkar},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {L2G: Repurposing language models for genomics tasks},
  url          = {https://openreview.net/forum?id=5NM4guc90N},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Foldable SuperNets: Scalable merging of transformers with different initializations and tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6FqwLestHv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent methods aim to merge neural networks (NNs) with identical architectures trained on different tasks into a single multi-task model. While most works focus on the simpler setup of merging NNs initialized from a common pre-trained network, we target the harder problem of merging large transformers trained on different tasks from distinct initializations. We show that traditional merging methods fail catastrophically in this setup, while Knowledge Distillation (KD) achieves much better results, though at a higher cost. However, KD is data-inefficient, as it does not exploit the original models' weights. To solve this, we introduce "Foldable SuperNet Merge" (FS-Merge), which trains a SuperNet containing the original models (with frozen weights) using a feature reconstruction objective. After training, the SuperNet is folded back to the size of a single original model. FS-Merge is simple, data-efficient, has a computational cost comparable to KD, and is proven to have superior expressiveness over traditional merging methods. It achieves SOTA results when tested on MLPs and transformers across various sizes, tasks, modalities, and distribution shifts, especially in low-data scenarios.},
  archive      = {J_TMLR},
  author       = {Edan kinderman and Itay Hubara and Haggai Maron and Daniel Soudry},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Foldable SuperNets: Scalable merging of transformers with different initializations and tasks},
  url          = {https://openreview.net/forum?id=6FqwLestHv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent adversarial training improves robustness to persistent harmful behaviors in LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6LxMeRlkWl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) can often be made to behave in undesirable ways that they are explicitly fine-tuned not to. For example, the LLM red-teaming literature has produced a wide variety of 'jailbreaking' techniques to elicit harmful text from models that were fine-tuned to be harmless. Recent work on red-teaming, model editing, and interpretability suggests that this challenge stems from how (adversarial) fine-tuning largely serves to suppress rather than remove undesirable capabilities from LLMs. Prior work has introduced latent adversarial training (LAT) as a way to improve robustness to broad classes of failures. These prior works have considered untargeted latent space attacks where the adversary perturbs latent activations to maximize loss on examples of desirable behavior. Untargeted LAT can provide a generic type of robustness but does not leverage information about specific failure modes. Here, we experiment with targeted LAT where the adversary seeks to minimize loss on a specific competing task. We find that it can augment a wide variety of state-of-the-art methods. First, we use targeted LAT to improve robustness to jailbreaks, outperforming a strong R2D2 baseline with orders of magnitude less compute. Second, we use it to more effectively remove backdoors with no knowledge of the trigger. Finally, we use it to more effectively unlearn knowledge for specific undesirable tasks in a way that is also more robust to re-learning. Overall, our results suggest that targeted LAT can be an effective tool for defending against harmful behaviors from LLMs.},
  archive      = {J_TMLR},
  author       = {Abhay Sheshadri and Aidan Ewart and Phillip Huang Guo and Aengus Lynch and Cindy Wu and Vivek Hebbar and Henry Sleight and Asa Cooper Stickland and Ethan Perez and Dylan Hadfield-Menell and Stephen Casper},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent adversarial training improves robustness to persistent harmful behaviors in LLMs},
  url          = {https://openreview.net/forum?id=6LxMeRlkWl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative feature training of thin 2-layer networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6oXNpKuBDK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the approximation of functions by 2-layer neural networks with a small number of hidden weights based on the squared loss and small datasets. Due to the highly non-convex energy landscape, gradient-based training often suffers from local minima. As a remedy, we initialize the hidden weights with samples from a learned proposal distribution, which we parameterize as a deep generative model. To train this model, we exploit the fact that with fixed hidden weights, the optimal output weights solve a linear equation. After learning the generative model, we refine the sampled weights with a gradient-based post-processing in the latent space. Here, we also include a regularization scheme to counteract potential noise. Finally, we demonstrate the effectiveness of our approach by numerical examples.},
  archive      = {J_TMLR},
  author       = {Johannes Hertrich and Sebastian Neumayer},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generative feature training of thin 2-layer networks},
  url          = {https://openreview.net/forum?id=6oXNpKuBDK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SuFP: Piecewise bit allocation floating-point for robust neural network quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7M1adi1nfX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth in model size and computational demand of Deep Neural Networks (DNNs) has led to significant challenges in memory and compute efficiency, necessitating the adoption of lower bit-width data types to enhance hardware performance. Floating-point 8 (FP8) has emerged as a promising solution, supported by the latest AI processors, due to its potential for reducing memory usage and computational load. However, each application often requires its own optimal FP8 configuration to achieve high performance, resulting in inconsistent performance and increased hardware complexity. To address these limitations, we introduce Super Floating-Point (SuFP), an innovative data type that integrates various floating-point configurations into a single representation through a piecewise bit allocation. This approach enables SuFP to effectively capture both dense regions near zero and sparse regions with outliers, thereby minimizing quantization errors and ensuring full-precision floating-point performance across different models. Furthermore, SuFP’s processing element design is optimized to reduce the hardware overhead. Our experimental results demonstrate the robustness and accuracy of SuFP over various neural networks in the vision and natural language processing domains. Remarkably, SuFP shows its superiority in large models such as large language model (Llama 2) and text-to-image generative model (Stable Diffusion v2). We also verify training feasibility on ResNet models and highlight the structural design of SuFP for general applicability.},
  archive      = {J_TMLR},
  author       = {Geonwoo Ko and Sungyeob Yoo and Seri Ham and Seeyeon Kim and Minkyu Kim and Joo-Young Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SuFP: Piecewise bit allocation floating-point for robust neural network quantization},
  url          = {https://openreview.net/forum?id=7M1adi1nfX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PrivShap: A finer-granularity network linearization method for private inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7TliYmJr2m'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private inference applies cryptographic techniques like homomorphic encryption, garble circuit and secret sharing to keep both sides privacy in a client-server setting during inference. It is often hindered by the high communication overheads, especially at non-linear activation layers such as ReLU. Hence ReLU pruning has been widely recognized as an efficient way to accelerate private inference. Existing approaches to ReLU pruning typically rely on coarse hypothesis, which assume an inverse correlation between the importance of ReLU and linear layers or shallow activation layers have less importance for universal models, to assign the budgets according to the layer while preserving the inference accuracy. However, these assumptions are based on limited empirical evidence and can fail to generalize to diverse model architectures. In this work, we introduce a finer-granularity ReLU budget assignment approach by assessing the layer-wise importance of ReLU with the Shapley value. To address the computational burden of exact Shapley value calculation, we propose a tree-trimming algorithm for fast estimation. We provide both theoretical guarantees and empirical validation of our method. Our extensive experiments show that we achieve better efficiency and accuracy than the state-of-the-art across diverse model architectures, activation functions, and datasets. Specifically, we only need $\sim$$2.5\times$ fewer ReLU operations to achieve a similar inference accuracy and gains up to $\sim$$8.13\%$ increase on inference accuracy with similar ReLU budgets.},
  archive      = {J_TMLR},
  author       = {Xiangrui Xu and Zhenzhen Wang and Rui Ning and Chunsheng Xin and Hongyi Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PrivShap: A finer-granularity network linearization method for private inference},
  url          = {https://openreview.net/forum?id=7TliYmJr2m},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rectified robust policy optimization for model-uncertain constrained reinforcement learning without strong duality. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7l63xwAgAW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of robust constrained reinforcement learning (RL) is to optimize an agent's performance under the worst-case model uncertainty while satisfying safety or resource constraints. In this paper, we demonstrate that strong duality does not generally hold in robust constrained RL, indicating that traditional primal-dual methods may fail to find optimal feasible policies. To overcome this limitation, we propose a novel primal-only algorithm called Rectified Robust Policy Optimization (RRPO), which operates directly on the primal problem without relying on dual formulations. We provide theoretical convergence guarantees under mild regularity assumptions, showing convergence to an approximately optimal feasible policy with iteration complexity matching the best-known lower bound when the uncertainty set diameter is controlled in a specific level. Empirical results in a grid-world environment validate the effectiveness of our approach, demonstrating that RRPO achieves robust and safe performance under model uncertainties while the non-robust method can violate the worst-case safety constraints.},
  archive      = {J_TMLR},
  author       = {Shaocong Ma and Ziyi Chen and Yi Zhou and Heng Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rectified robust policy optimization for model-uncertain constrained reinforcement learning without strong duality},
  url          = {https://openreview.net/forum?id=7l63xwAgAW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task diversity shortens the in-context learning plateau. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7t5DzaJOdB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-context learning (ICL) describes a language model's ability to generate outputs based on a set of input demonstrations and a subsequent query. To understand this remarkable capability, researchers have studied simplified, stylized models. These studies have consistently observed long loss plateaus, during which models exhibit minimal improvement, followed by a sudden, rapid surge of learning. In this work, we reveal that training on multiple diverse ICL tasks simultaneously shortens the loss plateaus, making each task easier to learn. This finding is surprising as it contradicts the natural intuition that the combined complexity of multiple ICL tasks would lengthen the learning process, not shorten it. Our result suggests that the recent success in large-scale training of language models may be attributed not only to the richness of the data at scale but also to the easier optimization (training) induced by the diversity of natural language training data.},
  archive      = {J_TMLR},
  author       = {Jaeyeon Kim and Sehyun Kwon and Joo Young Choi and Jongho Park and Jaewoong Cho and Jason D. Lee and Ernest K. Ryu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Task diversity shortens the in-context learning plateau},
  url          = {https://openreview.net/forum?id=7t5DzaJOdB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goal-conditioned data augmentation for offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8K16dplpE0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) enables policy learning from pre-collected offline datasets, relaxing the need to interact directly with the environment. However, limited by the quality of offline datasets, it generally fails to learn well-qualified policies in suboptimal datasets. To address datasets with insufficient optimal demonstrations, we introduce Goal-cOnditioned Data Augmentation (GODA), a novel goal-conditioned diffusion-based method for augmenting samples with higher quality. Leveraging recent advancements in generative modelling, GODA incorporates a novel return-oriented goal condition with various selection mechanisms. Specifically, we introduce a controllable scaling technique to provide enhanced return-based guidance during data sampling. GODA learns a comprehensive distribution representation of the original offline datasets while generating new data with selectively higher-return goals, thereby maximizing the utility of limited optimal demonstrations. Furthermore, we propose a novel adaptive gated conditioning method for processing noisy inputs and conditions, enhancing the capture of goal-oriented guidance. We conduct experiments on the D4RL benchmark and real-world challenges, specifically traffic signal control (TSC) tasks, to demonstrate GODA's effectiveness in enhancing data quality and superior performance compared to state-of-the-art data augmentation methods across various offline RL algorithms.},
  archive      = {J_TMLR},
  author       = {Xingshuai Huang and Di Wu and Benoit Boulet},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Goal-conditioned data augmentation for offline reinforcement learning},
  url          = {https://openreview.net/forum?id=8K16dplpE0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture of balanced information bottlenecks for long-tailed visual recognition. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9eiALSuZGA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved significant success in various applications with large-scale and balanced data. However, data in real-world visual recognition are usually long-tailed, bringing challenges to efficient training and deployment of DNNs. Information bottleneck (IB) is an elegant approach for representation learning. In this paper, we propose a balanced information bottleneck (BIB) approach, in which loss function re-balancing and self-distillation techniques are integrated into the original IB network. BIB is thus capable of learning a sufficient representation with essential label-related information fully preserved for long-tailed visual recognition. To further enhance the representation learning capability, we also propose a novel structure of mixture of multiple balanced information bottlenecks (MBIB), where different BIBs are responsible for combining knowledge from different network layers. MBIB facilitates an end-to-end learning strategy that trains representation and classification simultaneously from an information theory perspective. We conduct experiments on commonly used long-tailed datasets, including CIFAR100-LT, ImageNet-LT, and iNaturalist 2018. Both BIB and MBIB reach state-of-the-art performance for long-tailed visual recognition.},
  archive      = {J_TMLR},
  author       = {Yifan Lan and Cai xin and Jun Cheng and Shan Tan},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture of balanced information bottlenecks for long-tailed visual recognition},
  url          = {https://openreview.net/forum?id=9eiALSuZGA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss landscape degeneracy and stagewise development in transformers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=45qJyBG8Oj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning involves navigating a high-dimensional loss landscape over the neural network parameter space. Over the course of training, complex computational structures form and re-form inside the neural network, leading to shifts in input/output behavior. It is a priority for the science of deep learning to uncover principles governing the development of neural network structure and behavior. Drawing on the framework of singular learning theory, we propose that model development is deeply linked to degeneracy in the local geometry of the loss landscape. We investigate this link by monitoring loss landscape degeneracy throughout training, as quantified by the local learning coefficient, for a transformer language model and an in-context linear regression transformer. We show that training can be divided into distinct periods of change in loss landscape degeneracy, and that these changes in degeneracy coincide with significant changes in the internal computational structure and the input/output behavior of the transformers. This finding provides suggestive evidence that degeneracy and development are linked in transformers, underscoring the potential of a degeneracy-based perspective for understanding modern deep learning.},
  archive      = {J_TMLR},
  author       = {Jesse Hoogland and George Wang and Matthew Farrugia-Roberts and Liam Carroll and Susan Wei and Daniel Murfet},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Loss landscape degeneracy and stagewise development in transformers},
  url          = {https://openreview.net/forum?id=45qJyBG8Oj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How can knowledge of a task’s modular structure improve generalization and training efficiency?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=46hFTOUox7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world learning tasks have an underlying hierarchical and modular structure, composed of smaller sub-functions. Traditional neural networks (NNs) often disregard this structure, leading to inefficiencies in learning and generalization. Prior work has demonstrated that leveraging known structural information can enhance performance by aligning NN architectures with the task’s inherent modularity. However, the extent of prior structural knowledge required to achieve these performance improvements remains unclear. In this work, we investigate how modular NNs can outperform traditional dense NNs on tasks with simple yet known modular structure by systematically varying the degree of structural knowledge incorporated. We compare architectures ranging from monolithic dense NNs, which assume no prior knowledge, to hierarchically modular NNs with shared modules that leverage sparsity, modularity, and module reusability. Our experiments demonstrate that module reuse in modular NNs significantly improves learning efficiency and generalization. Furthermore, we find that module reuse enables modular NNs to excel in data-scarce scenarios by promoting functional specialization within modules and reducing redundancy.},
  archive      = {J_TMLR},
  author       = {Shreyas Malakarjun Patil and Cameron Ethan Taylor and Constantine Dovrolis},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How can knowledge of a task’s modular structure improve generalization and training efficiency?},
  url          = {https://openreview.net/forum?id=46hFTOUox7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using platt’s scaling for calibration after undersampling — Limitations and how to address them. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=80b2zaeTUe'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When modelling data where the response is dichotomous and highly imbalanced, response-based sampling where a subset of the majority class is retained (i.e., undersampling) is often used to create more balanced training datasets prior to modelling. However, the models fit to this undersampled data, which we refer to as base models, generate predictions that are severely biased. There are several calibration methods that can be used to combat this bias, one of which is Platt’s scaling. Here, a logistic regression model is used to model the relationship between the base model’s original predictions and the response. Despite its popularity for calibrating models after undersampling, Platt’s scaling was not designed for this purpose. Our work presents what we believe is the first detailed study focused on the validity of using Platt’s scaling to calibrate models after undersampling. We show analytically, as well as via a simulation study, that Platt’s scaling should not be used for calibration after undersampling without critical thought. If Platt’s scaling would have been able to successfully calibrate the base model had it been trained on the entire dataset (i.e., without undersampling), then Platt’s scaling might be appropriate for calibration after undersampling. If this is not the case, we recommend a modified version of Platt’s scaling that fits a logistic generalized additive model to the logit of the base model’s predictions, as this method is theoretically motivated and performed relatively well across the settings considered in our study.},
  archive      = {J_TMLR},
  author       = {Nathan Phelps and Daniel J Lizotte and Douglas G. Woolford},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Using platt’s scaling for calibration after undersampling — Limitations and how to address them},
  url          = {https://openreview.net/forum?id=80b2zaeTUe},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASkDAgger: Active skill-level data aggregation for interactive imitation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=987Az9f8fT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human teaching effort is a significant bottleneck for the broader applicability of interactive imitation learning. To reduce the number of required queries, existing methods employ active learning to query the human teacher only in uncertain, risky, or novel situations. However, during these queries, the novice’s planned actions are not utilized despite containing valuable information, such as the novice’s capabilities, as well as corresponding uncertainty levels. To this end, we allow the novice to say: “I plan to do this, but I am uncertain.” We introduce the Active Skill-level Data Aggregation (ASkDAgger) framework, which leverages teacher feedback on the novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating threshold to track sensitivity, specificity, or a minimum success rate; (2) Foresight Interactive Experience Replay (FIER), which recasts valid and relabeled novice action plans into demonstrations; and (3) Prioritized Interactive Experience Replay (PIER), which prioritizes replay based on uncertainty, novice success, and demonstration age. Together, these components balance query frequency with failure incidence, reduce the number of required demonstration annotations, improve generalization, and speed up adaptation to changing domains. We validate the effectiveness of ASkDAgger through language-conditioned manipulation tasks in both simulation and real-world environments. Code, data, and videos are available at https://askdagger.github.io.},
  archive      = {J_TMLR},
  author       = {Jelle Luijkx and Zlatan Ajanović and Laura Ferranti and Jens Kober},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ASkDAgger: Active skill-level data aggregation for interactive imitation learning},
  url          = {https://openreview.net/forum?id=987Az9f8fT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlling statistical, discretization, and truncation errors in learning fourier linear operators. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=A2sHNGcjLO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study learning-theoretic foundations of operator learning, using the linear layer of the Fourier Neural Operator architecture as a model problem. First, we identify three main errors that occur during the learning process: statistical error due to finite sample size, truncation error from finite rank approximation of the operator, and discretization error from handling functional data on a finite grid of domain points. Finally, we analyze a Discrete Fourier Transform (DFT) based least squares estimator, establishing both upper and lower bounds on the aforementioned errors.},
  archive      = {J_TMLR},
  author       = {Unique Subedi and Ambuj Tewari},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Controlling statistical, discretization, and truncation errors in learning fourier linear operators},
  url          = {https://openreview.net/forum?id=A2sHNGcjLO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence of SVGD in KL divergence via approximate gradient flow. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AG1zXt5aoA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the convergence of Stein variational gradient descent (SVGD), which is used to approximate a target distribution based on a gradient flow on the space of probability distributions. The existing studies mainly focus on the convergence in the kernel Stein discrepancy, which doesn't imply weak convergence in many practical settings. To address this issue, we propose to introduce a novel analytical approach called $(\epsilon,\delta)$-approximate gradient flow, extending conventional concepts of approximation error for the Wasserstein gradient. With this approach, we show the sub-linear convergence of SVGD in Kullback--Leibler divergence under the discrete time and infinite particle settings. Finally, we validate our theoretical findings through several numerical experiments.},
  archive      = {J_TMLR},
  author       = {Masahiro Fujisawa and Futoshi Futami},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the convergence of SVGD in KL divergence via approximate gradient flow},
  url          = {https://openreview.net/forum?id=AG1zXt5aoA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NnActive: A framework for evaluation of active learning in 3D biomedical segmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AJAnmRLJjJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a significant bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by selectively querying the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there remains no consensus on whether AL consistently outperforms Random sampling strategies. Current methodological assessment is hindered by the wide-spread occurrence of four pitfalls with respect to AL method evaluation. These are (1) restriction to too few datasets and annotation budgets, (2) training 2D models on 3D images and not incorporating partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that systematically overcomes the aforementioned pitfalls by (1) means of a large scale study evaluating 8 Query Methods on four biomedical imaging datasets and three label regimes, accompanied by four large-scale ablation studies, (2) extending the state-of-the-art 3D medical segmentation method nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance commonly encountered in 3D medical images and (4) propose the foreground efficiency metric, which captures that the annotation cost for background- compared to foreground-regions is very low. We reveal the following key findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) the benefits of AL depend on task specific parameters like number of classes and their locations; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices like longer training and smaller query sizes. As a holistic, open-source framework, nnActive has the potential to act as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: \href{https://github.com/MIC-DKFZ/nnActive}{https://github.com/MIC-DKFZ/nnActive}},
  archive      = {J_TMLR},
  author       = {Carsten T. Lüth and Jeremias Traub and Kim-Celine Kahl and Till J. Bungert and Lukas Klein and Lars Krämer and Paul F Jaeger and Fabian Isensee and Klaus Maier-Hein},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NnActive: A framework for evaluation of active learning in 3D biomedical segmentation},
  url          = {https://openreview.net/forum?id=AJAnmRLJjJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A proximal operator for inducing 2:4-sparsity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AsFbXRIe4q'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent hardware advancements in AI Accelerators and GPUs allow to efficiently compute sparse matrix multiplications, especially when 2 out of 4 consecutive weights are set to zero. However, this so-called 2:4 sparsity usually comes at a decreased accuracy of the model. We derive a regularizer that exploits the local correlation of features to find better sparsity masks in trained models. We minimize the regularizer jointly with a local squared loss by deriving the proximal operator for which we show that it has an efficient solution in the 2:4-sparse case. After optimizing the mask, we introduce masked-gradient updates to further minimize the local squared loss. We illustrate our method on toy problems and apply it to pruning entire large language models up to 70B parameters. On models up to 13B we improve over previous state of the art algorithms, whilst on 70B models we match their performance.},
  archive      = {J_TMLR},
  author       = {Jonas M. Kübler and Yu-Xiang Wang and Shoham Sabach and Navid Ansari and Matthäus Kleindessner and Kailash Budhathoki and Volkan Cevher and George Karypis},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A proximal operator for inducing 2:4-sparsity},
  url          = {https://openreview.net/forum?id=AsFbXRIe4q},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HDCS: Hierarchy discovery and critic shaping for reinforcement learning with automaton specification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BGoRme2MfG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training reinforcement learning (RL) agents by scalar reward signals is often infeasible when an environment has sparse and non-Markovian rewards. Deterministic finite-state automaton (DFA) provides a streamlined method for specifying tasks in reinforcement learning (RL) that surpass the limitations of traditional discounted return formulations. However, existing RL algorithms designed to address DFA tasks face unresolved challenges, hindering their practical application. One key issue is that subgoals in the DFA may exhibit hidden hierarchical structures, with some macro-subgoals comprising multiple micro-subgoals in certain orders. Without understanding this hierarchy, RL algorithms may struggle to efficiently solve tasks involving such macro-subgoals. Additionally, the sparse reward problem remains inadequately addressed. Previous approaches, such as potential-based reward shaping, often encounter inefficiencies or result in suboptimal solutions. To address these challenges, we propose a novel RL framework designed to uncover the hierarchical structure of subgoals and accelerating the solving of DFA tasks without changing the original optimal policies, short as HDCS. The framework operates in two phases: first, a hierarchical RL method is used to identify the prerequisites of subgoals and build the hierarchy; second, given any task specification (DFA), the subgoal hierarchy is incorporated into task DFA to make a product DFA, and then a simple and novel critic shaping approach is proposed to accelerate the satisfaction of product DFA, which does not change optimal policies of the original problem. The effectiveness of HDCS is demonstrated through experiments conducted across various domains. Especially, compared with representative baselines, the critic shaping can have 2X or 3X acceleration on task solving.},
  archive      = {J_TMLR},
  author       = {Duo XU and Faramarz Fekri},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HDCS: Hierarchy discovery and critic shaping for reinforcement learning with automaton specification},
  url          = {https://openreview.net/forum?id=BGoRme2MfG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining machine learning defenses without conflicts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=C7FgsjfFRC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) models require protection against various risks to security, privacy, and fairness. Real-life ML models need simultaneous protection against multiple risks, necessitating combining multiple defenses effectively, without incurring significant drop in the effectiveness of the constituent defenses. We present a systematization of existing work based on how defenses are combined, and how they interact. We then identify unexplored combinations, and evaluate combination techniques to identify their limitations. Using these insights, we present, Def\Con, a combination technique which is (a) accurate (correctly identifies whether a combination is effective or not), (b) scalable (allows combining multiple defenses), (c) non-invasive (allows combining existing defenses without modification), and (d) general (is applicable to different types of defenses). We show that Def\Con achieves 90% accuracy on eight combinations from prior work, and 86% in 30 unexplored combinations evaluated empirically.},
  archive      = {J_TMLR},
  author       = {Vasisht Duddu and Rui Zhang and N. Asokan},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Combining machine learning defenses without conflicts},
  url          = {https://openreview.net/forum?id=C7FgsjfFRC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding in-context learning of linear models in transformers through an adversarial lens. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CtMXJxO7SJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we make two contributions towards understanding of in-context learning of linear models by transformers. First, we investigate the adversarial robustness of in-context learning in transformers to hijacking attacks — a type of adversarial attacks in which the adversary’s goal is to manipulate the prompt to force the transformer to generate a specific output. We show that both linear transformers and transformers with GPT-2 architectures are vulnerable to such hijacking attacks. However, adversarial robustness to such attacks can be significantly improved through adversarial training --- done either at the pretraining or finetuning stage --- and can generalize to stronger attack models. Our second main contribution is a comparative analysis of adversarial vulnerabilities across transformer models and other algorithms for learning linear models. This reveals two novel findings. First, adversarial attacks transfer poorly between larger transformer models trained from different seeds despite achieving similar in-distribution performance. This suggests that transformers of the same architecture trained according to the same recipe may implement different in-context learning algorithms for the same task. Second, we observe that attacks do not transfer well between classical learning algorithms for linear models (single-step gradient descent and ordinary least squares) and transformers. This suggests that there could be qualitative differences between the in-context learning algorithms that transformers implement and these traditional algorithms.},
  archive      = {J_TMLR},
  author       = {Usman Anwar and Johannes von Oswald and Louis Kirsch and David Krueger and Spencer Frei},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding in-context learning of linear models in transformers through an adversarial lens},
  url          = {https://openreview.net/forum?id=CtMXJxO7SJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning via low-rank matrix optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DFJu1QB2Nr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (pFL) has gained significant attention for building a suite of models tailored to different clients. In pFL, the challenge lies in balancing the reliance on local datasets, which may lack representativeness, against the diversity of other clients' models, whose quality and relevance are uncertain. Focusing on the clustered FL scenario, where devices are grouped based on similarities in their data distributions without prior knowledge of cluster memberships, we develop a mathematical model for pFL using low-rank matrix optimization. Building on this formulation, we propose a pFL approach leveraging the Burer-Monteiro factorization technique. We examine the convergence guarantees of the proposed method and present numerical experiments on training deep neural networks, demonstrating the empirical performance of the proposed method in scenarios where personalization is crucial.},
  archive      = {J_TMLR},
  author       = {Ali Dadras and Sebastian U Stich and Alp Yurtsever},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized federated learning via low-rank matrix optimization},
  url          = {https://openreview.net/forum?id=DFJu1QB2Nr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From spikes to heavy tails: Unveiling the spectral evolution of neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DJHB8eBUnt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training strategies for modern deep neural networks (NNs) tend to induce a heavy-tailed (HT) empirical spectral density (ESD) in the layer weights. While previous efforts have shown that the HT phenomenon correlates with good generalization in large NNs, a theoretical explanation of its occurrence is still lacking. Especially, understanding the conditions which lead to this phenomenon can shed light on the interplay between generalization and weight spectra. Our work aims to bridge this gap by presenting a simple, rich setting to model the emergence of HT ESD. In particular, we present a theory-informed setup for ‘crafting’ heavy tails in the ESD of two-layer NNs and present a systematic analysis of the HT ESD emergence without any gradient noise. This is the first work to analyze a noise-free setting, and we also incorporate optimizer (GD/Adam) dependent (large) learning rates into the HT ESD analysis. Our results highlight the role of learning rates on the Bulk+Spike and HT shape of the ESDs in the early phase of training, which can facilitate generalization in the two-layer NN. These observations shed light on the behavior of large-scale NNs, albeit in a much simpler setting.},
  archive      = {J_TMLR},
  author       = {Vignesh Kothapalli and Tianyu Pang and Shenyang Deng and Zongmin Liu and Yaoqing Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {From spikes to heavy tails: Unveiling the spectral evolution of neural networks},
  url          = {https://openreview.net/forum?id=DJHB8eBUnt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Change point detection on a separable model for dynamic networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DSNJykzHF3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the unsupervised change point detection problem in time series of networks using the Separable Temporal Exponential-family Random Graph Model (STERGM). Inherently, dynamic network patterns are complex due to dyadic and temporal dependence, and change points detection can identify the discrepancies in the underlying data generating processes to facilitate downstream analysis. In particular, the STERGM that utilizes network statistics and nodal attributes to represent the structural patterns is a flexible and parsimonious model to fit dynamic networks. We propose a new estimator derived from the Alternating Direction Method of Multipliers (ADMM) procedure and Group Fused Lasso (GFL) regularization to simultaneously detect multiple time points where the parameters of a time-heterogeneous STERGM have shifted. Experiments on both simulated and real data show good performance of the proposed framework, and an R package CPDstergm is developed to implement the method.},
  archive      = {J_TMLR},
  author       = {Yik Lun Kei and Hangjian Li and Yanzhen Chen and OSCAR HERNAN MADRID PADILLA},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Change point detection on a separable model for dynamic networks},
  url          = {https://openreview.net/forum?id=DSNJykzHF3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilities of chat LLMs are miscalibrated but still predict correctness on multiple-choice Q&A. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=E6LOh5vz5x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study 15 large language models (LLMs) fine-tuned for chat and find that their maximum softmax probabilities (MSPs) are consistently miscalibrated on multiple-choice Q&A. However, those MSPs might still encode useful uncertainty information. Specifically, we hypothesized that wrong answers would be associated with smaller MSPs compared to correct answers. Via rigorous statistical testing, we show that this hypothesis holds for models which perform well on the underlying Q&A task. We also find a strong direction correlation between Q&A accuracy and MSP correctness prediction, while finding no correlation between Q&A accuracy and calibration error. This suggests that within the current fine-tuning paradigm, we can expect correctness prediction but not calibration to improve as LLM capabilities progress. To demonstrate the utility of correctness prediction, we show that when models have the option to abstain, performance can be improved by selectively abstaining based on the MSP of the initial model response, using only a small amount of labeled data to choose the MSP threshold.},
  archive      = {J_TMLR},
  author       = {Benjamin Plaut and Khanh Xuan Nguyen and Tu Trinh},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Probabilities of chat LLMs are miscalibrated but still predict correctness on multiple-choice Q&A},
  url          = {https://openreview.net/forum?id=E6LOh5vz5x},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLaVA-video: Video instruction tuning with synthetic data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EElFGvt39K'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of video large multimodal models (LMMs) has been hindered by the difficulty of curating large amounts of high-quality raw data from the web. To address this, we consider an alternative approach, creating a high-quality synthetic dataset specifically for video instruction-following, namely LLaVA-Video-178K. This dataset includes key tasks such as detailed captioning, open-ended question-answering (QA), and multiple-choice QA. By training on this proposed dataset, in combination with existing visual instruction tuning data, we introduce LLaVA-Video, a new video LMM. Our experiments demonstrate that LLaVA-Video achieves strong performance across various video benchmarks, highlighting the effectiveness of our dataset. We plan to release the dataset, its generation pipeline, and the model checkpoints.},
  archive      = {J_TMLR},
  author       = {Yuanhan Zhang and Jinming Wu and Wei Li and Bo Li and Zejun MA and Ziwei Liu and Chunyuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLaVA-video: Video instruction tuning with synthetic data},
  url          = {https://openreview.net/forum?id=EElFGvt39K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-shot federated distillation using monoclass teachers: A study of knowledge fragmentation and out-of-distribution supervision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ENdm5BM7aF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning models critically depends on the quality and diversity of training data. However, privacy, legal, and proprietary concerns often limit direct data sharing. Many organizations possess high-quality data for specific classes and may wish to share the knowledge derived from it without revealing the data or engaging in collaborative training. While federated learning (FL) enables distributed model training, it typically assumes mutual benefit, requires repeated communication, and produces a shared global model. Another paradigm, knowledge distillation (KD), allows a student model to learn from teacher predictions. We propose a one-shot federated distillation method in which a single client learns from monoclass teacher models trained independently by multiple providers. Each provider shares its model once, and the client combines these with unlabeled data to distill a multiclass student model—aggregating knowledge from disjoint, class-specific sources. This unidirectional, asymmetric setup poses a key challenge: out-of-distribution (OOD) supervision, where monoclass teachers often mispredict unseen inputs, leading to noisy signals for the student. The main contribution of this work is a systematic study of knowledge fragmentation in one-shot federated distillation with monoclass teachers. We evaluate five configurations with varying class coverage per provider and show that increasing fragmentation intensifies OOD supervision, degrading student performance. Experiments on MNIST, FashionMNIST, and CIFAR-10 confirm that fragmentation consistently reduces student accuracy. To mitigate this, we discuss three strategies: (1) exposing teachers to diverse off-class examples, (2) penalizing overconfidence, and (3) using contrastive learning to sharpen feature boundaries.},
  archive      = {J_TMLR},
  author       = {Cedric Maron and Virginie Fresse and ORZALESI},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {One-shot federated distillation using monoclass teachers: A study of knowledge fragmentation and out-of-distribution supervision},
  url          = {https://openreview.net/forum?id=ENdm5BM7aF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). [Re] cooperate or collapse: Emergence of sustainable cooperation in a society of LLM agents. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EWWxSkUchO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are increasingly used in strategic decision-making environments, including game-theoretic scenarios where multiple agents interact under predefined rules. One such setting is the common pool resource environment. In this study, we build upon Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents (Piatti et al., 2024), a framework designed to test cooperation strategies among LLM agents. We begin by replicating their results to a large degree to validate the framework, reproducing the original claims regarding model scale in their simulation environment. Then, we extend the analysis to include models that represent the recent reasoning paradigm: Phi-4, DeepSeek-R1, and one of the distilled variants, which show improvements over their baseline counterparts but come at a higher computational cost. Here, we identify a notable trend: specialized models with reasoning-oriented training outperform general-purpose models of similar scale in this environment. Finally, we investigate the impact of different experiments, including the veil of ignorance mechanism and other prompting strategies based on universalization principles with varying levels of abstraction. Our results suggest that older models benefit significantly from explicit boundary conditions, whereas newer models demonstrate greater robustness to implicit constraints.},
  archive      = {J_TMLR},
  author       = {Oliver van Erven and Konstantinos Zafeirakis and Jacobus Smit and Julio Smidi and Luc Buijs},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {[Re] cooperate or collapse: Emergence of sustainable cooperation in a society of LLM agents},
  url          = {https://openreview.net/forum?id=EWWxSkUchO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence rates of federated Q-learning across heterogeneous environments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EkLAG3gt3g'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-agent systems are often deployed across wide geographic areas, where agents interact with heterogeneous environments. There is an emerging interest in understanding the role of heterogeneity in the performance of the federated versions of classic reinforcement learning algorithms. In this paper, we study synchronous federated Q-learning, which aims to learn an optimal Q-function by having $K$ agents average their local Q-estimates per $E$ iterations. We provide a fine-grained characterization of the error evolution, which decays to zero as the number of iterations $T$ increases. When $K(E-1)$ is below a certain threshold, similar to the homogeneous environment settings, there is a linear speed-up concerning $K$. The slow convergence of having $E>1$ turns out to be fundamental rather than an artifact of our analysis. We prove that, for a wide range of stepsizes, the $\ell_{\infty}$ norm of the error cannot decay faster than $\Theta_R (\frac{E}{(1-\gamma)T})$, where $\Theta_R$ only hides numerical constants and the specific choice of reward values. In addition, our experiments demonstrate that the convergence exhibits an interesting two-phase phenomenon. For any given stepsize, there is a sharp phase transition of the convergence: the error decays rapidly in the beginning yet later bounces up and stabilizes.},
  archive      = {J_TMLR},
  author       = {Muxing Wang and Pengkun Yang and Lili Su},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the convergence rates of federated Q-learning across heterogeneous environments},
  url          = {https://openreview.net/forum?id=EkLAG3gt3g},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BELLA: Black-box model explanations by local linear approximations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F9Kv96KcwM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the decision-making process of black-box models has become not just a legal requirement, but also an additional way to assess their performance. However, the state of the art post-hoc explanation approaches for regression models rely on synthetic data generation, which introduces uncertainty and can hurt the reliability of the explanations. Furthermore, they tend to produce explanations that apply to only very few data points. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. BELLA maximizes the size of the neighborhood to which the linear model applies so that the explanations are accurate, simple, general, and robust.},
  archive      = {J_TMLR},
  author       = {Nedeljko Radulovic and Albert Bifet and Fabian M. Suchanek},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {BELLA: Black-box model explanations by local linear approximations},
  url          = {https://openreview.net/forum?id=F9Kv96KcwM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical language model design for interpretable graph reasoning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F74rZKJXfm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are being increasingly explored for graph tasks. Despite their remarkable success in text-based tasks, LLMs' capabilities in understanding explicit graph structures remain limited, particularly with large graphs. In this work, we introduce Hierarchical Language Model for Graph (HLM-G), which employs a two-block architecture to capture node-centric local information and interaction-centric global structure, effectively enhancing graph structure understanding abilities. The proposed scheme allows LLMs to address various graph queries with high efficacy, efficiency, and robustness, while reducing computational costs on large-scale graph tasks. Furthermore, we demonstrate the interpretability of our model using intrinsic attention weights and established explainers. Comprehensive evaluations across diverse graph reasoning and real-world tasks of node, link, and graph-levels highlight the superiority of our method, marking a significant advancement in the application of LLMs to graph understanding.},
  archive      = {J_TMLR},
  author       = {Sambhav Khurana and Xiner Li and Shurui Gui and Shuiwang Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hierarchical language model design for interpretable graph reasoning},
  url          = {https://openreview.net/forum?id=F74rZKJXfm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLoQ: Enhancing fine-tuning of quantized LLMs via calibrated LoRA initialization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FHnTRAAdAZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has become a highly efficient approach for downstream tasks, particularly in scenarios with limited computational resources. However, applying LoRA techniques to quantized LLMs poses unique challenges due to the reduced representational precision of quantized weights. In this paper, we introduce CLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic initialization strategy designed to overcome these challenges. Our approach focuses on minimizing the layer-wise discrepancy between the original LLM and its quantized counterpart with LoRA components during initialization. By leveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and determines the optimal LoRA components for each layer, ensuring a strong foundation for subsequent fine-tuning. A key contribution of this work is a novel theoretical result that enables the accurate and closed-form construction of these optimal LoRA components. We validate the efficacy of CLoQ across multiple tasks such as language generation, arithmetic reasoning, and commonsense reasoning, demonstrating that it consistently outperforms existing LoRA fine-tuning methods for quantized LLMs, especially at 2-bit.},
  archive      = {J_TMLR},
  author       = {Yanxia Deng and Aozhong Zhang and Selcuk Gurses and Naigang Wang and Zi Yang and Penghang Yin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CLoQ: Enhancing fine-tuning of quantized LLMs via calibrated LoRA initialization},
  url          = {https://openreview.net/forum?id=FHnTRAAdAZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal partial sensing forecast of long-term traffic. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ff08aPjVjD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting uses recent measurements by sensors installed at chosen locations to forecast the future road traffic. Existing work either assumes all locations are equipped with sensors or focuses on short-term forecast. This paper studies partial sensing forecast of long-term traffic, assuming sensors are available only at some locations. The problem is challenging due to the unknown data distribution at unsensed locations, the intricate spatio-temporal correlation in long-term forecasting, as well as noise to traffic patterns. We propose a Spatio-temporal Long-term Partial sensing Forecast model (SLPF) for traffic prediction, with several novel contributions, including a rank-based embedding technique to reduce the impact of noise in data, a spatial transfer matrix to overcome the spatial distribution shift from sensed locations to unsensed locations, and a multi-step training process that utilizes all available data to successively refine the model parameters for better accuracy. Extensive experiments on several real-world traffic datasets demonstrate its superior performance. Our source code is at https://github.com/zbliu98/SLPF},
  archive      = {J_TMLR},
  author       = {Zibo Liu and Zhe Jiang and Zelin Xu and Tingsong Xiao and Zhengkun Xiao and Yupu Zhang and Haibo Wang and Shigang Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Spatio-temporal partial sensing forecast of long-term traffic},
  url          = {https://openreview.net/forum?id=Ff08aPjVjD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient vocabulary-free fine-grained visual recognition in the age of multimodal LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FvA0UMw9X2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained Visual Recognition (FGVR) involves distinguishing between visually similar categories, which is inherently challenging due to subtle inter-class differences and the need for large, expert-annotated datasets. In domains like medical imaging, such curated datasets are unavailable due to issues like privacy concerns and high annotation costs. In such scenarios lacking labeled data, an FGVR model cannot rely on a predefined set of training labels, and hence has an unconstrained output space for predictions. We refer to this task as Vocabulary-Free FGVR (VF-FGVR), where a model must predict labels from an unconstrained output space without prior label information. While recent Multimodal Large Language Models (MLLMs) show potential for VF-FGVR, querying these models for each test input is impractical because of high costs and prohibitive inference times. To address these limitations, we introduce Nearest-Neighbor label Refinement (NeaR), a novel approach that fine-tunes a downstream CLIP model using labels generated by an MLLM. Our approach constructs a weakly supervised dataset from a small, unlabeled training set, leveraging MLLMs for label generation. NeaR is designed to handle the noise, stochasticity, and open-endedness inherent in labels generated by MLLMs, and establishes a new benchmark for efficient VF-FGVR.},
  archive      = {J_TMLR},
  author       = {Hari Chandana Kuchibhotla and Sai Srinivas Kancheti and Abbavaram Gowtham Reddy and Vineeth N. Balasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient vocabulary-free fine-grained visual recognition in the age of multimodal LLMs},
  url          = {https://openreview.net/forum?id=FvA0UMw9X2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can masked autoencoders also listen to birds?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GIBWR0Xo2J'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked Autoencoders (MAEs) learn rich representations in audio classification through an efficient self-supervised reconstruction task. Yet, general-purpose models struggle in fine-grained audio domains such as bird sound classification, which demands distinguishing subtle inter-species differences under high intra-species variability. We show that bridging this domain gap requires full-pipeline adaptation beyond domain-specific pretraining data. Using BirdSet, a large-scale bioacoustic benchmark, we systematically adapt pretraining, fine-tuning, and frozen feature utilization. Our Bird-MAE sets new state-of-the-art results on BirdSet’s multi-label classification benchmark. Additionally, we introduce the parameter-efficient prototypical probing, which boosts the utility of frozen MAE features by achieving up to 37 mAP points over linear probes and narrowing the gap to fine-tuning in low-resource settings. Bird-MAE also exhibits strong few-shot generalization with prototypical probes on our newly established few-shot benchmark on BirdSet, underscoring the importance of tailored self-supervised learning pipelines for fine-grained audio domains.},
  archive      = {J_TMLR},
  author       = {Lukas Rauch and René Heinrich and Ilyass Moummad and Alexis Joly and Bernhard Sick and Christoph Scholz},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Can masked autoencoders also listen to birds?},
  url          = {https://openreview.net/forum?id=GIBWR0Xo2J},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the role of discrete representation in sparse mixture of experts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GTWKmojpI7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Mixture of Experts (SMoE) is an effective solution for scaling up model capacity without increasing the computational costs. A crucial component of SMoE is the router, responsible for directing the input to relevant experts; however, it also presents a major weakness, leading to routing inconsistencies and representation collapse issues. Instead of fixing the router like previous works, we propose an alternative that assigns experts to input via \emph{indirection}, which employs the discrete representation of input that points to the expert. The discrete representations are learned via vector quantization, resulting in a new architecture dubbed Vector-Quantized Mixture of Experts (VQMoE). We provide theoretical support and empirical evidence demonstrating the VQMoE's ability to overcome the challenges present in traditional routers. Through extensive evaluations on both large language models and vision tasks for pre-training and fine-tuning, we show that VQMoE achieves a 28\% improvement in robustness compared to other SMoE routing methods while maintaining strong performance in fine-tuning tasks.},
  archive      = {J_TMLR},
  author       = {Giang Do and Kha Pham and Hung Le and Truyen Tran},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the role of discrete representation in sparse mixture of experts},
  url          = {https://openreview.net/forum?id=GTWKmojpI7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified approach towards active learning and out-of-distribution detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HL75La10FN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications of deep learning models, active learning (AL) strategies are essential for identifying label candidates from vast amounts of unlabeled data. In this context, robust out-of-distribution (OOD) detection mechanisms are crucial for handling data out- side the target distribution during the application’s operation. Usually, these problems have been addressed separately. In this work, we introduce SISOM as a unified solution designed explicitly for AL and OOD detection. By combining feature space-based and uncertainty- based metrics, SISOM leverages the strengths of the currently independent tasks to solve both effectively, without requiring specific training schemes. We conducted extensive experiments showing the problems arising when migrating between both tasks. In our experiments SISOM underlined its effectiveness by achieving first place in one of the commonly used OpenOOD benchmark settings and top-3 places in the remaining two for near-OOD data. In AL, SISOM delivers top performance in common image benchmarks.},
  archive      = {J_TMLR},
  author       = {Sebastian Schmidt and Leonard Schenk and Leo Schwinn and Stephan Günnemann},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified approach towards active learning and out-of-distribution detection},
  url          = {https://openreview.net/forum?id=HL75La10FN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentiable causal discovery of linear non-gaussian acyclic models under unmeasured confounding. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HR7MFlW73I'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a score-based method that extends the framework of the linear non- Gaussian acyclic model (LiNGAM) to address the problem of causal structure estimation in the presence of unmeasured variables. Building on the method pro- posed by Bhattacharya et al. (2021), we develop a method called ABIC LiNGAM, which assumes that error terms follow a multivariate generalized normal distribu- tion and employs continuous optimization techniques to recover acyclic directed mixed graphs (ADMGs). We demonstrate that the proposed method can esti- mate causal structures, including the possibility of identifying their orientations, rather than only Markov equivalence classes, under the assumption that the data are linear and follow a multivariate generalized normal distribution. Additionally, we provide proofs of the identifiability of the parameters in ADMGs when the er- ror terms follow a multivariate generalized normal distribution. The effectiveness of the proposed method is validated through simulations and experiments using real-world data.},
  archive      = {J_TMLR},
  author       = {Yoshimitsu Morinishi and Shohei Shimizu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentiable causal discovery of linear non-gaussian acyclic models under unmeasured confounding},
  url          = {https://openreview.net/forum?id=HR7MFlW73I},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stop overthinking: A survey on efficient reasoning for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HvoG8SxggZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks. Recent advancements in Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have further improved performance in System-2 reasoning domains like mathematics and programming by harnessing supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance Chain-of-Thought (CoT) reasoning. However, while longer CoT reasoning sequences improve performance, they also introduce significant computational overhead due to lengthy and redundant outputs, known as the ''overthinking phenomenon''. Efficient Reasoning, which seeks to optimize reasoning length while preserving reasoning capabilities, offers practical benefits such as faster processing times, lower energy consumption, and improved responsiveness, especially valuable for reasoning-intensive applications. Despite its potential, efficient reasoning remains in the early stages of research. In this paper, we provide the first structured survey to systematically investigate and explore the current progress toward achieving efficient reasoning in LLMs. Overall, relying on the inherent mechanism of LLMs, we categorize existing works into several key directions: (1) model-based efficient reasoning, which considers optimizing full-length reasoning models into more concise reasoning models or directly training efficient reasoning models; (2) reasoning output-based efficient reasoning, which aims to dynamically reduce reasoning steps and length during inference; (3) input prompts-based efficient reasoning, which seeks to enhance reasoning efficiency based on input prompt properties such as difficulty or length control. Additionally, we introduce the use of efficient data for training reasoning models, explore the reasoning capabilities of small language models, and discuss evaluation methods and benchmarking.},
  archive      = {J_TMLR},
  author       = {Yang Sui and Yu-Neng Chuang and Guanchu Wang and Jiamu Zhang and Tianyi Zhang and Jiayi Yuan and Hongyi Liu and Andrew Wen and Shaochen Zhong and Na Zou and Hanjie Chen and Xia Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stop overthinking: A survey on efficient reasoning for large language models},
  url          = {https://openreview.net/forum?id=HvoG8SxggZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated black-box prompt engineering for personalized text-to-image generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IVYVDN6pJ6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt engineering is an effective but labor-intensive way to control text-to-image (T2I) generative models. Its time-intensive nature and complexity have spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, or produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically produces human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompt distribution built upon the reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, styles, and images across multiple T2I models, including Stable Diffusion, DALL-E, and Midjourney.},
  archive      = {J_TMLR},
  author       = {Yutong He and Alexander Robey and Naoki Murata and Yiding Jiang and Joshua Nathaniel Williams and George J. Pappas and Hamed Hassani and Yuki Mitsufuji and Ruslan Salakhutdinov and J Zico Kolter},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Automated black-box prompt engineering for personalized text-to-image generation},
  url          = {https://openreview.net/forum?id=IVYVDN6pJ6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factor learning portfolio optimization informed by continuous-time finance models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KLOJUGusVE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study financial portfolio optimization in the presence of unknown and uncontrolled system variables referred to as stochastic factors. Existing work falls into two distinct categories: (i) reinforcement learning employs end-to-end policy learning with flexible factor representation, but does not precisely model the dynamics of asset prices or factors; (ii) continuous-time finance methods, in contrast, take advantage of explicitly modeled dynamics but pre-specify, rather than learn, factor representation. We propose FaLPO (factor learning portfolio optimization), a framework that interpolates between these two approaches. Specifically, FaLPO hinges on deep policy gradient to learn a performant investment policy that takes advantage of flexible representation for stochastic factors. Meanwhile, FaLPO also incorporates continuous-time finance models when modeling the dynamics. It uses the optimal policy functional form derived from such models and optimizes an objective that combines policy learning and model calibration. We prove the convergence of FaLPO and provide performance guarantees via a finite-sample bound. On both synthetic and real-world portfolio optimization tasks, we observe that FaLPO outperforms five leading methods. Finally, we show that FaLPO can be extended to other decision-making problems with stochastic factors.},
  archive      = {J_TMLR},
  author       = {Sinong Geng and houssam nassif and Zhaobin Kuang and Anders Max Reppen and K. Ronnie Sircar},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Factor learning portfolio optimization informed by continuous-time finance models},
  url          = {https://openreview.net/forum?id=KLOJUGusVE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReHub: Linear complexity graph transformers with adaptive hub-spoke reassignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=L4S54TUOQR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present ReHub, a novel graph transformer architecture that achieves linear complexity through an efficient reassignment technique between nodes and virtual nodes. Graph transformers have become increasingly important in graph learning for their ability to utilize long-range node communication explicitly, addressing limitations such as oversmoothing and oversquashing found in message-passing graph networks. However, their dense attention mechanism scales quadratically with the number of nodes, limiting their applicability to large-scale graphs. ReHub draws inspiration from the airline industry's hub-and-spoke model, where flights are assigned to optimize operational efficiency. In our approach, graph nodes (spokes) are dynamically reassigned to a fixed number of virtual nodes (hubs) at each model layer. Recent work, Neural Atoms (Li et al., 2024), has demonstrated impressive and consistent improvements over GNN baselines by utilizing such virtual nodes; their findings suggest that the number of hubs strongly influences performance. However, increasing the number of hubs typically raises complexity, requiring a trade-off to maintain linear complexity. Our key insight is that each node only needs to interact with a small subset of hubs to achieve linear complexity, even when the total number of hubs is large. To leverage all hubs without incurring additional computational costs, we propose a simple yet effective adaptive reassignment technique based on hub-hub similarity scores, eliminating the need for expensive node-hub computations. Our experiments on long-range graph benchmarks indicate a consistent improvement in results over the base method, Neural Atoms, while maintaining a linear complexity instead of $O(n^{3/2})$. Remarkably, our sparse model achieves performance on par with its non-sparse counterpart. Furthermore, ReHub outperforms competitive baselines and consistently ranks among the top performers across various benchmarks.},
  archive      = {J_TMLR},
  author       = {Tomer Borreda and Daniel Freedman and Or Litany},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ReHub: Linear complexity graph transformers with adaptive hub-spoke reassignment},
  url          = {https://openreview.net/forum?id=L4S54TUOQR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering group dynamics in coordinated time series via hierarchical recurrent switching-state models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LHchZthcOf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We seek a computationally efficient model for a collection of time series arising from multiple interacting entities (a.k.a. "agents"). Recent models of temporal patterns across individuals fail to incorporate explicit system-level collective behavior that can influence the trajectories of individual entities. To address this gap in the literature, we present a new hierarchical switching-state model that can be trained in an unsupervised fashion to simultaneously learn both system-level and individual-level dynamics. We employ a latent system-level discrete state Markov chain that provides top-down influence on latent entity-level chains which in turn govern the emission of each observed time series. Recurrent feedback from the observations to the latent chains at both entity and system levels allows recent situational context to inform how dynamics unfold at all levels in bottom-up fashion. We hypothesize that including both top-down and bottom-up influences on group dynamics will improve interpretability of the learned dynamics and reduce error when forecasting. Our hierarchical switching recurrent dynamical model can be learned via closed-form variational coordinate ascent updates to all latent chains that scale linearly in the number of entities. This is asymptotically no more costly than fitting a separate model for each entity. Analysis of both synthetic data and real basketball team movements suggests our lean parametric model can achieve competitive forecasts compared to larger neural network models that require far more computational resources. Further experiments on soldier data as well as a synthetic task with 64 cooperating entities show how our approach can yield interpretable insights about team dynamics over time.},
  archive      = {J_TMLR},
  author       = {Michael Wojnowicz and Kaitlin Gili and Preetish Rath and Eric Miller and Jeffrey W. Miller and Clifford Lee Hancock and Meghan O'Donovan and Seth Elkin-Frankston and Tad Brunye and Michael C Hughes},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Discovering group dynamics in coordinated time series via hierarchical recurrent switching-state models},
  url          = {https://openreview.net/forum?id=LHchZthcOf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cost efficiency in active learning with candidate set query. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LhHxl30xQ1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a cost-efficient active learning (AL) framework for classification, featuring a novel query design called candidate set query. Unlike traditional AL queries requiring the oracle to examine all possible classes, our method narrows down the set of candidate classes likely to include the ground-truth class, significantly reducing the search space and labeling cost. Moreover, we leverage conformal prediction to dynamically generate small yet reliable candidate sets, adapting to model enhancement over successive AL rounds. To this end, we introduce an acquisition function designed to prioritize data points that offer high information gain at lower cost. Empirical evaluations on CIFAR-10, CIFAR-100, and ImageNet64x64 demonstrate the effectiveness and scalability of our framework. Notably, it reduces labeling cost by 48% on ImageNet64x64. The project page can be found at https://yehogwon.github.io/csq-al.},
  archive      = {J_TMLR},
  author       = {Yeho Gwon and Sehyun Hwang and Hoyoung Kim and Jungseul Ok and Suha Kwak},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing cost efficiency in active learning with candidate set query},
  url          = {https://openreview.net/forum?id=LhHxl30xQ1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On time series clustering with graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MHQXfiXsr3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering and pooling operators have been adopted in graph-based architectures to capture meaningful patterns in time series data by leveraging both temporal and relational structures. However, the contribution of each design choice and the behavior of different operators remain underexplored. This work introduces a streamlined deep learning framework based on a spatio-temporal graph neural network (STGNN) for clustering time series, which can leverage prior knowledge on the spatial structure of the data. The STGNN-based model flexibly identifies clusters in various data settings through an encoder-decoder architecture with a bottleneck, showing that a spatio-temporal approach can identify meaningful clusters even in datasets that do not explicitly include spatial relations. We validate the framework’s qualitative performance through experiments on synthetic and real-world data, showing its effectiveness in different scenarios. We also provide a heuristic for model selection in unsupervised settings via a self-supervised forecasting loss. Code is available at https://github.com/NGMLGroup/Time-Series-Clustering-with-GNNs},
  archive      = {J_TMLR},
  author       = {Jonas Berg Hansen and Andrea Cini and Filippo Maria Bianchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On time series clustering with graph neural networks},
  url          = {https://openreview.net/forum?id=MHQXfiXsr3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shared imagination: LLMs hallucinate alike. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NUXpBMtDYs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent proliferation of large language models (LLMs), their training recipes -- model architecture, pre-training data and optimization algorithm -- are often very similar. This naturally raises the question of the similarity among the resulting models. In this paper, we propose a novel setting, imaginary question answering (IQA), to better understand model similarity. In IQA, we ask one model to generate purely imaginary questions (e.g., on completely made-up concepts in physics) and prompt another model to answer. Surprisingly, despite the total fictionality of these questions, all models can answer each other's questions with remarkable consistency, suggesting a "shared imagination space" in which these models operate during such hallucinations. We conduct a series of investigations into this phenomenon and discuss the implications of such model homogeneity on hallucination detection and computational creativity.},
  archive      = {J_TMLR},
  author       = {Yilun Zhou and Caiming Xiong and Silvio Savarese and Chien-Sheng Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shared imagination: LLMs hallucinate alike},
  url          = {https://openreview.net/forum?id=NUXpBMtDYs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying self-supervised clustering and energy-based models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NW0uKe6IZa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning excels at learning representations from large amounts of data. At the same time, generative models offer the complementary property of learning information about the underlying data generation process. In this study, we aim at establishing a principled connection between these two paradigms and highlight the benefits of their complementarity. In particular, we perform an analysis of self-supervised learning objectives, elucidating the underlying probabilistic graphical models and presenting a standardized methodology for their derivation from first principles. The analysis suggests a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a lower bound proven to reliably penalize the most important failure modes and unlocking full unification. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, demonstrating that our objective function allows to jointly train a backbone network in a discriminative and generative fashion, consequently outperforming existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that the solution can be integrated into a neuro-symbolic framework to tackle a simple yet non-trivial instantiation of the symbol grounding problem.},
  archive      = {J_TMLR},
  author       = {Emanuele Sansone and Robin Manhaeve},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unifying self-supervised clustering and energy-based models},
  url          = {https://openreview.net/forum?id=NW0uKe6IZa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the challenges and opportunities in generative AI. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NeS9Kj2JwF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of deep generative modeling has grown rapidly in the last few years. With the availability of massive amounts of training data coupled with advances in scalable unsupervised learning paradigms, recent large-scale generative models show tremendous promise in synthesizing high-resolution images and text, as well as structured data such as videos and molecules. However, we argue that current large-scale generative AI models exhibit several fundamental shortcomings that hinder their widespread adoption across domains. In this work, our objective is to identify these issues and highlight key unresolved challenges in modern generative AI paradigms that should be addressed to further enhance their capabilities, versatility, and reliability. By identifying these challenges, we aim to provide researchers with insights for exploring fruitful research directions, thus fostering the development of more robust and accessible generative AI solutions.},
  archive      = {J_TMLR},
  author       = {Laura Manduchi and Clara Meister and Kushagra Pandey and Robert Bamler and Ryan Cotterell and Sina Däubener and Sophie Fellenz and Asja Fischer and Thomas Gärtner and Matthias Kirchler and Marius Kloft and Yingzhen Li and Christoph Lippert and Gerard de Melo and Eric Nalisnick and Björn Ommer and Rajesh Ranganath and Maja Rudolph and Karen Ullrich and Guy Van den Broeck and Julia E Vogt and Yixin Wang and Florian Wenzel and Frank Wood and Stephan Mandt and Vincent Fortuin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the challenges and opportunities in generative AI},
  url          = {https://openreview.net/forum?id=NeS9Kj2JwF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hodge-aware convolutional learning on simplicial complexes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Nm5sp09Q25'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks on simplicial complexes (SCs) can learn representations from data residing on simplices such as nodes, edges, triangles, etc. However, existing works often overlook the Hodge theorem that decomposes simplicial data into three orthogonal characteristic subspaces, such as the identifiable gradient, curl and harmonic components of edge flows. This provides a universal tool to understand the machine learning models on SCs, thus, allowing for better principled and effective learning. In this paper, we study the effect of this data inductive bias on learning on SCs via the principle of convolutions. Particularly, we present a general convolutional architecture that respects the three key principles of uncoupling the lower and upper simplicial adjacencies, accounting for the inter-simplicial couplings, and performing higher-order convolutions. To understand these principles, we first use Dirichlet energy minimizations on SCs to interpret their effects on mitigating simplicial oversmoothing. Then, we show the three principles promote the Hodge-aware learning of this architecture, through the lens of spectral simplicial theory, in the sense that the three Hodge subspaces are invariant under its learnable functions and the learning in two nontrivial subspaces is independent and expressive. Third, we investigate the learning ability of this architecture in optic of perturbation theory on simplicial topologies and prove that the convolutional architecture is stable to small perturbations. Finally, we corroborate the three principles by comparing with methods that either violate or do not respect them. Overall, this paper bridges learning on SCs with the Hodge theorem, highlighting its importance for rational and effective learning from simplicial data, and provides theoretical insights to convolutional learning on SCs.},
  archive      = {J_TMLR},
  author       = {Maosheng Yang and Geert Leus and Elvin Isufi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hodge-aware convolutional learning on simplicial complexes},
  url          = {https://openreview.net/forum?id=Nm5sp09Q25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RefDeblur: Blind motion deblurring with self-generated reference image. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Nyewu7xztw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of blind motion deblurring is often tackled via two distinct paradigms: kernel-based and kernel-free methods. Each deblurring method provides inherent strengths. Kernel-based methods facilitate generating texture-detailed sharp images by closely aligning with the blurring process. In contrast, kernel-free methods are more effective in handling complex blur patterns. Building upon these complementary benefits, we propose a hybrid framework that decomposes a non-uniform deblurring task into two simpler tasks: a uniform kernel estimation, managed by our kernel-based method, and error prediction, handled by our kernel-free method. Our kernel-based method serves to generate a reference image with realistic texture details while our kernel-free model refines the reference image by correcting residual errors with preserving texture details. To efficiently build our kernel-based model, we consider the logarithmic fourier space that facilitates estimating a blur kernel easier by simplifying the relationship between blur and sharp samples. Furthermore, the regime under using a texture-detailed reference image allows for reducing the size of our kernel-free model without compromising performance. As a result, the proposed method achieves remarkable performance on several datasets such as RealBlur, RSBlur and GoPro, and comparable performance to state-of-the-art methods with a 75% reduction in computational costs.},
  archive      = {J_TMLR},
  author       = {Insoo Kim and Geonseok Seo and Hyong-Euk Lee and Jinwoo Shin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RefDeblur: Blind motion deblurring with self-generated reference image},
  url          = {https://openreview.net/forum?id=Nyewu7xztw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sortability of time series data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OGvmCpcHdV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the performance of causal discovery algorithms that aim to find causal relationships between time-dependent processes remains a challenging topic. In this paper, we show that certain characteristics of datasets, such as varsortability (Reisach et al. 2021) and R2-sortability (Reisach et al. 2023), also occur in datasets for autocorrelated stationary time series. We illustrate this empirically using four types of data: simulated data based on SVAR models and Erdős-Rényi graphs, the data used in the 2019 causality-for-climate challenge (Runge et al. 2019), real-world river stream datasets, and real-world data generated by the Causal Chamber of (Gamella et al. 2024). To do this, we adapt var- and R2-sortability to time series data. We also investigate the extent to which the performance of continuous score-based causal discovery methods goes hand in hand with high sortability. Arguably, our most surprising finding is that the investigated real-world datasets exhibit high varsortability and low R2-sortability indicating that scales may carry a significant amount of causal information.},
  archive      = {J_TMLR},
  author       = {Christopher Lohse and Jonas Wahl},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sortability of time series data},
  url          = {https://openreview.net/forum?id=OGvmCpcHdV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How does overparametrization affect performance on minority groups?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=POunezXgvF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The benefits of overparameterization for the overall performance of modern machine learning (ML) models are well known. However, the effect of overparameterization at a more granular level of data subgroups is less understood. Recent empirical studies demonstrate encouraging results: (i) when groups are not known, overparameterized models trained with empirical risk minimization (ERM) perform better on minority groups; (ii) when groups are known, ERM on data subsampled to equalize group sizes yields state-of-the-art worst-group accuracy in the overparameterized regime. In this paper, we complement these empirical studies with a theoretical investigation of the risk of overparameterized random feature regression models on minority groups with identical feature distribution as the majority group. In a setting in which the regression functions for the majority and minority groups are different, we show that overparameterization either improves or does not harm the asymptotic minority group performance under the ERM setting when the features are distributed uniformly over the sphere.},
  archive      = {J_TMLR},
  author       = {Saptarshi Roy and Subha Maity and Songkai Xue and Mikhail Yurochkin and Yuekai Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How does overparametrization affect performance on minority groups?},
  url          = {https://openreview.net/forum?id=POunezXgvF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and cost-effective speculative edge-cloud decoding with early exits. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PTIUjARnbc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) enable various applications on edge devices such as smartphones, wearables, and embodied robots. However, their deployment often depends on expensive cloud-based APIs, creating high operational costs, which limit access for smaller organizations and raise sustainability concerns. Certain LLMs can be deployed on-device, offering a cost-effective solution with reduced latency and improved privacy. Yet, limited computing resources constrain the size and accuracy of models that can be deployed, necessitating a collaborative design between edge and cloud. We propose a fast and cost-effective speculative edge-cloud decoding framework with a large target model on the server and a small draft model on the device. By introducing early exits in the target model, tokens are generated mid-verification, allowing the client to preemptively draft subsequent tokens before final verification, thus utilizing idle time and enhancing parallelism between edge and cloud. Using an NVIDIA Jetson Nano (client) and an A100 GPU (server) with Vicuna-68M (draft) and Llama2-7B (target) models, our method achieves up to a 35% reduction in latency compared to cloud-based autoregressive decoding, with an additional 11% improvement from preemptive drafting. To demonstrate real-world applicability, we deploy our method on the Unitree Go2 quadruped robot using Vision-Language Model (VLM) based control, achieving a 21% speedup over traditional cloud-based autoregressive decoding. These results demonstrate the potential of our framework for real-time LLM and VLM applications on resource-constrained edge devices.},
  archive      = {J_TMLR},
  author       = {Yeshwanth Venkatesha and Souvik Kundu and Priyadarshini Panda},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fast and cost-effective speculative edge-cloud decoding with early exits},
  url          = {https://openreview.net/forum?id=PTIUjARnbc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the robustness of language models for tabular question answering via attention analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PYHIDN9Wuq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs), already shown to ace various unstructured text comprehension tasks, have also remarkably been shown to tackle table (structured) comprehension tasks without specific training. Building on earlier studies of LLMs for tabular tasks, we probe how in-context learning (ICL), model scale, instruction tuning, and domain bias affect Tabular QA (TQA) robustness by testing LLMs, under diverse augmentations and perturbations, on diverse domains: Wikipedia-based $\textbf{WTQ}$, financial $\textbf{TAT-QA}$, and scientific $\textbf{SCITAB}$. Although instruction tuning and larger, newer LLMs deliver stronger, more robust TQA performance, data contamination and reliability issues, especially on $\textbf{WTQ}$, remain unresolved. Through an in-depth attention analysis, we reveal a strong correlation between perturbation-induced shifts in attention dispersion and the drops in performance, with sensitivity peaking in the model's middle layers. We highlight the need for improved interpretable methodologies to develop more reliable LLMs for table comprehension. Through an in-depth attention analysis, we reveal a strong correlation between perturbation-induced shifts in attention dispersion and performance drops, with sensitivity peaking in the model's middle layers. Based on these findings, we argue for the development of structure-aware self-attention mechanisms and domain-adaptive processing techniques to improve the transparency, generalization, and real-world reliability of LLMs on tabular data.},
  archive      = {J_TMLR},
  author       = {Kushal Raj Bhandari and Sixue Xing and Soham Dan and Jianxi Gao},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring the robustness of language models for tabular question answering via attention analysis},
  url          = {https://openreview.net/forum?id=PYHIDN9Wuq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering-based validation splits for model selection under domain shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q692C0WtiD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of model selection under domain shift. Motivated by principles from distributionally robust optimisation and domain adaptation theory, it is proposed that the training-validation split should maximise the distribution mismatch between the two sets. By adopting the maximum mean discrepancy (MMD) as the measure of mismatch, it is shown that the partitioning problem reduces to kernel k-means clustering. A constrained clustering algorithm, which leverages linear programming to control the size, label, and (optionally) group distributions of the splits, is presented. The algorithm does not require additional metadata, and comes with convergence guarantees. In experiments, the technique consistently outperforms alternative splitting strategies across a range of datasets and training algorithms, for both domain generalisation and unsupervised domain adaptation tasks. Analysis also shows the MMD between the training and validation sets to be well-correlated with test domain accuracy, further substantiating the validity of this approach.},
  archive      = {J_TMLR},
  author       = {Andrea Napoli and Paul White},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Clustering-based validation splits for model selection under domain shift},
  url          = {https://openreview.net/forum?id=Q692C0WtiD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Table foundation models: On knowledge pre-training for tabular learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QV4P8Csw17'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Table foundation models bring high hopes to data science: pre-trained on tabular data to embark knowledge or priors, they should facilitate downstream tasks on tables. One specific challenge is that of data semantics: numerical entries take their meaning from context, *e.g.*, column name. The traditional approach combines column-specific data preparation with tree-based models that adapt to column specificities. Pre-trained neural networks that jointly model column names and table entries have recently boosted prediction accuracy. While these models outline the promises of world knowledge to interpret table values, they lack the convenience of popular foundation models in text or vision. Indeed, they must be fine-tuned to bring benefits, come with sizeable computation costs, and cannot easily be reused or combined with other architectures. Here we introduce TARTE, a foundation model that transforms tables to knowledge-enhanced vector representations using the string to capture semantics. Pre-trained on large relational data, TARTE yields representations that facilitate subsequent learning with little additional cost. These representations can be fine-tuned or combined with other learners, giving models that push the state-of-the-art prediction performance and improve the prediction/computation performance trade-off. Specialized to a task or a domain, TARTE gives domain-specific representations that facilitate further learning. Our study demonstrates an effective approach to knowledge pre-training for tabular learning.},
  archive      = {J_TMLR},
  author       = {Myung Jun Kim and Félix Lefebvre and Gaëtan Brison and Alexandre Perez-Lebel and Gaël Varoquaux},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Table foundation models: On knowledge pre-training for tabular learning},
  url          = {https://openreview.net/forum?id=QV4P8Csw17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2SSP: A two-stage framework for structured pruning of LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Qd7LzJBg21'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25%, 37.5%, and 50%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time.},
  archive      = {J_TMLR},
  author       = {Fabrizio Sandri and Elia Cunegatti and Giovanni Iacca},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {2SSP: A two-stage framework for structured pruning of LLMs},
  url          = {https://openreview.net/forum?id=Qd7LzJBg21},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABC: Achieving better control of visual embeddings using VLLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RezANmBpxW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual embedding models excel at zero-shot tasks like visual retrieval and classification. However, these models cannot be used for tasks that contain ambiguity or require user in- struction. These tasks necessitate an embedding model which outputs can use a natural language instruction to control the representation of a visual embedding. Existing CLIP- based approaches embed images and text independently, and fuse the result. We find that this results in weak interactions between modalities, and poor user control over the repre- sentation. We introduce ABC, an open-source multimodal embedding model that uses a vision-language model backbone to deeply integrate image features with natural language instructions. ABC achieves best-for-size performance on MSCOCO image-to-text retrieval and is the top performing model on classification and VQA tasks in the Massive Multimodal Embedding Benchmark. With a strongly unified vision-language representation, ABC can use natural language to solve subtle and potentially ambiguous visual retrieval problems. To evaluate this capability, we design CtrlBench, a benchmark that requires interleaving tex- tual instructions with image content for correct retrieval. ABC advances the state of visual embeddings, outputting high-quality visual representations with natural language control. Our model and datasets are available at our project page: https://tiger-ai-lab.github.io/ABC/},
  archive      = {J_TMLR},
  author       = {Benjamin Schneider and Florian Kerschbaum and Wenhu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ABC: Achieving better control of visual embeddings using VLLMs},
  url          = {https://openreview.net/forum?id=RezANmBpxW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressed decentralized momentum stochastic gradient methods for nonconvex optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RqhMQHHkB4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design two compressed decentralized algorithms for solving nonconvex stochastic optimization under two different scenarios. Both algorithms adopt a momentum technique to achieve fast convergence and a message-compression technique to save communication costs. Though momentum acceleration and compressed communication have been used in literature, it is highly nontrivial to theoretically prove the effectiveness of their composition in a decentralized algorithm that can maintain the benefits of both sides, because of the need to simultaneously control the consensus error, the compression error, and the bias from the momentum gradient. For the scenario where gradients are bounded, our proposal is a compressed decentralized adaptive method. To the best of our knowledge, this is the first decentralized adaptive stochastic gradient method with compressed communication. For the scenario of data heterogeneity without bounded gradients, our proposal is a compressed decentralized heavy-ball method, which applies a gradient tracking technique to address the challenge of data heterogeneity. Notably, both methods achieve an optimal convergence rate, and they can achieve linear speed up and adopt topology-independent algorithmic parameters within a certain regime of the user-specified error tolerance. Superior empirical performance is observed over state-of-the-art methods on training deep neural networks (DNNs) and Transformers.},
  archive      = {J_TMLR},
  author       = {Wei Liu and Anweshit Panda and Ujwal Pandey and Christopher Brissette and Yikang Shen and George Slota and Naigang Wang and Jie Chen and Yangyang Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Compressed decentralized momentum stochastic gradient methods for nonconvex optimization},
  url          = {https://openreview.net/forum?id=RqhMQHHkB4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random erasing vs. model inversion: A promising defense or a false hope?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=S9CwKnPHaO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model Inversion (MI) attacks pose a significant privacy threat by reconstructing private training data from machine learning models. While existing defenses primarily concentrate on model-centric approaches, the impact of data on MI robustness remains largely unexplored. In this work, we explore Random Erasing (RE)—a technique traditionally used for improving model generalization under occlusion—and uncover its surprising effectiveness as a defense against MI attacks. Specifically, our novel feature space analysis shows that model trained with RE-images introduces a significant discrepancy between the features of MI-reconstructed images and those of the private data. At the same time, features of private images remain distinct from other classes and well-separated from different classification regions. These effects collectively degrade MI reconstruction quality and attack accuracy while maintaining reasonable natural accuracy. Furthermore, we explore two critical properties of RE including Partial Erasure and Random Location. First, Partial Erasure prevents the model from observing entire objects during training, and we find that this has significant impact on MI, which aims to reconstruct the entire objects. Second, the Random Location of erasure plays a crucial role in achieving a strong privacy-utility trade-off. Our findings highlight RE as a simple yet effective defense mechanism that can be easily integrated with existing privacy-preserving techniques. Extensive experiments of 37 setups demonstrate that our method achieves SOTA performance in privacy-utility tradeoff. The results consistently demonstrate the superiority of our defense over existing defenses across different MI attacks, network architectures, and attack configurations. For the first time, we achieve significant degrade in attack accuracy without decrease in utility for some configurations. Our code and additional results are available at: https://ngoc-nguyen-0.github.io/MIDRE/},
  archive      = {J_TMLR},
  author       = {Viet-Hung Tran and Ngoc-Bao Nguyen and Son T. Mai and Hans Vandierendonck and Ira Assent and Alex Kot and Ngai-Man Cheung},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Random erasing vs. model inversion: A promising defense or a false hope?},
  url          = {https://openreview.net/forum?id=S9CwKnPHaO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining confident black-box predictions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SAwZpgKJcc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability is crucial for leveraging predictive machine learning for decision-making, but the strongest performing models are often black-boxes in that they are difficult to understand. For binary classification models, a growing body of literature seeks to find \textit{model-agnostic} explanations by treating a model as a list of 0/1 predictions and identifying patterns for when a model predicts $1$ over $0$ (or vice versa). While such explanations are useful for understanding when a model predicts 1 over 0, they do not consider the confidence (i.e., the probability) behind predictions, a critical piece of information provided by most classification models. Since the 0/1 predictions of a model depend on the choice of a subjective threshold for discretizing predicted probabilities, as one changes the threshold, the resulting explanations may change despite the underlying model staying the same. In contrast, this work proposes model-agnostic explanations that treat a black-box model as a \textit{ranking} across a dataset from lowest predicted probability of $1$ to highest, rather than a list of 0/1 predictions. Under this ranking, a useful explanation should capture broadly when a model \textit{confidently} predicts $1$ (i.e., highly ranked data points). Since highly confident predictions are often correlated with predictions that are more accurate and actionable, understanding when a model predicts confidently is often quite valuable to a practitioner. This work builds explanations based on rule lists (i.e., a collection of if-then rules) as well as a novel special case called checklists. A strong rule list or checklist is satisfied by a large number of data points that are ranked highly by the model. This criteria is measured by the traditional metric of support (i.e., the number of data points an explanation applies to), the \textit{average} ranking of those data points, which we call the Average Black-Box Ranking (ABBR), as well as the sparsity of the explanation (e.g., number of rules in the rule list, among others). Given these metrics, this work develops a local-search based optimization methodology for finding explanations based on rule lists and checklists that maximize ABBR for a user-specified support and sparsity constraint. The methodology leverages a local search approach where an initial rule list is chosen greedily from a pool of candidate rules, then slowly perturbed by swapping rules from the rule list with those in the candidate pool. This approach is evaluated on 6 real world datasets in application areas ranging from healthcare to criminal justice and finance. Empirical results suggest that this methodology finds rule lists of length at most 5 with ABBR within 7.4\% of the optimal ABBR of any explanation, while checklists provide greater interpretability for a small cost in performance.},
  archive      = {J_TMLR},
  author       = {Evan Yao and Retsef Levi and Assaf Avrahami and Abraham Meidan},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining confident black-box predictions},
  url          = {https://openreview.net/forum?id=SAwZpgKJcc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional gaussian process regression with soft kernel interpolation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=U9b2FIjvWU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Soft Kernel Interpolation (SoftKI), a method that combines aspects of Structured Kernel Interpolation (SKI) and variational inducing point methods, to achieve scalable Gaussian Process (GP) regression on high-dimensional datasets. SoftKI approximates a kernel via softmax interpolation from a smaller number of interpolation points learned by optimizing a combination of the SoftKI marginal log-likelihood (MLL), and when needed, an approximate MLL for improved numerical stability. Consequently, it can overcome the dimensionality scaling challenges that SKI faces when interpolating from a dense and static lattice while retaining the flexibility of variational methods to adapt inducing points to the dataset. We demonstrate the effectiveness of SoftKI across various examples and show that it is competitive with other approximated GP methods when the data dimensionality is modest (around $10$).},
  archive      = {J_TMLR},
  author       = {Chris L Camaño and Daniel Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {High-dimensional gaussian process regression with soft kernel interpolation},
  url          = {https://openreview.net/forum?id=U9b2FIjvWU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic mapping in indoor embodied AI - A survey on advances, challenges, and future directions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=USgQ38RG6G'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent embodied agents (e.g. robots) need to perform complex semantic tasks in unfamiliar environments. Among many skills that the agents need to possess, building and maintaining a semantic map of the environment is most crucial in long-horizon tasks. A semantic map captures information about the environment in a structured way, allowing the agent to reference it for advanced reasoning throughout the task. While existing surveys in embodied AI focus on general advancements or specific tasks like navigation and manipulation, this paper provides a comprehensive review of semantic map-building approaches in embodied AI, specifically for indoor navigation. We categorize these approaches based on their structural representation (spatial grids, topological graphs, dense point-clouds or hybrid maps) and the type of information they encode (implicit features or explicit environmental data). We also explore the strengths and limitations of the map building techniques, highlight current challenges, and propose future research directions. We identify that the field is moving towards developing open-vocabulary, queryable, task-agnostic map representations, while high memory demands and computational inefficiency still remaining to be open challenges. This survey aims to guide current and future researchers in advancing semantic mapping techniques for embodied AI systems.},
  archive      = {J_TMLR},
  author       = {Sonia Raychaudhuri and Angel X Chang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semantic mapping in indoor embodied AI - A survey on advances, challenges, and future directions},
  url          = {https://openreview.net/forum?id=USgQ38RG6G},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FraGNNet: A deep probabilistic model for tandem mass spectrum prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UsqeHx9Mbx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compound identification from tandem mass spectrometry (MS/MS) data is a critical step in the analysis of complex mixtures. Typical solutions for the MS/MS spectrum to compound (MS2C) problem involve comparing the unknown spectrum against a library of known spectrum-molecule pairs, an approach that is limited by incomplete library coverage. Compound to MS/MS spectrum (C2MS) models can improve retrieval rates by augmenting real libraries with predicted MS/MS spectra. Unfortunately, many existing C2MS models suffer from problems with mass accuracy, generalization, or interpretability. We develop a new probabilistic method for C2MS prediction, FraGNNet, that can efficiently and accurately simulate MS/MS spectra with high mass accuracy. Our approach formulates the C2MS problem as learning a distribution over molecule fragments. FraGNNet achieves state-of-the-art performance in terms of prediction error and surpasses existing C2MS models as a tool for retrieval-based MS2C.},
  archive      = {J_TMLR},
  author       = {Adamo Young and Fei Wang and David Wishart and BO WANG and Russell Greiner and Hannes Rost},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FraGNNet: A deep probabilistic model for tandem mass spectrum prediction},
  url          = {https://openreview.net/forum?id=UsqeHx9Mbx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Head-specific intervention can induce misaligned AI coordination in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VY0huMBr5n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust alignment guardrails for large language models (LLMs) are becoming increasingly important with their widespread application. In contrast to previous studies, we demonstrate that inference-time activation interventions can bypass safety alignments and effectively steer model generations towards harmful AI coordination. Our method applies fine-grained interventions at specific attention heads, which we identify by probing each head in a simple binary choice task. We then show that interventions on these heads generalise to the open-ended generation setting, effectively circumventing safety guardrails. We demonstrate that intervening on a few attention heads is more effective than intervening on full layers or supervised fine-tuning. We further show that only a few example completions are needed to compute effective steering directions, which is an advantage over classical fine-tuning. We also demonstrate applying interventions in the negative direction can prevent a common jailbreak attack. Our results suggest that, at the attention head level, activations encode fine-grained linearly separable behaviours. Practically, the approach offers a straightforward methodology to steer large language model behaviour, which could be extended to diverse domains beyond safety requiring fine-grained control over the model output.},
  archive      = {J_TMLR},
  author       = {Paul Darm and Annalisa Riccardi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Head-specific intervention can induce misaligned AI coordination in large language models},
  url          = {https://openreview.net/forum?id=VY0huMBr5n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MobileCLIP2: Improving multi-modal reinforced training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WeF9zolng8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation image-text models such as CLIP with zero-shot capabilities enable a wide array of applications. MobileCLIP is a recent family of image-text models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot accuracy. The main ingredients in MobileCLIP were its low-latency and light architectures and a novel multi-modal reinforced training that made knowledge distillation from multiple caption-generators and CLIP teachers efficient, scalable, and reproducible. In this paper, we improve the multi-modal reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles trained on the DFN dataset, 2) improved captioner teachers trained on the DFN dataset and fine-tuned on a diverse selection of high-quality image-caption datasets. We discover new insights through ablations such as the importance of temperature tuning in contrastive knowledge distillation, the effectiveness of caption-generator fine-tuning for caption diversity, and the additive improvement from combining synthetic captions generated by multiple models. We train a new family of models called MobileCLIP2 and achieve state-of-the-art ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe 2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2× smaller and improves on DFN ViT-L/14 at 2.5× lower latency. We release our pretrained models and the data generation code. The data generation code makes it easy to create new reinforced datasets with arbitrary teachers using distributed scalable processing.},
  archive      = {J_TMLR},
  author       = {Fartash Faghri and Pavan Kumar Anasosalu Vasu and Cem Koc and Vaishaal Shankar and Alexander T Toshev and Oncel Tuzel and Hadi Pouransari},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MobileCLIP2: Improving multi-modal reinforced training},
  url          = {https://openreview.net/forum?id=WeF9zolng8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond grids: Multi-objective bayesian optimization with adaptive discretization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Wq150HaRVE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing a vector-valued objective function $\boldsymbol{f}$ sampled from a Gaussian Process (GP) whose index set is a well-behaved, compact metric space $(\mathcal{X},d)$ of designs. We assume that $\boldsymbol{f}$ is not known beforehand and that evaluating $\boldsymbol{f}$ at design $x$ results in a noisy observation of $\boldsymbol{f}(x)$. Since identifying the Pareto optimal designs via exhaustive search is infeasible when the cardinality of $\mathcal{X}$ is large, we propose an algorithm, called Adaptive $\boldsymbol{\epsilon}$-PAL, that exploits the smoothness of the GP-sampled function and the structure of $(\mathcal{X},d)$ to learn fast. In essence, Adaptive $\boldsymbol{\epsilon}$-PAL employs a tree-based adaptive discretization technique to identify an $\boldsymbol{\epsilon}$-accurate Pareto set of designs in as few evaluations as possible. We provide both information-type and metric dimension-type bounds on the sample complexity of $\boldsymbol{\epsilon}$-accurate Pareto set identification. We also experimentally show that our algorithm outperforms other Pareto set identification methods.},
  archive      = {J_TMLR},
  author       = {Andi Nika and Sepehr Elahi and Cagin Ararat and Cem Tekin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond grids: Multi-objective bayesian optimization with adaptive discretization},
  url          = {https://openreview.net/forum?id=Wq150HaRVE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dextr: Zero-shot neural architecture search with singular value decomposition and extrinsic curvature. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=X0vPof5DVh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot Neural Architecture Search (NAS) typically optimises the architecture search process by exploiting the network or gradient properties at initialisation through zero-cost proxies. The existing proxies often rely on labelled data, which is usually unavailable in real-world settings. Furthermore, the majority of the current methods focus either on optimising the convergence and generalisation attributes or solely on the expressivity of the network architectures. To address both limitations, we first demonstrate how channel collinearity affects the convergence and generalisation properties of a neural network. Then, by incorporating the convergence, generalisation and expressivity in one approach, we propose a zero-cost proxy that omits the requirement of labelled data for its computation. In particular, we leverage the Singular Value Decomposition (SVD) of the neural network layer features and the extrinsic curvature of the network output to design our proxy. As a result, the proposed proxy is formulated as the simplified harmonic mean of the logarithms of two key components: the sum of the inverse of the feature condition number and the extrinsic curvature of the network output. Our approach enables accurate prediction of network performance on test data using only a single label-free data sample. Our extensive evaluation includes a total of six experiments, including the Convolutional Neural Network (CNN) search space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The proposed proxy demonstrates a superior performance on multiple correlation benchmarks, including NAS-Bench-101, NAS-Bench-201, and TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the AutoFormer search space, all while being notably efficient. The code is available at https://github.com/rohanasthana/Dextr.},
  archive      = {J_TMLR},
  author       = {Rohan Asthana and Joschua Conrad and Maurits Ortmanns and Vasileios Belagiannis},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dextr: Zero-shot neural architecture search with singular value decomposition and extrinsic curvature},
  url          = {https://openreview.net/forum?id=X0vPof5DVh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AlignFix: Fixing adversarial perturbations by agreement checking for adversarial robustness against black-box attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XgK05fssnx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the vulnerability of feed-forward visual pathways to adversarial-like inputs and the overall robustness of biological perception, commonly attributed to top-down feedback processes, we propose a new defense method AlignFix. We exploit the fact that natural and adversarially trained models rely on distinct feature sets for classification. Notably, naturally trained models, referred to as \textit{weakM}, retain commendable accuracy against adversarial examples generated using adversarially trained models referred to as \textit{strongM}, and vice-versa. Further these two models tend to agree more on their prediction if input is nudged towards correct class prediction. Leveraging this, AlignFix initially perturbs the input toward the class predicted by a naturally trained model, using a joint loss from both \textit{weakM} and \textit{strongM}. If this retains or leads to agreement, the prediction is accepted, otherwise the original \textit{strongM} output is used. This mechanism is highly effective against leading SQA (Score-based Query Attacks) as well as decision-based and transfer-based black-box attacks. We demonstrate its effectiveness through comprehensive experiments across various datasets (CIFAR and ImageNet) and architectures (ResNet and ViT).},
  archive      = {J_TMLR},
  author       = {Ashutosh Kumar Nirala and Jin Tian and Olukorede Fakorede and Modeste Atsague},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AlignFix: Fixing adversarial perturbations by agreement checking for adversarial robustness against black-box attacks},
  url          = {https://openreview.net/forum?id=XgK05fssnx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent symbol-like number variables in artificial neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YPnYpiru5W'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What types of numeric representations emerge in neural systems, and what would a satisfying answer to this question look like? In this work, we interpret Neural Network (NN) solutions to sequence based number tasks through a variety of methods to understand how well we can interpret them through the lens of interpretable Symbolic Algorithms (SAs)—precise algorithms describable by rules operating on typed, mutable variables. We use GRUs, LSTMs, and Transformers trained using Next Token Prediction (NTP) on tasks where the correct tokens depend on numeric information only latent in the task structure. We show through multiple causal and theoretical methods that we can interpret raw NN activity through the lens of simplified SAs when we frame the neural activity in terms of neural subspaces rather than individual neurons. Using Distributed Alignment Search (DAS), we find that, depending on network architecture, dimensionality, and task specifications, alignments with SA’s can be very high, while other times they can be only approximate, or fail altogether. We extend our analytic toolkit to address the failure cases by expanding the DAS framework to a broader class of alignment functions that more flexibly capture NN activity in terms of interpretable variables from SAs, and we provide theoretic and empirical explorations of Linear Alignment Functions (LAFs) in contrast to the preexisting Orthogonal Alignment Functions (OAFs). Through analyses of specific cases we confirm the usefulness of causal interventions on neural subspaces for NN interpretability, and we show that recurrent models can develop graded, symbol-like number variables within their neural activity. We further show that shallow Transformers learn very different solutions than recurrent networks, and we prove that such models must use anti-Markovian solutions—solutions that do not rely on cumulative, Markovian hidden states—in the absence of sufficient attention layers.},
  archive      = {J_TMLR},
  author       = {Satchel Grant and Noah Goodman and James Lloyd McClelland},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent symbol-like number variables in artificial neural networks},
  url          = {https://openreview.net/forum?id=YPnYpiru5W},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corner cases: How size and position of objects challenge ImageNet-trained models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Yqf2BhqfyZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backgrounds in images play a major role in contributing to spurious correlations among different data points. Owing to aesthetic preferences of humans capturing the images, datasets can exhibit positional (location of the object within a given frame) and size (region-of-interest to image ratio) biases for different classes. In this paper, we show that these biases can impact how much a model relies on spurious features in the background to make its predictions. To better illustrate our findings, we propose a synthetic dataset derived from ImageNet-1k, Hard-Spurious-ImageNet, which contains images with various backgrounds, object positions, and object sizes. By evaluating the dataset on different pretrained models, we find that most models rely heavily on spurious features in the background when the region-of-interest (ROI) to image ratio is small and the object is far from the center of the image. Moreover, we also show that current methods that aim to mitigate harmful spurious features, do not take into account these factors, hence fail to achieve considerable performance gains for worst-group accuracies when the size and location of core features in an image change. The dataset and implementation code are available at \url{https://github.com/Mishalfatima/Corner_Cases}.},
  archive      = {J_TMLR},
  author       = {Mishal Fatima and Steffen Jung and Margret Keuper},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Corner cases: How size and position of objects challenge ImageNet-trained models},
  url          = {https://openreview.net/forum?id=Yqf2BhqfyZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRIDE: A text-assisted radar-image weather-aware fusion network for depth estimation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZMqMnwMfse'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation, essential for autonomous driving, seeks to interpret the 3D environment surrounding vehicles. The development of radar sensors, known for their cost-efficiency and robustness, has spurred interest in radar-camera fusion-based solutions. However, existing algorithms fuse features from these modalities without accounting for weather conditions, despite radars being known to be more robust than cameras under adverse weather. Additionally, while Vision-Language models have seen rapid advancement, utilizing language descriptions alongside other modalities for depth estimation remains an open challenge. This paper first introduces a text-generation strategy along with feature extraction and fusion techniques that can assist monocular depth estimation pipelines, leading to improved accuracy across different algorithms on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion algorithm that enhances text feature extraction by incorporating radar point information. To address the impact of weather on sensor performance, we introduce a weather-aware fusion block that adaptively adjusts radar weighting based on current weather conditions. Our method, benchmarked on the nuScenes dataset, demonstrates performance gains over the state-of-the-art, achieving a 12.87% improvement in MAE and a 9.08% improvement in RMSE. Code: https://github.com/harborsarah/TRIDE},
  archive      = {J_TMLR},
  author       = {Huawei Sun and Zixu Wang and Hao Feng and Julius Ott and Lorenzo Servadei and Robert Wille},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TRIDE: A text-assisted radar-image weather-aware fusion network for depth estimation},
  url          = {https://openreview.net/forum?id=ZMqMnwMfse},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified wisdom: Harnessing collaborative learning to improve efficacy of knowledge distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Zj9bb8aQNg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD), which involves training a smaller student model to approximate the predictions of a larger teacher model is useful in striking a balance between model accuracy and computational constraints. However, KD has been found to be ineffective when the teacher and student models have a significant capacity gap. In this work, we address this issue via “meta-collaborative distillation” (MC-Distil), where students of varying capacities collaborate during distillation. Using a “coordinator” network (C-Net), MC-Distil enables mutual learning among students as a meta-learning task. Our insight is that C-Net learns from each student’s performance and training instance characteristics, allowing students of different capacities to improve together. Our method enhances student accuracy for all students, surpassing state-of-the-art baselines, including multi-step distillation, consensus enforcement, and teacher re-training. We achieve average gains of 2.5% on CIFAR-100 and 2% on Tiny ImageNet datasets, consistently across diverse student sizes, teacher sizes, and architectures. Notably, larger students benefiting through meta-collaboration with smaller students is a novel idea. MC-Distil excels in training superior student models under real-world conditions such as label noise and domain adaptation. Our approach also yields consistent improvements on the MS COCO object detection benchmark and introduces only a modest 5% computational overhead during training, with no additional cost at inference.},
  archive      = {J_TMLR},
  author       = {Atharva Abhijit Tambat and Durga S and Ganesh Ramakrishnan and Pradeep Shenoy},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unified wisdom: Harnessing collaborative learning to improve efficacy of knowledge distillation},
  url          = {https://openreview.net/forum?id=Zj9bb8aQNg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training dynamics of the cooldown stage in warmup-stable-decay learning rate scheduler. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZnSYEcZod3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning rate scheduling is essential in transformer training, where the final annealing plays a crucial role in getting the best performance. However, the mechanisms behind this cooldown phase, with its characteristic drop in loss, remain poorly understood. To address this, we provide a comprehensive analysis focusing solely on the cooldown phase in the Warmup-Stable-Decay (WSD) learning rate scheduler. Our analysis reveals that different cooldown shapes reveal a fundamental bias-variance trade-off in the resulting models, with shapes that balance exploration and exploitation consistently outperforming alternatives. Similarly, we find substantial performance variations — comparable to those from cooldown shape selection — when tuning AdamW hyperparameters. Notably, we observe consistent improvements with higher values of $\beta_2$ during cooldown. From a loss landscape perspective, we provide visualizations of the landscape during cooldown, supporting the river valley loss perspective empirically. These findings offer practical recommendations for configuring the WSD scheduler in transformer training, emphasizing the importance of optimizing the cooldown phase alongside traditional hyperparameter tuning.},
  archive      = {J_TMLR},
  author       = {Aleksandr Dremov and Alexander Hägele and Atli Kosson and Martin Jaggi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Training dynamics of the cooldown stage in warmup-stable-decay learning rate scheduler},
  url          = {https://openreview.net/forum?id=ZnSYEcZod3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding-based regression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=avUQ8jguxg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models have recently been shown capable of performing regression wherein numeric predictions are represented as decoded strings. In this work, we provide theoretical grounds for this capability and furthermore investigate the utility of causal sequence decoding models as numeric regression heads given any feature representation. We find that, despite being trained in the usual way - for next-token prediction via cross-entropy loss - decoder-based heads are as performant as standard pointwise heads when benchmarked over standard regression tasks, while being flexible enough to capture smooth numeric distributions, such as in the task of density estimation.},
  archive      = {J_TMLR},
  author       = {Xingyou Song and Dara Bahri},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decoding-based regression},
  url          = {https://openreview.net/forum?id=avUQ8jguxg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MESSI: A multi-elevation semantic segmentation image dataset of an urban environment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ayWqZ1wyIv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI) dataset. A reduced version of the dataset has been published at https://github.com/messi-dataset/ for reviewing purposes (due to the anonymity requirement). The full dataset will be made available at the time of the decision. MESSI comprises 2525 images taken by a drone flying over dense urban environments. MESSI is unique in two main features. First, it contains images from various altitudes (both with horizontal and vertical trajectories), allowing us to investigate the effect of depth on semantic segmentation. Second, it includes images taken from several different urban regions (at different altitudes). This is important since the variety covers the visual richness captured by a drone's 3D flight, performing horizontal and vertical maneuvers. MESSI contains images annotated with location, orientation, and the camera's intrinsic parameters. It can be used to train a deep neural network for semantic segmentation or other applications of interest. This paper describes the dataset and provides annotation details. It also explains how semantic segmentation was performed using several neural network models and shows several relevant statistics. MESSI will be published in the public domain to serve as an evaluation benchmark for semantic segmentation using images captured by a drone or similar vehicle flying over a dense urban environment.},
  archive      = {J_TMLR},
  author       = {Barak Pinkovich and Boaz Matalon and Ehud Rivlin and Hector Rotstein},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MESSI: A multi-elevation semantic segmentation image dataset of an urban environment},
  url          = {https://openreview.net/forum?id=ayWqZ1wyIv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent corpus pre-training benefits vision language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bivKGSaXkD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-Language Pre-trained Models (VL-PTMs) have achieved impressive performance across a wide range of tasks, but their success often hinges on access to large-scale multimodal datasets. While effective in high-resource settings, these models tend to struggle in data-scarce regimes. In this work, we investigate Emergent Communication (EC) as a mechanism to improve sample efficiency in VL-PTMs. We pre-train a Vision-Language Model (VLM) using EC tokens generated through a referential game between two artificial agents. Across three diverse cross-modal matching and reasoning benchmarks, EC pretraining yields substantial gains, improving Visual Referring Expression (VRE) accuracy by 108.6% and Visual Entailment (VE) by 69.6%. To further validate the effectiveness of EC pretraining, we introduce LLaVA-1.5-EC, a LLaVA variant trained entirely on EC tokens. LLaVA-1.5-EC outperforms strong LVLM baselines, including BLIP-2 (13B), achieving relative gains of 104.23% on VizWiz, 34.8% on GQA, and 10.8% on VQAv2, and top performance on MMBench, a challenging instruction-following benchmark. These results highlight the transferability and generalization capacity of EC pretraining and underscore the potential of leveraging grounded EC tokens to enhance vision-language reasoning in low-resource settings, especially in settings with limited natural language data. We discuss implications and propose avenues for future research to explore the connections between EC and VL for multimodal understanding and effective human-machine communication. Project Website: https://plan-lab.github.io/ec-vlm/},
  archive      = {J_TMLR},
  author       = {Makanjuola Adekunmi Ogunleye and Chase Vickery and Ismini Lourentzou},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent corpus pre-training benefits vision language models},
  url          = {https://openreview.net/forum?id=bivKGSaXkD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFAR: A training-free framework for autonomous reliable reasoning in visual question answering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cBAKeZN3jy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent approaches introduce chain-of-thought (CoT) reasoning to mitigate the challenges, such as hallucination and reasoning deficit in multimodal large language models (MLLMs) and enhance performance. However, existing CoT-based methods often rely on extensive data annotation and training. To overcome these limitations, we propose a training-free framework for autonomous and reliable reasoning (TFAR), which only uses common lightweight vision tools to improve the reasoning ability of MLLMs. TFAR enables an MLLM to autonomously and accurately identify relevant regions of interest (RoIs) and support CoT reasoning, without requiring additional training or annotations, and with low computational overhead during inference. However, the use of external tools will introduce noise and uncertainty. To mitigate the uncertainty introduced by external tools and select the optimal pathway, we propose a conformal prediction-based uncertainty quantification method that calibrates the outputs from external tools and dynamically selects the most appropriate tool based on the MLLM’s output uncertainty. Experiments across five datasets demonstrate that TFAR improves performance over the base MLLM by an average of 4.6$\%$, in some cases even outperforming fine-tuned baselines, while maintaining low inference cost. These results offer new insights into training-free CoT guidance for MLLMs and underscore the value of reliable visual tools.},
  archive      = {J_TMLR},
  author       = {Zhuo Zhi and Chen Feng and Adam Daneshmend and Mine Orlu and Andreas Demosthenous and Lu Yin and Da Li and Ziquan Liu and Miguel R. D. Rodrigues},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TFAR: A training-free framework for autonomous reliable reasoning in visual question answering},
  url          = {https://openreview.net/forum?id=cBAKeZN3jy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the low-rank parametrization of reward models for controlled language generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cjRsEGLT8B'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models trained on large amounts of data are known to produce inappropriate content in some cases and require careful tuning to be used in the real world. We revisit an effective and modular approach for controllability of the language models, when an external expert model guides the decoding. Particularly, we zoom in into the parametrization choice of an external expert, highlighting the difference between low-rank and higher-rank parametrizations. Higher-rank experts are designed to support high flexibility when representing the rewards, leading to higher computational costs during decoding. However, we demonstrate that they might not use their full flexibility. By analyzing the recently proposed reward-augmented decoding approach (RAD), which uses a higher-rank expert model, we introduce a simpler but more efficient low-rank parametrization of the expert model enabling fast and effective guided decoding. We empirically show that the low-rank RAD performs on par with the more flexible RAD on a detoxification and a sentiment control task, while requiring only a single reward model call per generated token.},
  archive      = {J_TMLR},
  author       = {Sergey Troshin and Vlad Niculae and Antske Fokkens},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the low-rank parametrization of reward models for controlled language generation},
  url          = {https://openreview.net/forum?id=cjRsEGLT8B},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From reasoning to learning: A survey on hypothesis discovery and rule learning with large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=d7W38UzUg0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the advent of Large Language Models (LLMs), efforts have largely focused on improving their instruction-following and deductive reasoning abilities, leaving open the question of whether these models can truly discover new knowledge. In pursuit of artificial general intelligence (AGI), there is a growing need for models that not only execute commands or retrieve information but also learn, reason, and generate new knowledge by formulating novel hypotheses and theories that deepen our understanding of the world. Guided by Peirce's framework of abduction, deduction, and induction, this survey offers a structured lens to examine LLM-based hypothesis discovery. We synthesize existing work in hypothesis generation, application, and validation, identifying both key achievements and critical gaps. By unifying these threads, we illuminate how LLMs might evolve from mere ``information executors'' into engines of genuine innovation, potentially transforming research, science, and real-world problem solving.},
  archive      = {J_TMLR},
  author       = {Kaiyu He and Zhiyu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {From reasoning to learning: A survey on hypothesis discovery and rule learning with large language models},
  url          = {https://openreview.net/forum?id=d7W38UzUg0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-controlling prediction with distributionally robust optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=d9dl6DyJpJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction is a popular paradigm to quantify the uncertainty of a model's output on a new batch of data. Quite differently, distributionally robust optimization aims at training a model that is robust to uncertainties in the distribution of the training data. In this paper, we examine the links between the two approaches. In particular, we show that we can learn conformal prediction intervals by distributionally robust optimization on a well chosen objective. This further entails to train a model and build conformal prediction intervals all at once, using the same data.},
  archive      = {J_TMLR},
  author       = {Franck Iutzeler and Adrien Mazoyer},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Risk-controlling prediction with distributionally robust optimization},
  url          = {https://openreview.net/forum?id=d9dl6DyJpJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient pooling of predictions via kernel embeddings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dji9MfONNP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic predictions are probability distributions over the set of possible outcomes. Such predictions quantify the uncertainty in the outcome, making them essential for effective decision making. By combining multiple predictions, the information sources used to generate the predictions are pooled, often resulting in a more informative forecast. Probabilistic predictions are typically combined by linearly pooling the individual predictive distributions; this encompasses several ensemble learning techniques, for example. The weights assigned to each prediction can be estimated based on their past performance, allowing more accurate predictions to receive a higher weight. This can be achieved by finding the weights that optimise a proper scoring rule over some training data. By embedding predictions into a Reproducing Kernel Hilbert Space (RKHS), we illustrate that estimating the linear pool weights that optimise kernel-based scoring rules is a convex quadratic optimisation problem. This permits an efficient implementation of the linear pool when optimally combining predictions on arbitrary outcome domains. This result also holds for other combination strategies, and we additionally study a flexible generalisation of the linear pool that overcomes some of its theoretical limitations, whilst allowing an efficient implementation within the RKHS framework. These approaches are compared in an application to operational wind speed forecasts, where this generalisation is found to offer substantial improvements upon the traditional linear pool.},
  archive      = {J_TMLR},
  author       = {Sam Allen and David Ginsbourger and Johanna Ziegel},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient pooling of predictions via kernel embeddings},
  url          = {https://openreview.net/forum?id=dji9MfONNP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient knowledge injection in LLMs via self-distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=drYpdSnRJk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical applications, large language models (LLMs) need to acquire new knowledge not present in their pre-training data. Efficiently leveraging this knowledge usually relies on supervised fine-tuning or retrieval-augmented generation (RAG). Although RAG has emerged as the industry standard for knowledge injection, fine-tuning has not yet achieved comparable success. This paper proposes utilizing prompt distillation, a self-distillation-based method previously explored primarily for style alignment and instruction tuning, to internalize new factual knowledge from free-form documents. Unlike prior methods, our approach requires neither larger teacher models nor structured knowledge formats. Across multiple LLM sizes and model families, we show that prompt distillation outperforms standard supervised fine-tuning and can even surpass RAG. We analyze the key factors contributing to prompt distillation's effectiveness and examine how it scales.},
  archive      = {J_TMLR},
  author       = {Kalle Kujanpää and Pekka Marttinen and Harri Valpola and Alexander Ilin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient knowledge injection in LLMs via self-distillation},
  url          = {https://openreview.net/forum?id=drYpdSnRJk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation, estimation and optimization errors for a deep neural network. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dzND5haNvA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The error of supervised learning is typically split into three components: approximation, estimation and optimization errors. While all three have been extensively studied in the literature, a unified treatment is less frequent, in part because of conflicting assumptions. Current approximation results rely on carefully hand crafted weights or practically unavailable information, which are difficult to achieve by gradient descent. Optimization theory is best understood in over-parametrized regimes with more weights than samples, while classical estimation errors require the opposite regime with more samples than weights. This paper contains two results which bound all three error components simultaneously for (non-convex) training of the second but last layer of deep fully connected networks on the unit sphere. The first uses a regular least squares loss and shows convergence in the under-parametrized regime. The second uses a kernel based loss function and shows convergence in both under and over-parametrized regimes.},
  archive      = {J_TMLR},
  author       = {Gerrit Welper and Benjamin Keene},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximation, estimation and optimization errors for a deep neural network},
  url          = {https://openreview.net/forum?id=dzND5haNvA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are domain generalization benchmarks with accuracy on the line misspecified?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fNywRyqPQo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious correlations, unstable statistical shortcuts a model can exploit, are expected to degrade performance out-of-distribution (OOD). However, across many popular OOD generalization benchmarks, vanilla empirical risk minimization (ERM) often achieves the highest OOD accuracy. Moreover, gains in in-distribution accuracy generally improve OOD accuracy, a phenomenon termed accuracy on the line, which contradicts the expected harm of spurious correlations. We show that these observations are an artifact of misspecified OOD datasets that do not include shifts in spurious correlations that harm OOD generalization, the setting they are meant to evaluate. Consequently, current practice evaluates "robustness" without truly stressing the spurious signals we seek to eliminate; our work pinpoints when that happens and how to fix it. Contributions. (i) We derive necessary and sufficient conditions for a distribution shift to reveal a model's reliance on spurious features; when these conditions hold, "accuracy on the line" disappears. (ii) We audit leading OOD datasets and find that most still display accuracy on the line, suggesting they are misspecified for evaluating robustness to spurious correlations. (iii) We catalog the few well-specified datasets and summarize generalizable design principles, such as identifying datasets of natural interventions (e.g., a pandemic), to guide future well-specified benchmarks.},
  archive      = {J_TMLR},
  author       = {Olawale Elijah Salaudeen and Nicole Chiou and Shiny Weng and Sanmi Koyejo},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Are domain generalization benchmarks with accuracy on the line misspecified?},
  url          = {https://openreview.net/forum?id=fNywRyqPQo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G2D2: Gradient-guided discrete diffusion for inverse problem solving. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fj23qnVifX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent literature has effectively leveraged diffusion models trained on continuous variables as priors for solving inverse problems. Notably, discrete diffusion models with discrete latent codes have shown strong performance, particularly in modalities suited for discrete compressed representations, such as image and motion generation. However, their discrete and non-differentiable nature has limited their application to inverse problems formulated in continuous spaces. This paper presents a novel method for addressing linear inverse problems by leveraging generative models based on discrete diffusion as priors. We overcome these limitations by approximating the true posterior distribution with a variational distribution constructed from categorical distributions and continuous relaxation techniques. Furthermore, we employ a star-shaped noise process to mitigate the drawbacks of traditional discrete diffusion models with absorbing states, demonstrating that our method performs comparably to continuous diffusion techniques with lower GPU memory consumption.},
  archive      = {J_TMLR},
  author       = {Naoki Murata and Chieh-Hsin Lai and Yuhta Takida and Toshimitsu Uesaka and Bac Nguyen and Stefano Ermon and Yuki Mitsufuji},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {G2D2: Gradient-guided discrete diffusion for inverse problem solving},
  url          = {https://openreview.net/forum?id=fj23qnVifX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model tensor planning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fk1ZZdXCE3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling-based model predictive control (MPC) offers strong performance in nonlinear and contact-rich robotic tasks, yet often suffers from poor exploration due to locally greedy sampling schemes. We propose \emph{Model Tensor Planning} (MTP), a novel sampling-based MPC framework that introduces high-entropy control trajectory generation through structured tensor sampling. By sampling over randomized multipartite graphs and interpolating control trajectories with B-splines and Akima splines, MTP ensures smooth and globally diverse control candidates. We further propose a simple $\beta$-mixing strategy that blends local exploitative and global exploratory samples within the modified Cross-Entropy Method (CEM) update, balancing control refinement and exploration. Theoretically, we show that MTP achieves asymptotic path coverage and maximum entropy in the control trajectory space in the limit of infinite tensor depth and width. Our implementation is fully vectorized using JAX and compatible with MuJoCo XLA, supporting \emph{Just-in-time} (JIT) compilation and batched rollouts for real-time control with online domain randomization. Through experiments on various challenging robotic tasks, ranging from dexterous in-hand manipulation to humanoid locomotion, we demonstrate that MTP outperforms standard MPC and evolutionary strategy baselines in task success and control robustness. Design and sensitivity ablations confirm the effectiveness of MTP’s tensor sampling structure, spline interpolation choices, and mixing strategy. Altogether, MTP offers a scalable framework for robust exploration in model-based planning and control.},
  archive      = {J_TMLR},
  author       = {An Thai Le and Khai Nguyen and Minh Nhat VU and Joao Carvalho and Jan Peters},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Model tensor planning},
  url          = {https://openreview.net/forum?id=fk1ZZdXCE3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling human beliefs about AI behavior for scalable oversight. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gSJfsdQnex'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI systems advance beyond human capabilities, scalable oversight becomes critical: how can we supervise AI that exceeds our abilities? A key challenge is that human evaluators may form incorrect beliefs about AI behavior in complex tasks, leading to unreliable feedback and poor value inference. To address this, we propose modeling evaluators' beliefs to interpret their feedback more reliably. We formalize human belief models, analyze their theoretical role in value learning, and characterize when ambiguity remains. To reduce reliance on precise belief models, we introduce "belief model covering" as a relaxation. This motivates our preliminary proposal to use the internal representations of adapted foundation models to mimic human evaluators' beliefs. These representations could be used to learn correct values from human feedback even when evaluators misunderstand the AI's behavior. Our work suggests that modeling human beliefs can improve value learning and outlines practical research directions for implementing this approach to scalable oversight.},
  archive      = {J_TMLR},
  author       = {Leon Lang and Patrick Forré},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Modeling human beliefs about AI behavior for scalable oversight},
  url          = {https://openreview.net/forum?id=gSJfsdQnex},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private regression via data-dependent sufficient statistic perturbation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gtCfDKm9ME'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sufficient statistic perturbation (SSP) is a widely used method for differentially private linear regression. SSP adopts a data-independent approach where privacy noise from a simple distribution is added to sufficient statistics. However, sufficient statistics can often be expressed as linear queries and better approximated by data-dependent mechanisms. In this paper we introduce data-dependent SSP for linear regression based on post-processing privately released marginals, and find that it outperforms state-of-the-art data-independent SSP. We extend this result to logistic regression by developing an approximate objective that can be expressed in terms of sufficient statistics, resulting in a novel and highly competitive SSP approach for logistic regression. We also make a connection to synthetic data for machine learning: for models with sufficient statistics, training on synthetic data corresponds to data-dependent SSP, with the overall utility determined by how well the mechanism answers these linear queries.},
  archive      = {J_TMLR},
  author       = {Cecilia Ferrando and Daniel Sheldon},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Private regression via data-dependent sufficient statistic perturbation},
  url          = {https://openreview.net/forum?id=gtCfDKm9ME},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling and distilling transformer models for sEMG. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hFPWThwUiZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyography (sEMG) signals offer a promising avenue for developing innovative human-computer interfaces by providing insights into muscular activity. However, limited available training data and computational constraints during deployment have restricted the use of state-of-the-art machine learning models, such as transformers, in challenging sEMG tasks. In this paper, we demonstrate that transformer models can learn effective and generalizable representations from sEMG datasets that are small by modern deep learning standards (approximately 100 users), surpassing the performance of classical machine learning methods and older neural network architectures. Additionally, by leveraging model distillation techniques, we reduce parameter counts by up to 50x with minimal loss of performance. This results in efficient and expressive models suitable for complex real-time sEMG tasks in dynamic real-world environments.},
  archive      = {J_TMLR},
  author       = {Nick Mehlman and Jean-Christophe Gagnon-Audet and Michael Shvartsman and Kelvin Niu and Alexander H Miller and Shagun Sodhani},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scaling and distilling transformer models for sEMG},
  url          = {https://openreview.net/forum?id=hFPWThwUiZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node duplication improves cold-start link prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hIOTzz87N9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are prominent in graph machine learning and have shown state-of-the-art performance in Link Prediction (LP) tasks. Nonetheless, recent studies show that GNNs struggle to produce good results on low-degree nodes despite their overall strong performance. In practical applications of LP, like recommendation systems, improving performance on low-degree nodes is critical, as it amounts to tackling the cold-start problem of improving the experiences of users with few observed interactions. In this paper, we investigate improving GNNs' LP performance on low-degree nodes while preserving their performance on high-degree nodes and propose a simple yet surprisingly effective augmentation technique called NodeDup. Specifically, NodeDup duplicates low-degree nodes and creates links between nodes and their own duplicates before following the standard supervised LP training scheme. By leveraging a ``multi-view'' perspective for low-degree nodes, NodeDup shows significant LP performance improvements on low-degree nodes without compromising any performance on high-degree nodes. Additionally, as a plug-and-play augmentation module, NodeDup can be easily applied on existing GNNs with very light computational cost. Extensive experiments show that NodeDup achieves 38.49%, 13.34%, and 6.76% relative improvements on isolated, low-degree, and warm nodes, respectively, on average across all datasets compared to GNNs and the existing cold-start methods.},
  archive      = {J_TMLR},
  author       = {Zhichun Guo and Tong Zhao and Yozen Liu and Kaiwen Dong and William Shiao and Mingxuan Ju and Neil Shah and Nitesh V Chawla},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Node duplication improves cold-start link prediction},
  url          = {https://openreview.net/forum?id=hIOTzz87N9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing plaque segmentation in CCTA with prompt- based diffusion data augmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hbTYt8PX9n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary computed tomography angiography (CCTA) is essential for non-invasive assessment of coronary artery disease (CAD). However, accurate segmentation of atherosclerotic plaques remains challenging due to data scarcity, severe class imbalance, and significant variability between calcified and non-calcified plaques. Inspired by DiffTumor’s tumor synthesis and PromptIR’s adaptive restoration framework, we introduce PromptLesion, a prompt-conditioned diffusion model for multi-class lesion synthesis. Unlike single-class methods, our approach integrates lesion-specific prompts within the diffusion generation process, enhancing diversity and anatomical realism in synthetic data. We validate PromptLesion on a private CCTA dataset and multi-organ tumor segmentation tasks (kidney, liver, pancreas) using public datasets, achieving superior performance compared to baseline methods. Models trained with our prompt-guided synthetic augmentation significantly improve Dice Similarity Coefficient (DSC) scores for both plaque and tumor segmentation. Extensive evaluations and ablation studies confirm the effectiveness of prompt conditioning.},
  archive      = {J_TMLR},
  author       = {Ruan Yizhe and Xuangeng Chu and Ziteng Cui and Yusuke Kurose and JUNICHI IHO and Yoji Tokunaga and Makoto Horie and YUSAKU HAYASHI and Keisuke Nishizawa and Yasushi Koyama and Tatsuya Harada},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing plaque segmentation in CCTA with prompt- based diffusion data augmentation},
  url          = {https://openreview.net/forum?id=hbTYt8PX9n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous parallel relaxation for finding diverse solutions in combinatorial optimization problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ix33zd5zCw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the optimal solution is often the primary goal in combinatorial optimization (CO). However, real-world applications frequently require diverse solutions rather than a single optimum, particularly in two key scenarios. The first scenario occurs in real-world applications where strictly enforcing every constraint is neither necessary nor desirable. Allowing minor constraint violations can often lead to more cost-effective solutions. This is typically achieved by incorporating the constraints as penalty terms in the objective function, which requires careful tuning of penalty parameters. The second scenario involves cases where CO formulations tend to oversimplify complex real-world factors, such as domain knowledge, implicit trade-offs, or ethical considerations. To address these challenges, generating (i) penalty-diversified solutions by varying penalty intensities and (ii) variation-diversified solutions with distinct structural characteristics provides valuable insights, enabling practitioners to post-select the most suitable solution for their specific needs. However, efficiently discovering these diverse solutions is more challenging than finding a single optimal one. This study introduces Continual Parallel Relaxation Annealing (CPRA), a computationally efficient framework for unsupervised-learning (UL)-based CO solvers that generates diverse solutions within a single training run. CPRA leverages representation learning and parallelization to automatically discover shared representations, substantially accelerating the search for these diverse solutions. Numerical experiments demonstrate that CPRA outperforms existing UL-based solvers in generating these diverse solutions while significantly reducing computational costs.},
  archive      = {J_TMLR},
  author       = {Yuma Ichikawa and Hiroaki Iwashita},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continuous parallel relaxation for finding diverse solutions in combinatorial optimization problems},
  url          = {https://openreview.net/forum?id=ix33zd5zCw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling users to falsify deepfake attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jl6G0DgyaT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of deepfake technology has made everyone vulnerable to false claims based on manipulated media. While many existing deepfake detection methods aim to identify fake media, they often struggle with deepfakes created by new generative models not seen during training. In this paper, we propose FACTOR, a method that enables users to prove that the media claiming to show them are false. FACTOR is based on two key assumptions: (i) generative models struggle to exactly depict a specific identity, and (ii) they often fail to perfectly synchronize generated lip movements with speech. By combining these assumptions with powerful modern representation encoders, FACTOR achieves highly effective results, even against previously unseen deepfakes. Through extensive experiments, we demonstrate that FACTOR significantly outperforms state-of-the-art deepfake detection techniques despite being simple to implement and not relying on any fake data for pretraining.},
  archive      = {J_TMLR},
  author       = {Tal Reiss and Bar Cavia and Yedid Hoshen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enabling users to falsify deepfake attacks},
  url          = {https://openreview.net/forum?id=jl6G0DgyaT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GLOV: Guided large language models as implicit optimizers for vision language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kZLANTp6Vw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose GLOV, which enables Large Language Models (LLMs) to act as implicit optimizers for Vision-Language Models (VLMs) to enhance downstream vision tasks. GLOV prompts an LLM with the downstream task description, querying it for suitable VLM prompts (\eg for zero-shot classification with CLIP). These prompts are ranked according to their fitness for the downstream vision task. In each respective optimization step, the ranked prompts are fed as in-context examples (with their accuracies) to equip the LLM with the knowledge of the type of prompts preferred by the downstream VLM. Furthermore, we explicitly guide the LLM's generation at each optimization step by adding an offset vector -- calculated from the embedding differences between previous \textit{positive} and \textit{negative} solutions -- to the intermediate layer of the network for the next generation. This offset vector biases the LLM generation toward the type of language the downstream VLM prefers, resulting in enhanced performance on the downstream vision tasks. We comprehensively evaluate our GLOV on two tasks: object recognition and the critical task of enhancing VLM safety. Our GLOV shows performance improvement by up to $15.0\%$ and $57.5\%$ for dual-encoder (\eg~CLIP) and encoder-decoder (\eg~\llava) models for object recognition and reduces the attack success rate (ASR) on state-of-the-art VLMs by up to $60.7\%$.},
  archive      = {J_TMLR},
  author       = {Muhammad Jehanzeb Mirza and Mengjie Zhao and Zhuoyuan Mao and Sivan Doveh and Wei Lin and Paul Gavrikov and Michael Dorkenwald and Shiqi Yang and Saurav Jha and Hiromi Wakaki and Yuki Mitsufuji and Horst Possegger and Rogerio Feris and Leonid Karlinsky and James R. Glass},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GLOV: Guided large language models as implicit optimizers for vision language models},
  url          = {https://openreview.net/forum?id=kZLANTp6Vw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A curious case of remarkable resilience to gradient attacks via fully convolutional and differentiable front end with a skip connection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kt7Am2wHlm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We experimented with front-end enhanced neural models where a differentiable and fully convolutional model with a skip connection added before a frozen backbone classifier. By training such composite models using a small learning rate for about one epoch, we obtained models that retained the accuracy of the backbone classifier while being unusually resistant to gradient attacks—including APGD and FAB-T attacks from the AutoAttack package—which we attribute to gradient masking. Although gradient masking is not new, the degree we observe is striking for fully differentiable models without obvious gradient-shattering—e.g., JPEG compression—or gradient-diminishing components. The training recipe to produce such models is also remarkably stable and reproducible: We applied it to three datasets (CIFAR10, CIFAR100, and ImageNet) and several modern architectures (including vision Transformers) without a single failure case. While black-box attacks such as the SQUARE attack and zero-order PGD can partially overcome gradient masking, these attacks are easily defeated by simple randomized ensembles. We estimate that these ensembles achieve near-SOTA AutoAttack accuracy on CIFAR10, CIFAR100, and ImageNet (while retaining almost all clean accuracy of the original classifiers) despite having near-zero accuracy under adaptive attacks. Moreover, adversarially training the backbone further amplifies this front-end “robustness”. On CIFAR10, the respective randomized ensemble achieved 90.8±2.5% (99% CI) accuracy under the full AutoAttack while having only 18.2±3.6% accuracy under the adaptive attack (ε = 8/255, L∞ norm). While our primary goal is to expose weaknesses of the AutoAttack package—rather than to propose a new defense or establish SOTA in adversarial robustness—we nevertheless conclude the paper with a discussion of whether randomized ensembling can serve as a practical defense. Code and instructions to reproduce key results are available. https://github.com/searchivarius/curious_case_of_gradient_masking},
  archive      = {J_TMLR},
  author       = {Leonid Boytsov and Ameya Joshi and Filipe Condessa},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A curious case of remarkable resilience to gradient attacks via fully convolutional and differentiable front end with a skip connection},
  url          = {https://openreview.net/forum?id=kt7Am2wHlm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formulating node labelling as node classification or link prediction in different graph representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lK7tjysj0s'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message-passing Graph Neural Networks (GNNs) are increasingly used for predictive tasks on graphs. Much work has been done to improve GNN architectures, but how the actual data graph should be designed is not well studied. In this paper, we investigate how two different graph representations impact the performance of GNN models across datasets with varying characteristics grouped by homophily, heterogeneity, and number of labels per node. A unique phenomenon is that the same abstract predictive task of labelling nodes is formulated as a node classification problem on one representation and as a link prediction problem on the other. Our work is the first to blur the line between these two basic and fundamental tasks in graph learning. Our experiments on 12 real-world datasets suggest that different representations (and tasks) are optimal for different datasets, models, and hyperparameters. We derive empirical heuristics of choosing between the two and pave the way towards a criterion of choosing the optimal graph representations and towards formally understanding the interconnection between node classification and link prediction.},
  archive      = {J_TMLR},
  author       = {Tobias Möller and Borun Shi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Formulating node labelling as node classification or link prediction in different graph representations},
  url          = {https://openreview.net/forum?id=lK7tjysj0s},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Streaming heteroscedastic probabilistic PCA with missing data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lb2rPLuP9X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Streaming principal component analysis (PCA) is an integral tool in large-scale machine learning for rapidly estimating low-dimensional subspaces from very high-dimensional data arriving at a high rate. However, modern datasets increasingly combine data from a variety of sources, and thus may exhibit heterogeneous quality across samples. Standard streaming PCA algorithms do not account for non-uniform noise, so their subspace estimates can quickly degrade. While the recently proposed Heteroscedastic Probabilistic PCA Technique (HePPCAT) addresses this heterogeneity, it was not designed to handle streaming data that may exhibit non-stationary behavior. Moreover, HePPCAT does not allow for missing entries in the data, which can be common in streaming data. This paper proposes the Streaming HeteroscedASTic Algorithm for PCA (SHASTA-PCA) to bridge this divide. SHASTA-PCA employs a stochastic alternating expectation-maximization approach that jointly learns the low-rank latent factors and the unknown noise variances from streaming data that may have missing entries and heteroscedastic noise, all while maintaining a low memory and computational footprint. Numerical experiments demonstrate the superior subspace estimation of our method compared to state-of-the-art streaming PCA algorithms in the heteroscedastic setting. Finally, we illustrate SHASTA-PCA applied to highly heterogeneous real data from astronomy.},
  archive      = {J_TMLR},
  author       = {Kyle Gilman and David Hong and Jeffrey A Fessler and Laura Balzano},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Streaming heteroscedastic probabilistic PCA with missing data},
  url          = {https://openreview.net/forum?id=lb2rPLuP9X},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lcTFm4LIRR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) demonstrate an impressive ability to utilise information within the context of their input sequences to appropriately respond to data unseen by the LLM during its training procedure. This ability is known as in-context learning (ICL). Humans and non-human animals demonstrate similar abilities, however their neural architectures differ substantially from LLMs. Despite this, a critical component within LLMs, the attention mechanism, resembles modern associative memory models, widely used in and influenced by the computational neuroscience community to model biological memory systems. Using this connection, we introduce an associative memory model capable of performing ICL. We use this as inspiration for a novel residual stream architecture which allows information to directly flow between attention heads. We test this architecture during training within a two-layer Transformer and show its ICL abilities manifest more quickly than without this modification. We then apply our architecture in small language models with 8 million and 1 billion parameters, focusing on attention head values, with results also indicating improved performance at these larger and more naturalistic scales.},
  archive      = {J_TMLR},
  author       = {Thomas F Burns and Tomoki Fukai and Christopher Earls},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture},
  url          = {https://openreview.net/forum?id=lcTFm4LIRR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defending against unforeseen failure modes with latent adversarial training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mVPPhQ8cAd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite extensive diagnostics and debugging by developers, AI systems sometimes exhibit harmful unintended behaviors. Finding and fixing these is challenging because the attack surface is so large – it is not tractable to exhaustively search for inputs that may elicit harmful behaviors. Red-teaming and adversarial training (AT) are commonly used to improve robustness, however, they empirically struggle to fix failure modes that differ from the attacks used during training. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without leveraging knowledge of what they are or using inputs that elicit them. LAT makes use of the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. Here, we use it to defend against failure modes without examples that elicit them. Specifically, we use LAT to remove backdoors and defend against held-out classes of adversarial attacks. We show in image classification, text classification, and text generation tasks that LAT usually improves both robustness to novel attacks and performance on clean data relative to AT. This suggests that LAT can be a promising tool for defending against failure modes that are not explicitly identified by developers.},
  archive      = {J_TMLR},
  author       = {Stephen Casper and Lennart Schulze and Oam Patel and Dylan Hadfield-Menell},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Defending against unforeseen failure modes with latent adversarial training},
  url          = {https://openreview.net/forum?id=mVPPhQ8cAd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Set-based training for neural network verification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=n0lzHrAWIA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are vulnerable to adversarial attacks, i.e., small input perturbations can significantly affect the outputs of a neural network. Therefore, to ensure safety of neural networks in safety-critical environments, the robustness of a neural network must be formally verified against input perturbations, e.g., from noisy sensors. To improve the robustness of neural networks and thus simplify the formal verification, we present a novel set-based training procedure in which we compute the set of possible outputs given the set of possible inputs and compute for the first time a gradient set, i.e., each possible output has a different gradient. Therefore, we can directly reduce the size of the output enclosure by choosing gradients toward its center. Small output enclosures increase the robustness of a neural network and, at the same time, simplify its formal verification. The latter benefit is due to the fact that a larger size of propagated sets increases the conservatism of most verification methods. Our extensive evaluation demonstrates that set-based training produces robust neural networks with competitive performance, which can be verified using fast (polynomial-time) verification algorithms due to the reduced output set.},
  archive      = {J_TMLR},
  author       = {Lukas Koller and Tobias Ladner and Matthias Althoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Set-based training for neural network verification},
  url          = {https://openreview.net/forum?id=n0lzHrAWIA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-aware spatiotemporal causal graph network for forecasting with limited data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=n3yrVzPcNa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal models have drawn significant interest recently due to their widespread applicability across many domains. These models are often made more practically useful by incorporating beneficial inductive biases, such as laws or symmetries from domain-relevant physics equations. This "physics-awareness" provides an interpretable means of grounding otherwise purely data-driven models, improving robustness and boosting performance in settings with limited data. In this work, we view physical dynamics as domain knowledge that captures fundamental causal relationships across space and time, and can be effectively leveraged by our proposed physics-aware spatiotemporal causal graph network (P-STCGN). We firstly describe a means of deriving causal relationships from spatiotemporal data, serving as physics-aware labels to learn a causal structure via a dedicated neural module. We then formulate a forecasting module that can operate under this causal structure, producing predictions that are guided by physics-aware cause-effect relationships among modeled variables. Extensive experimentation demonstrates that our method is robust to noisy and limited data, outperforming existing models across a variety of challenging synthetic tasks and benchmark datasets. We further evaluate our method on real-world graph signals and observe superior forecasting performance, achieved by effectively utilizing causal signals from prior physics knowledge.},
  archive      = {J_TMLR},
  author       = {Zijun Cui and Sam Griesemer and Sungyong Seo and Joshua Hikida and Yan Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Physics-aware spatiotemporal causal graph network for forecasting with limited data},
  url          = {https://openreview.net/forum?id=n3yrVzPcNa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic gradient descent algorithm with random search directions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=npER8AaLSb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic coordinate descent algorithms are efficient methods in which each iterate is obtained by fixing most coordinates at their values from the current iteration, and approximately minimizing the objective with respect to the remaining coordinates. However, this approach is usually restricted to canonical basis vectors of $\mathbb{R}^d$. In this paper, we develop the class of stochastic gradient descent algorithms with random search directions. These methods use the directional derivative of the gradient estimate following more general random vectors. We establish the almost sure convergence of these algorithms with decreasing step. We further investigate their central limit theorem and pay particular attention to analyze the impact of the search distributions on the asymptotic covariance matrix. We also provide non-asymptotic $\mathbb{L}^p$ rates of convergence.},
  archive      = {J_TMLR},
  author       = {Eméric Gbaguidi},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A stochastic gradient descent algorithm with random search directions},
  url          = {https://openreview.net/forum?id=npER8AaLSb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReFeR: Improving evaluation and reasoning through hierarchy of models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=otSHFe8wTf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the quality of generative model outputs from large language models (LLMs) or vision-language models (VLMs), poses significant challenges. Traditional evaluation methods either rely on human assessment which is resource-intensive and not scalable or on automatic metrics that often correlate poorly with human preferences. Another approach is to train dedicated neural evaluators, but this typically requires substantial training data and compute. In this study, we thus introduce ReFeR, a tuning-free framework for evaluating generative outputs including both text and images, using a two-level hierarchy of pre-trained LLM and VLM evaluators. This multi-agent hierarchical strategy leverages additional compute at inference time by orchestrating multiple models and utilizing the increased test-time reasoning to boost performance. By having models themselves provide feedback and final judgments, ReFeR reduces the dependence on human evaluation. We rigorously evaluate ReFeR on four diverse evaluation benchmarks, where it surpasses prior methods in accuracy while also generating constructive feedback useful for downstream distillation and self-improvement via finetuning. Interestingly, ReFeR is also applicable for reasoning tasks - experiments on four reasoning benchmarks show ReFeR’s superior collective reasoning abilities. We present two variants of the framework: ReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a more test-time compute efficient solution. ReFeR-Lite is $\sim12-14\times$ more compute efficient than previous works while being comparably accurate to ReFeR-Turbo.},
  archive      = {J_TMLR},
  author       = {Yaswanth Narsupalli and Abhranil Chandra and Sreevatsa Muppirala and Manish Gupta and Pawan Goyal},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ReFeR: Improving evaluation and reasoning through hierarchy of models},
  url          = {https://openreview.net/forum?id=otSHFe8wTf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FoldDiff: Folding in point cloud diffusion. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pmRabMH1JW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion denoising has emerged as a powerful approach for modeling data distributions, treating data as particles with their position and velocity modeled by a stochastic diffusion process. While this framework assumes data resides in a fixed vector spaces (e.g., images as pixel-ordered vectors), point clouds present unique challenges due to their unordered representation. Existing point cloud diffusion methods often rely on voxelization to address this issue, but this approach is computationally expensive, with cubically scaling complexity. In this work, we investigate the misalignment between point cloud irregularity and diffusion models, analyzing it through the lens of denoising implicit priors. First, we demonstrate how the unknown permutations inherent in point cloud structures disrupt denoising implicit priors. To address this, we then propose a novel folding-based approach that reorders point clouds into a permutation-invariant grid, enabling diffusion to be performed directly on the structured representation. This construction is exploited both globally and locally. Globally, \reviewcdmS{folded objects can represent point cloud objects} in a fixed vector space (like images), therefore it enables us to extend the work of denoising as implicit priors to point clouds. \reviewcdmS{Locally, the folded tokens are} efficient and novel token representations that can improve existing transformer-based point cloud diffusion models. Our experiments show that the proposed folding operation integrates effectively with both denoising implicit priors as well as advanced diffusion architectures, such as UNet and Diffusion Transformers (DiTs). Notably, DiT with \reviewcdmS{locally} folded tokens achieves competitive generative performance compared to state-of-the-art models while significantly reducing training and inference costs relative to voxelization-based methods.},
  archive      = {J_TMLR},
  author       = {Yuzhou Zhao and Juan Matias Di Martino and Amirhossein Farzam and Guillermo Sapiro},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FoldDiff: Folding in point cloud diffusion},
  url          = {https://openreview.net/forum?id=pmRabMH1JW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph personalized federated learning via client network learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pyTTR4pxkU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification is a widely studied problem for applications such as molecule/protein function prediction and drug discovery. Powerful graph neural networks (GNNs) have demonstrated state-of-the-art performance for the classification of complex graphs, but training such models can require significant amounts of high-quality labeled graphs that are expensive to collect. When individual institutes do not possess sufficient graph data, federated learning (FL) becomes a handy solution for them to collaboratively obtain powerful graph models without directly sharing their own graph data. However, existing FL frameworks for graph data do not consider the realistic setting of personalized FL with heterogeneous data, where each client aims to leverage the data of certain other clients to boost its own model performance. In this work, inspired by graph structure learning, we propose to learn a dynamic client network that tracks the graph data similarity across clients to guide model sharing along FL. Specifically, we rely on the marginal parameters of local GNNs to dynamically learn the client network, and refer to a set of fundamental graph properties to guide its learning. Extensive experiments on three real-world graph datasets demonstrate the consistent effectiveness of our two major proposed modules, which also mutually verify the effectiveness of each other.},
  archive      = {J_TMLR},
  author       = {Jiachen Zhou and Han Xie and Carl Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph personalized federated learning via client network learning},
  url          = {https://openreview.net/forum?id=pyTTR4pxkU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rollout total correlation for deep reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qTdRJAL8Li'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning task-relevant representations is crucial for reinforcement learning. Recent approaches aim to learn such representations by improving the temporal consistency in the observed transitions. However, they only consider individual transitions and can fail to achieve long-term consistency. Instead, we argue that capturing aspects of the state that correlate with other states and actions of the trajectory---even more distant in the future---could further help in extracting task-relevant information. Hence, in this paper we investigate how to learn representations by maximizing the rollout total correlation, the correlation among all learned representations and actions within the trajectories produced by the agent. For improving rollout total correlation, we propose to combine two complementary lower bounds based on a generative and a discriminative model, combined with a simple and effective technique of chunk-wise mini-batching. Furthermore, we propose an intrinsic reward based on the learned representation for better exploration. Experimental evaluations on a set of challenging image-based simulated control tasks show that our method achieves better sample efficiency, and robustness to both white noise and natural video backgrounds compared to leading baselines.},
  archive      = {J_TMLR},
  author       = {Bang You and Huaping Liu and Jan Peters and Oleg Arenz},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rollout total correlation for deep reinforcement learning},
  url          = {https://openreview.net/forum?id=qTdRJAL8Li},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic-evolutionary graph neural networks: A paradigm for improved graph representation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qzYTklXVAB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message-passing graph neural networks have become the dominant framework for learning over graphs. However, empirical studies continually show that message-passing graph neural networks tend to generate over-smoothed representations for nodes after iteratively applying message passing. This over-smoothing problem is a core issue that limits the representational capacity of message-passing graph neural networks. We argue that the fundamental problem with over-smoothing is a lack of diversity in the generated embeddings, and the problem could be reduced by enhancing the embedding diversity in the embedding generation process. To this end, we propose genetic-evolutionary graph neural networks, a new paradigm for graph representation learning inspired by genetic algorithms. We view each layer of a graph neural network as an evolutionary process and develop operations based on crossover and mutation to prevent embeddings from becoming similar to one another, thus enabling the model to generate improved graph representations. The proposed framework has good interpretablility, as it directly draws inspiration from genetic algorithms for preserving population diversity. We experimentally validate the proposed framework on six benchmark datasets on different tasks. The results show that our method significant advances the performance of current graph neural networks, resulting in new state-of-the-art results for graph representation learning on these datasets.},
  archive      = {J_TMLR},
  author       = {Haimin ZHANG and Min Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Genetic-evolutionary graph neural networks: A paradigm for improved graph representation learning},
  url          = {https://openreview.net/forum?id=qzYTklXVAB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled and self-explainable node representation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=s51TQ8Eg1e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node embeddings are low-dimensional vectors that capture node properties, typically learned through unsupervised structural similarity objectives or supervised tasks. While recent efforts have focused on post-hoc explanations for graph models, intrinsic interpretability in unsupervised node embeddings remains largely underexplored. To bridge this gap, we introduce DiSeNE (Disentangled and Self-Explainable Node Embedding), a framework that learns self-explainable node representations in an unsupervised fashion. By leveraging disentangled representation learning, DiSeNE ensures that each embedding dimension corresponds to a distinct topological substructure of the graph, thus offering clear, dimension-wise interpretability. We introduce new objective functions grounded in principled desiderata, jointly optimizing for structural fidelity, disentanglement, and human interpretability. Additionally, we propose several new metrics to evaluate representation quality and human interpretability. Extensive experiments on multiple benchmark datasets demonstrate that DiSeNE not only preserves the underlying graph structure but also provides transparent, human-understandable explanations for each embedding dimension.},
  archive      = {J_TMLR},
  author       = {Simone Piaggesi and André Panisson and Megha Khosla},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Disentangled and self-explainable node representation learning},
  url          = {https://openreview.net/forum?id=s51TQ8Eg1e},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node-level data valuation on graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tNyApIqDSJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How much is a node worth? We answer this question using an emerging set of data valuation techniques, where the value of a data point is measured via its marginal contribution when added to the (training) dataset. Data valuation has been primarily studied in the i.i.d. setting, giving rise to methods like influence functions, leave-one-out estimation, data Shapley, and data Banzhaf. We conduct a comprehensive study of data valuation approaches applied to graph-structured models such as graph neural networks in a semi-supervised transductive setting. Since all nodes (labeled and unlabeled) influence both training and inference we construct various scenarios to understand the diverse mechanisms by which nodes can impact learning. We show that the resulting node values can be used to identify (positively and negatively) influential nodes, quantify model brittleness, detect poisoned data, and accurately predict counterfactuals.},
  archive      = {J_TMLR},
  author       = {Simone Antonelli and Aleksandar Bojchevski},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Node-level data valuation on graphs},
  url          = {https://openreview.net/forum?id=tNyApIqDSJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spurious privacy leakage in neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tRXDCIgvTT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks trained on real-world data often exhibit biases while simultaneously being vulnerable to privacy attacks aimed at extracting sensitive information. Despite extensive research on each problem individually, their intersection remains poorly understood. In this work, we investigate the privacy impact of spurious correlation bias. We introduce _spurious privacy leakage_, a phenomenon in which spurious groups are significantly more vulnerable to privacy attacks than non-spurious groups. We observe that privacy disparity between groups increases in tasks with simpler objectives (e.g. fewer classes) due to spurious features. Counterintuitively, we demonstrate that spurious robust methods, designed to reduce spurious bias, fail to mitigate privacy disparity. Our analysis reveals that this occurs because robust methods can reduce reliance on spurious features for prediction, but do not prevent their memorization during training. Finally, we systematically compare the privacy of different model architectures trained with spurious data, demonstrating that, contrary to previous work, architectural choice can affect privacy evaluation.},
  archive      = {J_TMLR},
  author       = {Chenxiang Zhang and Jun Pang and Sjouke Mauw},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Spurious privacy leakage in neural networks},
  url          = {https://openreview.net/forum?id=tRXDCIgvTT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential score matching: Debiasing molecular structure sampling with potential energy guidance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tTdzbnvTno'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ensemble average of physical properties of molecules is closely related to the distribution of molecular conformations, and sampling such distributions is a fundamental challenge in physics and chemistry. Traditional methods like molecular dynamics (MD) simulations and Markov chain Monte Carlo (MCMC) sampling are commonly used but can be time-consuming and costly. Recently, diffusion models have emerged as efficient alternatives by learning the distribution of training data. Obtaining an unbiased target distribution is still an expensive task, primarily because it requires satisfying ergodicity. To tackle these challenges, we propose Potential Score Matching (PSM), an approach that utilizes the potential energy gradient to guide generative models. PSM does not require exact energy functions and can debias sample distributions even when trained on limited and biased data. Our method outperforms existing state-of-the-art (SOTA) models on the Lennard-Jones (LJ) potential, a commonly used toy model. Furthermore, we extend the evaluation of PSM to high-dimensional problems using the MD17 and MD22 datasets. The results demonstrate that molecular distributions generated by PSM more closely approximate the Boltzmann distribution compared to traditional diffusion models.},
  archive      = {J_TMLR},
  author       = {Liya Guo and Zun Wang and Chang Liu and Junzhe Li and Pipi Hu and Yi Zhu and Tao Qin},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Potential score matching: Debiasing molecular structure sampling with potential energy guidance},
  url          = {https://openreview.net/forum?id=tTdzbnvTno},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Don’t judge before you CLIP: A unified approach for perceptual tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uvQTYi6kbu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual perceptual tasks aim to predict human judgment of images (e.g., emotions invoked by images, image quality assessment). Unlike objective tasks such as object/scene recognition, perceptual tasks rely on {subjective} human assessments, making their data-labeling difficult. The scarcity of such human-annotated data results in small datasets leading to poor generalization. Typically, specialized models were designed for each perceptual task, tailored to its unique characteristics and its own training dataset. We propose an identical architectural framework for solving multiple different perceptual tasks leveraging CLIP as a prior. Our approach is based on recent cognitive findings which indicate that CLIP correlates well with human judgment. While CLIP was explicitly trained to align images and text, it implicitly also learned human inclinations. We attribute this to the inclusion of human-written image captions in CLIP's training data, which contain not only factual image descriptions, but inevitably also human sentiments and emotions. This makes CLIP a particularly strong prior for perceptual tasks. Accordingly, we suggest that minimal adaptation of CLIP suffices for solving a variety of perceptual tasks. Our simple unified framework employs a lightweight adaptation to fine-tune CLIP to each task, without requiring any task-specific architectural changes. We evaluate our approach on three tasks: (i) Image Memorability Prediction, (ii) No-reference Image Quality Assessment, and (iii) Visual Emotion Analysis. Our model achieves state-of-the-art results on all three tasks, while demonstrating improved generalization across different datasets.},
  archive      = {J_TMLR},
  author       = {Amit Zalcher and navve wasserman and Roman Beliy and Oliver Heinimann and michal Irani},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Don’t judge before you CLIP: A unified approach for perceptual tasks},
  url          = {https://openreview.net/forum?id=uvQTYi6kbu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiDoRA: Bi-level optimization-based weight-decomposed low-rank adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=v2xCm3VYl4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) is a flexible and efficient method for adapting large language models (LLMs) to downstream tasks. Among these methods, weight-decomposed low-rank adaptation (DoRA) is a promising approach that decomposes weight matrices into magnitude and direction components to mimic full fine-tuning (FT) better. However, DoRA's simultaneous optimization of these components makes it over-expressive, increases the risk of overfitting, and creates a coupled updating pattern that limits its learning capacity. To address these issues, we propose Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation (BiDoRA), a novel PEFT method based on a bi-level optimization framework. BiDoRA fundamentally differs from DoRA by optimizing the magnitude and direction in two separate, asynchronous loops using distinct training and validation data splits. This decoupled optimization process effectively mitigates overfitting and allows for more flexible updates that align even more closely with FT. For instance, weight decomposition analysis shows BiDoRA achieves a magnitude-direction update correlation of $-8.042$, significantly closer to the FT ideal compared to $-1.784$ for DoRA. Evaluation of BiDoRA on diverse tasks spanning natural language understanding, generation, token classification, and extremely small biomedical datasets reveals that it consistently outperforms DoRA and a wide range of leading PEFT methods. This improvement is statistically significant, as demonstrated on the GLUE benchmark where BiDoRA surpasses DoRA with a p-value of $2.4\times10^{-4}$ in terms of the Wilcoxon signed-rank test. The code for BiDoRA is available at https://github.com/t2ance/BiDoRA.},
  archive      = {J_TMLR},
  author       = {Peijia Qin and Ruiyi Zhang and Pengtao Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {BiDoRA: Bi-level optimization-based weight-decomposed low-rank adaptation},
  url          = {https://openreview.net/forum?id=v2xCm3VYl4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does equivariance matter at scale?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wilNute8Tn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given large datasets and sufficient compute, is it beneficial to design neural architectures for the structure and symmetries of each problem? Or is it more efficient to learn them from data? We study empirically how equivariant and non-equivariant networks scale with compute and training samples. Focusing on a benchmark problem of rigid-body interactions and on general-purpose transformer architectures, we perform a series of experiments, varying the model size, training steps, and dataset size. We find evidence for three conclusions. First, equivariance improves data efficiency, but training non-equivariant models with data augmentation can close this gap given sufficient epochs. Second, scaling with compute follows a power law, with equivariant models outperforming non-equivariant ones at each tested compute budget. Finally, the optimal allocation of a compute budget onto model size and training duration differs between equivariant and non-equivariant models.},
  archive      = {J_TMLR},
  author       = {Johann Brehmer and Sönke Behrends and Pim De Haan and Taco Cohen},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Does equivariance matter at scale?},
  url          = {https://openreview.net/forum?id=wilNute8Tn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mamba state-space models are lyapunov-stable learners. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wzsYQYs3dO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba state-space models (SSMs) have recently outperformed state-of-the-art (SOTA) Transformer large language models (LLMs) in various tasks and been widely adapted. However, a major concern for stable learning in recurrent-based deep models (such as SSMs) is the sensitivity of their recurrent dynamics. Despite widespread adaptation, the sensitivity of Mamba’s recurrent dynamics under common fine-tuning methods–e.g., mixed-precision fine-tuning (MPFT) and parameter-efficient fine-tuning (PEFT)–remains unexplored. Empirically, we show that Mamba LLMs are extremely stable to changes introduced by combinations of MPFT and PEFT, in stark contrast to Transformer LLMs, which we demonstrate may drastically diverge from their respective full-precision counterparts under different combinations of MPFT and PEFT (despite the near-ubiquitous adaptation of these fine-tuning frameworks for attention-based models). The demonstrated robustness of Mamba LLMs are due to their recurrent dynamics, which we prove are guaranteed to be stable using dynamical systems theory (in particular, Lyapunov stability). We conclude by using MPFT and PEFT to novelly study Mamba LLMs’ in-context learning (ICL) abilities on natural language tasks, thus supplementing other recent work.},
  archive      = {J_TMLR},
  author       = {John Timothy Halloran and Manbir S Gulati and Paul F Roysdon},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mamba state-space models are lyapunov-stable learners},
  url          = {https://openreview.net/forum?id=wzsYQYs3dO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mixture of exemplars approach for efficient out-of-distribution detection with foundation models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xpKqnSJtE4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the early weaknesses identified in deep neural networks trained for image classification tasks was their inability to provide low confidence predictions on out-of-distribution (OOD) data that was significantly different from the in-distribution (ID) data used to train them. Representation learning, where neural networks are trained in specific ways that improve their ability to detect OOD examples, has emerged as a promising solution. However, these approaches require long training times and can add additional overhead to detect OOD examples. Recent developments in Vision Transformer (ViT) foundation models—large networks trained on large and diverse datasets with self-supervised approaches—also show strong performance in OOD detection, and could address these challenges. This paper presents Mixture of Exemplars (MoLAR), an efficient approach to tackling OOD detection challenges that is designed to maximise the benefit of training a classifier with a high quality, frozen, pretrained foundation model backbone. MoLAR provides strong OOD detection performance when only comparing the similarity of OOD examples to the exemplars, a small set of images chosen to be representative of the dataset, leading to \mhl{significantly reduced overhead} for OOD detection inference over other methods that provide best performance when the full ID dataset is used. Extensive experiments demonstrate the improved OOD detection performance of MoLAR in comparison to comparable approaches in both supervised and semi-supervised settings, and code is available at github.com/emannix/molar-mixture-of-exemplars.},
  archive      = {J_TMLR},
  author       = {Evelyn Mannix and Howard Bondell},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A mixture of exemplars approach for efficient out-of-distribution detection with foundation models},
  url          = {https://openreview.net/forum?id=xpKqnSJtE4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slicing the gaussian mixture wasserstein distance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yPBtJ4JPwi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian mixture models (GMMs) are widely used in machine learning for tasks such as clustering, classification, image reconstruction, and generative modeling. A key challenge in working with GMMs is defining a computationally efficient and geometrically meaningful metric. The mixture Wasserstein (MW) distance adapts the Wasserstein metric to GMMs and has been applied in various domains, including domain adaptation, dataset comparison, and reinforcement learning. However, its high computational cost—arising from repeated Wasserstein distance computations involving matrix square root estimations and an expensive linear program—limits its scalability to high-dimensional and large-scale problems. To address this, we propose multiple novel slicing-based approximations to the MW distance that significantly reduce computational complexity while preserving key optimal transport properties. From a theoretical viewpoint, we establish several weak and strong equivalences between the introduced metrics, and show the relations to the original MW distance and the well-established sliced Wasserstein distance. Furthermore, we validate the effectiveness of our approach through numerical experiments, demonstrating computational efficiency and applications in clustering, perceptual image comparison, and GMM minimization},
  archive      = {J_TMLR},
  author       = {Moritz Piening and Robert Beinert},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Slicing the gaussian mixture wasserstein distance},
  url          = {https://openreview.net/forum?id=yPBtJ4JPwi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variance reduced smoothed functional REINFORCE policy gradient algorithms. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yagxqSJbiY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the REINFORCE policy gradient algorithm from the literature that works with reward (or cost) returns obtained over episodes or trajectories. We propose a major enhancement to the basic algorithm where we estimate the policy gradient using a smoothed functional (random perturbation) gradient estimator obtained from direct function measurements. To handle the issue of high variance that is typical of REINFORCE, we propose two independent enhancements to the basic scheme: (i) use the sign of the increment instead of the original (full) increment that results in smoother convergence and (ii) use clipped gradient estimates as proposed in the Proximal Policy Optimization (PPO) based scheme. We prove the asymptotic convergence of all algorithms and show the results of several experiments on various MuJoCo locomotion tasks wherein we compare the performance of our algorithms with the recently proposed ARS algorithms in the literature as well as other well known algorithms namely A2C, PPO and TRPO. Our algorithms are seen to be competitive against all algorithms and in fact show the best results on a majority of experiments.},
  archive      = {J_TMLR},
  author       = {Shalabh Bhatnagar and Deepak H R},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variance reduced smoothed functional REINFORCE policy gradient algorithms},
  url          = {https://openreview.net/forum?id=yagxqSJbiY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CYCle: Choosing your collaborators wisely to enhance collaborative fairness in decentralized learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ygqNiLQqfH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative learning (CL) enables multiple participants to jointly train machine learning (ML) models on decentralized data sources without raw data sharing. While the primary goal of CL is to maximize the expected accuracy gain for each participant, it is also important to ensure that the gains are fairly distributed: no client should be negatively impacted, and gains should reflect contributions. Most existing CL methods require central coordination and focus only on gain maximization, overlooking fairness. In this work, we first show that the existing measure of collaborative fairness based on the correlation between accuracy values without and with collaboration has drawbacks because it does not account for negative collaboration gain. We argue that maximizing mean collaboration gain (MCG) while simultaneously minimizing the collaboration gain spread (CGS) is a fairer alternative. Next, we propose the CYCle protocol that enables individual participants in a private decentralized learning (PDL) framework to achieve this objective through a novel reputation scoring method based on gradient alignment between the local cross-entropy and distillation losses. We further extend the CYCle protocol to operate on top of gossip-based decentralized algorithms such as Gossip-SGD. We also theoretically show that CYCle performs better than standard FedAvg in a two-client mean estimation setting under high heterogeneity. Empirical experiments demonstrate the effectiveness of the CYCle protocol to ensure positive and fair collaboration gains for all participants, even in cases where the data distributions of participants are highly skewed. The code can be found at https://github.com/tnurbek/cycle.},
  archive      = {J_TMLR},
  author       = {Nurbek Tastan and Samuel Horváth and Karthik Nandakumar},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CYCle: Choosing your collaborators wisely to enhance collaborative fairness in decentralized learning},
  url          = {https://openreview.net/forum?id=ygqNiLQqfH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAREL: Instruction-guided reinforcement learning with cross-modal auxiliary objectives. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zJUEYr5X1X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grounding the instruction in the environment is a key step in solving language-guided goal-reaching reinforcement learning problems. In automated reinforcement learning, a key concern is to enhance the model's ability to generalize across various tasks and environments. In goal-reaching scenarios, the agent must comprehend the different parts of the instructions within the environmental context in order to complete the overall task successfully. In this work, we propose \textbf{CAREL} (\textit{\textbf{C}ross-modal \textbf{A}uxiliary \textbf{RE}inforcement \textbf{L}earning}) as a new framework to solve this problem using auxiliary loss functions inspired by video-text retrieval literature and a novel method called instruction tracking, which automatically keeps track of progress in an environment. The results of our experiments suggest superior sample efficiency and systematic generalization for this framework in multi-modal reinforcement learning problems.},
  archive      = {J_TMLR},
  author       = {Armin Saghafian and Amirmohammad Izadi and Negin Hashemi Dijujin and Mahdieh Soleymani Baghshah},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CAREL: Instruction-guided reinforcement learning with cross-modal auxiliary objectives},
  url          = {https://openreview.net/forum?id=zJUEYr5X1X},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferring reasoning capabilities between LLMs operating via curriculum learning policy. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zPKqyjmyEQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-context reasoning methods, exemplified by Chain-of-Thought (CoT) (et alia.,) empower the reasoning abilities of large language models (LLMs), eliciting them to solve complex reasoning tasks step-by-step. Nevertheless, the capacities to deliver robust CoT explanations arise only in models with billions of parameters, representing a barrier to entry for many users forced to operate on a smaller model scale, i.e., Small Language Models (SLMs). Even though many companies are releasing LLMs of the same family with a reduced number of parameters, these models sometimes produce misleading answers and are unable to deliver accurate step-wise reasoned answers. This paper proposes a method to transfer step-wise reasoning over SLMs by operating via Instruction-tuning (IT) on synthetic demonstrations delivered in a pedagogically motivated manner. In particular, firstly, we propose aligning step-wise reasoning capabilities via IT using Demonstrations "taught" by LLMs teacher to SLMs students. Then, we operate via Curriculum Learning, a pedagogically motivated learning method that improves the IT phase. We analyse the impact on the downstream performances of four question-answering benchmarks. The results show that SMLs can be instructed to reason via Demonstrations delivered by LLMs. We move a step further in research: conceiving SLMs as human learners, we expose them to a CL teaching-based approach, obtaining better results on downstream performances.},
  archive      = {J_TMLR},
  author       = {Leonardo Ranaldi and Giulia Pucci and Fabio Massimo Zanzotto},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transferring reasoning capabilities between LLMs operating via curriculum learning policy},
  url          = {https://openreview.net/forum?id=zPKqyjmyEQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cardinality sparsity: Applications in matrix-matrix multiplications and machine learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zoSRSpGu9C'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data has become ubiquitous across the sciences but presents computational and statistical challenges. A common approach to addressing these challenges is through sparsity. In this paper, we introduce a new concept of sparsity, called cardinality sparsity. Broadly speaking, we define a tensor as sparse if it contains only a small number of unique values. We demonstrate that cardinality sparsity can improve deep learning and tensor regression both statistically and computationally. Along the way, we generalize recent statistical theories in these fields. Most importantly, we show that cardinality sparsity has a strikingly powerful application beyond high-dimensional data analysis: it can significantly speed up matrix-matrix multiplications. For instance, we demonstrate that cardinality sparsity leads to algorithms for binary-matrix multiplication that outperform state-of-the-art algorithms by a substantial margin. Additionally, another crucial aspect of this sparsity is minimizing memory usage. By executing matrix multiplication in the compressed domain, we can significantly lower the amount of memory needed to store the input data.},
  archive      = {J_TMLR},
  author       = {Ali Mohaddes and Johannes Lederer},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cardinality sparsity: Applications in matrix-matrix multiplications and machine learning},
  url          = {https://openreview.net/forum?id=zoSRSpGu9C},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifier-free guidance is a predictor-corrector. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zrWNtzSZsf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the theoretical foundations of classifier-free guidance (CFG). CFG is the dominant method of conditional sampling for text-to-image diffusion models, yet unlike other aspects of diffusion, it remains on shaky theoretical footing. In this paper, we first show that CFG interacts differently with DDPM (Ho et al., 2020) and DDIM (Song et al., 2021), and neither sampler with CFG generates the gamma-powered distribution $p(x|c)^\gamma p(x)^{1-\gamma}$. Then, we clarify the behavior of CFG by showing that it is a kind of predictor-corrector method (Song et al., 2020) that alternates between denoising and sharpening, which we call predictor-corrector guidance (PCG). We prove that in the SDE limit, CFG is actually equivalent to combining a DDIM predictor for the conditional distribution together with a Langevin dynamics corrector for a gamma-powered distribution (with a carefully chosen gamma). Our work thus provides a lens to theoretically understand CFG by embedding it in a broader design space of principled sampling methods.},
  archive      = {J_TMLR},
  author       = {Arwen Bradley and Preetum Nakkiran},
  journal      = {Transactions on Machine Learning Research},
  month        = {8},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Classifier-free guidance is a predictor-corrector},
  url          = {https://openreview.net/forum?id=zrWNtzSZsf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time fairness and robustness in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1fML4VF5FG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frontier Large Language Models (LLMs) can be socially discriminatory or sensitive to spurious features of their inputs. Because only well-resourced corporations can train frontier LLMs, we need robust test-time strategies to control such biases. Existing solutions, which instruct the LLM to be fair or robust, rely on the model’s implicit understanding of bias. Causality provides a rich formalism through which we can be explicit about our debiasing requirements. Yet, as we show, a naive application of the standard causal debiasing strategy, counterfactual data augmentation, fails to fulfill individual-level debiasing requirements at test time. To address this, we develop stratified invariance, a flexible debiasing notion that can capture a range of debiasing requirements, from population level to individual level, through an additional measurement that stratifies the predictions. We developed a complete test for this new approach and introduced a data augmentation strategy that guarantees stratified invariance at test time under suitable assumptions, together with a prompting strategy that encourages stratified invariance in LLMs. We show that our prompting strategy, unlike implicit instructions, consistently reduces the bias of frontier LLMs across a suite of synthetic and real-world benchmarks without requiring additional data, finetuning or pre-training.},
  archive      = {J_TMLR},
  author       = {Leonardo Cotta and Chris J. Maddison},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Test-time fairness and robustness in large language models},
  url          = {https://openreview.net/forum?id=1fML4VF5FG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian neighborhood adaptation for graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2zEemRib3a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for message aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis shows that the scope inference improves the expressivity of a GNN. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, achieving competitive or superior performance on the node classification task, and providing well-calibrated predictions.},
  archive      = {J_TMLR},
  author       = {Paribesh Regmi and Rui Li and Kishan K C},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian neighborhood adaptation for graph neural networks},
  url          = {https://openreview.net/forum?id=2zEemRib3a},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning federated neural graph databases for answering complex queries from distributed knowledge graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3K1LRetR6Y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for deep learning-based foundation models has highlighted the importance of efficient data retrieval mechanisms. Neural graph databases (NGDBs) offer a compelling solution, leveraging neural spaces to store and query graph-structured data, thereby enabling LLMs to access precise and contextually relevant information. However, current NGDBs are constrained to single-graph operation, limiting their capacity to reason across multiple, distributed graphs. Furthermore, the lack of support for multi-source graph data in existing NGDBs hinders their ability to capture the complexity and diversity of real-world data. In many applications, data is distributed across multiple sources, and the ability to reason across these sources is crucial for making informed decisions. This limitation is particularly problematic when dealing with sensitive graph data, as directly sharing and aggregating such data poses significant privacy risks. As a result, many applications that rely on NGDBs are forced to choose between compromising data privacy or sacrificing the ability to reason across multiple graphs. To address these limitations, we propose to learn Federated Neural Graph DataBase (FedNGDB), a pioneering systematic framework that empowers privacy-preserving reasoning over multi-source graph data. FedNGDB leverages federated learning to collaboratively learn graph representations across multiple sources, enriching relationships between entities, and improving the overall quality of graph data. Unlike existing methods, FedNGDB can handle complex graph structures and relationships, making it suitable for various downstream tasks. We evaluate FedNGDBs on three real-world datasets, demonstrating its effectiveness in retrieving relevant information from multi-source graph data while keeping sensitive information secure on local devices. Our results show that FedNGDBs can efficiently retrieve answers to cross-graph queries, making it a promising approach for LLMs and other applications that rely on efficient data retrieval mechanisms.},
  archive      = {J_TMLR},
  author       = {Qi Hu and Weifeng Jiang and Haoran Li and Zihao Wang and Jiaxin Bai and Qianren Mao and Yangqiu Song and Lixin Fan and Jianxin Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning federated neural graph databases for answering complex queries from distributed knowledge graphs},
  url          = {https://openreview.net/forum?id=3K1LRetR6Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do concept bottleneck models respect localities?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4mCkRbUXOf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based explainability methods use human-understandable intermediaries to produce explanations for machine learning models. These methods assume concept predictions can help understand a model's internal reasoning. In this work, we assess the degree to which such an assumption is true by analyzing whether concept predictors leverage "relevant" features to make predictions, a term we call locality. Concept-based models that fail to respect localities also fail to be explainable because concept predictions are based on spurious features, making the interpretation of the concept predictions vacuous. To assess whether concept-based models respect localities, we construct and use three metrics to characterize when models respect localities, complementing our analysis with theoretical results. Each of our metrics captures a different notion of perturbation and assess whether perturbing "irrelevant" features impacts the predictions made by a concept predictors. We find that many concept-based models used in practice fail to respect localities because concept predictors cannot always clearly distinguish distinct concepts. Based on these findings, we propose suggestions for alleviating this issue.},
  archive      = {J_TMLR},
  author       = {Naveen Janaki Raman and Mateo Espinosa Zarlenga and Juyeon Heo and Mateja Jamnik},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Do concept bottleneck models respect localities?},
  url          = {https://openreview.net/forum?id=4mCkRbUXOf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reproducibility study of decoupling feature extraction and classification layers for calibrated neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5Hwzd48ILf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many neural networks, especially over-parameterized ones, suffer from poor calibration and overconfidence. To address this, Jordahn & Olmos (2024) recently proposed a Two-Stage Training (TST) procedure that decouples the training of feature extraction and classification layers. In this study, we replicate their findings and extend their work through a series of ablation studies. We reproduce their main results and find that most of them replicate, with slight deviation for CIFAR100. Additionally, we extend the author's results by exploring the impact of different model architectures, Monte Carlo (MC) sample sizes, and classification head designs. We further compare the method with focal loss -- an implicit regularization technique known to improve calibration -- and investigate whether calibration can be improved further by combining the two methods. Beyond focal loss, we also evaluate the effect of incorporating other similar regularization techniques such as label smoothing and L2 regularization during two-stage training. We find that calibration can be improved even further by using focal loss in the first training stage of two-stage training. Similar improvements are observed when combining two-stage training with label smoothing and L2 regularization. Our experiments validate the claims made by Jordahn & Olmos (2024), and show the transferability of the two-stage training to different architectures.},
  archive      = {J_TMLR},
  author       = {Johanna D'Ciofalo Khodaverdian and Eric Banzuzi and Katharina Deckenbach},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A reproducibility study of decoupling feature extraction and classification layers for calibrated neural networks},
  url          = {https://openreview.net/forum?id=5Hwzd48ILf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does confidence calibration improve conformal prediction?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6DDaTwTvdE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction is an emerging technique for uncertainty quantification that constructs prediction sets guaranteed to contain the true label with a predefined probability. Previous works often employ temperature scaling to calibrate classifiers, assuming that confidence calibration benefits conformal prediction. However, the specific impact of confidence calibration on conformal prediction remains underexplored. In this work, we make two key discoveries about the impact of confidence calibration methods on adaptive conformal prediction. Firstly, we empirically show that current confidence calibration methods (e.g., temperature scaling) typically lead to larger prediction sets in adaptive conformal prediction. Secondly, by investigating the role of temperature value, we observe that high-confidence predictions can enhance the efficiency of adaptive conformal prediction. Theoretically, we prove that predictions with higher confidence result in smaller prediction sets on expectation. This finding implies that the rescaling parameters in these calibration methods, when optimized with cross-entropy loss, might counteract the goal of generating efficient prediction sets. To address this issue, we propose \textbf{Conformal Temperature Scaling} (ConfTS), a variant of temperature scaling with a novel loss function designed to enhance the efficiency of prediction sets. This approach can be extended to optimize the parameters of other post-hoc methods of confidence calibration. Extensive experiments demonstrate that our method improves existing adaptive conformal prediction methods in both image and text classification tasks.},
  archive      = {J_TMLR},
  author       = {HuaJun Xi and Jianguo Huang and Kangdao Liu and Lei Feng and Hongxin Wei},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Does confidence calibration improve conformal prediction?},
  url          = {https://openreview.net/forum?id=6DDaTwTvdE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What matters for model merging at scale?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9sbetmvNpW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model merging aims to combine multiple expert models into a more capable single model, offering benefits such as reduced storage and serving costs, improved generalization, and support for decentralized model development. Despite its promise, previous studies have primarily focused on merging a few small models. This leaves many unanswered questions about the effect of scaling model size and how it interplays with other key factors—like the base model quality and number of expert models— to affect the merged model’s performance. This work systematically evaluates the utility of model merging at scale for transformer based models to examine the impact of these different factors. We experiment with merging fully fine-tuned models using four popular merging methods—Averaging, Task Arithmetic, Dare-TIES, and TIES-Merging—across model sizes ranging from 1B to 64B parameters and merging up to 8 different expert models. We evaluate the merged models on both held-in tasks, i.e., the expert’s training tasks, and zero-shot generalization to unseen held-out tasks. Our wide range of experiments provide several new insights about merging transformer based language models at scale and the interplay between different factors. First, we find that merging is more effective when experts are created from strong base models, i.e., models with good zero-shot performance, compared to pre-trained ones. Second, larger models perform better when merged. Third merging consistently improves generalization capabilities. Notably, when merging eight large expert models, the merged models often generalize better compared to the multitask trained models. Fourth, we can better merge more expert models when working with larger models. Fifth, different merging methods behave very similarly at larger scales. Overall, our findings shed light on some interesting properties of model merging while also highlighting some limitations.},
  archive      = {J_TMLR},
  author       = {Prateek Yadav and Tu Vu and Jonathan Lai and Alexandra Chronopoulou and Manaal Faruqui and Mohit Bansal and Tsendsuren Munkhdalai},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What matters for model merging at scale?},
  url          = {https://openreview.net/forum?id=9sbetmvNpW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlled model debiasing through minimal and interpretable updates. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B9fdU4qjpD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches to learning fair machine learning models often require rebuilding models from scratch, typically without considering potentially existing models. In a context where models need to be retrained frequently, this can lead to inconsistent model updates, as well as redundant and costly validation testing. To address this limitation, we introduce the notion of controlled model debiasing, a novel supervised learning task relying on two desiderata: that the differences between the new fair model and the existing one should be (i) minimal and (ii) interpretable. After providing theoretical guarantees to this new problem, we introduce a novel algorithm for algorithmic fairness, COMMOD, that is both model-agnostic and does not require the sensitive attribute at test time. In addition, our algorithm is explicitly designed to enforce minimal and interpretable changes between biased and debiased predictions in a binary classification task—a property that, while highly desirable in high-stakes applications, is rarely prioritized as an explicit objective in fairness literature. Our approach combines a concept-based architecture and adversarial learning and we demonstrate through empirical results that it achieves comparable performance to state-of-the-art debiasing methods while performing minimal and interpretable prediction changes.},
  archive      = {J_TMLR},
  author       = {Federico Di Gennaro and Thibault Laugel and Vincent Grari and Marcin Detyniecki},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Controlled model debiasing through minimal and interpretable updates},
  url          = {https://openreview.net/forum?id=B9fdU4qjpD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaboration with dynamic open ad hoc team via team state modelling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BukMU42P3G'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open ad hoc teamwork presents the challenging problem of designing an autonomous agent that can rapidly adapt to collaborate with teammates without prior coordination in an open environment. Existing methods primarily rely on fixed, predefined teammate types, overlooking the fact that teammates may change dynamically. To address this limitation, we propose a novel reinforcement learning approach, the Open Online Teammate Adaptation Framework (Open-OTAF), which enables a controlled agent to collaborate with dynamic teammates in open ad hoc environments. To achieve this, the controlled agent employs a dual teamwork situation inference model to capture the current teamwork state, facilitating decision-making under partial observability. To handle the dynamic nature of teammate types, we first introduce a Chinese Restaurant Process-based model to categorize diverse teammate policies into distinct clusters, improving the efficiency of identifying teamwork situations. Next, to model heterogeneous agent relationships and accommodate a variable number of teammates, we represent the team as a heterogeneous graph and leverage heterogeneous graph attention neural networks to learn the representation of the teamwork situation. Extensive experiments across four challenging multi-agent benchmark tasks—Level-Based Foraging, Wolf-Pack, Cooperative Navigation, and FortAttack—demonstrate that our method successfully enables dynamic teamwork in open ad hoc settings. Open-OTAF outperforms state-of-the-art methods, achieving superior performance with faster convergence.},
  archive      = {J_TMLR},
  author       = {Jing Sun and Cong Zhang and Zhiguang Cao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Collaboration with dynamic open ad hoc team via team state modelling},
  url          = {https://openreview.net/forum?id=BukMU42P3G},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task arithmetic through the lens of one-shot federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Cgyo7S7Oy0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task Arithmetic is a model merging technique that enables the combination of multiple models' capabilities into a single model through simple arithmetic in the weight space, without the need for additional fine-tuning or access to the original training data. However, the factors that determine the success of Task Arithmetic remain unclear. In this paper, we examine Task Arithmetic for multi-task learning by framing it as a one-shot Federated Learning problem. We demonstrate that Task Arithmetic is mathematically equivalent to the commonly used algorithm in Federated Learning, called Federated Averaging (FedAvg). By leveraging well-established theoretical results from FedAvg, we identify two key factors that impact the performance of Task Arithmetic: data heterogeneity and training heterogeneity. To mitigate these challenges, we adapt several algorithms from Federated Learning to improve the effectiveness of Task Arithmetic. Our experiments demonstrate that applying these algorithms can often significantly boost performance of the merged model compared to the original Task Arithmetic approach. This work bridges Task Arithmetic and Federated Learning, offering new theoretical perspectives on Task Arithmetic and improved practical methodologies for model merging.},
  archive      = {J_TMLR},
  author       = {Zhixu Tao and Ian Mason and Sanjeev Kulkarni and Xavier Boix},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Task arithmetic through the lens of one-shot federated learning},
  url          = {https://openreview.net/forum?id=Cgyo7S7Oy0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Where to intervene: Action selection in deep reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=D3au9XkWuy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (RL) has gained widespread adoption in recent years but faces significant challenges, particularly in unknown and complex environments. Among these, high-dimensional action selection stands out as a critical problem. Existing works often require a sophisticated prior design to eliminate redundancy in the action space, relying heavily on domain expert experience or involving high computational complexity, which limits their generalizability across different RL tasks. In this paper, we address these challenges by proposing a general data-driven action selection approach with model-free and computationally friendly properties. Our method not only selects minimal sufficient actions but also controls the false discovery rate via knockoff sampling. More importantly, we seamlessly integrate the action selection into deep RL methods during online training. Empirical experiments validate the established theoretical guarantees, demonstrating that our method surpasses various alternative techniques in terms of both performance in variable selection and overall achieved rewards.},
  archive      = {J_TMLR},
  author       = {Wenbo Zhang and Hengrui Cai},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Where to intervene: Action selection in deep reinforcement learning},
  url          = {https://openreview.net/forum?id=D3au9XkWuy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free reinforcement learning with noisy actions for automated experimental control in optics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DAYsM4zDNg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Setting up and controlling optical systems is often a challenging and tedious task. The high number of degrees of freedom to control mirrors, lenses, or phases of light makes automatic control challenging, especially when the complexity of the system cannot be adequately modeled due to noise or non-linearities. Here, we show that reinforcement learning (RL) can overcome these challenges when coupling laser light into an optical fiber, using a model-free RL approach that trains directly on the experiment without pre-training on simulations. By utilizing the sample-efficient algorithms Soft Actor-Critic (SAC), Truncated Quantile Critics (TQC), or CrossQ, our agents learn to couple with 90% efficiency. A human expert reaches this efficiency, but the RL agents are quicker. In particular, the CrossQ agent outperforms the other agents in coupling speed while requiring only half the training time. We demonstrate that direct training on an experiment can replace extensive system modeling. Our result exemplifies RL's potential to tackle problems in optics, paving the way for more complex applications where full noise modeling is not feasible.},
  archive      = {J_TMLR},
  author       = {Lea Richtmann and Viktoria-S. Schmiesing and Dennis Wilken and Jan Heine and Aaron D Tranter and Avishek Anand and Tobias J. Osborne and Michèle Heurs},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Model-free reinforcement learning with noisy actions for automated experimental control in optics},
  url          = {https://openreview.net/forum?id=DAYsM4zDNg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Setting the record straight on transformer oversmoothing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HHI6qWLFF1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have recently become wildly successful across a diverse set of domains. At the same time, recent work has shown empirically and theoretically that Transformers are inherently limited. Specifically, they argue that as model depth increases, Transformers oversmooth, i.e., inputs become more and more similar. A natural question is: How can Transformers achieve these successes given this shortcoming? In this work we test these observations empirically and theoretically and uncover a number of surprising findings. We find that there are cases where feature similarity increases but, contrary to prior results, this is not inevitable, even for existing pre-trained models. Theoretically, we show that smoothing behavior depends on the eigenspectrum of the value and projection weights. We verify this empirically and observe that the sign of layer normalization weights can influence this effect. Our analysis reveals a simple way to parameterize the weights of the Transformer update equations to influence smoothing behavior. We hope that our findings give ML researchers and practitioners additional insight into how to develop future Transformer-based models.},
  archive      = {J_TMLR},
  author       = {Gbetondji Jean-Sebastien Dovonon and Michael M. Bronstein and Matt Kusner},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Setting the record straight on transformer oversmoothing},
  url          = {https://openreview.net/forum?id=HHI6qWLFF1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch training for streaming time series: A transferable augmentation framework to combat distribution shifts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ht7rlkRCHq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting, which predicts future dynamics by analyzing historical data, has become an essential tool in modern data analysis. With the development of deep models, batch-training based time series forecasting has made significant progress. However, in real-world applications, time series data is often collected incrementally in a streaming manner, with only a portion of the data available at each time step. As time progresses, distribution shifts in the data can occur, leading to a drastic decline in model performance. To address this challenge, online test-time adaptation and online time series forecasting have emerged as a promising solution. However, for the former, most online test-time adaptation methods are primarily designed for images and do not consider the specific characteristics of time series. As for the latter, online time series forecasting typically relies on updating the model with each newly collected sample individually, which may be problematic when the sample deviates significantly from the historical data distribution and contains noise, which may lead to a worse generalization performance. In this paper, we propose Batch Training with Transferable Online Augmentation (BTOA), which enhances model performance through three key ideas while enabling batch training. First, to fully leverage historical information, Transferable Historical Sample Selection (THSS) is proposed with theoretical guarantees to select historical samples that are most similar to the test-time distribution. Then, to mitigate the negative impact of distribution shifts through batch training and take advantage of the unique characteristics of time series, Transferable Online Augmentation (TOA) is proposed to augment the selected historical samples from the perspective of amplitude and phase in the frequency domain in a two-stream manner. Finally, a prediction module that utilizes a series decomposition module and a two-stream forecaster is employed to extract the complex patterns in time series, boosting the prediction performance. Moreover, BTOA is a general approach that is readily pluggable into any existing batch-training based deep models.Comprehensive experiments under both ideal and practice experimental settings demonstrate that the proposed method exhibits superior performance across all seven benchmark datasets. Compared to state-of-the-art approaches, our method reduces the Mean Squared Error (MSE) by up to 13.7\%.},
  archive      = {J_TMLR},
  author       = {Weiyang Zhang and Xinyang Chen and Yu Sun and Weili Guan and Liqiang Nie},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Batch training for streaming time series: A transferable augmentation framework to combat distribution shifts},
  url          = {https://openreview.net/forum?id=Ht7rlkRCHq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness and disentanglement: A critical review of predominant bias in neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LLiJ1WsL2e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bias issues of neural networks garner significant attention along with their promising advancement. Among various bias issues, mitigating two predominant biases is crucial in advancing fair and trustworthy AI: (1) ensuring neural networks yield even performance across demographic groups, and (2) ensuring algorithmic decision-making does not rely on protected attributes. However, upon the investigation of 415 papers in the relevant literature, we find that there exists a persistent, extensive but under-explored confusion regarding these two types of biases. Furthermore, the confusion has already significantly hampered the clarity of the community and the subsequent development of debiasing methodologies. Thus, in this work, we aim to restore clarity by providing two mathematical definitions for these two predominant biases and leveraging these definitions to unify a comprehensive list of papers. Next, we highlight the common phenomena and the possible reasons for the existing confusion. To alleviate the confusion, we provide extensive experiments on synthetic, census, and image datasets to validate the distinct nature of these biases, distinguish their different real-world manifestations, and evaluate the effectiveness of a comprehensive list of bias assessment metrics in assessing the mitigation of these biases. Further, we compare these two types of biases from multiple dimensions, including the underlying causes, debiasing methods, evaluation protocol, prevalent datasets, and future directions. Last, we provide several suggestions aiming to guide researchers engaged in bias-related work to avoid confusion and further enhance clarity in the community.},
  archive      = {J_TMLR},
  author       = {Jiazhi Li and Mahyar Khayatkhoei and Jiageng Zhu and Hanchen Xie and Mohamed E. Hussein and Wael AbdAlmageed},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness and disentanglement: A critical review of predominant bias in neural networks},
  url          = {https://openreview.net/forum?id=LLiJ1WsL2e},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combinatorial multi-armed bandits: Arm selection via group testing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Mq59rTnIfE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of combinatorial multi-armed bandits with semi-bandit feedback and a cardinality constraint on the super-arm size. Existing algorithms for solving this problem typically involve two key sub-routines: (1) a *parameter estimation* routine that sequentially estimates a set of base-arm parameters, and (2) a *super-arm selection* policy for selecting a subset of base arms deemed optimal based on these parameters. State-of-the-art algorithms assume access to an *exact* oracle for super-arm selection with unbounded computational power. At each instance, this oracle evaluates a list of score functions, the number of which grows as low as linearly and as high as exponentially with the number of arms. This can be prohibitive in the regime of a large number of arms. This paper introduces a novel realistic alternative to the perfect oracle. This algorithm uses a combination of *group-testing* for selecting the super arms and *quantized* Thompson sampling for parameter estimation. Under a general separability assumption on the reward function, the proposed algorithm reduces the complexity of the super-arm-selection oracle to be *logarithmic* in the number of base arms while achieving the same regret order as the state-of-the-art algorithms that use exact oracles. This translates to *at least an exponential* reduction in complexity compared to the oracle-based approaches.},
  archive      = {J_TMLR},
  author       = {Arpan Mukherjee and Shashanka Ubaru and Keerthiram Murugesan and Karthikeyan Shanmugam and Ali Tajer},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Combinatorial multi-armed bandits: Arm selection via group testing},
  url          = {https://openreview.net/forum?id=Mq59rTnIfE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On efficient bayesian exploration in model-based reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Na02hDWqkF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the challenge of data-efficient exploration in reinforcement learning by examining existing principled, information-theoretic approaches to intrinsic motivation. Specifically, we focus on a class of exploration bonuses that targets epistemic uncertainty rather than the aleatoric noise inherent in the environment. We prove that these bonuses naturally signal epistemic information gains and converge to zero once the agent becomes sufficiently certain about the environment’s dynamics and rewards, thereby aligning exploration with genuine knowledge gaps. Our analysis provides formal guarantees for IG-based approaches, which previously lacked theoretical grounding. To enable practical use, we also discuss tractable approximations via sparse variational Gaussian Processes, Deep Kernels and Deep Ensemble models. We then outline a general framework — Predictive Trajectory Sampling with Bayesian Exploration (PTS-BE) — which integrates model-based planning with information-theoretic bonuses to achieve sample-efficient deep exploration. We empirically demonstrate that PTS-BE substantially outperforms other baselines across a variety of environments characterized by sparse rewards and/or purely exploratory tasks.},
  archive      = {J_TMLR},
  author       = {Alberto Caron and Vasilios Mavroudis and Chris Hicks},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On efficient bayesian exploration in model-based reinforcement learning},
  url          = {https://openreview.net/forum?id=Na02hDWqkF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Walking on the fiber: A simple geometric approximation for bayesian neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NsuPykrjOd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Neural Networks provide a principled framework for uncertainty quantification by modeling the posterior distribution of network parameters. However, exact posterior inference is computationally intractable, and widely used approximations like the Laplace method struggle with scalability and posterior accuracy in modern deep networks. In this work, we revisit sampling techniques for posterior exploration, proposing a simple variation tailored to efficiently sample from the posterior in over-parameterized networks by leveraging the low-dimensional structure of loss minima. Building on this, we introduce a model that learns a deformation of the parameter space, enabling rapid posterior sampling without requiring iterative methods. Empirical results demonstrate that our approach achieves competitive posterior approximations with improved scalability compared to recent refinement techniques. These contributions provide a practical alternative for Bayesian inference in deep learning.},
  archive      = {J_TMLR},
  author       = {Alfredo Reichlin and Miguel Vasco and Danica Kragic},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Walking on the fiber: A simple geometric approximation for bayesian neural networks},
  url          = {https://openreview.net/forum?id=NsuPykrjOd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counting hours, counting losses: The toll of unpredictable work schedules on financial security. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PEZz2i9kiP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial instability is a pressing concern in the United States, with drivers that include growing employment disparities and insufficient wages. While research typically focuses on financial aspects such as income inequality in precarious work environments, there is a tendency to overlook the time-related aspect of unstable work schedules. The inability to rely on a consistent work schedule not only leads to burnout and conflicts between work and family life but also results in financial shocks that directly impact workers' income and assets. Unforeseen fluctuations in earnings pose challenges in financial planning, affecting decisions regarding savings and spending, and ultimately undermining individuals' long-term financial stability and well-being. Our objective in this study is to understand how unforeseen fluctuations in earnings exacerbate financial fragility by investigating the extent to which individuals' financial management depends on their ability to anticipate and plan for future events. To answer this question, we present a computational framework to model real-time consumption decisions under income uncertainty, drawing on advances in online planning and reinforcement learning (RL) with lookahead. We introduce a novel online algorithm that enables utility-maximizing agents to dynamically adapt consumption choices in response to financial shocks, leveraging partial deterministic information about future income. This approach forms the basis of our simulation framework, which models how workers manage consumption in the face of variable work schedules and the imperative to avoid financial ruin. Through theoretical analysis, we quantify the utility advantage conferred by varying levels of lookahead. Empirical simulations demonstrate how increased lookahead improves financial utility. That is, with this framework, we demonstrate both theoretically and empirically how a worker's capacity to anticipate schedule changes enhances their long-term utility. Conversely, the inability to predict future events can worsen workers' financial instability. Moreover, our framework enables us to explore policy interventions aimed at mitigating the problem of schedule uncertainty. By modeling both individual behavior and potential policy interventions (e.g., advance scheduling regulations), our framework draws on ideas from machine learning and reinforcement learning to inform economic questions surrounding information access in financial planning.},
  archive      = {J_TMLR},
  author       = {Pegah Nokhiz and Aravinda Kanchana Ruwanpathirana and Aditya Bhaskara and Suresh Venkatasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Counting hours, counting losses: The toll of unpredictable work schedules on financial security},
  url          = {https://openreview.net/forum?id=PEZz2i9kiP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variance dichotomy in feature spaces of facial recognition systems is a weak defense against simple weight manipulation attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q1Cf07flwD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that several leading pretrained facial recognition systems exhibit a variance dichotomy in their feature space. In other words, the feature vectors approximately lie in a lower dimensional linear subspace. We demonstrate that this variance dichotomy degrades the performance of an otherwise powerful scheme for anonymity/unlinkability and confusion attacks on facial recognition system devised by Zehavi et al. (2024), which is based on simple weight manipulations in only the last hidden layer. Lastly, we propose a method for the attacker to overcome this intrinsic defense of these pretrained facial recognition systems.},
  archive      = {J_TMLR},
  author       = {Matthew Bowditch and Mike Paterson and Matthias Englert and Ranko Lazic},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variance dichotomy in feature spaces of facial recognition systems is a weak defense against simple weight manipulation attacks},
  url          = {https://openreview.net/forum?id=Q1Cf07flwD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Celo: Training versatile learned optimizers on a compute diet. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SLqJbt4emY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learned optimization has emerged as a promising alternative to hand-crafted optimizers, with the potential to discover stronger learned update rules that enable faster, hyperparameter-free training of neural networks. A critical element for practically useful learned optimizers, that can be used off-the-shelf after meta-training, is strong meta-generalization: the ability to apply the optimizers to new tasks. Recent state-of-the-art work in learned optimizers, VeLO (Metz et al., 2022), requires a large number of highly diverse meta-training tasks along with massive computational resources, 4000 TPU months, to achieve meta-generalization. This makes further improvements to such learned optimizers impractical. In this work, we identify several key elements in learned optimizer architectures and meta-training procedures that can lead to strong meta-generalization. We also propose evaluation metrics to reliably assess quantitative performance of an optimizer at scale on a set of evaluation tasks. Our proposed approach, Celo, makes a significant leap in improving the meta-generalization performance of learned optimizers and also outperforms tuned state-of-the-art optimizers on a diverse set of out-of-distribution tasks, despite being meta-trained for just 24 GPU hours.},
  archive      = {J_TMLR},
  author       = {Abhinav Moudgil and Boris Knyazev and Guillaume Lajoie and Eugene Belilovsky},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Celo: Training versatile learned optimizers on a compute diet},
  url          = {https://openreview.net/forum?id=SLqJbt4emY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DisDet: Exploring detectability of backdoor attack on diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SfqCaAOF1S'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content-generation tool. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges. In this paper, we explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the distribution discrepancy of the trigger pattern in the existing diffusion backdoor attacks. Based on this finding, we propose a trigger detection mechanism that can effectively identify the poisoned input noise. Then, from the attack side, we propose a backdoor attack strategy that can learn the unnoticeable trigger to evade our proposed detection scheme. Our empirical evaluations across various diffusion models and datasets demonstrate the effectiveness of the proposed trigger detection and detection-evading attack strategy. For trigger detection, our distribution discrepancy-based solution can achieve a 100% detection rate for the Trojan triggers used in the existing works. For evading trigger detection, our proposed stealthy trigger design approach performs end-to-end learning to make the distribution of poisoned noise input approach that of benign noise, enabling nearly 100% detection pass rate with very high attack and benign performance for the backdoored diffusion models.},
  archive      = {J_TMLR},
  author       = {Yang Sui and Huy Phan and Jinqi Xiao and Tianfang Zhang and Zijie Tang and Cong Shi and Yan Wang and Yingying Chen and Bo Yuan},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DisDet: Exploring detectability of backdoor attack on diffusion models},
  url          = {https://openreview.net/forum?id=SfqCaAOF1S},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of contamination detection methods in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SxNMjbtdFm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of Large Language Models (LLMs) in recent years, abundant new opportunities are emerging, but also new challenges, among which contamination is quickly becoming critical. Business applications and fundraising in Artificial Intelligence (AI) have reached a scale at which a few percentage points gained on popular question-answering benchmarks could translate into dozens of millions of dollars, placing high pressure on model integrity. At the same time, it is becoming harder and harder to keep track of the data that LLMs have seen; if not impossible with closed-source models like GPT-4 and Claude-3 not divulging any information on the training set. As a result, contamination becomes a major issue: LLMs’ performance may not be reliable anymore, as the high performance may be at least partly due to their previous exposure to the data. This limitation jeopardizes real capability improvement in the field of NLP, yet, there remains a lack of methods on how to efficiently detect contamination. In this paper, we survey all recent work on contamination detection with LLMs, analyzing their methodologies and use cases to shed light on the appropriate usage of contamination detection methods. Our work calls the NLP research community’s attention into systematically taking into account contamination bias in LLM evaluation.},
  archive      = {J_TMLR},
  author       = {Mathieu Ravaut and Bosheng Ding and Fangkai Jiao and Hailin Chen and Xingxuan Li and Ruochen Zhao and Chengwei Qin and Caiming Xiong and Shafiq Joty},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A comprehensive survey of contamination detection methods in large language models},
  url          = {https://openreview.net/forum?id=SxNMjbtdFm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Successor clusters: A behavior basis for unsupervised zero-shot reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UB22Tt3sfF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce Successor Clusters (SCs), a novel method for tackling unsupervised zero-shot reinforcement learning (RL) problems. The goal in this setting is to directly identify policies capable of optimizing any given reward functions without requiring further learning after an initial reward-free training phase. Existing state-of-the-art techniques leverage Successor Features (SFs)---functions capable of characterizing a policy's expected discounted sum of a set of $d$ reward features. Importantly, however, the performance of existing techniques depends critically on how well the reward features enable arbitrary reward functions of interest to be linearly approximated. We introduce a novel and principled approach for constructing reward features and prove that they allow for any Lipschitz reward functions to be approximated arbitrarily well. Furthermore, we mathematically derive upper bounds on the corresponding approximation errors. Our method constructs features by clustering the state space via a novel distance metric quantifying the minimal expected number of timesteps needed to transition between any state pairs. Building on these theoretical contributions, we introduce Successor Clusters (SCs), a variant of the successor features framework capable of predicting the time spent by a policy in different regions of the state space. We demonstrate that, after a pre-training phase, our method can approximate and maximize any new reward functions in a zero-shot manner. Importantly, we also formally show that as the number and quality of clusters increase, the set of policies induced by Successor Clusters converges to a set containing the optimal policy for any new task. Moreover, we show that our technique naturally produces interpretable features, enabling applications such as visualizing the sequence of state regions an agent is likely to visit while solving a task. Finally, we empirically demonstrate that our method outperforms state-of-the-art SF-based competitors in challenging continuous control benchmarks, achieving superior zero-shot performance and lower reward approximation error.},
  archive      = {J_TMLR},
  author       = {Louis Bagot and Lucas Nunes Alegre and Steven Latre and Kevin Mets and Bruno Castro da Silva},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Successor clusters: A behavior basis for unsupervised zero-shot reinforcement learning},
  url          = {https://openreview.net/forum?id=UB22Tt3sfF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finetuning CLIP to reason about pairwise differences. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=USNJFZTWPn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language models (VLMs) such as CLIP are trained via contrastive learning between text and image pairs, resulting in aligned image and text embeddings that are useful for many downstream tasks. A notable drawback of CLIP, however, is that the resulting embedding space seems to lack some of the structure of its purely text-based alternatives. For instance, while text embeddings have been long noted to satisfy analogies in embedding space using vector arithmetic, CLIP has no such property. In this paper, we propose an approach to natively train CLIP in a contrastive manner to reason about differences in embedding space. We finetune CLIP so that text descriptions of differences between images correspond to their difference in image embedding space, using synthetically generated data with large language models on image-caption paired datasets. We first demonstrate that our approach yields significantly improved capabilities in ranking images by a certain attribute (e.g., elephants are larger than cats), which is useful in retrieval or constructing attribute-based classifiers, and improved zeroshot classification performance on many downstream image classification tasks. In addition, our approach enables a new mechanism for inference that we refer to as comparative prompting, where we leverage prior knowledge of text descriptions of differences between classes of interest, achieving even larger performance gains in classification. Finally, we illustrate that the resulting embeddings obey a larger degree of geometric properties in embedding space, such as in text-to-image generation.},
  archive      = {J_TMLR},
  author       = {Dylan Sam and Devin Willmott and João D. Semedo and J Zico Kolter},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Finetuning CLIP to reason about pairwise differences},
  url          = {https://openreview.net/forum?id=USNJFZTWPn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank momentum factorization for memory efficient training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=W3D3TVo9a3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning large foundation models presents significant memory challenges due to stateful optimizers like AdamW, often requiring several times more GPU memory than inference. While memory-efficient methods like parameter-efficient fine-tuning (e.g., LoRA) and optimizer state compression exist, recent approaches like GaLore bridge these by using low-rank gradient projections and subspace moment accumulation. However, such methods may struggle with fixed subspaces or computationally costly offline resampling (e.g., requiring full-matrix SVDs). We propose Momentum Factorized SGD (MoFaSGD), which maintains a dynamically updated low-rank SVD representation of the first-order momentum, closely approximating its full-rank counterpart throughout training. This factorization enables a memory-efficient fine-tuning method that adaptively updates the optimization subspace at each iteration. Crucially, MoFaSGD leverages the computed low-rank momentum factors to perform efficient spectrally normalized updates, offering an alternative to subspace moment accumulation. We establish theoretical convergence guarantees for MoFaSGD, proving it achieves an optimal rate for non-convex stochastic optimization under standard assumptions. Empirically, we demonstrate MoFaSGD's effectiveness on large language model alignment benchmarks, achieving a competitive trade-off between memory reduction (comparable to LoRA) and performance compared to state-of-the-art low-rank optimization methods. Our implementation is available at \url{https://github.com/pmahdavi/MoFaSGD}.},
  archive      = {J_TMLR},
  author       = {Pouria Mahdavinia and Mehrdad Mahdavi},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Low-rank momentum factorization for memory efficient training},
  url          = {https://openreview.net/forum?id=W3D3TVo9a3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model confidence estimation via black-box access. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WrWYChkyRI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating uncertainty or confidence in the responses of a model can be significant in evaluating trust not only in the responses, but also in the model as a whole. In this paper, we explore the problem of estimating confidence for responses of large language models (LLMs) with simply black-box or query access to them. We propose a simple and extensible framework where, we engineer novel features and train a (interpretable) model (viz. logistic regression) on these features to estimate the confidence. We empirically demonstrate that our simple framework is effective in estimating confidence of Flan-ul2, Llama-13b, Mistral-7b and GPT-4 on four benchmark Q&A tasks as well as of Pegasus-large and BART-large on two benchmark summarization tasks with it surpassing baselines by even over 10% (on AU-ROC) in some cases. Additionally, our interpretable approach provides insight into features that are predictive of confidence, leading to the interesting and useful discovery that our confidence models built for one LLM generalize zero-shot across others on a given dataset.},
  archive      = {J_TMLR},
  author       = {Tejaswini Pedapati and Amit Dhurandhar and Soumya Ghosh and Soham Dan and Prasanna Sattigeri},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Large language model confidence estimation via black-box access},
  url          = {https://openreview.net/forum?id=WrWYChkyRI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learned-database systems security. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XNVBSbtcKB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A learned database system uses machine learning (ML) internally to improve performance. We can expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned component is shared between mutually-distrusting users or processes, much like microarchitectural resources such as caches, potentially giving rise to highly-realistic attacker models. However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model. Additionally, the difference between the attack surface of learned and non-learned versions of the same system is often subtle. These factors obfuscate the de-facto risks that the incorporation of ML carries. We analyze the root causes of potentially-increased attack surface in learned database systems and develop a framework for identifying vulnerabilities that stem from the use of ML. We apply our framework to a broad set of learned components currently being explored in the database community. To empirically validate the vulnerabilities surfaced by our framework, we choose 3 of them and implement and evaluate exploits against these. We show that the use of ML cause leakage of past queries in a database, enable a poisoning attack that causes exponential memory blowup in an index structure and crashes it in seconds, and enable index users to snoop on each others' key distributions by timing queries over their own keys. We find that adversarial ML is an universal threat against learned components in database systems, point to open research gaps in our understanding of learned-systems security, and conclude by discussing mitigations, while noting that data leakage is inherent in systems whose learned component is shared between multiple parties.},
  archive      = {J_TMLR},
  author       = {Roei Schuster and Jin Peng Zhou and Thorsten Eisenhofer and Paul Grubbs and Nicolas Papernot},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learned-database systems security},
  url          = {https://openreview.net/forum?id=XNVBSbtcKB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster and predict latents patches for improved masked image modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ycmz7qJxUQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI -- a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8\% accuracy on ImageNet and 32.1\% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2.},
  archive      = {J_TMLR},
  author       = {Timothée Darcet and Federico Baldassarre and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cluster and predict latents patches for improved masked image modeling},
  url          = {https://openreview.net/forum?id=Ycmz7qJxUQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-wise generalization error: An information-theoretic analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=asW4VcDFpi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing generalization theories for supervised learning typically take a holistic approach and provide bounds for the expected generalization over the whole data distribution, which implicitly assumes that the model generalizes similarly for all different classes. In practice, however, there are significant variations in generalization performance among different classes, which cannot be captured by the existing generalization bounds. In this work, we tackle this problem by theoretically studying the class-generalization error, which quantifies the generalization performance of the model for each individual class. We derive a novel information-theoretic bound for class-generalization error using the KL divergence, and we further obtain several tighter bounds using recent advances in conditional mutual information bound, which enables practical evaluation. We empirically validate our proposed bounds in various neural networks and show that they accurately capture the complex class-generalization behavior. Moreover, we demonstrate that the theoretical tools developed in this work can be applied in several other applications.},
  archive      = {J_TMLR},
  author       = {Firas Laakom and Moncef Gabbouj and Jürgen Schmidhuber and Yuheng Bu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Class-wise generalization error: An information-theoretic analysis},
  url          = {https://openreview.net/forum?id=asW4VcDFpi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated generalized novel category discovery with prompts tuning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dVMESwnMlo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized category discovery (GCD) is proposed to handle categories from unseen labels during the inference stage by clustering them. Most works in GCD provide solutions for unseen classes in data-centralized settings. However, unlabeled categories possessed by clients, which are common in real-world federated learning (FL), have been largely ignored and degraded the performance of classic FL algorithms. To demonstrate and mitigate the harmful effect of unseen classes, we dive into a GCD problem setting applicable for FL named FedGCD, analyze overfitting problem in FedGCD in detail, establish a strong baseline constructed with state-of-the-art GCD algorithm simGCD, and design a learning framework with prompt tuning to tackle both the overfitting and communication burden problems in FedGCD. In our methods, clients first separately carry out prompt learning on local data. Then, we aggregate the prompts from all clients as the global prompt to help capture global knowledge and then send the global prompts to local clients to allow access to broader knowledge from other clients. By this method, we significantly reduce the parameters needed to upload in FedGCD, which is a common obstacle in the real application of most FL algorithms. We conduct experiments on both generic and fine-grained datasets like CIFAR-100 and CUB-200, and show that our method is comparable to the FL version of simGCD and surpasses other baselines with significantly fewer parameters to transmit.},
  archive      = {J_TMLR},
  author       = {Lei Shen and Nan Pu and Zhun Zhong and Mingming Gong and Dianhai Yu and Chengqi Zhang and Bo Han},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated generalized novel category discovery with prompts tuning},
  url          = {https://openreview.net/forum?id=dVMESwnMlo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LC-PLM: Long-context protein language modeling using bidirectional mamba with shared projection layers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dWvztQzfy4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised training of language models (LMs) has seen great success for protein sequences in learning meaningful representations and for generative drug design. Most protein LMs are based on the Transformer architecture trained on individual proteins with short context lengths. Such protein LMs cannot extrapolate to longer proteins and protein complexes well. They also fail to account for the underlying biological mechanisms carried out by biomolecular interactions and dynamics i.e., proteins often interact with other proteins, molecules, and pathways in complex biological systems. In this work, we propose LC-PLM based on an alternative protein LM architecture, BiMamba-S, built upon selective structured state-space models, to learn high-quality universal protein representations at the amino acid token level using masked language modeling. We also introduce its graph-contextual variant, LC-PLM, which contextualizes protein-protein interaction (PPI) graphs for a second stage of training. LC-PLM demonstrates favorable neural scaling laws, better length extrapolation capability, and up to 30% and 16% improvements on protein downstream tasks compared to Transformer-based ESM-2 when trained with 100B and 1T tokens, respectively. LC-PLM-G further trained within the context of PPI graphs shows promising results on protein structure and function prediction tasks. Our study demonstrates the benefit of increasing the context size with computationally efficient LM architecture (e.g., structured state space models) in learning universal protein representations and incorporating molecular interaction contexts contained in biological graphs. Model is available at github.com/amazon-science/LC-PLM.},
  archive      = {J_TMLR},
  author       = {Yingheng Wang and Zichen Wang and Gil Sadeh and Luca Zancato and Alessandro Achille and George Karypis and Huzefa Rangwala},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LC-PLM: Long-context protein language modeling using bidirectional mamba with shared projection layers},
  url          = {https://openreview.net/forum?id=dWvztQzfy4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenCAD: Image-conditioned computer-aided design generation with transformer-based contrastive representation and diffusion priors. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=e817c1wEZ6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The creation of manufacturable and editable 3D shapes through Computer-Aided Design (CAD) remains a highly manual and time-consuming task, hampered by the complex topology of boundary representations of 3D solids and unintuitive design tools. While most work in the 3D shape generation literature focuses on representations like meshes, voxels, or point clouds, practical engineering applications demand the modifiability and manufacturability of CAD models and the ability for multi-modal conditional CAD model generation. This paper introduces GenCAD, a generative model that employs autoregressive transformers with a contrastive learning framework and latent diffusion models to transform image inputs into parametric CAD command sequences, resulting in editable 3D shape representations. Extensive evaluations demonstrate that GenCAD significantly outperforms existing state-of-the-art methods in terms of the unconditional and conditional generations of CAD models. Additionally, the contrastive learning framework of GenCAD facilitates the retrieval of CAD models using image queries from large CAD databases, which is a critical challenge within the CAD community. Our results provide a significant step forward in highlighting the potential of generative models to expedite the entire design-to-production pipeline and seamlessly integrate different design modalities.},
  archive      = {J_TMLR},
  author       = {Md Ferdous Alam and Faez Ahmed},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GenCAD: Image-conditioned computer-aided design generation with transformer-based contrastive representation and diffusion priors},
  url          = {https://openreview.net/forum?id=e817c1wEZ6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No $D_{train}$: Model-agnostic counterfactual explanations using reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=egNzAG9rOu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) methods have experienced significant growth in the past decade, yet their practical application in high-impact real-world domains has been hindered by their opacity. When ML methods are responsible for making critical decisions, stakeholders often require insights into how to alter these decisions. Counterfactual explanations (CFEs) have emerged as a solution, offering interpretations of opaque ML models and providing a pathway to transition from one decision to another. However, most existing CFE methods require access to the model's training dataset, few methods can handle multivariate time-series, and none of model-agnostic CFE methods can handle multivariate time-series without training datasets. These limitations can be formidable in many scenarios. In this paper, we present NTD-CFE, a novel model-agnostic CFE method based on reinforcement learning (RL) that generates CFEs when training datasets are unavailable. NTD-CFE is suitable for both static and multivariate time-series datasets with continuous and discrete features. NTD-CFE reduces the CFE search space from a multivariate time-series domain to a lower dimensional space and addresses the problem using RL. Users have the flexibility to specify non-actionable, immutable, and preferred features, as well as causal constraints. We demonstrate the performance of NTD-CFE against four baselines on several datasets and find that, despite not having access to a training dataset, NTD-CFE finds CFEs that make significantly fewer and significantly smaller changes to the input time-series. These properties make CFEs more actionable, as the magnitude of change required to alter an outcome is vastly reduced. The code is available in the supplementary material.},
  archive      = {J_TMLR},
  author       = {Xiangyu Sun and Raquel Aoki and Kevin H. Wilson},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {No $D_{train}$: Model-agnostic counterfactual explanations using reinforcement learning},
  url          = {https://openreview.net/forum?id=egNzAG9rOu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian processes with bayesian inference of covariate couplings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fameEAljo3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes are powerful probabilistic models that are often coupled with ARD capable of uncovering the importance of individual covariates. We develop covariances characterized by affine transformations of the inputs, formalized via a precision matrix between covariates, which can uncover covariate couplings for enhanced interpretability. We study a range of couplings priors from Wishart to Horseshoe and present fully Bayesian inference of such precision matrices within sparse Gaussian processes. We empirically demonstrate the efficacy and interpretability of this approach.},
  archive      = {J_TMLR},
  author       = {Mattia Rosso and Juho Ylä-Jääski and Zheyang Shen and Markus Heinonen and Maurizio Filippone},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gaussian processes with bayesian inference of covariate couplings},
  url          = {https://openreview.net/forum?id=fameEAljo3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A baseline method for removing invisible image watermarks using deep image prior. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=g85Vxlrq0O'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse.},
  archive      = {J_TMLR},
  author       = {Hengyue Liang and Taihui Li and Ju Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A baseline method for removing invisible image watermarks using deep image prior},
  url          = {https://openreview.net/forum?id=g85Vxlrq0O},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully automatic neural network reduction for formal verification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gmflcWlVMl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal verification of neural networks is essential before their deployment in safety-critical applications. However, existing methods for formally verifying neural networks are not yet scalable enough to handle practical problems under strict time constraints. We address this challenge by introducing a fully automatic and sound reduction of neural networks using reachability analysis. The soundness ensures that the verification of the reduced network entails the verification of the original network. Our sound reduction approach is applicable to neural networks with any type of element-wise activation function, such as ReLU, sigmoid, and tanh. The network reduction is computed on the fly while simultaneously verifying the original network and its specification. All parameters are automatically tuned to minimize the network size without compromising verifiability. We further show the applicability of our approach to convolutional neural networks by explicitly exploiting similar neighboring pixels. Our evaluation shows that our approach reduces large neural networks to a fraction of the original number of neurons and thus shortens the verification time to a similar degree.},
  archive      = {J_TMLR},
  author       = {Tobias Ladner and Matthias Althoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fully automatic neural network reduction for formal verification},
  url          = {https://openreview.net/forum?id=gmflcWlVMl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Qualifying knowledge and knowledge sharing in multilingual models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hnpB3SRbZj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained language models (PLMs) have demonstrated a remarkable ability to encode factual knowledge. However, the mechanisms underlying how this knowledge is stored and retrieved remain poorly understood, with important implications for AI interpretability and safety. In this paper, we disentangle the multifaceted nature of knowledge: successfully completing a knowledge retrieval task (e.g., “{The capital of France is __”) involves mastering underlying concepts (e.g., France, Paris), relationships between these concepts (e.g., capital of) and the structure of prompts, including the language of the query. We propose to disentangle these distinct aspects of knowledge and apply this typology to offer a critical view of neuron-level knowledge attribution techniques. For concreteness, we focus on Dai et al.'s (2022) Knowledge Neurons (KNs) across multiple PLMs (BERT, OPT, Llama and Gemma), testing 10 natural languages and additional unnatural languages (e.g. Autoprompt). Our key contributions are twofold: (i) we show that KNs come in different flavors, some indeed encoding entity level concepts, some having a much less transparent, more polysemantic role , and (ii) we address the problem of cross-linguistic knowledge sharing at the neuron level, more specifically we uncover an unprecedented overlap in KNs across up to all of the 10 languages we tested, pointing to the existence of a partially unified, language-agnostic retrieval system. To do so, we introduce and release the Multi-ParaRel dataset, an extension of ParaRel, featuring prompts and paraphrases for cloze-style knowledge retrieval tasks in parallel over 10 languages.}},
  archive      = {J_TMLR},
  author       = {Nicolas Guerin and Ryan M. Nefdt and Emmanuel Chemla},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Qualifying knowledge and knowledge sharing in multilingual models},
  url          = {https://openreview.net/forum?id=hnpB3SRbZj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAMUT: A novel framework for modifying mathematical formulas for the generation of specialized datasets for language model training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=khODmRpQEx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical formulas are a fundamental and widely used component in various scientific fields, serving as a universal language for expressing complex concepts and relationships. While state-of-the-art transformer models excel in processing and understanding natural language, they encounter challenges with mathematical notation, which involves a complex structure and diverse representations. This study focuses on the development of specialized training datasets to enhance the encoding of mathematical content. We introduce Math Mutator (MAMUT), a framework capable of generating equivalent and falsified versions of a given mathematical formula in LaTeX notation, effectively capturing the mathematical variety in notation of the same concept. Based on MAMUT, we have generated four large mathematical datasets containing diverse notation, which can be used to train language models with enhanced mathematical embeddings. Experiments show that models trained on these datasets exhibit new SoTA performance on mathematical retrieval tasks. We publish our code, generated datasets, and pretrained mathematical models: https://github.com/aieng-lab/math-mutator.},
  archive      = {J_TMLR},
  author       = {Jonathan Drechsel and Anja Reusch and Steffen Herbold},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MAMUT: A novel framework for modifying mathematical formulas for the generation of specialized datasets for language model training},
  url          = {https://openreview.net/forum?id=khODmRpQEx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximations to worst-case data dropping: Unmasking failure modes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=m6EQ6YdPXV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data analyst might worry about generalization if dropping a very small fraction of data points from a study could change its substantive conclusions. Checking this non-robustness directly poses a combinatorial optimization problem and is intractable even for simple models and moderate data sizes. Recently various authors have proposed a diverse set of approximations to detect this non-robustness. In the present work, we show that, even in a setting as simple as ordinary least squares (OLS) linear regression, many of these approximations can fail to detect (true) non-robustness in realistic data arrangements. We focus on OLS in the present work due its widespread use and since some approximations work only for OLS. Across our synthetic and real-world data sets, we find that a simple recursive greedy algorithm is the sole algorithm that does not fail any of our tests and also that it can be orders of magnitude faster to run than some competitors.},
  archive      = {J_TMLR},
  author       = {Jenny Y. Huang and David R. Burt and Yunyi Shen and Tin D. Nguyen and Tamara Broderick},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximations to worst-case data dropping: Unmasking failure modes},
  url          = {https://openreview.net/forum?id=m6EQ6YdPXV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniTST: Effectively modeling inter-series and intra-series dependencies for multivariate time series forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=p3y5q4cvzV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have emerged as powerful tools for multivariate time series forecasting (MTSF). However, existing Transformer models often fall short of capturing both intricate dependencies across variate and temporal dimensions in MTS data. Some recent models are proposed to separately capture variate and temporal dependencies through either two sequential or parallel attention mechanisms. However, these methods cannot directly and explicitly learn the intricate inter-series and intra-series dependencies. In this work, we first demonstrate that these dependencies are very important as they usually exist in real-world data. To directly model these dependencies, we propose a transformer-based model UniTST containing a unified attention mechanism on the flattened patch tokens. Additionally, we add a dispatcher module which reduces the complexity and makes the model feasible for a potentially large number of variates. Although our proposed model employs a simple architecture, it offers compelling performance as shown in our extensive experiments on several datasets for time series forecasting.},
  archive      = {J_TMLR},
  author       = {Juncheng Liu and Chenghao Liu and Gerald Woo and Yiwei Wang and Bryan Hooi and Caiming Xiong and Doyen Sahoo},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {UniTST: Effectively modeling inter-series and intra-series dependencies for multivariate time series forecasting},
  url          = {https://openreview.net/forum?id=p3y5q4cvzV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SURE-VQA: Systematic understanding of robustness evaluation in medical VQA tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qjNdGpgpV8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-Language Models (VLMs) have great potential in medical tasks, like Visual Question Answering (VQA), where they could act as interactive assistants for both patients and clinicians. Yet their robustness to distribution shifts on unseen data remains a key concern for safe deployment. Evaluating such robustness requires a controlled experimental setup that allows for systematic insights into the model's behavior. However, we demonstrate that current setups fail to offer sufficiently thorough evaluations. To address this gap, we introduce a novel framework, called SURE-VQA, centered around three key requirements to overcome current pitfalls and systematically analyze VLM robustness: 1) Since robustness on synthetic shifts does not necessarily translate to real-world shifts, it should be measured on real-world shifts that are inherent to the VQA data; 2) Traditional token-matching metrics often fail to capture underlying semantics, necessitating the use of large language models (LLMs) for more accurate semantic evaluation; 3) Model performance often lacks interpretability due to missing sanity baselines, thus meaningful baselines should be reported that allow assessing the multimodal impact on the VLM. To demonstrate the relevance of this framework, we conduct a study on the robustness of various Fine-Tuning (FT) methods across three medical datasets with four types of distribution shifts. Our study highlights key insights into robustness: 1) No FT method consistently outperforms others in robustness, and 2) robustness trends are more stable across FT methods than across distribution shifts. Additionally, we find that simple sanity baselines that do not use the image data can perform surprisingly well and confirm LoRA as the best-performing FT method on in-distribution data. Code is provided at https://github.com/IML-DKFZ/sure-vqa.},
  archive      = {J_TMLR},
  author       = {Kim-Celine Kahl and Selen Erkan and Jeremias Traub and Carsten T. Lüth and Klaus Maier-Hein and Lena Maier-hein and Paul F Jaeger},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SURE-VQA: Systematic understanding of robustness evaluation in medical VQA tasks},
  url          = {https://openreview.net/forum?id=qjNdGpgpV8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive control and regret analysis of non-stationary MDP with look-ahead information. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uObs1YwXjQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy design in non-stationary Markov Decision Processes (MDPs) is inherently challenging due to the complexities introduced by time-varying system transition and reward, which make it difficult for learners to determine the optimal actions for maximizing cumulative future rewards. Fortunately, in many practical applications, such as energy systems, look-ahead predictions are available, including forecasts for renewable energy generation and demand. In this paper, we leverage these look-ahead predictions and propose an algorithm designed to achieve low regret in non-stationary MDPs by incorporating such predictions. Our theoretical analysis demonstrates that, under certain assumptions, the regret decreases exponentially as the look-ahead window expands. When the system prediction is subject to error, the regret does not explode even if the prediction error grows sub-exponentially as a function of the prediction horizon. We validate our approach through simulations and confirm its efficacy in non-stationary environments.},
  archive      = {J_TMLR},
  author       = {Ziyi Zhang and yorie nakahira and Guannan Qu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predictive control and regret analysis of non-stationary MDP with look-ahead information},
  url          = {https://openreview.net/forum?id=uObs1YwXjQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tracing facts or just copies? a critical investigation of the competitions of mechanisms in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1QrB5WSWOR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reproducibility study examining how Large Language Models (LLMs) manage competing factual and counterfactual information, focusing on the role of attention heads in this process. We attempt to reproduce and reconcile findings from three recent studies by Ortu et al. [13], Yu, Merullo, and Pavlick [17] and McDougall et al. [7] that investigate the competition between model-learned facts and contradictory context information through Mechanistic Interpretability tools. Our study specifically examines the relationship between attention head strength and factual output ratios, evaluates competing hypotheses about attention heads' suppression mechanisms, and investigates the domain specificity of these attention patterns. Our findings suggest that attention heads promoting factual output do so via general copy suppression rather than selective counterfactual suppression, as strengthening them can also inhibit correct facts. Additionally, we show that attention head behavior is domain-dependent, with larger models exhibiting more specialized and category-sensitive patterns.},
  archive      = {J_TMLR},
  author       = {Dante Campregher and Yanxu Chen and Sander Hoffman and Maria Heuss},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tracing facts or just copies? a critical investigation of the competitions of mechanisms in large language models},
  url          = {https://openreview.net/forum?id=1QrB5WSWOR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The over-certainty phenomenon in modern test-time adaptation algorithms. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AGQRij8iUC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When neural networks are confronted with unfamiliar data that deviate from their training set, this signifies a domain shift. While these networks output predictions on their inputs, they typically fail to account for their level of familiarity with these novel observations. Prevailing works navigate test-time adaptation with the goal of curtailing model entropy, yet they unintentionally produce models that struggle with sub-optimal calibration—a dilemma we term the over-certainty phenomenon. This over-certainty in predictions can be particularly dangerous in the setting of domain shifts, as it may lead to misplaced trust. In this paper, we propose a solution that not only maintains accuracy but also addresses calibration by mitigating the over-certainty phenomenon. To do this, we introduce a certainty regularizer that dynamically adjusts pseudo-label confidence by accounting for both backbone entropy and logit norm. Our method achieves state-of-the-art performance in terms of Expected Calibration Error and Negative Log Likelihood, all while maintaining parity in accuracy.},
  archive      = {J_TMLR},
  author       = {Fin Amin and Jung-Eun Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The over-certainty phenomenon in modern test-time adaptation algorithms},
  url          = {https://openreview.net/forum?id=AGQRij8iUC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal link predictor by in-context learning on graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EYpqmoejB8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models. UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training. We address the challenge of conflicting connectivity patterns—arising from the unique distributions of different graphs—through the implementation of In-context Learning (ICL). This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer. Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been finetuned for specific datasets. Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework.},
  archive      = {J_TMLR},
  author       = {Kaiwen Dong and Haitao Mao and Zhichun Guo and Nitesh V Chawla},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Universal link predictor by in-context learning on graphs},
  url          = {https://openreview.net/forum?id=EYpqmoejB8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data (Almost) from scratch: Generalized instruction tuning for language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PahnCreCxK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Generalized Instruction Tuning (called GLAN), a general and scalable method for instruction tuning of Large Language Models (LLMs). Unlike prior work that relies on seed examples or existing datasets to construct instruction-tuning data, GLAN exclusively utilizes a pre-curated taxonomy of human knowledge and capabilities as input and generates large-scale synthetic instruction data across all disciplines. Specifically, inspired by the systematic structure in human education system, we build the taxonomy by decomposing human knowledge and capabilities to various fields, sub-fields and ultimately, distinct disciplines semi-automatically, facilitated by LLMs. Subsequently, we generate a comprehensive list of subjects for every discipline and proceed to design a syllabus tailored to each subject, again utilizing LLMs. With the fine-grained key concepts detailed in every class session of the syllabus, we are able to generate diverse instructions with a broad coverage across the entire spectrum of human knowledge and skills. Extensive experiments on large language models (e.g., Mistral) demonstrate that GLAN excels in multiple dimensions from mathematical reasoning, coding, academic exams, logical reasoning to general instruction following without using task-specific training data of these tasks. In addition, GLAN allows for easy customization and new fields or skills can be added by simply incorporating a new node into our taxonomy. While promising, our approach may inherit biases or inaccuracies from LLM-generated data as in other synthetic data work and is primarily evaluated on exam-style benchmarks. Broader evaluations and data quality control are left for future work.},
  archive      = {J_TMLR},
  author       = {Haoran Li and Qingxiu Dong and Zhengyang Tang and Chaojun Wang and Xingxing Zhang and Haoyang Huang and Shaohan Huang and Xiaolong Huang and Zeqiang Huang and Dongdong Zhang and Yuxian Gu and Xin Cheng and Xun Wang and Si-Qing Chen and Li Dong and Wei Lu and Zhifang Sui and Benyou Wang and Wai Lam and Furu Wei},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Synthetic data (Almost) from scratch: Generalized instruction tuning for language models},
  url          = {https://openreview.net/forum?id=PahnCreCxK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online selective conformal inference: Errors and solutions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PjIQwFyP07'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online selective conformal inference, data arrives sequentially, and prediction intervals are constructed only when an online selection rule is met. Since online selections may break the exchangeability between the selected test datum and the rest of the data, one must correct for this by suitably selecting the calibration data. In this paper, we evaluate existing calibration selection strategies and pinpoint some fundamental errors in the associated claims that guarantee selection-conditional coverage and control of the false coverage rate (FCR). To address these shortcomings, we propose novel calibration selection strategies that provably preserve the exchangeability of the calibration data and the selected test datum. Consequently, we demonstrate that online selective conformal inference with these strategies guarantees both selection-conditional coverage and FCR control. Our theoretical findings are supported by experimental evidence examining trade-offs between valid methods.},
  archive      = {J_TMLR},
  author       = {Yusuf Sale and Aaditya Ramdas},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online selective conformal inference: Errors and solutions},
  url          = {https://openreview.net/forum?id=PjIQwFyP07},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What should embeddings embed? autoregressive models represent latent generating distributions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YyMACp98Kz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive language models have demonstrated a remarkable ability to extract latent structure from text. The embeddings from large language models have been shown to capture aspects of the syntax and semantics of language. But what should embeddings represent? We show that the embeddings from autoregressive models correspond to predictive sufficient statistics. By identifying settings where the predictive sufficient statistics are interpretable distributions over latent variables, including exchangeable models and latent state models, we show that embeddings of autoregressive models encode these explainable quantities of interest. We conduct empirical probing studies to extract information from transformers about latent generating distributions. Furthermore, we show that these embeddings generalize to out-of-distribution cases, do not exhibit token memorization, and that the information we identify is more easily recovered than other related measures. Next, we extend our analysis of exchangeable models to more realistic scenarios where the predictive sufficient statistic is difficult to identify by focusing on an interpretable subcomponent of language, topics. We show that large language models encode topic mixtures inferred by latent Dirichlet allocation (LDA) in both synthetic datasets and natural corpora.},
  archive      = {J_TMLR},
  author       = {Liyi Zhang and Michael Y. Li and R. Thomas McCoy and Theodore Sumers and Jian-Qiao Zhu and Thomas L. Griffiths},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What should embeddings embed? autoregressive models represent latent generating distributions},
  url          = {https://openreview.net/forum?id=YyMACp98Kz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on future frame synthesis: Bridging deterministic and generative approaches. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZN4rzrHlNz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future Frame Synthesis (FFS), the task of generating subsequent video frames from context, represents a core challenge in machine intelligence and a cornerstone for developing predictive world models. This survey provides a comprehensive analysis of the FFS landscape, charting its critical evolution from deterministic algorithms focused on pixel-level accuracy to modern generative paradigms that prioritize semantic coherence and dynamic plausibility. We introduce a novel taxonomy organized by algorithmic stochasticity, which not only categorizes existing methods but also reveals the fundamental drivers—advances in architectures, datasets, and computational scale—behind this paradigm shift. Critically, our analysis identifies a bifurcation in the field's trajectory: one path toward efficient, real-time prediction, and another toward large-scale, generative world simulation. By pinpointing key challenges and proposing concrete research questions for both frontiers, this survey serves as an essential guide for researchers aiming to advance the frontiers of visual dynamic modeling.},
  archive      = {J_TMLR},
  author       = {Ruibo Ming and Zhewei Huang and Jingwei Wu and Zhuoxuan Ju and Daxin Jiang and Jianming HU and Lihui Peng and Shuchang Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on future frame synthesis: Bridging deterministic and generative approaches},
  url          = {https://openreview.net/forum?id=ZN4rzrHlNz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient contrastive PAC learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dBJo9hyKVg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study contrastive learning under the PAC learning framework. While a series of recent works have shown statistical results for learning under contrastive loss, based either on the VC-dimension or Rademacher complexity, their algorithms are inherently inefficient or not implying PAC guarantees. In this paper, we consider contrastive learning of the fundamental concept of linear representations. Surprisingly, even under such basic setting, the existence of efficient PAC learners is largely open. We first show that the problem of contrastive PAC learning of linear representations is intractable to solve in general. We then show that it can be relaxed to a semi-definite program when the distance between contrastive samples is measured by the $\ell_2$-norm. We then establish generalization guarantees based on Rademacher complexity, and connect it to PAC guarantees under certain contrastive large-margin conditions. To the best of our knowledge, this is the first efficient PAC learning algorithm for contrastive learning.},
  archive      = {J_TMLR},
  author       = {Jie Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards efficient contrastive PAC learning},
  url          = {https://openreview.net/forum?id=dBJo9hyKVg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseDiff: Sparse discrete diffusion for scalable graph generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kuJ3lpxnVC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generative models encounter significant scaling challenges due to the need to predict the presence or type of edges for every node pair, resulting in quadratic complexity. While some models attempt to support large graph generation, they often impose restrictive assumptions, such as enforcing cluster or hierarchical structures, which can limit generalizability and result in unstable generation quality across various graph types. To address this, we introduce SparseDiff, a novel diffusion framework that leverages the inherent sparsity in large graphs - a highly relaxed assumption that enables efficient sparse modeling without sacrificing generation quality for different datasets. SparseDiff reduces the complexity of the three core components in graph diffusion models. It first introduces a noising trajectory that preserves sparsity with more memory-efficient computation. During training, SparseDiff uses a denoising network based on convolutional attention layers over a sparse edge subsets combining edge-based graph attention and query edge-based random attention mechanisms, maintaining expressiveness with reduced memory usage. Finally, for inference, at each denoising step, SparseDiff generates edge subsets iteratively, progressively reconstructing the adjacency structure. SparseDiff achieves state-of-the-art results on both small and large datasets, showing its robustness across varying graph sizes and its scalability. Additionally, it ensures faster convergence for large graphs, achieving a fourfold speedup on the large-scale Ego dataset compared to dense models. SparseDiff's efficiency, combined with its effective control over space complexity, positions it as a powerful solution for scaling applications involving large graphs.},
  archive      = {J_TMLR},
  author       = {Yiming QIN and Clement Vignac and Pascal Frossard},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SparseDiff: Sparse discrete diffusion for scalable graph generation},
  url          = {https://openreview.net/forum?id=kuJ3lpxnVC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FB-MOAC: A reinforcement learning algorithm for forward-backward markov decision processes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=li5DyC6rfS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) algorithms are effective in solving problems that can be modeled as Markov decision processes (MDPs). These algorithms primarily target forward MDPs whose dynamics evolve over time from an initial state. However, several important problems in different scenarios including stochastic control and network systems exhibit both a forward and a backward dynamics. As a consequence, they cannot be expressed as a standard MDP, thereby calling for a novel theory for RL in this context. Accordingly, this work introduces the concept of Forward-Backward Markov Decision Processes (FB-MDPs) for multi-objective problems, develops a novel theoretical framework to characterize their optimal solutions, and proposes a general forward-backward step-wise template that allows to adapt RL algorithms for FB-MDP problems. A Forward Backward Multi Objective Actor Critic (FB-MOAC) algorithm is introduced accordingly to obtain optimal policies with guaranteed convergence and a competitive rate with respect to standard approaches in RL. FB-MOAC is evaluated on diverse use cases in the context of mathematical finance and mobile resource management. The obtained results show that FB-MOAC outperforms the state of the art across different metrics, highlighting its ability to learn and maximize rewards.},
  archive      = {J_TMLR},
  author       = {Mohsen Amidzadeh and Mario Di Francesco},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FB-MOAC: A reinforcement learning algorithm for forward-backward markov decision processes},
  url          = {https://openreview.net/forum?id=li5DyC6rfS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesizing world models for bilevel planning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=m9V4JHLJrD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern reinforcement learning (RL) systems have demonstrated remarkable capabilities in complex environments, such as video games. However, they still fall short of achieving human-like sample efficiency and adaptability when learning new domains. Theory-based reinforcement learning (TBRL) is an algorithmic framework specifically designed to address this gap. Modeled on cognitive theories, TBRL leverages structured, causal world models---``theories''---as forward simulators for use in planning, generalization and exploration. Although current TBRL systems provide compelling explanations of how humans learn to play video games, they face several technical limitations: their theory languages are restrictive, and their planning algorithms are not scalable. To address these challenges, we introduce TheoryCoder, an instantiation of TBRL that exploits hierarchical representations of theories and efficient program synthesis methods for more powerful learning and planning. TheoryCoder equips agents with general-purpose abstractions (e.g., ``move to''), which are then grounded in a particular environment by learning a low-level transition model (a Python program synthesized from observations by a large language model). A bilevel planning algorithm can exploit this hierarchical structure to solve large domains. We demonstrate that this approach can be successfully applied to diverse and challenging grid-world games, where approaches based on directly synthesizing a policy perform poorly. Ablation studies demonstrate the benefits of using hierarchical abstractions.},
  archive      = {J_TMLR},
  author       = {Zergham Ahmed and Joshua B. Tenenbaum and Chris Bates and Samuel J. Gershman},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Synthesizing world models for bilevel planning},
  url          = {https://openreview.net/forum?id=m9V4JHLJrD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic fairness with monotone likelihood ratios. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mtoWa0gIKy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that inequalities of many commonly used fairness metrics (true/false positive/negative rates, predicted positive/negative rates, and positive/negative predictive values) are guaranteed for groups with different outcome rates under a monotonically calibrated model whose risk distributions have a monotone likelihood ratio, extending existing impossibility results. We further provide lower bounds on the FNR/FPR disparities and PPR/PNR disparities in the same setting, showing that either the FNR disparity or FPR disparity is at least as large as the positive outcome rate disparity (for FNR disparity) or negative outcome rate disparity (for FPR disparity), and either the PPR disparity or PNR disparity is at least as large as the positive outcome rate disparity (for PPR disparity) or negative outcome rate disparity (for PNR disparity). While incompatibilities of some combinations of these metrics have been demonstrated previously, we are unaware of any work that has demonstrated direct incompatibility of calibration with these individual equalities, equivalence of these inequalities, or lower bounds for the disparity in these values under distributional assumptions about a model's predictions.},
  archive      = {J_TMLR},
  author       = {Wes Camp},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Algorithmic fairness with monotone likelihood ratios},
  url          = {https://openreview.net/forum?id=mtoWa0gIKy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on the $k$-means clustering for missing data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pcqlTvePXS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical $k$-means clustering algorithm requires complete data and cannot be directly applied when observations contain missing entries. An intuitive and computationally efficient extension addresses this issue by minimizing the $k$-means loss over the observed entries only, a strategy considered in several studies. This method is known as $k$-POD clustering. In this paper, we provide a theoretical analysis of this approach and demonstrate that it is generally inconsistent, even under the missing completely at random (MCAR) assumption. Specifically, we show that the expected loss being minimized asymptotically differs from the original $k$-means objective, leading to biased estimates of cluster centers in the large-sample limit. This highlights a fundamental limitation: the method may fail to recover the true underlying cluster structure, even in settings where $k$-means performs well on fully observed data. Nevertheless, when the missing rate per variable is sufficiently low and the dimensionality is high, the method can still produce stable and practically useful results, making it a viable alternative when the complete-case analysis is ineffective.},
  archive      = {J_TMLR},
  author       = {Yoshikazu Terada and Xin Guan},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A note on the $k$-means clustering for missing data},
  url          = {https://openreview.net/forum?id=pcqlTvePXS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust scale-invariant mutual information estimators. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vB7Wvytko5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutual information (MI) is hard to estimate for high dimensional data, and various estimators have been proposed over the years to tackle this problem. Here, we note that there exists another challenging problem, namely that many estimators of MI, which we denote as $I(X;T)$, are sensitive to scale, i.e., $I(X;\alpha T)\neq I(X;T)$ where $\alpha \in \mathbb{R}^{+}$. Although some normalization methods have been hinted at in previous works, there is no in-depth study of the problem. In this work, we study new normalization strategies for MI estimators to be scale-invariant, particularly for the Kraskov–Stögbauer–Grassberger (KSG) and the neural network-based MI (MINE) estimators. We provide theoretical and empirical results and show that the original un-normalized estimators are not scale-invariant and highlight the consequences of an estimator's scale-dependence. We propose new global normalization strategies that are tuned to the corresponding estimator and scale invariant. We compare our global normalization strategies to existing local normalization strategies and provide intuitive and empirical arguments to support the use of global normalization. Extensive experiments across multiple distributions and settings are conducted, and we find that our proposed variants KSG-Global-$L_{\infty}$ and MINE-Global-Corrected are most accurate within their respective approaches. Finally, we perform an information plane analysis of neural networks and observe clearer trends of fitting and compression using the normalized estimators compared to the original un-normalized estimators. Our work highlights the importance of scale awareness and global normalization in the MI estimation problem.},
  archive      = {J_TMLR},
  author       = {Cheuk Ting Leung and Rohan Ghosh and Mehul Motani},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards robust scale-invariant mutual information estimators},
  url          = {https://openreview.net/forum?id=vB7Wvytko5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expressive pooling for graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xGADInGWMt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considerable efforts have been dedicated to exploring methods that enhance the expressiveness of graph neural networks. Current endeavors primarily focus on modifying the message-passing process to overcome limitations imposed by the Weisfeiler-Leman test, often at the expense of increasing computational cost. In practical applications, message-passing layers are interleaved with pooling layers for graph-level tasks, enabling the learning of increasingly abstract and coarser representations of input graphs. In this work, we formally prove two directions that allow pooling methods to increase the expressive power of a graph neural network while keeping the message-passing method unchanged. We systemically assign eight frequently used pooling operators to our theoretical conditions for increasing expressivity and introduce a novel pooling method XP, short for eXpressive Pooling, as an additional simple method that satisfies our theoretical conditions. Experiments conducted on the Brec dataset confirm that those pooling methods that satisfy our conditions empirically increase the expressivity of graph neural networks.},
  archive      = {J_TMLR},
  author       = {Veronica Lachi and Alice Moallemy-Oureh and Andreas Roth and Pascal Welke},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Expressive pooling for graph neural networks},
  url          = {https://openreview.net/forum?id=xGADInGWMt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmasking trees for tabular data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0AxbTF3Ouq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite much work on advanced deep learning and generative modeling techniques for tabular data generation and imputation, traditional methods have continued to win on imputation benchmarks. We herein present UnmaskingTrees, a simple method for tabular imputation (and generation) employing gradient-boosted decision trees which are used to incrementally unmask individual features. On a benchmark for out-of-the-box performance on 27 small tabular datasets, UnmaskingTrees offers leading performance on imputation; state-of-the-art performance on generation given data with missingness; and competitive performance on vanilla generation given data without missingness. To solve the conditional generation subproblem, we propose a tabular probabilistic prediction method, BaltoBot, which fits a balanced tree of boosted tree classifiers. Unlike older methods, it requires no parametric assumption on the conditional distribution, accommodating features with multimodal distributions; unlike newer diffusion methods, it offers fast sampling, closed-form density estimation, and flexible handling of discrete variables. We finally consider our two approaches as meta-algorithms, demonstrating in-context learning-based generative modeling with TabPFN.},
  archive      = {J_TMLR},
  author       = {Calvin McCarter},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unmasking trees for tabular data},
  url          = {https://openreview.net/forum?id=0AxbTF3Ouq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long context transfer from language to vision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=30RAWQVGlx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video sequences offer valuable temporal information, but existing large multimodal models (LMMs) fall short in understanding extremely long videos. Many works address this by reducing the number of visual tokens using visual resamplers. Alternatively, in this paper, we approach this problem from the perspective of the language model. By simply extrapolating the context length of the language backbone, we enable LMMs to comprehend orders of magnitude more visual tokens without any video training. We call this phenomenon \textit{long context transfer} and carefully ablate its properties. To effectively measure LMMs' ability to generalize to long contexts in the vision modality, we develop V-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmark inspired by the language model' s NIAH test. Our proposed Long Video Assistant (LongVA) can process 2000 frames or over 200K visual tokens without additional complexities. With its extended context length, LongVA achieves state-of-the-art performance on Video-MME and MLVU among 7B-scale models by densely sampling more input frames.},
  archive      = {J_TMLR},
  author       = {Peiyuan Zhang and Kaichen Zhang and Bo Li and Guangtao Zeng and Jingkang Yang and Yuanhan Zhang and Ziyue Wang and Haoran Tan and Chunyuan Li and Ziwei Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long context transfer from language to vision},
  url          = {https://openreview.net/forum?id=30RAWQVGlx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customizing spider silk: Generative models with mechanical property conditioning for protein engineering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=37YSapXDK6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable mechanical properties of spider silk, including its tensile strength and extensibility, are primarily governed by the repeat regions of the proteins that constitute the fiber, the major ampullate spidroins (MaSps). However, establishing correlations between mechanical characteristics and repeat sequences remains challenging due to the intricate sequence–structure–function relationships of MaSps and the limited availability of annotated datasets. In this study, we present a novel computational framework for designing MaSp repeat sequences with customizable mechanical properties. To achieve this, we developed a lightweight GPT-based generative model by distilling the pre-trained ProtGPT2 protein language model. The distilled model was subjected to multi-level fine-tuning using curated subsets of the Spider Silkome dataset. Specifically, we adapted the model for MaSp repeat generation using 6,000 MaSp repeat sequences and further refined it via cross-validation on 592 repeats associated with experimentally determined fiber-level mechanical properties. Our model generates biologically plausible MaSp repeat regions tailored to specific mechanical properties, while also predicting those properties for given sequences. Validation includes sequence-level analysis, assessing physicochemical attributes, the expected distribution of key motifs, and secondary structure compositions. A correlation study using BLAST on the Spider Silkome dataset and a test set of MaSp repeats with known mechanical properties further confirmed the predictive accuracy of the model. This framework advances the rational design of spider silk-inspired biomaterials, offering a versatile tool for engineering protein sequences with tailored mechanical attributes.},
  archive      = {J_TMLR},
  author       = {Neeru Dubey and Elin Karlsson and Miguel A. Redondo and Johan Reimegård and Anna Rising and Hedvig Kjellstrom},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Customizing spider silk: Generative models with mechanical property conditioning for protein engineering},
  url          = {https://openreview.net/forum?id=37YSapXDK6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying macro causal effects in a C-DMG over ADMGs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=905LEugq6R'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal effect identification using causal graphs is a fundamental challenge in causal inference. While extensive research has been conducted in this area, most existing methods assume the availability of fully specified directed acyclic graphs or acyclic directed mixed graphs. However, in complex domains such as medicine and epidemiology, complete causal knowledge is often unavailable, and only partial information about the system is accessible. This paper focuses on causal effect identification within partially specified causal graphs, with particular emphasis on cluster-directed mixed graphs (C-DMGs) which can represent many different acyclic directed mixed graphs (ADMGs). These graphs provide a higher-level representation of causal relationships by grouping variables into clusters, offering a more practical approach for handling complex systems. Unlike fully specified ADMGs, C-DMGs can contain cycles, which complicate their analysis and interpretation. Furthermore, their cluster-based nature introduces new challenges, as it gives rise to two distinct types of causal effects: macro causal effects and micro causal effects, each with different properties. In this work, we focus on macro causal effects, which describe the effects of entire clusters on other clusters. We establish that the do-calculus is both sound and complete for identifying these effects in C-DMGs over ADMGs when the cluster sizes are either unknown or of size greater than one. Additionally, we provide a graphical characterization of non-identifiability for macro causal effects in these graphs.},
  archive      = {J_TMLR},
  author       = {Simon Matthieu Ferreira and Charles K. Assaad},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identifying macro causal effects in a C-DMG over ADMGs},
  url          = {https://openreview.net/forum?id=905LEugq6R},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image generation via energy-based CLIP. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FBmWiJXIGk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint Energy Models (JEMs), while drawing significant research attention, have not been successfully scaled to real-world, high-resolution datasets. We present CLIP-JEM, a novel approach extending JEMs to the multimodal vision-language domain using CLIP, integrating both generative and discriminative objectives. For the generative one, we introduce an image-text joint-energy function based on Cosine similarity in the CLIP space, training CLIP to assign low energy to real image-caption pairs and high energy otherwise. For the discriminative one, we employ contrastive adversarial loss, extending the adversarial training objective to the multimodal domain. CLIP-JEM not only generates realistic images from text but also achieves competitive results on the compositionality benchmark, outperforming leading methods with fewer parameters. Additionally, we demonstrate the superior guidance capability of CLIP-JEM by enhancing CLIP-based generative frameworks and converting unconditional diffusion models to text-based ones. Lastly, we show that our model can serve as a more robust evaluation metric for text-to-image generative tasks than CLIP.},
  archive      = {J_TMLR},
  author       = {Roy Ganz and Michael Elad},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Text-to-image generation via energy-based CLIP},
  url          = {https://openreview.net/forum?id=FBmWiJXIGk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization of robustness measures under input uncertainty: A randomized gaussian process upper confidence bound approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FDzojiLSia'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization based on the Gaussian process upper confidence bound (GP-UCB) offers a theoretical guarantee for optimizing black-box functions. In practice, however, black-box functions often involve input uncertainty. To handle such cases, GP-UCB can be extended to optimize evaluation criteria known as robustness measures. However, GP-UCB-based methods for robustness measures require a trade-off parameter, $\beta$, which, as in the original GP-UCB, must be set sufficiently large to ensure theoretical validity. In this study, we propose randomized robustness measure GP-UCB (RRGP-UCB), a novel method that samples $\beta$ from a chi-squared-based probability distribution. This approach eliminates the need to explicitly specify $\beta$. Notably, the expected value of $\beta$ under this distribution is not excessively large. Furthermore, we show that RRGP-UCB provides tight bounds on the expected regret between the optimal and estimated solutions. Numerical experiments demonstrate the effectiveness of the proposed method.},
  archive      = {J_TMLR},
  author       = {Yu Inatsu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian optimization of robustness measures under input uncertainty: A randomized gaussian process upper confidence bound approach},
  url          = {https://openreview.net/forum?id=FDzojiLSia},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YoooP: You only optimize one prototype per class for non-exemplar incremental learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FYe66NLDkO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental learning (IL) usually addresses catastrophic forgetting of old tasks when learning new tasks by replaying old tasks' raw data stored in memory, which can be limited by its size and the risk of privacy leakage. Recent non-exemplar IL methods store class centroids as prototypes and perturb them with high-dimensional Gaussian noise to generate synthetic data for replaying. Unfortunately, this approach has two major limitations. First, the boundary between embedding clusters around prototypes of different classes might be unclear, leading to serious catastrophic forgetting. Second, directly applying high-dimensional Gaussian noise produces nearly identical synthetic samples that fail to preserve the true data distribution, ultimately degrading performance. In this paper, we propose YoooP, a novel exemplar-free IL approach that can greatly outperform previous methods by only storing and replaying one prototype per class even without synthetic data replay. Instead of merely storing class centroids, YoooP optimizes each prototype by (1) shifting it to high-density regions within each class using an attentional mean-shift algorithm, and (2) optimizing its cosine similarity with class-specific embeddings to form compact, well-separated clusters. As a result, replaying only the optimized prototypes effectively reduces inter-class interference and maintains clear decision boundaries. Furthermore, we extend YoooP to YoooP+ by synthesizing replay data preserving the angular distribution between each class prototype and the class's real data in history, which cannot be obtained by high-dimensional Gaussian perturbation. YoooP+ effectively stabilizes and further improves YoooP without storing real data. Extensive experiments demonstrate the superiority of YoooP/YoooP+ over non-exemplar baselines in terms of different metrics. The code is released at https://github.com/Snowball0823/YoooP.git.},
  archive      = {J_TMLR},
  author       = {Jiangtao Kong and Zhenyu Zong and Tianyi Zhou and Huajie Shao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {YoooP: You only optimize one prototype per class for non-exemplar incremental learning},
  url          = {https://openreview.net/forum?id=FYe66NLDkO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstraction for bayesian reinforcement learning in factored POMDPs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HHgdT6m9L9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian reinforcement learning provides an elegant solution to addressing the exploration-exploitation trade-off in Partially Observable Markov Decision Processes (POMDPs) when the environment’s dynamics and reward function are initially unknown. By maintaining a belief over these unknown components and the state, the agent can effectively learn the environment’s dynamics and optimize their policy. However, scaling Bayesian reinforcement learning methods to large problems remains to be a significant challenge. While prior work has leveraged factored models and online sample-based planning to address this issue, these approaches often retain unnecessarily complex models and factors within the belief space that have minimal impact on the optimal policy. While this complexity might be necessary for accurate model learning, in reinforcement learning, the primary objective is not to recover the ground truth model but to optimize the policy for maximizing the expected sum of rewards. Abstraction offers a way to reduce model complexity by removing factors that are less relevant to achieving high rewards. In this work, we propose and analyze the integration of abstraction with online planning in factored POMDPs. Our empirical results demonstrate two key benefits. First, abstraction reduces model size, enabling faster simulations and thus more planning simulations within a fixed runtime. Second, abstraction enhances performance even with a fixed number of simulations due to greater statistical strength. These results underscore the potential of abstraction to improve both the scalability and effectiveness of Bayesian reinforcement learning in factored POMDPs.},
  archive      = {J_TMLR},
  author       = {Rolf A. N. Starre and Sammie Katt and Mustafa Mert Çelikok and Marco Loog and Frans A Oliehoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Abstraction for bayesian reinforcement learning in factored POMDPs},
  url          = {https://openreview.net/forum?id=HHgdT6m9L9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elucidating the design choice of probability paths in flow matching for forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JApMDLwbLR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow matching has recently emerged as a powerful paradigm for generative modeling and has been extended to probabilistic time series forecasting. However, the impact of the specific choice of probability path model on forecasting performance, particularly for high-dimensional spatio-temporal dynamics, remains under-explored. In this work, we demonstrate that forecasting spatio-temporal data with flow matching is highly sensitive to the selection of the probability path model. Motivated by this insight, we propose a novel probability path model designed to improve forecasting performance. Our empirical results across various dynamical system benchmarks show that our model achieves faster convergence during training and improved predictive performance compared to existing probability path models. Importantly, our approach is efficient during inference, requiring only a few sampling steps. This makes our proposed model practical for real-world applications and opens new avenues for probabilistic forecasting.},
  archive      = {J_TMLR},
  author       = {Soon Hoe Lim and Yijin Wang and Annan Yu and Emma Hart and Michael W. Mahoney and Sherry Li and N. Benjamin Erichson},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Elucidating the design choice of probability paths in flow matching for forecasting},
  url          = {https://openreview.net/forum?id=JApMDLwbLR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knockout: A simple way to handle missing inputs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=K71y5pge84'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models benefit from rich (e.g., multi-modal) input features. However, multimodal models might be challenging to deploy, because some inputs may be missing at inference. Current popular solutions include marginalization, imputation, and training multiple models. Marginalization achieves calibrated predictions, but it is computationally expensive and only feasible for low dimensional inputs. Imputation may result in inaccurate predictions, particularly when high-dimensional data, such as images, are missing. Training multiple models, where each model is designed to handle different subsets of inputs, can work well but requires prior knowledge of missing input patterns. Furthermore, training and retaining multiple models can be costly. We propose an efficient method to learn both the conditional distribution using full inputs and the marginal distributions. Our method, Knockout, randomly replaces input features with appropriate placeholder values during training. We provide a theoretical justification for Knockout and show that it can be interpreted as an implicit marginalization strategy. We evaluate Knockout across a wide range of simulations and real-world datasets and show that it offers strong empirical performance.},
  archive      = {J_TMLR},
  author       = {Minh Nguyen and Batuhan K. Karaman and Heejong Kim and Alan Q. Wang and Fengbei Liu and Mert R. Sabuncu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Knockout: A simple way to handle missing inputs},
  url          = {https://openreview.net/forum?id=K71y5pge84},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-RainbowPA: Improvements integrated preference alignment for diffusion-based text-to-image generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KY0TSY2bx8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although rapidly increasing capabilities of text-to-image (T2I) models have profound implications across various industries, they concurrently suffer from numerous shortcomings, necessitating the implementation of effective alignment strategies with human preference. Diffusion-DPO and SPO have emerged as robust approaches for aligning diffusion-based T2I models with human preference feedback. However, they tend to suffer from text-image misalignment, aesthetic overfitting and low-quality generation. To tackle such matters, we improve the alignment paradigm through a tripartite perspective, which are the calibration enhancement (Calibration Enhanced Preference Alignment), the overfitting mitigation (Identical Preference Alignment, Jensen-Shannon Divergence Constraint) and the performance optimization (Margin Strengthened Preference Alignment, SFT-like Regularization). Furthermore, combining them with the step-aware preference alignment paradigm, we propose the Diffusion-RainbowPA, a suite of total six improvements that collectively improve the alignment performance of Diffusion-DPO. With comprehensive alignment performance evaluation and comparison, it is demonstrated that Diffusion-RainbowPA outperforms current state-of-the-art methods. We also conduct ablation studies on the introduced components that reveal incorporation of each has positively enhanced alignment performance.},
  archive      = {J_TMLR},
  author       = {Haoyuan Sun and Bin Liang and Bo Xia and Jiaqi Wu and Yifei Zhao and Kai Qin and Yongzhe Chang and Xueqian Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion-RainbowPA: Improvements integrated preference alignment for diffusion-based text-to-image generation},
  url          = {https://openreview.net/forum?id=KY0TSY2bx8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the potential of direct feedback alignment for continual learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MRZQrn7JEG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world applications of machine learning require robustness to shifts in the data distribution over time. A critical limitation of standard artiﬁcial neural networks trained with backpropagation (BP) is their susceptibility to catastrophic forgetting: they “forget” prior knowledge when trained on a new task, while biological neural networks tend to be more robust to catastrophic forgetting. While various algorithmic ways of mitigating catastrophic forgetting have been proposed, developing an optimization algorithm that is capable of learning continuously remains an open problem. Motivated by recent theoretical results, here we explore whether a biologically inspired learning algorithm like Direct Feedback Align- ment (DFA) can mitigate catastrophic forgetting in artiﬁcial neural networks. We train fully-connected networks on several continual learning benchmarks using DFA and compare its performance to vanilla backpropagation, random features, and other continual learning algorithms. We ﬁnd that an inherent bias of DFA, called “degeneracy breaking”, leads to low average forgetting on common continual learning benchmarks when using DFA in the Domain-Incremental and the Task-Incremental learning scenarios. We show how to control the trade-oﬀ between learning and forgetting with DFA, and relate diﬀerent modes of using DFA to other methods in the ﬁeld.},
  archive      = {J_TMLR},
  author       = {Sara Folchini and Viplove Arora and Sebastian Goldt},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring the potential of direct feedback alignment for continual learning},
  url          = {https://openreview.net/forum?id=MRZQrn7JEG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse condensed data generation via class preserving distribution matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QOrzmDQYou'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale datasets for training many real-world machine learning models pose significant computational resource challenges. One approach to mitigate this is via data condensation, which aims at learning a small dataset but still sufficiently capturing the rich information in the original one. Most of existing approaches learn the condensed dataset and task-related model parameters (e.g., classifier) in a bi-level meta-learning way. The recently proposed distribution matching (DM), however, avoids the expensive bi-level optimization but ignores task-related models. This work proposes a novel class preserving DM framework consisting of two key components. The first one is responsible for capturing the original data distribution of each class based on energy distance, which can encourage the diversity in the generated synthetic data. The other is classifier-critic constraint, which forces the learned synthetic samples to fit pre-trained task-related models, such as an off-the-shelf classifier. Designing the optimization loss in this way, we can generate more diverse and class preserving distilled data without the bi-level optimization. Extensive experiments reveal that our method can produce more effective condensed data for downstream tasks with less training cost and can also be successfully applied to de-biased dataset condensation.},
  archive      = {J_TMLR},
  author       = {Dandan Guo and Zhuo Li and He Zhao and Mingyuan Zhou and Hongyuan Zha},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diverse condensed data generation via class preserving distribution matching},
  url          = {https://openreview.net/forum?id=QOrzmDQYou},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of frontiers in LLM reasoning: Inference scaling, learning to reason, and agentic systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SlsZZ25InC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multiagent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. Finally, we identify emerging trends, such as domain-specific reasoning systems, and open challenges, such as evaluation and data quality. This survey aims to provide AI researchers and practitioners with a comprehensive foundation for advancing reasoning in LLMs, paving the way for more sophisticated and reliable AI systems.},
  archive      = {J_TMLR},
  author       = {Zixuan Ke and Fangkai Jiao and Yifei Ming and Xuan-Phi Nguyen and Austin Xu and Do Xuan Long and Minzhi Li and Chengwei Qin and PeiFeng Wang and silvio savarese and Caiming Xiong and Shafiq Joty},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey of frontiers in LLM reasoning: Inference scaling, learning to reason, and agentic systems},
  url          = {https://openreview.net/forum?id=SlsZZ25InC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reproducibility study of "Competition of mechanisms: Tracing how language models handle facts and counterfactuals". <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VCG6j3tcAA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reproducibility study of Ortu et al. (2024), investigating the competition of the factual recall and counterfactual in-context adaptation mechanisms in GPT-2. We extend experiments developed by the original authors with softmax-normalized logits as another metric for gauging the evolution of the scoring of tokens in the model. Our reproduced and extended experiments validate the original paper's main claims regarding the location of the competition of mechanisms in GPT-2, i.e. that the competition emerges predominantly in later layers, and is driven by the attention blocks corresponding to a subset of specialized attention heads. Additionally, we explore intervention strategies based on attention modification to increase factual accuracy. We find that boosting multiple attention heads involved in factual recall simultaneously can have a synergistic effect on factual accuracy, which is further enhanced by the suppression of copy heads. Finally, we rework how the competition of mechanisms is conceptualized and find that the specialized factual recall heads identified by Ortu et al. (2024) act as copy regulators, penalizing counterfactual in-context adaptation and rewarding the copying of factual information.},
  archive      = {J_TMLR},
  author       = {Tijs Wiegman and Leyla Perotti and Viktória Pravdová and Ori Brand and Maria Heuss},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reproducibility study of "Competition of mechanisms: Tracing how language models handle facts and counterfactuals"},
  url          = {https://openreview.net/forum?id=VCG6j3tcAA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward linearly regularizing the geometric bottleneck of linear generalized attention. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Vpyg3fqXbl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers excel across domains, yet their full self-attention carries a prohibitive $\mathcal{O}(n^2)$ cost for long sequences with length $n$. Existing \textit{efficient} attention methods either restrict the attention pattern (local/sparse attention) or approximate the softmax kernel with certain drawbacks. The former suffers from attention bottlenecks (over-squashing of long-range dependencies) and invalidates the use of global tokens in autoregressive tasks, while the latter often requires sequential processing that can degrade in accuracy when approximations fall short. In this work, we introduce the \textit{Bottleneck Regularized Linear Attention (BRL-Attention)}, uniting the strengths of pattern-based and kernel-based techniques to enable efficient, global information flow with linear complexity. BRL-Attention extends a local attention pattern with a small set of compressed tokens that serve as a global information reservoir, ensuring long-range interactions without quadratic cost. This bottleneck regularization strategy effectively alleviates the geometric attention bottleneck and retains full expressiveness; that is, it matches the sequence modeling capacity of full softmax attention while mitigating over-squashing across layers. Moreover, it integrates global tokens without breaking causal masking, making it applicable to both encoder-only and autoregressive decoder architectures. Extensive experiments on sequence and graph benchmarks demonstrate that BRL-Attention matches or surpasses the predictive performance of standard Transformers with full attention, while substantially reducing memory usage and computation time to levels comparable with linear sparse attention.},
  archive      = {J_TMLR},
  author       = {Jiaxu Liu and Xinping Yi and Xiangyu Yin and Yuhang Song and Gaojie Jin and Xiaowei Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Toward linearly regularizing the geometric bottleneck of linear generalized attention},
  url          = {https://openreview.net/forum?id=Vpyg3fqXbl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Between linear and sinusoidal: Rethinking the time encoder in dynamic graph learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=W6GQvdOGHg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph learning is essential for applications involving temporal networks and requires effective modeling of temporal relationships. Seminal attention-based models like TGAT and DyGFormer rely on sinusoidal time encoders to capture temporal dependencies between edge events. Prior work justified sinusoidal encodings because their inner products depend on the time spans between events, which are crucial features for modeling inter-event relations. However, sinusoidal encodings inherently lose temporal information due to their many-to-one nature and therefore require high dimensions. In this paper, we rigorously study a simpler alternative: the linear time encoder, which avoids temporal information loss caused by sinusoidal functions and reduces the need for high-dimensional time encoders. We show that the self-attention mechanism can effectively learn to compute time spans between events from linear time encodings and extract relevant temporal patterns. Through extensive experiments on six dynamic graph datasets, we demonstrate that the linear time encoder improves the performance of TGAT and DyGFormer in most cases. Moreover, the linear time encoder can lead to significant savings in model parameters with minimal performance loss. For example, compared to a 100-dimensional sinusoidal time encoder, TGAT with a 2-dimensional linear time encoder saves 43% of parameters and achieves higher average precision on five datasets. While both encoders can be used simultaneously, our study highlights the often-overlooked advantages of linear time features in modern dynamic graph models. These findings can positively impact the design choices of various dynamic graph learning architectures and eventually benefit temporal network applications such as recommender systems, communication networks, and traffic forecasting. The experimental code is available at: https://github.com/hsinghuan/dg-linear-time.git.},
  archive      = {J_TMLR},
  author       = {Hsing-Huan Chung and Shravan S Chaudhari and Xing Han and Yoav Wald and Suchi Saria and Joydeep Ghosh},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Between linear and sinusoidal: Rethinking the time encoder in dynamic graph learning},
  url          = {https://openreview.net/forum?id=W6GQvdOGHg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The geometry of phase transitions in diffusion models: Tubular neighbourhoods and singularities. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ahVFKFLYk2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models undergo phase transitions during the generative process where data features suddenly emerge in the final stages. The current study aims to elucidate this critical phenomenon from the geometrical perspective. We employ the concept of ``injectivity radius'', a quantity that characterises the structure of the data manifold. Through theoretical and empirical evidence, we demonstrate that phase transitions in the generative process of diffusion models are closely related to the injectivity radius. Our findings offer a novel perspective on phase transitions in diffusion models, with potential implications for improving performance and sampling efficiency.},
  archive      = {J_TMLR},
  author       = {Manato Yaguchi and Kotaro Sakamoto and Ryosuke Sakamoto and Masato Tanabe and Masatomo Akagawa and Yusuke Hayashi and Masahiro Suzuki and Yutaka Matsuo},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The geometry of phase transitions in diffusion models: Tubular neighbourhoods and singularities},
  url          = {https://openreview.net/forum?id=ahVFKFLYk2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large action models: From inception to implementation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bYdKtf0Q31'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI continues to advance, there is a growing demand for systems that go beyond language-based assistance and move toward intelligent agents capable of performing real-world actions. This evolution requires the transition from traditional Large Language Models (LLMs), which excel at generating textual responses, to Large Action Models (LAMs), designed for action generation and execution within dynamic environments. Enabled by agent systems, LAMs hold the potential to transform AI from passive language understanding to active task completion, marking a significant milestone in the progression toward artificial general intelligence. In this paper, we present a comprehensive framework for developing LAMs, offering a systematic approach to their creation, from inception to deployment. We begin with an overview of LAMs, highlighting their unique characteristics and delineating their differences from LLMs. Using a Windows OS-based agent as a case study, we provide a detailed, step-by-step guide on the key stages of LAM development, including data collection, model training, environment integration, grounding, and evaluation. This generalizable workflow can serve as a blueprint for creating functional LAMs in various application domains. We conclude by identifying the current limitations of LAMs and discussing directions for future research and industrial deployment, emphasizing the challenges and opportunities that lie ahead in realizing the full potential of LAMs in real-world applications.},
  archive      = {J_TMLR},
  author       = {Lu Wang and Fangkai Yang and Chaoyun Zhang and Junting Lu and Jiaxu Qian and Shilin He and Pu Zhao and Bo Qiao and He Huang and Si Qin and Qisheng Su and Jiayi Ye and Yudi Zhang and Jian-Guang Lou and Qingwei Lin and Saravan Rajmohan and Dongmei Zhang and Qi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Large action models: From inception to implementation},
  url          = {https://openreview.net/forum?id=bYdKtf0Q31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOCK: An algorithm for learning nonparametric differential equations via multivariate occupation kernel functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fjVIp2Z9RS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a nonparametric system of ordinary differential equations from trajectories in a $d$-dimensional state space requires learning $d$ functions of $d$ variables. Explicit formulations often scale quadratically in $d$ unless additional knowledge about system properties, such as sparsity and symmetries, is available. In this work, we propose a linear approach, the multivariate occupation kernel method (MOCK), using the implicit formulation provided by vector-valued reproducing kernel Hilbert spaces. The solution for the vector field relies on multivariate occupation kernel functions associated with the trajectories and scales linearly with the dimension of the state space. We validate through experiments on a variety of simulated and real datasets ranging from 2 to 1024 dimensions, and provide an example with a divergence-free vector field. MOCK outperforms all other comparators on 3 of the 9 datasets on full trajectory prediction and 4 out of the 9 datasets on next-point prediction.},
  archive      = {J_TMLR},
  author       = {Victor William Rielly and Kamel Lahouel and Ethan Lew and Nicholas Fisher and Vicky Geneva Haney and Michael Lee Wells and Bruno Michel Jedynak},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MOCK: An algorithm for learning nonparametric differential equations via multivariate occupation kernel functions},
  url          = {https://openreview.net/forum?id=fjVIp2Z9RS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data is sufficient for zero-shot visual generalization from offline data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gFmSFa408D'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) offers a promising framework for training agents using pre-collected datasets without the need for further environment interaction. However, policies trained on offline data often struggle to generalise due to limited exposure to diverse states.The complexity of visual data introduces additional challenges such as noise, distractions, and spurious correlations, which can misguide the policy and increase the risk of overfitting if the training data is not sufficiently diverse. Indeed, this makes it challenging to leverage vision-based offline data in training robust agents that can generalize to unseen environments. To solve this problem, we propose a simple approach—generating additional synthetic training data. We propose a two-step process, first augmenting the originally collected offline data to improve zero-shot generalization by introducing diversity, then using a diffusion model to generate additional data in latent space. We test our method across both continuous action spaces (Visual D4RL) and discrete action spaces (Procgen), demonstrating that it significantly improves generalization without requiring any algorithmic changes to existing model-free offline RL methods. We show that our method not only increases the diversity of the training data but also significantly reduces the generalization gap at test time while maintaining computational efficiency. We believe this approach could fuel additional progress in generating synthetic data to train more general agents in the future.},
  archive      = {J_TMLR},
  author       = {Ahmet H. Güzel and Ilija Bogunovic and Jack Parker-Holder},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Synthetic data is sufficient for zero-shot visual generalization from offline data},
  url          = {https://openreview.net/forum?id=gFmSFa408D},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSkips: Efficiency through explicit temporal delay connections in spiking neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hwz32S06G4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) with their bio-inspired Leaky Integrate-and-Fire (LIF) neurons inherently capture temporal information. This makes them well-suited for sequential tasks like processing event-based data from Dynamic Vision Sensors (DVS) and event-based speech tasks. Harnessing the temporal capabilities of SNNs requires mitigating vanishing spikes during training, capturing spatio-temporal patterns and enhancing precise spike timing. To address these challenges, we propose _TSkips_, augmenting SNN architectures with forward and backward skip connections that incorporate explicit temporal delays. These connections capture long-term spatio-temporal dependencies and facilitate better spike flow over long sequences. The introduction of _TSkips_ creates a vast search space of possible configurations, encompassing skip positions and time delay values. To efficiently navigate this search space, this work leverages training-free Neural Architecture Search (NAS) to identify optimal network structures and corresponding delays. We demonstrate the effectiveness of our approach on four event-based datasets: DSEC-flow for optical flow estimation, DVS128 Gesture for hand gesture recognition and Spiking Heidelberg Digits (SHD) and Spiking Speech Commands (SSC) for speech recognition. Our method achieves significant improvements across these datasets: up to 18% reduction in Average Endpoint Error (AEE) on DSEC-flow, 8% increase in classification accuracy on DVS128 Gesture, and up to ~8% and ~16% higher classification accuracy on SHD and SSC, respectively.},
  archive      = {J_TMLR},
  author       = {Prajna G. Malettira and Shubham Negi and Wachirawit Ponghiran and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TSkips: Efficiency through explicit temporal delay connections in spiking neural networks},
  url          = {https://openreview.net/forum?id=hwz32S06G4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting data augmentation for ultrasound images. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=iGcxlTLIL5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation is a widely used and effective technique to improve the generalization performance of deep neural networks. Yet, despite often facing limited data availability when working with medical images, it is frequently underutilized. This appears to come from a gap in our collective understanding of the efficacy of different augmentation techniques across different tasks and modalities. One modality where this is especially true is ultrasound imaging. This work addresses this gap by analyzing the effectiveness of different augmentation techniques at improving model performance across a wide range of ultrasound image analysis tasks. To achieve this, we introduce a new standardized benchmark of 14 ultrasound image classification and semantic segmentation tasks from 10 different sources and covering 11 body regions. Our results demonstrate that many of the augmentations commonly used for tasks on natural images are also effective on ultrasound images, even more so than augmentations developed specifically for ultrasound images in some cases. We also show that diverse augmentation using TrivialAugment, which is widely used for natural images, is also effective for ultrasound images. Moreover, our proposed methodology represents a structured approach for assessing various data augmentations that can be applied to other contexts and modalities.},
  archive      = {J_TMLR},
  author       = {Adam Tupper and Christian Gagné},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting data augmentation for ultrasound images},
  url          = {https://openreview.net/forum?id=iGcxlTLIL5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking visual secrets: Inverting features with diffusion priors for image reconstruction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=j6MgbuBiGV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverting visual representations within deep neural networks (DNNs) presents a challenging and important problem in the field of security and privacy for deep learning. The main goal is to invert the features of an unidentified target image generated by a pre-trained DNN, aiming to reconstruct the original image. Feature inversion holds particular significance in understanding the privacy leakage inherent in contemporary split DNN execution techniques, as well as in various applications based on the extracted DNN features. In this paper, we explore the use of diffusion models, a promising technique for image synthesis, to enhance feature inversion quality. We also investigate the potential of incorporating alternative forms of prior knowledge, such as textual prompts and cross-frame temporal correlations, to further improve the quality of inverted features. Our findings reveal that diffusion models can effectively leverage hidden information from the DNN features, resulting in superior reconstruction performance compared to previous methods. This research offers valuable insights into how diffusion models can enhance privacy and security within applications that are reliant on DNN features.},
  archive      = {J_TMLR},
  author       = {Sai Qian Zhang and Ziyun Li and Chuan Guo and Saeed Mahloujifar and Deeksha Dangwal and G. Edward Suh and Barbara De Salvo and Chiao Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlocking visual secrets: Inverting features with diffusion priors for image reconstruction},
  url          = {https://openreview.net/forum?id=j6MgbuBiGV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resolution residual networks — Generalizing across resolutions easily and efficiently. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kTh5tFd1Mq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of signal data captured in the real world uses numerous sensors with different resolutions. In practice, most deep learning architectures are fixed-resolution; they consider a single resolution at training and inference time. This is convenient to implement but fails to fully take advantage of the diverse signal data that exists. In contrast, other deep learning architectures are adaptive-resolution; they directly allow various resolutions to be processed at training and inference time. This provides computational adaptivity but either sacrifices robustness or compatibility with mainstream layers, which hinders their use. In this work, we introduce Adaptive Resolution Residual Networks (ARRNs) to surpass this tradeoff. We construct ARRNs from Laplacian residuals, which serve as generic adaptive-resolution adapters for fixed-resolution layers. We use smoothing filters within Laplacian residuals to linearly separate input signals over a series of resolution steps. We can thereby skip Laplacian residuals to cast high-resolution ARRNs into low-resolution ARRNs that are computationally cheaper yet numerically identical over low-resolution signals. We guarantee this result when Laplacian residuals are implemented with perfect smoothing kernels. We complement this novel component with Laplacian dropout, which randomly omits Laplacian residuals during training. This regularizes for robustness to a distribution of lower resolutions. This also regularizes for numerical errors that may occur when Laplacian residuals are implemented with approximate smoothing kernels. We provide a solid grounding for the advantageous properties of ARRNs through a theoretical analysis based on neural operators, and empirically show that ARRNs embrace the challenge posed by diverse resolutions with computational adaptivity, robustness, and compatibility with mainstream layers.},
  archive      = {J_TMLR},
  author       = {Léa Demeule and Mahtab Sandhu and Glen Berseth},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive resolution residual networks — Generalizing across resolutions easily and efficiently},
  url          = {https://openreview.net/forum?id=kTh5tFd1Mq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian loss smoothing enables certified training with tight convex relaxations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lknvxcjuos'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training neural networks with high certified accuracy against adversarial examples remains an open challenge despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods, perhaps surprisingly, can perform worse than looser relaxations. Prior work hypothesized that this phenomenon is caused by the discontinuity, non-smoothness, and perturbation sensitivity of the loss surface induced by tighter relaxations. In this work, we theoretically show that Gaussian Loss Smoothing (GLS) can alleviate these issues. We confirm this empirically by instantiating GLS with two variants: a zeroth-order optimization algorithm, called PGPE, which allows training with non-differentiable relaxations, and a first-order optimization algorithm, called RGS, which requires gradients of the relaxation but is much more efficient than PGPE. Extensive experiments show that when combined with tight relaxations, these methods surpass state-of-the-art methods when training on the same network architecture for many settings. Our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks and pave a path towards leveraging tighter relaxations for certified training.},
  archive      = {J_TMLR},
  author       = {Stefan Balauca and Mark Niklas Mueller and Yuhao Mao and Maximilian Baader and Marc Fischer and Martin Vechev},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gaussian loss smoothing enables certified training with tight convex relaxations},
  url          = {https://openreview.net/forum?id=lknvxcjuos},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformers trained on proteins can learn to attend to euclidean distance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mU59bDyqqv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While conventional Transformers generally operate on sequence data, they can be used in conjunction with structure models, typically SE(3)-invariant or equivariant graph neural networks (GNNs), for 3D applications such as protein structure modelling. These hybrids typically involve either (1) preprocessing/tokenizing structural features as input for Transformers or (2) taking Transformer embeddings and processing them within a structural representation. However, there is evidence that Transformers can learn to process structural information on their own, such as the AlphaFold3 structural diffusion model. In this work we show that Transformers can function independently as structure models when passed linear embeddings of coordinates. We first provide a theoretical explanation for how Transformers can learn to filter attention as a 3D Gaussian with learned variance. We then validate this theory using both simulated 3D points and in the context of masked token prediction for proteins. Finally, we show that pre-training protein Transformer encoders with structure improves performance on multiple downstream tasks, yielding competitive performance with custom structural models. Together, this work provides a basis for using standard Transformers as hybrid structure-language models. The code is available at: https://github.com/oxpig/attending-to-distance.},
  archive      = {J_TMLR},
  author       = {Isaac Ellmen and Constantin Schneider and Matthew I. J. Raybould and Charlotte Deane},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transformers trained on proteins can learn to attend to euclidean distance},
  url          = {https://openreview.net/forum?id=mU59bDyqqv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive large language models for reliable answering under incomplete context. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nnlmcxYWlV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of large language models (LLMs) has revolutionized the way humans interact with artificial intelligence systems. However, their reliability in sensitive applications—such as personal consultations or clinical decision-making—remains limited. A critical shortfall lies in LLMs’ inherent lack of interactivity: these models generate responses even when essential context or domain-specific knowledge is absent, risking inaccurate or misleading outputs. A potential approach to mitigate this issue is to enable LLMs to pose clarifying questions, thereby uncovering the missing information required to provide accurate responses. However, previous methods often tend to greedily prompt LLMs to ask questions. This burdens the user to respond to potentially irrelevant questions and makes the system less flexible. In this paper, we introduce LaMSeI (Language Model with Selective Interaction) method, which enhances LLMs’ ability to judge when interaction is necessary under ambiguous or incomplete contexts. The motivation of LaMSeI is to measure the level of LLMs’ uncertainty about the user query, and interacts with user only when the uncertainty is high. Additionally, we incorporate active learning techniques to select the most informative questions from question candidates, for effectively uncovering the missing context. Our empirical studies, across various challenging question answering benchmarks, where LLMs are posed queries with incomplete context, demonstrate the effectiveness of LaMSeI. The method improves answer accuracy from 31.9% to 50.9%, outperforming other leading question-answering frameworks. Moreover, in experiments involving human participants, LaMSeI consistently generates answers superior to or comparable to baselines in more than 82% of the cases. Moreover, we verify the performance of LaMSeI on various LLMs, such as LLAMA2, LLAMA3, Vicuna and GPT-3.5, highlighting its capability to improve interactive language models.},
  archive      = {J_TMLR},
  author       = {Jing-Cheng Pang and Heng-Bo Fan and Pengyuan Wang and Jia-Hao Xiao and Nan Tang and Si-Hang Yang and Chengxing Jia and Ming-Kun Xie and Xiang Chen and Sheng-Jun Huang and Yang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interactive large language models for reliable answering under incomplete context},
  url          = {https://openreview.net/forum?id=nnlmcxYWlV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep autoregressive models as causal inference engines. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uuREHPf2ll'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing causal inference (CI) models are often restricted to data with low-dimensional confounders and singleton actions. We propose an autoregressive (AR) CI framework capable of handling complex confounders and sequential actions commonly found in modern applications. Our approach accomplishes this using sequencification, which transforms data from an underlying causal diagram into a sequence of tokens. Sequencification not only accommodates training with data generated from a large class of DAGs, but also extends existing CI capabilities to estimate multiple causal quantities using a single model. We can directly compute probabilities from interventional distributions, simplifying inference and improving outcome prediction accuracy. We demonstrate that an AR model adapted for CI is efficient and effective in various complex applications such as navigating mazes, playing chess endgames, and evaluating the impact of certain keywords on paper acceptance rates, where we consider causal queries beyond standard reinforcement learning-type questions.},
  archive      = {J_TMLR},
  author       = {Daniel Jiwoong Im and Kevin Zhang and Nakul Verma and Kyunghyun Cho},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep autoregressive models as causal inference engines},
  url          = {https://openreview.net/forum?id=uuREHPf2ll},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting systematic weaknesses in vision models along predefined human-understandable dimensions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yK9pvt4nBX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slice discovery methods (SDMs) are prominent algorithms for finding systematic weaknesses in DNNs. They identify top-k semantically coherent slices/subsets of data where a DNN-under-test has low performance. For being directly useful, slices should be aligned with human-understandable and relevant dimensions, which, for example, are defined by safety and domain experts as part of the operational design domain (ODD). While SDMs can be applied effectively on structured data, their application on image data is complicated by the lack of semantic metadata. To address these issues, we present an algorithm that combines foundation models for zero-shot image classification to generate semantic metadata with methods for combinatorial search to find systematic weaknesses in images. In contrast to existing approaches, ours identifies weak slices that are in line with predefined human-understandable dimensions. As the algorithm includes foundation models, its intermediate and final results may not always be exact. Therefore, we include an approach to address the impact of noisy metadata. We validate our algorithm on both synthetic and real-world datasets, demonstrating its ability to recover human-understandable systematic weaknesses. Furthermore, using our approach, we identify systematic weaknesses of multiple pre-trained and publicly available state-of-the-art computer vision DNNs.},
  archive      = {J_TMLR},
  author       = {Sujan Sai Gannamaneni and Rohil Prakash Rao and Michael Mock and Maram Akila and Stefan Wrobel},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Detecting systematic weaknesses in vision models along predefined human-understandable dimensions},
  url          = {https://openreview.net/forum?id=yK9pvt4nBX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian scenes: Pose-free sparse-view scene reconstruction using depth-enhanced diffusion priors. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yp1CYo6R0r'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a generative approach for pose-free (without camera parameters) reconstruction of 360 scenes from a sparse set of 2D images. Pose-free scene reconstruction from incomplete, pose-free observations is usually regularized with depth estimation or 3D foundational priors. While recent advances have enabled sparse-view reconstruction of large complex scenes (with high degree of foreground and background detail) with known camera poses using view-conditioned generative priors, these methods cannot be directly adapted for the pose-free setting when ground-truth poses are not available during evaluation. To address this, we propose an image-to-image generative model designed to inpaint missing details and remove artifacts in novel view renders and depth maps of a 3D scene. We introduce context and geometry conditioning using Feature-wise Linear Modulation (FiLM) modulation layers as a lightweight alternative to cross-attention and also propose a novel confidence measure for 3D Gaussian splat representations to allow for better detection of these artifacts. By progressively integrating these novel views in a Gaussian-SLAM-inspired process, we achieve a multi-view-consistent 3D representation. Evaluations on the MipNeRF360 and DL3DV-10K benchmark dataset demonstrate that our method surpasses existing pose-free techniques and performs competitively with state-of-the-art posed (precomputed camera parameters are given) reconstruction methods in complex 360 scenes. Our code and datasets will be open-sourced upon acceptance.},
  archive      = {J_TMLR},
  author       = {Soumava Paul and Prakhar Kaushik and Alan Yuille},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gaussian scenes: Pose-free sparse-view scene reconstruction using depth-enhanced diffusion priors},
  url          = {https://openreview.net/forum?id=yp1CYo6R0r},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring end-to-end differentiable neural charged particle tracking – A loss landscape perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1Pi2GwduEz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement and analysis of high energetic particles for scientific, medical or industrial applications is a complex procedure, requiring the design of sophisticated detector and data processing systems. The development of adaptive and differentiable software pipelines using a combination of conventional and machine learning algorithms is therefore getting ever more important to optimize and operate the system efficiently while maintaining end-to-end (E2E) differentiability. In this work, we lay the groundwork for E2E differentiable decision focused learning for the application of charged particle tracking using graph neural networks with combinatorial components solving a linear assignment problem for each detector layer. We demonstrate empirically that including differentiable variations of discrete assignment operations allows for efficient network optimization, working better or on par with approaches that lack E2E differentiability. In additional studies, we dive deeper into the optimization process and provide further insights from a loss landscape perspective, providing a robust foundation for future work. We demonstrate that while both methods converge into similar performing, globally well-connected regions, they suffer under substantial predictive instability across initialization and optimization methods, which can have unpredictable consequences on the performance of downstream tasks such as image reconstruction. We also point out a dependency between the interpolation factor of the gradient estimator and the prediction stability of the model, suggesting the choice of sufficiently small values. Given the strong global connectivity of learned solutions and the excellent training performance, we argue that E2E differentiability provides, besides the general availability of gradient information, an important tool for robust particle tracking to mitigate prediction instabilities by favoring solutions that perform well on downstream tasks.},
  archive      = {J_TMLR},
  author       = {Tobias Kortus and Ralf Keidel and Nicolas R. Gauger},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring end-to-end differentiable neural charged particle tracking – A loss landscape perspective},
  url          = {https://openreview.net/forum?id=1Pi2GwduEz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Activate and adapt: A two-stage framework for open-set model adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2AWbwSpET9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of generalizing to new environments is critical for deep neural networks. Most existing works presume that the training and test data share an identical label set, overlooking the potential presence of new classes in test data. In this paper, we tackle a practical and challenging problem: Open-Set Model Adaptation (OSMA). OSMA aims to train a model on the source domain, which contains only known class data, and then adapt the trained model to the distribution-shifted target domain to classify known class data while identifying new class data. In this context, we face two challenges: (1) enabling the model to recognize new classes using only the known class data from the source domain during training, and (2) adapting the source-trained model to the target domain that contains new class data. To address these challenges, we propose a novel and universal two-stage framework named Activate and Adapt (ADA). In the training stage, we extract potential new class information hidden within the rich semantics of the source domain data to enable the model to identify new class data. Additionally, to retain source domain information while preserving data privacy, we condense the source domain data into a small dataset, facilitating the subsequent adaptation phase. In the test stage, we adaptively adjust the source-trained model to the target domain with new classes by infusing the style of target data into the condensed dataset, and decoupling domain alignment for known and new classes. Experiments across three standard benchmarks demonstrate that ADA surpasses previous methods in both online and offline settings.},
  archive      = {J_TMLR},
  author       = {Xiasi Wang and Jiaqi Lin and Chaoqi Chen and Luyao Tang and Yi Huang and Chengsen Wang and Lei YE and Yuan Yao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Activate and adapt: A two-stage framework for open-set model adaptation},
  url          = {https://openreview.net/forum?id=2AWbwSpET9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIVINE: Diverse-inconspicuous feature learning to mitigate abridge learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8NGKGTAD6F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning algorithms aim to minimize overall error and exhibit impressive performance on test datasets across various domains. However, they often struggle with out-of-distribution (OOD) data samples. We posit that deep models primarily capture prominent features beneficial for the task while neglecting subtle yet discriminative features, a phenomenon we refer to as Abridge Learning. To address this issue and encourage more comprehensive feature utilization, we introduce DIVINE (DIVerse and INconspicuous FEature Learning), a novel approach that leverages iterative feature suppression guided by dominance maps to ensure that models engage with a diverse and complementary set of discriminative features. Through extensive experiments on multiple datasets, including MNIST, CIFAR-10, CIFAR-100, TinyImageNet, and their corrupted and perturbed variants (CIFAR-10-C/P, CIFAR-100-C/P, TinyImageNet-C/P), we demonstrate that DIVINE significantly improves model robustness and generalization. On perturbation benchmarks, DIVINE achieves mean Flip Rates (mFR) of 5.36%, 3.10%, and 21.85% on CIFAR-10-P, CIFAR-100-P, and TinyImageNet-P respectively, compared to 6.53%, 11.75%, and 31.90% for standard training methods exhibiting Abridge Learning. Moreover, DIVINE attains state-of-the-art results on CIFAR-100-P, demonstrating that addressing Abridge Learning leads to more robust models against real-world distribution variations.},
  archive      = {J_TMLR},
  author       = {Saheb Chhabra and Kartik Thakral and Surbhi Mittal and Mayank Vatsa and Richa Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DIVINE: Diverse-inconspicuous feature learning to mitigate abridge learning},
  url          = {https://openreview.net/forum?id=8NGKGTAD6F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsity-driven plasticity in multi-task reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9L4Z23EfE9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plasticity loss, a diminishing capacity to adapt as training progresses, is a critical challenge in deep reinforcement learning. We examine this issue in multi-task reinforcement learning (MTRL), where higher representational flexibility is crucial for managing diverse and potentially conflicting task demands. We systematically explore how sparsification methods, particularly Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance plasticity and consequently improve performance in MTRL agents. We evaluate these approaches across distinct MTRL architectures (shared backbone, Mixture of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks, comparing against dense baselines, and a comprehensive range of alternative plasticity-inducing or regularization methods. Our results demonstrate that both GMP and SET effectively mitigate key indicators of plasticity degradation, such as neuron dormancy and representational collapse. These plasticity improvements often correlate with enhanced multi-task performance, with sparse agents frequently outperforming dense counterparts and achieving competitive results against explicit plasticity interventions. Our findings offer insights into the interplay between plasticity, network sparsity, and MTRL designs, highlighting dynamic sparsification as a robust but context-sensitive tool for developing more adaptable MTRL systems.},
  archive      = {J_TMLR},
  author       = {Aleksandar Todorov and Juan Cardenas-Cartagena and Rafael F. Cunha and Marco Zullich and Matthia Sabatelli},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparsity-driven plasticity in multi-task reinforcement learning},
  url          = {https://openreview.net/forum?id=9L4Z23EfE9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preference discerning with LLM-enhanced generative retrieval. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=74mrOdhvvT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sequential recommendation, models recommend items based on user's interaction history. To this end, current models usually incorporate information such as item descriptions and user intent or preferences. User preferences are usually not explicitly given in open-source datasets, and thus need to be approximated, for example via large language models (LLMs). Current approaches leverage approximated user preferences only during training and rely solely on the past interaction history for recommendations, limiting their ability to dynamically adapt to changing preferences, potentially reinforcing echo chambers. To address this issue, we propose a new paradigm, namely *preference discerning*, which explicitly conditions a generative recommendation model on user preferences in natural language within its context. To evaluate *preference discerning*, we introduce a novel benchmark that provides a holistic evaluation across various scenarios, including preference steering and sentiment following. Upon evaluating current state-of-the-art methods on our benchmark, we discover that their ability to dynamically adapt to evolving user preferences is limited. To address this, we propose a new method named Mender (**M**ultimodal Prefer**en**ce **D**iscern**er**), which achieves state-of-the-art performance in our benchmark. Our results show that Mender effectively adapts its recommendation guided by human preferences, even if not observed during training, paving the way toward more flexible recommendation models.},
  archive      = {J_TMLR},
  author       = {Fabian Paischer and Liu Yang and Linfeng Liu and Shuai Shao and Kaveh Hassani and Jiacheng Li and Ricky T. Q. Chen and Zhang Gabriel Li and Xiaoli Gao and Wei Shao and Xue Feng and Nima Noorshams and Sem Park and Bo Long and Hamid Eghbalzadeh},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Preference discerning with LLM-enhanced generative retrieval},
  url          = {https://openreview.net/forum?id=74mrOdhvvT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model tampering attacks enable more rigorous evaluations of LLM capabilities. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=E60YbLnQd2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, this approach suffers from two limitations. First, input-output evaluations cannot fully evaluate realistic risks from open-weight models. Second, the behaviors identified during any particular input-output evaluation can only lower-bound the model's worst-possible-case input-output behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together, these results highlight the difficulty of suppressing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone.},
  archive      = {J_TMLR},
  author       = {Zora Che and Stephen Casper and Robert Kirk and Anirudh Satheesh and Stewart Slocum and Lev E McKinney and Rohit Gandikota and Aidan Ewart and Domenic Rosati and Zichu Wu and Zikui Cai and Bilal Chughtai and Yarin Gal and Furong Huang and Dylan Hadfield-Menell},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Model tampering attacks enable more rigorous evaluations of LLM capabilities},
  url          = {https://openreview.net/forum?id=E60YbLnQd2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MUC: Machine unlearning for contrastive learning with black-box evaluation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F9pjSDvuM9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning offers effective solutions for revoking the influence of specific training data on pre-trained model parameters. While existing approaches address unlearning for classification and generative models, they overlook an important category of machine learning models: contrastive learning (CL) methods. This paper addresses this gap by introducing the Machine Unlearning for Contrastive Learning (MUC) framework and adapting existing methods. We identify limitations in current approaches, noting that several methods perform inadequately as unlearners and that existing evaluation tools insufficiently validate unlearning effects in contrastive learning. To address these issues, we propose Alignment Calibration (AC), a novel method that explicitly considers contrastive learning properties and optimizes towards new auditing metrics for easy verification of unlearning. Through empirical comparisons with baseline methods on SimCLR, MoCo, and CLIP, we demonstrate that AC: (1) achieves state-of-the-art performance, approximating exact unlearning (retraining); (2) enables data owners to clearly visualize unlearning effects through black-box evaluation. The code is available at https://github.com/EhanW/Alignment-Calibration.},
  archive      = {J_TMLR},
  author       = {Yihan Wang and Yiwei Lu and Guojun Zhang and Franziska Boenisch and Adam Dziedzic and Yaoliang Yu and Xiao-Shan Gao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MUC: Machine unlearning for contrastive learning with black-box evaluation},
  url          = {https://openreview.net/forum?id=F9pjSDvuM9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic block model-aware topological neural networks for graph link prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FBjVSPAsgs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is an important learning task for graph-structured data and is indispensable to understanding graphs' properties. Recent works focus on designing complicated graph neural networks (GNNs) architectures to explore and capture various pairwise interactions among graph nodes. Most GNNs are based on combining graph structural and node feature information by iterative message-passing schemes. However, despite GNNs revolutionizing the field of graph representation learning, some thorny questions are raised concerning whether GNNs can efficiently learn the edge probabilities based on topological structures (i.e., higher-order interactions) and node features, and provide statistically rigorous uncertainty estimates. In this paper, we tackle these challenges and propose a novel stochastic block model (SBM)-aware topological neural networks, called SBM-TNN, that uses SBMs to infer the latent community structure of nodes from graph structures and uses persistent homology to encode higher-order information. Furthermore, we theoretically study the entrywise bound and asymptotic normality of the estimated edge probability matrix to quantify the uncertainty in statistical inference of the edge probabilities. Our extensive experiments for link prediction on both graphs and knowledge graphs show that SBM-TNN achieves state-of-the-art performance over a set of popular baseline methods.},
  archive      = {J_TMLR},
  author       = {Yuzhou Chen and Xiao Guo and Shujie Ma},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic block model-aware topological neural networks for graph link prediction},
  url          = {https://openreview.net/forum?id=FBjVSPAsgs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining caption-image interactions in CLIP models with second-order attributions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HUUL19U7HP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual encoder architectures like Clip models map two types of inputs into a shared em- bedding space and predict similarities between them. Despite their wide application, it is, however, not understood how these models compare their two inputs. Common first-order feature-attribution methods explain importances of individual features and can, thus, only provide limited insights into dual encoders, whose predictions depend on interactions be- tween features. In this paper, we first derive a second-order method enabling the attribution of predictions by any differentiable dual encoder onto feature-interactions between its inputs. Second, we apply our method to Clip models and show that they learn fine-grained correspondences between parts of captions and regions in images. They match objects across input modes and also account for mismatches. This intrinsic visual-linguistic grounding ability, however, varies heavily between object classes, exhibits pronounced out-of-domain effects and we can identify individual errors as well as systematic failure categories. Code is publicly available: https://github.com/lucasmllr/exCLIP},
  archive      = {J_TMLR},
  author       = {Lucas Moeller and Pascal Tilli and Thang Vu and Sebastian Padó},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining caption-image interactions in CLIP models with second-order attributions},
  url          = {https://openreview.net/forum?id=HUUL19U7HP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffNat: Exploiting the kurtosis concentration property for image quality improvement. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HdZQ7pMPRd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have significantly advanced generative AI in terms of creating and editing natural images. However, improving the image quality of generated images is still of paramount interest. In this context, we propose a generic kurtosis concentration (KC) loss that can be readily applied to any standard diffusion model pipeline to improve image quality. Our motivation stems from the projected kurtosis concentration property of natural images, which states that natural images have nearly constant kurtosis values across different band-pass filtered versions of the image. To improve the image quality of generated images, we reduce the gap between the highest and lowest kurtosis values across the band-pass filtered versions (e.g., Discrete Wavelet Transform (DWT)) of images. In addition, we also propose a novel condition-agnostic perceptual guidance strategy during inference to further improve the quality. We validate the proposed approach on four diverse tasks, viz., (1) personalized few-shot finetuning using text guidance, (2) unconditional image generation, (3) image super-resolution, and (4) blind face-restoration. Integrating the proposed KC loss and perceptual guidance has improved the perceptual quality in all these tasks in terms of FID, MUSIQ score, and user evaluation. Code: https://github.com/aniket004/DiffNat.git},
  archive      = {J_TMLR},
  author       = {Aniket Roy and Maitreya Suin and Anshul Shah and Ketul Shah and Jiang Liu and Rama Chellappa},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DiffNat: Exploiting the kurtosis concentration property for image quality improvement},
  url          = {https://openreview.net/forum?id=HdZQ7pMPRd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive gradient normalization and independent sampling for (Stochastic) generalized-smooth optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KKSQQMlEfw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that many nonconvex machine learning problems satisfy a generalized-smooth condition that extends beyond traditional smooth nonconvex optimization. However, the existing algorithms are not fully adapted to such generalized-smooth nonconvex geometry and encounter significant technical limitations on their convergence analysis. In this work, we first analyze the convergence of adaptively normalized gradient descent under function geometries characterized by generalized-smoothness and the generalized PL condition, revealing the advantage of adaptive gradient normalization. Our results provide theoretical insights into adaptive normalization across various scenarios. For stochastic generalized-smooth nonconvex optimization, we propose the Independent-Adaptively Normalized Stochastic Gradient Descent algorithm, which leverages adaptive gradient normalization, independent sampling, and gradient clipping to achieve an $\mathcal{O}(\epsilon^{-4})$ sample complexity under relaxed noise assumptions. Experiments on large-scale nonconvex generalized-smooth problems demonstrate the fast convergence of our algorithm.},
  archive      = {J_TMLR},
  author       = {Yufeng Yang and Erin E. Tripp and Yifan Sun and Shaofeng Zou and Yi Zhou},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive gradient normalization and independent sampling for (Stochastic) generalized-smooth optimization},
  url          = {https://openreview.net/forum?id=KKSQQMlEfw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label smoothing is a pragmatic information bottleneck. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q0QEDhpbAK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study revisits label smoothing via a form of information bottleneck. Under the assumption of sufficient model flexibility and no conflicting labels for the same input, we theoretically and experimentally demonstrate that the model output obtained through label smoothing explores the optimal solution of the information bottleneck. Based on this, label smoothing can be interpreted as a practical approach to the information bottleneck, enabling simple implementation. As an information bottleneck method, we experimentally show that label smoothing also exhibits the property of being insensitive to factors that do not contain information about the target, or to factors that provide no additional information about it when conditioned on another variable.},
  archive      = {J_TMLR},
  author       = {Sota Kudo},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label smoothing is a pragmatic information bottleneck},
  url          = {https://openreview.net/forum?id=Q0QEDhpbAK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAIF: Sparse adversarial and imperceptible attack framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YZL29eJ5j1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks hamper the decision-making ability of neural networks by perturbing the input signal. For instance, adding calculated small distortions to images can deceive a well-trained image classification network. In this work, we propose a novel attack technique called \textbf{S}parse \textbf{A}dversarial and \textbf{I}mperceptible Attack \textbf{F}ramework (SAIF). Specifically, we design imperceptible attacks that contain low-magnitude perturbations at a few pixels and leverage these sparse attacks to reveal the vulnerability of classifiers. We use the Frank-Wolfe (conditional gradient) algorithm to simultaneously optimize the attack perturbations for bounded magnitude and sparsity with $O(1/\sqrt{T})$ convergence. Empirical results show that SAIF computes highly imperceptible and interpretable adversarial examples, and largely outperforms state-of-the-art sparse attack methods on ImageNet and CIFAR-10.},
  archive      = {J_TMLR},
  author       = {Tooba Imtiaz and Morgan R Kohler and Jared F Miller and Zifeng Wang and Masih Eskandar and Mario Sznaier and Octavia Camps and Jennifer Dy},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SAIF: Sparse adversarial and imperceptible attack framework},
  url          = {https://openreview.net/forum?id=YZL29eJ5j1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsity regularization via tree-structured environments for disentangled representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZzUz0jo200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many causal systems such as biological processes in cells can only be observed indirectly via measurements, such as gene expression. Causal representation learning---the task of correctly mapping low-level observations to latent causal variables---could advance scientific understanding by enabling inference of latent variables such as pathway activation. In this paper, we develop methods for inferring latent variables from multiple related datasets (environments) and tasks. As a running example, we consider the task of predicting a phenotype from gene expression, where we often collect data from multiple cell types or organisms that are related in known ways. The key insight is that the mapping from latent variables driven by gene expression to the phenotype of interest changes sparsely across closely related environments. To model sparse changes, we introduce Tree-Based Regularization (TBR), an objective that minimizes both prediction error and regularizes closely related environments to learn similar predictors. We prove that under assumptions about the degree of sparse changes, TBR identifies the true latent variables up to some simple transformations. We evaluate the theory empirically with both simulations and ground-truth gene expression data. We find that TBR recovers the latent causal variables better than related methods across these settings, even under settings that violate some assumptions of the theory.},
  archive      = {J_TMLR},
  author       = {Elliot Layne and Jason Hartford and Sebastien Lachapelle and Mathieu Blanchette and Dhanya Sridhar},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparsity regularization via tree-structured environments for disentangled representations},
  url          = {https://openreview.net/forum?id=ZzUz0jo200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact recovery guarantees for parameterized nonlinear system identification problem under sparse disturbances or semi-oblivious attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=c9o9UAmN3r'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of learning a nonlinear dynamical system by parameterizing its dynamics using basis functions. We assume that disturbances occur at each time step with an arbitrary probability $p$, which models the sparsity level of the disturbance vectors over time. These disturbances are drawn from an arbitrary, unknown probability distribution, which may depend on past disturbances, provided that it satisfies a zero-mean assumption. The primary objective of this paper is to learn the system's dynamics within a finite time and analyze the sample complexity as a function of $p$. To achieve this, we examine a LASSO-type non-smooth estimator, and establish necessary and sufficient conditions for its well-specifiedness and the uniqueness of the global solution to the underlying optimization problem. We then provide exact recovery guarantees for the estimator under two distinct conditions: boundedness and Lipschitz continuity of the basis functions. We show that finite-time exact recovery is achieved with high probability, even when $p$ approaches $1$. Unlike prior works, which primarily focus on independent and identically distributed (i.i.d.) disturbances and provide only asymptotic guarantees for system learning, this study presents the first finite-time analysis of nonlinear dynamical systems under a highly general disturbance model. Our framework allows for possible temporal correlations in the disturbances and accommodates semi-oblivious adversarial attacks, significantly broadening the scope of existing theoretical results.},
  archive      = {J_TMLR},
  author       = {Haixiang Zhang and Baturalp Yalcin and Javad Lavaei and Eduardo Sontag},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exact recovery guarantees for parameterized nonlinear system identification problem under sparse disturbances or semi-oblivious attacks},
  url          = {https://openreview.net/forum?id=c9o9UAmN3r},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cumulative reasoning with large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=grW15p4eq2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have shown remarkable progress, yet their ability to solve complex problems remains limited. In this work, we introduce Cumulative Reasoning (CR), a structured framework that enhances LLM problem-solving by emulating human-like iterative and cumulative thought processes. CR orchestrates LLMs in three distinct roles---Proposer, Verifier(s), and Reporter---to systematically decompose tasks, generate and validate intermediate reasoning steps, and compose them into a solution by building a dynamic Directed Acyclic Graph (DAG) of verified propositions. This approach substantially enhances problem-solving capabilities. We demonstrate CR’s advantage through several complex reasoning tasks: it outperforms existing methods in logical inference tasks with up to a 9.3% improvement, achieving 98.04% accuracy on the curated FOLIO wiki dataset. In the Game of 24, it achieves 98% accuracy, marking a 24% improvement over previous methods. In solving MATH problems, CR achieves a 4.2% increase from previous methods and a 43% relative improvement in the most challenging level 5 problems. When incorporating a code environment with CR, we further harness LLMs’ reasoning capabilities and outperform the Program of Thought (PoT) method by 38.8%. The code is available at https://github.com/iiis-ai/cumulative-reasoning.},
  archive      = {J_TMLR},
  author       = {Yifan Zhang and Jingqin Yang and Yang Yuan and Andrew C Yao},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cumulative reasoning with large language models},
  url          = {https://openreview.net/forum?id=grW15p4eq2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence properties of natural gradient descent for minimizing KL divergence. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=h6hjjAF5Bj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kullback-Leibler (KL) divergence plays a central role in probabilistic machine learning, where it commonly serves as the canonical loss function. Optimization in such settings is often performed over the probability simplex, where the choice of parameterization significantly impacts convergence. In this work, we study the problem of minimizing the KL divergence and analyze the behavior of gradient-based optimization algorithms under two dual coordinate systems within the framework of information geometry$-$ the exponential family ($\theta$ coordinates) and the mixture family ($\eta$ coordinates). We compare Euclidean gradient descent (GD) in these coordinates with the coordinate-invariant natural gradient descent (NGD), where the natural gradient is a Riemannian gradient that incorporates the intrinsic geometry of the underlying statistical model. In continuous time, we prove that the convergence rates of GD in the $\theta$ and $\eta$ coordinates provide lower and upper bounds, respectively, on the convergence rate of NGD. Moreover, under affine reparameterizations of the dual coordinates, the convergence rates of GD in $\eta$ and $\theta$ coordinates can be scaled to $2c$ and $\frac{2}{c}$, respectively, for any $c>0$, while NGD maintains a fixed convergence rate of $2$, remaining invariant to such transformations and sandwiched between them. Although this suggests that NGD may not exhibit uniformly superior convergence in continuous time, we demonstrate that its advantages become pronounced in discrete time, where it achieves faster convergence and greater robustness to noise, outperforming GD. Our analysis hinges on bounding the spectrum and condition number of the Hessian of the KL divergence at the optimum, which coincides with the Fisher information matrix.},
  archive      = {J_TMLR},
  author       = {Adwait Datar and Nihat Ay},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convergence properties of natural gradient descent for minimizing KL divergence},
  url          = {https://openreview.net/forum?id=h6hjjAF5Bj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally robust alignment for medical federated vision-language pre-training under data heterogeneity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hb3ZGvBja4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language pre-training (VLP) has emerged as an effective scheme for multimodal representation learning, but its reliance on large-scale multimodal data poses significant challenges for medical applications. Federated learning (FL) offers a promising solution to scale up the dataset for medical VLP while preserving data privacy. However, we observe that client data heterogeneity in real-world scenarios could cause models to learn biased cross-modal alignment during local pre-training. This would limit the transferability of the federally learned representation model on downstream tasks. To address this challenge, we propose Federated Distributionally Robust Alignment (FedDRA), a framework for federated VLP that achieves robust vision-language alignment under heterogeneous conditions. Based on client datasets, we construct a distribution family that encompasses potential test-time domains, and apply a distributionally robust framework to optimize the pre-trained model's performance across this distribution space. This approach bridges the gap between pre-training samples and downstream applications. To avoid over-fitting on client-specific information, we use anchor representation from the global model to guide the local training, and adopt a two-stage approach to first tune deeper layers before updating the entire network. Extensive experiments on real-world datasets demonstrate FedDRA’s effectiveness in enhancing medical federated VLP under data heterogeneity. Our method also adapts well to various medical pre-training methods.},
  archive      = {J_TMLR},
  author       = {Zitao Shuai and Chenwei Wu and Zhengxu Tang and Liyue Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributionally robust alignment for medical federated vision-language pre-training under data heterogeneity},
  url          = {https://openreview.net/forum?id=hb3ZGvBja4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified triplet-level hallucination evaluation for large vision-language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=iNywrSPpvc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, we design a unified framework to measure object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to evaluate hallucinations in (object, relation, object) triplets extracted from LVLMs’ responses, making it easily generalizable to various vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. With comprehensive evaluations on Tri-HE, we observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple training-free approach that effectively mitigates hallucinations for LVLMs.},
  archive      = {J_TMLR},
  author       = {Junjie Wu and Tsz Ting Chung and Kai Chen and Dit-Yan Yeung},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unified triplet-level hallucination evaluation for large vision-language models},
  url          = {https://openreview.net/forum?id=iNywrSPpvc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agreement-based cascading for efficient inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jn9B7LMlzk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive inference schemes reduce the cost of machine learning inference by assigning smaller models to easier examples, attempting to avoid invocation of larger models when possible. In this work we explore a simple, effective adaptive inference technique we term Agreement-Based Cascading (ABC). ABC builds a cascade of models of increasing size/complexity and uses agreement between ensembles of models at each level of the cascade as a basis for data-dependent routing. Although ensemble execution introduces additional expense, we show that these costs can be easily offset in practice due to large expected differences in model sizes, parallel inference execution capabilities, and accuracy benefits of ensembling. We examine ABC theoretically and empirically in terms of these parameters, showing that the approach can reliably act as a drop-in replacement for existing models and surpass the best single model it aims to replace in terms of both efficiency and accuracy. Additionally, we explore the performance of ABC relative to existing cascading methods in three common scenarios: (1) edge-to-cloud inference, where ABC reduces communication costs by up to 14x; (2) cloud-based model serving, where it achieves a 3x reduction in rental costs; and (3) inference via model API services, where ABC achieves a 2-25x reduction in average price per token/request relative to state-of-the-art LLM cascades.},
  archive      = {J_TMLR},
  author       = {Steven Kolawole and Don Dennis and Ameet Talwalkar and Virginia Smith},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Agreement-based cascading for efficient inference},
  url          = {https://openreview.net/forum?id=jn9B7LMlzk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial subspace generation for outlier detection in high-dimensional data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k7QsjiRE17'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection in high-dimensional tabular data is challenging since data is often distributed across multiple lower-dimensional subspaces—a phenomenon known as the Multiple Views effect (MV). This effect led to a large body of research focused on mining such subspaces, known as *subspace selection*. However, as the precise nature of the MV effect was not well understood, traditional methods had to rely on heuristic-driven search schemes that struggle to accurately capture the true structure of the data. Properly identifying these subspaces is critical for unsupervised tasks such as outlier detection or clustering, where misrepresenting the underlying data structure can hinder the performance. We introduce Myopic Subspace Theory (MST), a new theoretical framework that mathematically formulates the Multiple Views effect and writes subspace selection as a stochastic optimization problem. Based on MST, we introduce V-GAN, a generative method trained to solve such an optimization problem. This approach avoids any exhaustive search over the feature space while ensuring that the intrinsic data structure is preserved. Experiments on 42 real-world datasets show that using V-GAN subspaces to build ensemble methods leads to a significant increase in one-class classification performance—compared to existing subspace selection, feature selection, and embedding methods. Further experiments on synthetic data show that V-GAN identifies subspaces more accurately while scaling better than other relevant subspace selection methods. These results confirm the theoretical guarantees of our approach and also highlight its practical viability in high-dimensional settings.},
  archive      = {J_TMLR},
  author       = {Jose Cribeiro-Ramallo and Federico Matteucci and Paul Enciu and Alexander Jenke and Vadim Arzamasov and Thorsten Strufe and Klemens Böhm},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adversarial subspace generation for outlier detection in high-dimensional data},
  url          = {https://openreview.net/forum?id=k7QsjiRE17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SKADA-bench: Benchmarking unsupervised domain adaptation methods with realistic validation on diverse modalities. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k9F63DV3Qe'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a labeled source domain to perform well on an unlabeled target domain with some data distribution shift. While many methods have been proposed in the literature, fair and realistic evaluation remains an open question, particularly due to methodological difficulties in selecting hyperparameters in the unsupervised setting. With SKADA-bench, we propose a framework to evaluate DA methods on diverse modalities, beyond computer vision task that have been largely explored in the literature. We present a complete and fair evaluation of existing shallow algorithms, including reweighting, mapping, and subspace alignment. Realistic hyperparameter selection is performed with nested cross-validation and various unsupervised model selection scores, on both simulated datasets with controlled shifts and real-world datasets across diverse modalities, such as images, text, biomedical, and tabular data. Our benchmark highlights the importance of realistic validation and provides practical guidance for real-life applications, with key insights into the choice and impact of model selection approaches. SKADA-bench is open-source, reproducible, and can be easily extended with novel DA methods, datasets, and model selection criteria without requiring re-evaluating competitors. The code is available at https://github.com/scikit-adaptation/skada-bench.},
  archive      = {J_TMLR},
  author       = {Yanis Lalou and Theo Gnassounou and Antoine Collas and Antoine de Mathelin and Ambroise Odonnat and Thomas Moreau and Alexandre Gramfort and Rémi Flamary},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SKADA-bench: Benchmarking unsupervised domain adaptation methods with realistic validation on diverse modalities},
  url          = {https://openreview.net/forum?id=k9F63DV3Qe},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMMA: End-to-end multimodal model for autonomous driving. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kH3t5lmOU8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving. Built on a multimodal large language model foundation, EMMA directly maps raw camera sensor data into various driving-specific outputs, including planner trajectories, perception objects, and road graph elements. EMMA maximizes the utility of world knowledge from the pre-trained large language models, by representing all non-sensor inputs (e.g. navigation instructions and ego vehicle status) and outputs (e.g. trajectories and 3D locations) as natural language text. This approach allows EMMA to jointly process various driving tasks in a unified language space, and generate the outputs for each task using task-specific prompts. Empirically, we demonstrate EMMA’s effectiveness by achieving state-of-the-art performance in motion planning on nuScenes as well as competitive results on an in-house large-scale benchmark. EMMA also yields competitive results for camera-primary 3D object detection on the Waymo Open Dataset (WOD). We show that co-training EMMA with planner trajectories, object detection, and road graph tasks yields improvements across all three domains, highlighting EMMA’s potential as a generalist model for autonomous driving applications. We hope that our results will inspire research to further evolve the state of the art in autonomous driving model architectures.},
  archive      = {J_TMLR},
  author       = {Jyh-Jing Hwang and Runsheng Xu and Hubert Lin and Wei-Chih Hung and Jingwei Ji and Kristy Choi and Di Huang and Tong He and Paul Covington and Benjamin Sapp and Yin Zhou and James Guo and Dragomir Anguelov and Mingxing Tan},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {EMMA: End-to-end multimodal model for autonomous driving},
  url          = {https://openreview.net/forum?id=kH3t5lmOU8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budgeted-bandits with controlled restarts with applications in learning and computing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lvb5qDAa4B'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing the cumulative reward of a sequence of tasks under a time budget has been ubiquitous in many applications in computing and machine learning. Often, tasks can have random completion time and the controller needs to learn the unknown statistics while making optimal decisions. In addition to the classic exploration-exploitation trade-off, it has been shown that restarting strategy can boost the performance of the control algorithm by interrupting ongoing tasks at the expense of losing its reward. In this work, we consider a bandit setting where each decision takes a random completion time and yields a random (possibly correlated) reward at the end, both with unknown values at the time of decision. The goal of the decision-maker is to maximize the expected total reward subject to a stringent time budget $\tau$. As an additional control, we allow the decision-maker to interrupt an ongoing task and forgo its reward for a potentially more rewarding restart. Unlike previous works, we do not: assume any prior knowledge on the system statistics, or limit the action space of restarting strategies to be finite. Under this general framework, we developed efficient bandit algorithms to find optimal arms and restart strategies with $O(\log(\tau))$ and $O(\sqrt{\tau\log(\tau)})$ regret for both finite and continuous set of restart times, respectively. Furthermore, through numerical studies, we verified the applicability of our algorithm in the diverse contexts of: (i) algorithm portfolios for SAT solvers; (ii) task scheduling in wireless networks; and (iii) hyperparameter tuning in neural network training.},
  archive      = {J_TMLR},
  author       = {Semih Cayci and Yilin Zheng and Atilla Eryilmaz},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Budgeted-bandits with controlled restarts with applications in learning and computing},
  url          = {https://openreview.net/forum?id=lvb5qDAa4B},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term fairness inquiries and pursuits in machine learning: A survey of notions, methods, and challenges. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mYi6EWvFlR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread integration of Machine Learning systems in daily life, particularly in high-stakes domains, has raised concerns about the fairness implications. While prior works have investigated static fairness measures, recent studies reveal that automated decision-making has long-term implications and that off-the-shelf fairness approaches may not serve the purpose of achieving long-term fairness. Additionally, the existence of feedback loops and the interaction between models and the environment introduces additional complexities that may deviate from the initial fairness goals. In this survey, we review existing literature on long-term fairness from different perspectives and present a taxonomy for long-term fairness studies. We highlight key challenges and consider future research directions, analyzing both current issues and potential further explorations.},
  archive      = {J_TMLR},
  author       = {Usman Gohar and Zeyu Tang and Jialu Wang and Kun Zhang and Peter Spirtes and Yang Liu and Lu Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long-term fairness inquiries and pursuits in machine learning: A survey of notions, methods, and challenges},
  url          = {https://openreview.net/forum?id=mYi6EWvFlR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variance reduction of stochastic hypergradient estimation by mixed fixed-point iteration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mkmX2ICi5c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergradient represents how the hyperparameter of an optimization problem (or inner-problem) changes an outer-cost through the optimized inner-parameter, and it takes a crucial role in hyperparameter optimization, meta learning, and data influence estimation. This paper studies hypergradient computation involving a stochastic inner-problem, a typical machine learning setting where the empirical loss is estimated by minibatches. Stochastic hypergradient estimation requires estimating products of Jacobian matrices of the inner iteration. Current methods struggle with large estimation variance because they depend on a specific sequence of Jacobian samples to estimate this product. This paper overcomes this problem by \emph{mixing} two different stochastic hypergradient estimation methods that use distinct sequences of Jacobian samples. Furthermore, we show that the proposed method enables almost sure convergence to the true hypergradient through the stochastic Krasnosel'ski\u{\i}-Mann iteration. Theoretical analysis demonstrates that, compared to existing approaches, our method achieves lower asymptotic variance bounds while maintaining comparable computational complexity. Empirical evaluations on synthetic and real-world tasks verify our theoretical results and superior variance reduction over existing methods.},
  archive      = {J_TMLR},
  author       = {Naoyuki Terashita and Satoshi Hara},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variance reduction of stochastic hypergradient estimation by mixed fixed-point iteration},
  url          = {https://openreview.net/forum?id=mkmX2ICi5c},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging AutoML for sustainable deep learning: A multi- objective HPO approach on deep shift neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vk7b11DHcW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets. However, the computational demands of DL models pose environmental and resource challenges. Deep Shift Neural Networks (DSNNs) present a solution by leveraging shift operations to reduce computational complexity at inference. Compared to common DNNs, DSNNs are still less well understood and less well optimized. By leveraging AutoML techniques, we provide valuable insights into the potential of DSNNs and how to design them in a better way. We focus on image classification, a core task in computer vision, especially in low-resource environments. Since we consider complementary objectives such as accuracy and energy consumption, we combine state-of-the-art multi-fidelity (MF) hyperparameter optimization (HPO) with multi-objective optimization to find a set of Pareto optimal trade-offs on how to design DSNNs. Our approach led to significantly better configurations of DSNNs regarding loss and emissions compared to default DSNNs. This includes simultaneously increasing performance by about 20% and reducing emissions, in some cases by more than 60%. Investigating the behavior of quantized networks in terms of both emissions and accuracy, our experiments reveal surprising model-specific trade-offs, yielding the greatest energy savings. For example, in contrast to common expectations, quantizing smaller portions of the network with low precision can be optimal with respect to energy consumption while retaining or improving performance. We corroborated these findings across multiple backbone architectures, highlighting important nuances in quantization strategies and offering an automated approach to balancing energy efficiency and model performance.},
  archive      = {J_TMLR},
  author       = {Leona Hennig and Marius Lindauer},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging AutoML for sustainable deep learning: A multi- objective HPO approach on deep shift neural networks},
  url          = {https://openreview.net/forum?id=vk7b11DHcW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RNA-FrameFlow: Flow matching for de novo 3D RNA backbone design. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wOc1Yx5s09'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self consistency TM-score ≥ 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design},
  archive      = {J_TMLR},
  author       = {Rishabh Anand and Chaitanya K. Joshi and Alex Morehead and Arian Rokkum Jamasb and Charles Harris and Simon V Mathis and Kieran Didi and Rex Ying and Bryan Hooi and Pietro Lio},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RNA-FrameFlow: Flow matching for de novo 3D RNA backbone design},
  url          = {https://openreview.net/forum?id=wOc1Yx5s09},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable spectral embedding with an application to UMAP. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8cuQwztCKk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral Embedding (SE) is a popular method for dimensionality reduction, applicable across diverse domains. Nevertheless, its current implementations face three prominent drawbacks which curtail its broader applicability: generalizability (i.e., out-of-sample extension), scalability, and eigenvectors separation. Existing SE implementations often address two of these drawbacks; however, they fall short in addressing the remaining one. In this paper, we introduce $\textit{Sep-SpectralNet}$ (eigenvector-separated SpectralNet), a SE implementation designed to address $\textit{all}$ three limitations. Sep-SpectralNet extends SpectralNet with an efficient post-processing step to achieve eigenvectors separation, while ensuring both generalizability and scalability. This method expands the applicability of SE to a wider range of tasks and can enhance its performance in existing applications. We empirically demonstrate Sep-SpectralNet's ability to consistently approximate and generalize SE, while maintaining SpectralNet's scalability. Additionally, we show how Sep-SpectralNet can be leveraged to enable generalizable UMAP visualization.},
  archive      = {J_TMLR},
  author       = {Nir Ben-Ari and Amitai Yacobi and Uri Shaham},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalizable spectral embedding with an application to UMAP},
  url          = {https://openreview.net/forum?id=8cuQwztCKk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Importance weighting for aligning language models under deployment distribution shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=C7QWN4AXvp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning language models (LMs) with human preferences remains challenging partly because popular approaches, such as reinforcement learning from human feedback and direct preference optimization (DPO), often assume that the training data is sufficiently representative of the environment in which the model will be deployed. However, real-world applications frequently involve distribution shifts, e.g., changes in end-user behavior or preferences during usage or deployment, which pose a significant challenge to LM alignment approaches. In this paper, we propose an importance weighting method tailored for DPO, namely IW-DPO, to address distribution shifts in LM alignment. IW-DPO can be applied to joint distribution shifts in the prompts, responses, and preference labels without explicitly assuming the type of distribution shift. Our experimental results on various distribution shift scenarios demonstrate the usefulness of IW-DPO.},
  archive      = {J_TMLR},
  author       = {Thanawat Lodkaew and Tongtong Fang and Takashi Ishida and Masashi Sugiyama},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Importance weighting for aligning language models under deployment distribution shift},
  url          = {https://openreview.net/forum?id=C7QWN4AXvp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A max-min approach to the worst-case class separation problem. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EEmwBd4tfZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel discriminative feature learning method based on a minorization-maximization framework for min-max (MM4MM) to address the long-standing “worst-case class separation (WCCS)” problem, which, in our design, refers to maximizing the minimum pairwise Chernoff distance between all class pairs in the low-dimensional subspace. The proposed algorithm relies on the relaxation of a semi-orthogonality constraint, which is proven to be tight at every iteration of the algorithm. To solve the worst-case class separation problem, we first introduce the vanilla version of the proposed algorithm, which requires solving a semi-definite program (SDP) at each iteration. We further simplify it to solving a quadratic program by formulating the dual of the surrogate maximization problem. We also then present reformulations of the worst-case class separation problem that enforce sparsity of the dimension-reducing matrix. The proposed algorithms are computationally efficient and are guaranteed to converge to optimal solutions. An important feature of these algorithms is that they do not require any hyperparameter tuning (except for the sparsity case, where a penalty parameter controlling sparsity must be chosen by the user). Experiments on several machine learning datasets demonstrate the effectiveness of the MM4MM approach.},
  archive      = {J_TMLR},
  author       = {Mohammad Mahdi Omati and Prabhu babu and Petre Stoica and Arash Amini},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A max-min approach to the worst-case class separation problem},
  url          = {https://openreview.net/forum?id=EEmwBd4tfZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving quadratic programs via deep unrolled douglas-rachford splitting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xOfOgPnbtF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex quadratic programs (QPs) are fundamental to numerous applications, including finance, engineering, and energy systems. Among the various methods for solving them, the Douglas-Rachford (DR) splitting algorithm is notable for its robust convergence properties. Concurrently, the emerging field of Learning-to-Optimize offers promising avenues for enhancing algorithmic performance, with algorithm unrolling receiving considerable attention due to its computational efficiency and interpretability. In this work, we propose an approach that unrolls a modified DR splitting algorithm to efficiently learn solutions for convex QPs. Specifically, we introduce a tailored DR splitting algorithm that replaces the computationally expensive linear system-solving step with a simplified gradient-based update, while retaining convergence guarantees. Consequently, we unroll the resulting DR splitting method and present a well-crafted neural network architecture to predict QP solutions. Our method achieves up to 50% reductions in iteration counts and 40% in solve time across benchmarks on both synthetic and real-world QP datasets, demonstrating its scalability and superior performance in enhancing computational efficiency across varying sizes.},
  archive      = {J_TMLR},
  author       = {Jinxin Xiong and Xi Gao and Linxin Yang and Jiang Xue and Xiaodong Luo and Akang Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {7},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving quadratic programs via deep unrolled douglas-rachford splitting},
  url          = {https://openreview.net/forum?id=xOfOgPnbtF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Full-rank unsupervised node embeddings for directed graphs via message aggregation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3ECbEZg2If'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear message-passing models have emerged as compelling alternatives to non-linear graph neural networks for unsupervised node embedding learning, due to their scalability and competitive performance on downstream tasks. However, we identify a fundamental flaw in recently proposed linear models that combine embedding aggregation with concatenation during each message-passing iteration: rank deficiency. A rank-deficient embedding matrix contains column vectors which take arbitrary values, leading to ill-conditioning that degrades downstream task accuracy, particularly in unsupervised tasks such as graph alignment. We deduce that repeated embedding aggregation and concatenation introduces linearly dependent features, causing rank deficiency. To address this, we propose ACC (Aggregate, Compress, Concatenate), a novel model that avoids redundant feature computation by applying aggregation to the messages from the previous iteration, rather than the embeddings. Consequently, ACC generates full-rank embeddings, significantly improving graph alignment accuracy from 10% to 60% compared to rank-deficient embeddings, while also being faster to compute. Additionally, ACC employs directed message-passing and achieves node classification accuracies comparable to state-of-the-art self-supervised graph neural networks on directed graph benchmarks, while also being over 70 times faster on graphs with over 1 million edges.},
  archive      = {J_TMLR},
  author       = {Ciwan Ceylan and Kambiz Ghoorchian and Danica Kragic},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Full-rank unsupervised node embeddings for directed graphs via message aggregation},
  url          = {https://openreview.net/forum?id=3ECbEZg2If},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeurIPS 2023 competition: Privacy preserving federated learning document VQA. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3HKNwejEEq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA) competition challenged the community to develop provably private and communication-efficient solutions in a federated setting for a real-life use case: invoice processing. The competition introduced a dataset of real invoice documents, along with associated questions and answers requiring information extraction and reasoning over the document images. Thereby, it brings together researchers and expertise from the document analysis, privacy, and federated learning communities. Participants fine-tuned a pre-trained, state-of-the-art Document Visual Question Answering model provided by the organizers for this new domain, mimicking a typical federated invoice processing setup. The base model is a multi-modal generative language model, and sensitive information could be exposed through either the visual or textual input modality. Participants proposed elegant solutions to reduce communication costs while maintaining a minimum utility threshold in track 1 and to protect all information from each document provider using differential privacy in track 2. The competition served as a new testbed for developing and testing private federated learning methods, simultaneously raising awareness about privacy within the document image analysis and recognition community. Ultimately, the competition analysis provides best practices and recommendations for successfully running privacy-focused federated learning challenges in the future.},
  archive      = {J_TMLR},
  author       = {Marlon Tobaben and Mohamed Ali Souibgui and Rubèn Tito and Khanh Nguyen and Raouf Kerkouche and Kangsoo Jung and Joonas Jälkö and Lei Kang and Andrey Barsky and Vincent Poulain d'Andecy and Aurélie JOSEPH and Aashiq Muhamed and Kevin Kuo and Virginia Smith and Yusuke Yamasaki and Takumi Fukami and Kenta Niwa and Iifan Tyou and Hiro Ishii and Rio Yokota and Ragul N and Rintu Kutum and Josep Llados and Ernest Valveny and Antti Honkela and Mario Fritz and Dimosthenis Karatzas},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NeurIPS 2023 competition: Privacy preserving federated learning document VQA},
  url          = {https://openreview.net/forum?id=3HKNwejEEq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To be greedy, or not to be – That is the question for population based training variants. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3qmnxysNbi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving excellent results with neural networks requires careful hyperparameter tuning, which can be automated via hyperparameter optimization algorithms such as Population Based Training (PBT). PBT stands out for its capability to efficiently optimize hyperparameter schedules in parallel and within the wall-clock time of training a single network. Several PBT variants have been proposed that improve performance in the experimental settings considered in the associated publications. However, the experimental settings and tasks vary across publications, while the best previous PBT variant is not always included in the comparisons, thus making the relative performance of PBT variants unclear. In this work, we empirically evaluate five single-objective PBT variants on a set of image classification and reinforcement learning tasks with different setups (such as increasingly large search spaces). We find that the Bayesian Optimization (BO) variants of PBT tend to behave greedier than the non-BO ones, which is beneficial when aggressively pursuing short-term gains improves long-term performance and harmful otherwise. This is a previously overlooked caveat to the reported improvements of the BO PBT variants. Examining their theoretical properties, we find that the returns of BO PBT variants are guaranteed to asymptotically approach the returns of the greedy hyperparameter schedule (rather than the optimal one, as claimed in prior work). Together with our empirical results, this leads us to conclude that there is currently no single best PBT variant capable of outperforming others both when pursuing short-term gains is helpful in the long term, and when it is harmful.},
  archive      = {J_TMLR},
  author       = {Alexander Chebykin and Tanja Alderliesten and Peter Bosman},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {To be greedy, or not to be – That is the question for population based training variants},
  url          = {https://openreview.net/forum?id=3qmnxysNbi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel benchmark for few-shot semantic segmentation in the era of foundation models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5EXrH2h3I5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation (FSS) is a crucial challenge in computer vision, driving extensive research into a diverse range of methods, from advanced meta-learning techniques to simple transfer learning baselines. With the emergence of vision foundation models (VFM) serving as generalist feature extractors, we seek to explore the adaptation of these models for FSS. While current FSS benchmarks focus on adapting pre-trained models to new tasks with few images, they emphasize in-domain generalization, making them less suitable for VFM trained on large-scale web datasets. To address this, we propose a novel realistic benchmark with a simple and straightforward adaptation process tailored for this task. Using this benchmark, we conduct a comprehensive comparative analysis of prominent VFM and semantic segmentation models. To evaluate their effectiveness, we leverage various adaption methods, ranging from linear probing to parameter efficient fine-tuning (PEFT) and full fine-tuning. Our findings show that models designed for segmentation can be outperformed by self-supervised (SSL) models. On the other hand, while PEFT methods yields competitive performance, they provide little discrepancy in the obtained results compared to other methods, highlighting the critical role of the feature extractor in determining results. To our knowledge, this is the first study on the adaptation of VFM for FSS.},
  archive      = {J_TMLR},
  author       = {Reda Bensaid and Vincent Gripon and François Leduc-Primeau and Lukas Mauch and Ghouthi BOUKLI HACENE and Fabien Cardinaux},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A novel benchmark for few-shot semantic segmentation in the era of foundation models},
  url          = {https://openreview.net/forum?id=5EXrH2h3I5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic schwartz-fourier neural operator for enhanced expressive power. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B0E2yjrNb8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, neural operators have emerged as a prevailing approach for learning discretization-invariant mappings between function spaces. A particular example is the Fourier Neural Operator (FNO), which constrains integral kernels to be convolutions and learns the kernel directly in the frequency domain. Due to the capacity of Fourier transforms to effectively reduce the dimensionality and preserve information, FNOs demonstrate superior performance in terms of both efficiency and accuracy. In FNOs, the convolution kernel is fixed as a point-wise multiplication in the frequency domain; however, these translation-invariant kernels might limit the expressiveness of FNOs. For instance, if the underlying system lacks translational symmetries, the kernels learned by the FNO will still exhibit translational invariance, thereby limiting the model's expressive power. We propose a dynamic Schwartz operator that induces interactions between modes to enhance the expressiveness of FNOs. In this work, we introduce a novel approach that equips FNOs with Schwartz operators to learn dynamic kernels, termed Dynamic Kernel Fourier Neural Operators (DSFNOs). By incorporating this dynamic mechanism, our model gains the ability to capture relevant frequency information patterns, facilitating a better understanding and representation of complex physical phenomena. Through experiments, we demonstrate that DSFNOs can improve FNOs on a range of tasks, highlighting the effectiveness of our proposed approach. The code is available at https://github.com/wenhangao21/TMLR25_DSFNO.},
  archive      = {J_TMLR},
  author       = {Wenhan Gao and Jian Luo and Ruichen Xu and Yi Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamic schwartz-fourier neural operator for enhanced expressive power},
  url          = {https://openreview.net/forum?id=B0E2yjrNb8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictable reinforcement learning dynamics through entropy rate minimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DDUsc1lD27'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Reinforcement Learning (RL), agents have no incentive to exhibit predictable trajectories, and are often pushed (through e.g. policy entropy regularisation) to randomise their actions in favor of exploration. This lack of predictability awareness often makes it challenging for other agents and humans to predict an agent's trajectories, possibly triggering unsafe scenarios (e.g. in human-robot interaction). We propose a novel method to induce predictable trajectories in RL agents, termed Predictability-Aware RL (PARL), employing the agent's trajectory entropy rate to quantify predictability. Our method maximizes a linear combination of a standard discounted reward and the negative entropy rate, thus trading off optimality with predictability. We show how the entropy rate can be formally cast as an average reward, how entropy-rate value functions can be estimated from a learned model and incorporate this in policy-gradient algorithms, and demonstrate how this approach produces predictable (near-optimal) policies in tasks inspired by human-robot use-cases.},
  archive      = {J_TMLR},
  author       = {Daniel Jarne Ornia and Giannis Delimpaltadakis and Jens Kober and Javier Alonso-Mora},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predictable reinforcement learning dynamics through entropy rate minimization},
  url          = {https://openreview.net/forum?id=DDUsc1lD27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning using a single forward pass. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EDQ8QOGqjr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a learning algorithm to overcome the limitations of traditional backpropagation in resource-constrained environments: Solo Pass Embedded Learning Algorithm (SPELA). SPELA operates with local loss functions to update weights, significantly saving on resources allocated to the propagation of gradients and storing computational graphs while being sufficiently accurate. Consequently, SPELA can closely match backpropagation using less memory. Moreover, SPELA can effectively fine-tune pre-trained image recognition models for new tasks. Further, SPELA is extended with significant modifications to train CNN networks, which we evaluate on CIFAR-10, CIFAR-100, and SVHN 10 datasets, showing equivalent performance compared to backpropagation. Our results indicate that SPELA, with its features such as local learning and early exit, is a potential candidate for learning in resource-constrained edge AI applications.},
  archive      = {J_TMLR},
  author       = {Aditya Somasundaram and Pushkal Mishra and Ayon Borthakur},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning using a single forward pass},
  url          = {https://openreview.net/forum?id=EDQ8QOGqjr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Change point detection in the frequency domain with statistical reliability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FNRdaHz3qN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective condition monitoring in complex systems requires identifying change points (CPs) in the frequency domain, as the structural changes often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems.},
  archive      = {J_TMLR},
  author       = {Akifumi Yamada and Tomohiro Shiraishi and Shuichi Nishino and Teruyuki Katsuoka and Kouichi Taji and Ichiro Takeuchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Change point detection in the frequency domain with statistical reliability},
  url          = {https://openreview.net/forum?id=FNRdaHz3qN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and accurate optimal transport with mirror descent and conjugate gradients. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FVFqrxeF8e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Mirror Descent Optimal Transport (MDOT), a novel method for solving discrete optimal transport (OT) problems with high precision, by unifying temperature annealing in entropic-regularized OT (EOT) with mirror descent techniques. In this framework, temperature annealing produces a sequence of EOT dual problems, whose solution gradually gets closer to the solution of the original OT problem. We solve each problem efficiently using a GPU-parallel nonlinear conjugate gradients algorithm (PNCG) that outperforms traditional Sinkhorn iterations under weak regularization. Moreover, our investigation also reveals that the theoretical convergence rate of Sinkhorn iterations can exceed existing non-asymptotic bounds when its stopping criterion is tuned in a manner analogous to MDOT. Our comprehensive ablation studies of MDOT-PNCG affirm its robustness across a wide range of algorithmic parameters. Benchmarking on 24 problem sets of size $n=4096$ in a GPU environment demonstrate that our method attains high-precision, feasible solutions significantly faster than a representative set of existing OT solvers—including accelerated gradient methods and advanced Sinkhorn variants—in both wall-clock time and number of operations. Empirical convergence rates range between $O(n^2 \varepsilon^{-1/4})$ and $O(n^2 \varepsilon^{-1})$, where $\varepsilon$ is the optimality gap. For problem sizes up to $n=16\,384$, the empirical runtime scales as $\widetilde{O}(n^2)$ for moderate precision and as $\widetilde{O}(n^{5/2})$ at worst for high precision. These findings establish MDOT-PNCG as a compelling alternative to current OT solvers, particularly in challenging weak-regularization regimes.},
  archive      = {J_TMLR},
  author       = {Mete Kemertas and Allan Douglas Jepson and Amir-massoud Farahmand},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient and accurate optimal transport with mirror descent and conjugate gradients},
  url          = {https://openreview.net/forum?id=FVFqrxeF8e},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparser, better, faster, stronger: Sparsity detection for efficient automatic differentiation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GtXSN52nIW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From implicit differentiation to probabilistic modeling, Jacobian and Hessian matrices have many potential use cases in Machine Learning (ML), but they are viewed as computationally prohibitive. Fortunately, these matrices often exhibit sparsity, which can be leveraged to speed up the process of Automatic Differentiation (AD). This paper presents advances in sparsity detection, previously the performance bottleneck of Automatic Sparse Differentiation (ASD). Our implementation of sparsity detection is based on operator overloading, able to detect both local and global sparsity patterns, and supports flexible index set representations. It is fully automatic and requires no modification of user code, making it compatible with existing ML codebases. Most importantly, it is highly performant, unlocking Jacobians and Hessians at scales where they were considered too expensive to compute. On real-world problems from scientific ML, graph neural networks and optimization, we show significant speed-ups of up to three orders of magnitude. Notably, using our sparsity detection system, ASD outperforms standard AD for one-off computations, without amortization of either sparsity detection or matrix coloring.},
  archive      = {J_TMLR},
  author       = {Adrian Hill and Guillaume Dalle},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparser, better, faster, stronger: Sparsity detection for efficient automatic differentiation},
  url          = {https://openreview.net/forum?id=GtXSN52nIW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recall and refine: A simple but effective source-free open- set domain adaptation framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HBZoXjUAqV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source domain to an unlabeled target domain, where novel classes — also referred to as target-private unknown classes — are present. Source-free Open-set Domain Adaptation (SF-OSDA) methods address OSDA without accessing labeled source data, making them particularly relevant under privacy constraints. However, SF-OSDA presents significant challenges due to distribution shifts and the introduction of novel classes. Existing SF-OSDA methods typically rely on thresholding the prediction entropy of a sample to identify it as either a known or unknown class, but fail to explicitly learn discriminative features for the target-private unknown classes. We propose Recall and Refine (RRDA), a novel SF-OSDA framework designed to address these limitations by explicitly learning features for target-private unknown classes. RRDA employs a two-stage process. First, we enhance the model’s capacity to recognize unknown classes by training a target classifier with an additional decision boundary, guided by synthetic samples generated from target domain features. This enables the classifier to effectively separate known and unknown classes. Second, we adapt the entire model to the target domain, addressing both domain shifts and distinguishability to unknown classes. Any off-the-shelf source-free domain adaptation method (e.g.\ SHOT, AaD) can be seamlessly integrated into our framework at this stage. Extensive experiments on three benchmark datasets demonstrate that RRDA significantly outperforms existing SF-OSDA and OSDA methods.},
  archive      = {J_TMLR},
  author       = {Ismail Nejjar and Hao Dong and Olga Fink},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Recall and refine: A simple but effective source-free open- set domain adaptation framework},
  url          = {https://openreview.net/forum?id=HBZoXjUAqV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CodeLutra: Boosting LLM code generation via preference-guided refinement. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IGsEgWM4to'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have revolutionized code generation but are require significant resources and tend to over-generalize, limiting their task-specific efficiency. Fine-tuning smaller, open-source LLMs is a cost-effective alternative, yet standard supervised approaches rely solely on correct examples, overlooking valuable insights from failures. We introduce CodeLutra, a new framework that leverages both correct and incorrect code attempts. Instead of purely instructing with correct solutions, CodeLutra uses iterative preference-based refinement, comparing successful and failed outputs to better approximate desired results. This process narrows the performance gap with state-of-the-art, larger models, without requiring massive datasets or auxiliary models. For example, on a challenging data science coding task, using only 500 samples improved Llama-3-8B’s accuracy from 28.2% to 48.6%, approaching GPT-4’s level. By capitalizing on both successes and mistakes, \textsc{CodeLutra} offers a scalable, efficient path to high-quality code generation, making smaller open-source models more competitive with leading closed-source alternatives.},
  archive      = {J_TMLR},
  author       = {Leitian Tao and Xiang Chen and Tong Yu and Tung Mai and Ryan A. Rossi and Yixuan Li and Saayan Mitra},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CodeLutra: Boosting LLM code generation via preference-guided refinement},
  url          = {https://openreview.net/forum?id=IGsEgWM4to},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harmony: A joint self-supervised and weakly-supervised framework for learning general purpose visual representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IcOBCufqFO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language contrastive learning frameworks such as CLIP enable learning representations from natural language supervision and provide strong zero-shot classification capabilities. However, due to the nature of the supervisory signal in these paradigms, they lack the ability to learn localized features, leading to degraded performance on dense prediction tasks such as segmentation and detection. On the other hand, self-supervised learning methods have shown the ability to learn granular representations, complementing the high-level features in vision-language training. In this work, we present Harmony, a framework that combines vision-language training with discriminative and generative self-supervision to learn visual features that can be generalized across different downstream vision tasks. Our framework is specifically designed to work on web-scraped data by not relying on negative examples in the self-supervised learning path and addressing the one-to-one correspondence issue using soft CLIP targets generated by an EMA model. Moreover, Harmony optimizes for five different objectives simultaneously, efficiently utilizing the supervision in each data example, making it even more suited in data-constrained settings. We comprehensively evaluate Harmony across various vision downstream tasks and find that it significantly outperforms the baseline CLIP and outperforms the previously leading joint self- and weakly supervised methods, SLIP, MaskCLIP, and DetailCLIP. Specifically, when compared against these methods, Harmony shows superior performance in linear-probing, fine-tuning, and zero-shot classification on ImageNet-1k, semantic segmentation on ADE20K, and both object detection and instance segmentation on MS-COCO, when pre-training a ViT-B on CC3M. We also show that Harmony outperforms SILC on detection, linear and fine-tuning classification, and outperforms other self-supervised learning methods like iBOT and MAE across all tasks evaluated. Our code is publicly available at https://github.com/MohammedSB/Harmony.},
  archive      = {J_TMLR},
  author       = {Mohammed Baharoon and Jonathan Klein and Dominik Michels},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Harmony: A joint self-supervised and weakly-supervised framework for learning general purpose visual representations},
  url          = {https://openreview.net/forum?id=IcOBCufqFO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for finding local saddle points in two-player zero-sum black-box games. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NbRybPuWCv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saddle point optimization is a critical problem employed in numerous real-world applications, including portfolio optimization, generative adversarial networks, and robotics. It has been extensively studied in cases where the objective function is known and differentiable. Existing work in black-box settings with unknown objectives that can only be sampled either assumes convexity-concavity in the objective to simplify the problem or operates with noisy gradient estimators. In contrast, we introduce a framework inspired by Bayesian optimization which utilizes Gaussian processes to model the unknown (potentially nonconvex-nonconcave) objective and requires only zeroth-order samples. Our approach frames the saddle point optimization problem as a two-level process which can flexibly leverage existing general-sum Nash game solvers to solve for saddle points of zero-sum games. The upper level of our framework produces a model of the objective function by sampling in promising locations, and the lower level of our framework uses the existing model to frame and solve a general-sum game to identify locations to sample. This lower level procedure can be designed in complementary ways, and we demonstrate the flexibility of our approach by introducing variants which appropriately trade off between factors like runtime, the cost of function evaluations, and the number of available initial samples. We experimentally demonstrate these algorithms on synthetic and realistic datasets in black-box nonconvex-nonconcave settings, showcasing their ability to efficiently locate local saddle points in these contexts.},
  archive      = {J_TMLR},
  author       = {Shubhankar Agarwal and Hamzah I Khan and Sandeep P. Chinchali and David Fridovich-Keil},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A framework for finding local saddle points in two-player zero-sum black-box games},
  url          = {https://openreview.net/forum?id=NbRybPuWCv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leopard: A vision language model for text-rich multi- image tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=R2rasAEPVi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-rich images, where text serves as the central visual element guiding the overall understanding, are prevalent in real-world applications, such as presentation slides, scanned documents, and webpage snapshots. Tasks involving multiple text-rich images are especially challenging, as they require not only understanding the content of individual images but reasoning about inter-relationships and logical flows across multiple visual inputs. Despite the importance of these scenarios, current multimodal large language models (MLLMs) struggle to handle such tasks due to two key challenges: (1) the scarcity of high-quality instruction tuning datasets for text-rich multi-image scenarios, and (2) the difficulty in balancing image resolution with visual feature sequence length. To address these challenges, we propose Leopard, a MLLM designed specifically for handling vision-language tasks involving multiple text-rich images. First, we curated about one million high-quality multimodal instruction-tuning data, tailored to text-rich, multi-image scenarios. Second, we proposed an adaptive high-resolution multi-image encoding module to dynamically optimize the allocation of visual sequence length based on the original aspect ratios and resolutions of images. Experiments on a diverse set of benchmarks reveal that our model consistently outperforms state-of-the-art systems, such as Llama-3.2 and Qwen2-VL, in challenging text-rich, multi-image evaluations. Remarkably, our approach achieves outstanding performance using only 1.2M fully open-sourced training instances, outperforming models that rely on large-scale in-house data, highlighting its efficiency and effectiveness. Our code and data are available at https://anonymous.4open.science/r/Leopard-908F.},
  archive      = {J_TMLR},
  author       = {Mengzhao Jia and Wenhao Yu and Kaixin Ma and Tianqing Fang and Zhihan Zhang and Siru Ouyang and Hongming Zhang and Dong Yu and Meng Jiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leopard: A vision language model for text-rich multi- image tasks},
  url          = {https://openreview.net/forum?id=R2rasAEPVi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Link prediction with relational hypergraphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=S6fe4aH6YA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction with knowledge graphs has been thoroughly studied in graph machine learning, leading to a rich landscape of graph neural network architectures with successful applications. Nonetheless, it remains challenging to transfer the success of these architectures to inductive link prediction with relational hypergraphs, where the task is over $k$-ary relations, substantially harder than link prediction on knowledge graphs with binary relations only. In this paper, we propose a framework for link prediction with relational hypergraphs, empowering applications of graph neural networks on fully relational structures. Theoretically, we conduct a thorough analysis of the expressive power of the resulting model architectures via corresponding relational Weisfeiler-Leman algorithms and also via logical expressiveness. Empirically, we validate the power of the proposed model architectures on various relational hypergraph benchmarks. The resulting model architectures substantially outperform every baseline for inductive link prediction and also lead to competitive results for transductive link prediction.},
  archive      = {J_TMLR},
  author       = {Xingyue Huang and Miguel Romero Orth and Pablo Barcelo and Michael M. Bronstein and Ismail Ilkan Ceylan},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Link prediction with relational hypergraphs},
  url          = {https://openreview.net/forum?id=S6fe4aH6YA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeoBERT: A next generation BERT. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TJRyDi7mwH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent innovations in architecture, pre-training, and fine-tuning have led to the remarkable in-context learning and reasoning abilities of large auto-regressive language models such as LLaMA and DeepSeek. In contrast, encoders like BERT and RoBERTa have not seen the same level of progress despite being foundational for many downstream NLP applications. To bridge this gap, we introduce NeoBERT, a next-generation encoder that redefines the capabilities of bidirectional models by integrating state-of-the-art advancements in architecture, modern data, and optimized pre-training methodologies. NeoBERT is designed for seamless adoption: it serves as a plug-and-play replacement for existing base models, relies on an optimal depth-to-width ratio, and leverages an extended context length of 4,096 tokens. Despite its compact 250M parameter footprint, it achieves state-of-the-art results on the massive MTEB benchmark, outperforming BERT$_{large}$, RoBERTa$_{large}$, NomicBERT, and ModernBERT under identical fine-tuning conditions. In addition, we rigorously evaluate the impact of each modification on GLUE and design a uniform fine-tuning and evaluation framework for MTEB. We release all code, data, checkpoints, and training scripts to accelerate research and real-world adoption.},
  archive      = {J_TMLR},
  author       = {Lola Le Breton and Quentin Fournier and Mariam El Mezouar and Sarath Chandar},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NeoBERT: A next generation BERT},
  url          = {https://openreview.net/forum?id=TJRyDi7mwH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical characterization of better-than-random multiclass models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VdW9SkALSd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A binary supervised model outperforms chance if and only if the determinant of the confusion matrix is positive. This is equivalent to saying that the associated point in the ROC space is above the random guessing line. This also means that Youden's J, Cohen's $\kappa$ and Matthews' correlation coefficient are positive. We extend these results to any number of classes: for a target variable with $m \geq 2$ classes, we show that a model does better than chance if and only if the entries of the confusion matrix verify $m(m-1)$ homogeneous polynomial inequalities of degree 2, which can be expressed using generalized likelihood ratios. We also obtain a more theoretical formulation: a model does better than chance if and only if it is a maximum likelihood estimator of the target variable. When this is the case, we find that the multiclass versions of the previous metrics remain positive. If $m>2$, we notice that no-skill classifiers are only a small part of the topological boundary between better-than-random models and bad models. For $m=3$, we show that bad models occupy exactly 90\% of the ROC space, far more than the 50\% of the two-class problems. Finally, we propose to define weak multiclass classifiers by conditions on these generalized likelihood ratios.},
  archive      = {J_TMLR},
  author       = {Sébastien Foulle},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mathematical characterization of better-than-random multiclass models},
  url          = {https://openreview.net/forum?id=VdW9SkALSd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble kalman diffusion guidance: A derivative-free method for inverse problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XPEEsKneKs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving inverse problems, one increasingly popular approach is to use pre-trained diffusion models as plug-and-play priors. This framework can accommodate different forward models without re-training while preserving the generative capability of diffusion models. Despite their success in many imaging inverse problems, most existing methods rely on privileged information such as derivative, pseudo-inverse, or full knowledge about the forward model. This reliance poses a substantial limitation that restricts their use in a wide range of problems where such information is unavailable, such as in many scientific applications. We propose Ensemble Kalman Diffusion Guidance (EnKG), a derivative-free approach that can solve inverse problems by only accessing forward model evaluations and a pre-trained diffusion model prior. We study the empirical effectiveness of EnKG across various inverse problems, including scientific settings such as inferring fluid flows and astronomical objects, which are highly non-linear inverse problems that often only permit black-box access to the forward model. We open-source our code at https://github.com/devzhk/enkg-pytorch.},
  archive      = {J_TMLR},
  author       = {Hongkai Zheng and Wenda Chu and Austin Wang and Nikola Borislavov Kovachki and Ricardo Baptista and Yisong Yue},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ensemble kalman diffusion guidance: A derivative-free method for inverse problems},
  url          = {https://openreview.net/forum?id=XPEEsKneKs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Labeling without seeing? blind annotation for privacy-preserving entity resolution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bAM8y3Hm0p'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world. To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed. However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records. To the best of our knowledge, there is no prior work on privacy-preserving ground truth labeling in the context of entity resolution. We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truth without sharing data in plaintext with other parties. In addition, we design a domain-specific, user-friendly language that conceals the complex underlying homomorphic encryption circuits, making it more accessible and easier for users to adopt this technique. The empirical experiments indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\% compared with the real ground truth).},
  archive      = {J_TMLR},
  author       = {Yixiang Yao and Weizhao Jin and Srivatsan Ravi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Labeling without seeing? blind annotation for privacy-preserving entity resolution},
  url          = {https://openreview.net/forum?id=bAM8y3Hm0p},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disappearance of timestep embedding: A case study on neural ODE and diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bpaLYaf6Dp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamical systems are often time-varying, whose modeling requires a function that evolves with respect to time. Recent studies such as the neural ordinary differential equation proposed a time-dependent neural network, which provides a neural network varying with respect to time. However, we claim that the architectural choice to build a time-dependent neural network significantly affects its time-awareness but still lacks sufficient validation in its current states. In this study, we conduct an in-depth analysis of the architecture of neural ordinary differential equations. Here, we report a vulnerability of vanishing timestep embedding, which disables the time-awareness of a time-dependent neural network. Specifically, we find that the ConcatConv operation, which is widely used in neural ordinary differential equations, causes an additive effect of timestep embedding, which is readily canceled out by the subsequent batch normalization. This vanishing timestep embedding also arises for group normalization and is analyzed thoroughly with respect to the number of channels, groups, and relative variance. Furthermore, we find that this vulnerability can also be observed in diffusion models because they employ a similar architecture that incorporates timestep embedding to discriminate between different timesteps during a diffusion process. Our analysis provides a detailed description of this phenomenon as well as several solutions to address the root cause. Through experiments on neural ordinary differential equations and diffusion models, we observed that ensuring alive time-awareness via proposed solutions boosted their performance, such as classification accuracy, FID, and inception score, which implies that their current implementations lack sufficient time-dependency.},
  archive      = {J_TMLR},
  author       = {Bum Jun Kim and Yoshinobu Kawahara and Sang Woo Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Disappearance of timestep embedding: A case study on neural ODE and diffusion models},
  url          = {https://openreview.net/forum?id=bpaLYaf6Dp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow map matching with stochastic interpolants: A mathematical framework for consistency models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cqDH0e6ak2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models based on dynamical equations such as flows and diffusions offer exceptional sample quality, but require computationally expensive numerical integration during inference. The advent of consistency models has enabled efficient one-step or few-step generation, yet despite their practical success, a systematic understanding of their design has been hindered by the lack of a comprehensive theoretical framework. Here we introduce Flow Map Matching (FMM), a principled framework for learning the two-time flow map of an underlying dynamical generative model, thereby providing this missing mathematical foundation. Leveraging stochastic interpolants, we propose training objectives both for distillation from a pre-trained velocity field and for direct training of a flow map over an interpolant or a forward diffusion process. Theoretically, we show that FMM unifies and extends a broad class of existing approaches for fast sampling, including consistency models, consistency trajectory models, and progressive distillation. Experiments on CIFAR-10 and ImageNet-32 highlight that our approach can achieve sample quality comparable to flow matching while reducing generation time by a factor of 10-20.},
  archive      = {J_TMLR},
  author       = {Nicholas Matthew Boffi and Michael Samuel Albergo and Eric Vanden-Eijnden},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Flow map matching with stochastic interpolants: A mathematical framework for consistency models},
  url          = {https://openreview.net/forum?id=cqDH0e6ak2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective bayesian optimization for likelihood-free inference in sequential sampling models of decision making. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hQjwDqfSzj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical models are often defined by a generative process for simulating synthetic data, but this can lead to intractable likelihoods. Likelihood free inference (LFI) methods enable Bayesian inference to be performed in this case. Extending a popular approach to simulation-efficient LFI for single-source data, we propose Multi-objective Bayesian Optimization for Likelihood Free Inference (MOBOLFI) to perform LFI using multi-source data. MOBOLFI models a multi-dimensional discrepancy between observed and simulated data, using a separate discrepancy for each data source. The use of a multivariate discrepancy allows for approximations to individual data source likelihoods in addition to the joint likelihood, enabling detection of conflicting information and deeper understanding of the importance of different data sources in estimating individual parameters. The adaptive choice of simulation parameters using multi-objective Bayesian optimization ensures simulation efficient approximation of likelihood components for all data sources. We illustrate our approach in sequential sampling models (SSMs), which are widely used in psychology and consumer-behavior modeling. SSMs are often fitted using multi-source data, such as choice and response time. The advantages of our approach are illustrated in comparison with a single discrepancy for an SSM fitted to data assessing preferences of ride-hailing drivers in Singapore to rent electric vehicles.},
  archive      = {J_TMLR},
  author       = {David Chen and Xinwei Li and Eui-Jin Kim and Prateek Bansal and David J Nott},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-objective bayesian optimization for likelihood-free inference in sequential sampling models of decision making},
  url          = {https://openreview.net/forum?id=hQjwDqfSzj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multi-output gaussian processes with stochastic variational inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kK0WrBZAli'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Output Gaussian Process (MOGP) is a popular tool for modelling data from multiple sources. A typical choice to build a covariance function for a MOGP is the Linear Model of Coregionalisation (LMC) which parametrically models the covariance between outputs. The Latent Variable MOGP (LV-MOGP) generalises this idea by modelling the covariance between outputs using a kernel applied to latent variables, one per output, leading to a flexible MOGP model that allows efficient generalisation to new outputs with few data points. The computational complexity in LV-MOGP grows linearly with the number of outputs, which makes it unsuitable for problems with a large number of outputs. In this paper, we propose a stochastic variational inference approach for the LV-MOGP that allows mini-batches for both inputs and outputs, making computational complexity per training iteration independent of the number of outputs. We demonstrate the performance of the model by benchmarking against some other MOGP models in several real-world datasets, including spatial-temporal climate modelling and spatial transcriptomics.},
  archive      = {J_TMLR},
  author       = {Xiaoyu Jiang and Sokratia Georgaka and Magnus Rattray and Mauricio A Álvarez},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scalable multi-output gaussian processes with stochastic variational inference},
  url          = {https://openreview.net/forum?id=kK0WrBZAli},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient hardware scaling and diminishing returns in large-scale training of language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=p7jQEf3wlh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To train the exceedingly large neural networks required in modern applications, such as large language models (LLMs), model training is distributed across tens of thousands of hardware accelerators (e.g. GPUs), requiring orchestration of computation and communication across large computing clusters. In this work, we demonstrate that careful consideration of hardware configuration and parallelization strategy is critical for effective (i.e. compute- and cost-efficient) scaling of model training. We conduct an extensive empirical study of the performance of large-scale LLM training workloads across model size, hardware configurations, and distributed parallelization strategies with current best practices. In experiments with model sizes up to 70B parameters and utilizing up to 2048 H100 GPUs, we demonstrate that: (1) Naive scale out with Fully Sharded Data Parallelism (FSDP) incurs communication overhead which leads parallelization strategies previously thought to be sub-optimal in fact become preferable; and (2) scaling the total number of accelerators for training quickly yields diminishing returns even when hardware and parallelization strategies are properly optimized, implying poor marginal performance per additional unit of power or GPU-hour.},
  archive      = {J_TMLR},
  author       = {Jared Fernandez and Luca Wehrstedt and Leonid Shamis and Mostafa Elhoushi and Kalyan Saladi and Yonatan Bisk and Emma Strubell and Jacob Kahn},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient hardware scaling and diminishing returns in large-scale training of language models},
  url          = {https://openreview.net/forum?id=p7jQEf3wlh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit personalization and local training: Double communication acceleration in federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qVUEuhlaEa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is an evolving machine learning paradigm, in which multiple clients perform computations based on their individual private data, interspersed by communication with a remote server. A common strategy to curtail communication costs is Local Training, which consists in performing multiple local stochastic gradient descent steps between successive communication rounds. However, the conventional approach to local training overlooks the practical necessity for client-specific personalization, a technique to tailor local models to individual needs. We introduce Scafflix, a novel algorithm that efficiently integrates explicit personalization with local training. This innovative approach benefits from these two techniques, thereby achieving doubly accelerated communication, as we demonstrate both in theory and practice.},
  archive      = {J_TMLR},
  author       = {Kai Yi and Laurent Condat and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explicit personalization and local training: Double communication acceleration in federated learning},
  url          = {https://openreview.net/forum?id=qVUEuhlaEa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lie symmetry net: Preserving conservation laws in modelling financial market dynamics via differential equations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=rkfop9GyxB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs a novel Lie symmetries-based framework to model the intrinsic symmetries within financial market. Specifically, we introduce Lie symmetry net (LSN), which characterises the Lie symmetries of the differential equations (DE) estimating financial market dynamics, such as the Black-Scholes equation. To simulate these differential equations in a symmetry-aware manner, LSN incorporates a Lie symmetry risk derived from the conservation laws associated with the Lie symmetry operators of the target differential equations. This risk measures how well the Lie symmetries are realised and guides the training of LSN under the structural risk minimisation framework. Extensive numerical experiments demonstrate that LSN effectively realises the Lie symmetries and achieves an error reduction of more than one order of magnitude compared to state-of-the-art methods. The code is available at https://github.com/Jxl163/LSN_code.},
  archive      = {J_TMLR},
  author       = {Xuelian Jiang and Tongtian Zhu and Yingxiang Xu and Can Wang and Yeyu Zhang and Fengxiang He},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lie symmetry net: Preserving conservation laws in modelling financial market dynamics via differential equations},
  url          = {https://openreview.net/forum?id=rkfop9GyxB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalization of large language models: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tf6A9EYMo6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners.},
  archive      = {J_TMLR},
  author       = {Zhehao Zhang and Ryan A. Rossi and Branislav Kveton and Yijia Shao and Diyi Yang and Hamed Zamani and Franck Dernoncourt and Joe Barrow and Tong Yu and Sungchul Kim and Ruiyi Zhang and Jiuxiang Gu and Tyler Derr and Hongjie Chen and Junda Wu and Xiang Chen and Zichao Wang and Subrata Mitra and Nedim Lipka and Nesreen K. Ahmed and Yu Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalization of large language models: A survey},
  url          = {https://openreview.net/forum?id=tf6A9EYMo6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prior learning in introspective VAEs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=u4YDVFodYX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational Autoencoders (VAEs) are a popular framework for unsupervised learning and data generation. A plethora of methods have been proposed focusing on improving VAEs, with the incorporation of adversarial objectives and the integration of prior learning mechanisms being prominent directions. When it comes to the former, an indicative instance is the recently introduced family of Introspective VAEs aiming at ensuring that a low likelihood is assigned to unrealistic samples. In this study, we focus on the Soft-IntroVAE (S-IntroVAE), one of only two members of the Introspective VAE family, the other being the original IntroVAE. We select S-IntroVAE for its state-of-the-art status and its training stability. In particular, we investigate the implication of incorporating a multimodal and trainable prior into this S-IntroVAE. Namely, we formulate the prior as a third player and show that when trained in cooperation with the decoder constitutes an effective way for prior learning, which shares the Nash Equilibrium with the vanilla S-IntroVAE. Furthermore, based on a modified formulation of the optimal ELBO in S-IntroVAE, we develop theoretically motivated regularizations, namely (i) adaptive variance clipping to stabilize training when learning the prior and (ii) responsibility regularization to discourage the formation of inactive prior modes. Finally, we perform a series of targeted experiments on a 2D density estimation benchmark and in an image generation setting comprised of the (F)-MNIST and CIFAR-10 datasets demonstrating the effect of prior learning in S-IntroVAE in generation and representation learning.},
  archive      = {J_TMLR},
  author       = {Ioannis Athanasiadis and Fredrik Lindsten and Michael Felsberg},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Prior learning in introspective VAEs},
  url          = {https://openreview.net/forum?id=u4YDVFodYX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reproducibility study of ’SLICE: Stabilized LIME for consistent explanations for image classification’. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vKUPXuEzj8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reproducibility study of SLICE: Stabilized LIME for Consistent Explanations for Image Classification by Bora et al. (2024). SLICE enhances LIME by incorporating Sign Entropy-based Feature Elimination (SEFE) to remove unstable superpixels and an adaptive perturbation strategy using Gaussian blur to improve consistency in feature importance rankings. The original work claims that SLICE significantly improves explanation stability and fidelity. Our study systematically verifies these claims through extensive experimentation using the Oxford-IIIT Pets, PASCAL VOC, and MS COCO datasets. Our results confirm that SLICE achieves higher consistency than LIME, supporting its ability to reduce instability. However, our fidelity analysis challenges the claim of superior performance, as LIME often achieves higher Ground Truth Overlap (GTO) scores, indicating stronger alignment with object segmentations. To further investigate fidelity, we introduce an alternative AOPC evaluation to ensure a fair comparison across methods. Additionally, we propose GRID-LIME, a structured grid-based alternative to LIME, which improves stability while maintaining computational efficiency. Our findings highlight trade-offs in post-hoc explainability methods and emphasize the need for fairer fidelity evaluations. Our implementation is publicly available at our GitHub repository.},
  archive      = {J_TMLR},
  author       = {Aritra Bandyopadhyay and Chiranjeev Bindra and Roan van Blanken and Arijit Ghosh},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reproducibility study of ’SLICE: Stabilized LIME for consistent explanations for image classification’},
  url          = {https://openreview.net/forum?id=vKUPXuEzj8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-view panorama synthesis using geospatially guided diffusion. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ylUVRikhTL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the task of mixed-view panorama synthesis, where the goal is to synthesize a novel panorama given a small set of input panoramas and a satellite image of the area. This contrasts with previous work which only uses input panoramas (same-view synthesis), or an input satellite image (cross-view synthesis). We argue that the mixed-view setting is the most natural to support panorama synthesis for arbitrary locations worldwide. A critical challenge is that the spatial coverage of panoramas is uneven, with few panoramas available in many regions of the world. We introduce an approach that utilizes diffusion-based modeling and an attention-based architecture for extracting information from all available input imagery. Experimental results demonstrate the effectiveness of our proposed method. In particular, our model can handle scenarios when the available panoramas are sparse or far from the location of the panorama we are attempting to synthesize.},
  archive      = {J_TMLR},
  author       = {Zhexiao Xiong and Xin Xing and Scott Workman and Subash Khanal and Nathan Jacobs},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixed-view panorama synthesis using geospatially guided diffusion},
  url          = {https://openreview.net/forum?id=ylUVRikhTL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MemBench: Memorized image trigger prompt dataset for diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=z3RIiidJgD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have achieved remarkable success in Text-to-Image generation tasks, leading to the development of many commercial models. However, recent studies have reported that diffusion models often repeatedly generate memorized images in train data when triggered by specific prompts, potentially raising social issues ranging from copyright to privacy concerns. To sidestep the memorization, recent studies have been conducted to develop memorization mitigation methods for diffusion models. Nevertheless, the lack of benchmarks hinders the assessment of the true effectiveness of these methods. In this work, we present MemBench, the first benchmark for evaluating image memorization mitigation methods. Our benchmark includes a large number of memorized image trigger prompts in various Text-to-Image diffusion models. Furthermore, in contrast to the prior work evaluating mitigation performance only on trigger prompts, we present metrics evaluating on both trigger prompts and general prompts, so that we can see whether mitigation methods address the memorization issue while maintaining performance for general prompts. Through our MemBench evaluation, we revealed that existing memorization mitigation methods notably degrade the overall performance of diffusion models and need to be further developed.},
  archive      = {J_TMLR},
  author       = {Chunsan Hong and Tae-Hyun Oh and Minhyuk Sung},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MemBench: Memorized image trigger prompt dataset for diffusion models},
  url          = {https://openreview.net/forum?id=z3RIiidJgD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normality-guided distributional reinforcement learning for continuous control. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=z27hb0rmLT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a predictive model of the mean return, or value function, plays a critical role in many reinforcement learning algorithms. Distributional reinforcement learning (DRL) has been shown to improve performance by modeling the value distribution, not just the mean. We study the value distribution in several continuous control tasks and find that the learned value distribution is empirically quite close to normal. We design a method that exploits this property, employing variances predicted from a variance network, along with returns, to analytically compute target quantile bars representing a normal for our distributional value function. In addition, we propose a policy update strategy based on the correctness as measured by structural characteristics of the value distribution not present in the standard value function. The approach we outline is compatible with many DRL structures. We use two representative on-policy algorithms, PPO and TRPO, as testbeds. Our method yields statistically significant improvements in 10 out of 16 continuous task settings, while utilizing a reduced number of weights and achieving faster training time compared to an ensemble-based method for quantifying value distribution uncertainty.},
  archive      = {J_TMLR},
  author       = {Ju-Seung Byun and Andrew Perrault},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Normality-guided distributional reinforcement learning for continuous control},
  url          = {https://openreview.net/forum?id=z27hb0rmLT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GradSkip: Communication-accelerated local gradient methods with better computational complexity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6R3fRqFfhn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of distributed optimization algorithms that aim to alleviate high communication costs by allowing clients to perform multiple local gradient-type training steps before communication. In a recent breakthrough, Mishchenko et al. (2022) proved that local training, when properly executed, leads to provable communication acceleration, and this holds in the strongly convex regime without relying on any data similarity assumptions. However, their ProxSkip method requires all clients to take the same number of local training steps in each communication round. We propose a redesign of the ProxSkip method, allowing clients with ``less important'' data to get away with fewer local training steps without impacting the overall communication complexity of the method. In particular, we prove that our modified method, GradSkip, converges linearly under the same assumptions and has the same accelerated communication complexity, while the number of local gradient steps can be reduced relative to a local condition number. We further generalize our method by extending the randomness of probabilistic alternations to arbitrary unbiased compression operators and by considering a generic proximable regularizer. This generalization, which we call GradSkip+, recovers several related methods in the literature as special cases. Finally, we present an empirical study on carefully designed toy problems that confirm our theoretical claims.},
  archive      = {J_TMLR},
  author       = {Arto Maranjyan and Mher Safaryan and Peter Richtárik},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GradSkip: Communication-accelerated local gradient methods with better computational complexity},
  url          = {https://openreview.net/forum?id=6R3fRqFfhn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metamorphic forward adaptation network: Dynamically adaptive and modular multi-layer learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6RCs2tLsHq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Back-propagation is a widely used algorithm for training neural networks by adjusting weights based on error gradients. However, back-propagation is biologically implausible with global derivative computation and lacks robustness in long-term dynamic learning. A previously proposed alternative to back-propagation is the Forward-Forward algorithm, which bypasses global gradient dependency and localises computations, making it a more biologically plausible approach. However, Forward-Forward has been evaluated in limited environments, does not yet match back-propagation's performance, and only supports classification, not regression. This research introduces the Metamorphic Forward Adaptation Network (MFAN), using a contrastive learning property as its core, and retaining the layer-wise architecture of the Forward-Forward algorithm. Compared to the Forward-Forward model being limited to discrete classification, MFAN can process discrete and continuous data, showing stability, adaptability, and the ability to handle evolving data. MFAN performs well in continuous data stream scenarios, demonstrating superior adaptability and robustness compared to back-propagation, particularly in tasks requiring dynamic, long-term learning.},
  archive      = {J_TMLR},
  author       = {Yu Sun and Vijja Wichitwechkarn and Ronald Clark and Mirko Kovac and Basaran Bahadir Kocer},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Metamorphic forward adaptation network: Dynamically adaptive and modular multi-layer learning},
  url          = {https://openreview.net/forum?id=6RCs2tLsHq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-agent path finding as an LLM benchmark: How, how good and why. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8hAxEFRVQT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid success of large language models (LLMs) has spurred extensive research into their ability to solve a wide range of tasks. However, their potential in multi-agent planning remains underexplored. Multi-agent planning presents unique challenges due to the combined complexity of coordination and long-horizon reasoning, often making it difficult to leverage external tools for assistance. In this paper, we introduce Multi-Agent Path Finding (MAPF), also known as multi-robot route planning, as a novel benchmark for evaluating the reasoning capabilities of LLMs. We first describe how the MAPF benchmark can be adapted for LLM-based evaluation, including dataset curation and an agentic workflow for LLMs. We show the motivating success of single-agent planning and multi-agent pathfinding in an empty room map without obstacles, then the failure to plan on the harder room map and maze map of the standard MAPF benchmark. We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis. Based on our results, we discussed how researchers with different backgrounds could help with this problem from different perspectives.},
  archive      = {J_TMLR},
  author       = {Weizhe Chen and Sven Koenig and Bistra Dilkina},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Solving multi-agent path finding as an LLM benchmark: How, how good and why},
  url          = {https://openreview.net/forum?id=8hAxEFRVQT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting discover-then-name concept bottleneck models: A reproducibility study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=946cT3Jsq5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept Bottleneck Models (CBMs) (Koh et al., 2020) are a class of interpretable deep learning frameworks that improve transparency by mapping input data into human-understandable concepts. Recent advances, including the Discover-then-Name CBM proposed by Rao et al. (2024), eliminate reliance on external language models by automating concept discovery and naming using a CLIP feature extractor and sparse autoencoder. This study focuses on replicating the key findings reported by Rao et al. (2024). We conclude that the core conceptual ideas are reproducible, but not to the extent presented in the original work. Many representations of active neurons appear to be misaligned with their assigned concepts, indicating a lack of faithfulness of the DN-CBM’s explanations. To address this, we propose a model extension: an enhanced alignment method that we evaluate through a user study. Our extended model provides more interpretable concepts (with statistical significance), at the cost of a slight decrease in accuracy.},
  archive      = {J_TMLR},
  author       = {Freek Byrman and Emma Kasteleyn and Bart Kuipers and Daniel Uyterlinde},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting discover-then-name concept bottleneck models: A reproducibility study},
  url          = {https://openreview.net/forum?id=946cT3Jsq5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring and improving initialization for deep graph neural networks: A signal propagation perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6Aj0aNXfRy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) often suffer from performance degradation as the network depth increases. This paper addresses this issue by introducing initialization methods that enhance signal propagation (SP) within GNNs. We propose three key metrics for effective SP in GNNs: forward propagation, backward propagation, and graph embedding variation (GEV). While the first two metrics derive from classical SP theory, the third is specifically designed for GNNs. We theoretically demonstrate that a broad range of commonly used initialization methods for GNNs, which exhibit performance degradation with increasing depth, fail to control these three metrics simultaneously. To deal with this limitation, a direct exploitation of the SP analysis--searching for weight initialization variances that optimize the three metrics--is shown to significantly enhance the SP in deep GCNs. This approach is called \textit{\textbf{S}ignal \textbf{P}ropagation \textbf{o}n \textbf{G}raph-guided \textbf{Init}ialization (\textbf{SPoGInit})}. Our experiments demonstrate that SPoGInit outperforms commonly used initialization methods on various tasks and architectures. Notably, SPoGInit enables performance improvements as GNNs deepen, which represents a significant advancement in addressing depth-related challenges and highlights the validity and effectiveness of the SP analysis framework.},
  archive      = {J_TMLR},
  author       = {Senmiao Wang and Yupeng Chen and Yushun Zhang and Ruoyu Sun and Tian Ding},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring and improving initialization for deep graph neural networks: A signal propagation perspective},
  url          = {https://openreview.net/forum?id=6Aj0aNXfRy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and flexible neural network training through layer-wise feedback propagation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9oToxYVOSW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based optimization has been a cornerstone of machine learning that enabled the vast ad- vances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can be- come limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications — neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) — we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function.},
  archive      = {J_TMLR},
  author       = {Leander Weber and Jim Berend and Moritz Weckbecker and Alexander Binder and Thomas Wiegand and Wojciech Samek and Sebastian Lapuschkin},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient and flexible neural network training through layer-wise feedback propagation},
  url          = {https://openreview.net/forum?id=9oToxYVOSW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tackling the abstraction and reasoning corpus with vision transformers: The importance of 2D representation, positions, and objects. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Al72Fp0rCg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on visual reasoning in the evaluation of Artificial Intelligence systems. In its original framing, an ARC task requires solving a program synthesis problem over small 2D images using a few input-output training pairs. In this work, we adopt the recently popular data-driven approach to the ARC and ask whether a Vision Transformer (ViT) can learn the implicit mapping, from input image to output image, that underlies the task. We show that a ViT—otherwise a state-of-the-art model for images—fails dra- matically on most ARC tasks even when trained on one million examples per task. This points to an inherent representational deficiency of the ViT architecture that makes it incapable of uncov- ering the simple structured mappings underlying the ARC tasks. Building on these insights, we propose VITARC, a ViT-style architecture that unlocks some of the visual reasoning capabilities re- quired by the ARC. Specifically, we use a pixel-level input representation, design a spatially-aware tokenization scheme, and introduce a novel object-based positional encoding that leverages auto- matic segmentation, among other enhancements. Our task-specific VITARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids. This calls attention to the importance of imbuing the powerful (Vision) Transformer with the correct inductive biases for abstract visual reasoning that are critical even when the training data is plentiful and the mapping is noise-free. Hence, VITARC provides a strong foundation for future research in visual reasoning using transformer-based architectures.},
  archive      = {J_TMLR},
  author       = {Wenhao Li and Yudong Xu and Scott Sanner and Elias Boutros Khalil},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tackling the abstraction and reasoning corpus with vision transformers: The importance of 2D representation, positions, and objects},
  url          = {https://openreview.net/forum?id=Al72Fp0rCg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TapWeight: Reweighting pretraining objectives for task-adaptive pretraining. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DCCw2CEVFS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale general domain pretraining followed by downstream-specific finetuning has become a predominant paradigm in machine learning. However, discrepancies between the pretraining and target domains can still lead to performance degradation in certain cases, underscoring the need for task-adaptive continued pretraining (TAP). TAP methods typically involve continued pretraining on task-specific unlabeled datasets or introducing additional unsupervised learning objectives to enhance model capabilities. While many TAP methods perform continued pretraining with multiple pretraining objectives, they often determine the tradeoff parameters between objectives manually, resulting in suboptimal outcomes and higher computational costs. In this paper, we propose TapWeight, a task-adaptive pretraining framework which automatically determines the optimal importance of each pretraining objective based on downstream feedback. TapWeight reweights each pretraining objective by solving a multi-level optimization problem. We applied TapWeight to both molecular property prediction and natural language processing tasks, significantly surpassing baseline methods. Experimental results validate the effectiveness and generalizability of TapWeight.},
  archive      = {J_TMLR},
  author       = {Ruiyi Zhang and Sai Ashish Somayajula and Pengtao Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TapWeight: Reweighting pretraining objectives for task-adaptive pretraining},
  url          = {https://openreview.net/forum?id=DCCw2CEVFS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconciling privacy and explainability in high-stakes: A systematic inquiry. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DQqdjPcE6g'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning’s preponderance across scientific domains has reshaped high-stakes decision-making, making it essential to follow rigorous operational frameworks that include both Right-to-Privacy (RTP) and Right-to-Explanation (RTE). This paper examines the complexities of combining these two requirements. For RTP, we focus on ‘Differential privacy’ (DP), which is considered the current gold standard for privacy-preserving machine learning due to its strong quantitative guarantee of privacy. For RTE, we focus on post-hoc explainers: they are the go-to option for model auditing as they operate independently of model training. We formally investigate DP models and various commonly-used post-hoc explainers: how to evaluate these explainers subject to RTP, and analyze the intrinsic interactions between DP models and these explainers. Furthermore, our work throws light on how RTP and RTE can be effectively combined in high-stakes applications. Our study concludes by outlining an industrial software pipeline, with the example of a widely used use case, that respects both RTP and RTE requirements.},
  archive      = {J_TMLR},
  author       = {Supriya Manna and Niladri Sett},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reconciling privacy and explainability in high-stakes: A systematic inquiry},
  url          = {https://openreview.net/forum?id=DQqdjPcE6g},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally robust coreset selection under covariate shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Eu7XMLJqsC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coreset selection, which involves selecting a small subset from an existing training dataset, is an approach to reducing training data, and various approaches have been proposed for this method. In practical situations where these methods are employed, it is often the case that the data distributions differ between the development phase and the deployment phase, with the latter being unknown. Thus, it is challenging to select an effective subset of training data that performs well across all deployment scenarios. We therefore propose Distributionally Robust Coreset Selection (DRCS). DRCS theoretically derives an estimate of the upper bound for the worst-case test error, assuming that the future covariate distribution may deviate within a defined range from the training distribution. Furthermore, by selecting instances in a way that suppresses the estimate of the upper bound for the worst-case test error, DRCS achieves distributionally robust training instance selection. This study is primarily applicable to convex training computation, but we demonstrate that it can also be applied to deep learning under appropriate approximations. In this paper, we focus on covariate shift, a type of data distribution shift, and demonstrate the effectiveness of DRCS through experiments.},
  archive      = {J_TMLR},
  author       = {Tomonari Tanaka and Hiroyuki Hanada and Hanting Yang and Aoyama Tatsuya and Yu Inatsu and Akahane Satoshi and Yoshito Okura and Noriaki Hashimoto and Taro Murayama and Hanju Lee and Shinya Kojima and Ichiro Takeuchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributionally robust coreset selection under covariate shift},
  url          = {https://openreview.net/forum?id=Eu7XMLJqsC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness with respect to stereotype predictors: Impossibilities and best practices. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FPJKZDzdsW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI systems increasingly influence decision-making from consumer recommendations to educational opportunities, their accountability becomes paramount. This need for oversight has driven extensive research into algorithmic fairness, a body of work that has examined both allocative and representational harms. However, numerous works examining representational harms such as stereotypes encompass many different concepts measured by different criteria, yielding many, potentially conflicting, characterizations of harm. The abundance of measurement approaches makes the mitigation of stereotypes in downstream machine learning models highly challenging. Our work introduces and unifies a broad class of auditors through the framework of \textit{stereotype predictors}. We map notions of fairness with respect to these predictors to existing notions of group fairness. We give guidance, with theoretical foundations, for selecting one or a set of stereotype predictors and provide algorithms for achieving fairness with respect to stereotype predictors under various fairness notions. We demonstrate the effectiveness of our algorithms with different stereotype predictors in two empirical case studies.},
  archive      = {J_TMLR},
  author       = {Inbal Rachel Livni Navon and Omer Reingold and Judy Hanwen Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness with respect to stereotype predictors: Impossibilities and best practices},
  url          = {https://openreview.net/forum?id=FPJKZDzdsW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LASE: Learned adjacency spectral embeddings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=J65NBLWrmh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We put forth a principled design of a neural architecture to learn nodal Adjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear the gradient descent (GD) method and leveraging the technique of algorithm unrolling, we truncate and re-interpret each GD iteration as a layer in a graph neural network (GNN) that is trained to approximate the ASE. Accordingly, we call the resulting embeddings and our parametric model Learned ASE (LASE), which is interpretable, parameter efficient, robust to inputs with unobserved edges, and offers controllable complexity during inference. LASE layers combine Graph Convolutional Network (GCN) and fully-connected Graph Attention Network (GAT) modules, which is intuitively pleasing since GCN-based local aggregations alone are insufficient to express the sought graph eigenvectors. We propose several refinements to the unrolled LASE architecture (such as sparse attention in the GAT module and decoupled layerwise parameters) that offer favorable approximation error versus computation tradeoffs; even outperforming heavily-optimized eigendecomposition routines from scientific computing libraries. Because LASE is a differentiable function with respect to its parameters as well as its graph input, we can seamlessly integrate it as a trainable module within a larger (semi-)supervised graph representation learning pipeline. The resulting end-to-end system effectively learns "discriminative ASEs" that exhibit competitive performance in supervised link prediction and node classification tasks, outperforming a GNN even when the latter is endowed with open loop, meaning task-agnostic, precomputed spectral positional encodings.},
  archive      = {J_TMLR},
  author       = {María Sofía Pérez Casulo and Marcelo Fiori and Federico Larroca and Gonzalo Mateos},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LASE: Learned adjacency spectral embeddings},
  url          = {https://openreview.net/forum?id=J65NBLWrmh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tackling feature and sample heterogeneity in decentralized multi-task learning: A sheaf-theoretic approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JlPq0LmApB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments show that although Sheaf-FMTL introduces computational and storage overhead due to the management of interaction maps, it achieves substantial communication savings in terms of transmitted bits when compared to decentralized FMTL baselines. This trade-off makes Sheaf-FMTL especially suitable for cross-silo FL scenarios, where managing model heterogeneity and ensuring communication efficiency are essential, and where clients have adequate computational resources.},
  archive      = {J_TMLR},
  author       = {Chaouki Ben Issaid and Praneeth Vepakomma and Mehdi Bennis},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tackling feature and sample heterogeneity in decentralized multi-task learning: A sheaf-theoretic approach},
  url          = {https://openreview.net/forum?id=JlPq0LmApB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-constrained offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KcR8ykFlHA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional offline reinforcement learning (RL) methods predominantly operate in a batch-constrained setting. This confines the algorithms to a specific state-action distribution present in the dataset, reducing the effects of distributional shift but restricting the policy to seen actions. In this paper, we alleviate this limitation by introducing state-constrained offline RL, a novel framework that focuses solely on the dataset’s state distribution. This approach allows the policy to take high-quality out-of-distribution actions that lead to in- distribution states, significantly enhancing learning potential. The proposed setting not only broadens the learning horizon but also improves the ability to combine different trajectories from the dataset effectively, a desirable property inherent in offline RL. Our research is underpinned by theoretical findings that pave the way for subsequent advancements in this area. Additionally, we introduce StaCQ, a deep learning algorithm that achieves state-of-the-art performance on the D4RL benchmark datasets and aligns with our theoretical propositions. StaCQ establishes a strong baseline for forthcoming explorations in this domain.},
  archive      = {J_TMLR},
  author       = {Charles Alexander Hepburn and Yue Jin and Giovanni Montana},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {State-constrained offline reinforcement learning},
  url          = {https://openreview.net/forum?id=KcR8ykFlHA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization guarantees for square-root natural-gradient variational inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OMOFmb6ve7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries.},
  archive      = {J_TMLR},
  author       = {Navish Kumar and Thomas Möllenhoff and Mohammad Emtiyaz Khan and Aurelien Lucchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimization guarantees for square-root natural-gradient variational inference},
  url          = {https://openreview.net/forum?id=OMOFmb6ve7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective concept bottleneck models without predefined concepts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PMO30TLI4l'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based models like Concept Bottleneck Models (CBMs) have garnered significant interest for improving model interpretability by first predicting human-understandable concepts before mapping them to the output classes. Early approaches required costly concept annotations. To alleviate this, recent methods utilized large language models to automatically generate class-specific concept descriptions and learned mappings from a pretrained black-box model’s raw features to these concepts using vision-language models. However, these approaches assume prior knowledge of which concepts the black-box model has learned. In this work, we discover the concepts encoded by the model through unsupervised concept discovery techniques instead. We further leverage a simple input-dependent concept selection mechanism that dynamically retains a sparse set of relevant concepts of each input, enhancing both sparsity and interpretability. Our approach not only improves downstream performance, but also needs significantly fewer concepts for accurate classification. Lastly, we show how large vision-language models can guide the editing of our models' weights to correct model errors.},
  archive      = {J_TMLR},
  author       = {Simon Schrodi and Julian Schur and Max Argus and Thomas Brox},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Selective concept bottleneck models without predefined concepts},
  url          = {https://openreview.net/forum?id=PMO30TLI4l},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified preference optimization: Language model alignment beyond the preference frontier. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=R7QFlwvnne'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For aligning large language models (LLMs), prior work has leveraged reinforcement learning via human feedback (RLHF) or variations of direct preference optimization (DPO). While DPO offers a simpler framework based on maximum likelihood estimation, it compromises on the ability to easily tune language models to maximize auxiliary, non-preferential objectives according to the LLM designer's preferences (e.g., tuning lexical style or minimizing specific kinds of harmful content). Critically, these designer objectives may not be amply human-labeled or represented in available data, align with user preferences, or even be able to be captured tractably by binary preference pairs. To leverage the simplicity and performance of DPO with the generality of RL, we propose a unified approach. Based on a simple decomposition of preference and auxiliary objectives, we allow for tuning LLMs to optimize user and designer preferences without any additional specialized or preference data, computational cost, stability "tweaks", hyperparameter tuning, or training instability. The proposed method, Unified Preference Optimization, shows the ability to effectively generalize to user preferences and auxiliary objectives, while preserving or surpassing alignment performance on challenging benchmarks across a range of model sizes.},
  archive      = {J_TMLR},
  author       = {Anirudhan Badrinath and Prabhat Agarwal and Jiajing Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unified preference optimization: Language model alignment beyond the preference frontier},
  url          = {https://openreview.net/forum?id=R7QFlwvnne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowing what not to do: Leverage language model insights for action space pruning in multi-agent reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=T49vPTkIt5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) is employed to develop autonomous agents that can learn to adopt cooperative or competitive strategies within complex environments. However, the linear increase in the number of agents leads to a combinatorial explosion of the action space, which always results in algorithmic instability, difficulty in convergence, or entrapment in local optima. While researchers have designed a variety of effective algorithms to compress the action space, these methods also introduce new challenges, such as the need for manually designed prior knowledge or reliance on the structure of the problem, which diminishes the applicability of these techniques. In this paper, we introduce \textbf{E}volutionary action \textbf{SPA}ce \textbf{R}eduction with \textbf{K}nowledge (eSpark), an exploration function generation framework driven by large language models (LLMs) to boost exploration and prune unnecessary actions in MARL. Using just a basic prompt that outlines the overall task and setting, eSpark is capable of generating exploration functions in a zero-shot manner, identifying and pruning redundant or irrelevant state-action pairs, and then achieving autonomous improvement from policy feedback. In reinforcement learning tasks involving inventory management and traffic light control encompassing a total of 15 scenarios, eSpark consistently outperforms the combined MARL algorithm in all scenarios, achieving an average performance gain of 34.4% and 9.9% in the two types of tasks respectively. Additionally, eSpark has proven to be capable of managing situations with a large number of agents, securing a 29.7% improvement in scalability challenges that featured over 500 agents. The code can be found in https://github.com/LiuZhihao2022/eSpark.},
  archive      = {J_TMLR},
  author       = {Zhihao Liu and Xianliang Yang and Zichuan Liu and Yifan Xia and Wei Jiang and Yuanyu Zhang and Lijuan Li and Guoliang Fan and Lei Song and Jiang Bian},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Knowing what not to do: Leverage language model insights for action space pruning in multi-agent reinforcement learning},
  url          = {https://openreview.net/forum?id=T49vPTkIt5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CXAD: Contrastive explanations for anomaly detection: Algorithms, complexity results and experiments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Tnwci2kLna'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly/Outlier detection (AD/OD) is often used in controversial applications to detect unusual behavior which is then further investigated or policed. This means an explanation of why something was predicted as an anomaly is desirable not only for individuals but also for the general population and policy-makers. However, existing explainable AI (XAI) methods are not well suited for Explainable Anomaly detection (XAD). In particular, most XAI methods provide instance-level explanations, whereas a model/global-level explanation is desirable for a complete understanding of the definition of normality or abnormality used by an AD algorithm. Further, existing XAI methods try to explain an algorithm’s behavior by finding an explanation of why an instance belongs to a category. However, by definition, anomalies/outliers are chosen because they are different from the normal instances. We propose a new style of model agnostic explanation, called contrastive explanation, that is designed specifically for AD algorithms. It addresses the novel challenge of providing a model-agnostic and global-level explanation by finding contrasts between the outlier group of instances and the normal group. We propose three formulations: (i) Contrastive Explanation, (ii) Strongly Contrastive Explanation, and (iii) Multiple Strong Contrastive Explanations. The last formulation is specifically for the case where a given dataset is believed to have many types of anomalies. For the first two formulations, we show the underlying problem is in the computational class P by presenting linear and polynomial time exact algorithms. We show that the last formulation is computationally intractable, and we use an integer linear program for that version to generate experimental results. We demonstrate our work on several data sets such as the CelebA image data set, the HateXplain language data set, and the COMPAS dataset on fairness. These data sets are chosen as their ground truth explanations are clear or well-known.},
  archive      = {J_TMLR},
  author       = {Ian Davidson and Nicolás Kennedy and S. S. Ravi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CXAD: Contrastive explanations for anomaly detection: Algorithms, complexity results and experiments},
  url          = {https://openreview.net/forum?id=Tnwci2kLna},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal policy distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WfVXe88oMh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Proximal Policy Distillation (PPD), a novel policy distillation method that integrates student-driven distillation and Proximal Policy Optimization (PPO) to increase sample efficiency and to leverage the additional rewards that the student policy collects during distillation. To assess the efficacy of our method, we compare PPD with two common alternatives, student-distill and teacher-distill, over a wide range of reinforcement learning environments that include discrete actions and continuous control (ATARI, Mujoco, and Procgen). For each environment and method, we perform distillation to a set of target student neural networks that are smaller, identical (self-distillation), or larger than the teacher network. Our findings indicate that PPD improves sample efficiency and produces better student policies compared to typical policy distillation approaches. Moreover, PPD demonstrates greater robustness than alternative methods when distilling policies from imperfect demonstrations. The code for the paper is released as part of a new Python library built on top of stable-baselines3 to facilitate policy distillation: <Anonymized GitHub Repository> .},
  archive      = {J_TMLR},
  author       = {Giacomo Spigler},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Proximal policy distillation},
  url          = {https://openreview.net/forum?id=WfVXe88oMh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rational tuning of LLM cascades via probabilistic modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YCBVcGSZeR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the reliability of large language models (LLMs) has recently garnered significant attention. Given LLMs' propensity to hallucinate, as well as their high sensitivity to prompt design, it is already challenging to predict the performance of an individual LLM. However, the problem becomes more complex for compound LLM systems such as cascades, where in addition to each model's standalone performance, we must understand how the error rates of different models interact. In this paper, we present a probabilistic model for the joint performance distribution of a sequence of LLMs, which enables a framework for rationally tuning the confidence thresholds of a LLM cascade using continuous optimization. Compared to selecting confidence thresholds using Bayesian optimization, our parametric Markov-copula model yields more favorable error-cost trade-offs, improving the area under the error-cost curve by 4.3% on average for cascades with $k\geq 3$ models. In the low-sample regime with $n \leq 30$ training examples, the performance improvement widens to 10.2%, suggesting that our framework's inductive assumptions about the interactions between the error rates of different LLMs enhance sample efficiency. Overall, our Markov-copula model provides a rational basis for tuning LLM cascade performance and points to the potential of probabilistic methods in analyzing systems of LLMs.},
  archive      = {J_TMLR},
  author       = {Michael J. Zellinger and Matt Thomson},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rational tuning of LLM cascades via probabilistic modeling},
  url          = {https://openreview.net/forum?id=YCBVcGSZeR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). [Re] improving interpretation faithfulness for vision transformers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Z0DhgU8fBt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to reproduce the results of Faithful Vision Transformers (FViTs) proposed by Hu et al. (2024) alongside interpretability methods for Vision Transformers from Chefer et al. (2021) and Xu et al. (2022). We investigate claims made by Hu et al. (2024), namely that the usage of Diffusion Denoised Smoothing (DDS) improves interpretability robustness to (1) attacks in a segmentation task and (2) perturbation and attacks in a classification task. We also extend the original study by investigating the authors’ claims that adding DDS to any interpretability method can improve its robustness under attack. This is tested on baseline methods and the recently proposed Attribution Rollout method. In addition, we measure the computational costs and environmental impact of obtaining an FViT through DDS. Our results broadly agree with the original study’s findings, although minor discrepancies were found and discussed.},
  archive      = {J_TMLR},
  author       = {Izabela Kurek and Wojciech Trejter and Stipe Frkovic and Andro Erdelez},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {[Re] improving interpretation faithfulness for vision transformers},
  url          = {https://openreview.net/forum?id=Z0DhgU8fBt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI agents that matter. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Zy4uFzMviZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI agents are an exciting new research direction, and agent development is driven by benchmarks. Our analysis of current agent benchmarks and evaluation practices reveals several shortcomings that hinder their usefulness in real-world applications. First, there is a narrow focus on accuracy without attention to other metrics. As a result, SOTA agents are needlessly complex and costly, and the community has reached mistaken conclusions about the sources of accuracy gains. Our focus on cost in addition to accuracy motivates the new goal of jointly optimizing the two metrics. We design and implement one such optimization, showing its potential to greatly reduce cost while maintaining accuracy. Second, the benchmarking needs of model and downstream developers have been conflated, making it hard to identify which agent would be best suited for a particular application. Third, many agent benchmarks have inadequate holdout sets, and sometimes none at all. This has led to agents that are fragile because they take shortcuts and overfit to the benchmark in various ways. We prescribe a principled framework for avoiding overfitting. Finally, there is a lack of standardization in evaluation practices, leading to a pervasive lack of reproducibility. We hope that the steps we introduce for addressing these shortcomings will spur the development of agents that are useful in the real world and not just accurate on benchmarks.},
  archive      = {J_TMLR},
  author       = {Sayash Kapoor and Benedikt Stroebl and Zachary S Siegel and Nitya Nadgir and Arvind Narayanan},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AI agents that matter},
  url          = {https://openreview.net/forum?id=Zy4uFzMviZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SR-reward: Taking the path more traveled. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bzk1sV1svm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel method for learning reward functions directly from offline demonstrations. Unlike traditional inverse reinforcement learning (IRL), our approach decouples the reward function from the learner's policy, eliminating the adversarial interaction typically required between the two. This results in a more stable and efficient training process. Our reward module, \textit{SR-Reward}, leverages successor representation (SR) to encode a state based on expected future states' visitation under the demonstration policy and transition dynamics. By utilizing the Bellman equation, SR-Reward can be learned concurrently with most reinforcement learning (RL) algorithms without altering the existing training pipeline. We also introduce a negative sampling strategy to mitigate overestimation errors by reducing rewards for out-of-distribution data, thereby enhancing robustness. This strategy introduces an inherent conservative bias into RL algorithms that employ the learned reward, encouraging them to stay close to the demonstrations where the consequences of the actions are better understood. We evaluate our method on D4RL as well as Maniskill Robot Manipulation environments, achieving competitive results compared to offline RL algorithms with access to true rewards and imitation learning (IL) techniques like behavioral cloning.},
  archive      = {J_TMLR},
  author       = {Seyed Mahdi B. Azad and Zahra Padar and Gabriel Kalweit and Joschka Boedecker},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SR-reward: Taking the path more traveled},
  url          = {https://openreview.net/forum?id=bzk1sV1svm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics of the accelerated t-SNE. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dfUebM9asV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the dynamics of t-Stochastic Neighbor Embedding (t-SNE), a popular tool for visualizing complex datasets in exploratory data analysis, optimized by the Nesterov’s accelerated gradient method. Building on the foundational work that connects t-SNE with spectral clustering and dynamical systems, we extend the analysis to include accelerated dynamics which is not addressed in the previous work, revealing the emergence of Bessel and modified Bessel functions as a novel aspect of the algorithm’s behavior characterizing the temporal evolution of the accelerated t-SNE. Because the ordinary differential equation corresponding to the optimization process under consideration has a closed-form solution, by performing eigenvalue decomposition of the data’s adjacency matrix as a pre-processing step, we can obtain low-dimensional embeddings at any point in time without performing sequential optimization. This advancement not only enhances the practical utility of t-SNE but also contributes to a deeper understanding of its underlying dynamics.},
  archive      = {J_TMLR},
  author       = {Kyoichi Iwasaki and Hideitsu Hino},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamics of the accelerated t-SNE},
  url          = {https://openreview.net/forum?id=dfUebM9asV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple calibration via geodesic kernels. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dpcRp8ix5T'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep discriminative approaches, such as decision forests and deep neural networks, have recently found applications in many important real-world scenarios. However, deploying these learning algorithms in safety-critical applications raises concerns, particularly when it comes to ensuring calibration for both in-distribution and out-of-distribution regions. Many popular methods for in-distribution (ID) calibration, such as isotonic and Platt’s sigmoidal regression, exhibit adequate ID calibration performance. However, these methods are not calibrated for the entire feature space, leading to overconfidence in the out-of-distribution (OOD) region. Existing OOD calibration methods generally exhibit poor ID calibration. In this paper, we jointly address the ID and OOD problems. We leveraged the fact that deep models learn to partition feature space into a union of polytopes, that is, flat-sided geometric objects. We introduce a geodesic distance to measure the distance between these polytopes and further distinguish samples within the same polytope using a Gaussian kernel. Our experiments on both tabular and vision benchmarks show that the proposed approaches, namely Kernel Density Forest (KDF) and Kernel Density Network (KDN), obtain well-calibrated posteriors for both ID and OOD samples, while mostly preserving the classification accuracy and extrapolating beyond the training data to handle OOD inputs appropriately.},
  archive      = {J_TMLR},
  author       = {Jayanta Dey and Haoyin Xu and Ashwin De Silva and Joshua T Vogelstein},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simple calibration via geodesic kernels},
  url          = {https://openreview.net/forum?id=dpcRp8ix5T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end training for text-to-image synthesis using dual-text embeddings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gJ1OknHV5e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image (T2I) synthesis is a challenging task that requires modeling complex interactions between two modalities ( i.e., text and image). A common framework adopted in recent state-of-the-art approaches to achieving such multimodal interactions is to bootstrap the learning process with pre-trained image-aligned text embeddings trained using contrastive loss. Furthermore, these embeddings are typically trained generically and reused across various synthesis models. In contrast, we explore an approach to learning text embeddings specifically tailored to the T2I synthesis network, trained in an end-to-end fashion. Further, we combine generative and contrastive training and use two embeddings, one optimized to enhance the photo-realism of the generated images, and the other seeking to capture text-to-image alignment. A comprehensive set of experiments on three text-to-image benchmark datasets (Oxford-102, Caltech-UCSD, and MS-COCO) reveal that having two separate embeddings gives better results than using a shared one and that such an approach performs favourably in comparison with methods that use text representations from a pre-trained text encoder trained using a discriminative approach. Finally, we demonstrate that such learned embeddings can be used in other contexts as well, such as text-to-image manipulation.},
  archive      = {J_TMLR},
  author       = {Yeruru Asrar Ahmed and Anurag Mittal},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {End-to-end training for text-to-image synthesis using dual-text embeddings},
  url          = {https://openreview.net/forum?id=gJ1OknHV5e},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MACCA: Offline multi-agent reinforcement learning with causal credit assignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gwUOzI4DuV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Multi-agent Reinforcement Learning (MARL) is valuable in scenarios where online interaction is impractical or risky. While independent learning in MARL offers flexibility and scalability, accurately assigning credit to individual agents in offline settings poses challenges because interactions with an environment are prohibited. In this paper, we propose a new framework, namely \textbf{M}ulti-\textbf{A}gent \textbf{C}ausal \textbf{C}redit \textbf{A}ssignment (\textbf{MACCA}), to address credit assignment in the offline MARL setting. Our approach, MACCA, characterizing the generative process as a Dynamic Bayesian Network, captures relationships between environmental variables, states, actions, and rewards. Estimating this model on offline data, MACCA can learn each agent's contribution by analyzing the causal relationship of their individual rewards, ensuring accurate and interpretable credit assignment. Additionally, the modularity of our approach allows it to integrate with various offline MARL methods seamlessly. Theoretically, we proved that under the setting of the offline dataset, the underlying causal structure and the function for generating the individual rewards of agents are identifiable, which laid the foundation for the correctness of our modeling. In our experiments, we demonstrate that MACCA not only outperforms state-of-the-art methods but also enhances performance when integrated with other backbones.},
  archive      = {J_TMLR},
  author       = {Ziyan Wang and Yali Du and Yudi Zhang and Meng Fang and Biwei Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MACCA: Offline multi-agent reinforcement learning with causal credit assignment},
  url          = {https://openreview.net/forum?id=gwUOzI4DuV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non asymptotic analysis of adaptive stochastic gradient algorithms and applications. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=iyfbGyAkKt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In stochastic optimization, a widely used approach for handling large samples sequentially is the stochastic gradient algorithm (SGD). However, a key limitation of SGD is that its step size sequence remains uniform across all gradient directions, which can lead to poor performance in practice, particularly for ill-conditioned problems. To address this issue, adaptive gradient algorithms, such as Adagrad and stochastic Newton methods, have been developed. These algorithms adapt the step size to each gradient direction, providing significant advantages in such challenging settings. This paper focuses on the non-asymptotic analysis of these adaptive gradient algorithms for strongly convex objective functions. The theoretical results are further applied to practical examples, including linear regression and regularized generalized linear models, using both Adagrad and stochastic Newton algorithms.},
  archive      = {J_TMLR},
  author       = {Antoine Godichon-Baggioni and Pierre Tarrago},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Non asymptotic analysis of adaptive stochastic gradient algorithms and applications},
  url          = {https://openreview.net/forum?id=iyfbGyAkKt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards undistillable models by minimizing conditional mutual information. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jVABSsD4Vf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deep neural network (DNN) is said to be undistillable if, when used as a black-box input- output teacher, it cannot be distilled through knowledge distillation (KD). In this case, the distilled student (referred to as the knockoff student) does not outperform a student trained independently with label smoothing (LS student) in terms of prediction accuracy. To protect intellectual property of DNNs, it is desirable to build undistillable DNNs. To this end, it is first observed that an undistillable DNN may have the trait that each cluster of its output probability distributions in response to all sample instances with the same label should be highly concentrated to the extent that each cluster corresponding to each label should ideally collapse into one probability distribution. Based on this observation and by measuring the concentration of each cluster in terms of conditional mutual information (CMI), a new training method called CMI minimized (CMIM) method is proposed, which trains a DNN by jointly minimizing the conventional cross entropy (CE) loss and the CMI values of all temperature scaled clusters across the entire temperature spectrum. The resulting CMIM model is shown, by extensive experiments, to be undistillable by all tested KD methods existing in the literature. That is, the knockoff students distilled by these KD methods from the CMIM model underperform the respective LS students. In addition, the CMIM model is also shown to performs better than the model trained with the CE loss alone in terms of their own prediction accuracy.},
  archive      = {J_TMLR},
  author       = {Linfeng Ye and Shayan Mohajer Hamidi and EN-HUI YANG},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards undistillable models by minimizing conditional mutual information},
  url          = {https://openreview.net/forum?id=jVABSsD4Vf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). [RE] GNNBoundary: Finding boundaries and going beyond them. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kEUvWFHEsn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification models are becoming increasingly popular, while explainability methods face challenges due to the discrete nature of graphs and other factors. However, investigating model decision-making, such as through decision-boundary regions, helps prevent misclassification and improve model robustness. This study aims to reproduce the findings of GNNBoundary: Towards Explaining Graph Neural Networks Through the Lens of Decision Boundaries (Wang & Shen, 2024). Their work supports 3 main claims: (1) their proposed algorithm can identify adjacent class pairs reliably, (2) their GNNBoundary can effectively and consistently generate near-boundary graphs outperforming the cross entropy baseline and (3) the generated near-boundary graphs can be used to accurately assess key properties of the decision boundary; margin, thickness, and complexity. We reproduce the experiments on the same datasets and extended them to two additional real-world datasets. Beyond that, we test different boundary probability ranges and their effect on decision boundary metrics, develop an additional baseline, and conduct hyperparameter tuning. We confirm the first claim regarding the adjacency discovery as well as the second claim that GNNBoundary outperforms the cross-entropy baseline under the limitation that it requires intensive hyperparameter tuning for convergence. The third claim is partially accepted as we observe a high variance between reported and obtained results, disproving the reliability and precision of the boundary statistics. Code and instructions are available at: https://github.com/jhb300/re_gnnboundary.},
  archive      = {J_TMLR},
  author       = {Jan Henrik Bertrand and Lukas Bierling and Ina Klaric and Aron Wezenberg},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {[RE] GNNBoundary: Finding boundaries and going beyond them},
  url          = {https://openreview.net/forum?id=kEUvWFHEsn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Return-aligned decision transformer. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lTt2cTW8h1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. It is increasingly important to adjust the performance of AI agents to meet human requirements, for example, in applications like video games and education tools. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and includes a mechanism to control the agent's performance using the target return. However, the action generation is hardly influenced by the target return because DT’s self-attention allocates scarce attention scores to the return tokens. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to more effectively align the actual return with the target return. RADT leverages features extracted by paying attention solely to the return, enabling action generation to consistently depend on the target return. Extensive experiments show that RADT significantly reduces the discrepancies between the actual return and the target return compared to DT-based methods.},
  archive      = {J_TMLR},
  author       = {Tsunehiko Tanaka and Kenshi Abe and Kaito Ariu and Tetsuro Morimura and Edgar Simo-Serra},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Return-aligned decision transformer},
  url          = {https://openreview.net/forum?id=lTt2cTW8h1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning in complex action spaces without policy gradients. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nOL9M6D4oM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While conventional wisdom holds that policy gradient methods are better suited to complex action spaces than action-value methods, foundational work has shown that the two paradigms are equivalent in small, finite action spaces (O'Donoghue et al., 2017; Schulman et al., 2017a). This raises the question of why their computational applicability and performance diverge as the complexity of the action space increases. We hypothesize that the apparent superiority of policy gradients in such settings stems not from intrinsic qualities of the paradigm but from universal principles that can also be applied to action-value methods, enabling similar functions. We identify three such principles and provide a framework for incorporating them into action-value methods. To support our hypothesis, we instantiate this framework in what we term QMLE, for Q-learning with maximum likelihood estimation. Our results show that QMLE can be applied to complex action spaces at a computational cost comparable to that of policy gradient methods, all without using policy gradients. Furthermore, QMLE exhibits strong performance on the DeepMind Control Suite, even when compared to state-of-the-art methods such as DMPO and D4PG.},
  archive      = {J_TMLR},
  author       = {Arash Tavakoli and Sina Ghiassian and Nemanja Rakicevic},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning in complex action spaces without policy gradients},
  url          = {https://openreview.net/forum?id=nOL9M6D4oM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thoughts and lessons on using visual foundation models for manipulation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=o6mnkDzVuc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training vision-based robotic systems from scratch is both computationally expensive and memory intensive. To mitigate these challenges, recent approaches forgo end-to-end training in favor of adopting visual representations from visual foundation models -- large scale models designed for broad task transferability. Recent years have seen numerous vision foundation models emerge, including several designed specifically for manipulation tasks. However, we still lack clear principles for what makes these models effective for robotics applications. To address this gap, we systematically evaluate vision foundation models to understand what makes them effective for offline robotic learning. We find that across eleven diverse vision encoders, a representation's ability to reconstruct edges and predict keypoints strongly correlates with its performance on manipulation tasks. Extensive correlation analysis across 21 manipulation tasks consistently shows that representations preserving edge and keypoint information achieve the highest environment success rates. These findings appear to challenge conventional wisdom about holistic reconstruction-based pretraining and offer a new lens for understanding what makes vision representations effective for robotics.},
  archive      = {J_TMLR},
  author       = {Ryan Chen and Ziteng Pang and Bradly C. Stadie},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Thoughts and lessons on using visual foundation models for manipulation},
  url          = {https://openreview.net/forum?id=o6mnkDzVuc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spaced scheduling for large language model training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=p0KTYl2B9T'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent breakthroughs in deep learning have accelerated progress toward increasingly capable large language models (LLMs), even sparking discussions about the path to Artificial General Intelligence (AGI). Yet, current LLM training pipelines continue to depend on heuristics and human-driven empirical analysis to curate data. In practice, more sophisticated data selection methods often incur high costs, exhibit limited adaptability, or do not consistently surpass simple random baselines across various models and datasets. In this work, we propose Spaced Scheduled Training (Sst), a novel adaptive data selection strategy that prioritizes training examples based solely on per-example perplexity computed from the model’s own evolving parameters. By obviating the need for external reference models, Sst customizes data selection to the model’s unique characteristics, including its pre-training data composition, and eliminates biases commonly introduced by these external models. Extensive experiments on seven LLMs (0.5B to 32B parameters) in the instruction-finetuning (IFT) setting show that Sst consistently outperforms representative state-of-the-art selection approaches like Deita and InsTag on the Open LLM Leaderboard. For instance, with Qwen2.5-32B and a 30k examples data budget, Sst achieved a 42.75% Open LLM Leaderboard score, exceeding a leading data-selection baseline (38.56%) and the full-100k dataset baseline (39.58%). We further present a theoretical framework to assess computational overhead of model-based selection methods, showing that Sst remains efficient in practical scenarios, and propose strategies to mitigate the overhead in worst-case scenarios. Our findings underscore the potential of model-informed dynamic data selection, offering an efficient, adaptable, and cost-effective approach. We release our training code, trained models, and data mixes in our public repository.},
  archive      = {J_TMLR},
  author       = {Amine El hattami and Nicolas Chapados and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Spaced scheduling for large language model training},
  url          = {https://openreview.net/forum?id=p0KTYl2B9T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model-brained GUI agents: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xChvYjvXTp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphical User Interfaces (GUIs) have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. Traditionally, automating GUI interactions relied on script-based or rule-based approaches, which, while effective for fixed workflows, lacked the flexibility and adaptability required for dynamic, real-world applications. The advent of Large Language Models (LLMs), particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, task generalization, and visual processing. This has paved the way for a new generation of ''LLM-brained'' GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry. To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address critical research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents. We anticipate that this survey will serve both as a practical cookbook for constructing LLM-powered GUI agents, and as a definitive reference for advancing research in this rapidly evolving domain.},
  archive      = {J_TMLR},
  author       = {Chaoyun Zhang and Shilin He and Jiaxu Qian and Bowen Li and Liqun Li and Si Qin and Yu Kang and Minghua Ma and Guyue Liu and Qingwei Lin and Saravan Rajmohan and Dongmei Zhang and Qi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Large language model-brained GUI agents: A survey},
  url          = {https://openreview.net/forum?id=xChvYjvXTp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SEE-DPO: Self entropy enhanced direct preference optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xQbRFHfgGL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct Preference Optimization (DPO) has been successfully used to align large language models (LLMs) according to human preferences, and more recently it has also been applied to improving the quality of text-to-image diffusion models. However, DPO-based methods such as SPO, Diffusion-DPO, and D3PO are highly susceptible to overfitting and reward hacking, especially when the generative model is optimized to fit out-of-distribution during prolonged training. To overcome these challenges and stabilize the training of diffusion models, we introduce a self-entropy regularization mechanism in reinforcement learning from human feedback. This enhancement improves DPO training by encouraging broader exploration and greater robustness. Our regularization technique effectively mitigates reward hacking, leading to improved stability and enhanced image quality across the latent space. Extensive experiments demonstrate that integrating human feedback with self-entropy regularization can significantly boost image diversity and specificity, achieving state-of-the-art results on key image generation metrics.},
  archive      = {J_TMLR},
  author       = {Shivanshu Shekhar and Shreyas Singh and Tong Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SEE-DPO: Self entropy enhanced direct preference optimization},
  url          = {https://openreview.net/forum?id=xQbRFHfgGL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pitfalls in evaluating inference-time methods for improving LLM reliability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xeGWsmqFS8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though Large Language Models (LLMs) have demonstrated remarkable capabilities, they are still prone to outputting falsehoods using seemingly persuasive language. Many recent works attempt to address this problem by using LLMs in a framework where a single seed prompt results in a series of interactions involving augmented prompts with an otherwise unchanged LLM, and the results are aggregated with a goal of producing a more reliable output. We consider the replicability and generalizability of evaluations of inference-time methods intended to improve the reliability of responses from a base LLMs. We survey how methods have been evaluated in the literature and find a great variety of benchmarks and models in use. Motivated by this, we conduct our own evaluation to evaluate the effectiveness of a few methods across a range of benchmarks and models. Our evaluation reveals that while these techniques show promise in improving reliability, there is still significant variability in performance across different domains and tasks, and methods that show substantial improvements on weaker base models often do not improve reliability for better base models.},
  archive      = {J_TMLR},
  author       = {Michael M. Jerge and David Evans},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pitfalls in evaluating inference-time methods for improving LLM reliability},
  url          = {https://openreview.net/forum?id=xeGWsmqFS8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sample generation of diffusion models using noise level correction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=y8VXikiIU0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The denoising process of diffusion models can be interpreted as an approximate projection of noisy samples onto the data manifold. Moreover, the noise level in these samples approximates their distance to the underlying manifold. Building on this insight, we propose a novel method to enhance sample generation by aligning the estimated noise level with the true distance of noisy samples to the manifold. Specifically, we introduce a noise level correction network, leveraging a pre-trained denoising network, to refine noise level estimates during the denoising process. Additionally, we extend this approach to various image restoration tasks by integrating task-specific constraints, including inpainting, deblurring, super-resolution, colorization, and compressed sensing. Experimental results demonstrate that our method significantly improves sample quality in both unconstrained and constrained generation scenarios. Notably, the proposed noise level correction framework is compatible with existing denoising schedulers (e.g., DDIM), offering additional performance improvements.},
  archive      = {J_TMLR},
  author       = {Abulikemu Abuduweili and Chenyang Yuan and Changliu Liu and Frank Permenter},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing sample generation of diffusion models using noise level correction},
  url          = {https://openreview.net/forum?id=y8VXikiIU0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing deep neural networks through complex-valued representations and kuramoto synchronization dynamics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zx6QGmBL43'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural synchrony is hypothesized to play a crucial role in how the brain organizes visual scenes into structured representations, enabling the robust encoding of multiple objects within a scene. However, current deep learning models often struggle with object binding, limiting their ability to represent multiple objects effectively. Inspired by neuroscience, we investigate whether synchrony-based mechanisms can enhance object encoding in artificial models trained for visual categorization. Specifically, we combine complex-valued representations with Kuramoto dynamics to promote phase alignment, facilitating the grouping of features belonging to the same object. We evaluate two architectures employing synchrony: a feedforward model and a recurrent model with feedback connections to refine phase synchronization using top-down information. Both models outperform a real-valued baseline and complex-valued models without Kuramoto synchronization on tasks involving multi-object images, such as overlapping handwritten digits, noisy inputs, and out-of-distribution transformations. Our findings highlight the potential of synchrony-driven mechanisms to enhance deep learning models, improving their performance, robustness, and generalization in complex visual categorization tasks.},
  archive      = {J_TMLR},
  author       = {Sabine Muzellec and Andrea Alamia and Thomas Serre and Rufin VanRullen},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing deep neural networks through complex-valued representations and kuramoto synchronization dynamics},
  url          = {https://openreview.net/forum?id=zx6QGmBL43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal and efficient detection of adversarial data through nonuniform impact on network layers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0CY5APFnFI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously vulnerable to adversarial input designs with limited noise budgets. While numerous successful attacks with subtle modifications to original input have been proposed, defense techniques against these attacks are relatively understudied. Existing defense approaches either focus on improving DNN robustness by negating the effects of perturbations or use a secondary model to detect adversarial data. Although equally important, the attack detection approach, which is studied in this work, provides a more practical defense compared to the robustness approach. We show that the existing detection methods are either ineffective against the state-of-the-art attack techniques or computationally inefficient for real-time processing. We propose a novel universal and efficient method to detect adversarial examples by analyzing the varying degrees of impact of attacks on different DNN layers. Our method trains a lightweight regression model that predicts deeper-layer features from early-layer features, and uses the prediction error to detect adversarial samples. Through theoretical arguments and extensive experiments, we demonstrate that our detection method is highly effective, computationally efficient for real-time processing, compatible with any DNN architecture, and applicable across different domains, such as image, video, and audio.},
  archive      = {J_TMLR},
  author       = {Furkan Mumcu and Yasin Yilmaz},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Universal and efficient detection of adversarial data through nonuniform impact on network layers},
  url          = {https://openreview.net/forum?id=0CY5APFnFI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-lingual transfer in programming languages: An extensive empirical study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1PRBHKgQVM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have achieved state-of-the-art performance in various software engineering tasks, including error detection, clone detection, and code translation, primarily leveraging high-resource programming languages like Python and Java. However, many critical languages, such as COBOL, as well as emerging languages, such as Rust and Swift, remain low-resource due to limited openly available code. This scarcity hampers the training and effectiveness of LLMs for these languages, increasing software maintenance costs and stifling innovation. Addressing this gap, we investigate the potential of transfer learning to enhance LLM performance on low-resource programming languages by leveraging data from high-resource counterparts. Our extensive empirical study evaluates transferability across 10 to 41 programming languages and five key tasks: code generation, clone detection, code repair, solution domain classification, and error detection. Additionally, we develop a performance prediction model to guess the best source languages for a given target and task, and analyze the features that influence transfer performance. We further replicate a representative subset of experiments with a larger model to test the generalizability of our conclusions to contemporary large‑scale LLMs. Our findings demonstrate that cross-lingual transfer significantly outperforms zero-shot learning, with effectiveness varying based on both source and target languages. Languages such as Java and Go emerge as the best targets, while Kotlin and JavaScript are excellent sources. Furthermore, our model reliably predicts successful transfer sources by considering linguistic and dataset-specific features, offering practical guidance for data acquisition and model training. This work contributes to the development of LLM-driven tools for low-resource programming languages and provides insights into the characteristics that facilitate transfer across language pairs.},
  archive      = {J_TMLR},
  author       = {Razan Baltaji and Saurabh Pujar and Martin Hirzel and Louis Mandel and Luca Buratti and Lav R. Varshney},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross-lingual transfer in programming languages: An extensive empirical study},
  url          = {https://openreview.net/forum?id=1PRBHKgQVM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting CroPA: A reproducibility study and enhancements for cross-prompt adversarial transferability in vision-language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5L90cl0xtf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (VLMs) have revolutionized computer vision, enabling tasks such as image classification, captioning, and visual question answering. However, they re- main highly vulnerable to adversarial attacks, particularly in scenarios where both visual and textual modalities can be manipulated. In this study, we conduct a comprehensive reproducibility study of "An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on Vision-Language Models" validating the Cross-Prompt Attack (CroPA) and confirming its superior cross-prompt transferability compared to existing baselines. Be- yond replication we propose several key improvements: (1) A novel initialization strategy that significantly improves Attack Success Rate (ASR). (2) Investigate cross-image trans- ferability by learning universal perturbations. (3) A novel loss function targeting vision encoder attention mechanisms to improve generalization. Our evaluation across prominent VLMs—including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on LLaVA validates the original results and demonstrates that our improvements consistently boost adversarial effectiveness. Our work reinforces the importance of studying adversarial vulnerabilities in VLMs and provides a more robust framework for generating transferable adversarial examples, with significant implications for understanding the security of VLMs in real-world applications.},
  archive      = {J_TMLR},
  author       = {Atharv Mittal and Agam Pandey and Amritanshu Tiwari and Sukrit Jindal and Swadesh Swain},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting CroPA: A reproducibility study and enhancements for cross-prompt adversarial transferability in vision-language models},
  url          = {https://openreview.net/forum?id=5L90cl0xtf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the generalizability of "Competition of mechanisms: Tracing how language models handle facts and counterfactuals". <em>TMLR</em>. (<a href='https://openreview.net/forum?id=15keyzQj9h'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a reproduction study of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which investigates competition of mechanisms in language models between factual recall and counterfactual in-context repetition. Our study successfully reproduces their primary findings regarding the localization of factual and counterfactual information, the dominance of attention blocks in mechanism competition, and the specialization of attention heads in handling competing information. We reproduce their results on both GPT-2 (Radford et al., 2019) and Pythia 6.9B (Biderman et al., 2023). We extend their work in three significant directions. First, we explore the generalizability of these findings to even larger models by replicating the experiments on Llama 3.1 8B (Grattafiori et al., 2024), discovering greatly reduced attention head specialization. Second, we investigate the impact of prompt structure by introducing variations where we avoid repeating the counterfactual statement verbatim or we change the premise word, observing a marked decrease in the logit for the counterfactual token. Finally, we test the validity of the authors’ claims for prompts of specific domains, discovering that certain categories of prompts skew the results by providing the factual prediction token as part of the subject of the sentence. Overall, we find that the attention head ablation proposed in Ortu et al. (2024) is ineffective for domains that are underrepresented in their dataset, and that the effectiveness varies based on model architecture, prompt structure, domain and task.},
  archive      = {J_TMLR},
  author       = {Asen Dotsinski and Udit Thakur and Marko Ivanov and Mohammad Hafeez Khan and Maria Heuss},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the generalizability of "Competition of mechanisms: Tracing how language models handle facts and counterfactuals"},
  url          = {https://openreview.net/forum?id=15keyzQj9h},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularized gradient clipping provably trains wide and deep neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ABT1XQLbOx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and analyze a novel regularized form of the gradient clipping algorithm, proving that it converges to global minima of the loss surface of deep neural networks under the squared loss, provided that the layers are of sufficient width. The algorithm presented here, dubbed $\delta-$GClip, introduces a modification to gradient clipping that leads to a first-of-its-kind example of a step size scheduling for gradient descent that provably minimizes training losses of deep neural nets. We also present empirical evidence that our theoretically founded $\delta-$GClip algorithm is competitive with the state-of-the-art deep learning heuristics on various neural architectures including modern transformer based architectures. The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Łojasiewicz inequality which was recently proven to be true for sufficiently wide neural networks at any depth within a neighbourhood of the initialization.},
  archive      = {J_TMLR},
  author       = {Matteo Tucat and Anirbit Mukherjee and Procheta Sen and Mingfei Sun and Omar Rivasplata},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Regularized gradient clipping provably trains wide and deep neural networks},
  url          = {https://openreview.net/forum?id=ABT1XQLbOx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). [Re] benchmarking LLM capabilities in negotiation through scoreable games. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BVH81SAAh2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.},
  archive      = {J_TMLR},
  author       = {Jorge Carrasco Pollo and Ioannis Kapetangeorgis and Joshua Rosenthal and John Hua Yao},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {[Re] benchmarking LLM capabilities in negotiation through scoreable games},
  url          = {https://openreview.net/forum?id=BVH81SAAh2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized out-of-distribution detection and beyond in vision language model era: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FO3IA4lUEY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM.},
  archive      = {J_TMLR},
  author       = {Atsuyuki Miyai and Jingkang Yang and Jingyang Zhang and Yifei Ming and Yueqian Lin and Qing Yu and Go Irie and Shafiq Joty and Yixuan Li and Hai Helen Li and Ziwei Liu and Toshihiko Yamasaki and Kiyoharu Aizawa},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized out-of-distribution detection and beyond in vision language model era: A survey},
  url          = {https://openreview.net/forum?id=FO3IA4lUEY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SynCode: LLM generation with grammar augmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HiUZtgAPoH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LLMs are widely used in complex AI applications. These applications underscore the need for LLM outputs to adhere to a specific format, for their integration with other components in the systems. Typically the format rules – e.g., data serialization formats such as JSON, YAML, or Code in Programming Language – are expressed as context-free grammar (CFG). Due to the hallucinations and unreliability of LLMs, instructing LLMs to adhere to specified syntax becomes an increasingly important challenge. We present SynCode, a novel framework for efficient and general syntactical decoding with LLMs, to address this challenge. SynCode ensures soundness and completeness with respect to the CFG of a formal language, effectively retaining valid tokens while filtering out invalid ones. SynCode uses an offline-constructed, efficient lookup table, the DFA mask store, created from the DFA (Deterministic Finite Automaton) of the language’s grammar for efficient generation. SynCode seamlessly integrates with any language defined by CFG, as evidenced by experiments focusing on generating JSON, SQL, Python, and Go outputs. Our experiments evaluating the effectiveness of SynCode for JSON generation demonstrate that SynCode eliminates all syntax errors and significantly outperforms state-of-the-art baselines. Furthermore, our results underscore how SynCode significantly reduces 96.07% of syntax errors in generated Python and Go code, showcasing its substantial impact on enhancing syntactical precision in LLM generation.},
  archive      = {J_TMLR},
  author       = {Shubham Ugare and Tarun Suresh and Hangoo Kang and Sasa Misailovic and Gagandeep Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SynCode: LLM generation with grammar augmentation},
  url          = {https://openreview.net/forum?id=HiUZtgAPoH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond parameter count: Implicit bias in soft mixture of experts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=II9agMKTb1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional viewpoint on Sparse Mixture of Experts (MoE) models is that instead of training a single _large_ expert, which is computationally expensive, we can train many _small_ experts. The hope is that if the total parameter count of the small experts equals that of the singular large expert, then we retain the representation power of the large expert while gaining computational tractability and promoting expert specialization. The recently introduced Soft MoE replaces the Sparse MoE's discrete routing mechanism with a differentiable gating function that smoothly mixes tokens. While this smooth gating function successfully mitigates the various training instabilities associated with Sparse MoE, it is unclear whether it induces implicit biases that affect Soft MoE's representation power or potential for expert specialization. We prove that Soft MoE with a single arbitrarily powerful expert cannot represent simple convex functions. This justifies that Soft MoE's success cannot be explained by the traditional viewpoint of many small experts collectively mimicking the representation power of a single large expert, and that multiple experts are actually _necessary_ to achieve good representation power (even for a fixed total parameter count). Continuing along this line of investigation, we introduce a notion of expert specialization for Soft MoE, and while varying the number of experts yet fixing the total parameter count, we consider the following (computationally intractable) task. Given any input, how can we discover the expert subset that is specialized to predict this input's label? We empirically show that when there are many small experts, the architecture is implicitly biased in a fashion that allows us to efficiently approximate the specialized expert subset. Our method can be easily implemented to potentially reduce computation during inference. For example, using our method on ImageNet, one can perform inference using only $1/8$ of the experts and still retain $99$% of the test accuracy of using all experts.},
  archive      = {J_TMLR},
  author       = {Youngseog Chung and Dhruv Malik and Jeff Schneider and Yuanzhi Li and Aarti Singh},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond parameter count: Implicit bias in soft mixture of experts},
  url          = {https://openreview.net/forum?id=II9agMKTb1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural varifolds: An aggregate representation for quantifying the geometry of point clouds. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=P02hoA7vln'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds are popular 3D representations for real-life objects (such as in LiDAR and Kinect) due to their detailed and compact representation of surface-based geometry. Recent approaches characterise the geometry of point clouds by bringing deep learning based techniques together with geometric fidelity metrics such as optimal transportation costs (e.g., Chamfer and Wasserstein metrics). In this paper, we propose a new surface geometry characterisation within this realm, namely a neural varifold representation of point clouds. Here, the surface is represented as a measure/distribution over both point positions and tangent spaces of point clouds. The varifold representation quantifies not only the surface geometry of point clouds through the manifold-based representation, but also subtle geometric consistencies on the surface due to the combined product space. This study proposes neural varifold algorithms to compute the varifold norm between two point clouds using neural networks on point clouds and their neural tangent kernel representations. The proposed neural varifold is evaluated on three different sought-after tasks -- shape matching, few-shot shape classification, and shape reconstruction. Detailed evaluation and comparison to the state-of-the-art methods demonstrate that the proposed versatile neural varifold is superior in shape matching and few-shot shape classification, and is competitive for shape reconstruction.},
  archive      = {J_TMLR},
  author       = {Juheon Lee and Xiaohao Cai and Carola-Bibiane Schönlieb and Simon Masnou},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural varifolds: An aggregate representation for quantifying the geometry of point clouds},
  url          = {https://openreview.net/forum?id=P02hoA7vln},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical learning performance of graph networks: The impact of jumping connections and layer-wise sparsification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q9AkJpfJks'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jumping connections enable Graph Convolutional Networks (GCNs) to overcome over-smoothing, while graph sparsification reduces computational demands by selecting a submatrix of the graph adjacency matrix during neighborhood aggregation. Learning GCNs with graph sparsification has shown empirical success across various applications, but a theoretical understanding of the generalization guarantees remains limited, with existing analyses ignoring either graph sparsification or jumping connections. This paper presents the first learning dynamics and generalization analysis of GCNs with jumping connections using graph sparsification. Our analysis demonstrates that the generalization accuracy of the learned model closely approximates the highest achievable accuracy within a broad class of target functions dependent on the proposed sparse effective adjacency matrix $A^*$. Thus, graph sparsification maintains generalization performance when $A^*$ accurately models data correlations. We reveal that jumping connections lead to different sparsification requirements across layers. In a two-hidden-layer GCN, the generalization is more affected by the sparsified matrix deviations from $A^*$ of the first layer than the second layer. To the best of our knowledge, this marks the first theoretical characterization of jumping connections' role in sparsification requirements. We validate our theoretical results on benchmark datasets in deep GCNs.},
  archive      = {J_TMLR},
  author       = {Jiawei Sun and Hongkang Li and Meng Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Theoretical learning performance of graph networks: The impact of jumping connections and layer-wise sparsification},
  url          = {https://openreview.net/forum?id=Q9AkJpfJks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ModernTCN revisited: A critical look at the experimental setup in general time series analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=R20kKdWmVZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While numerous time series models claim state-of-the-art performance, their evaluation often relies on flawed experimental setups, leading to questionable conclusions. This study provides a critical re-evaluation of this landscape, using ModernTCN as a case study. We conduct a rigorous and extended benchmark, correcting methodological issues related to data loading, validation, and evaluation methods, and show that performance claims are sensitive to these details. Additionally, we find that ModernTCN overlooks a line of research in global convolutional models, and our comparison reveals that despite claims of an enlarged effective receptive field (ERF), it falls short of these methods. More than a critique, we introduce an architectural innovation: by embedding irregularly sampled data with a continuous kernel convolution and processing it with the ModernTCN backbone, we achieve new state-of-the-art performance on the challenging PhysioNet 2019 dataset. This work not only provides a robust reassessment of ModernTCN but also serves as an audit of the commonly used general time series analysis experimental setup, which includes tasks such as forecasting, imputation, classification, and anomaly detection.},
  archive      = {J_TMLR},
  author       = {Önder Akacik and Mark Hoogendoorn},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ModernTCN revisited: A critical look at the experimental setup in general time series analysis},
  url          = {https://openreview.net/forum?id=R20kKdWmVZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesizing minority samples for long-tailed classification via distribution matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VqLe8tPbZn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, deep neural networks (DNNs) often perform poorly on datasets with long-tailed distributions. To address this issue, a promising approach is to propose an optimization objective to transform real majority samples into synthetic minority samples. However, this objective is designed only from the classification perspective. To this end, we propose a novel framework that synthesizes minority samples from the majority by considering both classification and distribution matching. Specifically, our method adjusts the distribution of synthetic minority samples to closely align with that of the true minority class, while enforcing the synthetic samples to learn more generalizable and discriminative features of the minority class. Experimental results on several standard benchmark datasets demonstrate the effectiveness of our method in both long-tailed classification and synthesizing high-quality synthetic minority samples.},
  archive      = {J_TMLR},
  author       = {Zhuo Li and He Zhao and Jinke Ren and Anningzhe Gao and Dandan Guo and Xiang Wan and Hongyuan Zha},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Synthesizing minority samples for long-tailed classification via distribution matching},
  url          = {https://openreview.net/forum?id=VqLe8tPbZn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AQA-bench: An interactive benchmark for evaluating LLMs’ sequential reasoning ability in algorithmic environments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=W22g6Ksmbi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol — for example, in DFS, the availability of each node’s connected edge is contingent upon the model’s traversal to that node, thereby necessitating the LLM’s ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models’ performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs’ capabilities in sequential reasoning.},
  archive      = {J_TMLR},
  author       = {Siwei Yang and Bingchen Zhao and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AQA-bench: An interactive benchmark for evaluating LLMs’ sequential reasoning ability in algorithmic environments},
  url          = {https://openreview.net/forum?id=W22g6Ksmbi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GaussianFlow: Splatting gaussian dynamics for 4D content creation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XBL7xi5rt0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating 4D fields of Gaussian Splatting from images or videos is a challenging task due to its under-constrained nature. While the optimization can draw photometric reference from the input videos or be regulated by generative models, directly supervising Gaussian motions remains underexplored. In this paper, we introduce a novel concept, Gaussian flow, which connects the dynamics of 3D Gaussians and pixel velocities between consecutive frames. The Gaussian flow can be obtained efficiently by splatting Gaussian dynamics into the image space. This differentiable process enables direct dynamic supervision from optical flow. Our method significantly benefits 4D dynamic content generation and 4D novel view synthesis with Gaussian Splatting, especially for contents with rich motions that are hard to handle by existing methods. The common color drifting issue that occurs in 4D generation is also resolved with improved Guassian dynamics. Superior visual quality in extensive experiments demonstrates the effectiveness of our method. As shown in our evaluation, GaussianFlow can drastically improve both quantitative and qualitative results for 4D generation and 4D novel view synthesis.},
  archive      = {J_TMLR},
  author       = {Quankai Gao and Qiangeng Xu and Zhe Cao and Ben Mildenhall and Wenchao Ma and Le Chen and Danhang Tang and Ulrich Neumann},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GaussianFlow: Splatting gaussian dynamics for 4D content creation},
  url          = {https://openreview.net/forum?id=XBL7xi5rt0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient inversion attack on graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=a0mLrqkWyx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph federated learning is of essential importance for training over large graph datasets while protecting data privacy, where each client stores a subset of local graph data, while the server collects the local gradients and broadcasts only the aggregated gradients. Recent studies reveal that a malicious attacker can steal private image data from the gradient exchange of neural networks during federated learning. However, the vulnerability of graph data and graph neural networks under such attacks, i.e., reconstructing both node features and graph structure from gradients, remains largely underexplored. To answer this question, this paper studies the problem of whether private data can be reconstructed from leaked gradients in both node classification and graph classification tasks and proposes a novel attack named Graph Leakage from Gradients (GLG). Two widely used GNN frameworks are analyzed, namely GCN and GraphSAGE. The effects of different model settings on reconstruction are extensively discussed. Theoretical analysis and empirical validation demonstrate that, by leveraging the unique properties of graph data and GNNs, GLG achieves more accurate reconstruction of both nodal features and graph structure from gradients.},
  archive      = {J_TMLR},
  author       = {Divya Anand Sinha and Yezi Liu and Ruijie Du and Athina Markopoulou and Yanning Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gradient inversion attack on graph neural networks},
  url          = {https://openreview.net/forum?id=a0mLrqkWyx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reproducibility study of "Improving interpretation faithfulness for vision transformers". <em>TMLR</em>. (<a href='https://openreview.net/forum?id=a0rytDAGUD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper attempts to reproduce the findings of the study "Improving Interpretation Faith-fulness For Vision Transformers" Hu et al. (2024). The authors focus on making visual transformers (ViTs) more robust to adversarial attacks, and calling these robust ViTs faithful ViTs (FViTs). In their paper they propose a universal method to transform ViTs to FViTs called denoised diffusion smoothing (DDS). The reproduction of the authors study suffers from certain challenges, but the main claims still hold. Furthermore, this study extends the original paper by trying different diffusion models for DDS and tries to generalize the increased robustness of FViTs.},
  archive      = {J_TMLR},
  author       = {Meher Changlani and Benjamin Hucko and Ioannis Kechagias and Aswin Krishna Mahadevan},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reproducibility study of "Improving interpretation faithfulness for vision transformers"},
  url          = {https://openreview.net/forum?id=a0rytDAGUD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting XRec: How collaborative signals influence LLM-based recommendation explanations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cPtqOkxQqH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems help users navigate large volumes of online content by offering personalized recommendations. However, the increasing reliance on deep learning-based techniques has made these systems opaque and difficult to interpret. To address this, XRec (Ma et al., 2024) was introduced as a novel framework that integrates collaborative signals and textual descriptions of past interactions into Large Language Models (LLMs) to generate natural language explanations for recommendations. In this work, we reproduce and expand upon the findings of Ma et al. (2024). While our results validate most of the original authors’ claims, we were unable to fully replicate the reported performance improvements from injecting collaborative information into every LLM attention layer, nor the claimed effects of data sparsity. Beyond replication, our contributions provide evidence that the Graph Neural Network (GNN) component does not enhance explainability. Instead, the observed performance improvement is attributed to the Collaborative Information Adapter, which can act as a form of soft prompting, efficiently encoding task-specific information. This finding aligns with prior research suggesting that lightweight adaptation mechanisms can condition frozen LLMs for specific downstream tasks. Our implementation is open-source.},
  archive      = {J_TMLR},
  author       = {Cătălin-Emanuel Brița and Hieu Nguyen and Lubov Chalakova and Nikola Petrov},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting XRec: How collaborative signals influence LLM-based recommendation explanations},
  url          = {https://openreview.net/forum?id=cPtqOkxQqH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monocular dynamic gaussian splatting: Fast, brittle, and scene complexity rules. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fzmw8Joug4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian splatting methods are emerging as a popular approach for converting multi-view image data into scene representations that allow view synthesis. In particular, there is interest in enabling view synthesis for dynamic scenes using only monocular input data---an ill-posed and challenging problem. The fast pace of work in this area has produced multiple simultaneous papers that claim to work best, which cannot all be true. In this work, we organize, benchmark, and analyze many Gaussian-splatting-based methods, providing apples-to-apples comparisons that prior works have lacked. We use multiple existing datasets and a new instructive synthetic dataset designed to isolate factors that affect reconstruction quality. We systematically categorize Gaussian splatting methods into specific motion representation types and quantify how their differences impact performance. Empirically, we find that their rank order is well-defined in synthetic data, but the complexity of real-world data currently overwhelms the differences. Furthermore, the fast rendering speed of all Gaussian-based methods comes at the cost of brittleness in optimization. We summarize our experiments into a list of findings that can help to further progress in this lively problem setting.},
  archive      = {J_TMLR},
  author       = {Yiqing Liang and Mikhail Okunev and Mikaela Angelina Uy and Runfeng Li and Leonidas Guibas and James Tompkin and Adam W Harley},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Monocular dynamic gaussian splatting: Fast, brittle, and scene complexity rules},
  url          = {https://openreview.net/forum?id=fzmw8Joug4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provable robustness of (Graph) neural networks against data poisoning and backdoor attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jIAPLDdGVx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization of machine learning models can be severely compromised by data poisoning, where adversarial changes are applied to the training data. This vulnerability has led to interest in certifying (i.e., proving) that such changes up to a certain magnitude do not affect test predictions. We, for the first time, certify Graph Neural Networks (GNNs) against poisoning attacks, including backdoors, targeting the node features of a given graph. Our certificates are white-box and based upon $(i)$ the neural tangent kernel, which characterizes the training dynamics of sufficiently wide networks; and $(ii)$ a novel reformulation of the bilevel optimization problem describing poisoning as a mixed-integer linear program. Consequently, we leverage our framework to provide fundamental insights into the role of graph structure and its connectivity on the worst-case robustness behavior of convolution-based and PageRank-based GNNs. We note that our framework is more general and constitutes the first approach to derive white-box poisoning certificates for NNs, which can be of independent interest beyond graph-related tasks.},
  archive      = {J_TMLR},
  author       = {Lukas Gosch and Mahalakshmi Sabanayagam and Debarghya Ghoshdastidar and Stephan Günnemann},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provable robustness of (Graph) neural networks against data poisoning and backdoor attacks},
  url          = {https://openreview.net/forum?id=jIAPLDdGVx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reassessing fairness: A reproducibility study of NIFA’s impact on GNN models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=l5fXUKi8GO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown strong performance on graph-structured data but raise fairness concerns by amplifying existing biases. The Node Injection-based Fairness Attack (NIFA) (Luo et al., 2024) is a recently proposed gray-box attack that degrades group fairness while preserving predictive utility. In this study, we reproduce and evaluate NIFA across multiple datasets and GNN architectures. Our findings confirm that NIFA consistently degrades fairness—measured via Statistical Parity and Equal Opportunity—while maintaining utility on classical GNNs. However, claims of NIFA’s superiority over existing fairness and utility attacks are only partially supported due to limitations in baseline reproducibility. We further extend NIFA to accommodate multi-class sensitive attributes and evaluate its behavior under varying levels of graph homophily. While NIFA remains effective in multi-class contexts, its impact is more sensitive in mixed and highly homophilic graphs. Although this is not a comprehensive validation of all NIFA claims, our work provides targeted insights into its reproducibility and generalizability across fairness-sensitive scenarios. The codebase is publicly available at: https://github.com/sjoerdgunneweg/Reassessing-NIFA.},
  archive      = {J_TMLR},
  author       = {Ruben Figge and Sjoerd Gunneweg and Aaron Kuin and Mees Lindeman},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reassessing fairness: A reproducibility study of NIFA’s impact on GNN models},
  url          = {https://openreview.net/forum?id=l5fXUKi8GO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagicPose4D: Crafting articulated models with appearance and motion control. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qgHq1NFUJk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the success of 2D and 3D visual generative models, there is growing interest in generating 4D content. Existing methods primarily rely on text prompts to produce 4D content, but they often fall short of accurately defining complex or rare motions. To address this limitation, we propose MagicPose4D, a novel framework for refined control over both appearance and motion in 4D generation. Unlike current 4D generation methods, MagicPose4D accepts monocular videos or mesh sequences as motion prompts, enabling precise and customizable motion control. MagicPose4D comprises two key modules: (i) Dual-Phase 4D Reconstruction Module which operates in two phases. The first phase focuses on capturing the model's shape using accurate 2D supervision and less accurate but geometrically informative 3D pseudo-supervision without imposing skeleton constraints. The second phase extracts the 3D motion (skeleton poses) using more accurate pseudo-3D supervision, obtained in the first phase, and introduces kinematic chain-based skeleton constraints to ensure physical plausibility. Additionally, we propose a Global-local Chamfer loss that aligns the overall distribution of predicted mesh vertices with the supervision while maintaining part-level alignment without extra annotations. (ii) Cross-category Motion Transfer Module leverages the extracted motion from the 4D reconstruction module and uses a kinematic-chain-based skeleton to achieve cross-category motion transfer. It ensures smooth transitions between frames through dynamic rigidity, facilitating robust generalization without additional training. Through extensive experiments, we demonstrate that MagicPose4D significantly improves the accuracy and consistency of 4D content generation, outperforming existing methods in various benchmarks.},
  archive      = {J_TMLR},
  author       = {Hao Zhang and Di Chang and Fang Li and Mohammad Soleymani and Narendra Ahuja},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MagicPose4D: Crafting articulated models with appearance and motion control},
  url          = {https://openreview.net/forum?id=qgHq1NFUJk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing molecular conformer generation via fragment- augmented diffusion pretraining. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=t5WzHOniAF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in diffusion-based methods have shown promising results for molecular conformer generation, yet their performance remains constrained by training data scarcity---particularly for structurally complex molecules. In this work, we present Fragment-Augmented Diffusion (FragDiff), a data-centric augmentation strategy that incorporates chemical fragmentation techniques into the pre-training phase of modern diffusion-based generative models. Our key innovation lies in decomposing molecules into chemically meaningful fragments that serve as building blocks for systematic data augmentation, enabling the diffusion model to learn enhanced local geometry while maintaining global molecular topology. Unlike existing approaches that focus on complex architectural modifications, FragDiff adopts a data-centric paradigm orthogonal to model design. Comprehensive benchmarks show FragDiff's superior performance, especially in data-scarce scenarios. Notably, it achieves 12.2--13.4% performance improvement on molecules 3$\times$ beyond training scale through pretraining on fragments. Overall, we establish a new paradigm integrating chemical fragmentations with diffusion models, advancing computational chemistry workflows. The code is available at https://github.com/ShawnKS/fragdiff.},
  archive      = {J_TMLR},
  author       = {Xiaozhuang Song and YUZHAO TU and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing molecular conformer generation via fragment- augmented diffusion pretraining},
  url          = {https://openreview.net/forum?id=t5WzHOniAF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on verifiable cross-silo federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uMir8UIHST'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a widespread approach that allows training machine learning (ML) models with data distributed across multiple storage units. In cross-silo FL, which often appears in domains like healthcare or finance, the number of participants is moderate, and each party typically represents a well-known organization. For instance, in medicine data owners are often hospitals or data hubs which are well-established entities. However, malicious parties may still attempt to disturb the training procedure in order to obtain certain benefits, for example, a biased result or a reduction in computational load. While one can easily detect a malicious agent when data used for training is public, the problem becomes much more acute when it is necessary to maintain the privacy of the training dataset. To address this issue, there is recently growing interest in developing verifiable protocols, where one can check that parties do not deviate from the training procedure and perform computations correctly. In this paper, we present a survey on verifiable cross-silo FL. We analyze various protocols, fit them in a taxonomy, and compare their efficiency and threat models. We also analyze Zero-Knowledge Proof (ZKP) schemes and discuss how their overall cost in a FL context can be minimized. Lastly, we identify research gaps and discuss potential directions for future scientific work.},
  archive      = {J_TMLR},
  author       = {Aleksei Korneev and Jan Ramon},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on verifiable cross-silo federated learning},
  url          = {https://openreview.net/forum?id=uMir8UIHST},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reproducibility study of “User-item fairness tradeoffs in recommendations”. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vltzxxhzLU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems are necessary to filter the abundance of information presented in our everyday lives. A recommendation system could exclusively recommend items that users prefer the most, potentially resulting in certain items never getting recommended. Conversely, an exclusive focus on including all items could hurt overall recommendation quality. This gives rise to the challenge of balancing user and item fairness. The paper “User-item fairness tradeoffs in recommendations” by Greenwood et al. (2024) explores this tradeoff by developing a theoretical framework that optimizes for user-item fairness constraints. Their theoretical framework suggests that the cost of item fairness is low when users have varying preferences compared to each other, and may be high for users whose preferences are misestimated. They empirically measured these phenomena by creating their own recommendation system on arXiv preprints, and confirmed that the cost of item fairness is low when users have preferences that differ from one another. However, contrary to their theoretical expectations, misestimated users do not encounter a higher cost of item fairness. This study investigates the reproducibility of their research by replicating the empirical study. Additionally, we extend their research in two ways: (i) verifying the generalizability of their findings on a different dataset (Amazon books reviews), and (ii) analyzing the tradeoffs when recommending multiple items to a user instead of a single item. Our results further validate the claims made in the original paper. We concluded the claims hold true when recommending multiple items, with the cost of item fairness decreasing as more items are recommended.},
  archive      = {J_TMLR},
  author       = {Sander Honig and Elyanne Oey and Lisanne Wallaard and Sharanda Suttorp and Clara Rus},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A reproducibility study of “User-item fairness tradeoffs in recommendations”},
  url          = {https://openreview.net/forum?id=vltzxxhzLU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable LLM-based table question answering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2eTsZBoU2W'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability in Table Question Answering (Table QA) is critical, especially in high-stakes domains like finance and healthcare. While recent Table QA approaches based on Large Language Models (LLMs) achieve high accuracy, they often produce ambiguous explanations of how answers are derived. We propose Plan-of-SQLs (POS), a new Table QA method that makes the model's decision-making process interpretable. POS decomposes a question into a sequence of atomic steps, each directly translated into an executable SQL command on the table, thereby ensuring that every intermediate result is transparent. Through extensive experiments, we show that: First, POS generates the highest-quality explanations among compared methods, which markedly improves the users' ability to simulate and verify the model’s decisions. Second, when evaluated on standard Table QA benchmarks (TabFact, WikiTQ, and FeTaQA), POS achieves QA accuracy that is competitive to existing methods, while also offering greater efficiency—requiring significantly fewer LLM calls and table database queries (up to 25x fewer)—and more robust performance on large-sized tables. Finally, we observe high agreement (up to 90.59% in forward simulation) between LLMs and human users when making decisions based on the same explanations, suggesting that LLMs could serve as an effective proxy for humans in evaluating Table QA explanations.},
  archive      = {J_TMLR},
  author       = {Giang Nguyen and Ivan Brugere and Shubham Sharma and Sanjay Kariyappa and Anh Totti Nguyen and Freddy Lecue},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interpretable LLM-based table question answering},
  url          = {https://openreview.net/forum?id=2eTsZBoU2W},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled embedding through style and mutual information for domain generalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=552tedTByb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks often experience performance degradation when faced with distributional shifts between training and testing data, a challenge referred to as domain shift. Domain Generalization (DG) addresses this issue by training models on multiple source domains, enabling the development of invariant representations that generalize to unseen distributions. While existing DG methods have achieved success by minimizing variations across source domains within a shared feature space, recent advances inspired by representation disentanglement have demonstrated improved performance by separating latent features into domain-specific and domain-invariant components. We propose two novel frameworks: Disentangled Embedding through Mutual Information (DETMI) and Disentangled Embedding through Style Information (DETSI). DETMI enforces disentanglement by employing a mutual information estimator, minimizing the mutual dependence between domain-agnostic and domain-specific embeddings. DETSI, on the other hand, achieves disentanglement through style extraction and perturbation, facilitating the learning of domain-invariant and domain-specific representations. Extensive experiments on the PACS, Office-Home, and VLCS datasets show that both frameworks outperform several state-of-the-art DG techniques.},
  archive      = {J_TMLR},
  author       = {Noaman Mehmood and Kenneth Barner},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Disentangled embedding through style and mutual information for domain generalization},
  url          = {https://openreview.net/forum?id=552tedTByb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A user's guide to sampling strategies for sliced optimal transport. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ECBepTWAFG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper serves as a user's guide to sampling strategies for sliced optimal transport. We provide reminders and additional regularity results on the Sliced Wasserstein distance. We detail the construction methods, generation time complexity, theoretical guarantees, and conditions for each strategy. Additionally, we provide insights into their suitability for sliced optimal transport in theory. Extensive experiments on both simulated and real-world data offer a representative comparison of the strategies, culminating in practical recommendations for their best usage.},
  archive      = {J_TMLR},
  author       = {Keanu Sisouk and Julie Delon and Julien Tierny},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A user's guide to sampling strategies for sliced optimal transport},
  url          = {https://openreview.net/forum?id=ECBepTWAFG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riemann-lebesgue forest for regression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Gx8ujJTnG9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea in RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree (RLT) which has a chance to perform ``Lebesgue'' type cutting,i.e., splitting the node from response Y at certain non-terminal nodes. In other words, we introduce the ``splitting type randomness'' in training our ensemble method. Since the information of Y is unavailable in the prediction step, weak local models such as small random forests or decision trees are fit in non-terminal nodes with ``Lebesgue'' type cutting to determine which child node should we proceed to. We show that the optimal ``Lebesgue'' type cutting results in larger variance reduction in response Y than ordinary CART cutting (an analogue of Riemann partition) in fitting a base tree. Such property is beneficial to the ensemble part of RLF, which is verified by extensive experiments. We also establish the asymptotic normality of RLF under different parameter settings. Two one-dimensional examples are provided to illustrate the flexibility of RLF. The competitive performance of RLF with small local random forests against original random forest (RF) and boosting methods such as XGboost is demonstrated by extensive experiments in simulation data and real-world datasets. Additional experiments further illustrate that RLF with local decision trees could achieve decent performance comparable to that of RF with less running time, especially in large datasets.},
  archive      = {J_TMLR},
  author       = {Tian Qin and Wei-Min Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Riemann-lebesgue forest for regression},
  url          = {https://openreview.net/forum?id=Gx8ujJTnG9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient heterogeneous federated learning with generalized heavy-ball momentum. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LNoFjcLywb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios. However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation.},
  archive      = {J_TMLR},
  author       = {Riccardo Zaccone and Sai Praneeth Karimireddy and Carlo Masone and Marco Ciccone},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Communication-efficient heterogeneous federated learning with generalized heavy-ball momentum},
  url          = {https://openreview.net/forum?id=LNoFjcLywb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised panoptic interpretation of latent spaces in GANs using space-filling vector quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SEJatSGZX8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) learn a latent space whose samples can be mapped to real-world images. Such latent spaces are difficult to interpret. Some earlier supervised methods aim to create an interpretable latent space or discover interpretable directions, which requires exploiting data labels or annotated synthesized samples for training. However, we propose using a modification of vector quantization called space-filling vector quantization (SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture the underlying morphological structure of the latent space, making it interpretable. We apply this technique to model the latent space of pre-trained StyleGAN2 and BigGAN networks on various datasets. Our experiments show that the SFVQ curve yields a general interpretable model of the latent space such that it determines which parts of the latent space correspond to specific generative factors. Furthermore, we demonstrate that each line of the SFVQ curve can potentially refer to an interpretable direction for applying intelligible image transformations. We also demonstrate that the points located on an SFVQ line can be used for controllable data augmentation.},
  archive      = {J_TMLR},
  author       = {Mohammad Hassan Vali and Tom Bäckström},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised panoptic interpretation of latent spaces in GANs using space-filling vector quantization},
  url          = {https://openreview.net/forum?id=SEJatSGZX8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair online influence maximization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=T1NjRBI5xs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair influence maximization in networks has been actively studied to ensure equity in fields like viral marketing and public health. Existing studies often assume an offline setting, meaning that the learner identifies a set of seed nodes with known per-edge activation probabilities. In this paper, we study the problem of fair online influence maximization, i.e., without knowing the ground-truth activation probabilities. The learner in this problem aims to maximally propagate the information among demographic groups, while interactively selecting seed nodes and observing the activation feedback on the fly. We propose Fair Online Influence Maximization (FOIM) framework that can solve the online influence maximization problem under a wide range of fairness notions. Given a fairness notion, FOIM solves the problem with a combinatorial multi-armed bandit algorithm for balancing exploration-exploitation and an offline fair influence maximization oracle for seed nodes selection. FOIM enjoys sublinear regret when the fairness notion satisfies two mild conditions, i.e., monotonicity and bounded smoothness. Our analyses show that common fairness notions, including maximin fairness, diversity fairness, and welfare function, all satisfy the condition, and we prove the corresponding regret upper bounds under these notions. Extensive empirical evaluations on three real-world networks demonstrate the efficacy of our proposed framework.},
  archive      = {J_TMLR},
  author       = {Xiangqi Wang and Shaokun Zhang and Jose Efraim Aguilar Escamilla and Qingyun Wu and Xiangliang Zhang and Jian Kang and Huazheng Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fair online influence maximization},
  url          = {https://openreview.net/forum?id=T1NjRBI5xs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are convex optimization curves convex?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TZtpxselK2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study when we might expect the optimization curve induced by gradient descent to be \emph{convex} -- precluding, for example, an initial plateau followed by a sharp decrease, making it difficult to decide when optimization should stop. Although such undesirable behavior can certainly occur when optimizing general functions, might it also occur in the benign and well-studied case of smooth convex functions? As far as we know, this question has not been tackled in previous work. We show, perhaps surprisingly, that the answer crucially depends on the choice of the step size. In particular, for the range of step sizes which are known to result in monotonic convergence to an optimal value, we characterize a regime where the optimization curve will be provably convex, and a regime where the curve can be non-convex. We also extend our results to gradient flow, and to the closely-related but different question of whether the gradient norm decreases monotonically.},
  archive      = {J_TMLR},
  author       = {Guy Barzilai and Ohad Shamir and Moslem Zamani},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Are convex optimization curves convex?},
  url          = {https://openreview.net/forum?id=TZtpxselK2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution guided generative flow networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UgZIR6TF5N'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Flow Networks (GFlowNets) are a family of probabilistic generative models recently invented that learn to sample compositional objects proportional to their rewards. One big challenge of GFlowNets is training them effectively when dealing with long time horizons and sparse rewards. To address this, we propose Evolution guided generative flow networks (EGFN), a simple but powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA). Our method can work on top of any GFlowNets training objective, by training a set of agent parameters using EA, storing the resulting trajectories in the prioritized replay buffer, and training the GFlowNets agent using the stored trajectories. We present a thorough investigation over a wide range of toy and real-world benchmark tasks showing the effectiveness of our method in handling long trajectories and sparse rewards. We release the code at http://github.com/zarifikram/egfn.},
  archive      = {J_TMLR},
  author       = {Zarif Ikram and Ling Pan and Dianbo Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evolution guided generative flow networks},
  url          = {https://openreview.net/forum?id=UgZIR6TF5N},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accounting for AI and users shaping one another: The role of mathematical models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UkP4DhrJt1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI systems enter into a growing number of societal domains, these systems increasingly shape and are shaped by user preferences, opinions, and behaviors. However, the design of AI systems only sometimes accounts for how AI and users shape one another. In this survey paper, we discuss the development of formal interaction models which mathematically specify how AI and users shape one another. Formal interaction models can be leveraged to (1) specify interactions for implementation, (2) monitor interactions through empirical analysis, (3) anticipate societal impacts via counterfactual analysis, and (4) control societal impacts via interventions. The design space of formal interaction models is vast, and model design requires careful consideration of factors such as style, granularity, mathematical complexity, and measurability. Using content recommender systems as a case study, we critically examine the nascent literature of formal interaction models with respect to these use-cases and design axes. More broadly, we call for the community to leverage formal interaction models when designing, evaluating, or auditing any AI system which interacts with users.},
  archive      = {J_TMLR},
  author       = {Sarah Dean and Evan Dong and Meena Jagadeesan and Liu Leqi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Accounting for AI and users shaping one another: The role of mathematical models},
  url          = {https://openreview.net/forum?id=UkP4DhrJt1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modularity aided consistent attributed graph clustering via coarsening. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VtSIjrpFwA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is an unsupervised learning technique for partitioning graphs with attributes and detecting communities. However, current methods struggle to accurately capture true community structures and intra-cluster relations, be computationally efficient, and identify smaller communities. We address these challenges by integrating coarsening and modularity maximization, effectively leveraging both adjacency and node features to enhance clustering accuracy. We propose a loss function incorporating log-determinant, smoothness, and modularity components using a block majorization-minimization technique, resulting in superior clustering outcomes. The method is theoretically consistent under the Degree-Corrected Stochastic Block Model (DC-SBM), ensuring asymptotic error-free performance and complete label recovery. Our provably convergent and time-efficient algorithm seamlessly integrates with Graph Neural Networks (GNNs) and Variational Graph AutoEncoders (VGAEs) to learn enhanced node features and deliver exceptional clustering performance. Extensive experiments on benchmark datasets demonstrate its superiority over existing state-of-the-art methods for both attributed and non-attributed graphs.},
  archive      = {J_TMLR},
  author       = {Yukti Makhija and Samarth Bhatia and Manoj Kumar and Sandeep Kumar},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Modularity aided consistent attributed graph clustering via coarsening},
  url          = {https://openreview.net/forum?id=VtSIjrpFwA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph fourier neural ODEs: Modeling spatial-temporal multi-scales in molecular dynamics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XK7cIdj6Fz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting long-horizon molecular dynamics (MD) trajectories remains a significant challenge, as existing deep learning methods often struggle to retain fidelity over extended simulations. We hypothesize that one key factor limiting accuracy is the difficulty of capturing interactions that span distinct spatial and temporal scales—ranging from high-frequency local vibrations to low-frequency global conformational changes. To address these limitations, we propose **Graph Fourier Neural ODEs (GF-NODE)**, integrating a graph Fourier transform for spatial frequency decomposition with a Neural ODE framework for continuous-time evolution. Specifically, GF-NODE first decomposes molecular configurations into multiple spatial frequency modes using the graph Laplacian, then evolves the frequency components in time via a learnable Neural ODE module that captures both local and global dynamics, and finally reconstructs the updated molecular geometry through an inverse graph Fourier transform. By explicitly modeling high- and low-frequency phenomena in this unified pipeline, GF-NODE more effectively captures long-range correlations and local fluctuations alike. We provide theoretical insight through heat equation analysis on a simplified diffusion model, demonstrating how graph Laplacian eigenvalues can determine temporal dynamics scales, and crucially validate this correspondence through comprehensive empirical analysis on real molecular dynamics trajectories showing quantitative spatial-temporal correlations across diverse molecular systems. Experimental results on challenging MD benchmarks, including MD17 and alanine dipeptide, demonstrate that GF-NODE achieves state-of-the-art accuracy while preserving essential geometrical features over extended simulations. These findings highlight the promise of bridging spectral decomposition with continuous-time modeling to improve the robustness and predictive power of MD simulations. Our implementation is publicly available at https://github.com/FrancoTSolis/GF-NODE-code .},
  archive      = {J_TMLR},
  author       = {Fang Sun and Zijie Huang and Haixin Wang and Huacong Tang and Xiao Luo and Wei Wang and Yizhou Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph fourier neural ODEs: Modeling spatial-temporal multi-scales in molecular dynamics},
  url          = {https://openreview.net/forum?id=XK7cIdj6Fz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influential bandits: Pulling an arm may change the environment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YNKaDfYbY3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While classical formulations of multi-armed bandit problems assume that each arm's reward is independent and stationary, real-world applications often involve non-stationary environments and interdependencies between arms. In particular, selecting one arm may influence the future rewards of other arms, a scenario not adequately captured by existing models such as rotting bandits or restless bandits. To address this limitation, we propose the influential bandit problem, which models inter-arm interactions through an unknown, symmetric, positive semi-definite interaction matrix that governs the dynamics of arm losses. We formally define this problem and establish two regret lower bounds, including a superlinear $\Omega(T^2 / \log^2 T)$ bound for the standard LCB algorithm (loss minimization version of UCB) and an algorithm-independent $\Omega(T)$ bound, which highlight the inherent difficulty of the setting. We then introduce a new algorithm based on a lower confidence bound (LCB) estimator tailored to the structure of the loss dynamics. Under mild assumptions, our algorithm achieves a regret of $O(KT \log T)$, which is nearly optimal in terms of its dependence on the time horizon. The algorithm is simple to implement and computationally efficient. Empirical evaluations on both synthetic and real-world datasets demonstrate the presence of inter-arm influence and confirm the superior performance of our method compared to conventional bandit algorithms.},
  archive      = {J_TMLR},
  author       = {Ryoma Sato and Shinji Ito},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Influential bandits: Pulling an arm may change the environment},
  url          = {https://openreview.net/forum?id=YNKaDfYbY3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCas4D: Structural cascaded optimization for boosting persistent 4D novel view synthesis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YkycjbKjYP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent dynamic scene modeling for tracking and novel-view synthesis remains challenging, particularly due to the complexity of capturing accurate deformations while maintaining computational efficiency. In this paper, we present SCas4D, a novel cascaded optimization framework that leverages inherent structural patterns in 3D Gaussian Splatting (3DGS) for dynamic scenes. Our key insight is that real-world deformations often exhibit hierarchical patterns, where groups of Gaussians undergo similar transformations. By employing a structural cascaded optimization approach that progressively refines deformations from coarse part-level to fine point-level adjustments, SCas4D achieves convergence within 100 iterations per time frame while maintaining competitive quality to the state-of-the-art method with only 1/20th of the training iterations. We further demonstrate our method's effectiveness in self-supervised articulated object segmentation, establishing a natural capability from our representation. Extensive experiments demonstrate our method's effectiveness in novel view synthesis and dense point tracking tasks. Please find our project page at https://github-tree-0.github.io/SCas4D-project-page/.},
  archive      = {J_TMLR},
  author       = {Jipeng Lyu and Jiahua Dong and Yu-Xiong Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SCas4D: Structural cascaded optimization for boosting persistent 4D novel view synthesis},
  url          = {https://openreview.net/forum?id=YkycjbKjYP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy-regularized process reward model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cSxDH7N3x9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have shown promise in performing complex multi-step reasoning, yet they continue to struggle with mathematical reasoning, often making systematic errors. A promising solution is reinforcement learning (RL) guided by reward models, particularly those focusing on process rewards, which score each intermediate step rather than solely evaluating the final outcome. This approach is more effective at guiding policy models towards correct reasoning trajectories. In this work, we propose an entropy-regularized process reward model (ER-PRM) that integrates KL-regularized Markov Decision Processes (MDP) to balance policy optimization with the need to prevent the policy from shifting too far from its initial distribution. We derive a novel reward construction method based on the theoretical results. Our theoretical analysis shows that we could derive the optimal reward model from the initial policy sampling. Our empirical experiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM consistently outperforms existing process reward models, achieving 1% improvement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation, and more than 1% improvement under RLHF. These results highlight the efficacy of entropy-regularization in enhancing LLMs' reasoning capabilities.},
  archive      = {J_TMLR},
  author       = {Hanning Zhang and Pengcheng Wang and Shizhe Diao and Yong Lin and Rui Pan and Hanze Dong and Dylan Zhang and Pavlo Molchanov and Tong Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Entropy-regularized process reward model},
  url          = {https://openreview.net/forum?id=cSxDH7N3x9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed exploration in reinforcement learning from linear temporal logic. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cjK5ZvP4zZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear temporal logic (LTL) is a powerful language for task specification in reinforcement learning, as it allows describing objectives beyond the expressivity of conventional discounted return formulations. Nonetheless, recent works have shown that LTL formulas can be translated into a variable rewarding and discounting scheme, whose optimization produces a policy maximizing a lower bound on the probability of formula satisfaction. However, the synthesized reward signal remains fundamentally sparse, making exploration challenging. We aim to overcome this limitation, which can prevent current algorithms from scaling beyond low-dimensional, short-horizon problems. We show how better exploration can be achieved by further leveraging the LTL specification and casting its corresponding Limit Deterministic Büchi Automaton (LDBA) as a Markov reward process, thus enabling a form of high-level value estimation. By taking a Bayesian perspective over LDBA dynamics and proposing a suitable prior distribution, we show that the values estimated through this procedure can be treated as a shaping potential and mapped to informative intrinsic rewards. Empirically, we demonstrate applications of our method from tabular settings to high-dimensional continuous systems, which have so far represented a significant challenge for LTL-based reinforcement learning algorithms.},
  archive      = {J_TMLR},
  author       = {Marco Bagatella and Andreas Krause and Georg Martius},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Directed exploration in reinforcement learning from linear temporal logic},
  url          = {https://openreview.net/forum?id=cjK5ZvP4zZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributional reduction: Unifying dimensionality reduction and clustering with gromov-wasserstein. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cllm6SS354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction (DR) methods to project data onto lower-dimensional spaces or organizing points into meaningful clusters (clustering). In this work, we revisit these approaches under the lens of optimal transport and exhibit relationships with the Gromov-Wasserstein problem. This unveils a new general framework, called distributional reduction, that recovers DR and clustering as special cases and allows addressing them jointly within a single optimization problem. We empirically demonstrate its relevance to the identification of low-dimensional prototypes representing data at different scales, across multiple image and genomic datasets.},
  archive      = {J_TMLR},
  author       = {Hugues Van Assel and Cédric Vincent-Cuaz and Nicolas Courty and Rémi Flamary and Pascal Frossard and Titouan Vayer},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributional reduction: Unifying dimensionality reduction and clustering with gromov-wasserstein},
  url          = {https://openreview.net/forum?id=cllm6SS354},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of reinforcement learning from human feedback. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=f7OkIurx4b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning from human feedback (RLHF) is a variant of reinforcement learning (RL) that learns from human feedback instead of relying on an engineered reward function. Building on prior work on the related setting of preference-based reinforcement learning (PbRL), it stands at the intersection of artificial intelligence and human-computer interaction. This positioning provides a promising approach to enhance the performance and adaptability of intelligent systems while also improving the alignment of their objectives with human values. The success in training large language models (LLMs) has impressively demonstrated this potential in recent years, where RLHF has played a decisive role in directing the model's capabilities towards human objectives. This article provides an overview of the fundamentals of RLHF, exploring how RL agents interact with human feedback. While recent focus has been on RLHF for LLMs, our survey covers the technique across multiple domains. We provide our most comprehensive coverage in control and robotics, where many fundamental techniques originate, alongside a dedicated LLM section. We examine the core principles that underpin RLHF, how algorithms and human feedback work together, and discuss the main research trends in the field. Our goal is to give researchers and practitioners a clear understanding of this rapidly growing field.},
  archive      = {J_TMLR},
  author       = {Timo Kaufmann and Paul Weng and Viktor Bengs and Eyke Hüllermeier},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey of reinforcement learning from human feedback},
  url          = {https://openreview.net/forum?id=f7OkIurx4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seeing beyond labels: Source-free domain adaptation via hypothesis consolidation of prediction rationale. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fywo0eRzAu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Unsupervised Domain Adaptation (SFUDA) is a challenging task where a model needs to be adapted to a new domain without access to target domain labels or source domain data. The primary difficulty in this task is that the model's predictions may be inaccurate, and using these inaccurate predictions for model adaptation can lead to misleading results. To address this issue, this paper proposes a novel approach that considers multiple prediction hypotheses for each sample and investigates the rationale behind each hypothesis. By consolidating these hypothesis rationales, we identify the most likely correct hypotheses, which we then use as a pseudo-labeled set to support a semi-supervised learning procedure for model adaptation. This approach distinguishes itself from conventional semi-supervised learning by relying solely on pseudo-labels rather than ground-truth annotations. To achieve the optimal performance, we propose a three-step adaptation process: model pre-adaptation, hypothesis consolidation, and semi-supervised learning. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance in the SFUDA task and can be easily integrated into existing approaches to improve their performance. The codes are available at \url{https://github.com/GANPerf/HCPR}.},
  archive      = {J_TMLR},
  author       = {Yangyang Shu and Yuhang Liu and Xiaofeng Cao and Qi Chen and Bowen Zhang and Ziqin Zhou and Anton van den Hengel and Lingqiao Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Seeing beyond labels: Source-free domain adaptation via hypothesis consolidation of prediction rationale},
  url          = {https://openreview.net/forum?id=fywo0eRzAu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of state representation learning for deep reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gOk34vUHtz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning methods are an important tool for addressing the challenges posed by complex observations spaces in sequential decision making problems. Recently, many methods have used a wide variety of types of approaches for learning meaningful state representations in reinforcement learning, allowing better sample efficiency, generalization, and performance. This survey aims to provide a broad categorization of these methods within a model-free online setting, exploring how they tackle the learning of state representations differently. We categorize the methods into six main classes, detailing their mechanisms, benefits, and limitations. Through this taxonomy, our aim is to enhance the understanding of this field and provide a guide for new researchers. We also discuss techniques for assessing the quality of representations, and detail relevant future directions.},
  archive      = {J_TMLR},
  author       = {Ayoub Echchahed and Pablo Samuel Castro},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey of state representation learning for deep reinforcement learning},
  url          = {https://openreview.net/forum?id=gOk34vUHtz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying generative and dense retrieval for sequential recommendation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jxdnFIsjCb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential dense retrieval models utilize advanced sequence learning techniques to compute item and user representations, which are then used to rank relevant items for a user through inner product computation between the user and all item representations. While effective, these approaches incur high memory and computational costs due to the need to store and compare a unique embedding for each item--leading to lower resource efficiency. In contrast, the recently proposed generative retrieval paradigm offers a promising alternative by directly predicting item indices using a generative model trained on semantic IDs that encapsulate items’ semantic information. Despite its potential for large-scale applications, a comprehensive comparison between generative retrieval and sequential dense retrieval under fair conditions is still lacking, leaving open questions regarding performance and resource efficiency trade-offs. To address this, we compare these two approaches under controlled conditions on academic benchmarks and observe performance gaps, with dense retrieval showing stronger ranking performance, while generative retrieval provides greater resource efficiency. Motivated by these observations, we propose LIGER (LeveragIng dense retrieval for GEnerative Retrieval), a hybrid model that combines the strengths of these two widely used approaches. LIGER integrates sequential dense retrieval into generative retrieval, mitigating performance differences between the two methods, and enhancing cold-start item recommendation in the evaluated datasets. This hybrid approach provides insight into the trade-offs between these approaches and demonstrates improvements in efficiency and effectiveness for recommendation systems in small-scale benchmarks.},
  archive      = {J_TMLR},
  author       = {Liu Yang and Fabian Paischer and Kaveh Hassani and Jiacheng Li and Shuai Shao and Zhang Gabriel Li and Yun He and Xue Feng and Nima Noorshams and Sem Park and Bo Long and Robert D Nowak and Xiaoli Gao and Hamid Eghbalzadeh},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unifying generative and dense retrieval for sequential recommendation},
  url          = {https://openreview.net/forum?id=jxdnFIsjCb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMMA: Efficient visual alignment in multi-modal LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lbrO3bGpeO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Large Language Models (MLLMs) have recently exhibited impressive general- purpose capabilities by leveraging vision foundation models to encode the core concepts of images into representations. These are then combined with instructions and processed by the language model to generate high-quality responses. Despite significant progress in enhancing the language component, challenges persist in optimally fusing visual encodings within the language model for task-specific adaptability. Recent research has focused on improving this fusion through modality adaptation modules but at the cost of significantly increased model complexity and training data needs. In this paper, we propose EMMA (Efficient Multi-Modal Adaptation), a lightweight cross-modality module designed to efficiently fuse visual and textual encodings, generating instruction-aware visual representations for the language model. Our key contributions include: (1) an efficient early fusion mechanism that integrates vision and language representations with minimal added parameters (less than 0.2% increase in model size), (2) an in-depth interpretability analysis that sheds light on the internal mechanisms of the proposed method; (3) comprehensive experiments that demonstrate notable improvements on both specialized and general benchmarks for MLLMs. Empirical results show that EMMA boosts performance across multiple tasks by up to 9.3% while significantly improving robustness against hallucinations.},
  archive      = {J_TMLR},
  author       = {Sara Ghazanfari and Alexandre Araujo and Prashanth Krishnamurthy and Siddharth Garg and Farshad Khorrami},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {EMMA: Efficient visual alignment in multi-modal LLMs},
  url          = {https://openreview.net/forum?id=lbrO3bGpeO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic polynomial expansion for uncertainty propagation through networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lyDRBhUjhv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network-based machine learning constructs are becoming more prevalent in sensing and decision-making systems. As these systems are implemented in safety-critical environments such as pedestrian detection and power management, it is crucial to evaluate confidence in their decisions. At the heart of this problem is a need to understand and characterize how errors at the input of networks become progressively expanded or contracted as signals move through layers, especially in light of the non-trivial nonlinearities manifest throughout modern machine learning architectures. When sampling methods become expensive due to network size or complexity, approximation is needed and popular methods include Jacobian (first order Taylor) linearization and stochastic linearization. However, despite computational tractability, the accuracy of these methods can break down in situations with moderate to high input uncertainty. Here, we present a generalized method of propagating variational multivariate Gaussian distributions through neural networks. We propose a modified Taylor expansion function for nonlinear transformation of Gaussian distributions, with an additional approximation in which the polynomial terms act on independent Gaussian random variables (which are identically distributed). With these approximated higher order terms (HOTs), we obtain significantly more accurate estimation of layer-wise distributions. Despite the introduction of the HOTs, this method can propagate a full covariance matrix with a complexity of $\boldsymbol{O}(n^2)$ (and $\boldsymbol{O}(n)$ if only propagating marginal variance), comparable to Jacobian linearization. Thus, our method finds a balance between efficiency and accuracy. We derived the closed form solutions for this approximate Stochastic Taylor expansion for seven commonly used nonlinearities and verified the effectiveness of our method in deep residual neural networks, Bayesian neural networks, and variational autoencoders. This general method can be integrated into use-cases such as Kalman filtering, adversarial training, and variational learning.},
  archive      = {J_TMLR},
  author       = {Songhan Zhang and ShiNung Ching},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A stochastic polynomial expansion for uncertainty propagation through networks},
  url          = {https://openreview.net/forum?id=lyDRBhUjhv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UnSTAR: Unlearning with self-taught anti-sample reasoning for LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mNXCViKZbI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data-samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. Although token based anti-samples have been previously introduced (Eldan & Russinovich (2023)), the use of reasoning-driven anti-samples—constructed with falsified answers and misleading rationales—remains unexplored. In this paper, we introduce UnStar: Unlearning with SelfTaught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold: first, we propose a novel concept of reasoning-based anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge—something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.},
  archive      = {J_TMLR},
  author       = {Yash Sinha and Murari Mandal and Mohan Kankanhalli},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {UnSTAR: Unlearning with self-taught anti-sample reasoning for LLMs},
  url          = {https://openreview.net/forum?id=mNXCViKZbI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InkSight: Offline-to-online handwriting conversion by teaching vision-language models to read and write. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pSyUfV5BqA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in a vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice that is still favored by a vast majority. Our work InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore, it generalizes beyond its training domain into simple sketches. Our human evaluation reveals that 87% of the samples produced by our model on the challenging HierText dataset are considered as a valid tracing of the input image and 67% look like a pen trajectory traced by a human.},
  archive      = {J_TMLR},
  author       = {Blagoj Mitrevski and Arina Rak and Julian Schnitzler and Chengkun Li and Andrii Maksai and Jesse Berent and Claudiu Cristian Musat},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {InkSight: Offline-to-online handwriting conversion by teaching vision-language models to read and write},
  url          = {https://openreview.net/forum?id=pSyUfV5BqA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling channel-adaptive self-supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pT8sgtRVAf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in self-supervised pre-training of foundation models for natural images have made them a popular choice for various visual systems and applications. Self-supervised strategies are also promising in non-RGB scientific imaging domains such as in biology, medical and satellite imagery, but their broader application is hampered by heterogeneity in channel composition and semantics between relevant datasets: two datasets may contain different numbers of channels, and these may reveal distinct aspects of an object or scene. Recent works on channel adaptive strategies report substantial advantages for those that account for variable channel compositions without sacrificing the ability to jointly encode channels; yet, how these strategies behave at scale remains unclear. We here show that, surprisingly, trained across large-scale datasets, independent-encoding of channels outperforms joint-encoding methods by a substantial margin. We validate this result along an extensive set of experiments on various datasets from cell microscopy to geospatial imagery. Our DINO BoC approach sets a new state-of-the-art across challenging benchmarks, including generalization to out-of-distribution tasks and unseen channel combinations at test time. We will open source the code, along with model weights that constitute a new general purpose feature extractor for fluorescent microscopy.},
  archive      = {J_TMLR},
  author       = {Alice V. De Lorenci and Seung Eun Yi and Théo Moutakanni and Piotr Bojanowski and Camille Couprie and Juan C. Caicedo and Wolfgang Maximilian Anton Pernice},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scaling channel-adaptive self-supervised learning},
  url          = {https://openreview.net/forum?id=pT8sgtRVAf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture of cache-conditional experts for efficient mobile device inference. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ul4W26KEKz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture of Experts (MoE) LLMs enhance performance by selectively activating specialized subnetworks ("experts") per input. While MoEs offer efficiency benefits through distributed inference in typical high-throughput settings, deploying them on memory-constrained devices remains challenging, particularly for sequential token generation with batch size one. In this work, we optimize MoE for such constrained environments, where only a subset of expert weights fit into DRAM. Through empirical analysis, we show MoEs can tolerate careful deviations in expert selection with minimal predictive performance loss. Inspired by this observation, we propose a novel cache-aware routing strategy that leverages expert reuse during token generation to significantly improve cache locality. Evaluating on language modeling, MMLU, and GSM8K benchmarks, our method reduces cache miss rates by over 50%, with negligible impact on perplexity (0.1%–3%) and downstream task accuracy (<0.1%). Unlike prior methods limited by the optimal oracle cache bound, our approach surpasses this theoretical limit by allowing slight flexibility in expert selection. Finally, we present on-device results demonstrating 2$\times$ speedups on mobile hardware, offering a flexible and training-free solution to extend MoE's applicability across real-world applications.},
  archive      = {J_TMLR},
  author       = {Andrii Skliar and Ties van Rozendaal and Romain Lepert and Todor Boinovski and Mart Van Baalen and Markus Nagel and Paul N. Whatmough and Babak Ehteshami Bejnordi},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture of cache-conditional experts for efficient mobile device inference},
  url          = {https://openreview.net/forum?id=ul4W26KEKz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive clipping for differential private federated learning in interpolation regimes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vvSHlH3a8V'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate improving the utility of standard differential private optimization algorithms by adaptively determining the clipping radius in federated learning. Our adaptive clipping radius is based on the root-mean-square of the gradient norms, motivated by the interpolation property and smoothness of the objectives. In addition to Renyi Differential Privacy (RDP) analysis, we conduct theoretical utility analysis of the proposed algorithm, showing that our method enhances utility compared to DP-SGD for smooth and non-strongly convex objectives. Numerical experiments confirm the superiority of our adaptive clipping algorithm over standard DP optimization with fixed clipping radius in federated learning settings.},
  archive      = {J_TMLR},
  author       = {Takumi Fukami and Tomoya Murata and Kenta Niwa},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive clipping for differential private federated learning in interpolation regimes},
  url          = {https://openreview.net/forum?id=vvSHlH3a8V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRA: Better length generalisation with threshold relative attention. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yNiBUc2hMW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers struggle with length generalisation, displaying poor performance even on basic tasks. We test whether these limitations can be explained through two key failures of the self-attention mechanism. The first is the inability to fully remove irrelevant information. The second is tied to position, even if the dot product between a key and query is highly negative (i.e. an irrelevant key) learned positional biases may unintentionally up-weight such information - dangerous when distances become out of distribution. Put together, these two failure cases lead to compounding generalisation difficulties. We test whether they can be mitigated through the combination of a) selective sparsity - completely removing irrelevant keys from the attention softmax and b) contextualised relative distance - distance is only considered as between the query and the keys that matter. We show how refactoring the attention mechanism with these two mitigations in place can substantially improve generalisation capabilities of decoder only transformers.},
  archive      = {J_TMLR},
  author       = {Mattia Opper and Roland Fernandez and Paul Smolensky and Jianfeng Gao},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TRA: Better length generalisation with threshold relative attention},
  url          = {https://openreview.net/forum?id=yNiBUc2hMW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disobeying directions: Switching random walk filters for unsupervised node embedding learning on directed graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yngjRgVA5A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised learning of node embeddings for directed graphs (digraphs) requires careful handling to ensure unbiased modelling. This paper addresses two key challenges: (1) the obstruction of information propagation in random walk and message-passing methods due to local sinks, and (2) the representation of multiple multi-step directed neighbourhoods, arising from the distinction between in- and out-neighbours. These challenges are interconnected—local sinks can be mitigated by treating the graph as undirected, but this comes at the cost of discarding all directional information. We make two main contributions to unsupervised embedding learning for digraphs. First, we introduce ReachNEs (Reachability Node Embeddings), a general framework for analysing embedding models and diagnosing local sink behaviour on digraphs. ReachNEs defines the reachability filter, a matrix polynomial over normalized adjacency matrices that captures multi-step, direction-sensitive proximity. It unifies the analysis of message-passing and random walk models, making its insights applicable across a wide range of embedding methods. Second, we propose DirSwitch, a novel embedding model that resolves both local sink bias and neighbourhood multiplicity via switching random walks. These walks use directed edges for local steps, preserving directional structure, then switch to undirected edges for long-range transitions, enabling escape from local sinks and improving information dispersal. Empirical results on node classification benchmarks demonstrate that DirSwitch consistently outperforms state-of-the-art unsupervised digraph proximity embedding methods, and also serves as a flexible digraph extension for self-supervised graph neural networks.},
  archive      = {J_TMLR},
  author       = {Ciwan Ceylan and Kambiz Ghoorchian and Danica Kragic},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Disobeying directions: Switching random walk filters for unsupervised node embedding learning on directed graphs},
  url          = {https://openreview.net/forum?id=yngjRgVA5A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and reducing the class-dependent effects of data augmentation with a two-player game approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zNsfgCns7x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over five datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.},
  archive      = {J_TMLR},
  author       = {Yunpeng Jiang and Yutong Ban and Paul Weng},
  journal      = {Transactions on Machine Learning Research},
  month        = {6},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding and reducing the class-dependent effects of data augmentation with a two-player game approach},
  url          = {https://openreview.net/forum?id=zNsfgCns7x},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing cycle life prediction of lithium-ion batteries via a physics-informed model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1weZ9Wsajk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately measuring the cycle lifetime of commercial lithium-ion batteries is crucial for performance and technology development. We introduce a novel hybrid approach combining a physics-based equation with a self-attention model to predict the cycle lifetimes of commercial lithium iron phosphate graphite cells via early-cycle data. After fitting capacity loss curves to this physics-based equation, we then use a self-attention layer to reconstruct entire battery capacity loss curves. Our model exhibits comparable performances to existing models while predicting more information: the entire capacity loss curve instead of cycle life. This provides more robustness and interpretability: our model does not need to be retrained for a different notion of end-of-life and is backed by physical intuition.},
  archive      = {J_TMLR},
  author       = {Nathan Sun and Daniel Nicolae and Sara Sameer and Karena Yan},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimizing cycle life prediction of lithium-ion batteries via a physics-informed model},
  url          = {https://openreview.net/forum?id=1weZ9Wsajk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-myopic multi-objective bayesian optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2e1aZZd88C'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of finite-horizon sequential experimental design to solve multi-objective optimization (MOO) of expensive black-box objective functions. This problem arises in many real-world applications, including materials design, where we have a small resource budget to make and evaluate candidate materials in the lab. We solve this problem using the framework of Bayesian optimization (BO) and propose the first set of non-myopic methods for MOO problems. Prior work on non-myopic BO for single-objective problems relies on the Bellman optimality principle to handle the lookahead reasoning process. However, this principle does not hold for most MOO problems because the reward function needs to satisfy some conditions: scalar variable, monotonicity, and additivity. We address this challenge by using hypervolume improvement (HVI) as our scalarization approach, which allows us to use a lower-bound on the Bellman equation to approximate the finite-horizon using a batch expected hypervolume improvement (EHVI) acquisition function (AF) for MOO. Our formulation naturally allows us to use other improvement-based scalarizations and compare their efficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF, which is based on the exact computation of the lower bound, 2) the Joint AF, which is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast and approximate variant based on batch multi-objective acquisition functions. Our experiments on multiple diverse real-world MO problems demonstrate that our non-myopic AFs substantially improve performance over the existing myopic AFs for MOBO.},
  archive      = {J_TMLR},
  author       = {Syrine Belakaria and Alaleh Ahmadian and Barbara E Engelhardt and Stefano Ermon and Jana Doppa},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Non-myopic multi-objective bayesian optimization},
  url          = {https://openreview.net/forum?id=2e1aZZd88C},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging unlabeled data sharing through kernel function approximation in offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=78N9tCL6Ly'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) learns policies from a fixed dataset, but often requires large amounts of data. The challenge arises when labeled datasets are expensive, especially when rewards have to be provided by human labelers for large datasets. In contrast, unlabelled data tends to be less expensive. This situation highlights the importance of finding effective ways to use unlabelled data in offline RL, especially when labelled data is limited or expensive to obtain. In this paper, we present the algorithm to utilize the unlabeled data in the offline RL method with kernel function approximation and give the theoretical guarantee. We present various eigenvalue decay conditions of $\mathcal{H}_k$ which determine the complexity of the algorithm. In summary, our work provides a promising approach for exploiting the advantages offered by unlabeled data in offline RL, whilst maintaining theoretical assurances.},
  archive      = {J_TMLR},
  author       = {Yen Ru Lai and Fu-Chieh Chang and Pei-Yuan Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging unlabeled data sharing through kernel function approximation in offline reinforcement learning},
  url          = {https://openreview.net/forum?id=78N9tCL6Ly},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System-aware neural ODE processes for few-shot bayesian optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FFnRLvWefK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing initial conditions and termination time in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and the state's value can not be measured in real-time but only with a delay while the measuring device processes the sample. To identify the optimal conditions in limited trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information. At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block. We further develop a two-stage BO framework to effectively incorporate search space constraints, enabling efficient optimization of both initial conditions and observation timings. We conduct extensive experiments showcasing SANODEP's potential for few-shot BO within dynamical systems. We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy.},
  archive      = {J_TMLR},
  author       = {Jixiang Qing and Rebecca D. Langdon and Robert Matthew Lee and Behrang Shafei and Mark van der Wilk and Calvin Tsay and Ruth Misener},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {System-aware neural ODE processes for few-shot bayesian optimization},
  url          = {https://openreview.net/forum?id=FFnRLvWefK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deflated dynamics value iteration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IbQTE24aZw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Value Iteration (VI) algorithm is an iterative procedure to compute the value function of a Markov decision process, and is the basis of many reinforcement learning (RL) algorithms as well. As the error convergence rate of VI as a function of iteration $k$ is $O(\gamma^k)$, it is slow when the discount factor $\gamma$ is close to $1$. To accelerate the computation of the value function, we propose Deflated Dynamics Value Iteration (DDVI). DDVI uses matrix splitting and matrix deflation techniques to effectively remove (deflate) the top $s$ dominant eigen-structure of the transition matrix $\mathcal{P}^\pi$. We prove that this leads to a $\tilde{O}(\gamma^k |\lambda_{s+1}|^k)$ convergence rate, where $\lambda_{s+1}$ is the $(s+1)$-th largest eigenvalue of the dynamics matrix. We also extend DDVI to the RL setting and present Deflated Dynamics Temporal Difference (DDTD) algorithm. We empirically show the effectiveness of the proposed algorithms.},
  archive      = {J_TMLR},
  author       = {Jongmin Lee and Amin Rakhsha and Ernest K. Ryu and Amir-massoud Farahmand},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deflated dynamics value iteration},
  url          = {https://openreview.net/forum?id=IbQTE24aZw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized layer selection for graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JyjTJAG9yZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) combine node attributes over a fixed granularity of the local graph structure around a node to predict its label. However, different nodes may relate to a node-level property with a different granularity of its local neighborhood, and using the same level of smoothing for all nodes can be detrimental to their classification. In this work, we challenge the common fact that a single GNN layer can classify all nodes of a graph by training GNNs with a distinct personalized layer for each node. Inspired by metric learning, we propose a novel algorithm, MetSelect, to select the optimal representation layer to classify each node. In particular, we identify a prototype representation of each class in a transformed GNN layer and then, classify using the layer where the distance is smallest to a class prototype after normalizing with that layer’s variance. Results on 10 datasets and 3 different GNNs show that we significantly improve the node classification accuracy of GNNs in a plug-and-play manner. We also find that using variable layers for prediction enables GNNs to be deeper and more robust to poisoning attacks. We hope this work can inspire future works to learn more adaptive and personalized graph representations.},
  archive      = {J_TMLR},
  author       = {Kartik Sharma and Vineeth Rakesh and Yingtong Dou and Srijan Kumar and Mahashweta Das},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized layer selection for graph neural networks},
  url          = {https://openreview.net/forum?id=JyjTJAG9yZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized prediction set with bandit feedback. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VlwqIz41Hp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-stakes environments where uncertainties abound, set-valued prediction offers a cautious and robust mechanism by presenting multiple potential labels as the prediction for each test instance to mitigate the potential risk associated with prediction errors. Yet, integrating this paradigm with out-of-distribution (OOD) detection remains scarcely explored in such settings as online learning with bandit feedback. The bandit feedback mechanism informs the learner about the correctness of the pulled arm/action instead of the explicit ground truth label, leaving the true class label unknown when an incorrect action is taken. To address this challenge, we introduce BanditGPS which conducts set-valued prediction with OOD detection in the bandit feedback setting, using an estimation to the ground truth of class labels. BanditGPS achieves three objectives: render small/informative prediction sets, enhance the OOD detection performance, and control the recall for all normal classes to meet prescribed requirements. Our approach is characterized by the loss function, which trades off between high OOD detection and small prediction sets. Theoretically, we prove that the convergence rate of the regret is $\tilde{\mathcal{O}}(T^{-1/2})$. The empirical results further show that BanditGPS effectively controls the recalls with promising performances on OOD detection and informative prediction.},
  archive      = {J_TMLR},
  author       = {Zhou Wang and Xingye Qiao},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized prediction set with bandit feedback},
  url          = {https://openreview.net/forum?id=VlwqIz41Hp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeNIe: Generative hard negative images through diffusion. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VuLEOyTiPO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation is crucial in training deep models, preventing them from overfitting to limited data. Recent advances in generative AI, e.g., diffusion models, have enabled more sophisticated augmentation techniques that produce data resembling natural images. We introduce $\texttt{GeNIe}$ a novel augmentation method which leverages a latent diffusion model conditioned on a text prompt to combine two contrasting data points (an image from the source category and a text prompt from the target category) to generate challenging augmentations. To achieve this, we adjust the noise level (equivalently, number of diffusion iterations) to ensure the generated image retains low-level and background features from the source image while representing the target category, resulting in a hard negative sample for the source category. We further automate and enhance $\texttt{GeNIe}$ by adaptively adjusting the noise level selection on a per image basis (coined as $\texttt{GeNIe-Ada}$), leading to further performance improvements. Our extensive experiments, in both few-shot and long-tail distribution settings, demonstrate the effectiveness of our novel augmentation method and its superior performance over the prior art. Our code is available at https://github.com/UCDvision/GeNIe.},
  archive      = {J_TMLR},
  author       = {Soroush Abbasi Koohpayegani and Anuj Singh and Navaneet K L and Hamed Pirsiavash and Hadi J. Rad},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GeNIe: Generative hard negative images through diffusion},
  url          = {https://openreview.net/forum?id=VuLEOyTiPO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When SNN meets ANN: Error-free ANN-to-SNN conversion for extreme edge efficiency. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WOwQKguWT0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNN) are now demonstrating comparable accuracy to convolutional neural networks (CNN), thanks to advanced ANN-to-SNN conversion techniques, all while delivering remarkable energy and latency efficiency when deployed on neuromorphic hardware. However, these conversion techniques incur a large number of time steps, and consequently, high spiking activity. In this paper, we propose a novel ANN-to-SNN conversion framework, that incurs an exponentially lower number of time steps compared to that required in the existing conversion approaches. Our framework modifies the standard integrate-and-fire (IF) neuron model used in SNNs with no change in computational complexity and shifts the bias term of each batch normalization (BN) layer in the trained ANN. To reduce spiking activity, we propose training the source ANN with a fine-grained $\ell_1$ regularizer with surrogate gradients that encourages high spike sparsity in the converted SNN. Our proposed framework thus yields lossless SNNs with low latency, low compute energy, thanks to the low time steps and high spike sparsity, and high test accuracy, for example, $75.12$% with only $4$ time steps on the ImageNet dataset. Codes will be made available. Code is available at https://github.com/godatta/SNN_meets_ANN.},
  archive      = {J_TMLR},
  author       = {Gourav Datta and Zeyu Liu and James Diffenderfer and Bhavya Kailkhura and Peter Anthony Beerel},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When SNN meets ANN: Error-free ANN-to-SNN conversion for extreme edge efficiency},
  url          = {https://openreview.net/forum?id=WOwQKguWT0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HyperVQ: MLR-based vector quantization in hyperbolic space. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WgJgIULL9Q'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of models operating on tokenized data has heightened the need for effective tokenization methods, particularly in vision and auditory tasks where inputs are naturally continuous. A common solution is to employ Vector Quantization (VQ) within VQ Variational Autoencoders (VQVAEs), transforming inputs into discrete tokens by clustering embeddings in Euclidean space. However, Euclidean embeddings not only suffer from inefficient packing and limited separation—due to their polynomial volume growth—but are also prone to codebook collapse, where only a small subset of codebook vectors are effectively utilized. To address these limitations, we introduce HyperVQ, a novel approach that formulates VQ as a hyperbolic Multinomial Logistic Regression (MLR) problem, leveraging the exponential volume growth in hyperbolic space to mitigate collapse and improve cluster separability. Additionally, HyperVQ represents codebook vectors as geometric representatives of hyperbolic decision hyperplanes, encouraging disentangled and robust latent representations. Our experiments demonstrate that HyperVQ matches traditional VQ in generative and reconstruction tasks, while surpassing it in discriminative performance and yielding a more efficient and disentangled codebook.},
  archive      = {J_TMLR},
  author       = {Nabarun Goswami and Yusuke Mukuta and Tatsuya Harada},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HyperVQ: MLR-based vector quantization in hyperbolic space},
  url          = {https://openreview.net/forum?id=WgJgIULL9Q},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating continual pretraining in large language models: Insights and implications. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aKjJoEVKgO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning (CL) in large language models (LLMs) is an evolving domain that focuses on developing efficient and sustainable training strategies to adapt models to emerging knowledge and achieve robustness in dynamic environments. Our primary emphasis is on continual domain-adaptive pretraining, a process designed to equip LLMs with the ability to integrate new information from various domains while retaining previously learned knowledge. Since existing works concentrate mostly on continual fine-tuning for a limited selection of downstream tasks or training domains, we introduce a new benchmark designed to measure the adaptability of LLMs to changing pretraining data landscapes. We further examine the impact of model size on learning efficacy and forgetting, as well as how the progression and similarity of emerging domains affect the knowledge transfer within these models. Our findings uncover several key insights: (i) continual pretraining consistently improves <1.5B models studied in this work and is also superior to domain adaptation, (ii) larger models always achieve better perplexity than smaller ones when continually pretrained on the same corpus, (iii) smaller models are particularly sensitive to continual pretraining, showing the most significant rates of both learning and forgetting, (iv) continual pretraining boosts downstream task performance of GPT-2 family, (v) continual pretraining enables LLMs to specialize better when the sequence of domains shows semantic similarity while randomizing training domains leads to better transfer and final performance otherwise. We posit that our research establishes a new benchmark for CL in LLMs, providing a more realistic evaluation of knowledge retention and transfer across diverse domains.},
  archive      = {J_TMLR},
  author       = {Çağatay Yıldız and Nishaanth Kanna Ravichandran and Nitin Sharma and Matthias Bethge and Beyza Ermis},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Investigating continual pretraining in large language models: Insights and implications},
  url          = {https://openreview.net/forum?id=aKjJoEVKgO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural deconstruction search for vehicle routing problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bCmEP1Ltwq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive construction approaches generate solutions to vehicle routing problems in a step-by-step fashion, leading to high-quality solutions that are nearing the performance achieved by handcrafted operations research techniques. In this work, we challenge the conventional paradigm of sequential solution construction and introduce an iterative search framework where solutions are instead deconstructed by a neural policy. Throughout the search, the neural policy collaborates with a simple greedy insertion algorithm to rebuild the deconstructed solutions. Our approach matches or surpasses the performance of state-of-the-art operations research methods across three challenging vehicle routing problems of various problem sizes.},
  archive      = {J_TMLR},
  author       = {André Hottung and Paula Wong-Chung and Kevin Tierney},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural deconstruction search for vehicle routing problems},
  url          = {https://openreview.net/forum?id=bCmEP1Ltwq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph theory-based deep graph similarity learning: A unified survey of pipeline, techniques, and challenges. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fHf4jbIfex'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph similarity computation, which measures the resemblance between graphs, is a crucial operation in fields such as graph search. Recent advances in graph neural networks have enabled the embedding of graphs into low-dimensional vector spaces, where the sim- ilarity or distance between graphs can be efficiently quantified. However, these methods are often tailored to specific tasks and function as black boxes, limiting both generalization and interpretability. To address these challenges, there is growing interest in incorporating domain-agnostic and interpretable concepts from graph theory—such as subgraph isomorphism, maximum common subgraph, and graph edit distance—into graph similarity learning as training objectives. This survey presents a comprehensive review of recent advancements in deep graph similarity learning, focusing on models that integrate these graph theory concepts. Despite the different training objectives of these approaches, they share significant commonalities in the training pipeline, techniques, and challenges. We analyze them within a unified lens referred to as graph theory-based deep similarity learning (GTDGSL) methods. We systematically compare existing GTDGSL methods alongside their common training pipeline, highlighting the technique trend and discussing key challenges, applications, and future research directions in this domain. We organize the papers included in this survey and their open-source implementations at https://github.com/liuzhouyang/Graph-Theory-Based-Deep-Graph-Similarity-Learning-Survey.},
  archive      = {J_TMLR},
  author       = {Zhouyang LIU and Ning Liu and Yixin Chen and Ziqing Wen and Jiezhong He and Dongsheng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph theory-based deep graph similarity learning: A unified survey of pipeline, techniques, and challenges},
  url          = {https://openreview.net/forum?id=fHf4jbIfex},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASTRA: A scene-aware transformer-based model for trajectory prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fqSVqPcaVi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present ASTRA (A Scene-aware Transformer-based model for trajectory prediction), a light-weight pedestrian trajectory forecasting model that integrates the scene context, spatial dynamics, social inter-agent interactions and temporal progressions for precise forecasting. We utilised a U-Net-based feature extractor, via its latent vector representation, to capture scene representations and a graph-aware transformer encoder for capturing social interactions. These components are integrated to learn an agent-scene aware embedding, enabling the model to learn spatial dynamics and forecast the future trajectory of pedestrians. The model is designed to produce both deterministic and stochastic outcomes, with the stochastic predictions being generated by incorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also proposes a simple yet effective weighted penalty loss function, which helps to yield predictions that outperform a wide array of state-of-the-art deterministic and generative models. ASTRA demonstrates an average improvement of 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26% improvement on the PIE dataset, respectively, along with seven times fewer parameters than the existing state-of-the-art model (see Figure 1). Additionally, the model's versatility allows it to generalize across different perspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).},
  archive      = {J_TMLR},
  author       = {Izzeddin Teeti and Aniket Thomas and Munish Monga and Sachin Kumar Giroh and Uddeshya Singh and Andrew Bradley and Biplab Banerjee and Fabio Cuzzolin},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ASTRA: A scene-aware transformer-based model for trajectory prediction},
  url          = {https://openreview.net/forum?id=fqSVqPcaVi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is what you ask for what you get? investigating concept associations in text-to-image models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mk1YIkVvTQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image (T2I) models are increasingly used in impactful real-life applications. As such, there is a growing need to audit these models to ensure that they generate desirable, task-appropriate images. However, systematically inspecting the associations between prompts and generated content in a human-understandable way remains challenging. To address this, we propose \emph{Concept2Concept}, a framework where we characterize conditional distributions of vision language models using interpretable concepts and metrics that can be defined in terms of these concepts. This characterization allows us to use our framework to audit models and prompt-datasets. To demonstrate, we investigate several case studies of conditional distributions of prompts, such as user-defined distributions or empirical, real-world distributions. Lastly, we implement Concept2Concept as an open-source interactive visualization tool to facilitate use by non-technical end-users. A demo is available at https://tinyurl.com/Concept2ConceptDemo. Warning: This paper contains discussions of harmful content, including CSAM and NSFW material, which may be disturbing to some readers.},
  archive      = {J_TMLR},
  author       = {Salma Abdel Magid and Weiwei Pan and Simon Warchol and Grace Guo and Junsik Kim and Mahia Rahman and Hanspeter Pfister},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Is what you ask for what you get? investigating concept associations in text-to-image models},
  url          = {https://openreview.net/forum?id=mk1YIkVvTQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on LLM test-time compute via search: Tasks, LLM profiling, search algorithms, and relevant frameworks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=x9VQFjtOPS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LLM test-time compute (or LLM inference) via search has emerged as a promising research area with rapid developments. However, current frameworks often adopt distinct perspectives on three key aspects—task definition, LLM profiling, and search procedures—making direct comparisons challenging. Moreover, the search algorithms employed often diverge from standard implementations, and their specific characteristics are not thoroughly specified. This survey aims to provide a comprehensive but integrated technical review on existing LIS frameworks. Specifically, we unify task definitions under Markov Decision Process (MDP) and provides modular definitions of LLM profiling and search procedures. The definitions enable precise comparisons of various LLM inference frameworks while highlighting their departures from conventional search algorithms. We also discuss the applicability, performance, and efficiency of these methods. For ongoing paper updates, please refer to our GitHub repository: https://github.com/xinzhel/LLM-Search.},
  archive      = {J_TMLR},
  author       = {Xinzhe Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on LLM test-time compute via search: Tasks, LLM profiling, search algorithms, and relevant frameworks},
  url          = {https://openreview.net/forum?id=x9VQFjtOPS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational stochastic gradient descent for deep neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xu4ATNjcdy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing deep neural networks is one of the main tasks in successful deep learning. Current state-of-the-art optimizers are adaptive gradient-based optimization methods such as Adam. Recently, there has been an increasing interest in formulating gradient-based optimizers in a probabilistic framework for better modeling the uncertainty of the gradients. Here, we propose to combine both approaches, resulting in the Variational Stochastic Gradient Descent (VSGD) optimizer. We model gradient updates as a probabilistic model and utilize stochastic variational inference (SVI) to derive an efficient and effective update rule. Further, we show how our VSGD method relates to other adaptive gradient-based optimizers like Adam. Lastly, we carry out experiments on two image classification datasets and four deep neural network architectures, where we show that VSGD outperforms Adam and SGD.},
  archive      = {J_TMLR},
  author       = {Anna Kuzina and Haotian Chen and Babak Esmaeili and Jakub M. Tomczak},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational stochastic gradient descent for deep neural networks},
  url          = {https://openreview.net/forum?id=xu4ATNjcdy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating symbolic world models via test-time scaling of large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zVo6PfBa0K'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality—a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domains, achieving over 50% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform the current state-of-the-art methods on almost all competition-level planning tasks.},
  archive      = {J_TMLR},
  author       = {Zhouliang Yu and Yuhuan Yuan and Tim Z. Xiao and Fuxiang Frank Xia and Jie Fu and Ge Zhang and Ge lin and Weiyang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generating symbolic world models via test-time scaling of large language models},
  url          = {https://openreview.net/forum?id=zVo6PfBa0K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards better understanding of in-context learning ability from in-context uncertainty quantification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0c6iG28rRl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting simple function classes has been widely used as a testbed for developing theory and understanding of the trained Transformer's in-context learning (ICL) ability. In this paper, we revisit the training of Transformers on linear regression tasks, and different from all the existing literature, we consider a bi-objective prediction task of predicting both the conditional expectation $\mathbb{E}[Y|X]$ and the conditional variance Var$(Y|X)$. This additional uncertainty quantification objective provides a handle to (i) better design out-of-distribution experiments to distinguish ICL from in-weight learning (IWL) and (ii) make a better separation between the algorithms with and without using the prior information of the training distribution. Theoretically, we show that the trained Transformer reaches near Bayes optimum, suggesting the usage of the information of the training distribution. Our method can be extended to other cases. Specifically, with the Transformer's context window $S$, we prove a generalization bound of $\tilde{\mathcal{O}}(\sqrt{\min\{S, T\}/(n T)})$ on $n$ tasks with sequences of length $T$, providing sharper analysis compared to previous results of $\tilde{\mathcal{O}}(\sqrt{1/n})$. Empirically, we illustrate that while the trained Transformer behaves as the Bayes-optimal solution as a natural consequence of supervised training in distribution, it does not necessarily perform a Bayesian inference when facing task shifts, in contrast to the \textit{equivalence} between these two proposed in many existing literature. We also demonstrate the trained Transformer's ICL ability over covariate shift and prompt-length shift and interpret them as a generalization over a meta distribution.},
  archive      = {J_TMLR},
  author       = {Shang Liu and Zhongze Cai and Guanting Chen and Xiaocheng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards better understanding of in-context learning ability from in-context uncertainty quantification},
  url          = {https://openreview.net/forum?id=0c6iG28rRl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lurie networks with robust convergent dynamics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3Jm4dbrKGZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Lurie network is a novel and unifying time-invariant neural ODE. Many existing continuous-time models, including recurrent neural networks and neural oscillators, are special cases of the Lurie network in this context. Mild constraints on the weights and biases of the Lurie network are derived to ensure a generalised concept of stability is guaranteed. This generalised stability measure is that of k-contraction which permits global convergence to a point, line or plane in the neural state-space. This includes global convergence to one of multiple equilibrium points or limit cycles as observed in many dynamical systems including associative and working memory. Weights and biases of the Lurie network, which satisfy the k-contraction constraints, are encoded through unconstrained parametrisations. The novel stability results and parametrisations provide a toolset for training over the space of k-contracting Lurie network's using standard optimisation algorithms. These results are also leveraged to construct and train a graph Lurie network satisfying the same convergence properties. Empirical results show the improvement in prediction accuracy, generalisation and robustness on a range of simulated dynamical systems, when the graph structure and k-contraction conditions are introduced. These results also compare favourably against other well known stability-constrained models and an unconstrained neural ODE.},
  archive      = {J_TMLR},
  author       = {Carl R Richardson and Matthew C. Turner and Steve R. Gunn},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lurie networks with robust convergent dynamics},
  url          = {https://openreview.net/forum?id=3Jm4dbrKGZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard-negative sampling for contrastive learning: Optimal representation geometry and neural- vs dimensional-collapse. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3cnpZ5SIjU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a widely-studied data model and general loss and sample-hardening functions we prove that the losses of Supervised Contrastive Learning (SCL), Hard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) are minimized by representations that exhibit Neural-Collapse (NC), i.e., the class means form an Equiangular Tight Frame (ETF) and data from the same class are mapped to the same representation. We also prove that for any representation mapping, the HSCL and Hard-UCL (HUCL) losses are lower bounded by the corresponding SCL and UCL losses. In contrast to existing literature, our theoretical results for SCL do not require class-conditional independence of augmented views and work for a general loss function class that includes the widely used InfoNCE loss function. Moreover, our proofs are simpler, compact, and transparent. Similar to existing literature, our theoretical claims also hold for the practical scenario where batching is used for optimization. We empirically demonstrate, for the first time, that Adam optimization (with batching) of HSCL and HUCL losses with random initialization and suitable hardness levels can indeed converge to the NC-geometry if we incorporate unit-ball or unit-sphere feature normalization. Without incorporating hard-negatives or feature normalization, however, the representations learned via Adam suffer from Dimensional-Collapse (DC) and fail to attain the NC-geometry. These results exemplify the role of hard-negative sampling in contrastive representation learning and we conclude with several open theoretical problems for future work. The code can be found at https://github.com/rjiang03/HCL/tree/main},
  archive      = {J_TMLR},
  author       = {Ruijie Jiang and Thuan Nguyen and Shuchin Aeron and Prakash Ishwar},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hard-negative sampling for contrastive learning: Optimal representation geometry and neural- vs dimensional-collapse},
  url          = {https://openreview.net/forum?id=3cnpZ5SIjU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retrieve, merge, predict: Augmenting tables with data lakes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4uPJN6yfY1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-learning from a disparate set of tables, a data lake, requires assembling features by merging and aggregating tables. Data discovery can extend autoML to data tables by automating these steps. We present an in-depth analysis of such automated table augmentation for machine learning tasks, analyzing different methods for the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table. We use two data lakes: Open Data US, a well-referenced real data lake, and a novel semi-synthetic dataset, YADL (Yet Another Data Lake), which we developed as a tool for benchmarking this data discovery task. Systematic exploration on both lakes outlines 1) the importance of accurately retrieving join candidates, 2) the efficiency of simple merging methods, and 3) the resilience of tree-based learners to noisy conditions. Our experimental environment is easily reproducible and based on open data, to foster more research on feature engineering, autoML, and learning in data lakes},
  archive      = {J_TMLR},
  author       = {Riccardo Cappuzzo and Aimee Coelho and Félix Lefebvre and Paolo Papotti and Gaël Varoquaux},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Retrieve, merge, predict: Augmenting tables with data lakes},
  url          = {https://openreview.net/forum?id=4uPJN6yfY1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node classification with reject option. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4xXJDO8Bvu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key tasks in graph learning is node classification. While Graph neural networks have been used for various applications, their adaptivity to reject option settings has not been previously explored. In this paper, we propose NCwR, a novel approach to node classification in Graph Neural Networks (GNNs) with an integrated reject option. This allows the model to abstain from making predictions for samples with high uncertainty. We propose cost-based and coverage-based methods for classification with abstention in node classification settings using GNNs. We perform experiments using our method on standard citation network datasets Cora, CiteSeer, PubMed and ogbn-arxiv. We also model the Legal judgment prediction problem on the ILDC dataset as a node classification problem, where nodes represent legal cases and edges represent citations. We further interpret the model by analyzing the cases in which it abstains from predicting and visualizing which part of the input features influenced this decision.},
  archive      = {J_TMLR},
  author       = {Uday Bhaskar Kuchipudi and Jayadratha Gayen and Charu Sharma and Naresh Manwani},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Node classification with reject option},
  url          = {https://openreview.net/forum?id=4xXJDO8Bvu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language models are good tabular learners. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6o3vVBWYis'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based language models have become the de facto standard in natural language processing. However, they underperform in the tabular data domain compared to traditional tree-based methods. We posit that current models fail to achieve the full potential of language models due to (i) heterogeneity of tabular data; and (ii) challenges faced by the model in interpreting numerical values. Based on this hypothesis, we propose the Tabular Domain Transformer (TDTransformer) framework. TDTransformer has distinct embedding processes for different types of columns. The alignment layers for different column-types transform these embeddings to a common space. Besides, TDTransformer adapts piece-wise linear encoding for numerical values for better performance. We test the proposed method on 76 real-world tabular classification datasets from the OpenML benchmark. Extensive experiments indicate that TDTransformer significantly improves the state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Zhenhan Huang and Kavitha Srinivas and Horst Samulowitz and Niharika S. D'Souza and Charu C. Aggarwal and Pin-Yu Chen and Jianxi Gao},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Language models are good tabular learners},
  url          = {https://openreview.net/forum?id=6o3vVBWYis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking the value of training-free structured pruning of LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7KkytYYhMv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the effectiveness of training-free structured pruning techniques for Large Language Models (LLMs), with a particular focus on depth and width pruning strategies. Through an extensive empirical evaluation across a diverse range of tasks, datasets and modalities, we reveal critical limitations in current pruning methods. While some tasks exhibit minimal performance degradation, others face significant deterioration, even at low pruning rates, contradicting prior findings that often rely on selective benchmarks. Our analysis also finds that depth pruning, despite its simplicity, usually outperforms the more granular width pruning approaches in maintaining downstream task performance. Our findings highlight that existing evaluations of pruned LLMs often overstate their effectiveness due to incomplete or limited evaluation tasks, necessitating a critical reassessment of the true value of pruning and emphasizing the need to explore more robust pruning algorithms.},
  archive      = {J_TMLR},
  author       = {Nahush Lele and Arnav Chavan and Aryamaan Thakur and Deepak Gupta},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking the value of training-free structured pruning of LLMs},
  url          = {https://openreview.net/forum?id=7KkytYYhMv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient open set single image test time adaptation of vision language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=72YVabBErN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapting models to dynamic, real-world environments characterized by shifting data distributions and unseen test scenarios is a critical challenge in deep learning. In this paper, we consider a realistic and challenging Test-Time Adaptation setting, where a model must continuously adapt to test samples that arrive sequentially, one at a time, while distinguishing between known and unknown classes. Current Test-Time Adaptation methods operate under closed-set assumptions or batch processing, differing from the real-world open-set scenarios. We address this limitation by establishing a comprehensive benchmark for Open-set Single-image Test-Time Adaptation using Vision-Language Models. Furthermore, we propose ROSITA, a novel framework that leverages dynamically updated feature banks to identify reliable test samples and employs a contrastive learning objective to improve the separation between known and unknown classes. Our approach effectively adapts models to domain shifts for known classes while rejecting unfamiliar samples. Extensive experiments across diverse real-world benchmarks demonstrate that ROSITA sets a new state-of-the-art in open-set TTA, achieving both strong performance and computational efficiency for real-time deployment. The code is released at https://github.com/manogna-s/ROSITA.git.},
  archive      = {J_TMLR},
  author       = {Manogna Sreenivas and Soma Biswas},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient open set single image test time adaptation of vision language models},
  url          = {https://openreview.net/forum?id=72YVabBErN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Foundation models meet federated learning: A one-shot feature-sharing method with privacy and performance guarantees. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=55593xywWG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapting foundation models for downstream tasks via Federated Learning (FL) is a promising strategy for protecting privacy while leveraging the capability of foundation models. However, FL's iterative training and model transmission result in high communication costs and GPU memory demands, making large foundation models impractical for FL. This paper introduces a one-shot FL method with a server-side performance bound to enable foundation models by reducing communication costs and GPU memory requirements. Our approach, FedPFT (FL with Parametric Feature Transfer), involves clients learning and transferring parametric models for features extracted from frozen foundation models in a single round. Parametric models are then used to generate synthetic features at the server to train a classifier head. We evaluate FedPFT across eight vision datasets using three vision foundation models. Our findings demonstrate that FedPFT is agnostic to data heterogeneity and network topology and it enhances the communication-accuracy frontier up to 7.8\%. Finally, we show FedPFT's compatibility with differential privacy and its resilience against reconstruction attacks. Our work highlights the capability of private, feature-sharing methods for one-shot knowledge transfer using foundation models.},
  archive      = {J_TMLR},
  author       = {Mahdi Beitollahi and Alex Bie and Sobhan Hemati and Leo Maxime Brunswic and Xu Li and Xi Chen and Guojun Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Foundation models meet federated learning: A one-shot feature-sharing method with privacy and performance guarantees},
  url          = {https://openreview.net/forum?id=55593xywWG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based confidence calibration for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BDPvuD5FTg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable confidence estimation is essential for enhancing the trustworthiness of large language models (LLMs), especially in high-stakes scenarios. Despite its importance, accurately estimating confidence in LLM responses remains a significant challenge. In this work, we propose using an auxiliary learning model to assess response correctness based on the self-consistency of multiple outputs generated by the LLM. Our method builds a consistency graph to represent the agreement among multiple responses and uses a graph neural network (GNN) to estimate the likelihood that each response is correct. Experiments demonstrate that this method has strong calibration performance on various benchmark datasets and generalizes well to out-of-domain cases.},
  archive      = {J_TMLR},
  author       = {Yukun Li and Sijia Wang and Lifu Huang and Liping Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph-based confidence calibration for large language models},
  url          = {https://openreview.net/forum?id=BDPvuD5FTg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ctrl-V: Higher fidelity autonomous vehicle video generation with bounding-box controlled object motion. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BMGikHBjlx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable video generation has attracted significant attention, largely due to advances in video diffusion models. In domains such as autonomous driving, developing highly accurate predictions for object motions is essential. This paper addresses the key challenge of enabling fine-grained control over object motion in the context of driving video synthesis. To accomplish this, we 1) employ a distinct, specialized model to forecast the trajectories of object bounding boxes, 2) adapt and enhance a separate video diffusion network to create video content conditioned on these high-quality trajectory forecasts, and 3) we are able to exert precise control over object position/movements using bounding boxes in both 2D and 3D spaces. Our method, Ctrl-V, leverages modified and fine-tuned Stable Video Diffusion (SVD) models to solve both trajectory and video generation. Extensive experiments conducted on the KITTI, Virtual-KITTI 2, BDD100k, and nuScenes datasets validate the effectiveness of our approach in producing realistic and controllable video generation. Project page: \url{https://oooolga.github.io/ctrl-v.github.io/}},
  archive      = {J_TMLR},
  author       = {Ge Ya Luo and ZhiHao Luo and Anthony Gosselin and Alexia Jolicoeur-Martineau and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ctrl-V: Higher fidelity autonomous vehicle video generation with bounding-box controlled object motion},
  url          = {https://openreview.net/forum?id=BMGikHBjlx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infrastructure for AI agents. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ckh17xN2R2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {\textbf{AI agents} plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. To facilitate beneficial interactions and mitigate harmful ones, much research focuses on directly modifying agent behaviour. For example, developers can train agents to follow user instructions. This focus on direct modifications is useful, but insufficient. We will also need external protocols and systems that shape how agents interact with institutions and other actors. For instance, agents will need more efficient protocols to communicate with each other and form agreements. In addition, attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of \textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.},
  archive      = {J_TMLR},
  author       = {Alan Chan and Kevin Wei and Sihao Huang and Nitarshan Rajkumar and Elija Perrier and Seth Lazar and Gillian K Hadfield and Markus Anderljung},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Infrastructure for AI agents},
  url          = {https://openreview.net/forum?id=Ckh17xN2R2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on large language model-based social agents in game-theoretic scenarios. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CsoSWpR5xC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities, as well as their interactions and synergistic effects on decision-making. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. Additionally, we analyze the performance of current social agents across various game scenarios. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.},
  archive      = {J_TMLR},
  author       = {Xiachong Feng and Longxu Dou and Minzhi Li and Qinghao Wang and Yu Guo and Haochuan Wang and Chang Ma and Lingpeng Kong},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on large language model-based social agents in game-theoretic scenarios},
  url          = {https://openreview.net/forum?id=CsoSWpR5xC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When should reinforcement learning use causal reasoning?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=D1PPuk8ZBI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) and causal reasoning naturally complement each other. The goal of causal reasoning is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper provides a theoretical study examining which reinforcement learning settings we can expect to benefit from causal reasoning, and how. According to our analysis, the key factor is {\em whether the behavioral policy---which generates the data---can be executed by the learning agent}, meaning that the observation signal available to the learning agent comprises all observations used by the behavioral policy. Common RL settings with behavioral policies that are executable by the learning agent include on-policy learning and online exploration, where the learning agent uses a behavioral policy to explore the environment. Common RL settings with behavioral policies that are not executable by the learning agent include offline learning with a partially observable state space and asymmetric imitation learning where the demonstrator has access to more observations than the imitator. Using the theory of causal graphs, we show formally that when the behavioral policy is executable by the learning agent, conditional probabilities are causal, and can therefore be used to estimate expected rewards as done in traditional RL. However, when the behavioral policy is not executable by the learning agent, conditional probabilities may be confounded and provide misleading estimates of expected rewards. For confounded settings, we describe previous and new methods for leveraging causal reasoning.},
  archive      = {J_TMLR},
  author       = {Oliver Schulte and Pascal Poupart},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When should reinforcement learning use causal reasoning?},
  url          = {https://openreview.net/forum?id=D1PPuk8ZBI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross entropy versus label smoothing: A neural collapse perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FEo55EIvGI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label smoothing loss is a widely adopted technique to mitigate overfitting in deep neural networks. This paper studies label smoothing from the perspective of Neural Collapse (NC), a powerful empirical and theoretical framework which characterizes model behavior during the terminal phase of training. We first show empirically that models trained with label smoothing converge faster to neural collapse solutions and attain a stronger level of neural collapse compared to those trained with cross-entropy loss. Furthermore, we show that at the same level of NC1, models under label smoothing loss exhibit intensified NC2. These findings provide valuable insights into the impact of label smoothing on model performance and calibration. Then, leveraging the unconstrained feature model, we derive closed-form solutions for the global minimizers under both label smoothing and cross-entropy losses. We show that models trained with label smoothing have a lower conditioning number and, therefore, theoretically converge faster. Our study, combining empirical evidence and theoretical results, not only provides nuanced insights into the differences between label smoothing and cross-entropy losses, but also serves as an example of how the powerful neural collapse framework can be used to improve our understanding of DNNs.},
  archive      = {J_TMLR},
  author       = {Li Guo and George Andriopoulos and Zifan Zhao and Zixuan Dong and Shuyang Ling and Keith W. Ross},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cross entropy versus label smoothing: A neural collapse perspective},
  url          = {https://openreview.net/forum?id=FEo55EIvGI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniZero: Generalized and efficient planning with scalable latent world models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Gl6dF9soQo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning predictive world models is crucial for enhancing the planning capabilities of reinforcement learning (RL) agents. Recently, MuZero-style algorithms, leveraging the value equivalence principle and Monte Carlo Tree Search (MCTS), have achieved superhuman performance in various domains. However, these methods struggle to scale in heterogeneous scenarios with diverse dependencies and task variability. To overcome these limitations, we introduce UniZero, a novel approach that employs a transformer-based world model to effectively learn a shared latent space. By concurrently predicting latent dynamics and decision-oriented quantities conditioned on the learned latent history, UniZero enables joint optimization of the long-horizon world model and policy, facilitating broader and more efficient planning in the latent space. We show that UniZero significantly outperforms existing baselines in benchmarks that require long-term memory. Additionally, UniZero demonstrates superior scalability in multitask learning experiments conducted on Atari benchmarks. In standard single-task RL settings, such as Atari and DMControl, UniZero matches or even surpasses the performance of current state-of-the-art methods. Finally, extensive ablation studies and visual analyses validate the effectiveness and scalability of UniZero's design choices. Our code is available at \textcolor{magenta}{https://github.com/opendilab/LightZero}.},
  archive      = {J_TMLR},
  author       = {Yuan Pu and Yazhe Niu and Zhenjie Yang and Jiyuan Ren and Hongsheng Li and Yu Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {UniZero: Generalized and efficient planning with scalable latent world models},
  url          = {https://openreview.net/forum?id=Gl6dF9soQo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remembering to be fair again: Reproducing non-markovian fairness in sequential decision making. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=H6DtMcZf5s'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring long-term fairness in sequential decision-making is a key challenge in machine learning. Alamdari et al. (2024) introduced FairQCM, a reinforcement learning algorithm that enforces fairness in non-Markovian settings via memory augmentations and counterfactual reasoning. We reproduce and extend their findings by validating their claims and introducing novel enhancements. We confirm that FairQCM outperforms standard baselines in fairness enforcement and sample efficiency across different environments. However, alternative fairness metrics (Egalitarian, Gini) yield mixed results, and counterfactual memories show limited impact on fairness improvement. Further, we introduce a realistic COVID-19 vaccine allocation environment based on SEIR, a popular compartmental model of epidemiology. To accommodate continuous action spaces, we develop FairSCM, which integrates counterfactual memories into a Soft Actor-Critic framework. Our results reinforce that counterfactual memories provide little fairness benefit and, in fact, hurt performance, especially in complex, dynamic settings. The original code, modified to be 70% more efficient, and our extensions are available on GitHub: https://github.com/bozo22/remembering-to-be-fair-again.},
  archive      = {J_TMLR},
  author       = {Domonkos Nagy and Lohithsai Yadala Chanchu and Krystof Bobek and Xin Zhou and Jacobus Smit},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Remembering to be fair again: Reproducing non-markovian fairness in sequential decision making},
  url          = {https://openreview.net/forum?id=H6DtMcZf5s},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust offline imitation learning from diverse auxiliary data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Hy2KAldqAo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline imitation learning enables learning a policy solely from a set of expert demonstrations, without any environment interaction. To alleviate the issue of distribution shift arising due to the small amount of expert data, recent works incorporate large numbers of auxiliary demonstrations alongside the expert data. However, the performance of these approaches rely on assumptions about the quality and composition of the auxiliary data, and they are rarely successful when those assumptions do not hold. To address this limitation, we propose Robust Offline Imitation from Diverse Auxiliary Data (ROIDA). ROIDA first identifies high-quality transitions from the entire auxiliary dataset using a learned reward function. These high-reward samples are combined with the expert demonstrations for weighted behavioral cloning. For lower-quality samples, ROIDA applies temporal difference learning to steer the policy towards high-reward states, improving long-term returns. This two-pronged approach enables our framework to effectively leverage both high and low-quality data without any assumptions. Extensive experiments validate that ROIDA achieves robust and consistent performance across multiple auxiliary datasets with diverse ratios of expert and non-expert demonstrations. ROIDA effectively leverages unlabeled auxiliary data, outperforming prior methods reliant on specific data assumptions.},
  archive      = {J_TMLR},
  author       = {Udita Ghosh and Dripta S. Raychaudhuri and Jiachen Li and Konstantinos Karydis and Amit Roy-Chowdhury},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust offline imitation learning from diverse auxiliary data},
  url          = {https://openreview.net/forum?id=Hy2KAldqAo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FGAIF: Aligning large vision-language models with fine-grained AI feedback. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Qhfw5CUVd7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (LVLMs) have demonstrated proficiency in tackling a variety of visual-language tasks. However, current LVLMs suffer from misalignment between text and image modalities which causes three kinds of hallucination problems, i.e., object existence, object attribute, and object relationship. To tackle this issue, existing methods mainly utilize Reinforcement Learning (RL) to align modalities in LVLMs. However, they still suffer from three main limitations: (1) General feedback can not indicate the hallucination type contained in the response; (2) Sparse rewards only give the sequence-level reward for the whole response; and (3)Annotation cost is time-consuming and labor-intensive. To handle these limitations, we propose an innovative method to align modalities in LVLMs through \textbf{F}ine-\textbf{G}rained \textbf{A}rtificial \textbf{I}ntelligence \textbf{F}eedback (\textbf{\ours}), which mainly consists of three steps: AI-based Feedback Collection, Fine-grained Reward Model Training, and Reinforcement Learning with Fine-grained Reward. Finally, a novel fine-grained feedback module is integrated into the Proximal Policy Optimization (PPO) algorithm. Extensive experiments are conducted on hallucination and general benchmarks, demonstrating the superior performance of our proposed method. Notably, compared with previous models trained with the RL-based aligning method, our proposed method is effective even with fewer parameters.},
  archive      = {J_TMLR},
  author       = {Liqiang Jing and Xinya Du},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FGAIF: Aligning large vision-language models with fine-grained AI feedback},
  url          = {https://openreview.net/forum?id=Qhfw5CUVd7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating large language models in causal discovery: A statistical causal approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Reh1S8rxfh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is important for reasonable causal models reflecting the broad knowledge of domain experts, despite the challenges in the systematic acquisition of background knowledge. To overcome these challenges, this paper proposes a novel method for causal inference, in which SCD and knowledge-based causal inference (KBCI) with a large language model (LLM) are synthesized through ``statistical causal prompting (SCP)'' for LLMs and prior knowledge augmentation for SCD. The experiments in this work have revealed that the results of LLM-KBCI and SCD augmented with LLM-KBCI approach the ground truths, more than the SCD result without prior knowledge. These experiments have also revealed that the SCD result can be further improved if the LLM undergoes SCP. Furthermore, with an unpublished real-world dataset, we have demonstrated that the background knowledge provided by the LLM can improve the SCD on this dataset, even if this dataset has never been included in the training data of the LLM. For future practical application of this proposed method across important domains such as healthcare, we also thoroughly discuss the limitations, risks of critical errors, expected improvement of techniques around LLMs, and realistic integration of expert checks of the results into this automatic process, with SCP simulations under various conditions both in successful and failure scenarios. The careful and appropriate application of the proposed approach in this work, with improvement and customization for each domain, can thus address challenges such as dataset biases and limitations, illustrating the potential of LLMs to improve data-driven causal inference across diverse scientific domains. The code used in this work is publicly available at: https://github.com/mas-takayama/LLM-and-SCD.},
  archive      = {J_TMLR},
  author       = {MASAYUKI TAKAYAMA and Tadahisa OKUDA and Thong Pham and Tatsuyoshi Ikenoue and Shingo Fukuma and Shohei Shimizu and Akiyoshi Sannai},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Integrating large language models in causal discovery: A statistical causal approach},
  url          = {https://openreview.net/forum?id=Reh1S8rxfh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node feature forecasting in temporal graphs: An interpretable online algorithm. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Teu1Blr2YJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an online algorithm mspace for forecasting node features in temporal graphs, which captures spatial cross-correlation among different nodes as well as the temporal auto-correlation within a node. The algorithm can be used for both probabilistic and deterministic multi-step forecasting, making it applicable for estimation and generation tasks. Evaluations against various baselines, including temporal graph neural network (TGNN) models and classical Kalman filters, demonstrate that mspace performs comparably to the state-of-the-art and even surpasses them on some datasets. Importantly, mspace demonstrates consistent performance across datasets with varying training sizes, a notable advantage over TGNN models that require abundant training samples to effectively learn the spatiotemporal trends in the data. Therefore, employing mspace is advantageous in scenarios where the training sample availability is limited. Additionally, we establish theoretical bounds on multi-step forecasting error of mspace and show that it scales linearly with the number of forecast steps $q$ as $\mathcal{O}(q)$. For an asymptotically large number of nodes $n$, and timesteps $T$, the computational complexity of mspace grows linearly with both \$n\$ and \$T\$, i.e., $\mathcal{O}(nT)$, while its space complexity remains constant $\mathcal{O}(1)$. We compare the performance of various mspace variants against ten recent TGNN baselines and two classical baselines, ARIMA and the Kalman filter, across ten real-world datasets. Lastly, we have investigated the interpretability of different mspace variants by analyzing model parameters alongside dataset characteristics to jointly derive model-centric and data-centric insights.},
  archive      = {J_TMLR},
  author       = {Aniq Ur Rahman and Justin Coon},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Node feature forecasting in temporal graphs: An interpretable online algorithm},
  url          = {https://openreview.net/forum?id=Teu1Blr2YJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the effectiveness of rotation-equivariance in U-net: A benchmark for image segmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UcrVnXBdZI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous studies have recently focused on incorporating different variations of equivariance in Convolutional Neural Networks (CNNs). In particular, rotation-equivariance has gathered significant attention due to its relevance in many applications related to medical imaging, microscopic imaging, satellite imaging, industrial tasks, etc. While prior research has primarily focused on enhancing classification tasks with rotation equivariant CNNs, their impact on more complex architectures, such as U-Net for image segmentation, remains scarcely explored. Indeed, previous work interested in integrating rotation-equivariance into U-Net architecture have focused on solving specific applications with a limited scope. In contrast, this paper aims to provide a more exhaustive evaluation of rotation equivariant U-Net for image segmentation across a broader range of tasks. We benchmark their effectiveness against standard U-Net architectures, assessing improvements in terms of performance and sustainability (i.e., computational cost). Our evaluation focuses on datasets whose orientation of objects of interest is arbitrary in the image (e.g., Kvasir-SEG), but also on more standard segmentation datasets (such as COCO-Stuff) as to explore the wider applicability of rotation equivariance beyond tasks undoubtedly concerned by rotation equivariance. The main contribution of this work is to provide insights into the trade-offs and advantages of integrating rotation equivariance for segmentation tasks.},
  archive      = {J_TMLR},
  author       = {Robin Ghyselinck and Valentin Delchevalerie and Bruno Dumas and Benoit Frenay},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the effectiveness of rotation-equivariance in U-net: A benchmark for image segmentation},
  url          = {https://openreview.net/forum?id=UcrVnXBdZI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal bounds on full-reference image quality for imaging inverse problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WADLPccB6o'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc. This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis. But since we don’t know the true image, computing FRIQ is non-trivial. In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability. We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems.},
  archive      = {J_TMLR},
  author       = {Jeffrey Wen and Rizwan Ahmad and Philip Schniter},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conformal bounds on full-reference image quality for imaging inverse problems},
  url          = {https://openreview.net/forum?id=WADLPccB6o},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T2L: Efficient zero-shot action recognition with temporal token learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WvgoxpGpuU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks. Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain. While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the temporal aspects inherent to the video domain. In this study, we present Efficient Zero-Shot Action Recognition with Temporal Token Learning(T2L), a simple and efficient adaptation of CLIP that addresses these challenges. T2L leverages Temporal Token Learning (TTL) for seamless temporal adaptation, requiring no fundamental changes to the core CLIP architecture while preserving its remarkable generalization abilities. TTL relies on temporal feature diversity (TFD), a novel learning objective, which guides TTL to focus on capturing motion, thereby enhancing its learning capabilities from videos. We perform extensive experiments on nine different benchmark datasets, thoroughly evaluating T2L for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization. Impressively, with merely 5.2 million learnable parameters, T2L can be efficiently trained on a single GPU (with 25x less learnable parameters, 3x reduction in GFLOPs, and 4x improvement in throughput when compared with prior best model), outperforming existing approaches in several evaluations.},
  archive      = {J_TMLR},
  author       = {Shahzad Ahmad and Sukalpa Chanda and Yogesh S Rawat},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {T2L: Efficient zero-shot action recognition with temporal token learning},
  url          = {https://openreview.net/forum?id=WvgoxpGpuU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NITO: Neural implicit fields for resolution-free and domain-adaptable topology optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XHXAvACdgv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural topology optimization plays a crucial role in engineering by determining the optimal material layout within a design space to maximize performance under given constraints. We introduce Neural Implicit Topology Optimization (NITO), a deep learning regression approach to accelerate topology optimization tasks. We demonstrate that, compared to state-of-the-art diffusion models, NITO generates structures that are under 15% as structurally sub-optimal and does so ten times faster. Furthermore, we show that NITO is entirely resolution-free and domain-agnostic, offering a more scalable solution than the current fixed-resolution and domain-specific diffusion models. To achieve this state-of-the-art performance, NITO combines three key innovations. First, we introduce the Boundary Point Order-Invariant MLP (BPOM), which represents loads and supports in a sparse and domain-agnostic manner, allowing NITO to train on variable conditioning, domain shapes, and mesh resolutions. Second, we adopt a neural implicit field representation, which allows NITO to synthesize topologies of any shape or resolution. Finally, we propose an inference-time refinement step using a few steps of gradient-based optimization to enable NITO to achieve results comparable to direct optimization methods. These three innovations empower NITO with a precision and versatility that is currently unparalleled among competing deep learning approaches for topology optimization. Code & Data: https://github.com/ahnobari/NITO_Public},
  archive      = {J_TMLR},
  author       = {Amin Heyrani Nobari and Lyle Regenwetter and Giorgio Giannone and Faez Ahmed},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {NITO: Neural implicit fields for resolution-free and domain-adaptable topology optimization},
  url          = {https://openreview.net/forum?id=XHXAvACdgv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging lottery ticket and grokking: Understanding grokking from inner structure of networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eQeYyup1tm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grokking is an intriguing phenomenon of delayed generalization, where neural networks initially memorize training data with perfect accuracy but exhibit poor generalization, subsequently transitioning to a generalizing solution with continued training. While factors such as weight norms and sparsity have been proposed to explain this delayed generalization, the influence of network structure remains underexplored. In this work, we link the grokking phenomenon to the lottery ticket hypothesis to investigate the impact of internal network structures. We demonstrate that utilizing lottery tickets obtained during the generalizing phase (termed grokked tickets) significantly reduces delayed generalization across various tasks, including multiple modular arithmetic operations, polynomial regression, sparse parity, and MNIST classification. Through controlled experiments, we show that the mitigation of delayed generalization is not due solely to reduced weight norms or increased sparsity, but rather to the discovery of good subnetworks. Furthermore, we find that grokked tickets exhibit periodic weight patterns and undergo rapid structural changes that coincide with improvements in generalization. Additionally, pruning techniques like the edge-popup algorithm can identify these effective structures without modifying the weights, thereby transforming memorizing networks into generalizing ones. These results underscore the novel insight that structural exploration plays a pivotal role in understanding grokking.},
  archive      = {J_TMLR},
  author       = {Gouki Minegishi and Yusuke Iwasawa and Yutaka Matsuo},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging lottery ticket and grokking: Understanding grokking from inner structure of networks},
  url          = {https://openreview.net/forum?id=eQeYyup1tm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LocalFormer: Mitigating over-globalising in transformers on graphs with localised training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hMPzJ3qKpf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Transformers become more popular for graph machine learning, a significant issue has recently been observed. Their global attention mechanisms tend to overemphasize distant vertices, leading to the phenomenon of ``over-globalising.'' This phenomenon often results in the dilution of essential local information, particularly in graphs where local neighbourhoods carry significant predictive power. Existing methods often struggle with rigidity in their local processing, where tightly coupled operations limit flexibility and adaptability in diverse graph structures. Additionally, these methods can overlook critical structural nuances, resulting in an incomplete integration of local and global contexts. This paper addresses these issues by proposing LocalFormer, a novel framework, to effectively localise a transformer model by integrating a distinct local module and a complementary module that integrates global information. The local module focuses on capturing and preserving fine-grained, neighbourhood-specific patterns, ensuring that the model maintains sensitivity to critical local structures. In contrast, the complementary module dynamically integrates broader context without overshadowing the localised information, offering a balanced approach to feature aggregation across different scales of the graph. Through collaborative and warm-up training strategies, these modules work synergistically to mitigate the adverse effects of over-globalising, leading to improved empirical performance. Our experimental results demonstrate the effectiveness of LocalFormer compared to state-of-the-art baselines on vertex-classification tasks.},
  archive      = {J_TMLR},
  author       = {Naganand Yadati},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LocalFormer: Mitigating over-globalising in transformers on graphs with localised training},
  url          = {https://openreview.net/forum?id=hMPzJ3qKpf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G-RepsNet: A lightweight construction of equivariant networks for arbitrary matrix groups. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k1eYngOvf0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group equivariance is a strong inductive bias useful in a wide range of deep learning tasks. However, constructing efficient equivariant networks for general groups and domains is difficult. Recent work by Finzi et al. directly solves the equivariance constraint for arbitrary matrix groups to obtain equivariant MLPs (EMLPs). But this method does not scale well and scaling is crucial in deep learning. Here, we introduce Group Representation Networks (G-RepsNets), a lightweight equivariant network for arbitrary matrix groups with features represented using tensor polynomials. The key insight in our design is that using tensor representations in the hidden layers of a neural network along with simple inexpensive tensor operations leads to scalable equivariant networks. Further, these networks are universal approximators of functions equivariant to orthogonal groups. We find G-RepsNet to be competitive to EMLP on several tasks with group symmetries such as $O(5)$, $O(1, 3)$, and $O(3)$ with scalars, vectors, and second-order tensors as data types. On image classification tasks, we find that G-RepsNet using second-order representations is competitive and often even outperforms sophisticated state-of-the-art equivariant models such as GCNNs and $E(2)$-CNNs. To further illustrate the generality of our approach, we show that G-RepsNet is competitive to G-FNO and EGNN on N-body predictions and solving PDEs respectively, while being efficient.},
  archive      = {J_TMLR},
  author       = {Sourya Basu and Suhas Lohit and Matthew Brand},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {G-RepsNet: A lightweight construction of equivariant networks for arbitrary matrix groups},
  url          = {https://openreview.net/forum?id=k1eYngOvf0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized compressed sensing for image reconstruction with diffusion probabilistic models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lmHh4FmPWZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the problem of selecting a small set of linear measurements for reconstructing high-dimensional signals. Well-established methods for optimizing such measurements include principal component analysis (PCA), independent component analysis (ICA) and compressed sensing (CS) based on random projections, all of which rely on axis- or subspace-aligned statistical characterization of the signal source. However, many naturally occurring signals, including photographic images, contain richer statistical structure. To exploit such structure, we introduce a general method for obtaining an optimized set of linear measurements for efficient image reconstruction, where the signal statistics are expressed by the prior implicit in a neural network trained to perform denoising (known as a ``diffusion model''). We demonstrate that the optimal measurements derived for two natural image datasets differ from those of PCA, ICA, or CS, and result in substantially lower mean squared reconstruction error. Interestingly, the marginal distributions of the measurement values are asymmetrical (skewed), substantially more so than those of previous methods. We also find that optimizing with respect to perceptual loss, as quantified by structural similarity (SSIM), leads to measurements different from those obtained when optimizing for MSE. Our results highlight the importance of incorporating the specific statistical regularities of natural signals when designing effective linear measurements.},
  archive      = {J_TMLR},
  author       = {Ling-Qi Zhang and Zahra Kadkhodaie and Eero P Simoncelli and David H. Brainard},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized compressed sensing for image reconstruction with diffusion probabilistic models},
  url          = {https://openreview.net/forum?id=lmHh4FmPWZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural slot interpreters: Grounding object semantics in emergent slot representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lyxRBPmmnV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several accounts of human cognition posit that our intelligence is rooted in our ability to form abstract composable concepts, ground them in our environment, and reason over these grounded entities. This trifecta of human thought has remained elusive in modern intelligent machines. In this work, we investigate whether slot representations extracted from visual scenes serve as appropriate compositional abstractions for grounding and reasoning. We present the Neural Slot Interpreter (NSI), which learns to ground object semantics in slots. At the core of NSI is a nested schema that uses simple syntax rules to organize the object semantics of a scene into object-centric schema primitives. Then, the NSI metric learns to ground primitives into slots through a structured contrastive learning objective that reasons over the intermodal alignment. Experiments with a bi-modal object-property and scene retrieval task demonstrate the grounding efficacy and interpretability of correspondences learned by NSI. From a scene representation standpoint, we find that emergent NSI slots that move beyond the image grid by binding to spatial objects facilitate improved visual grounding compared to conventional bounding-box-based approaches. From a data efficiency standpoint, we empirically validate that NSI learns more generalizable representations from a fixed amount of annotation data than the traditional approach. We also show that the grounded slots surpass unsupervised slots in real-world object discovery and scale with scene complexity. Finally, we investigate the downstream efficacy of the grounded slots. Vision Transformers trained on grounding-aware NSI tokenizers using as few as ten tokens outperform patch-based tokens on challenging few-shot classification tasks.},
  archive      = {J_TMLR},
  author       = {Bhishma Dedhia and Niraj Jha},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural slot interpreters: Grounding object semantics in emergent slot representations},
  url          = {https://openreview.net/forum?id=lyxRBPmmnV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical study of neural network expressive power via manifold topology. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qRAjZuf48S'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A prevalent assumption regarding real-world data is that it lies on or close to a low-dimensional manifold. When deploying a neural network on data manifolds, the required size, i.e., the number of neurons of the network, heavily depends on the intricacy of the underlying latent manifold. While significant advancements have been made in understanding the geometric attributes of manifolds, it's essential to recognize that topology, too, is a fundamental characteristic of manifolds. In this study, we investigate network expressive power in terms of the latent data manifold. Integrating both topological and geometric facets of the data manifold, we present a size upper bound of ReLU neural networks.},
  archive      = {J_TMLR},
  author       = {Jiachen Yao and Lingjie Yi and Mayank Goswami and Chao Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A theoretical study of neural network expressive power via manifold topology},
  url          = {https://openreview.net/forum?id=qRAjZuf48S},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of pre-trained model selection for out-of-distribution generalization and calibration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tYjoHjShxF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In out-of-distribution (OOD) generalization tasks, fine-tuning pre-trained models has become a prevalent strategy. Different from most prior work that has focused on advancing learning algorithms, we systematically examined how pre-trained model size, pre-training dataset size, and training strategies impact generalization and uncertainty calibration on downstream tasks. We evaluated 100 models across diverse pre-trained model sizes, five pre-training datasets, and five data augmentations through extensive experiments on four distribution shift datasets totaling over 120,000 GPU hours. Our results demonstrate the significant impact of pre-trained model selection, with optimal choices substantially improving OOD accuracy over algorithm improvement alone. Additionally, we find that larger models and bigger pre-training datasets not only enhance OOD performance but also improve calibration, helping to mitigate overconfidence, contrary to some prior studies that found modern deep networks to calibrate worse than classical shallow models. Our work underscores the overlooked importance of pre-trained model selection for out-of-distribution generalization and calibration.},
  archive      = {J_TMLR},
  author       = {Hiroki Naganuma and Ryuichiro Hataya and Kotaro Yoshida and Ioannis Mitliagkas},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An empirical study of pre-trained model selection for out-of-distribution generalization and calibration},
  url          = {https://openreview.net/forum?id=tYjoHjShxF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning energy-based generative models via potential flow: A variational principle approach to probability density homotopy matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vc7poEYOFK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-based models (EBMs) are a powerful class of probabilistic generative models due to their flexibility and interpretability. However, relationships between potential flows and explicit EBMs remain underexplored, while contrastive divergence training via implicit Markov chain Monte Carlo (MCMC) sampling is often unstable and expensive in high-dimensional settings. In this paper, we propose Variational Potential (VAPO) Flow Bayes, a new energy-based generative framework that eliminates the need for implicit MCMC sampling and does not rely on auxiliary networks or cooperative training. VAPO learns an energy-parameterized potential flow by constructing a flow-driven density homotopy that is matched to the data distribution through a variational loss minimizing the Kullback-Leibler divergence between the flow-driven and marginal homotopies. This principled formulation enables robust and efficient generative modeling while preserving the interpretability of EBMs. Experimental results on image generation, interpolation, out-of-distribution detection, and compositional generation confirm the effectiveness of VAPO, showing that our method performs competitively with existing approaches in terms of sample quality and versatility across diverse generative modeling tasks.},
  archive      = {J_TMLR},
  author       = {Junn Yong Loo and Leong Fang Yu and Michelle Adeline and Julia K. Lau and Hwa Hui Tew and Arghya Pal and VISHNU MONN BASKARAN and Chee-Ming Ting and Raphael CW Phan},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning energy-based generative models via potential flow: A variational principle approach to probability density homotopy matching},
  url          = {https://openreview.net/forum?id=vc7poEYOFK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized transformers with centralized aggregation are sample-efficient multi-agent world models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xT8BEgXmVc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a world model for model-free Reinforcement Learning (RL) agents can significantly improve the sample efficiency by learning policies in imagination. However, building a world model for Multi-Agent RL (MARL) can be particularly challenging due to the scalability issue across different number of agents in a centralized architecture, and also the non-stationarity issue in a decentralized architecture stemming from the inter-dependency among agents. To address both challenges, we propose a novel world model for MARL that learns decentralized local dynamics for scalability, combined with a centralized representation aggregation from all agents. We cast the dynamics learning as an auto-regressive sequence modeling problem over discrete tokens by leveraging the expressive Transformer architecture, in order to model complex local dynamics across different agents and provide accurate and consistent long-term imaginations. As the first pioneering Transformer-based world model for multi-agent systems, we introduce a Perceiver Transformer as an effective solution to enable centralized representation aggregation within this context. Extensive results on Starcraft Multi-Agent Challenge (SMAC) and MAMujoco demonstrate superior sample efficiency and overall performance compared to strong model-free approaches and existing model-based methods.},
  archive      = {J_TMLR},
  author       = {Yang Zhang and Chenjia Bai and Bin Zhao and Junchi Yan and Xiu Li and Xuelong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decentralized transformers with centralized aggregation are sample-efficient multi-agent world models},
  url          = {https://openreview.net/forum?id=xT8BEgXmVc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adam-family methods with decoupled weight decay in deep learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xVEHiAZ7uR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the convergence properties of a wide class of Adam-family methods for minimizing quadratically regularized nonsmooth nonconvex optimization problems, especially in the context of training nonsmooth neural networks with weight decay. Motivated by AdamW, we propose a novel framework for Adam-family methods with decoupled weight decay. Within our framework, the estimators for the first-order and second-order moments of stochastic subgradients are updated independently of the weight decay term. Under mild assumptions and with non-diminishing stepsizes for updating the primary optimization variables, we establish the convergence properties of our proposed framework. In addition, we show that our proposed framework encompasses a wide variety of well-known Adam-family methods, hence offering convergence guarantees for these methods in the training of nonsmooth neural networks. More importantly, compared to the existing results on the choices of the parameters for the moment terms in Adam, we show that our proposed framework provides more flexibility for these parameters. As a practical application of our proposed framework, we propose a novel Adam-family method named Adam with Decoupled Weight Decay (AdamD), and establish its convergence properties under mild conditions. Numerical experiments demonstrate that AdamD outperforms Adam and is comparable to AdamW, in the aspects of both generalization performance and efficiency.},
  archive      = {J_TMLR},
  author       = {Kuangyu Ding and Nachuan Xiao and Kim-chuan Toh},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adam-family methods with decoupled weight decay in deep learning},
  url          = {https://openreview.net/forum?id=xVEHiAZ7uR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEGO-learn: Label-efficient graph open-set learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=J6oxTJPOyN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we train graph-based models to recognize unseen classes while keeping labeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD) detection aim to address this challenge by training models that can accurately classify known, in-distribution (ID) classes while identifying and handling previously unseen classes during inference. It is critical for high-stakes, real-world applications where models frequently encounter unexpected data, including finance, security, and healthcare. However, current GOL methods assume access to a large number of labeled ID samples, which is unrealistic for large-scale graphs due to high annotation costs. In this paper, we propose LEGO-Learn (Label-Efficient Graph Open-set Learning), a novel framework that addresses open-set node classification on graphs within a given label budget by selecting the most informative ID nodes. LEGO-Learn employs a GNN-based filter to identify and exclude potential OOD nodes and then selects highly informative ID nodes for labeling using the K-Medoids algorithm. To prevent the filter from discarding valuable ID examples, we introduce a classifier that differentiates between the $C$ known ID classes and an additional class representing OOD nodes (hence, a $C+1$ classifier). This classifier utilizes a weighted cross-entropy loss to balance the removal of OOD nodes while retaining informative ID nodes. Experimental results on four real-world datasets demonstrate that LEGO-Learn significantly outperforms leading methods, achieving up to a $6.62\%$ improvement in ID classification accuracy and a $7.49\%$ increase in AUROC for OOD detection.},
  archive      = {J_TMLR},
  author       = {Haoyan Xu and Kay Liu and Zhengtao Yao and Philip S. Yu and Mengyuan Li and Kaize Ding and Yue Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LEGO-learn: Label-efficient graph open-set learning},
  url          = {https://openreview.net/forum?id=J6oxTJPOyN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-free loss gradients: A surprisingly effective baseline for coreset selection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OE4P1tW8iQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential rise in size and complexity of deep learning models and datasets have resulted in a considerable demand for computational resources. Coreset selection is one of the methods to alleviate this rising demand. The goal is to select a subset from a large dataset to train a model that performs almost at par with the one trained on the large dataset while reducing computational time and resource requirements. Existing approaches either attempt to identify remarkable samples (e.g., Forgetting, Adversarial Deepfool, EL2N, etc.) that stand out from the rest or solve complex optimization (e.g., submodular maximization, OMP) problems to compose the coresets. This paper proposes a novel and intuitive approach to efficiently select a coreset based on the similarity of loss gradients. Our method works on the hypothesis that gradients of samples belonging to a given class will point in similar directions during the early training phase. Samples with most neighbours that produce similar gradient directions, in other words, that produce noise-free gradients, will represent that class. Through extensive experimentation, we have demonstrated the effectiveness of our approach in out-performing state-of-the-art coreset selection algorithms on a range of benchmark datasets from CIFAR-10 to ImageNet with architectures of varied complexity (ResNet-18, ResNet-50, VGG-16, ViT).We have also demonstrated the effectiveness of our approach in Generative Modelling by implementing coreset selection to reduce training time for various GAN models (DCGAN, MSGAN, SAGAN, SNGAN) for different datasets (CIFAR-10, CIFAR-100, Tiny ImageNet) while not impacting the performance metrics significantly. Source code is provided at URL.},
  archive      = {J_TMLR},
  author       = {Saumyaranjan Mohanty and Chimata Anudeep and Konda Reddy Mopuri},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Noise-free loss gradients: A surprisingly effective baseline for coreset selection},
  url          = {https://openreview.net/forum?id=OE4P1tW8iQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preferential multi-objective bayesian optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mjsoESaWDH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preferential Bayesian optimization (PBO) is a framework for optimizing a decision-maker’s latent preferences over available design choices. While real-world problems often involve multiple conflicting objectives, existing PBO methods assume that preferences can be encoded by a single objective function. For instance, in the customization of robotic assistive devices, technicians aim to maximize user comfort while minimizing energy consumption to extend battery life. Likewise, in autonomous driving policy design, stakeholders must evaluate safety and performance trade-offs before committing to a policy. To bridge this gap, we introduce the first framework for PBO with multiple objectives. Within this framework, we propose dueling scalarized Thompson sampling (DSTS), a multi-objective generalization of the popular dueling Thompson sampling algorithm, which may also be of independent interest beyond our setting. We evaluate DSTS across four synthetic test functions and two simulated tasks—exoskeleton personalization and driving policy design—demonstrating that it outperforms several benchmarks. Finally, we prove that DSTS is asymptotically consistent. Along the way, we provide, to our knowledge, the first convergence guarantee for dueling Thompson sampling in single-objective PBO.},
  archive      = {J_TMLR},
  author       = {Raul Astudillo and Kejun Li and Maegan Tucker and Chu Xin Cheng and Aaron Ames and Yisong Yue},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Preferential multi-objective bayesian optimization},
  url          = {https://openreview.net/forum?id=mjsoESaWDH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). [RE] GNNBoundary: Towards explaining graph neural networks through the lens of decision boundaries. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zLfLTHOdZW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) can model complex relationships while posing significant interpretability challenges due to the unique and varying properties of graph structures, which hinder the adaptation of existing methods from other domains. To address interpretability challenges in GNNs, GNNBoundary was designed as a model-level explainability tool to provide insights into their overall behavior. This paper aims to thoroughly evaluate the reproducibility, robustness, and practical applicability of the findings presented in the original work by replicating and extending their experiments, highlighting both strengths and limitations while considering potential future improvements. Our results show that while the algorithm can reliably generate near-boundary graphs in certain settings, its performance is highly sensitive to hyperparameter choices and suffers from convergence issues. Furthermore, we find that the generated solutions lack diversity, often representing only a single region on the decision boundary, which limits their effectiveness in broader decision boundary analysis. All the code used throughout the research is publicly available on GitHub.},
  archive      = {J_TMLR},
  author       = {Tyme Chatupanyachotikul and Leonard Horns and Matei Nastase},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {[RE] GNNBoundary: Towards explaining graph neural networks through the lens of decision boundaries},
  url          = {https://openreview.net/forum?id=zLfLTHOdZW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-uniform confidence spheres for means of random vectors. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2NSb3cJE03'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study sequential mean estimation in $\mathbb{R}^d$. In particular, we derive time-uniform confidence spheres---\emph{confidence sphere sequences} (CSSs)---which contain the mean of random vectors with high probability simultaneously across all sample sizes. Our results include a dimension-free CSS for log-concave random vectors, a dimension-free CSS for sub-Gaussian random vectors, and CSSs for sub-$\psi$ random vectors (which includes sub-gamma, and sub-exponential distributions). Many of our results are optimal. For sub-Gaussian distributions we also provide a CSS which tracks a time-varying mean, generalizing Robbins' mixture approach to the multivariate setting. Finally, we provide several CSSs for heavy-tailed random vectors (two moments only). Our bounds hold under a martingale assumption on the mean and do not require that the observations be iid. Our work is based on PAC-Bayesian theory and inspired by an approach of Catoni and Giulini.},
  archive      = {J_TMLR},
  author       = {Ben Chugg and Hongjian Wang and Aaditya Ramdas},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Time-uniform confidence spheres for means of random vectors},
  url          = {https://openreview.net/forum?id=2NSb3cJE03},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards identifiability of micro total effects in summary causal graphs with latent confounding: Extension of the front-door criterion. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5f7YlSKG1l'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conducting experiments to estimate total effects can be challenging due to cost, ethical concerns, or practical limitations. As an alternative, researchers often rely on causal graphs to determine whether these effects can be identified from observational data. Identifying total effects in fully specified causal graphs has received considerable attention, with Pearl's front-door criterion enabling the identification of total effects in the presence of latent confounding even when no variable set is sufficient for adjustment. However, specifying a complete causal graph is challenging in many domains. Extending these identifiability results to partially specified graphs is crucial, particularly in dynamic systems where causal relationships evolve over time. This paper addresses the challenge of identifying total effects using a specific and well-known partially specified graph in dynamic systems called a summary causal graph, which does not specify the temporal lag between causal relations and can contain cycles. In particular, this paper presents sufficient graphical conditions for identifying total effects from observational data, even in the presence of cycles and latent confounding, and when no variable set is sufficient for adjustment.},
  archive      = {J_TMLR},
  author       = {Charles K. Assaad},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards identifiability of micro total effects in summary causal graphs with latent confounding: Extension of the front-door criterion},
  url          = {https://openreview.net/forum?id=5f7YlSKG1l},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How far away are truly hyperparameter-free learning algorithms?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6BlOCx5c5T'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite major advances in methodology, hyperparameter tuning remains a crucial (and expensive) part of the development of machine learning systems. Even ignoring architectural choices, deep neural networks have a large number of optimization and regularization hyperparameters that need to be tuned carefully per workload in order to obtain the best results. In a perfect world, training algorithms would not require workload-specific hyperparameter tuning, but would instead have default settings that performed well across many workloads. Recently, there has been a growing literature on optimization methods which attempt to reduce the number of hyperparameters---particularly the learning rate and its accompanying schedule. Given these developments, how far away is the dream of neural network training algorithms that completely obviate the need for painful tuning? In this paper, we evaluate the potential of learning-rate-free methods as components of hyperparameter-free methods. We freeze their (non-learning rate) hyperparameters to default values, and score their performance using the recently-proposed AlgoPerf: Training Algorithms benchmark. We found that literature-supplied default settings performed poorly on the benchmark, so we performed a search for hyperparameter configurations that performed well across all workloads simultaneously. The best "algoperf-calibrated" learning-rate-free methods had much improved performance but still lagged slightly behind a similarly calibrated NadamW baseline in overall benchmark score. Our results suggest that there is still much room for improvement for learning-rate-free methods, and that testing against a strong, workload-agnostic baseline is important to improve hyperparameter reduction techniques.},
  archive      = {J_TMLR},
  author       = {Priya Kasimbeg and Vincent Roulet and Naman Agarwal and Sourabh Medapati and Fabian Pedregosa and Atish Agarwala and George E. Dahl},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How far away are truly hyperparameter-free learning algorithms?},
  url          = {https://openreview.net/forum?id=6BlOCx5c5T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ETGL-DDPG: A deep deterministic policy gradient algorithm for sparse reward continuous control. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6g1WJ55N51'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider deep deterministic policy gradient (DDPG) in the context of reinforcement learning with sparse rewards. To enhance exploration, we introduce a search procedure, \emph{${\epsilon}{t}$-greedy}, which generates exploratory options for exploring less-visited states. We prove that search using $\epsilon t$-greedy has polynomial sample complexity under mild MDP assumptions. To more efficiently use the information provided by rewarded transitions, we develop a new dual experience replay buffer framework, \emph{GDRB}, and implement \emph{longest n-step returns}. The resulting algorithm, \emph{ETGL-DDPG}, integrates all three techniques: \bm{$\epsilon t$}-greedy, \textbf{G}DRB, and \textbf{L}ongest $n$-step, into DDPG. We evaluate ETGL-DDPG on standard benchmarks and demonstrate that it outperforms DDPG, as well as other state-of-the-art methods, across all tested sparse-reward continuous environments. Ablation studies further highlight how each strategy individually enhances the performance of DDPG in this setting.},
  archive      = {J_TMLR},
  author       = {Ehsan Futuhi and Shayan Karimi and Chao Gao and Martin Müller},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ETGL-DDPG: A deep deterministic policy gradient algorithm for sparse reward continuous control},
  url          = {https://openreview.net/forum?id=6g1WJ55N51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent mixed-effect models for high-dimensional longitudinal data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7A96yteeF9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling longitudinal data is an important yet challenging task. These datasets can be high-dimensional, contain non-linear effects and feature time-varying covariates. Gaussian process (GP) prior-based variational autoencoders (VAEs) have emerged as a promising approach due to their ability to model time-series data. However, they are costly to train and struggle to fully exploit the rich covariates characteristic of longitudinal data, making them difficult for practitioners to use effectively. In this work, we leverage linear mixed models (LMMs) and amortized variational inference to provide conditional priors for VAEs, and propose LMM-VAE, a scalable, interpretable and identifiable model. We highlight theoretical connections between it and GP-based techniques, providing a unified framework for this class of methods. Our proposal performs competitively compared to existing approaches across simulated and real-world datasets.},
  archive      = {J_TMLR},
  author       = {Priscilla Ong and Manuel Haussmann and Otto Lönnroth and Harri Lähdesmäki},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent mixed-effect models for high-dimensional longitudinal data},
  url          = {https://openreview.net/forum?id=7A96yteeF9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the effects of fairness interventions using pointwise representational similarity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CkVlt2Qgdb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) algorithms can often exhibit discriminatory behavior, negatively affecting certain populations across protected groups. To address this, numerous debiasing methods, and consequently evaluation measures, have been proposed. Current evaluation measures for debiasing methods suffer from two main limitations: (1) they primarily provide a global estimate of unfairness, failing to provide a more fine-grained analysis, and (2) they predominantly analyze the model output on a specific task, failing to generalize the findings to other tasks. In this work, we introduce Pointwise Normalized Kernel Alignment (PNKA), a pointwise representational similarity measure that addresses these limitations by measuring how debiasing measures affect the intermediate representations of individuals. On tabular data, the use of PNKA reveals previously unknown insights: while group fairness predominantly influences a small subset of the population, maintaining high representational similarity for the majority, individual fairness constraints uniformly impact representations across the entire population, altering nearly every data point. We show that by evaluating representations using PNKA, we can reliably predict the behavior of ML models trained on these representations. Moreover, applying PNKA to language embeddings shows that existing debiasing methods may not perform as intended, failing to remove biases from stereotypical words and sentences. Our findings suggest that current evaluation measures for debiasing methods are insufficient, highlighting the need for a deeper understanding of the effects of debiasing methods, and show how pointwise representational similarity metrics can help with fairness audits.},
  archive      = {J_TMLR},
  author       = {Camila Kolling and Till Speicher and Vedant Nanda and Mariya Toneva and Krishna P. Gummadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Investigating the effects of fairness interventions using pointwise representational similarity},
  url          = {https://openreview.net/forum?id=CkVlt2Qgdb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JkMifr17wc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves competitive sampling times while running on consumer-grade CPUs.},
  archive      = {J_TMLR},
  author       = {Christopher Scarvelis and Haitz Sáez de Ocáriz Borde and Justin Solomon},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Closed-form diffusion models},
  url          = {https://openreview.net/forum?id=JkMifr17wc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uniform noise distribution and compact clusters: Unveiling the success of self-supervised learning in label noise. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LDBjgS5Ez7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise is ubiquitous in real-world datasets, posing significant challenges to machine learning models. While self-supervised learning (SSL) algorithms have empirically demonstrated effectiveness in learning noisy labels, the theoretical understanding of their effectiveness remains underexplored. In this paper, we present a theoretical framework to understand how SSL methods enhance learning with noisy labels, especially for the instance-dependent label noise. We reveal that the uniform and compact cluster structures induced by contrastive SSL play a crucial role in mitigating the adverse effects of label noise. Specifically, we theoretically show that a classifier trained on SSL-learned representations significantly outperforms one trained using traditional supervised learning methods. This results from two key merits of SSL representations over label noise: 1. Uniform Noise Distribution: Label noise becomes uniformly distributed over SSL representations with respect to the true class labels, rather than the noisy ones, leading to an easier learning task. 2. Enhanced Cluster Structure: SSL enhances the formation of well-separated and compact categorical clusters, increasing inter-class distances while tightening intra-class clusters. We further theoretically justify the benefits of training a classifier on such structured representations, demonstrating that it encourages the classifier trained on noisy data to be aligned with the optimal classifier. Extensive experiments validate the robustness of SSL representations in combating label noise, confirming the practical values of our theoretical findings.},
  archive      = {J_TMLR},
  author       = {Pengcheng Xu and Li Yi and Gezheng Xu and Xi Chen and Ian McLeod and Charles Ling and Boyu Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uniform noise distribution and compact clusters: Unveiling the success of self-supervised learning in label noise},
  url          = {https://openreview.net/forum?id=LDBjgS5Ez7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guided discrete diffusion for electronic health record generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=N2rWhTgits'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records (EHRs) are a pivotal data source that enables numerous applications in computational medicine, e.g., disease progression prediction, clinical trial design, and health economics and outcomes research. Despite wide usability, their sensitive nature raises privacy and confidentially concerns, which limit potential use cases. To tackle these challenges, we explore the use of generative models to synthesize artificial, yet realistic EHRs. While diffusion-based methods have recently demonstrated state-of-the-art performance in generating other data modalities and overcome the training instability and mode collapse issues that plague previous GAN-based approaches, their applications in EHR generation remain underexplored. The discrete nature of tabular medical code data in EHRs poses challenges for high-quality data generation, especially for continuous diffusion models. To this end, we introduce a novel tabular EHR generation method, EHR-D3PM, which enables both unconditional and conditional generation using the discrete diffusion model. Our experiments demonstrate that EHR-D3PM significantly outperforms existing generative baselines on comprehensive fidelity and utility metrics while maintaining less attribute and membership vulnerability risks. Furthermore, we show EHR-D3PM is effective as a data augmentation method and enhances performance on downstream tasks when combined with real data.},
  archive      = {J_TMLR},
  author       = {Jun Han and Zixiang Chen and Yongqian Li and Yiwen Kou and Eran Halperin and Robert E. Tillman and Quanquan Gu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Guided discrete diffusion for electronic health record generation},
  url          = {https://openreview.net/forum?id=N2rWhTgits},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M3CoL: Harnessing shared relations via multimodal mixup contrastive learning for multimodal classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NeQYi56MFj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research.},
  archive      = {J_TMLR},
  author       = {Raja Kumar and Raghav Singhal and Pranamya Prashant Kulkarni and Deval Mehta and Kshitij Sharad Jadhav},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {M3CoL: Harnessing shared relations via multimodal mixup contrastive learning for multimodal classification},
  url          = {https://openreview.net/forum?id=NeQYi56MFj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep augmentation: Dropout as augmentation for self-supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OjWB2671AR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite dropout’s ubiquity in machine learning, its effectiveness as a form of data augmentation remains under-explored. We address two key questions: (i) When is dropout effective as an augmentation strategy? (ii) Is dropout uniquely effective under these conditions? To explore these questions, we propose Deep Augmentation, a network- and modality-agnostic method that applies dropout or PCA transformations to targeted layers in neural networks. Through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning, we find that uniformly applying dropout across layers does not consistently improve performance. Instead, dropout proves most beneficial in deeper layers and can be matched by alternative augmentations (e.g., PCA). We also show that a stop-gradient operation is critical for ensuring dropout functions effectively as an augmentation, and that performance trends invert when moving from contrastive tasks to supervised tasks. Our analysis suggests that Deep Augmentation helps mitigate inter-layer co-adaptation---a notable issue in self-supervised learning due to the absence of labeled data. Drawing on these insights, we outline a procedure for selecting the optimal augmentation layer and demonstrate that Deep Augmentation can outperform traditional input-level augmentations. This simple yet powerful approach can be seamlessly integrated into a wide range of architectures and modalities, yielding notable gains in both performance and generalization.},
  archive      = {J_TMLR},
  author       = {Rickard Brüel Gabrielsson and Tongzhou Wang and Manel Baradad and Justin Solomon},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep augmentation: Dropout as augmentation for self-supervised learning},
  url          = {https://openreview.net/forum?id=OjWB2671AR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Policy optimization via adv2: Adversarial learning on advantage functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Oyueig10Ed'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the reduction of learning in adversarial Markov decision processes [MDPs] to adversarial learning based on $Q$--values; this reduction has been considered in a number of recent articles as one building block to perform policy optimization. Namely, we first consider and extend this reduction in an ideal setting where an oracle provides value functions: it may involve any adversarial learning strategy (not just exponential weights) and it may be based indifferently on $Q$--values or on advantage functions. We then present two extensions: on the one hand, convergence of the last iterate for a vast class of adversarial learning strategies (again, not just exponential weights), satisfying a property called monotonicity of weights; on the other hand, stronger regret criteria for learning in MDPs, inherited from the stronger regret criteria of adversarial learning called strongly adaptive regret and tracking regret. Third, we demonstrate how adversarial learning, also referred to as aggregation of experts, relates to aggregation (orchestration) of expert policies: we obtain stronger forms of performance guarantees in this setting than existing ones, via yet another, simple reduction. Finally, we discuss the impact of the reduction of learning in adversarial MDPs to adversarial learning in the practical scenarios where transition kernels are unknown and value functions must be learned. In particular, we review the literature and note that many strategies for policy optimization feature a policy-improvement step based on exponential weights with estimated $Q$--values. Our main message is that this step may be replaced by the application of any adversarial learning strategy on estimated $Q$--values or on estimated advantage functions. We leave the empirical evaluation of these twists for future research.},
  archive      = {J_TMLR},
  author       = {Matthieu Jonckheere and Chiara Mignacco and Gilles Stoltz},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Policy optimization via adv2: Adversarial learning on advantage functions},
  url          = {https://openreview.net/forum?id=Oyueig10Ed},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOORL: A framework for integrating offline-online reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PHsfZnF2FC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sample efficiency and exploration remain critical challenges in Deep Reinforcement Learning (DRL), particularly in complex domains. Offline RL, which enables agents to learn optimal policies from static, pre-collected datasets, has emerged as a promising alternative. However, offline RL is constrained by issues such as out-of-distribution (OOD) actions that limit policy performance and generalization. To overcome these limitations, we propose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework that unifies offline and online RL for efficient and scalable learning. While previous hybrid methods rely on extensive design choices and added complexity to utilize offline data effectively, MOORL introduces a meta-policy that seamlessly adapts across offline and online trajectories. This enables the agent to leverage offline data for robust initialization while utilizing online interactions to drive efficient exploration. Importantly, MOORL addresses the key challenges of hybrid RL in terms of being design-free. Our theoretical analysis demonstrates that the hybrid approach enhances exploration by effectively combining the complementary strengths of offline and online data. Furthermore, we demonstrate that MOORL learns a stable Q-function without relying on extensive design choices. Extensive experiments on 28 tasks from the D4RL and V-D4RL benchmarks validate its effectiveness, showing consistent improvements over state-of-the-art offline and hybrid RL baselines. With minimal computational overhead, MOORL achieves strong performance, underscoring its potential for practical applications in real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Gaurav Chaudhary and Washim Uddin Mondal and Laxmidhar Behera},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MOORL: A framework for integrating offline-online reinforcement learning},
  url          = {https://openreview.net/forum?id=PHsfZnF2FC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RefinedFields: Radiance fields refinement for planar scene representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=S6JpSsYBDZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planar scene representations have recently witnessed increased interests for modeling scenes from images, as their lightweight planar structure enables compatibility with image-based models. Notably, K-Planes have gained particular attention as they extend planar scene representations to support in-the-wild scenes, in addition to object-level scenes. However, their visual quality has recently lagged behind that of state-of-the-art techniques. To reduce this gap, we propose RefinedFields, a method that leverages pre-trained networks to refine K-Planes scene representations via optimization guidance using an alternating training procedure. We carry out extensive experiments and verify the merit of our method on synthetic data and real tourism photo collections. RefinedFields enhances rendered scenes with richer details and improves upon its base representation on the task of novel view synthesis. Our project page can be found at https://refinedfields.github.io .},
  archive      = {J_TMLR},
  author       = {Karim Kassab and Antoine Schnepf and Jean-Yves Franceschi and Laurent Caraffa and Jeremie Mary and Valerie Gouet-Brunet},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RefinedFields: Radiance fields refinement for planar scene representations},
  url          = {https://openreview.net/forum?id=S6JpSsYBDZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A local polyak-Łojasiewicz and descent lemma of gradient descent for overparametrized linear models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VPl3T43Hxb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prior work on the convergence of gradient descent (GD) for overparameterized neural networks relies on strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (large, spectral, balanced). Recent efforts to relax these assumptions focus on two-layer linear networks trained with the squared loss. In this work, we derive a linear convergence rate for training two-layer linear neural networks with GD for general losses and under relaxed assumptions on the step size, width, and initialization. A key challenge in deriving this result is that classical ingredients for deriving convergence rates for nonconvex problems, such as the Polyak-Łojasiewicz (PL) condition and Descent Lemma, do not hold globally for overparameterized neural networks. Here, we prove that these two conditions hold locally with local constants that depend on the weights. Then, we provide bounds on these local constants, which depend on the initialization of the weights, the current loss, and the global PL and smoothness constants of the non-overparameterized model. Based on these bounds, we derive a linear convergence rate for GD. Our convergence analysis not only improves upon prior results but also suggests a better choice for the step size, as verified through our numerical experiments.},
  archive      = {J_TMLR},
  author       = {Ziqing Xu and Hancheng Min and Salma Tarmoun and Enrique Mallada and Rene Vidal},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A local polyak-Łojasiewicz and descent lemma of gradient descent for overparametrized linear models},
  url          = {https://openreview.net/forum?id=VPl3T43Hxb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hitchhiker's guide on the relation of energy-based models with other generative models, sampling and statistical physics: A comprehensive review. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VTgixSbrJI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-Based Models (EBMs) have emerged as a powerful framework in the realm of generative modeling, offering a unique perspective that aligns closely with principles of statistical mechanics. This review aims to provide physicists with a comprehensive understanding of EBMs, delineating their connection to other generative models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Normalizing Flows. We explore the sampling techniques crucial for EBMs, including Markov Chain Monte Carlo (MCMC) methods, and draw parallels between EBM concepts and statistical mechanics, highlighting the significance of energy functions and partition functions. Furthermore, we delve into state-of-the-art training methodologies for EBMs, covering recent advancements and their implications for enhanced model performance and efficiency. This review is designed to clarify the often complex interconnections between these models, which can be challenging due to the diverse communities working on the topic.},
  archive      = {J_TMLR},
  author       = {Davide Carbone},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hitchhiker's guide on the relation of energy-based models with other generative models, sampling and statistical physics: A comprehensive review},
  url          = {https://openreview.net/forum?id=VTgixSbrJI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical error bounds for GANs with nonlinear objective functionals. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZgjhykPSdU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) are unsupervised learning methods for training a generator distribution to produce samples that approximate those drawn from a target distribution. Many such methods can be formulated as minimization of a metric or divergence between probability distributions. Recent works have derived statistical error bounds for GANs that are based on integral probability metrics (IPMs), e.g., WGAN which is based on the 1-Wasserstein metric. In general, IPMs are defined by optimizing a linear functional (difference of expectations) over a space of discriminators. A much larger class of GANs, which we here call $(f,\Gamma)$-GANs, can be constructed using $f$-divergences (e.g., Jensen-Shannon, KL, or $\alpha$-divergences) together with a regularizing discriminator space $\Gamma$ (e.g., $1$-Lipschitz functions). These GANs have nonlinear objective functions, depending on the choice of $f$, and have been shown to exhibit improved performance in a number of applications. In this work we derive statistical error bounds for $(f,\Gamma)$-GANs for general classes of $f$ and $\Gamma$ in the form of finite-sample concentration inequalities. These results prove the statistical consistency of $(f,\Gamma)$-GANs and reduce to the known results for IPM-GANs in the appropriate limit. Our results use novel Rademacher complexity bounds which provide new insight into the performance of IPM-GANs for distributions with unbounded support and have application to statistical learning tasks beyond GANs.},
  archive      = {J_TMLR},
  author       = {Jeremiah Birrell},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Statistical error bounds for GANs with nonlinear objective functionals},
  url          = {https://openreview.net/forum?id=ZgjhykPSdU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning with physics knowledge for prediction: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZiJYahyXLU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.},
  archive      = {J_TMLR},
  author       = {Joe Watson and Chen Song and Oliver Weeger and Theo Gruner and An Thai Le and Kay Hansel and Ahmed Hendawy and Oleg Arenz and Will Trojak and Miles Cranmer and Carlo D'Eramo and Fabian Buelow and Tanmay Goyal and Jan Peters and Martin W Hoffmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Machine learning with physics knowledge for prediction: A survey},
  url          = {https://openreview.net/forum?id=ZiJYahyXLU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining the behavior of black-box prediction algorithms with causal learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZrqLpXbXvA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the “explanatory units” are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm’s behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allow for arbitrary unmeasured confounding among features. We demonstrate the resulting graph can differentiate between interpretable features that causally influence model predictions versus those that are merely associated with model predictions due to confounding. Our approach is motivated by a counterfactual theory of causal explanation wherein good explanations point to factors that are “difference-makers” in an interventionist sense.},
  archive      = {J_TMLR},
  author       = {Numair Sani and Daniel Malinsky and Ilya Shpitser},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining the behavior of black-box prediction algorithms with causal learning},
  url          = {https://openreview.net/forum?id=ZrqLpXbXvA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional image synthesis with diffusion models: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ewwNKwh6SK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional image synthesis based on user-specified requirements is a key component in creating complex visual content. In recent years, diffusion-based generative modeling has become a highly effective way for conditional image synthesis, leading to exponential growth in the literature. However, the complexity of diffusion-based modeling, the wide range of image synthesis tasks, and the diversity of conditioning mechanisms present significant challenges for researchers to keep up with rapid developments and to understand the core concepts on this topic. In this survey, we categorize existing works based on how conditions are integrated into the two fundamental components of diffusion-based modeling, i.e., the denoising network and the sampling process. We specifically highlight the underlying principles, advantages, and potential challenges of various conditioning approaches during the training, re-purposing, and specialization stages to construct a desired denoising network. We also summarize six mainstream conditioning mechanisms in the sampling process. All discussions are centered around popular applications. Finally, we pinpoint several critical yet still unsolved problems and suggest some possible solutions for future research.},
  archive      = {J_TMLR},
  author       = {Zheyuan Zhan and Defang Chen and Jian-Ping Mei and Zhenghe Zhao and Jiawei Chen and Chun Chen and Siwei Lyu and Can Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conditional image synthesis with diffusion models: A survey},
  url          = {https://openreview.net/forum?id=ewwNKwh6SK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LASP: Linear attention sequence parallelism. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gG8sQUUtN7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence parallelism (SP) serves as a prevalent strategy to handle long sequences that exceed the memory limit of a single device. However, for linear sequence modeling methods like linear attention, existing SP approaches do not take advantage of their right-product-first feature, resulting in sub-optimal communication efficiency and usability. In this paper, we introduce Linear Attention Sequence Parallelism (LASP), an efficient SP approach designed for linear attention-based transformer models. Specifically, we design an efficient point-to-point ring-style communication mechanism to leverage the right-product kernel trick of linear attention, which sharply decreases the communication overhead, comparing with existing SP methods. We enhance the computation efficiency of LASP by performing kernel fusion and intermediate state caching, making the implementation of LASP hardware-friendly on GPUs. Furthermore, we meticulously ensure the compatibility of sequence-level LASP with all types of batch-level data parallel methods, which is vital for distributed training on large clusters with very-long sequences. We also discuss the generalization of LASP on other linear sequence modeling methods. Extensive experiments on linear attention-based models are conducted with varying sequence lengths from 2K to 4096K. LASP scales sequence length up to 4096K on 128 GPUs, which is 8$\times$ longer than existing SP methods. Code is available at: \url{https://github.com/OpenNLPLab/LASP}.},
  archive      = {J_TMLR},
  author       = {Weigao Sun and Zhen Qin and Dong Li and Xuyang Shen and Yu Qiao and Yiran Zhong},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LASP: Linear attention sequence parallelism},
  url          = {https://openreview.net/forum?id=gG8sQUUtN7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting company fundamentals. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=haf78jerSt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Company fundamentals are key to assessing companies' financial and overall success and stability. Forecasting them is important in multiple fields, including investing and econometrics. While statistical and contemporary machine learning methods have been applied to many time series tasks, there is a lack of comparison of these approaches on this particularly challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate the theoretical properties and practical performance of 24 deterministic and probabilistic company fundamentals forecasting models on real company data. We observe that deep learning models provide superior forecasting performance to classical models, in particular when considering uncertainty estimation. To validate the findings, we compare them to human analyst expectations and find that their accuracy is comparable to the automatic forecasts. We further show how these high-quality forecasts can benefit automated stock allocation. We close by presenting possible ways of integrating domain experts to further improve performance and increase reliability.},
  archive      = {J_TMLR},
  author       = {Felix Divo and Eric Endress and Kevin Endler and Kristian Kersting and Devendra Singh Dhami},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Forecasting company fundamentals},
  url          = {https://openreview.net/forum?id=haf78jerSt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group fair federated learning via stochastic kernel regularization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k8x44wVIs1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring \textbf{group fairness} in federated learning (FL) presents unique challenges due to data heterogeneity and communication constraints. We propose Kernel Fair Federated Learning (\texttt{KFFL}), a novel framework that incorporates group fairness into FL models using the Kernel Hilbert-Schmidt Independence Criterion (KHSIC) as a fairness regularizer. To address scalability, \texttt{KFFL} approximates KHSIC with Random Feature Maps (RFMs), significantly reducing computational and communication overhead while achieving \textit{group fairness}. To address the resulting non-convex optimization problem, we propose \texttt{FedProxGrad}, a federated proximal gradient algorithm that guarantees convergence. Through experiments on standard benchmark datasets across both IID and Non-IID settings for regression and classification tasks, \texttt{KFFL} demonstrates its ability to balance accuracy and fairness effectively, outperforming existing methods by comprehensively exploring the Pareto Frontier. Furthermore, we introduce \texttt{KFFL-TD}, a time-delayed variant that further reduces communication rounds, enhancing efficiency in decentralized environments.},
  archive      = {J_TMLR},
  author       = {Huzaifa Arif and Pin-Yu Chen and Keerthiram Murugesan and Alex Gittens},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Group fair federated learning via stochastic kernel regularization},
  url          = {https://openreview.net/forum?id=k8x44wVIs1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Music foundation model as generic booster for music downstream tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kHl4JzyNzF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate the efficacy of using intermediate representations from a single foundation model to enhance various music downstream tasks. We introduce SoniDo, a music foundation model (MFM) designed to extract hierarchical features from target music samples. By leveraging hierarchical intermediate features, SoniDo constrains the information granularity, leading to improved performance across various downstream tasks including both understanding and generative tasks. We specifically evaluated this approach on representative tasks such as music tagging, music transcription, music source separation, and music mixing. Our results reveal that the features extracted from foundation models provide valuable enhancements in training downstream task models. This highlights the capability of using features extracted from music foundation models as a booster for downstream tasks. Our approach not only benefits existing task-specific models but also supports music downstream tasks constrained by data scarcity. This paves the way for more effective and accessible music processing solutions.},
  archive      = {J_TMLR},
  author       = {Wei-Hsiang Liao and Yuhta Takida and Yukara Ikemiya and Zhi Zhong and Chieh-Hsin Lai and Giorgio Fabbro and Kazuki Shimada and Keisuke Toyama and Kin Wai Cheuk and Marco A. Martínez-Ramírez and Shusuke Takahashi and Stefan Uhlich and Taketo Akama and Woosung Choi and Yuichiro Koyama and Yuki Mitsufuji},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Music foundation model as generic booster for music downstream tasks},
  url          = {https://openreview.net/forum?id=kHl4JzyNzF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the utility of existing fine-tuned models on data-scarce domains. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kY2fKLOGkI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have been observed to perform well on a wide range of downstream tasks when fine-tuned on domain-specific data. However, such data may not be readily available in many applications, motivating zero-shot or few-shot approaches using existing domain or task adjacent (fine-tuned) models, which we call DAFT. While several fine-tuned models for various tasks are available, finding one appropriate DAFT model for a given task is often not straight forward. In this paper, we explore different utilization techniques of these existing DAFT models for data-scarce problems, i.e., tasks for which data is not available or limited. We observe that for zero-shot problems, ensembling of DAFT models provides an accuracy performance close to that of the single best model. With few-shot problems (few data from target domain available), this performance can be improved further by picking or putting more weights to the DAFT models that are expected to perform better on the target task.},
  archive      = {J_TMLR},
  author       = {Md Ibrahim Ibne Alam and Parikshit Ram and Soham Dan and Horst Samulowitz and Koushik Kar},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the utility of existing fine-tuned models on data-scarce domains},
  url          = {https://openreview.net/forum?id=kY2fKLOGkI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cometh: A continuous-time discrete-state graph diffusion model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nuN1mRrrjX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete-state denoising diffusion models led to state-of-the-art performance in graph generation, especially in the molecular domain. Recently, they have been transposed to continuous time, allowing more flexibility in the reverse process and a better trade-off between sampling efficiency and quality. Here, to leverage the benefits of both approaches, we propose Cometh, a continuous-time discrete-state graph diffusion model, tailored to the specificities of graph data. In addition, we also successfully replaced the set of structural encodings previously used in the discrete graph diffusion model with a single random-walk-based encoding, providing a simple and principled way to boost the model's expressive power. Empirically, we show that integrating continuous time leads to significant improvements across various metrics over state-of-the-art discrete-state diffusion models on a large set of molecular and non-molecular benchmark datasets. In terms of VUN samples, Cometh obtains a near-perfect performance of 99.5% on the planar graph dataset and outperforms DiGress by 12.6% on the large GuacaMol dataset.},
  archive      = {J_TMLR},
  author       = {Antoine Siraudin and Fragkiskos D. Malliaros and Christopher Morris},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cometh: A continuous-time discrete-state graph diffusion model},
  url          = {https://openreview.net/forum?id=nuN1mRrrjX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pruning feature extractor stacking for cross-domain few-shot learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=p499xXaclC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining knowledge from source domains to learn efficiently from a few labelled instances in a target domain is a transfer learning problem known as cross-domain few-shot learning (CDFSL). Feature extractor stacking (FES) is a state-of-the-art CDFSL method that maintains a collection of source domain feature extractors instead of a single universal extractor. FES uses stacked generalisation to build an ensemble from extractor snapshots saved during target domain fine-tuning. It outperforms several contemporary universal model-based CDFSL methods in the Meta-Dataset benchmark. However, it incurs higher storage cost because it saves a snapshot for every fine-tuning iteration for every extractor. In this work, we propose a bidirectional snapshot selection strategy for FES, leveraging its cross-validation process and the ordered nature of its snapshots, and demonstrate that a 95% snapshot reduction can be achieved while retaining the same level of accuracy.},
  archive      = {J_TMLR},
  author       = {Hongyu Wang and Eibe Frank and Bernhard Pfahringer and Geoff Holmes},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pruning feature extractor stacking for cross-domain few-shot learning},
  url          = {https://openreview.net/forum?id=p499xXaclC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Studying exploration in RL: An optimal transport analysis of occupancy measure trajectories. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pdC092Nn8N'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising successes of RL are propelled by combining smart algorithmic strategies and deep architectures to optimize the distribution of returns and visitations over the state-action space. A quantitative framework to compare the learning processes of these eclectic RL algorithms is currently absent but desired in practice. We address this gap by representing the learning process of an RL algorithm as a sequence of policies generated during training, and then studying the policy trajectory induced in the manifold of state-action occupancy measures. Using an optimal transport-based metric, we measure the length of the paths induced by the policy sequence yielded by an RL algorithm between an initial policy and a final optimal policy. Hence, we first define the Effort of Sequential Learning (ESL). ESL quantifies the relative distance that an RL algorithm travels compared to the shortest path from the initial to the optimal policy. Furthermore, we connect the dynamics of policies in the occupancy measure space and regret (another metric to understand the suboptimality of an RL algorithm), by defining the Optimal Movement Ratio (OMR). OMR assesses the fraction of movements in the occupancy measure space that effectively reduce an analogue of regret. Finally, we derive approximation guarantees to estimate ESL and OMR with a finite number of samples and without access to an optimal policy. Through empirical analyses across various environments and algorithms, we demonstrate that ESL and OMR provide insights into the exploration processes of RL algorithms and the hardness of different tasks in discrete and continuous MDPs.},
  archive      = {J_TMLR},
  author       = {Reabetswe M. Nkhumise and Debabrota Basu and Tony J. Prescott and Aditya Gilra},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Studying exploration in RL: An optimal transport analysis of occupancy measure trajectories},
  url          = {https://openreview.net/forum?id=pdC092Nn8N},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring weak-to-strong generalization for CLIP-based classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=quE8gDDegf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning large-scale commercial models with user intent is crucial to preventing harmful outputs. Current methods rely on human supervision but become impractical as model complexity increases. When models surpass human knowledge, providing accurate feedback becomes challenging and inefficient. A novel solution proposed recently is using a weaker model to supervise a stronger model. This concept leverages the ability of weaker models to perform evaluations, thereby reducing the workload on human supervisors. Previous work has shown the effectiveness of weak-to-strong generalization in the context of language-only models. Extending this concept to vision-language models leverages these insights, adapting the proven benefits to a multi-modal context. In our study, we explore weak-to-strong generalization for CLIP-based classification. We propose a method, \emph{class prototype learning} (CPL), which aims to enhance the classification capabilities of the CLIP model, by learning more representative prototypes for each category. Our findings indicate that, despite using a simple loss function under weak supervision, CPL yields robust improvements in targeted scenarios, particularly when pretraining is limited. Extensive experiments demonstrate that our approach is effective under these settings, achieving a 3.67\% improvement over strong baseline methods.},
  archive      = {J_TMLR},
  author       = {Jinhao Li and Sarah Monazam Erfani and Lei Feng and James Bailey and Feng Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploring weak-to-strong generalization for CLIP-based classification},
  url          = {https://openreview.net/forum?id=quE8gDDegf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DyGMamba: Efficiently modeling long-term temporal dependency on continuous-time dynamic graphs with state space models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sq5AJvVuha'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget.},
  archive      = {J_TMLR},
  author       = {Zifeng Ding and Yifeng Li and Yuan He and Antonio Norelli and Jingcheng Wu and Volker Tresp and Michael M. Bronstein and Yunpu Ma},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DyGMamba: Efficiently modeling long-term temporal dependency on continuous-time dynamic graphs with state space models},
  url          = {https://openreview.net/forum?id=sq5AJvVuha},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on large language model acceleration based on KV cache management. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=z3JZzu9EA3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have revolutionized a wide range of domains such as natural language processing, computer vision, and multi-modal tasks due to their ability to comprehend context and perform logical reasoning. However, the computational and memory demands of LLMs, particularly during inference, pose significant challenges when scaling them to real-world, long-context, and real-time applications. Key-Value (KV) cache management has emerged as a critical optimization technique for accelerating LLM inference by reducing redundant computations and improving memory utilization. This survey provides a comprehensive overview of KV cache management strategies for LLM acceleration, categorizing them into token-level, model-level, and system-level optimizations. Token-level strategies include KV cache selection, budget allocation, merging, quantization, and low-rank decomposition, while model-level optimizations focus on architectural innovations and attention mechanisms to enhance KV reuse. System-level approaches address memory management, scheduling, and hardware-aware designs to improve efficiency across diverse computing environments. Additionally, the survey provides an overview of both text and multimodal datasets and benchmarks used to evaluate these strategies. By presenting detailed taxonomies and comparative analyses, this work aims to offer useful insights for researchers and practitioners to support the development of efficient and scalable KV cache management techniques, contributing to the practical deployment of LLMs in real-world applications.},
  archive      = {J_TMLR},
  author       = {Haoyang LI and Yiming Li and Anxin Tian and Tianhao Tang and Zhanchao Xu and Xuejia Chen and Nicole HU and Wei Dong and Li Qing and Lei Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on large language model acceleration based on KV cache management},
  url          = {https://openreview.net/forum?id=z3JZzu9EA3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AttentionSmithy: A modular framework for rapid transformer development. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0jhoriH9yA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer architectures have revolutionized a broad spectrum of AI applications by leveraging attention mechanisms for parallelized and long-range sequence processing. Despite their remarkable success, building and customizing transformers remains prohibitively complex for many domain experts who lack deep knowledge of low-level implementations. We introduce AttentionSmithy, a modular software package that lowers the barrier to transformer innovation by decomposing key components---attention modules, feed-forward networks, normalization layers, and positional encodings---into reusable building blocks. By disentangling architectural elements into well-defined interfaces, users can rapidly prototype, adapt, and evaluate transformer variants without extensive coding overhead. Our framework currently supports four distinct positional encoding strategies (sinusoidal, learned, rotary, and ALiBi), offers modular integration of multiple attention methods (including standard attention, Longformer, and Linformer), and integrates seamlessly with neural architecture search (NAS) for automated design exploration. The system is designed to support future extensions with minimal overhead. We validate AttentionSmithy by replicating the original ``Attention Is All You Need'' transformer under resource constraints, demonstrating robust performance on a machine translation task. Leveraging the package’s integrated NAS capability, we identified an optimized model configuration that outperformed our baseline, demonstrating the framework’s effectiveness for automated architecture search and model improvement. We further illustrate AttentionSmithy's adaptability through gene-specific modeling, where a variant of a BERT-style architecture achieves over 95\% accuracy on downstream cell type classification tasks using ranked transcriptomic data. These case studies underscore AttentionSmithy's core advantage: enabling specialized experimentation across diverse application domains---from natural language processing to genomic analysis---by obviating the need for labor-intensive, low-level framework manipulation. We anticipate that AttentionSmithy will serve as a foundation for creative transformer-based solutions, expediting research and development in numerous scientific and industrial fields.},
  archive      = {J_TMLR},
  author       = {Caleb Cranney and Jesse G Meyer},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AttentionSmithy: A modular framework for rapid transformer development},
  url          = {https://openreview.net/forum?id=0jhoriH9yA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-attribute constraint satisfaction via language model rewriting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3q1bUIHTJK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obeying precise constraints on top of multiple external attributes is a common computational problem underlying seemingly different domains, from controlled text generation to protein engineering. Existing language model (LM) controllability methods for multi-attribute constraint satisfaction often rely on specialized architectures or gradient-based classifiers, limiting their flexibility to work with arbitrary black-box evaluators and pretrained models. Current general-purpose large language models, while capable, cannot achieve fine-grained multi-attribute control over external attributes. Thus, we create Multi-Attribute Constraint Satisfaction (MACS), a generalized method capable of finetuning language models on any sequential domain to satisfy user-specified constraints on multiple external real-value attributes. Our method trains LMs as editors by sampling diverse multi-attribute edit pairs from an initial set of paraphrased outputs. During inference, LM iteratively improves upon its previous solution to satisfy constraints for all attributes by leveraging our designed constraint satisfaction reward. We additionally experiment with reward-weighted behavior cloning to further improve the constraint satisfaction rate of LMs. To evaluate our approach, we present a new Fine-grained Constraint Satisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text Style Transfer, where the goal is to simultaneously modify the sentiment and complexity of reviews, and (2) Protein Design, focusing on modulating fluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical results show that MACS achieves the highest threshold satisfaction in both FineCS tasks, outperforming strong domain-specific baselines. Our work opens new avenues for generalized and real-value multi-attribute control, with implications for diverse applications spanning natural language processing and bioinformatics.},
  archive      = {J_TMLR},
  author       = {Ashutosh Baheti and Debanjana Chakraborty and Faeze Brahman and Ronan Le Bras and Ximing Lu and Nouha Dziri and Yejin Choi and Mark Riedl and Maarten Sap},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-attribute constraint satisfaction via language model rewriting},
  url          = {https://openreview.net/forum?id=3q1bUIHTJK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning distributed representations with efficient SoftMax normalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9M4NKMZOPu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning distributed representations, or embeddings, that encode the relational similarity patterns among objects is a relevant task in machine learning. A popular method to learn the embedding matrices $X, Y$ is optimizing a loss function of the term ${\rm SoftMax}(XY^T)$. The complexity required to calculate this term, however, runs quadratically with the problem size, making it a computationally heavy solution. In this article, we propose a linear-time heuristic approximation to compute the normalization constants of ${\rm SoftMax}(XY^T)$ for embedding vectors with bounded norms. We show on some pre-trained embedding datasets that the proposed estimation method achieves higher or comparable accuracy with competing methods. From this result, we design an efficient and task-agnostic algorithm that learns the embeddings by optimizing the cross entropy between the softmax and a set of probability distributions given as inputs. The proposed algorithm is interpretable and easily adapted to arbitrary embedding problems. We consider a few use cases and observe similar or higher performances and a lower computational time than similar ``2Vec'' algorithms.},
  archive      = {J_TMLR},
  author       = {Lorenzo Dall'Amico and Enrico Maria Belliardo},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning distributed representations with efficient SoftMax normalization},
  url          = {https://openreview.net/forum?id=9M4NKMZOPu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offset unlearning for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=A4RLpHPXCu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the strong capabilities of Large Language Models (LLMs) to acquire knowledge from their training corpora, the memorization of sensitive information in the corpora such as copyrighted, biased, and private content has led to ethical and legal concerns. In response to these challenges, unlearning has emerged as a potential remedy for LLMs affected by problematic training data. However, previous unlearning techniques are either not applicable to black-box LLMs due to required access to model internal weights, or violate data protection principles by retaining sensitive data for inference-time correction. We propose $\delta$-unlearning, an offset unlearning framework for black-box LLMs. Instead of tuning the black-box LLM itself, $\delta$-unlearning learns the logit offset needed for unlearning by contrasting the logits from a pair of smaller models. Experiments demonstrate that $\delta$-unlearning can effectively unlearn target data while maintaining similar or even stronger performance on general out-of-forget-scope tasks. $\delta$-unlearning also effectively incorporates different unlearning algorithms, making our approach a versatile solution to adapting various existing unlearning algorithms to black-box LLMs.},
  archive      = {J_TMLR},
  author       = {James Y. Huang and Wenxuan Zhou and Fei Wang and Fred Morstatter and Sheng Zhang and Hoifung Poon and Muhao Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Offset unlearning for large language models},
  url          = {https://openreview.net/forum?id=A4RLpHPXCu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESTOR: Knowledge recovery in machine unlearning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BbwlJpNXgW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models trained on web-scale corpora can memorize undesirable data containing misinformation, copyrighted material, or private or sensitive information. Recently, several machine unlearning algorithms have been proposed to eliminate the effect of such datapoints from trained models-- that is, to approximate *a model that had never been trained on these datapoints in the first place*. However, evaluating the effectiveness of unlearning algorithms remains an open challenge. Previous work has relied on heuristics-- such as verifying that the model can no longer reproduce the specific information targeted for removal while maintaining accuracy on unrelated test data. These approaches inadequately capture the complete effect of reversing the influence of datapoints on a trained model. In this work, we propose the RESTOR framework for machine unlearning evaluation, which assesses the ability of unlearning algorithms for targeted data erasure, by evaluating the ability of models to forget the knowledge introduced in these datapoints, while simultaneously recovering the model's knowledge state had it never encountered these datapoints. RESTOR helps uncover several novel insights about popular unlearning algorithms, and the mechanisms through which they operate-- for instance, identifying that some algorithms merely emphasize forgetting but not recovering knowledge, and that localizing unlearning targets can enhance unlearning performance.},
  archive      = {J_TMLR},
  author       = {Keivan Rezaei and Khyathi Chandu and Soheil Feizi and Yejin Choi and Faeze Brahman and Abhilasha Ravichander},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RESTOR: Knowledge recovery in machine unlearning},
  url          = {https://openreview.net/forum?id=BbwlJpNXgW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal prediction: A theoretical note and benchmarking transductive node classification in graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ed1DBB3sBQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction has become increasingly popular for quantifying the uncertainty associated with machine learning models. Recent work in graph uncertainty quantification has built upon this approach for conformal graph prediction. The nascent nature of these explorations has led to conflicting choices for implementations, baselines, and method evaluation. In this work, we analyze the design choices made in the literature and discuss the tradeoffs associated with existing methods. Building on the existing implementations for existing methods, we introduce techniques to scale existing methods to large-scale graph datasets without sacrificing performance. Our theoretical and empirical results justify our recommendations for future scholarship in graph conformal prediction.},
  archive      = {J_TMLR},
  author       = {Pranav Maneriker and Aditya T. Vadlamani and Anutam Srinivasan and Yuntian He and Ali Payani and srinivasan parthasarathy},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conformal prediction: A theoretical note and benchmarking transductive node classification in graphs},
  url          = {https://openreview.net/forum?id=Ed1DBB3sBQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-driven view subset selection for indoor novel view synthesis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F42CRfcp3D'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel view synthesis of indoor scenes can be achieved by capturing a monocular video sequence of the environment. However, redundant information caused by artificial movements in the input video data reduces the efficiency of scene modeling. To address this, we formulate the problem as a combinatorial optimization task for view subset selection. In this work, we propose a novel subset selection framework that integrates a comprehensive diversity-based measurement with well-designed utility functions. We provide a theoretical analysis of these utility functions and validate their effectiveness through extensive experiments. Furthermore, we introduce IndoorTraj, a novel dataset designed for indoor novel view synthesis, featuring complex and extended trajectories that simulate intricate human behaviors. Experiments on IndoorTraj show that our framework consistently outperforms baseline strategies while using only 5–20% of the data, highlighting its remarkable efficiency and effectiveness.},
  archive      = {J_TMLR},
  author       = {Zehao Wang and Han Zhou and Matthew B. Blaschko and Tinne Tuytelaars and Minye Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diversity-driven view subset selection for indoor novel view synthesis},
  url          = {https://openreview.net/forum?id=F42CRfcp3D},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLImage: Human-annotated datasets for complementary-label learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FHkWY4aGsN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary-label learning (CLL) is a weakly-supervised learning paradigm that aims to train a multi-class classifier using only complementary labels, which indicate classes to which an instance does not belong. Despite numerous algorithmic proposals for CLL, their practical applicability remains unverified for two reasons. Firstly, these algorithms often rely on assumptions about the generation of complementary labels, and it is not clear how far the assumptions are from reality. Secondly, their evaluation has been limited to synthetically labeled datasets. To gain insights into the real-world performance of CLL algorithms, we developed a protocol to collect complementary labels from human annotators. Our efforts resulted in the creation of four datasets: CLCIFAR10, CLCIFAR20, CLMicroImageNet10, and CLMicroImageNet20, derived from well-known classification datasets CIFAR10, CIFAR100, and TinyImageNet200. These datasets represent the very first real-world CLL datasets, namely CLImage, which are publicly available at: https://github.com/ntucllab/CLImage_Dataset. Through extensive benchmark experiments, we discovered a notable decrease in performance when transitioning from synthetically labeled datasets to real-world datasets. We investigated the key factors contributing to the decrease with a thorough dataset-level ablation study. Our analyses highlight annotation noise as the most influential factor in the real-world datasets. In addition, we discover that the biased-nature of human-annotated complementary labels and the difficulty to validate with only complementary labels are two outstanding barriers to practical CLL. These findings suggest that the community focus more research efforts on developing CLL algorithms and validation schemes that are robust to noisy and biased complementary-label distributions.},
  archive      = {J_TMLR},
  author       = {Hsiu-Hsuan Wang and Mai Tan Ha and Nai-Xuan Ye and Wei-I Lin and Hsuan-Tien Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CLImage: Human-annotated datasets for complementary-label learning},
  url          = {https://openreview.net/forum?id=FHkWY4aGsN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating explainability techniques on discrete-time graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JzmXo0rfry'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete-time temporal Graph Neural Networks (GNNs) are powerful tools for modeling evolving graph-structured data and are widely used in decision-making processes across domains such as social network analysis, financial systems, and collaboration networks. Explaining the predictions of these models is an important research area due to the critical role their decisions play in building trust in social or financial systems. However, the explainability of Temporal Graph Neural Networks remains a challenging and relatively unexplored field. Hence, in this work, we propose a novel framework to evaluate explainability techniques tailored for discrete-time temporal GNNs. Our framework introduces new training and evaluation settings that capture the evolving nature of temporal data, defines metrics to assess the temporal aspects of explanations, and establishes baselines and models specific to discrete-time temporal networks. Through extensive experiments, we outline the best explainability techniques for discrete-time GNNs in terms of fidelity, efficiency, and human-readability trade-offs. By addressing the unique challenges of temporal graph data, our framework sets the stage for future advancements in explaining discrete-time GNNs.},
  archive      = {J_TMLR},
  author       = {Manuel Dileo and Matteo Zignani and Sabrina Tiziana Gaito},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating explainability techniques on discrete-time graph neural networks},
  url          = {https://openreview.net/forum?id=JzmXo0rfry},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tighter sparse variational gaussian processes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=L33DSu3zvq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse variational Gaussian process (GP) approximations based on inducing points have become the de facto standard for scaling GPs to large datasets, owing to their theoretical elegance, computational efficiency, and ease of implementation. This paper introduces a provably tighter variational approximation by relaxing the standard assumption that the conditional approximate posterior given the inducing points must match that in the prior. The key innovation is to modify the conditional posterior to have smaller variances than that of the prior at the training points. We derive the collapsed bound for the regression case, describe how to use the proposed approximation in large data settings, and discuss its application to handle orthogonally structured inducing points and GP latent variable models. Extensive experiments on regression benchmarks, classification, and latent variable models demonstrate that the proposed approximation consistently matches or outperforms standard sparse variational GPs while maintaining the same computational cost.},
  archive      = {J_TMLR},
  author       = {Thang D Bui and Matthew Ashman and Richard E. Turner},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Tighter sparse variational gaussian processes},
  url          = {https://openreview.net/forum?id=L33DSu3zvq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Responsive noise-relaying diffusion policy: Responsive and efficient visuomotor control. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LLWJkR6gaI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning is an efficient method for teaching robots a variety of tasks. Diffusion Policy, which uses a conditional denoising diffusion process to generate actions, has demonstrated superior performance, particularly in learning from multi-modal demonstrates. However, it relies on executing multiple actions predicted from the same inference step to retain performance and prevent mode bouncing, which limits its responsiveness, as actions are not conditioned on the most recent observations. To address this, we introduce Responsive Noise-Relaying Diffusion Policy (RNR-DP), which maintains a noise-relaying buffer with progressively increasing noise levels and employs a sequential denoising mechanism that generates immediate, noise-free actions at the head of the sequence, while appending noisy actions at the tail. This ensures that actions are responsive and conditioned on the latest observations, while maintaining motion consistency through the noise-relaying buffer. This design enables the handling of tasks requiring responsive control, and accelerates action generation by reusing denoising steps. Experiments on response-sensitive tasks demonstrate that, compared to Diffusion Policy, ours achieves 18% improvement in success rate. Further evaluation on regular tasks demonstrates that RNR-DP also exceeds the best acceleration method (DDIM) by 6.9% in success rate, highlighting its computational efficiency advantage in scenarios where responsiveness is less critical.},
  archive      = {J_TMLR},
  author       = {Zhuoqun Chen and Xiu Yuan and Tongzhou Mu and Hao Su},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Responsive noise-relaying diffusion policy: Responsive and efficient visuomotor control},
  url          = {https://openreview.net/forum?id=LLWJkR6gaI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Implicit) ensembles of ensembles: Epistemic uncertainty collapse in large models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ON7dtdEHVQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistemic uncertainty is crucial for safety-critical applications and data acquisition tasks. Yet, we find an important phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We introduce implicit ensembling as a possible explanation for this phenomenon. To investigate this hypothesis, we provide theoretical analysis and experiments that demonstrate uncertainty collapse in explicit ensembles of ensembles and show experimental evidence of similar collapse in wider models across various architectures, from simple MLPs to state-of-the-art vision models including ResNets and Vision Transformers. We further develop implicit ensemble extraction techniques to decompose larger models into diverse sub-models, showing we can thus recover epistemic uncertainty. We explore the implications of these findings for uncertainty estimation.},
  archive      = {J_TMLR},
  author       = {Andreas Kirsch},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {(Implicit) ensembles of ensembles: Epistemic uncertainty collapse in large models},
  url          = {https://openreview.net/forum?id=ON7dtdEHVQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised anomaly detection through mass repulsing optimal transport. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PPGJ3EvENv'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in datasets is a longstanding problem in machine learning. In this context, anomalies are defined as a sample that significantly deviates from the remaining data. Meanwhile, Optimal Transport (OT) is a field of mathematics concerned with the transportation, between two probability distribution, at least effort. In classical OT, the optimal transportation strategy of a distribution to itself is the identity, i.e., each sample keeps its mass. In this paper, we tackle anomaly detection by forcing samples to displace its mass, while keeping the least effort objective. We call this new transportation problem Mass Repulsing Optimal Transport (MROT). Naturally, samples lying in low density regions of space will be forced to displace mass very far, incurring a higher transportation cost. In contrast, samples on high density regions are able to send their mass just outside an \emph{exclusion zone}. We use these concepts to design a new anomaly score. Through a series of experiments in existing benchmarks, and fault detection problems, we show that our algorithm improves over existing methods. Our code is publicly available at https://github.com/eddardd/MROT},
  archive      = {J_TMLR},
  author       = {Eduardo Fernandes Montesuma and EL HABAZI Adel and Fred Maurice NGOLE MBOULA},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised anomaly detection through mass repulsing optimal transport},
  url          = {https://openreview.net/forum?id=PPGJ3EvENv},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible infinite-width graph convolutional neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q2M4yijKSo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed and tunable only through a small number of hyperparameters, thus eliminating the possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well because they are able to flexibly learn representations for the task at hand. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of node classification tasks on graphs. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a “knob” to control the amount of flexibility and hence representation learning. We found that representation learning gives noticeable performance improvements for heterophilous node classification tasks, but less so for homophilous node classification tasks.},
  archive      = {J_TMLR},
  author       = {Ben Anson and Edward Milsom and Laurence Aitchison},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Flexible infinite-width graph convolutional neural networks},
  url          = {https://openreview.net/forum?id=Q2M4yijKSo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternators for sequence modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q70C1HQ0VO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces alternators, a novel family of non-Markovian dynamical models for sequences. An alternator features two neural networks: the observation trajectory network (OTN) and the feature trajectory network (FTN). The OTN and the FTN work in conjunction, alternating between outputting samples in the observation space and some feature space, respectively. The parameters of the OTN and the FTN are not time-dependent and are learned via a minimum cross-entropy criterion over the trajectories. Alternators are versatile. They can be used as dynamical latent-variable generative models or as sequence-to-sequence predictors. Alternators can uncover the latent dynamics underlying complex sequential data, accurately forecast and impute missing data, and sample new trajectories. We showcase the capabilities of alternators in three applications. We first used alternators to model the Lorenz equations, often used to describe chaotic behavior. We then applied alternators to Neuroscience to map brain activity to physical activity. Finally, we applied alternators to Climate Science, focusing on sea-surface temperature forecasting. In all our experiments, we found alternators are stable to train, fast to sample from, yield high-quality generated samples and latent variables, and often outperform strong baselines such as Mambas, neural ODEs, and diffusion models in the domains we studied.},
  archive      = {J_TMLR},
  author       = {Mohammad Reza Rezaei and Adji Bousso Dieng},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Alternators for sequence modeling},
  url          = {https://openreview.net/forum?id=Q70C1HQ0VO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRAPES: Learning to sample graphs for scalable graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QI0l842vSq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) learn to represent nodes by aggregating information from their neighbors. As GNNs increase in depth, their receptive field grows exponentially, leading to high memory costs. Several works in the literature proposed to address this shortcoming by sampling subgraphs, or by using historical embeddings. These methods have mostly focused on benchmarks of single-label node classification on homophilous graphs, where neighboring nodes often share the same label. However, most of these methods rely on static heuristics that may not generalize across different graphs or tasks. We argue that the sampling method should be adaptive, adjusting to the complex structural properties of each graph. To this end, we introduce GRAPES, an adaptive sampling method that learns to identify the set of nodes crucial for training a GNN. GRAPES trains a second GNN to predict node sampling probabilities by optimizing the downstream task objective. We evaluate GRAPES on various node classification benchmarks involving homophilous as well as heterophilous graphs. We demonstrate GRAPES’ effectiveness in accuracy and scalability, particularly in multi-label heterophilous graphs. Additionally, GRAPES uses orders of magnitude less GPU memory than a strong baseline based on historical embeddings. Unlike other sampling methods, GRAPES maintains high accuracy even with smaller sample sizes and, therefore, can scale to massive graphs. Our implementation is publicly available online.},
  archive      = {J_TMLR},
  author       = {Taraneh Younesian and Daniel Daza and Emile van Krieken and Thiviyan Thanapalasingam and Peter Bloem},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GRAPES: Learning to sample graphs for scalable graph neural networks},
  url          = {https://openreview.net/forum?id=QI0l842vSq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining node embeddings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QQZ8uPxFb3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node embedding algorithms produce low-dimensional latent representations of nodes in a graph. These embeddings are often used for downstream tasks, such as node classification and link prediction. In this paper, we investigate the following two questions: (Q1) Can we explain each embedding dimension with human-understandable graph features (e.g. degree, clustering coefficient and PageRank). (Q2) How can we modify existing node embedding algorithms to produce embeddings that can be easily explained by human-understandable graph features? We find that the answer to Q1 is yes and introduce a new framework called XM (short for eXplain eMbedding) to answer Q2. A key aspect of XM involves minimizing the nuclear norm of the generated explanations. We show that by minimizing the nuclear norm, we minimize the lower bound on the entropy of the generated explanations. We test XM on a variety of real-world graphs and show that XM not only preserves the performance of existing node embedding methods, but also enhances their explainability.},
  archive      = {J_TMLR},
  author       = {Zohair Shafi and Ayan Chatterjee and Tina Eliassi-Rad},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining node embeddings},
  url          = {https://openreview.net/forum?id=QQZ8uPxFb3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information theoretic guarantees for policy alignment in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Uz9J77Riul'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy alignment of large language models refers to constrained policy optimization, where the policy is optimized to maximize a reward while staying close to a reference policy based on an $f$-divergence like $\mathsf{KL}$ divergence. The best of $n$ alignment policy selects the sample with the highest reward from $n$ independent samples. Recent work shows that the reward improvement of the aligned policy scales as $\sqrt{\mathsf{KL}}$, with an explicit bound on the $\mathsf{KL}$ for best of $n$ policies. We show that this $\sqrt{\mathsf{KL}}$ bound holds if the reference policy’s reward has sub-gaussian tails. For best of $n$ policies, the $\mathsf{KL}$ bound applies to any $f$-divergence through a reduction to exponential order statistics using the Rényi representation. Tighter control can be achieved with Rényi divergence if additional tail information is known. Finally, we demonstrate how these bounds transfer to golden rewards, resulting in decreased golden reward improvement due to proxy reward overestimation and approximation errors.},
  archive      = {J_TMLR},
  author       = {Youssef Mroueh and Apoorva Nitsure},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Information theoretic guarantees for policy alignment in large language models},
  url          = {https://openreview.net/forum?id=Uz9J77Riul},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visually descriptive language model for vector graphics reasoning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WzS33L1iPC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advancements, current large multimodal models (LMMs) struggle to bridge the gap between low-level visual perception—focusing on shapes, sizes, and layouts—and high-level language reasoning involving semantics, events, and logic. This limitation becomes evident in tasks requiring precise visual perception, such as comparing geometric properties or solving visual algorithmic reasoning problems. To study this failure mode, we focus on an important visual domain: vector graphics —images composed purely of 2D objects and shapes, which are prevalent in Web, PC, and Mobile environments. Importantly, we consider rasterized vector graphics without assuming access to their underlying vector code. We identify two key research questions: how can we enable precise visual perception, and how can we facilitate high-level reasoning based on such low-level perceptions? To accurately capture low-level visual details, we explore using SVG for the precise encoding of visual scenes. However, SVGs are not readily interpretable by LLMs or LMMs in a zero-shot manner. To address this challenge, we propose the Visually Descriptive Language Model (VDLM) to build a bridge between low-level visual perception and high-level language reasoning. VDLM learns an intermediate symbolic representation called Primal Visual Description (PVD), which translates raw SVGs into a higher-level abstraction comprising primitive attributes. This abstraction allows for direct interpretation by foundation models for zero-shot generalization to different reasoning tasks. Without any human-annotated data, VDLM leads to significant improvements in state-of-the-art LMMs, such as GPT-4o, across various low-level multimodal perception and reasoning tasks on rasterized vector graphics. Additionally, we provide extensive analyses of VDLM’s performance, showing that our framework offers improved interpretability due to its disentangled perception and reasoning processes. As the first attempt to construct a descriptive intermediate representation for low-level visual reasoning, we also conduct an in-depth error analysis, highlighting remaining limitations and suggesting directions for future research.},
  archive      = {J_TMLR},
  author       = {Zhenhailong Wang and Joy Hsu and Xingyao Wang and Kuan-Hao Huang and Manling Li and Jiajun Wu and Heng Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Visually descriptive language model for vector graphics reasoning},
  url          = {https://openreview.net/forum?id=WzS33L1iPC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithm configuration for structured pfaffian settings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Xmk1or5eH8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven algorithm design uses historical problem instances to automatically adjust and optimize algorithms to their application domain, typically by selecting algorithms from parameterized families. While the approach has been highly successful in practice, providing theoretical guarantees for several algorithmic families remains challenging. This is due to the intricate dependence of the algorithmic performance on the parameters, often exhibiting a piecewise discontinuous structure. In this work, we present new frameworks for providing learning guarantees for parameterized data-driven algorithm design problems in both statistical and online learning settings. For the statistical learning setting, we introduce the Pfaffian GJ framework, an extension of the classical Goldberg-Jerrum (GJ) framework (Bartlett et al., 2022; Goldberg & Jerrum, 1993), that is capable of providing learning guarantees for function classes for which the computation involves Pfaffian functions. Unlike the GJ framework, which is limited to function classes with computation characterized by rational functions (quotients of two polynomials), our proposed framework can deal with function classes involving Pfaffian functions, which are much more general and widely applicable. We then show that for many parameterized algorithms of interest, their utility function possesses a refined piecewise structure, which automatically translates to learning guarantees using our proposed framework. For the online learning setting, we provide a new tool for verifying the dispersion property of a sequence of loss functions, a sufficient condition that allows no-regret learning for sequences of piecewise structured loss functions where the piecewise structure involves Pfaffian transition boundaries. We use our framework to provide novel learning guarantees for many challenging data-driven design problems of interest, including data-driven linkage-based clustering, graph-based semi-supervised learning, and regularized logistic regression.},
  archive      = {J_TMLR},
  author       = {Maria Florina Balcan and Anh Tuan Nguyen and Dravyansh Sharma},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Algorithm configuration for structured pfaffian settings},
  url          = {https://openreview.net/forum?id=Xmk1or5eH8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do think tags really help LLMs plan? a critical evaluation of ReAct-style prompting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aFAMPSmNHR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reasoning abilities of Large Language Models (LLMs) remain a topic of considerable interest and debate. Among the original papers arguing for emergent reasoning abilities of LLMs, ReAct became particularly popular by claiming to tease out LLM reasoning abilities with special prompting involving “interleaving reasoning trace with action execution". In this paper, we critically examine the claims of ReAct style prompting for planning and sequential decision-making problems. By introducing systematic variations to the input prompt, we perform a sensitivity analysis along the original claims of ReAct. Our experiments in AlfWorld and WebShop, domains that were used in the original ReAct work, show that the performance is minimally influenced by the interleaved reasoning trace or by the content of these generated reasoning traces. Instead, the performance of LLMs is primarily driven by the unreasonably high degree of similarity between input example tasks and queries, with shockingly little ability to generalize. In addition to raising questions on claims about reasoning abilities, this lack of generalization also implicitly forces the prompt designer to provide instance-specific examples, significantly increasing the cognitive burden on the human. Our empirical results show that the perceived reasoning abilities of LLMs stem from the exemplar-query similarity and approximate retrieval rather than any inherent reasoning abilities, thereby leading to severe lack of generalization beyond the few-shot examples given in the prompts. Our code and prompt settings can be found here on GitHub.},
  archive      = {J_TMLR},
  author       = {Siddhant Bhambri and Mudit Verma and Subbarao Kambhampati},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Do think tags really help LLMs plan? a critical evaluation of ReAct-style prompting},
  url          = {https://openreview.net/forum?id=aFAMPSmNHR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViewFusion: Learning composable diffusion models for novel view synthesis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=amUisgrmte'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is providing a wealth of new approaches to the problem of novel view synthesis, from Neural Radiance Field (NeRF) based approaches to end-to-end style architectures. Each approach offers specific strengths but also comes with limitations in their applicability. This work introduces ViewFusion, an end-to-end generative approach to novel view synthesis with unparalleled flexibility. ViewFusion consists in simultaneously applying a diffusion denoising step to any number of input views of a scene, then combining the noise gradients obtained for each view with an (inferred) pixel-weighting mask, ensuring that for each region of the target view only the most informative input views are taken into account. Our approach resolves several limitations of previous approaches by (1) being trainable and generalizing across multiple scenes and object classes, (2) adaptively taking in a variable number of pose-free views at both train and test time, (3) generating plausible views even in severely underdetermined conditions (thanks to its generative nature)---all while generating views of quality on par or even better than comparable methods. Limitations include not generating a 3D embedding of the scene, resulting in a relatively slow inference speed, and our method only being tested on the relatively small Neural 3D Mesh Renderer dataset. Code is available.},
  archive      = {J_TMLR},
  author       = {Bernard Spiegl and Andrea Perin and Stephane Deny and Alexander Ilin},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ViewFusion: Learning composable diffusion models for novel view synthesis},
  url          = {https://openreview.net/forum?id=amUisgrmte},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Part-aware prompted segment anything model for adaptive segmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cCQKwd5MFP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision medicine, such as patient-adaptive treatments assisted by medical image analysis, poses new challenges for image segmentation algorithms due to the large variability across different patients and the limited availability of annotated data for each patient. In this work, we propose a data-efficient segmentation method to address these challenges, namely $\textit{\textbf{P}art-aware}$ $\textit{\textbf{P}rompted}$ $\textit{\textbf{S}egment}$ $\textit{\textbf{A}nything}$ $\textit{\textbf{M}odel}$ ($\mathbf{{P}^{2}SAM}$). Without any model fine-tuning, $\text{P}^2\text{SAM}$ enables seamless adaptation to any new patients relying only on one-shot patient-specific data. We introduce a novel part-aware prompt mechanism to select multiple-point prompts based on part-level features of the one-shot data, which can be extensively integrated into different promptable segmentation models, such as SAM and SAM 2. To further promote the robustness of the part-aware prompt mechanism, we propose a distribution-guided retrieval approach to determine the optimal number of part-level features for a specific case. $\text{P}^2\text{SAM}$ improves the performance by $\texttt{+} 8.0\%$ and $\texttt{+} 2.0\%$ mean Dice score for two different patient-adaptive segmentation applications, respectively. In addition, $\text{P}^2\text{SAM}$ also exhibits impressive generalizability in other adaptive segmentation tasks in the natural image domain, $\textit{e.g.}$, $\texttt{+} 6.4\%$ mIoU within personalized object segmentation task. Code will be released upon acceptance.},
  archive      = {J_TMLR},
  author       = {Chenhui Zhao and Liyue Shen},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Part-aware prompted segment anything model for adaptive segmentation},
  url          = {https://openreview.net/forum?id=cCQKwd5MFP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MarDini: Masked auto-regressive diffusion for video generation at scale. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fuOHI59rUW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce MarDini, a new family of video diffusion models that integrate the advantages of masked auto-regression (MAR) into a unified diffusion model (DM) framework. Here, MAR handles temporal planning, while DM focuses on spatial generation in an asymmetric network design: i) a MAR-based planning model containing most of the parameters generates planning signals for each masked frame using low-resolution input; ii) a lightweight generation model uses these signals to produce high-resolution frames via diffusion de-noising. MarDini’s MAR enables video generation conditioned on any number of masked frames at any frame positions: a single model can handle video interpolation (e.g., masking middle frames), image-to-video generation (e.g., masking from the second frame onward), and video expansion (e.g., masking half the frames). The efficient design allocates most of the computational resources to the low-resolution planning model, making computationally expensive but important spatio-temporal attention feasible at scale. MarDini sets a new state-of-the-art for video interpolation; meanwhile, within few inference steps, it efficiently generates videos on par with those of much more expensive advanced image-to-video models.},
  archive      = {J_TMLR},
  author       = {Haozhe Liu and Shikun Liu and Zijian Zhou and Mengmeng Xu and Yanping Xie and Xiao Han and Juan Camilo Perez and Ding Liu and Kumara Kahatapitiya and Menglin Jia and Jui-Chieh Wu and Sen He and Tao Xiang and Jürgen Schmidhuber and Juan-Manuel Perez-Rua},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MarDini: Masked auto-regressive diffusion for video generation at scale},
  url          = {https://openreview.net/forum?id=fuOHI59rUW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented invertible koopman autoencoder for long-term time series forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=o6ukhJLzMQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the introduction of Dynamic Mode Decomposition and its numerous extensions, many neural autoencoder-based implementations of the Koopman operator have recently been proposed. This class of methods appears to be of interest for modeling dynamical systems, either through direct long-term prediction of the evolution of the state or as a powerful embedding for downstream methods. In particular, a recent line of work has developed invertible Koopman autoencoders (IKAEs), which provide an exact reconstruction of the input state thanks to their analytically invertible encoder, based on coupling layer normalizing flow models. We identify that the conservation of the dimension imposed by the normalizing flows is a limitation for the IKAE models, and thus we propose to augment the latent state with a second, non-invertible encoder network. This results in our new model: the Augmented Invertible Koopman AutoEncoder (AIKAE). We demonstrate the relevance of the AIKAE through a series of long-term time series forecasting experiments, on satellite image time series as well as on a benchmark involving predictions based on a large lookback window of observations.},
  archive      = {J_TMLR},
  author       = {Anthony Frion and Lucas Drumetz and Mauro Dalla Mura and Guillaume Tochon and Abdeldjalil AISSA EL BEY},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Augmented invertible koopman autoencoder for long-term time series forecasting},
  url          = {https://openreview.net/forum?id=o6ukhJLzMQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking MUSHRA: Addressing modern challenges in text-to-speech evaluation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=oYmRiWCQ1W'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 492 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) reference-matching bias, where raters are unduly influenced by the human reference, and (ii) judgement ambiguity, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 246,000 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.},
  archive      = {J_TMLR},
  author       = {Praveen Srinivasa Varadhan and amogh gulati and Ashwin Sankar and Srija Anand and Anirudh Gupta and Anirudh Mukherjee and Shiva Kumar Marepally and Ankur Bhatia and Saloni Jaju and Suvrat Bhooshan and Mitesh M Khapra},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking MUSHRA: Addressing modern challenges in text-to-speech evaluation},
  url          = {https://openreview.net/forum?id=oYmRiWCQ1W},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online bandit nonlinear control with dynamic batch length and adaptive learning rate. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qmHlTkLdbL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the online bandit nonlinear control, which aims to learn the best stabilizing controller from a pool of stabilizing and destabilizing controllers of unknown types for a given nonlinear dynamical system. We develop an algorithm, named Dynamic Batch length and Adaptive learning Rate (DBAR), and study its stability and regret. Unlike the existing Exp3 algorithm requiring an exponentially stabilizing controller, DBAR only needs a significantly weaker notion of controller stability, in which case substantial time may be required to certify the system stability. Dynamic batch length in DBAR effectively addresses this issue and enables the system to attain asymptotic stability, where the algorithm behaves as if there were no destabilizing controllers. Moreover, adaptive learning rate in DBAR only uses the state norm information to achieve a tight regret bound even when none of the stabilizing controllers in the pool are exponentially stabilizing.},
  archive      = {J_TMLR},
  author       = {Jihun Kim and Javad Lavaei},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online bandit nonlinear control with dynamic batch length and adaptive learning rate},
  url          = {https://openreview.net/forum?id=qmHlTkLdbL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning actionable counterfactual explanations in large state spaces. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tXnVRpRlR8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recourse generators provide actionable insights, often through feature-based counterfactual explanations (CFEs), to help negatively classified individuals understand how to adjust their input features to achieve a positive classification. These feature-based CFEs, which we refer to as \emph{low-level} CFEs, are overly specific (e.g., coding experience: \(4 \to 5+\) years) and often recommended in a feature space that doesn't straightforwardly align with real-world actions. To bridge this gap, we introduce three novel recourse types grounded in real-world actions: high-level continuous (\emph{hl-continuous}), high-level discrete (\emph{hl-discrete}), and high-level ID (\emph{hl-id}) CFEs. We formulate single-agent CFE generation methods for hl-discrete and hl-continuous CFEs. For the hl-discrete CFE, we cast the task as a weighted set cover problem that selects the least cost set of hl-discrete actions that satisfy the eligibility of features, and model the hl-continuous CFE as a solution to an integer linear program that identifies the least cost set of hl-continuous actions capable of favorably altering the prediction of a linear classifier. Since these methods require costly optimization per agent, we propose data-driven CFE generation approaches that, given instances of agents and their optimal CFEs, learn a CFE generator that quickly provides optimal CFEs for new agents. This approach, also viewed as one of learning an optimal policy in a family of large but deterministic MDPs, considers several problem formulations, including formulations in which the actions and their effects are unknown, and therefore addresses informational and computational challenges. We conduct extensive empirical evaluations using publicly available healthcare datasets (BRFSS, Foods, and NHANES) and fully-synthetic data. For negatively classified agents identified by linear and threshold-based binary classifiers, we compare the proposed forms of recourse to low-level CFEs, which suggest how the agent can transition from state \(\mathbf{x}\) to a new state \(\mathbf{x}'\) where the model prediction is desirable. We also extensively evaluate the effectiveness of our neural network-based, data-driven CFE generation approaches. Empirical results show that the proposed data-driven CFE generators are accurate and resource-efficient, and the proposed forms of recourse offer various advantages over the low-level CFEs.},
  archive      = {J_TMLR},
  author       = {Keziah Naggita and Matthew Walter and Avrim Blum},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning actionable counterfactual explanations in large state spaces},
  url          = {https://openreview.net/forum?id=tXnVRpRlR8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient diffusion models: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wHECkBOwyt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field.},
  archive      = {J_TMLR},
  author       = {Hui Shen and Jingxuan Zhang and Boning Xiong and Rui Hu and Shoufa Chen and Zhongwei Wan and Xin Wang and Yu Zhang and Zixuan Gong and Guangyin Bao and Chaofan Tao and Yongfeng Huang and Ye Yuan and Mi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient diffusion models: A survey},
  url          = {https://openreview.net/forum?id=wHECkBOwyt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time contrastive concepts for open-world semantic segmentation with vision-language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wyOv4kGkbU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent CLIP-like Vision-Language Models (VLMs), pre-trained on large amounts of image-text pairs to align both modalities with a simple contrastive objective, have paved the way to open-vocabulary semantic segmentation. Given an arbitrary set of textual queries, image pixels are assigned the closest query in feature space. However, this works well when a user exhaustively lists all possible visual concepts in an image that contrast against each other for the assignment. This corresponds to the current evaluation setup in the literature, which relies on having access to a list of in-domain relevant concepts, typically classes of a benchmark dataset. Here, we consider the more challenging (and realistic) scenario of segmenting a single concept, given a textual prompt and nothing else. To achieve good results, besides contrasting with the generic “background” text, we propose two different approaches to automatically generate, at test time, query-specific textual contrastive concepts. We do so by leveraging the distribution of texts in the VLM’s training set or crafted LLM prompts. We also propose a metric designed to evaluate this scenario and show the relevance of our approach on commonly used datasets.},
  archive      = {J_TMLR},
  author       = {Monika Wysoczańska and Antonin Vobecky and Amaia Cardiel and Tomasz Trzcinski and Renaud Marlet and Andrei Bursuc and Oriane Siméoni},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Test-time contrastive concepts for open-world semantic segmentation with vision-language models},
  url          = {https://openreview.net/forum?id=wyOv4kGkbU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating long range dependency handling in code generation LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yzACI2vFaX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models support larger and larger context sizes, evaluating their ability to make effective use of that context becomes increasingly important. We analyze the ability of several code generation models to handle long range dependencies using a suite of multi-step key retrieval tasks in context windows up to 8k tokens in length. The tasks progressively increase in difficulty and allow more nuanced evaluation of model capabilities than tests like the popular needle-in-the-haystack test. We find that performance degrades significantly for many models (up to 2x) when a function references another function that is defined later in the prompt. We also observe that models that use sliding window attention mechanisms have difficulty handling references further than the size of a single window. We perform simple prompt modifications using call graph information to improve multi-step retrieval performance up to 3x. Our analysis highlights ways that long-context performance needs deeper consideration beyond retrieval of single facts within a document.},
  archive      = {J_TMLR},
  author       = {Yannick Assogba and Donghao Ren},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating long range dependency handling in code generation LLMs},
  url          = {https://openreview.net/forum?id=yzACI2vFaX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable representation learning for fMRI-based neurological disorder identification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zF9IrMTjCC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive advances achieved using deep learning for functional brain activity analysis, the heterogeneity of functional patterns and the scarcity of imaging data still pose challenges in tasks such as identifying neurological disorders. For functional Magnetic Resonance Imaging (fMRI), while data may be abundantly available from healthy controls, clinical data is often scarce, especially for rare diseases, limiting the ability of models to identify clinically-relevant features. We overcome this limitation by introducing a novel representation learning strategy integrating meta-learning with self-supervised learning to improve the generalization from normal to clinical features. This approach enables generalization to challenging clinical tasks featuring scarce training data. We achieve this by leveraging self-supervised learning on the control dataset to focus on inherent features that are not limited to a particular supervised task and incorporating meta-learning to improve the generalization across domains. To explore the generalizability of the learned representations to unseen clinical applications, we apply the model to four distinct clinical datasets featuring scarce and heterogeneous data for neurological disorder classification. Results demonstrate the superiority of our representation learning strategy on diverse clinically-relevant tasks.},
  archive      = {J_TMLR},
  author       = {Wenhui Cui and Haleh Akrami and Anand Joshi and Richard Leahy},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalizable representation learning for fMRI-based neurological disorder identification},
  url          = {https://openreview.net/forum?id=zF9IrMTjCC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local differential privacy-preserving spectral clustering for general graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zo5b60AuAH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is a widely used algorithm to find clusters in networks. Several researchers have studied the stability of spectral clustering under local differential privacy with the additional assumption that the underlying networks are generated from the stochastic block model (SBM). However, we argue that this assumption is too restrictive since social networks do not originate from the SBM. Thus, we delve into an analysis for general graphs in this work. Our primary focus is the edge flipping method -- a common technique for protecting local differential privacy. We show that, when the edges of an $n$-vertex graph satisfying some reasonable well-clustering assumptions are flipped with a probability of $O(\log n/n)$, the clustering outcomes are largely consistent. Empirical tests further corroborate these theoretical findings. Conversely, although clustering outcomes have been stable for non-sparse and well-clustered graphs produced from the SBM, we show that in general, spectral clustering may yield highly erratic results on certain graphs when the flipping probability is $\omega(\log n/n)$. This indicates that the best privacy budget obtainable for general graphs is $\Theta(\log n)$.},
  archive      = {J_TMLR},
  author       = {Sayan Mukherjee and Vorapong Suppakitpaisarn},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Local differential privacy-preserving spectral clustering for general graphs},
  url          = {https://openreview.net/forum?id=zo5b60AuAH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending graph condensation to multi-label datasets: A benchmark study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7aJxaPg30d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As graph data grows increasingly complicated, training graph neural networks (GNNs) on large-scale datasets presents significant challenges, including computational resource constraints, data redundancy, and transmission inefficiencies. While existing graph condensation techniques have shown promise in addressing these issues, they are predominantly designed for single-label datasets, where each node is associated with a single class label. However, many real-world applications, such as social network analysis and bioinformatics, involve multi-label graph datasets, where one node can have various related labels. To deal with this problem, we extend traditional graph condensation approaches to accommodate multi-label datasets by introducing modifications to synthetic dataset initialization and condensing optimization. Through experiments on eight real-world multi-label graph datasets, we prove the effectiveness of our method. In the experiment, the GCond framework, combined with K-Center initialization and binary cross-entropy loss (BCELoss), generally achieves the best performance. This benchmark for multi-label graph condensation not only enhances the scalability and efficiency of GNNs for multi-label graph data but also offers substantial benefits for diverse real-world applications.},
  archive      = {J_TMLR},
  author       = {Liangliang Zhang and Haoran Bao and Yao Ma},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Extending graph condensation to multi-label datasets: A benchmark study},
  url          = {https://openreview.net/forum?id=7aJxaPg30d},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An expanded benchmark that rediscovers and affirms the edge of uncertainty sampling for active learning in tabular datasets. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=855yo1Ubt2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Learning (AL) addresses the crucial challenge of enabling machines to efficiently gather labeled examples through strategic queries. Among the many AL strategies, Uncertainty Sampling (US) stands out as one of the most widely adopted. US queries the example(s) that the current model finds uncertain, proving to be both straightforward and effective. Despite claims in the literature suggesting superior alternatives to US, community-wide acceptance remains elusive. In fact, existing benchmarks for tabular datasets present conflicting conclusions on the continued competitiveness of US. In this study, we review the literature on AL strategies in the last decade and build the most comprehensive open-source AL benchmark to date to understand the relative merits of different AL strategies. The benchmark surpasses existing ones by encompassing a broader coverage of strategies, models, and data. Through our investigation of the conflicting conclusions in existing tabular AL benchmarks by evaluation under broad AL experimental settings, we uncover fresh insights into the often-overlooked issue of using machine learning models--**model compatibility** in the context of US. Specifically, we notice that adopting the different models for the querying unlabeled examples and learning tasks would degrade US's effectiveness. Notably, our findings affirm that US maintains a competitive edge over other strategies when paired with compatible models. These findings have practical implications and provide a concrete recipe for AL practitioners, empowering them to make informed decisions when working with tabular classifications with limited labeled data. The code for this project is available on https://github.com/ariapoy/active-learning-benchmark.},
  archive      = {J_TMLR},
  author       = {Po-Yi Lu and Yi-Jie Cheng and Chun-Liang Li and Hsuan-Tien Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An expanded benchmark that rediscovers and affirms the edge of uncertainty sampling for active learning in tabular datasets},
  url          = {https://openreview.net/forum?id=855yo1Ubt2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion model predictive control. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pvtgffHtJm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Diffusion Model Predictive Control (D-MPC), a novel MPC approach that learns a multi-step action proposal and a multi-step dynamics model, both using diffusion models, and combines them for use in online MPC. On the popular D4RL benchmark, we show performance that is significantly better than existing model-based offline planning methods using MPC (e.g. MBOP) and competitive with state-of-the-art (SOTA) model-based and model-free reinforcement learning methods. We additionally illustrate D-MPC’s ability to optimize novel reward functions at run time and adapt to novel dynamics, and highlight its advantages compared to existing diffusion-based planning baselines.},
  archive      = {J_TMLR},
  author       = {Guangyao Zhou and Sivaramakrishnan Swaminathan and Rajkumar Vasudeva Raju and J Swaroop Guntupalli and Wolfgang Lehrach and Joseph Ortiz and Antoine Dedieu and Miguel Lazaro-Gredilla and Kevin Patrick Murphy},
  journal      = {Transactions on Machine Learning Research},
  month        = {5},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion model predictive control},
  url          = {https://openreview.net/forum?id=pvtgffHtJm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent covariate shift: Unlocking partial identifiability for multi-source domain adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9kFlOyLwyf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source domain adaptation (MSDA) addresses the challenge of learning a label prediction function for an unlabeled target domain by leveraging both the labeled data from multiple source domains and the unlabeled data from the target domain. Conventional MSDA approaches often rely on covariate shift or conditional shift paradigms, which assume a consistent label distribution across domains. However, this assumption proves limiting in practical scenarios where label distributions do vary across domains, diminishing its applicability in real-world settings. For example, animals from different regions exhibit diverse characteristics due to varying diets and genetics. Motivated by this, we propose a novel paradigm called latent covariate shift (LCS), which introduces significantly greater variability and adaptability across domains. Notably, it provides a theoretical assurance for recovering the latent cause of the label variable, which we refer to as the latent content variable. Within this new paradigm, we present an intricate causal generative model by introducing latent noises across domains, along with a latent content variable and a latent style variable to achieve more nuanced rendering of observational data. We demonstrate that the latent content variable can be identified up to block identifiability due to its versatile yet distinct causal structure. We anchor our theoretical insights into a novel MSDA method, which learns the label distribution conditioned on the identifiable latent content variable, thereby accommodating more substantial distribution shifts. The proposed approach showcases exceptional performance and efficacy on both simulated and real-world datasets.},
  archive      = {J_TMLR},
  author       = {Yuhang Liu and Zhen Zhang and Dong Gong and Mingming Gong and Biwei Huang and Anton van den Hengel and Kun Zhang and Javen Qinfeng Shi},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent covariate shift: Unlocking partial identifiability for multi-source domain adaptation},
  url          = {https://openreview.net/forum?id=9kFlOyLwyf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical bayes trend filtering through a variational inference framework. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AHTz2mTlKk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel framework for Bayesian trend filtering using an empirical Bayes approach and a variational inference algorithm. Trend filtering is a nonparametric regression technique that has gained popularity for its simple formulation and local adaptability. Bayesian adaptations of trend filtering have been proposed as an alternative method, while they often rely on computationally intensive sampling-based methods for posterior inference. We propose an empirical Bayes trend filtering (EBTF) that leverages shrinkage priors, estimated through an empirical Bayes procedure by maximizing the marginal likelihood. To address the computational challenges posed by large datasets, we implement a variational inference algorithm for posterior computation, ensuring scalability and efficiency. Our framework is flexible, allowing the incorporation of various shrinkage priors, and optimizes the level of smoothness directly from the data. We also discuss alternative formulations of the EBTF model, along with their pros and cons. We demonstrate the performance of our EBTF method through comprehensive simulations and real-world data applications, highlighting its ability to maintain computational efficiency while providing accurate trend estimation.},
  archive      = {J_TMLR},
  author       = {Dongyue Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Empirical bayes trend filtering through a variational inference framework},
  url          = {https://openreview.net/forum?id=AHTz2mTlKk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On learning representations for tabular data distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GXlsrvOGIK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset distillation generates a small set of information-rich instances from a large dataset, resulting in reduced storage requirements, privacy or copyright risks, and computational costs for downstream modeling, though much of the research has focused on the image data modality. We study tabular data distillation, which brings in novel challenges such as the inherent feature heterogeneity and the common use of non-differentiable learning models (such as decision tree ensembles and nearest-neighbor predictors). To mitigate these challenges, we present $\texttt{TDColER}$, a tabular data distillation framework via column embeddings-based representation learning. To evaluate this framework, we also present a tabular data distillation benchmark, ${{\sf \small TDBench}}$. Based on an elaborate evaluation on ${{\sf \small TDBench}}$, resulting in 226,200 distilled datasets and 541,980 models trained on them, we demonstrate that $\texttt{TDColER}$ is able to boost the distilled data quality of off-the-shelf distillation schemes by 0.5-143% across 7 different tabular learning models. All of the code used in the experiments can be found in http://github.com/inwonakng/tdbench},
  archive      = {J_TMLR},
  author       = {Inwon Kang and Parikshit Ram and Yi Zhou and Horst Samulowitz and Oshani Seneviratne},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On learning representations for tabular data distillation},
  url          = {https://openreview.net/forum?id=GXlsrvOGIK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeformTime: Capturing variable dependencies with deformable attention for time series forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=M62P7iOT7d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multivariable time series (MTS) forecasting, existing state-of-the-art deep learning approaches tend to focus on autoregressive formulations and often overlook the potential of using exogenous variables in enhancing the prediction of the target endogenous variable. To address this limitation, we present DeformTime, a neural network architecture that attempts to capture correlated temporal patterns from the input space, and hence, improve forecasting accuracy. It deploys two core operations performed by deformable attention blocks (DABs): learning dependencies across variables from different time steps (variable DAB), and preserving temporal dependencies in data from previous time steps (temporal DAB). Input data transformation is explicitly designed to enhance learning from the deformed series of information while passing through a DAB. We conduct extensive experiments on 6 MTS data sets, using previously established benchmarks as well as challenging infectious disease modelling tasks with more exogenous variables. The results demonstrate that DeformTime improves accuracy against previous competitive methods across the vast majority of MTS forecasting tasks, reducing the mean absolute error by 7.2% on average. Notably, performance gains remain consistent across longer forecasting horizons.},
  archive      = {J_TMLR},
  author       = {Yuxuan Shu and Vasileios Lampos},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DeformTime: Capturing variable dependencies with deformable attention for time series forecasting},
  url          = {https://openreview.net/forum?id=M62P7iOT7d},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-output distributional fairness via post-processing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MJOKrHqiV1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The post-processing approaches are becoming prominent techniques to enhance machine learning models' fairness because of their intuitiveness, low computational cost, and excellent scalability. However, most existing post-processing methods are designed for task-specific fairness measures and are limited to single-output models. In this paper, we introduce a post-processing method for multi-output models, such as the ones used for multi-task/multi-class classification and representation learning, to enhance a model's distributional parity, a task-agnostic fairness measure. Existing methods for achieving distributional parity rely on the (inverse) cumulative density function of a model’s output, restricting their applicability to single-output models. Extending previous works, we propose to employ optimal transport mappings to move a model's outputs across different groups towards their empirical Wasserstein barycenter. An approximation technique is applied to reduce the complexity of computing the exact barycenter and a kernel regression method is proposed to extend this process to out-of-sample data. Our empirical studies evaluate the proposed approach against various baselines on multi-task/multi-class classification and representation learning tasks, demonstrating the effectiveness of the proposed approach.},
  archive      = {J_TMLR},
  author       = {Gang Li and Qihang Lin and Ayush Ghosh and Tianbao Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-output distributional fairness via post-processing},
  url          = {https://openreview.net/forum?id=MJOKrHqiV1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Almost sure convergence of stochastic gradient methods under gradient domination. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OTwnNBxZFB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient methods are among the most important algorithms in training machine learning problems. While classical assumptions such as strong convexity allow a simple analysis they are rarely satisfied in applications. In recent years, global and local gradient domination properties have shown to be a more realistic replacement of strong convexity. They were proved to hold in diverse settings such as (simple) policy gradient methods in reinforcement learning and training of deep neural networks with analytic activation functions. We prove almost sure convergence rates $f(X_n)-f^*\in o\big( n^{-\frac{1}{4\beta-1}+\epsilon}\big)$ of the last iterate for stochastic gradient descent (with and without momentum) under global and local $\beta$-gradient domination assumptions. The almost sure rates get arbitrarily close to recent rates in expectation. Finally, we demonstrate how to apply our results to the training task in both supervised and reinforcement learning.},
  archive      = {J_TMLR},
  author       = {Simon Weissmann and Sara Klein and Waïss Azizian and Leif Döring},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Almost sure convergence of stochastic gradient methods under gradient domination},
  url          = {https://openreview.net/forum?id=OTwnNBxZFB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency-guided asynchronous contrastive tuning for few-shot class-incremental tuning of foundation models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WfAvMdwiE8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Consistency-guided Asynchronous Contrastive Tuning (CoACT), a novel method for continuously tuning foundation models to learn new classes in few-shot settings. CoACT consists of three key components: (i) asynchronous contrastive tuning, which learns new classes by including LoRA modules in the pre-trained encoder while enforcing consistency between two asynchronous encoders; (ii) controlled fine-tuning, which facilitates effective tuning of a subset of the foundation model; and (iii) consistency-guided incremental tuning, which enforces additional regularization during later sessions to reduce forgetting of the learned classes. We evaluate our proposed solution on Few-Shot Class-Incremental Learning (FSCIL) as well as a new and more challenging setup called Few-Shot Class-Incremental Tuning (FSCIT), which facilitates the continual tuning of vision foundation models to learn new classes with only a few samples per class. Unlike traditional FSCIL, FSCIT does not require a large in-distribution base session for initial fully supervised training prior to the incremental few-shot sessions. We conduct extensive evaluations across 16 diverse datasets, demonstrating the effectiveness of CoACT in both FSCIL and FSCIT setups. CoACT outperforms existing methods by up to 5.02% in FSCIL and up to 12.51% in FSCIT for individual datasets, with an average improvement of 2.47%. Furthermore, CoACT exhibits reduced forgetting and enhanced robustness in low-shot experiments. Detailed ablation and sensitivity studies highlight the contribution of each component of CoACT. We make our code publicly available at https://github.com/ShuvenduRoy/CoACT-FSCIL.},
  archive      = {J_TMLR},
  author       = {Shuvendu Roy and Elham Dolatabadi and Arash Afkanpour and Ali Etemad},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Consistency-guided asynchronous contrastive tuning for few-shot class-incremental tuning of foundation models},
  url          = {https://openreview.net/forum?id=WfAvMdwiE8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilizing the kumaraswamy distribution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=baZLwdphqw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale latent variable models require expressive continuous distributions that support efficient sampling and low-variance differentiation, achievable through the reparameterization trick. The Kumaraswamy (KS) distribution is both expressive and supports the reparameterization trick with a simple closed-form inverse CDF. Yet, its adoption remains limited. We identify and resolve numerical instabilities in the log-pdf, CDF, and inverse CDF, exposing issues in libraries like PyTorch and TensorFlow. We then introduce simple and scalable latent variable models to address exploration-exploitation trade-offs in contextual multi-armed bandits and facilitate uncertainty quantification for link prediction with graph neural networks. We find these models to be most performant when paired with the stable KS. Our results support the stabilized KS distribution as a core component in scalable variational models for bounded latent variables.},
  archive      = {J_TMLR},
  author       = {Max Wasserman and Gonzalo Mateos},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stabilizing the kumaraswamy distribution},
  url          = {https://openreview.net/forum?id=baZLwdphqw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LitLLMs, LLMs for literature review: Are we there yet?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=heeJqQXKg7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Literature reviews are an essential component of scientific research, but they remain time-intensive and challenging to write, especially due to the recent influx of research papers. This paper explores the zero-shot abilities of recent Large Language Models (LLMs) in assisting with the writing of literature reviews based on an abstract. We decompose the task into two components: (1) Retrieving related works given a query abstract and (2) Writing a literature review based on the retrieved results. We analyze how effective LLMs are for both components. For retrieval, we introduce a novel two-step search strategy that first uses an LLM to extract meaningful keywords from the abstract of a paper and then retrieves potentially relevant papers by querying an external knowledge base. Additionally, we study a prompting-based re-ranking mechanism with attribution and show that re-ranking doubles the normalized recall compared to naive search methods while providing insights into the LLM’s decision-making process. In the generation phase, we propose a two-step approach that first outlines a plan for the review and then executes steps in the plan to generate the actual review. To evaluate different LLM-based literature review methods, we create test sets from arXiv papers using a protocol designed for rolling use with newly released LLMs to avoid test set contamination in zero-shot evaluations. We release this evaluation protocol to promote additional research and development in this regard. Our empirical results suggest that LLMs show promising potential for writing literature reviews when the task is decomposed into smaller components of retrieval and planning. Particularly, we find that combining keyword-based and document-embedding-based search improves precision and recall during retrieval by 10% and 30%, respectively, compared to using either of the methods in isolation. Further, we demonstrate that our planning-based approach achieves higher-quality reviews by minimizing hallucinated references in the generated review by 18-26% compared to existing simpler LLM-based generation methods. Our project page including a demonstration system and toolkit can be accessed here: https://litllm.github.io.},
  archive      = {J_TMLR},
  author       = {Shubham Agarwal and Gaurav Sahu and Abhay Puri and Issam H. Laradji and Krishnamurthy Dj Dvijotham and Jason Stanley and Laurent Charlin and Christopher Pal},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LitLLMs, LLMs for literature review: Are we there yet?},
  url          = {https://openreview.net/forum?id=heeJqQXKg7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient training algorithm for models with block-wise sparsity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nay3Kvw8BD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale machine learning (ML) models are increasingly being used in critical domains like education, lending, recruitment, healthcare, criminal justice, etc. However, the training, deployment, and utilization of these models demand substantial computational resources. To decrease computation and memory costs, machine learning models with sparse weight matrices are widely used in the literature. Among sparse models, those with special sparse structures (e.g., models with block-wise sparse weight matrices) fit better with the hardware accelerators and can decrease the memory and computation costs during the inference. Unfortunately, while there are several efficient training methods, none of them are designed to train a block-wise sparse model efficiently. As a result, the current methods for training block-wise sparse models start with full and dense models leading to inefficient training. In this work, we focus on training models with \textit{block-wise sparse matrices} and propose an efficient training algorithm to decrease both computation and memory costs during training and inference. In addition, we will show that our proposed method enables us to efficiently find the right block size for the sparsity pattern during the training process. Our extensive empirical and theoretical analyses show that our algorithms can decrease the computation and memory costs significantly without a performance drop compared to baselines.},
  archive      = {J_TMLR},
  author       = {Ding Zhu and Zhiqun Zuo and Mohammad Mahdi Khalili},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An efficient training algorithm for models with block-wise sparsity},
  url          = {https://openreview.net/forum?id=nay3Kvw8BD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning to teach semantic prompts for open domain generalization in vision-language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uJELgNGiMW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open Domain Generalization (ODG) addresses the challenges posed by domain and category shifts between labeled training sources and unlabeled target domains. Current state-of-the-art methods struggle with the limitations of traditional CNN backbones, leading to reduced generalization and increased error rates in detecting target open samples without prior knowledge. Additionally, recent CLIP-based prompt learning approaches fail to distinguish between known and unknown classes effectively, resulting in suboptimal performance. To address these challenges, we propose MetaPrompt, which leverages the semantic strengths of the vision-language model CLIP and the ''learning-to-learn'' capabilities of Meta-Learning to achieve robust generalization across domain and category shifts. Our framework introduces three key innovations: First, we approach ODG as a multi-class classification problem that includes both known and novel categories, designing novel prompts capable of detecting unknown class samples across multiple domains. These prompts are trained using Meta-Learning with momentum updates, enabling smooth and accurate differentiation between known and unknown classes. Second, we introduce a novel domain-agnostic semantic attention-based prompt alongside domain-focused prompts to enhance robustness in classifying unknown classes across various domains. Finally, we incorporate an unsupervised contrastive loss during episodic Meta-Training, which reinforces the boundaries in the metric space between known and unknown classes, thereby enhancing ''unknown'' class awareness in the prompts. MetaPrompt has demonstrated its superiority through extensive testing on diverse datasets, excelling in both closed and open-set DG scenarios and consistently outperforming existing solutions.},
  archive      = {J_TMLR},
  author       = {Shirsha Bose and Mainak Singha and Ankit Jha and Souradeep Mukhopadhyay and Biplab Banerjee},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning to teach semantic prompts for open domain generalization in vision-language models},
  url          = {https://openreview.net/forum?id=uJELgNGiMW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting deep hybrid models for out-of-distribution detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yeITEuhv4Q'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hybrid models (DHMs) for out-of-distribution (OOD) detection, jointly training a deep feature extractor with a classification head and a density estimation head based on a normalising flow, provide a conceptually appealing approach to visual OOD detection. The paper that introduced this approach reported 100% AuROC in experiments on two standard benchmarks, including one based on the CIFAR-10 data. As there are no implementations available, we set out to reproduce the approach by carefully filling in gaps in the description of the algorithm. Although we were unable to attain 100% OOD detection rates, and our results indicate that such performance is impossible on the CIFAR-10 benchmark, we achieved good OOD performance. We provide a detailed analysis of when the architecture fails and argue that it introduces an adversarial relationship between the classification component and the density estimator, rendering it highly sensitive to the balance of these two components and yielding a collapsed feature space without careful fine-tuning. Our implementation of DHMs is publicly available.},
  archive      = {J_TMLR},
  author       = {Paul-Ruben Schlumbom and Eibe Frank},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Revisiting deep hybrid models for out-of-distribution detection},
  url          = {https://openreview.net/forum?id=yeITEuhv4Q},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed and secure kernel-based quantum machine learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3jdI0aEW3k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing promises to revolutionize machine learning, offering significant efficiency gains for tasks such as clustering and distance estimation. Additionally, it provides enhanced security through fundamental principles like the measurement postulate and the no-cloning theorem, enabling secure protocols such as quantum teleportation and quantum key distribution. While advancements in secure quantum machine learning are notable, the development of secure and distributed quantum analogs of kernel-based machine learning techniques remains underexplored. In this work, we present a novel approach for securely computing three commonly used kernels: the polynomial, radial basis function (RBF), and Laplacian kernels, when data is distributed, using quantum feature maps. Our methodology formalizes a robust framework that leverages quantum teleportation to enable secure and distributed kernel learning. The proposed architecture is validated using IBM’s Qiskit Aer Simulator on various public datasets.},
  archive      = {J_TMLR},
  author       = {Arjhun Swaminathan and Mete Akgün},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributed and secure kernel-based quantum machine learning},
  url          = {https://openreview.net/forum?id=3jdI0aEW3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating compositional scene understanding in multimodal generative models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7bIfe2I7bK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visual world is fundamentally compositional. Visual scenes are defined by the composition of objects and their relations. Hence, it is essential for computer vision systems to reflect and exploit this compositionality to achieve robust and generalizable scene understanding. While major strides have been made toward the development of general-purpose, multimodal generative models, including both text-to-image models and multimodal vision-language models, it remains unclear whether these systems are capable of accurately generating and interpreting scenes involving the composition of multiple objects and relations. In this work, we present an evaluation of the compositional visual processing capabilities in the current generation of text-to-image (DALL-E 3) and multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5, QWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of these systems to human participants. The results suggest that these systems display some ability to solve compositional and relational tasks, showing notable improvements over the previous generation of multimodal models, but with performance nevertheless well below the level of human participants, particularly for more complex scenes involving many (>5) objects and multiple relations. These results highlight the need for further progress toward compositional understanding of visual scenes.},
  archive      = {J_TMLR},
  author       = {Shuhao Fu and Andrew Jun Lee and Yixin Anna Wang and Ida Momennejad and Trevor Bihl and Hongjing Lu and Taylor Whittington Webb},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating compositional scene understanding in multimodal generative models},
  url          = {https://openreview.net/forum?id=7bIfe2I7bK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank suggestion in non-negative matrix factorization: Residual sensitivity to initial conditions (RSIC). <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9Xj5w4DX0t'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the appropriate rank in Non-negative Matrix Factorization (NMF) is a critical challenge that often requires extensive parameter tuning and domain-specific knowledge. Traditional methods for rank determination focus on identifying a single optimal rank, which may not capture the complex structure inherent in real-world datasets. In this study, we introduce a novel approach called Residual Sensitivity to Intial Conditions (RSIC) that suggests potentially multiple ranks of interest by analyzing the sensitivity of the relative residuals (e.g., relative reconstruction error) to different initializations. By computing the Mean Coordinatewise Interquartile Range (MCI) of the residuals across multiple random initializations, our method identifies regions where the NMF solutions are less sensitive to initial conditions and potentially more meaningful. We evaluate RSIC on a diverse set of datasets, including single-cell gene expression data, image data, and text data, and compare it against current state-of-the-art rank determination methods. Our experiments demonstrate that RSIC effectively identifies relevant ranks consistent with the underlying structure of the data, outperforming traditional methods in scenarios where they are computationally infeasible or less accurate. This approach provides a more scalable and generalizable solution for rank determination in NMF that does not rely on domain-specific knowledge or assumptions.},
  archive      = {J_TMLR},
  author       = {Marc A. Tunnell and Zachary DeBruine and Erin Carrier},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rank suggestion in non-negative matrix factorization: Residual sensitivity to initial conditions (RSIC)},
  url          = {https://openreview.net/forum?id=9Xj5w4DX0t},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic evaluation of the planning and scheduling abilities of the reasoning model o1. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FkKBxp0FhR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OpenAI claims that their recent o1 (Strawberry) model has been specifically constructed and trained to escape the normal limitations of autoregressive Large Language Models (LLMs)–making it a new kind of model: a Large Reasoning Model (LRM)–and be generally capable of tackling procedural reasoning tasks. We present the first comprehensive evaluation of these models on the fundamental tasks of planning and scheduling. Previous research attempted to use LLMs’ expressive generation capabilities to solve these problems, but met with only limited success. We fill in the gaps in this literature by testing a larger suite of state-of-the-art LLMs on a set of large benchmarks, and then use this as a baseline to evaluate o1-preview and o1-mini. We see that while they can offer significant accuracy improvements over LLMs, this single metric is misleading and incomplete, as LRM queries demand large and unpredictable costs and take significant amounts of time to complete. We provide a case study demonstrating that, at those same price points, other methods of inference time scaling can do just as well. We also show that, contrary to OpenAI’s injunctions, o1’s performance can be improved further by embedding it in compound systems that separately, but complementarily, scale inference time further. Finally, while the paper is focused on o1, we provide similar evaluations of a more recent (and open-weight) LRM -- DeepSeek R1.},
  archive      = {J_TMLR},
  author       = {Karthik Valmeekam and Kaya Stechly and Atharva Gundawar and Subbarao Kambhampati},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A systematic evaluation of the planning and scheduling abilities of the reasoning model o1},
  url          = {https://openreview.net/forum?id=FkKBxp0FhR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bézier flow: A surface-wise gradient descent method for multi-objective optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=I1gALvbRxj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a framework to construct a multi-objective optimization algorithm from a single-objective optimization algorithm by using the Bézier simplex model. Additionally, we extend the stability of optimization algorithms in the sense of Probably Approximately Correct (PAC) learning and define the PAC stability. We prove that it leads to an upper bound on the generalization error with high probability. Furthermore, we show that multi-objective optimization algorithms derived from a gradient descent-based single-objective optimization algorithm are PAC stable. We conducted numerical experiments with synthetic and real multi-objective optimization problem instances and demonstrated that our method achieved lower generalization errors than the existing multi-objective optimization algorithms.},
  archive      = {J_TMLR},
  author       = {Akiyoshi Sannai and Yasunari Hikima and Ken Kobayashi and Akinori Tanaka and Naoki Hamada},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bézier flow: A surface-wise gradient descent method for multi-objective optimization},
  url          = {https://openreview.net/forum?id=I1gALvbRxj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking patch dependence for masked autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JT2KMuo2BV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we examine the impact of inter-patch dependencies in the decoder of masked autoencoders (MAE) on representation learning. We decompose the decoding mechanism for masked reconstruction into self-attention between mask tokens and cross-attention between masked and visible tokens. Our findings reveal that MAE reconstructs coherent images from visible patches not through interactions between patches in the decoder but by learning a global representation within the encoder. This discovery leads us to propose a simple visual pretraining framework: cross-attention masked autoencoders (CrossMAE). This framework employs only cross-attention in the decoder to independently read out reconstructions for a small subset of masked patches from encoder outputs. This approach achieves comparable or superior performance to traditional MAE across models ranging from ViT-S to ViT-H and significantly reduces computational requirements. By its design, CrossMAE challenges the necessity of interaction between mask tokens for effective masked pretraining. Code and models are publicly available: https://crossmae.github.io/},
  archive      = {J_TMLR},
  author       = {Letian Fu and Long Lian and Renhao Wang and Baifeng Shi and XuDong Wang and Adam Yala and Trevor Darrell and Alexei A Efros and Ken Goldberg},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking patch dependence for masked autoencoders},
  url          = {https://openreview.net/forum?id=JT2KMuo2BV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph potential field neural network for massive agents group-wise path planning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LJHVPWNnV6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent path planning is important in both multi-agent path finding and multi-agent reinforcement learning areas. However, continual group-wise multi-agent path planning that requires the agents to perform as a team to pursue high team scores instead of individually is less studied. To address this problem, we propose a novel graph potential field-based neural network (GPFNN), which models a valid potential field map for path planning. Our GPFNN unfolds the T-step iterative optimization of the potential field maps as a T-layer feedforward neural network. Thus, a deeper GPFNN leads to more precise potential field maps without the over-smoothing issue. A potential field map inherently provides a monotonic potential flow from any source node to the target nodes to construct the optimal path (w.r.t. the potential decay), equipping our GPFNN with an elegant planning ability. Moreover, we incorporate dynamically updated boundary conditions into our GPFNN to address group-wise multi-agent path planning that supports both static targets and dynamic moving targets. Empirically, experiments on three different-sized mazes (up to $1025 \times 1025$ sized mazes) with up to 1,000 agents demonstrate the planning ability of our GPFNN to handle both static and dynamic moving targets. Experiments on extensive graph node classification tasks on six graph datasets (up to millions of nodes) demonstrate the learning ability of our GPFNN.},
  archive      = {J_TMLR},
  author       = {Yueming Lyu and Xiaowei Zhou and Xingrui Yu and Ivor Tsang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph potential field neural network for massive agents group-wise path planning},
  url          = {https://openreview.net/forum?id=LJHVPWNnV6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Accelerated) noise-adaptive stochastic heavy-ball momentum. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Okxp1W8If0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic heavy ball momentum (SHB) is commonly used to train machine learning models, and often provides empirical improvements over stochastic gradient descent. By primarily focusing on strongly-convex quadratics, we aim to better understand the theoretical advantage of SHB and subsequently improve the method. For strongly-convex quadratics, Kidambi et al. (2018) show that SHB (with a mini-batch of size $1$) cannot attain accelerated convergence, and hence has no theoretical benefit over SGD. They conjecture that the practical gain of SHB is a by-product of using larger mini-batches. We first substantiate this claim by showing that SHB can attain an accelerated rate when the mini-batch size is larger than a threshold $b^*$ that depends on the condition number $\kappa$. Specifically, we prove that with the same step-size and momentum parameters as in the deterministic setting, SHB with a sufficiently large mini-batch size results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence when measuring the distance to the optimal solution in the $\ell_2$ norm, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. We prove a lower-bound which demonstrates that a $\kappa$ dependence in $b^*$ is necessary. To ensure convergence to the minimizer, we design a noise-adaptive multi-stage algorithm that results in an $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}}\right) + \frac{\sigma}{\sqrt{T}}\right)$ rate when measuring the distance to the optimal solution in the $\ell_2$ norm. We also consider the general smooth, strongly-convex setting and propose the first noise-adaptive SHB variant that converges to the minimizer at an $O(\exp(-\frac{T}{\kappa}) + \frac{\sigma^2}{T})$ rate when measuring the distance to the optimal solution in the squared $\ell_2$ norm. We empirically demonstrate the effectiveness of the proposed algorithms.},
  archive      = {J_TMLR},
  author       = {Anh Quang Dang and Reza Babanezhad Harikandeh and Sharan Vaswani},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {(Accelerated) noise-adaptive stochastic heavy-ball momentum},
  url          = {https://openreview.net/forum?id=Okxp1W8If0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximising the utility of validation sets for imbalanced noisy-label meta-learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SBM9yeNZz5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning is an effective method to handle imbalanced and noisy-label learning, but it generally depends on a clean validation set. Unfortunately, this validation set has poor scalability when the number of classes increases, as traditionally these samples need to be randomly selected, manually labelled and balanced-distributed. This problem therefore has motivated the development of meta-learning methods to automatically select validation samples that are likely to have clean labels and balanced class distribution. Unfortunately, a common missing point of existing meta-learning methods for noisy label learning is the lack of consideration for data informativeness when constructing the validation set. The construction of an informative validation set requires hard samples, i.e., samples that the model has low confident prediction, but these samples are more likely to be noisy, which can degrade the meta reweighting process. Therefore, the balance between sample informativeness and cleanness is an important criteria for validation set optimization. In this paper, we propose new criteria to characterise the utility of such meta-learning validation sets, based on: 1) sample informativeness; 2) balanced class distribution; and 3) label cleanliness. We also introduce a new imbalanced noisy-label meta-learning (INOLML) algorithm that auto- matically builds a validation set by maximising such utility criteria. The proposed method shows state-of-the-art (SOTA) results compared to previous meta-learning and noisy-label learning approaches on several noisy-label learning benchmarks.},
  archive      = {J_TMLR},
  author       = {Hoang Anh Dung and Cuong C. Nguyen and Vasileios Belagiannis and Thanh-Toan Do and Gustavo Carneiro},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maximising the utility of validation sets for imbalanced noisy-label meta-learning},
  url          = {https://openreview.net/forum?id=SBM9yeNZz5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An embedding is worth a thousand noisy labels. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=X3gSvQjShh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of deep neural networks scales with dataset size and label quality, rendering the efficient mitigation of low-quality data annotations crucial for building robust and cost-effective systems. Existing strategies to address label noise exhibit severe limitations due to computational complexity and application dependency. In this work, we propose WANN, a Weighted Adaptive Nearest Neighbor approach that builds on self-supervised feature representations obtained from foundation models. To guide the weighted voting scheme, we introduce a reliability score $\eta$, which measures the likelihood of a data label being correct. WANN outperforms reference methods, including a linear layer trained with robust loss functions, on diverse datasets of varying size and under various noise types and severities. WANN also exhibits superior generalization on imbalanced data compared to both Adaptive-NNs (ANN) and fixed k-NNs. Furthermore, the proposed weighting scheme enhances supervised dimensionality reduction under noisy labels. This yields a significant boost in classification performance with 10x and 100x smaller image embeddings, minimizing latency and storage requirements. Our approach, emphasizing efficiency and explainability, emerges as a simple, robust solution to overcome inherent limitations of deep neural network training.},
  archive      = {J_TMLR},
  author       = {Francesco Di Salvo and Sebastian Doerrich and Ines Rieger and Christian Ledig},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An embedding is worth a thousand noisy labels},
  url          = {https://openreview.net/forum?id=X3gSvQjShh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Downstream task guided masking learning in masked autoencoders using multi-level optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=cFmmaxkD5A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked Autoencoder (MAE) is a notable method for self-supervised pretraining in visual representation learning. It operates by randomly masking image patches and reconstructing these masked patches using the unmasked ones. A key limitation of MAE lies in its disregard for the varying informativeness of different patches, as it uniformly selects patches to mask. To overcome this, some approaches propose masking based on patch informativeness. However, these methods often do not consider the specific requirements of downstream tasks, potentially leading to suboptimal representations for these tasks. In response, we introduce the Multi-level Optimized Mask Autoencoder (MLO-MAE), a novel framework that leverages end-to-end feedback from downstream tasks to learn an optimal masking strategy during pretraining. Our experimental findings highlight MLO-MAE's significant advancements in visual representation learning. Compared to existing methods, it demonstrates remarkable improvements across diverse datasets and tasks, showcasing its adaptability and efficiency. Our code is available at https://github.com/Alexiland/MLO-MAE.},
  archive      = {J_TMLR},
  author       = {Han Guo and Ramtin Hosseini and Ruiyi Zhang and Sai Ashish Somayajula and Ranak Roy Chowdhury and Rajesh K. Gupta and Pengtao Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Downstream task guided masking learning in masked autoencoders using multi-level optimization},
  url          = {https://openreview.net/forum?id=cFmmaxkD5A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian learning-driven prototypical contrastive loss for class-incremental learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dNWaTuKV9M'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of methods in continual learning is to learn tasks in a sequential manner over time (sometimes from a stream of data), while mitigating the detrimental phenomenon of catastrophic forgetting. This paper proposes a method to learn an effective representation between previous and newly encountered class prototypes. We propose a prototypical network with a Bayesian learning-driven contrastive loss (BLCL), tailored specifically for class-incremental learning scenarios. We introduce a contrastive loss that incorporates novel classes into the latent representation by reducing intra-class and increasing inter-class distance. Our approach dynamically adapts the balance between the cross-entropy and contrastive loss functions with a Bayesian learning technique. Experimental results conducted on the CIFAR-10, CIFAR-100, and ImageNet100 datasets for image classification and images of a GNSS-based dataset for interference classification validate the efficacy of our method, showcasing its superiority over existing state-of-the-art approaches.},
  archive      = {J_TMLR},
  author       = {Nisha L. Raichur and Lucas Heublein and Tobias Feigl and Alexander Rügamer and Christopher Mutschler and Felix Ott},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian learning-driven prototypical contrastive loss for class-incremental learning},
  url          = {https://openreview.net/forum?id=dNWaTuKV9M},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LTL-constrained policy optimization with cycle experience replay. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gxUp2d4JTw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear Temporal Logic (LTL) offers a precise means for constraining the behavior of reinforcement learning agents. However, in many settings where both satisfaction and optimality conditions are present, LTL is insufficient to capture both. Instead, LTL-constrained policy optimization, where the goal is to optimize a scalar reward under LTL constraints, is needed. This constrained optimization problem proves difficult in deep Reinforcement Learning (DRL) settings, where learned policies often ignore the LTL constraint due to the sparse nature of LTL satisfaction. To alleviate the sparsity issue, we introduce Cycle Experience Replay (CyclER), a novel reward shaping technique that exploits the underlying structure of the LTL constraint to guide a policy towards satisfaction by encouraging partial behaviors compliant with the constraint. We provide a theoretical guarantee that optimizing CyclER will achieve policies that satisfy the LTL constraint with near-optimal probability. We evaluate CyclER in three continuous control domains. Our experimental results show that optimizing CyclER in tandem with the existing scalar reward outperforms existing reward-shaping methods at finding performant LTL-satisfying policies.},
  archive      = {J_TMLR},
  author       = {Ameesh Shah and Cameron Voloshin and Chenxi Yang and Abhinav Verma and Swarat Chaudhuri and Sanjit A. Seshia},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LTL-constrained policy optimization with cycle experience replay},
  url          = {https://openreview.net/forum?id=gxUp2d4JTw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GOTHAM: Graph class incremental learning framework under weak supervision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hCyT4RsF27'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are growing rapidly and so are the number of different categories associated with it. Applications like e-commerce, healthcare, recommendation systems, and various social media platforms are rapidly moving towards graph representation of data due to their ability to capture both structural and attribute information. One crucial task in graph analysis is node classification, where unlabeled nodes are categorized into predefined classes. In practice, novel classes appear incrementally sometimes with just a few labels (seen classes) or even without any labels (unseen classes), either because they are new or haven't been explored much. Traditional methods assume abundant labeled data for training, which isn't always feasible. We investigate a broader objective: Graph Class Incremental Learning under Weak Supervision (GCL), addressing this challenge by meta-training on base classes with limited labeled instances. During the incremental streams, novel classes can have few-shot or zero-shot representation. Our proposed framework GOTHAM efficiently accommodates these unlabeled nodes by finding the closest prototype representation, serving as class representatives in the attribute space. For Text-Attributed Graphs (TAGs), our framework additionally incorporates semantic information to enhance the representation. By employing teacher-student knowledge distillation to mitigate forgetting, GOTHAM achieves promising results across various tasks. Experiments on datasets such as Cora-ML, Amazon, and OBGN-Arxiv showcase the effectiveness of our approach in handling evolving graph data under limited supervision.},
  archive      = {J_TMLR},
  author       = {Aditya Hemant Shahane and Prathosh AP and Sandeep Kumar},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GOTHAM: Graph class incremental learning framework under weak supervision},
  url          = {https://openreview.net/forum?id=hCyT4RsF27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile activation: Correcting a failure mode of traditional ML models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nWk5OtZ7ze'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard ML models fail to infer the context distribution and suitably adapt. For instance, the learning fails when the underlying distribution is actually a mixture of distributions with contradictory labels. Learning also fails if there is a shift between train and test distributions. Standard neural network architectures like MLPs or CNNs are not equipped to handle this. In this article, we propose a simple activation function, quantile activation (QAct), that addresses this problem without significantly increasing computational costs. The core idea is to "adapt" the outputs of each neuron to its context distribution. The proposed quantile activation (QAct) outputs the relative quantile position of neuron activations within their context distribution, diverging from the direct numerical outputs common in traditional networks. A specific case of the above failure mode is when there is an inherent distribution shift, i.e the test distribution differs slightly from the train distribution. We validate the proposed activation function under covariate shifts, using datasets designed to test robustness against distortions. Our results demonstrate significantly better generalisation across distortions compared to conventional classifiers and other adaptive methods, across various architectures. Although this paper presents a proof of concept, we find that this approach unexpectedly outperforms DINOv2 (small), despite DINOv2 being trained with a much larger network and dataset.},
  archive      = {J_TMLR},
  author       = {Aditya Challa and Sravan Danda and Laurent Najman and Snehanshu Saha},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Quantile activation: Correcting a failure mode of traditional ML models},
  url          = {https://openreview.net/forum?id=nWk5OtZ7ze},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latte: Latent diffusion transformer for video generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ntGPYNUF3t'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Latte, a novel Latent Diffusion Transformer for video generation. Latte first extracts spatio-temporal tokens from input videos and then adopts a series of Transformer blocks to model video distribution in the latent space. In order to model a substantial number of tokens extracted from videos, four efficient variants are introduced from the perspective of decomposing the spatial and temporal dimensions of input videos. To improve the quality of generated videos, we determine the best practices of Latte through rigorous experimental analysis, including video clip patch embedding, model variants, timestep-class information injection, temporal positional embedding, and learning strategies. Our comprehensive evaluation demonstrates that Latte achieves state-of-the-art performance across four standard video generation datasets, \textit{i.e.}, FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In addition, we extend Latte to the text-to-video generation (T2V) task, where Latte achieves results that are competitive with recent T2V models. We strongly believe that Latte provides valuable insights for future research on incorporating Transformers into diffusion models for video generation.},
  archive      = {J_TMLR},
  author       = {Xin Ma and Yaohui Wang and Xinyuan Chen and Gengyun Jia and Ziwei Liu and Yuan-Fang Li and Cunjian Chen and Yu Qiao},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latte: Latent diffusion transformer for video generation},
  url          = {https://openreview.net/forum?id=ntGPYNUF3t},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing temporal consistency in video editing by reconstructing videos with 3D gaussian splatting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=s1zfBJysbI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency. To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors. Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos. In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach. For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds. These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views. Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views. In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model. This approach ensures the temporal consistency in the edited videos while maintaining high fidelity to the editing text prompt. We further propose a recursive and ensembled refinement by revisiting the denoising step and guidance scale used in video diffusion process with Video-3DGS. To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing. Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (×1.9, ×4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively. Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos.},
  archive      = {J_TMLR},
  author       = {Inkyu Shin and Qihang Yu and Xiaohui Shen and In So Kweon and Kuk-Jin Yoon and Liang-Chieh Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing temporal consistency in video editing by reconstructing videos with 3D gaussian splatting},
  url          = {https://openreview.net/forum?id=s1zfBJysbI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlled training data generation with diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sSOxuUjE2o'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method to control a text-to-image generative model to produce training data useful for supervised learning. Unlike previous works that employ an open-loop approach via pre-defined prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system that involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model to find adversarial prompts that result in generated images that maximize the model's loss and, consequently, expose its vulnerabilities. While these adversarial prompts generate training examples curated for improving the given model, they are not curated for a specific target distribution of interest, which can be inefficient. Therefore, we introduce the second feedback mechanism that can optionally guide the generation process towards a desirable target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. The proposed closed-loop system allows us to control the training data generation for a given model and target image distribution. We evaluate on different tasks, datasets, and architectures, with different types of distribution shifts (corruptions, spurious correlations, unseen domains) and illustrate the advantages of the proposed feedback mechanisms compared to open-loop approaches.},
  archive      = {J_TMLR},
  author       = {Teresa Yeo and Andrei Atanov and Harold Luc Benoit and Aleksandr Alekseev and Ruchira Ray and Pooya Esmaeil Akhoondi and Amir Zamir},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Controlled training data generation with diffusion models},
  url          = {https://openreview.net/forum?id=sSOxuUjE2o},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextualized messages boost graph representations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sXr1fRjs1N'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have gained significant attention in recent years for their ability to process data that may be represented as graphs. This has prompted several studies to explore their representational capability based on the graph isomorphism task. Notably, these works inherently assume a countable node feature representation, potentially limiting their applicability. Interestingly, only a few study GNNs with uncountable node feature representation. In the paper, a new perspective on the representational capability of GNNs is investigated across all levels—node-level, neighborhood-level, and graph-level—when the space of node feature representation is uncountable. Specifically, the injective and metric requirements of previous works are softly relaxed by employing a pseudometric distance on the space of input to create a soft-injective function such that distinct inputs may produce similar outputs if and only if the pseudometric deems the inputs to be sufficiently similar on some representation. As a consequence, a simple and computationally efficient soft-isomorphic relational graph convolution network (SIR-GCN) that emphasizes the contextualized transformation of neighborhood feature representations via anisotropic and dynamic message functions is proposed. Furthermore, a mathematical discussion on the relationship between SIR-GCN and key GNNs in literature is laid out to put the contribution into context, establishing SIR-GCN as a generalization of classical GNN methodologies. To close, experiments on synthetic and benchmark datasets demonstrate the relative superiority of SIR-GCN, outperforming comparable models in node and graph property prediction tasks.},
  archive      = {J_TMLR},
  author       = {Brian Godwin Lim and Galvin Brice Sy Lim and Renzo Roel Tan and Kazushi Ikeda},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Contextualized messages boost graph representations},
  url          = {https://openreview.net/forum?id=sXr1fRjs1N},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic pricing in the linear valuation model using shape constraints. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uKZ0R4IQaO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a shape-constrained approach to dynamic pricing for censored data in the linear valuation model eliminating the need for tuning parameters commonly required by existing methods. Previous works have addressed the challenge of unknown market noise distribution $F_0$ using strategies ranging from kernel methods to reinforcement learning algorithms, such as bandit techniques and upper confidence bounds (UCB), under the assumption that $F_0$ satisfies Lipschitz (or stronger) conditions. In contrast, our method relies on isotonic regression under the weaker assumption that $F_0$ is $\alpha$-H\"older continuous for some $\alpha \in (0,1]$, for which we derive a regret upper bound. Simulations and experiments with real-world data obtained by Welltower Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate that our method attains lower empirical regret in comparison to several existing methods in the literature while offering the advantage of being tuning-parameter free.},
  archive      = {J_TMLR},
  author       = {Daniele Bracale and Moulinath Banerjee and Yuekai Sun and Salam Turki and Kevin Stoll},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamic pricing in the linear valuation model using shape constraints},
  url          = {https://openreview.net/forum?id=uKZ0R4IQaO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResiDual transformer alignment with spectral decomposition. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=z37LCgSIzI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When examined through the lens of their residual streams, a puzzling property emerges in transformer networks: residual contributions (e.g., attention heads) sometimes specialize in specific tasks or input attributes. In this paper, we analyze this phenomenon in vision transformers, focusing on the spectral geometry of residuals, and explore its implications for modality alignment in vision-language models. First, we link it to the intrinsically low-dimensional structure of visual head representations, zooming into their principal components and showing that they encode specialized roles across a wide variety of input data distributions. Then, we analyze the effect of head specialization in multimodal models, focusing on how improved alignment between text and specialized heads impacts zero-shot classification performance. This specialization-performance link consistently holds across diverse pre-training data, network sizes, and objectives, demonstrating a powerful new mechanism for boosting zero-shot classification through targeted alignment. Ultimately, we translate these insights into actionable terms by introducing ResiDual, a technique for spectral alignment of the residual stream. Much like panning for gold, it lets the noise from irrelevant unit principal components (i.e., attributes) wash away to amplify task-relevant ones. Remarkably, this dual perspective on modality alignment yields fine-tuning level performance on different data distributions while modelling an extremely interpretable and parameter-efficient transformation, as we extensively show on 70 pre-trained network-dataset combinations (7 models, 10 datasets).},
  archive      = {J_TMLR},
  author       = {Lorenzo Basile and Valentino Maiorca and Luca Bortolussi and Emanuele Rodolà and Francesco Locatello},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ResiDual transformer alignment with spectral decomposition},
  url          = {https://openreview.net/forum?id=z37LCgSIzI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoregressive models in vision: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1BqXkjNEGP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive modeling has been a huge success in the field of natural language processing (NLP). Recently, autoregressive models have emerged as a significant area of focus in computer vision, where they excel in producing high-quality visual content. Autoregressive models in NLP typically operate on subword tokens. However, the representation strategy in computer vision can vary in different levels, i.e., pixel-level, token-level, or scale-level, reflecting the diverse and hierarchical nature of visual data compared to the sequential structure of language. This survey comprehensively examines the literature on autoregressive models applied to vision. To improve readability for researchers from diverse research backgrounds, we start with preliminary sequence representation and modeling in vision. Next, we divide the fundamental frameworks of visual autoregressive models into three general sub-categories, including pixel-based, token-based, and scale-based models based on the representation strategy. We then explore the interconnections between autoregressive models and other generative models. Furthermore, we present a multifaceted categorization of autoregressive models in computer vision, including image generation, video generation, 3D generation, and multimodal generation. We also elaborate on their applications in diverse domains, including emerging domains such as embodied AI and 3D medical AI, with about 250 related references. Finally, we highlight the current challenges to autoregressive models in vision with suggestions about potential research directions. We have also set up a Github repository to organize the papers included in this survey at: https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey.},
  archive      = {J_TMLR},
  author       = {Jing Xiong and Gongye Liu and Lun Huang and Chengyue Wu and Taiqiang Wu and Yao Mu and Yuan Yao and Hui Shen and Zhongwei Wan and Jinfa Huang and Chaofan Tao and Shen Yan and Huaxiu Yao and Lingpeng Kong and Hongxia Yang and Mi Zhang and Guillermo Sapiro and Jiebo Luo and Ping Luo and Ngai Wong},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Autoregressive models in vision: A survey},
  url          = {https://openreview.net/forum?id=1BqXkjNEGP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open problems in technical AI governance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1nO4qFMiS0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI progress is creating a growing range of risks and opportunities, but it is often unclear how they should be navigated. In many cases, the barriers and uncertainties faced are at least partly technical. Technical AI governance, referring to technical analysis and tools for supporting the effective governance of AI, seeks to address such challenges. It can help to (a) identify areas where intervention is needed, (b) assess the efficacy of potential governance actions, and (c) enhance governance options by designing mechanisms for enforcement, incentivization, or compliance. In this paper, we explain what technical AI governance is, outline why it is important, and present a taxonomy and incomplete catalog of its open problems. This paper is intended as a resource for technical researchers or research funders looking to contribute to AI governance.},
  archive      = {J_TMLR},
  author       = {Anka Reuel and Benjamin Bucknall and Stephen Casper and Timothy Fist and Lisa Soder and Onni Aarne and Lewis Hammond and Lujain Ibrahim and Alan Chan and Peter Wills and Markus Anderljung and Ben Garfinkel and Lennart Heim and Andrew Trask and Gabriel Mukobi and Rylan Schaeffer and Mauricio Baker and Sara Hooker and Irene Solaiman and Sasha Luccioni and Nitarshan Rajkumar and Nicolas Moës and Jeffrey Ladish and David Bau and Paul Bricman and Neel Guha and Jessica Newman and Yoshua Bengio and Tobin South and Alex Pentland and Sanmi Koyejo and Mykel Kochenderfer and Robert Trager},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Open problems in technical AI governance},
  url          = {https://openreview.net/forum?id=1nO4qFMiS0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MiniFold: Simple, fast, and accurate protein structure prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1p9hQTbjgo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction has emerged as a powerful tool for biologists and drug makers. However, the computational cost of state-of-the-art models such as AlphaFold limits their scalability and makes training and fine-tuning prohibitively expensive. Although previous work has achieved considerable inference speedups by replacing the multiple sequence alignment step with protein language models, the overall architecture of structure prediction models, inherited from AlphaFold2, has remained largely unchanged. In this work, we show that protein language model-based structure predictors can be dramatically simplified at little to no loss in accuracy. Our model, MiniFold, consists of a redesigned Evoformer and a lightweight structure module. We also propose two novel GPU kernels, tailored to the proposed architecture. Equipped with the same ESM2 protein language model, MiniFold is competitive with ESMFold on the standard CAMEO and CASP datasets while achieving training and inference speedups of up to 20x, and significant reductions in peak memory. Our results show that MiniFold is an effective solution for large-scale applications and resource-constrained environments.},
  archive      = {J_TMLR},
  author       = {Jeremy Wohlwend and Mateo Reveiz and Matt McPartlon and Axel Feldmann and Wengong Jin and Regina Barzilay},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MiniFold: Simple, fast, and accurate protein structure prediction},
  url          = {https://openreview.net/forum?id=1p9hQTbjgo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-distribution learning with human feedback. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5qo8MF3QU1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) learning often relies on strong statistical assumptions or predefined OOD data distributions, limiting its effectiveness in real-world deployment for both OOD generalization and detection, especially when human inspection is minimal. This paper introduces a novel framework for OOD learning that integrates human feedback to enhance model adaptation and reliability. Our approach leverages freely available unlabeled data in the wild, which naturally captures environmental test-time OOD distributions under both covariate and semantic shifts. To effectively utilize such data, we propose selectively acquiring human feedback to label a small subset of informative samples. These labeled samples are then used to train both a multi-class classifier and an OOD detector. By incorporating human feedback, our method significantly improves model robustness and precision in handling OOD scenarios. We provide theoretical insights by establishing generalization error bounds for our algorithm. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods by a significant margin. Code is publicly available at https://github.com/HaoyueBaiZJU/ood-hf.},
  archive      = {J_TMLR},
  author       = {Haoyue Bai and Xuefeng Du and Katie Rainey and Shibin Parameswaran and Yixuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Out-of-distribution learning with human feedback},
  url          = {https://openreview.net/forum?id=5qo8MF3QU1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness-aware dense subgraph discovery. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7rqV7Cb67L'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense subgraph discovery (DSD) is a key graph mining primitive with myriad applications including finding densely connected communities which are diverse in their vertex composition. In such a context, it is desirable to extract a dense subgraph that provides fair representation of the diverse subgroups that constitute the vertex set while incurring a small loss in terms of subgraph density. Existing methods for promoting fairness in DSD have important limitations - the associated formulations are NP-hard in the worst case and they do not provide flexible notions of fairness, making it non-trivial to analyze the inherent trade-off between density and fairness. In this paper, we introduce two tractable formulations for fair DSD, each offering a different notion of fairness. Our methods provide a structured and flexible approach to incorporate fairness, accommodating varying fairness levels. We introduce the fairness-induced relative loss in subgraph density as a price of fairness measure to quantify the associated trade-off. We are the first to study such a notion in the context of detecting fair dense subgraphs. Extensive experiments on real-world datasets demonstrate that our methods not only match but frequently outperform existing solutions, sometimes incurring even less than half the subgraph density loss compared to prior art, while achieving the target fairness levels. Importantly, they excel in scenarios that previous methods fail to adequately handle, i.e., those with extreme subgroup imbalances, highlighting their effectiveness in extracting fair and dense solutions.},
  archive      = {J_TMLR},
  author       = {Emmanouil Kariotakis and Nicholas D Sidiropoulos and Aritra Konar},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness-aware dense subgraph discovery},
  url          = {https://openreview.net/forum?id=7rqV7Cb67L},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Referential communication in heterogeneous communities of pre-trained visual deep networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8L3khbpUJL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large pre-trained image-processing neural networks are being embedded in autonomous agents such as self-driving cars or robots, the question arises of how such systems can communicate with each other about the surrounding world, despite their different architectures and training regimes. As a first step in this direction, we systematically explore the task of referential communication in a community of heterogeneous state-of-the-art pre-trained visual networks, showing that they can develop, in a self-supervised way, a shared protocol to refer to a target object among a set of candidates. This shared protocol can also be used, to some extent, to communicate about previously unseen object categories of different granularity. Moreover, a visual network that was not initially part of an existing community can learn the community's protocol with remarkable ease. Finally, we study, both qualitatively and quantitatively, the properties of the emergent protocol, providing some evidence that it is capturing high-level semantic features of objects.},
  archive      = {J_TMLR},
  author       = {Matéo Mahaut and Roberto Dessi and Francesca Franzon and Marco Baroni},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Referential communication in heterogeneous communities of pre-trained visual deep networks},
  url          = {https://openreview.net/forum?id=8L3khbpUJL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-syntactic discrepancy in images (SSDI): Learning meaning and order of features from natural images. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8otbGorZK2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite considerable progress in image classification tasks, classification models seem unaffected by the images that significantly deviate from those that appear natural to human eyes. Specifically, while human perception can easily identify abnormal appearances or compositions in images, classification models overlook any alterations in the arrangement of object parts as long as they are present in any order, even if unnatural. Hence, this work exposes the vulnerability of having semantic and syntactic discrepancy in images (SSDI) in the form of corruptions that remove or shuffle image patches or present images in the form of puzzles. To address this vulnerability, we propose the concept of "image grammar", comprising "image semantics" and "image syntax". Image semantics pertains to the interpretation of parts or patches within an image, whereas image syntax refers to the arrangement of these parts to form a coherent object. We present a semi-supervised two-stage method for learning the image grammar of visual elements and environments solely from natural images. While the first stage learns the semantic meaning of individual object parts, the second stage learns how their relative arrangement constitutes an entire object. The efficacy of the proposed approach is then demonstrated by achieving SSDI detection rates ranging from 70% to 90% on corruptions generated from CelebA and SUN-RGBD datasets. Code is publicly available at: https://github.com/ChunTao1999/SSDI/.},
  archive      = {J_TMLR},
  author       = {Chun Tao and Timur Ibrayev and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semantic-syntactic discrepancy in images (SSDI): Learning meaning and order of features from natural images},
  url          = {https://openreview.net/forum?id=8otbGorZK2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating generalization behaviours of generative flow networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9L0B5N5hUX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Flow Networks (GFlowNets, GFNs) are a generative framework for learning unnormalized probability mass functions over discrete spaces. Since their inception, GFlowNets have proven to be useful for learning generative models in applications where the majority of the discrete space is unvisited during training. This has inspired some to hypothesize that GFlowNets, when paired with deep neural networks (DNNs), have favorable generalization properties. In this work, we empirically verify some of the hypothesized mechanisms of generalization of GFlowNets. We accomplish this by introducing a novel graph-based benchmark environment where reward difficulty can be easily varied, $p(x)$ can be computed exactly, and an unseen test set can be constructed to quantify generalization performance. Using this graph-based environment, we are able to systematically test the hypothesized mechanisms of generalization of GFlowNets and put forth a set of empirical observations that summarize our findings. In particular, we find (and confirm) that the functions that GFlowNets learn to approximate have an implicit underlying structure which facilitate generalization. Surprisingly ---and somewhat contradictory to existing knowledge--- we also find that GFlowNets are sensitive to being trained offline and off-policy. However, the reward implicitly learned by GFlowNets is robust to changes in the training distribution.},
  archive      = {J_TMLR},
  author       = {Lazar Atanackovic and Emmanuel Bengio},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Investigating generalization behaviours of generative flow networks},
  url          = {https://openreview.net/forum?id=9L0B5N5hUX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FragFormer: A fragment-based representation learning framework for molecular property prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9aiuB3kIjd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular representation learning is central to molecular property prediction, which is a vital component in drug discovery. Existing methods, which mainly focus on the atom-level molecular graphs, often find it challenging to directly model the relation between fragment (substructure) and function of molecules, largely due to insufficient fragment priors. In this work, we propose a molecular self-supervised learning framework \textbf{FragFormer}, which aims to learn the representation of fragments and their contextual relationships. Given the prior that an atom can be part of multiple functional groups, we develop $k$-\textbf{D}egree \textbf{Ove}rlapping fragmentation (\textbf{DOVE}), which generates overlapping fragment graph by employing the iterative line graph. Besides, DOVE can preserve the connection information during the fragmentation phase compared to non-overlapping fragmentation. In the pre-training stage, we design a \textit{nested masked fragment prediction} objective, to capture the hierarchical nature of fragments, namely that larger fragments can encompass multiple smaller ones. Based on FragFormer, we introduce a simple yet efficient \textit{fragment-level} interpretation method \textbf{FragCAM} for the molecular property prediction results with greater accuracy. Moreover, thanks to the fragment modeling, our model is more capable of processing large molecule, such as peptides, and capturing the long-range interactions inside molecules. Our approach achieves state-of-the-art (SOTA) performance on eight out of eleven molecular property prediction datasets on PharmaBench. On long-range biological benchmark with peptide data, FragFormer can beat strong baselines by a clear margin, which shows the model's potential to generalize to larger molecules. Finally, we demonstrate that our model can effectively identify decisive fragments for prediction results on a real-world dataset\footnote{Our code is available at \url{https://github.com/wjxts/FragFormer/}}.},
  archive      = {J_TMLR},
  author       = {Jiaxi Wang and Yaosen Min and Miao Li and Ji Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FragFormer: A fragment-based representation learning framework for molecular property prediction},
  url          = {https://openreview.net/forum?id=9aiuB3kIjd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-informed message passing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9fPinz1iH2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due to their implicit homophily assumption. We mitigate this problem with a novel scheme that regulates the aggregation of messages, modulating the type and extent of message passing locally thereby preserving both the low and high-frequency components of information. Our approach relies solely on learnt embeddings, obviating the need for auxiliary labels, thus extending the benefits of heterophily-aware embeddings to broader applications, e.g. generative modelling. Our experiments, conducted across various data sets and GNN architectures, demonstrate performance enhancements and reveal heterophily patterns across standard classification benchmarks. Furthermore, application to molecular generation showcases notable performance improvements on chemoinformatics benchmarks.},
  archive      = {J_TMLR},
  author       = {Haishan Wang and Arno Solin and Vikas K Garg},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Heterophily-informed message passing},
  url          = {https://openreview.net/forum?id=9fPinz1iH2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-select: Feature selection with large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=16f7ea1N3p'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we demonstrate a surprising capability of large language models (LLMs): given only input feature names and a description of a prediction task, they are capable of selecting the most predictive features, with performance rivaling the standard tools of data science. Remarkably, these models exhibit this capacity across various query mechanisms. For example, we zero-shot prompt an LLM to output a numerical importance score for a feature (e.g., ``blood pressure'') in predicting an outcome of interest (e.g., ``heart failure''), with no additional context. In particular, we find that the latest models, such as GPT-4, can consistently identify the most predictive features regardless of the query mechanism and across various prompting strategies. We illustrate these findings through extensive experiments on real-world data, where we show that LLM-based feature selection consistently achieves strong performance competitive with data-driven methods such as the LASSO, despite never having looked at the downstream training data. Our findings suggest that LLMs may be useful not only for selecting the best features for training \textit{but also for deciding which features to collect in the first place}. This could potentially benefit practitioners in domains like healthcare and the social sciences, where collecting high-quality data comes at a high cost.},
  archive      = {J_TMLR},
  author       = {Daniel P Jeong and Zachary Chase Lipton and Pradeep Kumar Ravikumar},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLM-select: Feature selection with large language models},
  url          = {https://openreview.net/forum?id=16f7ea1N3p},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MaxCutBench: Revisiting and benchmarking graph neural networks for maximum cut. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=322PpCGAX8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been much work on designing general heuristics for graph-based, combinatorial optimization problems via the incorporation of Graph Neural Networks (GNNs) to learn distribution-specific solution structures. However, there is a lack of consistency in evaluating these heuristics in terms of the baselines and instances chosen, making it difficult to assess the relative performance of the algorithms. In this paper, we introduce \textbf{MaxCutBench}—an open-source benchmark suite dedicated to the NP-hard Maximum Cut problem. The suite offers a unified interface for $16$ algorithms, both traditional and machine-learning-based. Using our benchmark, we conduct an in-depth analysis of the implemented algorithms on a carefully selected set of hard instances from diverse graph datasets. Our main finding is that classical local search heuristics can outperform several highly cited learning-based approaches, including S2V-DQN (Khalil et al., 2017), ECO-DQN (Barrett et al., 2020), among others, in terms of objective value, generalization, inference time, and scalability. Additionally, we find that the performance of ECO-DQN either remains the same or improves when the GNN is replaced by simple linear regression. We hope our benchmark will contribute to the efforts of the community to standardize the evaluation of learned heuristics for combinatorial optimization. Code, data, and pre-trained models are available at: \url{https://github.com/ankurnath/MaxCut-Bench}.},
  archive      = {J_TMLR},
  author       = {Ankur Nath and Alan Kuhnle},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MaxCutBench: Revisiting and benchmarking graph neural networks for maximum cut},
  url          = {https://openreview.net/forum?id=322PpCGAX8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust model selection of gaussian graphical models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AIby9MQXbu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Gaussian graphical model selection, noise-corrupted samples present significant challenges. It is known that even minimal amounts of noise can obscure the underlying structure, leading to fundamental identifiability issues. A recent line of work addressing this “robust model selection” problem narrows its focus to tree-structured graphical models. Even within this specific class of models, exact structure recovery is shown to be impossible. However, several algorithms have been developed that are known to provably recover the underlying tree-structure up to an (unavoidable) equivalence class. In this paper, we extend these results beyond tree-structured graphs. We first characterize the equivalence class up to which general graphs can be recovered in the presence of noise. Despite the inherent ambiguity (which we prove is unavoidable), the structure that can be recovered reveals local clustering information and global connectivity patterns in the underlying model. Such information is useful in a range of real-world problems, including power grids, social networks, protein-protein interactions, and neural structures. We then propose an algorithm which provably recovers the underlying graph up to the identified ambiguity. We further provide finite sample guarantees in the high-dimensional regime for our algorithm and validate our results through numerical simulations.},
  archive      = {J_TMLR},
  author       = {Abrar Zahin and Rajasekhar Anguluri and Lalitha Sankar and Oliver Kosut and Gautam Dasarathy},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust model selection of gaussian graphical models},
  url          = {https://openreview.net/forum?id=AIby9MQXbu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RS-reg: Probabilistic and robust certified regression through randomized smoothing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AcLlg4J52H'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized smoothing has shown promising certified robustness against adversaries in classification tasks. Despite such success with only zeroth-order access to base models, randomized smoothing has not been extended to a general form of regression. By defining robustness in regression tasks flexibly through probabilities, we demonstrate how to establish upper bounds on input data point perturbation (using the $\ell_2$ norm) for a user-specified probability of observing valid outputs. Furthermore, we showcase the asymptotic property of a basic averaging function in scenarios where the regression model operates without any constraint. We then derive a certified upper bound of the input perturbations when dealing with a family of regression models where the outputs are bounded. Our simulations verify the validity of the theoretical results and reveal the advantages and limitations of simple smoothing functions, i.e., averaging, in regression tasks. The code is publicly available at \url{https://github.com/arekavandi/Certified_Robust_Regression}.},
  archive      = {J_TMLR},
  author       = {Aref Miri Rekavandi and Olga Ohrimenko and Benjamin I. P. Rubinstein},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RS-reg: Probabilistic and robust certified regression through randomized smoothing},
  url          = {https://openreview.net/forum?id=AcLlg4J52H},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal embedding guided negative sample generation for knowledge graph link prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B4SyciDyIh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) models encode the structural information of knowledge graphs to predicting new links. Effective training of these models requires distinguishing between positive and negative samples with high precision. Although prior research has shown that improving the quality of negative samples can significantly enhance model accuracy, identifying high-quality negative samples remains a challenging problem. This paper theoretically investigates the condition under which negative samples lead to optimal KG embedding and identifies a sufficient condition for an effective negative sample distribution. Based on this theoretical foundation, we propose \textbf{E}mbedding \textbf{MU}tation (\textsc{EMU}), a novel framework that \emph{generates} negative samples satisfying this condition, in contrast to conventional methods that focus on \emph{identifying} challenging negative samples within the training data. Importantly, the simplicity of \textsc{EMU} ensures seamless integration with existing KGE models and negative sampling methods. To evaluate its efficacy, we conducted comprehensive experiments across multiple datasets. The results consistently demonstrate significant improvements in link prediction performance across various KGE models and negative sampling methods. Notably, \textsc{EMU} enables performance improvements comparable to those achieved by models with embedding dimension five times larger. An implementation of the method and experiments are available at \url{https://github.com/nec-research/EMU-KG}.},
  archive      = {J_TMLR},
  author       = {Makoto Takamoto and Daniel Onoro Rubio and Wiem Ben Rim and Takashi Maruyama and Bhushan Kotnis},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimal embedding guided negative sample generation for knowledge graph link prediction},
  url          = {https://openreview.net/forum?id=B4SyciDyIh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formal verification of graph convolutional networks with uncertain node features and uncertain graph structure. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B6y12Ot0cP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks are becoming increasingly popular in the field of machine learning due to their unique ability to process data structured in graphs. They have also been applied in safety-critical environments where perturbations inherently occur. However, these perturbations require us to formally verify neural networks before their deployment in safety-critical environments as neural networks are prone to adversarial attacks. While there exists research on the formal verification of neural networks, there is no work verifying the robustness of generic graph convolutional network architectures with uncertainty in the node features and in the graph structure over multiple message-passing steps. This work addresses this research gap by explicitly preserving the non-convex dependencies of all elements in the underlying computations through reachability analysis with (matrix) polynomial zonotopes. We demonstrate our approach on three popular benchmark datasets.},
  archive      = {J_TMLR},
  author       = {Tobias Ladner and Michael Eichelbeck and Matthias Althoff},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Formal verification of graph convolutional networks with uncertain node features and uncertain graph structure},
  url          = {https://openreview.net/forum?id=B6y12Ot0cP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RLeXplore: Accelerating research in intrinsically-motivated reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B9BHjTN4z6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrinsic rewards can effectively guide reinforcement learning (RL) agents in specific tasks. However, extrinsic rewards frequently fall short in complex environments due to the significant human effort needed for their design and annotation. This limitation underscores the necessity for intrinsic rewards, which offer auxiliary and dense signals and can enable agents to learn in an unsupervised manner. Although various intrinsic reward formulations have been proposed, their implementation and optimization details are insufficiently explored and lack standardization, thereby hindering research progress. To address this gap, we introduce RLeXplore, a unified, highly modularized, and plug-and-play framework offering reliable implementations of eight state-of-the-art intrinsic reward methods. Furthermore, we conduct an in-depth study that identifies critical implementation details and establishes well-justified standard practices in intrinsically-motivated RL. Our documentation, examples, and source code are available at [https://github.com/RLE-Foundation/RLeXplore](https://github.com/RLE-Foundation/RLeXplore).},
  archive      = {J_TMLR},
  author       = {Mingqi Yuan and Roger Creus Castanyer and Bo Li and Xin Jin and Wenjun Zeng and Glen Berseth},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {RLeXplore: Accelerating research in intrinsically-motivated reinforcement learning},
  url          = {https://openreview.net/forum?id=B9BHjTN4z6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming knowledge barriers: Online imitation learning from visual observation with pretrained world models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BaRD2Nfj41'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretraining and finetuning models has become increasingly popular in decision-making. But there are still serious impediments in Imitation Learning from Observation (ILfO) with pretrained models. This study identifies two primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB). The EKB emerges due to the pretrained models' limitations in handling novel observations, which leads to inaccurate action inference. Conversely, the DKB stems from the reliance on limited demonstration datasets, restricting the model's adaptability across diverse scenarios. We propose separate solutions to overcome each barrier and apply them to Action Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new algorithm, AIME-NoB, integrates online interactions and a data-driven regulariser to mitigate the EKB. Additionally, it uses a surrogate reward function to broaden the policy's supported states, addressing the DKB. Our experiments on vision-based control tasks from the DeepMind Control Suite and MetaWorld benchmarks show that AIME-NoB significantly improves sample efficiency and converged performance, presenting a robust framework for overcoming the challenges in ILfO with pretrained models. Code available at https://github.com/IcarusWizard/AIME-NoB.},
  archive      = {J_TMLR},
  author       = {Xingyuan Zhang and Philip Becker-Ehmck and Patrick van der Smagt and Maximilian Karl},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Overcoming knowledge barriers: Online imitation learning from visual observation with pretrained world models},
  url          = {https://openreview.net/forum?id=BaRD2Nfj41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VLM’s eye examination: Instruct and inspect visual competency of vision language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CgWkVb2lHB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision language models (VLMs) have shown promising reasoning capabilities across various benchmarks; however, our understanding of their visual perception remains limited. In this work, we propose an eye examination process to investigate how a VLM perceives images, focusing on key aspects of visual recognition, ranging from basic color and shape to semantic understanding. We introduce a dataset, LENS, to guide VLMs to follow the examination and check its readiness. Once the model is ready, we conduct the examination. We quantify and visualize VLMs' sensitivities to color and shape, and semantic matching. Our findings reveal that VLMs have varying sensitivity to different colors while consistently showing insensitivity to green across different VLMs. Also, we found different shape sensitivity and semantic recognition depending on LLM's capacity despite using the same fixed visual encoder. Our analyses and findings have the potential to inspire the design of VLMs and the pre-processing of visual input to VLMs for improving application performance.},
  archive      = {J_TMLR},
  author       = {Nam Hyeon-Woo and Moon Ye-Bin and Wonseok Choi and Lee Hyun and Tae-Hyun Oh},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {VLM’s eye examination: Instruct and inspect visual competency of vision language models},
  url          = {https://openreview.net/forum?id=CgWkVb2lHB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ComPEFT: Compression for communicating parameter efficient updates via sparsification and quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CovLQwu611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) enables creation of specialized language models for diverse tasks, resulting in numerous expert modules. In many practical use cases, these expert PEFT modules are integrated into a single model that answers arbitrary queries by routing queries to different experts. However, only a few experts can be kept in GPU memory due to memory constraints. Consequently, expert modules are frequently loaded and offloaded between CPU/GPU memory or disk storage. This frequent swapping dramatically increases communication overhead, leading unacceptable latency and degrading user experience. The large size of modern PEFT modules further exacerbates this latency. For example, QLoRA experts for 65B LLaMA are 3.2GB, making swapping a major communication bottleneck, particularly in memory-constrained environments. To address these issues, we present ComPEFT (compressed PEFT), a novel method for compressing fine-tuning residuals (task vectors) of PEFT models. Reducing expert PEFT module size effectively addresses both memory and communication limitations, facilitating faster swapping and enabling a higher density of experts within a given memory footprint. ComPEFT employs sparsification and ternary quantization to reduce PEFT module size without any additional training while preserving or enhancing model performance. Extensive evaluation across T5, T0, and LLaMA-based models with 200M − 65B parameters, ComPEFT achieves compression ratios of 8x − 50x. Specifically, we show that ComPEFT improves with scale – stronger models exhibit higher compressibility and better performance. We show ComPEFT applied to LLaMA − 65B outperforms QLoRA by 4.16% on MMLU with a 26x storage size reduction. Additionally, compressed experts produced by ComPEFT maintain few-shot compositional generalization capabilities, facilitate efficient communication and computation, and exhibit enhanced performance when merged. Lastly, we provide an analysis of different method components, compare ComPEFT with other PEFT methods, and test its efficacy for compressing full finetuning residual.},
  archive      = {J_TMLR},
  author       = {Prateek Yadav and Leshem Choshen and Colin Raffel and Mohit Bansal},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ComPEFT: Compression for communicating parameter efficient updates via sparsification and quantization},
  url          = {https://openreview.net/forum?id=CovLQwu611},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-bellman operator for convergence of $Q$-learning with linear function approximation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=D2PjEPGXgh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the convergence of $Q$-learning with linear function approximation and introduce the multi-Bellman operator, an extension of the traditional Bellman operator. By analyzing the properties of this operator, we identify conditions under which the projected multi-Bellman operator becomes a contraction, yielding stronger fixed-point guarantees compared to the original Bellman operator. Building on these insights, we propose the multi-$Q$-learning algorithm, which achieves convergence and approximates the optimal solution with arbitrary precision. This contrasts with traditional $Q$-learning, which lacks such convergence guarantees. Finally, we empirically validate our theoretical results.},
  archive      = {J_TMLR},
  author       = {Diogo S. Carvalho and Pedro A. Santos and Francisco S. Melo},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multi-bellman operator for convergence of $Q$-learning with linear function approximation},
  url          = {https://openreview.net/forum?id=D2PjEPGXgh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Change point detection in dynamic graphs with decoder-only latent space model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DVeFqV56Iz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript studies the unsupervised change point detection problem in time series of graphs using a decoder-only latent space model. The proposed framework consists of learnable prior distributions for low-dimensional graph representations and of a decoder that bridges the observed graphs and latent representations. The prior distributions of the latent spaces are learned from the observed data as empirical Bayes to assist change point detection. Specifically, the model parameters are estimated via maximum approximate likelihood, with a Group Fused Lasso regularization imposed on the prior parameters. The augmented Lagrangian is solved via Alternating Direction Method of Multipliers, and Langevin Dynamics are recruited for posterior inference. Simulation studies show good performance of the latent space model in supporting change point detection and real data experiments yield change points that align with significant events.},
  archive      = {J_TMLR},
  author       = {Yik Lun Kei and Jialiang Li and Hangjian Li and Yanzhen Chen and OSCAR HERNAN MADRID PADILLA},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Change point detection in dynamic graphs with decoder-only latent space model},
  url          = {https://openreview.net/forum?id=DVeFqV56Iz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoDe: Blockwise control for denoising diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DqPCWMiMU0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {{Aligning diffusion models to downstream tasks often requires finetuning new models or gradient-based guidance at inference time to enable sampling from the reward-tilted posterior. In this work, we explore a simple inference-time gradient-free guidance approach, called controlled denoising (CoDe), that circumvents the need for differentiable guidance functions and model finetuning. CoDe is a blockwise sampling method applied during intermediate denoising steps, allowing for alignment with downstream rewards. Our experiments demonstrate that, despite its simplicity, CoDe offers a favorable trade-off between reward alignment, prompt instruction following, and inference cost, achieving a competitive performance against the state-of-the-art baselines}. Our code is available at https://github.com/anujinho/code.},
  archive      = {J_TMLR},
  author       = {Anuj Singh and Sayak Mukherjee and Ahmad Beirami and Hadi J. Rad},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CoDe: Blockwise control for denoising diffusion models},
  url          = {https://openreview.net/forum?id=DqPCWMiMU0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speech synthesis by unrolling diffusion process using neural network layers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F6l3BBPElY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel setup where a neural network is trained to predict multiple steps of the reverse diffusion process in an unrolled manner, with successive layers corresponding to equally spaced steps in the diffusion schedule. Each layer progressively denoises the input during the reverse process until the final layer estimates the original input, $x_0$. Additionally, we introduce a new learning target by using latent variables, rather than the conventional approach of predicting the original input $x_0$ or source error $\epsilon_0$. In speech synthesis, using $x_0$ or $\epsilon_0$ often leads to large prediction errors in the early stages of the denoising process, causing distortion in the recovered speech. Our method mitigates this issue and, through extensive evaluation, demonstrates the generation of high-fidelity speech in competitive time, outperforming current state-of-the-art techniques. Moreover, the proposed approach generalizes well to unseen speech. Sample audio is available at \url{https://onexpeters.github.io/UDPNet/}.},
  archive      = {J_TMLR},
  author       = {Peter Ochieng},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Speech synthesis by unrolling diffusion process using neural network layers},
  url          = {https://openreview.net/forum?id=F6l3BBPElY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging gradients for unsupervised accuracy estimation under distribution shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FIWHRSuoos'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the test performance of a model, possibly under distribution shift, without having access to the ground-truth labels is a challenging, yet very important problem for the safe deployment of machine learning algorithms in the wild. Existing works mostly rely on information from either the outputs or the extracted features of neural networks to estimate a score that correlates with the ground-truth test accuracy. In this paper, we investigate -- both empirically and theoretically -- how the information provided by the gradients can be predictive of the ground-truth test accuracy even under distribution shifts. More specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our intuition is that these gradients should be of higher magnitude when the model generalizes poorly. We provide the theoretical insights behind our approach and the key ingredients that ensure its empirical success. Extensive experiments conducted with various architectures on diverse distribution shifts demonstrate that our method significantly outperforms current state-of-the-art approaches. The code is available at \url{https://github.com/Renchunzi-Xie/GdScore}.},
  archive      = {J_TMLR},
  author       = {RENCHUNZI XIE and Ambroise Odonnat and Vasilii Feofanov and Ievgen Redko and Jianfeng Zhang and Bo An},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging gradients for unsupervised accuracy estimation under distribution shift},
  url          = {https://openreview.net/forum?id=FIWHRSuoos},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian transferability assessment for spiking neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GaUtrgXMHe'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired spiking neural networks (SNNs) attract broad interest in neuromorphic computing but suffer the problem of being difficult to optimize. Concurrently, pre-trained models (PTMs) have become a foundation for developing and applying artificial intelligence. Therefore, it is expected that pre-trained SNNs can alleviate the optimization difficulty of training from scratch. However, with a lot of PTMs available in the model hubs, effectively selecting the most appropriate PTM for a given task remains a significant challenge, often necessitating exhaustive fine-tuning and grid-searching. While several solutions to this challenge have been proposed for the mainstream artificial neural network (ANNs), aimed at developing efficient methods to assess the transferability of PTMs on target tasks, the realm of SNNs remains unexplored. The currently most used transferability assessment method for ANNs predicts transferability in a Bayesian perspective. Feature maps extracted by the PTM backbone on the target task are used to calculate the maximum model evidence as the indicator of transferability. However, ANNs and SNNs differ in architecture, rendering the existing Bayesian method incompatible with SNNs. To solve this problem, this paper introduces a novel approach to using the feature maps averaged over the time domain to calculate maximum evidence. Our proposed $\textbf{M}$aximum $\textbf{E}$vidence method with $\textbf{A}$veraged $\textbf{F}$eatures (MEAF) demonstrates effectiveness for SNNs. Additionally, the current algorithm calculates maximum evidence in an iterative way. To accelerate the selection of PTMs, an approximation method is proposed to avoid iteration in the calculation of maximum evidence, significantly reducing time consumption. It is shown through experiment that the proposed MEAF method is effective for the transferability assessment of SNNs. MEAF outperforms information theory-based assessment methods such as LEEP and NCE, which can directly adapt to SNNs on neuromorphic datasets, underscoring its potential to streamline PTM selection and application in the realm of SNNs.},
  archive      = {J_TMLR},
  author       = {Haiqing Hao and Wenhui Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bayesian transferability assessment for spiking neural networks},
  url          = {https://openreview.net/forum?id=GaUtrgXMHe},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HyperMagNet: A magnetic laplacian based hypergraph neural network. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Gdf4P7sEzE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data science, hypergraphs are natural models for data exhibiting multi-way or group relationships in contrast to graphs which only model pairwise relationships. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important multi-way or group information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a non-reversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix — the magnetic Laplacian — which serves as the input to our proposed hypergraph neural network. We study $\textit{HyperMagNet}$ for the task of node classification, and demonstrate its effectiveness over graph-reduction based hypergraph neural networks.},
  archive      = {J_TMLR},
  author       = {Tatyana Benko and Martin Buck and Ilya Amburg and Stephen J. Young and Sinan Guven Aksoy},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HyperMagNet: A magnetic laplacian based hypergraph neural network},
  url          = {https://openreview.net/forum?id=Gdf4P7sEzE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double horizon model-based policy optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HRvHCd03HM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long ``distribution rollout'' (DR) and a short ``training rollout'' (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.},
  archive      = {J_TMLR},
  author       = {Akihiro Kubo and Paavo Parmas and Shin Ishii},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Double horizon model-based policy optimization},
  url          = {https://openreview.net/forum?id=HRvHCd03HM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based framework for fair and scalable solution generation in kidney exchange problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IizmQoF86Y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning and Generative Flow Networks, known as GFlowNets, present an exciting possibility for neural networks to model distributions across various data structures. In this paper, we broaden their applicability to data structures consisting of optimal solutions for a combinatorial problem. Concretely, we propose using Q-learning and various policy gradient methods, as well as GFlowNets to learn the distribution of optimal solutions for kidney exchange problems (KEPs). This could provide a useful tool for decision-making authorities, policymakers and clinicians, as it offers them multiple optimal or near-optimal solutions, and provides a complementary landscape to their traditional integer programming-based toolbox for promoting fairness and societal benefits. Our reinforcement learning-based framework trained on KEP instances provides an effective addition to computationally expensive exact approaches, notably mixed-integer programming. Our experiments thoroughly evaluate the quality of the solution sets sampled from the trained neural networks in terms of optimality, their scalability when dealing with real-sized KEP instances, and their capability to generate a diverse pool of solutions. We also cover the use of their efficient solution generation capabilities to improve fairness and simulate the evolution of the KEP pool in a dynamic setting. Our contribution is thus: 1) methodological, as it introduces a novel setting for reinforcement learning in addition to GFlowNets, 2) implementational, as it delves beyond the theory and details how to use conditional information, and 3) of practical significance, as it considers a specific combinatorial problem in the healthcare domain.},
  archive      = {J_TMLR},
  author       = {William St-Arnaud and Margarida Carvalho and Golnoosh Farnadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A learning-based framework for fair and scalable solution generation in kidney exchange problems},
  url          = {https://openreview.net/forum?id=IizmQoF86Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adversarial perspective on machine unlearning for AI safety. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=J5IRyTKZ9s'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models are finetuned to refuse questions about hazardous knowledge, but these protections can often be bypassed. Unlearning methods aim at completely removing hazardous capabilities from models and make them inaccessible to adversaries. This work challenges the fundamental differences between unlearning and traditional safety post-training from an adversarial perspective. We demonstrate that existing jailbreak methods, previously reported as ineffective against unlearning, can be successful when applied carefully. Furthermore, we develop a variety of adaptive methods that recover most supposedly unlearned capabilities. For instance, we show that finetuning on 10 unrelated examples or removing specific directions in the activation space can recover most hazardous capabilities for models edited with RMU, a state-of-the-art unlearning method. Our findings challenge the robustness of current unlearning approaches and question their advantages over safety training.},
  archive      = {J_TMLR},
  author       = {Jakub Łucki and Boyi Wei and Yangsibo Huang and Peter Henderson and Florian Tramèr and Javier Rando},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An adversarial perspective on machine unlearning for AI safety},
  url          = {https://openreview.net/forum?id=J5IRyTKZ9s},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global graph counterfactual explanation: A subgraph mapping approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KQzJYI6eo0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been widely deployed in various real-world applications. However, most GNNs are black-box models that lack explanations. One strategy to explain GNNs is through counterfactual explanation, which aims to find minimum perturbations on input graphs that change the GNN predictions. Existing works on GNN counterfactual explanations primarily concentrate on the local-level perspective (i.e., generating counterfactuals for each individual graph), which suffers from information overload and lacks insights into the broader cross-graph relationships. To address such issues, we propose GlobalGCE, a novel global-level graph counterfactual explanation method. GlobalGCE aims to identify a collection of subgraph mapping rules as counterfactual explanations for the target GNN. According to these rules, substituting certain significant subgraphs with their counterfactual subgraphs will change the GNN prediction to the desired class for most graphs (i.e., maximum coverage). Methodologically, we design a significant subgraph generator and a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphs and the rules can be effectively generated. Extensive experiments demonstrate the superiority of our GlobalGCE compared to existing baselines. Our code can be found at \url{https://github.com/YinhanHe123/GlobalGCE}.},
  archive      = {J_TMLR},
  author       = {Yinhan He and Wendy Zheng and Yaochen Zhu and Jing Ma and Saumitra Mishra and Natraj Raman and Ninghao Liu and Jundong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global graph counterfactual explanation: A subgraph mapping approach},
  url          = {https://openreview.net/forum?id=KQzJYI6eo0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expressivity of representation learning on continuous-time dynamic graphs: An information-flow centric review. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=M7Lhr2anjg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are ubiquitous in real-world applications, ranging from social networks to biological systems, and have inspired the development of Graph Neural Networks (GNNs) for learning expressive representations. While most research has centered on static graphs, many real-world scenarios involve dynamic, temporally evolving graphs, motivating the need for Continuous-Time Dynamic Graph (CTDG) models. This paper provides a comprehensive review of Graph Representation Learning (GRL) on CTDGs with a focus on Self-Supervised Representation Learning (SSRL). We introduce a novel theoretical framework that analyzes the expressivity of CTDG models through an Information-Flow (IF) lens, quantifying their ability to propagate and encode temporal and structural information. Leveraging this framework, we categorize existing CTDG methods based on their suitability for different graph types and application scenarios. Within the same scope, we examine the design of SSRL methods tailored to CTDGs, such as predictive and contrastive approaches, highlighting their potential to mitigate the reliance on labeled data. Empirical evaluations on synthetic and real-world datasets validate our theoretical insights, demonstrating the strengths and limitations of various methods across long-range, bi-partite and community-based graphs. This work offers both a theoretical foundation and practical guidance for selecting and developing CTDG models, advancing the understanding of GRL in dynamic settings.},
  archive      = {J_TMLR},
  author       = {Sofiane ENNADIR and Gabriela Zarzar Gandler and Filip Cornell and Lele Cao and Oleg Smirnov and Tianze Wang and Levente Zólyomi and Björn Brinne and Sahar Asadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Expressivity of representation learning on continuous-time dynamic graphs: An information-flow centric review},
  url          = {https://openreview.net/forum?id=M7Lhr2anjg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reproducibility study of "Cooperation, competition, and maliciousness: LLM-stakeholders interactive negotiation". <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MTrhFmkC45'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reproducibility study and extension of "Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation." We validate the original findings using a range of open-weight models (1.5B-70B parameters), GPT-4, and GPT-4o Mini while introducing several novel contributions. We analyze the Pareto front of the games, propose a communication-free baseline to test whether successful negotiations are possible without agent interaction, evaluate recent small language models' performance, analyze structural information leakage in model responses, and implement an inequality metric to assess negotiation fairness. Our results demonstrate that smaller models (<10B parameters) struggle with format adherence and coherent responses, but larger open-weight models can approach proprietary model performance. Additionally, in many scenarios, single-agent approaches can achieve comparable results to multi-agent negotiations, challenging assumptions about the necessity of agent communication to perform well on the benchmark. This work also provides insights into accessibility, fairness, environmental impact, and privacy considerations of LLM-based negotiation systems.},
  archive      = {J_TMLR},
  author       = {Jose L. Garcia and Karolina Hajkova and Maria Marchenko and Carlos Miguel Patiño},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reproducibility study of "Cooperation, competition, and maliciousness: LLM-stakeholders interactive negotiation"},
  url          = {https://openreview.net/forum?id=MTrhFmkC45},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can kernel methods explain how the data affects neural collapse?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MbF1gYfIlY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vast amount of literature has recently focused on the “Neural Collapse” (NC) phenomenon, which emerges when training neural network (NN) classifiers beyond the zero training error point. The core component of NC is the decrease in the within-class variability of the network’s deepest features, dubbed as NC1. The theoretical works that study NC are typically based on simplified unconstrained features models (UFMs) that mask any effect of the data on the extent of collapse. To address this limitation of UFMs, this paper explores the possibility of analyzing NC1 using kernels associated with shallow NNs. We begin by formulating an NC1 metric as a function of the kernel. Then, we specialize it to the NN Gaussian Process kernel (NNGP) and the Neural Tangent Kernel (NTK), associated with wide networks at initialization and during gradient-based training with a small learning rate, respectively. As a key result, we show that the NTK does not represent more collapsed features than the NNGP for Gaussian data of arbitrary dimensions. This showcases the limitations of data-independent kernels such as NTK in approximating the NC behavior of NNs. As an alternative to NTK, we then empirically explore a recently proposed data-aware Gaussian Process kernel, which generalizes NNGP to model feature learning. We show that this kernel yields lower NC1 than NNGP but may not follow the trends of the shallow NN. Our study demonstrates that adaptivity to data may allow kernel-based analysis of NC, though further advancements in this area are still needed. A nice byproduct of our study is showing both theoretically and empirically that the choice of nonlinear activation function affects NC1 (with ERF yielding lower values than ReLU).},
  archive      = {J_TMLR},
  author       = {Vignesh Kothapalli and Tom Tirer},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Can kernel methods explain how the data affects neural collapse?},
  url          = {https://openreview.net/forum?id=MbF1gYfIlY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient exploration in multi-agent reinforcement learning via farsighted self-direction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=NUV8THrLZC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning faces greater challenges with efficient exploration compared to single-agent counterparts, primarily due to the exponential growth in state and action spaces. Methods based on intrinsic rewards have been proven to enhance exploration efficiency in multi-agent scenarios effectively. However, these methods are plagued by instability during training and biases in exploration direction. To address these challenges, we propose Farsighted Self-Direction (FSD), a novel model-free method that utilizes a long-term exploration bonus to achieve coordinated exploration. Since prediction error against individual Q-values indicates a potential bonus for committed exploration, it is taken into account in action selection to directly guide the coordinated exploration. Further, we also use clipped double Q-learning to reduce noise in prediction error. We validate the method on didactic examples and demonstrate the outperformance of our method on challenging StarCraft II micromanagement tasks.},
  archive      = {J_TMLR},
  author       = {Tiancheng Lao and Xudong Guo and Mengge Liu and Junjie Yu and Yi Liu and Wenhui Fan},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient exploration in multi-agent reinforcement learning via farsighted self-direction},
  url          = {https://openreview.net/forum?id=NUV8THrLZC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design editing for offline model-based optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OPFnpl7KiF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {{Offline model-based optimization (MBO) aims to maximize a black-box objective function using only an offline dataset of designs and scores. These tasks span various domains, such as robotics, material design, and protein and molecular engineering. A common approach involves training a surrogate model using existing designs and their corresponding scores, and then generating new designs through gradient-based updates with respect to the surrogate model. This method suffers from the out-of-distribution issue, where the surrogate model may erroneously predict high scores for unseen designs. To address this challenge, we introduce a novel method, Design Editing for Offline Model-based Optimization} (DEMO), which leverages a diffusion prior to calibrate overly optimized designs. DEMO first generates pseudo design candidates by performing gradient ascent with respect to a surrogate model. While these pseudo design candidates contain information beyond the offline dataset, they might be invalid or have erroneously high predicted scores. Therefore, to address this challenge while utilizing the information provided by pseudo design candidates, we propose an editing process to refine these pseudo design candidates. We introduce noise to the pseudo design candidates and subsequently denoise them with a diffusion prior trained on the offline dataset, ensuring they align with the distribution of valid designs. Empirical evaluations on seven offline MBO tasks show that, with properly tuned hyperparamters, DEMO's score is competitive with the best previously reported scores in the literature.},
  archive      = {J_TMLR},
  author       = {Ye Yuan and Youyuan Zhang and Can Chen and Haolun Wu and Melody Zixuan Li and Jianmo Li and James J. Clark and Xue Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Design editing for offline model-based optimization},
  url          = {https://openreview.net/forum?id=OPFnpl7KiF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling laws for predicting downstream performance in LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PJUbMDkQVY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise estimation of downstream performance in large language models (LLMs) prior to training is essential for guiding their development process. Scaling laws analysis utilizes the statistics of a series of significantly smaller sampling language models (LMs) to predict the performance of the target LLM. For downstream performance prediction, the critical challenge lies in the emergent abilities in LLMs that occur beyond task-specific computational thresholds. In this work, we focus on the pre-training loss as a more computation-efficient metric for performance estimation. Our two-stage approach FLP consists of first estimating a function that maps computational resources (e.g., FLOPs) to the pre-training Loss using a series of sampling models, followed by mapping the pre-training loss to downstream task Performance after the critical "emergent phase". In our experiments, this FLP solution accurately predicts the performance of LLMs with 7B and 13B parameters using a series of sampling LMs up to 3B, achieving error margins of 5% and 10%, respectively, and significantly outperforming the FLOPs-to-Performance approach. Further, we present FLP-M, a fundamental approach for performance prediction that addresses the practical need to integrate datasets from multiple sources during pre-training, specifically blending general corpus with code data to accurately represent the common necessity. FLP-M extends the power law analytical function to predict domain-specific pre-training loss based on FLOPs across data sources, and employs a two-layer neural network to model the non-linear relationship between multiple domain-specific loss and downstream performance. By utilizing a 3B LLM trained on a specific ratio and a series of smaller sampling LMs, FLP-M can effectively forecast the performance of 3B and 7B LLMs across various data mixtures for most benchmarks within 10% error margins.},
  archive      = {J_TMLR},
  author       = {Yangyi Chen and Binxuan Huang and Yifan Gao and Zhengyang Wang and Jingfeng Yang and Heng Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Scaling laws for predicting downstream performance in LLMs},
  url          = {https://openreview.net/forum?id=PJUbMDkQVY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated spectral graph transformers meet neural ordinary differential equations for non-IID graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TR6iUG8i6Z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Network (GNN) research is rapidly advancing due to GNNs’ capacity to learn distributed representations from graph-structured data. However, centralizing large volumes of real-world graph data for GNN training is often impractical due to privacy concerns, regulatory restrictions, and commercial competition. Federated learning (FL), a distributed learning paradigm, offers a solution by preserving data privacy with collaborative model training. Despite progress in training huge vision and language models, federated learning for GNNs remains underexplored. To address this challenge, we present a novel method for federated learning on GNNs based on spectral GNNs equipped with neural ordinary differential equations (ODE) for better information capture, showing promising results across both homophilic and heterophilic graphs. Our approach effectively handles non-Independent and Identically Distributed (non-IID) data, while also achieving performance comparable to existing methods that only operate on IID data. It is designed to be privacy-preserving and bandwidth-optimized, making it suitable for real-world applications such as social network analysis, recommendation systems, and fraud detection, which often involve complex, non-IID, and heterophilic graph structures. Our results in the area of federated learning on non-IID heterophilic graphs demonstrate significant improvements, while also achieving better performance on homophilic graphs. This work highlights the potential of federated learning in diverse and challenging graph settings.},
  archive      = {J_TMLR},
  author       = {Kishan Gurumurthy and Himanshu Pal and Charu Sharma},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated spectral graph transformers meet neural ordinary differential equations for non-IID graphs},
  url          = {https://openreview.net/forum?id=TR6iUG8i6Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODEStream: A buffer-free online learning framework with ODE-based adaptor for streaming time series forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TWOTKhwU5n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenges of irregularity and concept drift in streaming time series is crucial for real-world predictive modelling. Previous studies in time series continual learning often propose models that require buffering long sequences, potentially restricting the responsiveness of the inference system. Moreover, these models are typically designed for regularly sampled data, an unrealistic assumption in real-world scenarios. This paper introduces ODEStream, a novel buffer-free continual learning framework that incorporates a temporal isolation layer to capture temporal dependencies within the data. Simultaneously, it leverages the capability of neural ordinary differential equations to process irregular sequences and generate a continuous data representation, enabling seamless adaptation to changing dynamics in a data streaming scenario. Our approach focuses on learning how the dynamics and distribution of historical data change over time, facilitating direct processing of streaming sequences. Evaluations on benchmark real-world datasets demonstrate that ODEStream outperforms the state-of-the-art online learning and streaming analysis baseline models, providing accurate predictions over extended periods while minimising performance degradation over time by learning how the sequence dynamics change. The implementation of ODEStream is available at: \url{https://github.com/FtoonAbushaqra/ODEStream.git}.},
  archive      = {J_TMLR},
  author       = {Futoon M. Abushaqra and Hao Xue and Yongli Ren and Flora D. Salim},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ODEStream: A buffer-free online learning framework with ODE-based adaptor for streaming time series forecasting},
  url          = {https://openreview.net/forum?id=TWOTKhwU5n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When are bias-free ReLU networks effectively linear networks?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ucpfdn66k2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the implications of removing bias in ReLU networks regarding their expressivity and learning dynamics. We first show that two-layer bias-free ReLU networks have limited expressivity: the only odd function two-layer bias-free ReLU networks can express is a linear one. We then show that, under symmetry conditions on the data, these networks have the same learning dynamics as linear networks. This enables us to give analytical time-course solutions to certain two-layer bias-free (leaky) ReLU networks outside the lazy learning regime. While deep bias-free ReLU networks are more expressive than their two-layer counterparts, they still share a number of similarities with deep linear networks. These similarities enable us to leverage insights from linear networks to understand certain ReLU networks. Overall, our results show that some properties previously established for bias-free ReLU networks arise due to equivalence to linear networks.},
  archive      = {J_TMLR},
  author       = {Yedi Zhang and Andrew M Saxe and Peter E. Latham},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When are bias-free ReLU networks effectively linear networks?},
  url          = {https://openreview.net/forum?id=Ucpfdn66k2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating non-conjugate gaussian processes by trading off computation for uncertainty. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UdcF3JbSKb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-conjugate Gaussian processes (NCGPs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in NCGPs is prohibitively expensive for large datasets, thus requiring approximations in practice. The approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. We introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for NCGPs. As we demonstrate on large-scale classification problems, our method significantly accelerates posterior inference compared to competitive baselines by trading off reduced computation for increased uncertainty.},
  archive      = {J_TMLR},
  author       = {Lukas Tatzel and Jonathan Wenger and Frank Schneider and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Accelerating non-conjugate gaussian processes by trading off computation for uncertainty},
  url          = {https://openreview.net/forum?id=UdcF3JbSKb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable and robust spectral method for multi-view representation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=X6IY04Akw1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view representation learning (MvRL) has garnered substantial attention in recent years, driven by the increasing demand for applications that can effectively process and analyze data from multiple sources. In this context, graph Laplacian-based MvRL methods have demonstrated remarkable success in representing multi-view data. However, these methods often struggle with generalization to new data and face challenges with scalability. Moreover, in many practical scenarios, multi-view data is contaminated by noise or outliers. In such cases, modern deep-learning-based MvRL approaches that rely on alignment or contrastive objectives present degraded performance in downstream tasks, as they may impose incorrect consistency between clear and corrupted data sources. We introduce *SpecRaGE*, a novel fusion-based framework that integrates the strengths of graph Laplacian methods with the power of deep learning to overcome these challenges. SpecRage uses neural networks to learn parametric mapping that approximates a joint diagonalization of graph Laplacians. This solution bypasses the need for alignment while enabling generalizable and scalable learning of informative and meaningful representations. Moreover, it incorporates a meta-learning fusion module that dynamically adapts to data quality, ensuring robustness against outliers and noisy views. Our extensive experiments demonstrate that SpecRaGE outperforms state-of-the-art methods, particularly in scenarios with data contamination, paving the way for more reliable and efficient multi-view learning. Our code will be made publicly available upon acceptance.},
  archive      = {J_TMLR},
  author       = {Amitai Yacobi and Ofir Lindenbaum and Uri Shaham},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalizable and robust spectral method for multi-view representation learning},
  url          = {https://openreview.net/forum?id=X6IY04Akw1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A gold standard dataset for the reviewer assignment problem. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XofMHO5yVY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many peer-review venues are using algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the “similarity score’’ — a numerical estimate of the expertise of a reviewer in reviewing a paper — and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms currently employed in computer science conferences and come up with recommendations for stakeholders. Our four main findings are: - All algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, thereby highlighting the vital need for more research on the similarity-computation problem. - Most specialized algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter2 algorithm performs best. - The classical TF-IDF algorithm which can use full texts of papers is on par with Specter2 that uses only titles and abstracts. - The performance of off-the-shelf LLMs is worse than the specialized algorithms. We encourage researchers to participate in our survey and contribute their data to the dataset here: https://forms.gle/SP1Rh8eivGz54xR37},
  archive      = {J_TMLR},
  author       = {Ivan Stelmakh and John Frederick Wieting and Yang Xi and Graham Neubig and Nihar B Shah},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A gold standard dataset for the reviewer assignment problem},
  url          = {https://openreview.net/forum?id=XofMHO5yVY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faithful interpretation for graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Y8EspxaksH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, attention mechanisms have garnered increasing attention in Graph Neural Networks (GNNs), such as Graph Attention Networks (GATs) and Graph Transformers (GTs). This is due to not only the commendable boost in performance they offer but also their capacity to provide a more lucid rationale for model behaviors, which are often viewed as inscrutable. However, Attention-based GNNs have demonstrated instability in interpretability when subjected to various sources of perturbations during both training and testing phases, including factors like additional edges or nodes. In this paper, we propose a solution to this problem by introducing a novel notion called Faithful Graph Attention-based Interpretation (FGAI). In particular, FGAI has four crucial properties in terms of stability and sensitivity to interpretation and the final output distribution. Built upon this notion, we propose an efficient methodology for obtaining FGAI, which can be viewed as an ad hoc modification to the canonical Attention-based GNNs. To validate our proposed solution, we introduce two novel metrics tailored for graph interpretation assessment. Experimental results demonstrate that FGAI exhibits superior stability and preserves the interpretability of attention under various forms of perturbations and randomness, which makes FGAI a more faithful and reliable explanation tool.},
  archive      = {J_TMLR},
  author       = {Lijie Hu and Tianhao Huang and Lu Yu and Wanyu Lin and Tianhang Zheng and Di Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Faithful interpretation for graph neural networks},
  url          = {https://openreview.net/forum?id=Y8EspxaksH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future-aware safe active learning of time varying systems using gaussian processes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YBPbMKJbLd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental exploration of high-cost systems with safety constraints, common in engineering applications, is a challenging endeavor. Data-driven models offer a promising solution, but acquiring the requisite data remains expensive and is potentially unsafe. Safe active learning techniques prove essential, enabling the learning of high-quality models with minimal expensive data points and high safety. This paper introduces a safe active learning framework tailored for time-varying systems, addressing drift, seasonal changes, and complexities due to dynamic behavior. The proposed Time-aware Integrated Mean Squared Prediction Error (T-IMSPE) method minimizes posterior variance over current and future states, optimizing information gathering also in the time domain. Empirical results highlight T-IMSPE's advantages in model quality through synthetic and real-world examples. State of the art Gaussian processes are compatible with T-IMSPE. Our theoretical contributions include a clear delineation which Gaussian process kernels, domains, and weighting measures are suitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.},
  archive      = {J_TMLR},
  author       = {Markus Lange-Hegermann and Christoph Zimmer},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Future-aware safe active learning of time varying systems using gaussian processes},
  url          = {https://openreview.net/forum?id=YBPbMKJbLd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReDistill: Residual encoded distillation for peak memory reduction of CNNs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=akumIxQjNN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of neural network sizes and the enhanced resolution of modern image sensors result in heightened memory and power demands to process modern computer vision models. In order to deploy these models in extremely resource-constrained edge devices, it is crucial to reduce their peak memory, which is the maximum memory consumed during the execution of a model. A naive approach to reducing peak memory is aggressive down-sampling of feature maps via pooling with large stride, which often results in unacceptable degradation in network performance. To mitigate this problem, we propose residual encoded distillation (ReDistill) for peak memory reduction in a teacher-student framework, in which a student network with less memory is derived from the teacher network using aggressive pooling. We apply our distillation method to multiple problems in computer vision, including image classification and diffusion-based image generation. For image classification, our method yields 4x-5x theoretical peak memory reduction with less degradation in accuracy for most CNN-based architectures. For diffusion-based image generation, our proposed distillation method yields a denoising network with 4x lower theoretical peak memory while maintaining decent diversity and fidelity for image generation. Experiments demonstrate our method's superior performance compared to other feature-based and response-based distillation methods when applied to the same student network. The code is available at https://github.com/mengtang-lab/ReDistill.},
  archive      = {J_TMLR},
  author       = {Fang Chen and Gourav Datta and Mujahid Al Rafi and Hyeran Jeon and Meng Tang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ReDistill: Residual encoded distillation for peak memory reduction of CNNs},
  url          = {https://openreview.net/forum?id=akumIxQjNN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning from bagged reward. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bXUipBbZDA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Reinforcement Learning (RL), it is commonly assumed that an immediate reward signal is generated for each action taken by the agent, helping the agent maximize cumulative rewards to obtain the optimal policy. However, in many real-world scenarios, designing immediate reward signals is difficult; instead, agents receive a single reward that is contingent upon a partial sequence or a complete trajectory. In this work, we define this challenging problem as RL from Bagged Reward (RLBR), where sequences of data are treated as bags with non-Markovian bagged rewards, leading to the formulation of Bagged Reward Markov Decision Processes (BRMDPs). Theoretically, we demonstrate that RLBR can be addressed by solving a standard MDP with properly redistributed bagged rewards allocated to each instance within a bag. Empirically, we find that reward redistribution becomes more challenging as the bag length increases, due to reduced informational granularity. Existing reward redistribution methods are insufficient to address these challenges. Therefore, we propose a novel reward redistribution method equipped with a bidirectional attention mechanism, enabling the accurate interpretation of contextual nuances and temporal dependencies within each bag. We experimentally demonstrate that the proposed method consistently outperforms existing approaches.},
  archive      = {J_TMLR},
  author       = {Yuting Tang and Xin-Qiang Cai and Yao-Xiang Ding and Qiyu Wu and Guoqing Liu and Masashi Sugiyama},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning from bagged reward},
  url          = {https://openreview.net/forum?id=bXUipBbZDA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Covariate-dependent graphical model estimation via neural networks with statistical guarantees. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=beqSqPgE33'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphical models are widely used in diverse application domains to model the conditional dependencies amongst a collection of random variables. In this paper, we consider settings where the graph structure is covariate-dependent, and investigate a deep neural network-based approach to estimate it. The method allows for flexible functional dependency on the covariate, and fits the data reasonably well in the absence of a Gaussianity assumption. Theoretical results with PAC guarantees are established for the method, under assumptions commonly used in an Empirical Risk Minimization framework. The performance of the proposed method is evaluated on several synthetic data settings and benchmarked against existing approaches. The method is further illustrated on real datasets involving data from neuroscience and finance, respectively, and produces interpretable results.},
  archive      = {J_TMLR},
  author       = {Jiahe Lin and Yikai Zhang and George Michailidis},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Covariate-dependent graphical model estimation via neural networks with statistical guarantees},
  url          = {https://openreview.net/forum?id=beqSqPgE33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDM-TTS: Efficient dual-stage masked modeling for alignment-free text-to-speech synthesis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=c7vkDg558Z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tokenized speech modeling has significantly advanced zero-shot text-to-speech (TTS) capabilities. The most de facto approach involves a dual-stage process: text-to-semantic (T2S) followed by semantic-to-acoustic (S2A) generation. Several auto-regressive (AR) and non-autoregressive (NAR) methods have been explored in literature for both the stages. While AR models achieve state-of-the-art performance, its token-by-token generation causes inference inefficiencies, while NAR methods while being more efficient, require explicit alignment for upsampling intermediate representations, which constrains the model's capability for more natural prosody. To overcome these issues, we propose an **E**fficient **D**ual-stage **M**asked **TTS** (EDM-TTS) model that employs an alignment-free masked generative approach for the T2S stage that overcomes the constrains of an explicit aligner, while retaining the efficiency of NAR methods. For the S2A stage, we introduce an innovative NAR approach using a novel Injection Conformer architecture, that effectively models the conditional dependence among different acoustic quantization levels, optimized by a masked language modeling objective, enabling zero-shot speech generation. Our evaluations demonstrated not only the superior inference efficiency of EDM-TTS, but also its state-of-the-art high-quality zero-shot speech quality, naturalness and speaker similarity.},
  archive      = {J_TMLR},
  author       = {Nabarun Goswami and Hanqin Wang and Tatsuya Harada},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {EDM-TTS: Efficient dual-stage masked modeling for alignment-free text-to-speech synthesis},
  url          = {https://openreview.net/forum?id=c7vkDg558Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MemLLM: Finetuning LLMs to use explicit read-write memory. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dghM7sOudh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While current large language models (LLMs) perform well on many knowledge-related tasks, they are limited by relying on their parameters as an implicit storage mechanism. As a result, they struggle with memorizing rare events and with updating their memory as facts change over time. In addition, the uninterpretable nature of parametric memory makes it challenging to prevent hallucination. Model editing and augmenting LLMs with parameters specialized for memory are only partial solutions. In this paper, we introduce MemLLM, a novel method of enhancing LLMs by integrating a structured and explicit read-and-write memory module. MemLLM tackles the aforementioned challenges by enabling dynamic interaction with the memory and improving the LLM's capabilities in using stored knowledge. Our experiments indicate that MemLLM enhances the LLM's performance and interpretability, in language modeling in general and knowledge-intensive tasks in particular. We see MemLLM as an important step towards making LLMs more grounded and factual through memory augmentation. The project repository is publicly available at: https://github.com/amodaresi/MemLLM},
  archive      = {J_TMLR},
  author       = {Ali Modarressi and Abdullatif Köksal and Ayyoob Imani and Mohsen Fayyaz and Hinrich Schuetze},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MemLLM: Finetuning LLMs to use explicit read-write memory},
  url          = {https://openreview.net/forum?id=dghM7sOudh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex relaxation for solving large-margin classifiers in hyperbolic space. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eIPwJgadfZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperbolic spaces have increasingly been recognized for their outstanding performance in handling data with inherent hierarchical structures compared to their Euclidean counterparts. However, learning in hyperbolic spaces poses significant challenges. In particular, extending support vector machines to hyperbolic spaces is in general a constrained non-convex optimization problem. Previous and popular attempts to solve hyperbolic SVMs, primarily using projected gradient descent, are generally sensitive to hyperparameters and initializations, often leading to suboptimal solutions. In this work, by first rewriting the problem into a polynomial optimization, we apply semidefinite relaxation and sparse moment-sum-of-squares relaxation to effectively approximate the optima. From extensive empirical experiments, these methods are shown to achieve better classification accuracies than the projected gradient descent approach in most of the synthetic and real two-dimensional hyperbolic embedding dataset under the one-vs-rest multiclass-classification scheme.},
  archive      = {J_TMLR},
  author       = {Sheng Yang and Peihan Liu and Cengiz Pehlevan},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convex relaxation for solving large-margin classifiers in hyperbolic space},
  url          = {https://openreview.net/forum?id=eIPwJgadfZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian pre-activations in neural networks: Myth or reality?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=goe6fv6iSh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of feature propagation at initialization in neural networks lies at the root of numerous initialization designs. A very common assumption is that the pre-activations are Gaussian. Although this convenient *Gaussian hypothesis* can be justified when the number of neurons per layer tends to infinity, it is challenged by both theoretical and experimental work for finite-width neural networks. Our main contribution is to construct a family of pairs of activation functions and initialization distributions that ensure that the pre-activations remain Gaussian throughout the network depth, even in narrow neural networks, under the assumption that the pre-activations are independent. In the process, we discover a set of constraints that a neural network should satisfy to ensure Gaussian pre-activations. In addition, we provide a critical review of the claims of the Edge of Chaos line of work and construct a non-asymptotic Edge of Chaos analysis. We also propose a unified view on the propagation of pre-activations, encompassing the framework of several well-known initialization procedures. More generally, our work provides a principled framework for addressing the much-debated question: is it desirable to initialize the training of a neural network whose pre-activations are guaranteed to be Gaussian? Our code is available on GitHub: https://github.com/p-wol/gaussian-preact/ .},
  archive      = {J_TMLR},
  author       = {Pierre Wolinski and Julyan Arbel},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Gaussian pre-activations in neural networks: Myth or reality?},
  url          = {https://openreview.net/forum?id=goe6fv6iSh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample, estimate, aggregate: A recipe for causal discovery foundation models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=h434zx5SX0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery, the task of inferring causal structure from data, has the potential to uncover mechanistic insights from biological experiments, especially those involving perturbations. However, causal discovery algorithms over larger sets of variables tend to be brittle against misspecification or when data are limited. For example, single-cell transcriptomics measures thousands of genes, but the nature of their relationships is not known, and there may be as few as tens of cells per intervention setting. To mitigate these challenges, we propose a foundation model-inspired approach: a supervised model trained on large-scale, synthetic data to predict causal graphs from summary statistics — like the outputs of classical causal discovery algorithms run over subsets of variables and other statistical hints like inverse covariance. Our approach is enabled by the observation that typical errors in the outputs of a discovery algorithm remain comparable across datasets. Theoretically, we show that the model architecture is well-specified, in the sense that it can recover a causal graph consistent with graphs over subsets. Empirically, we train the model to be robust to misspecification and distribution shift using diverse datasets. Experiments on biological and synthetic data confirm that this model generalizes well beyond its training set, runs on graphs with hundreds of variables in seconds, and can be easily adapted to different underlying data assumptions.},
  archive      = {J_TMLR},
  author       = {Menghua Wu and Yujia Bao and Regina Barzilay and Tommi Jaakkola},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sample, estimate, aggregate: A recipe for causal discovery foundation models},
  url          = {https://openreview.net/forum?id=h434zx5SX0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reward distance comparisons under transition sparsity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=haP586YomL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reward comparisons are vital for evaluating differences in agent behaviors induced by a set of reward functions. Most conventional techniques utilize the input reward functions to learn optimized policies, which are then used to compare agent behaviors. However, learning these policies can be computationally expensive and can also raise safety concerns. Direct reward comparison techniques obviate policy learning but suffer from transition sparsity, where only a small subset of transitions are sampled due to data collection challenges and feasibility constraints. Existing state-of-the-art direct reward comparison methods are ill-suited for these sparse conditions since they require high transition coverage, where the majority of transitions from a given coverage distribution are sampled. When this requirement is not satisfied, a distribution mismatch between sampled and expected transitions can occur, leading to significant errors. This paper introduces the Sparsity Resilient Reward Distance (SRRD) pseudometric, designed to eliminate the need for high transition coverage by accommodating diverse sample distributions, which are common under transition sparsity. We provide theoretical justification for SRRD's robustness and conduct experiments to demonstrate its practical efficacy across multiple domains.},
  archive      = {J_TMLR},
  author       = {Clement Nyanhongo and Bruno Miranda Henrique and Eugene Santos},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reward distance comparisons under transition sparsity},
  url          = {https://openreview.net/forum?id=haP586YomL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperparameters in continual learning: A reality check. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hiiRCXmbAz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning (CL) aims to train a model on a sequence of tasks (i.e., a CL scenario) while balancing the trade-off between plasticity (learning new tasks) and stability (retaining prior knowledge). The dominantly adopted conventional evaluation protocol for CL algorithms selects the best hyperparameters (e.g., learning rate, mini-batch size, regularization strengths, etc.) within a given scenario and then evaluates the algorithms using these hyperparameters in the same scenario. However, this protocol has significant shortcomings: it overestimates the CL capacity of algorithms and relies on unrealistic hyperparameter tuning, which is not feasible for real-world applications. From the fundamental principles of evaluation in machine learning, we argue that the evaluation of CL algorithms should focus on assessing the generalizability of their CL capacity to unseen scenarios. Based on this, we propose the Generalizable Two-phase Evaluation Protocol (GTEP) consisting of hyperparameter tuning and evaluation phases. Both phases share the same scenario configuration (e.g., number of tasks) but are generated from different datasets. Hyperparameters of CL algorithms are tuned in the first phase and applied in the second phase to evaluate the algorithms. We apply this protocol to class-incremental learning, both with and without pretrained models. Across more than 8,000 experiments, our results show that most state-of-the-art algorithms fail to replicate their reported performance, highlighting that their CL capacity has been significantly overestimated in the conventional evaluation protocol.},
  archive      = {J_TMLR},
  author       = {Sungmin Cha and Kyunghyun Cho},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hyperparameters in continual learning: A reality check},
  url          = {https://openreview.net/forum?id=hiiRCXmbAz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep koopman learning using noisy data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=j6Rm6T2lFU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a data-driven framework to learn a finite-dimensional approximation of a Koopman operator for approximating the state evolution of a dynamical system under noisy observations. To this end, our proposed solution has two main advantages. First, the proposed method only requires the measurement noise to be bounded. Second, the proposed method modifies the existing deep Koopman operator formulations by characterizing the effect of the measurement noise on the Koopman operator learning and then mitigating it by updating the tunable parameter of the observable functions of the Koopman operator, making it easy to implement. The performance of the proposed method is demonstrated on several standard benchmarks. We then compare the presented method with similar methods proposed in the latest literature on Koopman learning.},
  archive      = {J_TMLR},
  author       = {Wenjian Hao and Devesh Upadhyay and Shaoshuai Mou},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep koopman learning using noisy data},
  url          = {https://openreview.net/forum?id=j6Rm6T2lFU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-guided self-supervised tabular learning with task-specific pre-text tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jXcx2oAIbw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most common approaches for self-supervised representation learning is defining pre-text tasks to learn data representations. Existing works determine pre-text tasks in a "task-agnostic'' way, without considering the forthcoming downstream tasks. This offers an advantage of broad applicability across tasks, but can also lead to a mismatch between task objectives, potentially degrading performance on downstream tasks. In this paper, we introduce TST-LLM, a framework that effectively reduces this mismatch when the natural language-based description of the downstream task is given without any ground-truth labels. TST-LLM instructs the LLM to use the downstream task's description and meta-information of data to discover features relevant to the target task. These discovered features are then treated as ground-truth labels to define "target-specific'' pre-text tasks. TST-LLM consistently outperforms contemporary baselines, such as STUNT and LFR, with win ratios of 95% and 81%, when applied to 22 benchmark tabular datasets, including binary and multi-class classification, and regression tasks.},
  archive      = {J_TMLR},
  author       = {Sungwon Han and Seungeon Lee and Meeyoung Cha and Sercan O Arik and Jinsung Yoon},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLM-guided self-supervised tabular learning with task-specific pre-text tasks},
  url          = {https://openreview.net/forum?id=jXcx2oAIbw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jet: A modern transformer-based normalizing flow. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jdvnaki7ZY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation, and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve a much simpler architecture that matches existing normalizing flow models and improves over them when paired with pretraining. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing the research frontier by serving as building components of more powerful generative models.},
  archive      = {J_TMLR},
  author       = {Alexander Kolesnikov and André Susano Pinto and Michael Tschannen},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Jet: A modern transformer-based normalizing flow},
  url          = {https://openreview.net/forum?id=jdvnaki7ZY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Oblique bayesian additive regression trees. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=l4Qnj4tHBx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current implementations of Bayesian Additive Regression Trees (BART) are based on axis-aligned decision rules that recursively partition the feature space using a single feature at a time. Several authors have demonstrated that oblique trees, whose decision rules are based on linear combinations of features, can sometimes yield better predictions than axis-aligned trees and exhibit excellent theoretical properties. We develop an oblique version of BART that leverages a data-adaptive decision rule prior that recursively partitions the feature space along random hyperplanes. Using several synthetic and real-world benchmark datasets, we systematically compared our oblique BART implementation to axis-aligned BART and other tree ensemble methods, finding that oblique BART was competitive with --- and sometimes much better than --- those methods.},
  archive      = {J_TMLR},
  author       = {Paul-Hieu V. Nguyen and Ryan Yee and Sameer Deshpande},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Oblique bayesian additive regression trees},
  url          = {https://openreview.net/forum?id=l4Qnj4tHBx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy awareness for information-sharing assistants: A case-study on form-filling with contextual integrity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=l9rATNBB8Y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize the design of privacy-conscious assistants that conform with *contextual integrity* (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of human annotations of common webform applications, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields strong results.},
  archive      = {J_TMLR},
  author       = {Sahra Ghalebikesabi and Eugene Bagdasarian and Ren Yi and Itay Yona and Ilia Shumailov and Aneesh Pappu and Chongyang Shi and Laura Weidinger and Robert Stanforth and Leonard Berrada and Pushmeet Kohli and Po-Sen Huang and Borja Balle},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Privacy awareness for information-sharing assistants: A case-study on form-filling with contextual integrity},
  url          = {https://openreview.net/forum?id=l9rATNBB8Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SmoothLLM: Defending large language models against jailbreaking attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=laPAh2hRFC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite efforts to align large language models (LLMs) with human intentions, widely-used LLMs such as GPT, Llama, and Claude are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, an algorithm designed to mitigate jailbreaking attacks. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. Across a range of popular LLMs, SmoothLLM offers improved robustness against the GCG, PAIR, RandomSearch, and AmpleGCG jailbreaks. SmoothLLM is also resistant against adaptive GCG attacks, exhibits a small, though non-negligible trade-off between robustness and nominal performance, and is compatible with any LLM.},
  archive      = {J_TMLR},
  author       = {Alexander Robey and Eric Wong and Hamed Hassani and George J. Pappas},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SmoothLLM: Defending large language models against jailbreaking attacks},
  url          = {https://openreview.net/forum?id=laPAh2hRFC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random policy enables in-context reinforcement learning within trust horizons. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mAiMKnr9r5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained foundation models (FMs) have exhibited extraordinary in-context learning performance, allowing zero-shot (or few-shot) generalization to new environments/tasks not encountered during the pretraining. In the case of reinforcement learning (RL), in-context RL (ICRL) emerges when pretraining FMs on decision-making problems in an autoregressive-supervised manner. Nevertheless, the current state-of-the-art ICRL algorithms, such as Algorithm Distillation, Decision Pretrained Transformer and Decision Importance Transformer, impose stringent requirements on the pretraining dataset concerning the behavior (source) policies, context information, and action labels, etc. Notably, these algorithms either demand optimal policies or require varying degrees of well-trained behavior policies for all pretraining environments. This significantly hinders the application of ICRL to real-world scenarios, where acquiring optimal or well-trained policies for a substantial volume of real-world training environments can be prohibitively expensive or even intractable. To overcome this challenge, we introduce a novel approach, termed State-Action Distillation (SAD), that allows to generate an effective pretraining dataset guided solely by random policies. In particular, SAD selects query states and corresponding action labels by distilling the outstanding state-action pairs from the entire state and action spaces by using random policies within a trust horizon, and then inherits the classical autoregressive-supervised mechanism during the pretraining. To the best of our knowledge, this is the first work that enables effective ICRL under (e.g., uniform) random policies and random contexts. We also establish the quantitative analysis of the trustworthiness as well as the performance guarantees of our SAD approach. Moreover, our empirical results across multiple popular ICRL benchmark environments demonstrate that, on average, SAD outperforms the best baseline by 236.3% in the offline evaluation and by 135.2% in the online evaluation.},
  archive      = {J_TMLR},
  author       = {Weiqin Chen and Santiago Paternain},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Random policy enables in-context reinforcement learning within trust horizons},
  url          = {https://openreview.net/forum?id=mAiMKnr9r5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE3Set: Harnessing equivariant hypergraph neural networks for molecular representation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=muWEt1TOyo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural network architecture tailored for advanced molecular representation learning. Hypergraphs are not merely an extension of traditional graphs; they are pivotal for modeling high-order relationships, a capability that conventional equivariant graph-based methods lack due to their inherent limitations in representing intricate many-body interactions. To achieve this, we first construct hypergraphs by proposing a new fragmentation method that considers both chemical and three-dimensional spatial information of the molecular system. We then design SE3Set, which incorporates equivariance into the hypergraph neural network. This ensures that the learned molecular representations are invariant to spatial transformations, thereby providing robustness essential for the accurate prediction of molecular properties. SE3Set has shown performance on par with state-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17. It demonstrates outstanding performance on the MD22 dataset, achieving a remarkable ~20\% improvement in accuracy across all molecules. Furthermore, on the OE62 dataset, SE3Set outperforms all short-range models. We also conducted a detailed analysis of OE62, highlighting the prevalence of complex many-body interactions in large molecules. This exceptional performance of SE3Set across diverse molecular structures underscores its transformative potential in computational chemistry, offering a route to more accurate and physically nuanced modeling. The code of this work is available at https://github.com/Navantock/SE3Set.},
  archive      = {J_TMLR},
  author       = {Hongfei Wu and Lijun Wu and Guoqing Liu and Zhirong Liu and Bin Shao and Zun Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SE3Set: Harnessing equivariant hypergraph neural networks for molecular representation learning},
  url          = {https://openreview.net/forum?id=muWEt1TOyo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimension reduction via score ratio matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mvbZBaqSXo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling.},
  archive      = {J_TMLR},
  author       = {Ricardo Baptista and Michael Brennan and Youssef Marzouk},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dimension reduction via score ratio matching},
  url          = {https://openreview.net/forum?id=mvbZBaqSXo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Amphibian: A meta-learning framework for rehearsal-free, fast online continual learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=n4AaKOBWbB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online continual learning is challenging as it requires fast adaptation over a stream of data in a non-stationary environment without forgetting the knowledge acquired in the past. To address this challenge, in this paper, we introduce Amphibian - a gradient-based meta-learner that learns to scale the direction of gradient descent to achieve the desired balance between fast learning and continual learning. For this purpose, using only the current batch of data, Amphibian minimizes a meta-objective that encourages alignments of gradients among given data samples along selected basis directions in the gradient space. From this objective, it learns a diagonal scale matrix in each layer that accumulates the history of such gradient alignments. Using these scale matrices Amphibian updates the model online only in the directions having positive cumulative gradient alignments among the data observed so far. With evaluation on standard continual image classification benchmarks, we show that such meta-learned scaled gradient descent in Amphibian achieves better accuracy in online continual learning than relevant baselines while enabling fast learning with less data and few-shot knowledge transfer to new tasks. We also introduce Amphibian-$\beta$ a unified and principled framework for analyzing and understanding the fast learning and continual learning dynamics. Additionally, with loss landscape visualizations, we show such gradient updates incur minimum loss to the old task enabling fast continual learning in Amphibian.},
  archive      = {J_TMLR},
  author       = {Gobinda Saha and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Amphibian: A meta-learning framework for rehearsal-free, fast online continual learning},
  url          = {https://openreview.net/forum?id=n4AaKOBWbB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating learned image compression through modeling neural training dynamics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nannw4SGfS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As learned image compression (LIC) methods become increasingly computationally demanding, enhancing their training efficiency is crucial. This paper takes a step forward in accelerating the training of LIC methods by modeling the neural training dynamics. We first propose a Sensitivity-aware True and Dummy Embedding Training mechanism (STDET) that clusters LIC model parameters into few separate modes where parameters are expressed as affine transformations of reference parameters within the same mode. By further utilizing the stable intra-mode correlations throughout training and parameter sensitivities, we gradually embed non-reference parameters, reducing the number of trainable parameters. Additionally, we incorporate a Sampling-then-Moving Average (SMA) technique, interpolating sampled weights from stochastic gradient descent (SGD) training to obtain the moving average weights, ensuring smooth temporal behavior and minimizing training state variances. Overall, our method significantly reduces training space dimensions and the number of trainable parameters without sacrificing model performance, thus accelerating model convergence. We also provide a theoretical analysis on the Noisy quadratic model, showing that the proposed method achieves a lower training variance than standard SGD. Our approach offers valuable insights for further developing efficient training methods for LICs.},
  archive      = {J_TMLR},
  author       = {Yichi Zhang and Zhihao Duan and Yuning Huang and Fengqing Zhu},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Accelerating learned image compression through modeling neural training dynamics},
  url          = {https://openreview.net/forum?id=nannw4SGfS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A functional framework for nonsmooth autodiff with {\it maxpooling} functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qahoztvThX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We make a comment on the recent work by Boustany, by showing that the Murat-TrombettiTheorem provides a simple and efficient mathematical framework for nonsmooth automatic differentiation of {\it maxpooling} functions. In particular it gives a the chain rule formula which correctly defines the composition of Lipschitz-continuous functions which are piecewise $C^1$. The formalism is applied to four basic examples, with some tests in PyTorch. A self contained proof of an important Stampacchia formula is in the appendix.},
  archive      = {J_TMLR},
  author       = {Bruno Després},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A functional framework for nonsmooth autodiff with {\it maxpooling} functions},
  url          = {https://openreview.net/forum?id=qahoztvThX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient decoding of visual stimuli from fMRI through inter-individual functional alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qvJraN50DT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is leading to major advances in the realm of brain decoding from functional Magnetic Resonance Imaging (fMRI). However, the large inter-individual variability in brain characteristics has constrained most studies to train models on one participant at a time. This limitation hampers the training of deep learning models, which typically requires very large datasets. Here, we propose to boost brain decoding of videos and static images across participants by aligning brain responses of training and left-out participants. Evaluated on a retrieval task, compared to the anatomically-aligned baseline, our method halves the median rank in out-of-subject setups. It also outperforms classical within-subject approaches when fewer than 100 minutes of data is available for the tested participant. Furthermore, we show that our alignment framework handles multiple subjects, which improves accuracy upon classical single-subject approaches. Finally, we show that this method aligns neural representations in accordance with brain anatomy. Overall, this study lays the foundations for leveraging extensive neuroimaging datasets and enhancing the decoding of individual brains when a limited amount of brain-imaging data is available.},
  archive      = {J_TMLR},
  author       = {Alexis Thual and Yohann Benchetrit and Felix Geilert and Jérémy Rapin and Iurii Makarov and Stanislas Dehaene and Bertrand Thirion and Hubert Banville and Jean-Remi King},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sample-efficient decoding of visual stimuli from fMRI through inter-individual functional alignment},
  url          = {https://openreview.net/forum?id=qvJraN50DT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for causal discovery without acyclicity constraints. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sNzBi8rZTy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, reinforcement learning (RL) has proved a promising alternative for conventional local heuristics in score-based approaches to learning directed acyclic causal graphs (DAGs) from observational data. However, the intricate acyclicity constraint still challenges the efficient exploration of the vast space of DAGs in existing methods. In this study, we introduce ALIAS (reinforced dAg Learning wIthout Acyclicity conStraints), a novel approach to causal discovery powered by the RL machinery. Our method features an efficient policy for generating DAGs in just a single step with an optimal quadratic complexity, fueled by a novel parametrization of DAGs that directly translates a continuous space to the space of all DAGs, bypassing the need for explicitly enforcing acyclicity constraints. This approach enables us to navigate the search space more effectively by utilizing policy gradient methods and established scoring functions. In addition, we provide compelling empirical evidence for the strong performance of ALIAS in comparison with state-of-the-arts in causal discovery over increasingly difficult experiment conditions on both synthetic and real datasets. Our implementation is provided at https://github.com/baosws/ALIAS.},
  archive      = {J_TMLR},
  author       = {Bao Duong and Hung Le and Biwei Huang and Thin Nguyen},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning for causal discovery without acyclicity constraints},
  url          = {https://openreview.net/forum?id=sNzBi8rZTy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operationalizing a threat model for red-teaming large language models (LLMs). <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sSAp8ITBpC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating secure and resilient applications with large language models (LLM) requires anticipating, adjusting to, and countering unforeseen threats. Red-teaming has emerged as a critical technique for identifying vulnerabilities in real-world LLM implementations. This paper presents a detailed threat model and provides a systematization of knowledge (SoK) of red-teaming attacks on LLMs. We develop a taxonomy of attacks based on the stages of the LLM development and deployment process and extract various insights from previous research. In addition, we compile methods for defense and practical red-teaming strategies for practitioners. By delineating prominent attack motifs and shedding light on various entry points, this paper provides a framework for improving the security and robustness of LLM-based systems.},
  archive      = {J_TMLR},
  author       = {Apurv Verma and Satyapriya Krishna and Sebastian Gehrmann and Madhavan Seshadri and Anu Pradhan and John A. Doucette and David Rabinowitz and Leslie Barrett and Tom Ault and Hai Phan},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Operationalizing a threat model for red-teaming large language models (LLMs)},
  url          = {https://openreview.net/forum?id=sSAp8ITBpC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Piecewise constant spectral graph neural network. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sTdVnDW0HX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved significant success across various domains by leveraging graph structures in data. Existing spectral GNNs, which use low-degree polynomial filters to capture graph spectral properties, may not fully identify the graph's spectral characteristics because of the polynomial's small degree. However, increasing the polynomial degree is computationally expensive and beyond certain thresholds leads to performance plateaus or degradation. In this paper, we introduce the Piecewise Constant Spectral Graph Neural Network(PieCoN) to address these challenges. PieCoN combines constant spectral filters with polynomial filters to provide a more flexible way to leverage the graph structure. By adaptively partitioning the spectrum into intervals, our approach increases the range of spectral properties that can be effectively learned. Experiments on nine benchmark datasets, including both homophilic and heterophilic graphs, demonstrate that PieCoN is particularly effective on heterophilic datasets, highlighting its potential for a wide range of applications.},
  archive      = {J_TMLR},
  author       = {Vahan Martirosyan and Jhony H. Giraldo and Fragkiskos D. Malliaros},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Piecewise constant spectral graph neural network},
  url          = {https://openreview.net/forum?id=sTdVnDW0HX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When resampling/reweighting improves feature learning in imbalanced classification? a toy-model study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=spqbyeGyLR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A toy model of binary classification is studied with the aim of clarifying the class-wise resampling/reweighting effect on the feature learning performance under the presence of class imbalance. In the analysis, a high-dimensional limit of the input space is taken while keeping the ratio of the dataset size against the input dimension finite and the non-rigorous replica method from statistical mechanics is employed. The result shows that there exists a case in which the no resampling/reweighting situation gives the best feature learning performance irrespectively of the choice of losses or classifiers, supporting recent findings in~\citet{kang2019decoupling,cao2019learning}. It is also revealed that the key of the result is the symmetry of the loss and the problem setting. Inspired by this, we propose a further simplified model exhibiting the same property in the multiclass setting. These clarify when the class-wise resampling/reweighting becomes effective in imbalanced classification.},
  archive      = {J_TMLR},
  author       = {Tomoyuki Obuchi and Toshiyuki Tanaka},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When resampling/reweighting improves feature learning in imbalanced classification? a toy-model study},
  url          = {https://openreview.net/forum?id=spqbyeGyLR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on model MoErging: Recycling and routing among specialized experts for collaborative learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=u0azVc9Y0y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of performant pre-trained models has led to a proliferation of fine-tuned expert models that are specialized to a particular domain or task. Model MoErging methods aim to recycle expert models to create an aggregate system with improved performance or generalization. A key component of MoErging methods is the creation of a router that decides which expert model(s) to use for a particular input or application. The promise, effectiveness, and large design space of MoErging has spurred the development of many new methods over the past few years. This rapid pace of development has made it challenging to compare different MoErging methods, which are rarely compared to one another and are often validated in different experimental setups. To remedy such gaps, we present a comprehensive survey of MoErging methods that includes a novel taxonomy for cataloging key design choices and clarifying suitable applications for each method. Apart from surveying MoErging research, we inventory software tools and applications that make use of MoErging. We additionally discuss related fields of study such as model merging, multitask learning, and mixture-of-experts models. Taken as a whole, our survey provides a unified overview of existing MoErging methods and creates a solid foundation for future work in this burgeoning field.},
  archive      = {J_TMLR},
  author       = {Prateek Yadav and Colin Raffel and Mohammed Muqeeth and Lucas Caccia and Haokun Liu and Tianlong Chen and Mohit Bansal and Leshem Choshen and Alessandro Sordoni},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on model MoErging: Recycling and routing among specialized experts for collaborative learning},
  url          = {https://openreview.net/forum?id=u0azVc9Y0y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ∇QDARTS: Quantization as an elastic dimension to differentiable NAS. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ubrOSWyTS8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable Neural Architecture Search methods efficiently find high-accuracy architectures using gradient-based optimization in a continuous domain, saving computational resources. Mixed-precision search helps optimize precision within a fixed architecture. However, applying it to a NAS-generated network does not assure optimal performance as the optimized quantized architecture may not emerge from a standalone NAS method. In light of these considerations, this paper introduces ∇QDARTS, a novel approach that combines differentiable NAS with mixed-precision search for both weight and activation. ∇QDARTS aims to identify the optimal mixed-precision neural architecture capable of achieving remarkable accuracy while operating with minimal computational requirements in a single-shot, end-to-end differentiable framework, obviating the need for pretraining and proxy methods. Compared to fp32, ∇QDARTS shows impressive performance on CIFAR10 with (2,4) bit precision, reducing bit operations by 160× with a slight 1.57% accuracy drop. Increasing the capacity enables ∇QDARTS to match fp32 accuracy while reducing bit operations by 18×. For the ImageNet dataset, with just (2,4) bit precision, ∇QDARTS outperforms state-of-the-art methods such as APQ, SPOS, OQA, and MNAS by 2.3%, 2.9%, 0.3%, and 2.7% in terms of accuracy. By incorporating (2,4,8) bit precision, ∇QDARTS further minimizes the accuracy drop to 1% compared to fp32, alongside a substantial reduction of 17× in required bit operations and 2.6× in memory footprint. In terms of bit-operation (memory footprint) ∇QDARTS excels over APQ, SPOS, OQA, and MNAS with similar accuracy by 2.3× (12×), 2.4× (3×), 13% (6.2×), 3.4× (37%), for bit-operation (memory footprint), respectively. ∇QDARTS enhances the overall search and training efficiency, achieving a 3.1× and 1.54× improvement over APQ and OQA, respectively.},
  archive      = {J_TMLR},
  author       = {Payman Behnam and Uday Kamal and Sanjana Vijay Ganesh and Zhaoyi Li and Michael Andrew Jurado and Alind Khare and Igor Fedorov and Gaowen Liu and Alexey Tumanov},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {∇QDARTS: Quantization as an elastic dimension to differentiable NAS},
  url          = {https://openreview.net/forum?id=ubrOSWyTS8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-TS integrator: Integrating LLM for enhanced time series modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vPVqQmjCy8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series~(TS) modeling is essential in dynamic systems like weather prediction and anomaly detection. Recent studies utilize Large Language Models (LLMs) for TS modeling, leveraging their powerful pattern recognition capabilities. These methods primarily position LLMs as the predictive backbone, often omitting the mathematical modeling within traditional TS models, such as periodicity. However, disregarding the potential of LLMs also overlooks their pattern recognition capabilities. To address this gap, we introduce \textit{LLM-TS Integrator}, a novel framework that effectively integrates the capabilities of LLMs into traditional TS modeling. Central to this integration is our \textit{mutual information} module. The core of this \textit{mutual information} module is a traditional TS model enhanced with LLM-derived insights for improved predictive abilities. This enhancement is achieved by maximizing the mutual information between traditional model's TS representations and LLM's textual representation counterparts, bridging the two modalities. Moreover, we recognize that samples vary in importance for two losses: traditional prediction and mutual information maximization. To address this variability, we introduce the \textit{sample reweighting} module to improve information utilization. This module assigns dual weights to each sample: one for prediction loss and another for mutual information loss, dynamically optimizing these weights via bi-level optimization. Our method achieves state-of-the-art or comparable performance across five mainstream TS tasks, including short-term and long-term forecasting, imputation, classification, and anomaly detection. Our code is available at: \url{https://anonymous.4open.science/r/llm_ts_anonymous-F07D/README.MD}},
  archive      = {J_TMLR},
  author       = {Can Chen and Gabriel L. Oliveira and Hossein Sharifi-Noghabi and Tristan Sylvain},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLM-TS integrator: Integrating LLM for enhanced time series modeling},
  url          = {https://openreview.net/forum?id=vPVqQmjCy8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relative phase equivariant deep neural systems for physical layer communications. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vttqWoSJIW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of telecommunications, the increasing demand for complex and specialized communication systems has led to a focus on improving physical layer communications. Artificial intelligence (AI) has emerged as a promising solution avenue for doing so. Deep neural receivers have already shown significant promise in improving the performance of communications systems. However, a major challenge lies in developing deep neural receivers that match the energy efficiency and speed of traditional receivers. This work investigates the incorporation of inductive biases in the physical layer using group-equivariant deep learning to improve the parameter efficiency of deep neural receivers. We do so by constructing a deep neural receiver that is equivariant with respect to the phase of arrival. We show that the inclusion of relative phase equivariance significantly reduces the error rate of deep neural receivers at similar model sizes. Thus, we show the potential of group-equivariant deep learning in the domain of physical layer communications.},
  archive      = {J_TMLR},
  author       = {Arwin Gansekoele and Sandjai Bhulai and Mark Hoogendoorn and Rob van der Mei},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relative phase equivariant deep neural systems for physical layer communications},
  url          = {https://openreview.net/forum?id=vttqWoSJIW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive physics-informed neural networks: A survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vz5P1Kbt6t'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have emerged as a promising approach for solving partial differential equations (PDEs) using neural networks, particularly in data-scarce scenarios due to their unsupervised training capability. However, a key limitation is the need for re-optimization with each change in PDE parameters, similar to the challenge in traditional numerical methods where each system of equations corresponds to a specific PDE instance. This characteristic poses a barrier to the widespread adoption of PINNs across scientific and engineering applications. This survey explores research addressing this limitation through transfer learning and meta-learning, synthesizing insights to establish a foundation for efficient data generation strategies tailored to PINNs. These methods can potentially improve PINNs’ training efficiency, enabling quicker adaptation to new PDEs with fewer data and computational demands. While numerical methods directly solve systems of equations to derive solutions, neural networks implicitly learn solutions by adjusting their parameters. One notable advantage of neural networks lies in their capacity to abstract away from specific problem domains, enabling them to retain, discard, or adapt learned representations to efficiently address similar problems. By understanding how these techniques can be applied to PINNs, this survey seeks to identify promising directions for future research to enable the widespread adoption of PINNs across a wide range of scientific and engineering applications.},
  archive      = {J_TMLR},
  author       = {Edgar Torres and Mathias Niepert},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive physics-informed neural networks: A survey},
  url          = {https://openreview.net/forum?id=vz5P1Kbt6t},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connecting parameter magnitudes and hessian eigenspaces at scale using sketched methods. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yGGoOVpBVP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been observed that when training a deep neural net with SGD, the majority of the loss landscape's curvature quickly concentrates in a tiny *top* eigenspace of the loss Hessian, which remains largely stable thereafter. Independently, it has been shown that successful magnitude pruning masks for deep neural nets emerge early in training and remain stable thereafter. In this work, we study these two phenomena jointly and show that they are connected: We develop a methodology to measure the similarity between arbitrary parameter masks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap* as the most useful such metric due to its interpretability and stability. To compute *overlap*, we develop a matrix-free algorithm based on sketched SVDs that allows us to compute over 1000 Hessian eigenpairs for nets with over 10M parameters --an unprecedented scale by several orders of magnitude. Our experiments reveal an *overlap* between magnitude parameter masks and top Hessian eigenspaces consistently higher than chance-level, and that this effect gets accentuated for larger network sizes. This result indicates that *top Hessian eigenvectors tend to be concentrated around larger parameters*, or equivalently, that *larger parameters tend to align with directions of larger loss curvature*. Our work provides a methodology to approximate and analyze deep learning Hessians at scale, as well as a novel insight on the structure of their eigenspace},
  archive      = {J_TMLR},
  author       = {Andres Fernandez and Frank Schneider and Maren Mahsereci and Philipp Hennig},
  journal      = {Transactions on Machine Learning Research},
  month        = {4},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Connecting parameter magnitudes and hessian eigenspaces at scale using sketched methods},
  url          = {https://openreview.net/forum?id=yGGoOVpBVP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KAGNNs: Kolmogorov-arnold networks meet graph learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=03UB1MCAMr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message-passing) layers, within which the representation of each node is updated based on those of its neighbors. The most expressive message-passing GNNs can be obtained through the use of the sum aggregator and of MLPs for feature transformation, thanks to their universal approximation capabilities. However, the limitations of MLPs recently motivated the introduction of another family of universal approximators, called Kolmogorov-Arnold Networks (KANs) which rely on a different representation theorem. In this work, we compare the performance of KANs against that of MLPs on graph learning tasks. We implement three new KAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We evaluate two different implementations of KANs using two distinct base families of functions, namely B-splines and radial basis functions. We perform extensive experiments on node classification, link prediction, graph classification and graph regression datasets. Our results indicate that KANs are on-par with or better than MLPs on all tasks studied in this paper. We also show that the size and training speed of RBF-based KANs is only marginally higher than for MLPs, making them viable alternatives. Code available at https://github.com/RomanBresson/KAGNN.},
  archive      = {J_TMLR},
  author       = {Roman Bresson and Giannis Nikolentzos and George Panagopoulos and Michail Chatzianastasis and Jun Pang and Michalis Vazirgiannis},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {KAGNNs: Kolmogorov-arnold networks meet graph learning},
  url          = {https://openreview.net/forum?id=03UB1MCAMr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No need for ad-hoc substitutes: The expected cost is a principled all-purpose classification metric. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5PPbvCExZs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected cost (EC) is one of the main classification metrics introduced in statistical and machine learning books. It is based on the assumption that, for a given application of interest, each decision made by the system has a corresponding cost which depends on the true class of the sample. An evaluation metric can then be defined by taking the expectation of the cost over the data. Two special cases of the EC are widely used in the machine learning literature: the error rate (one minus the accuracy) and the balanced error rate (one minus the balanced accuracy or unweighted average recall). Other instances of the EC can be useful for applications in which some types of errors are more severe than others, or when the prior probabilities of the classes differ between the evaluation data and the use-case scenario. Surprisingly, the general form for the EC is rarely used in the machine learning literature. Instead, alternative ad-hoc metrics like the F-beta score and the Matthews correlation coefficient (MCC) are used for many applications. In this work, we argue that the EC is superior to these alternative metrics, being more general, interpretable, and adaptable to any application scenario. We provide both theoretically-motivated discussions as well as examples to illustrate the behavior of the different metrics.},
  archive      = {J_TMLR},
  author       = {Luciana Ferrer},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {No need for ad-hoc substitutes: The expected cost is a principled all-purpose classification metric},
  url          = {https://openreview.net/forum?id=5PPbvCExZs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fairness in unsupervised graph anomaly detection through disentanglement. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5zRs34Ls3C'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) is becoming increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing bias inherent in graphrepresentation learning. Besides, to alleviate discriminatory bias in evaluating anomalies, DEFEND adopts a reconstruction-based method, which concentrates solely on node attributes and avoids incorporating biased graph topology. Additionally, given the inherent association between sensitive-relevant and -irrelevant attributes, DEFEND further constrains the correlation between the reconstruction error and predicted sensitive attributes. Empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. Our code is available at https://github.com/AhaChang/DEFEND.},
  archive      = {J_TMLR},
  author       = {Wenjing Chang and Kay Liu and Philip S. Yu and Jianjun Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing fairness in unsupervised graph anomaly detection through disentanglement},
  url          = {https://openreview.net/forum?id=5zRs34Ls3C},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DP-2Stage: Adapting language models as differentially private tabular data generators. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6nBIweDYzZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision signals. Recently, pre-trained Large Language Models (LLMs) -- even those at the scale of GPT-2 -- have demonstrated great potential in synthesizing tabular data. However, their applications under DP constraints remain largely unexplored. In this work, we address this gap by applying DP techniques to the generation of synthetic tabular data. Our findings shows that LLMs face difficulties in generating coherent text when fine-tuned with DP, as privacy budgets are inefficiently allocated to non-private elements like table structures. To overcome this, we propose DP-2Stage, a two-stage fine-tuning framework for differentially private tabular data generation. The first stage involves non-private fine-tuning on a pseudo dataset, followed by DP fine-tuning on a private dataset. Our empirical results show that this approach improves performance across various settings and metrics compared to directly fine-tuned LLMs in DP contexts. We release our code and setup at https://github.com/tejuafonja/DP-2Stage.},
  archive      = {J_TMLR},
  author       = {Tejumade Afonja and Hui-Po Wang and Raouf Kerkouche and Mario Fritz},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DP-2Stage: Adapting language models as differentially private tabular data generators},
  url          = {https://openreview.net/forum?id=6nBIweDYzZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-explainable heterogeneous GNN for relational deep learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8Q4qxe9a9Z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node’s class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model’s reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Francesco Ferrini and Antonio Longa and Andrea Passerini and Manfred Jaeger},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A self-explainable heterogeneous GNN for relational deep learning},
  url          = {https://openreview.net/forum?id=8Q4qxe9a9Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term imputer: Handling consecutive missing values in time series. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9NVJ0ZgEfT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encountered frequently in time series data, missing values can significantly impede time-series analysis. With the progression of deep learning, advanced imputation models delve into the temporal dependencies inherent in time series data, showcasing remarkable performance. This positions them as intuitive selections for time series imputation tasks which assume ``Miss Completely at Random''. Nonetheless, long-interval consecutive missing values may obstruct the model's ability to grasp long-term temporal dependencies, consequently hampering the efficacy of imputation performance. To tackle this challenge, we propose Long Short-term Imputer (LSTI) to impute consecutive missing values with different length of intervals. Long-term Imputer is designed using the idea of bi-directional autoregression. A forward prediction model and a backward prediction model are trained with a consistency regularization, which is designed to capture long-time dependency and can adapt to long-interval consecutive missing values. Short-term Imputer is designed to capture short-time dependency and can impute the short-interval consecutive missing values effectively. A meta-weighting network is then proposed to take advantage of the strengths of two imputers. As a result, LSTI can impute consecutive missing values with different intervals effectively. Experiments demonstrate that our approach, on average, reduces the error by 57.4% compared to state-of-the-art deep models across five datasets.},
  archive      = {J_TMLR},
  author       = {Jiacheng You and Xinyang Chen and Yu Sun and Weili Guan and Liqiang Nie},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long short-term imputer: Handling consecutive missing values in time series},
  url          = {https://openreview.net/forum?id=9NVJ0ZgEfT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 2024 foundation model transparency index. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=38cwP8xVxD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models are increasingly consequential yet extremely opaque. To characterize the status quo, the Foundation Model Transparency Index was launched in October 2023 to measure the transparency of leading foundation model developers. The October 2023 Index (v1.0) assessed 10 major foundation model developers (e.g. OpenAI, Google) on 100 transparency indicators (e.g. does the developer disclose the wages it pays for data labor?). At the time, developers publicly disclosed very limited information with the average score being 37 out of 100. To understand how the status quo has changed, we conduct a follow-up study (v1.1) after 6 months: we score 14 developers against the same 100 indicators. While in v1.0 we searched for publicly available information, in v1.1 developers submit reports on the 100 transparency indicators, potentially including information that was not previously public. We find that developers now score 58 out of 100 on average, a 21 point improvement over v1.0. Much of this increase is driven by developers disclosing information during the v1.1 process: on average, developers disclosed information related to 16.6 indicators that was not previously public. We observe regions of sustained (i.e. across v1.0 and v1.1) and systemic (i.e. across most or all developers) opacity such as on copyright status, data access, data labor, and downstream impact. We publish transparency reports for each developer that consolidate information disclosures: these reports are based on the information disclosed to us via developers. Our findings demonstrate that transparency can be improved in this nascent ecosystem, the Foundation Model Transparency Index likely contributes to these improvements, and policymakers should consider interventions in areas where transparency has not improved.},
  archive      = {J_TMLR},
  author       = {Rishi Bommasani and Kevin Klyman and Sayash Kapoor and Shayne Longpre and Betty Xiong and Nestor Maslej and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The 2024 foundation model transparency index},
  url          = {https://openreview.net/forum?id=38cwP8xVxD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HARE: Human-in-the-loop algorithmic recourse. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=56EBglCFvx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are seeing increasing use as decision making systems in domains such as education, finance and healthcare. It is desirable that these models are trustworthy to the end-user, by ensuring fairness, transparency and reliability of decisions. In this work, we consider a key aspect of responsible and transparent AI models -- actionable explanations, viz. the ability of such models to provide recourse to end users adversely affected by their decisions. While algorithmic recourse has seen a variety of efforts in recent years, there have been very few efforts on exploring personalized recourse for a given user. Two users with the same feature profile may prefer vastly different recourses. The limited work in this direction hitherto rely on one-time feature preferences provided by a user. Instead, we present a human-in-the-loop formulation of algorithmic recourse that can incorporate both relative and absolute human feedback for a given test instance. We show that our formulation can extend any existing recourse generating method, enabling the generation of recourses that are satisfactory to the user. We perform experiments on 3 benchmark datasets on top of 6 popular baseline recourse methods where we observe that our framework performs significantly better on simulated user preferences.},
  archive      = {J_TMLR},
  author       = {Sai Srinivas Kancheti and Rahul Vigneswaran and Bamdev Mishra and Vineeth N. Balasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HARE: Human-in-the-loop algorithmic recourse},
  url          = {https://openreview.net/forum?id=56EBglCFvx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution of discriminator and generator gradients in GAN training: From fitting to collapse. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=58gPkcVbFL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are powerful generative models but often suffer from mode mixture and mode collapse. We propose a perspective that views GAN training as a two-phase progression from fitting to collapse, where mode mixture and mode collapse are treated as inter-connected. Inspired by the particle model interpretation of GANs, we leverage the discriminator gradient to analyze particle movement and the generator gradient, specifically "steepness," to quantify the severity of mode mixture by measuring the generator's sensitivity to changes in the latent space. Using these theoretical insights into evolution of gradients, we design a specialized metric that integrates both gradients to detect the transition from fitting to collapse. This metric forms the basis of an early stopping algorithm, which stops training at a point that retains sample quality and diversity. Experiments on synthetic and real-world datasets, including MNIST, Fashion MNIST, and CIFAR-10, validate our theoretical findings and demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_TMLR},
  author       = {Weiguo Gao and Ming Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evolution of discriminator and generator gradients in GAN training: From fitting to collapse},
  url          = {https://openreview.net/forum?id=58gPkcVbFL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The BrowserGym ecosystem for web agent research. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5298fKGmv3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs) for web interaction tasks. Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. In an earlier work, Drouin et al. (2024) introduced BrowserGym which aims to solve this by providing a unified, gym-like environment with well-defined observation and actionspaces, facilitating standardized evaluation across diverse benchmarks. We propose an extended BrowserGym-based ecosystem for web agent research, which unifies existing benchmarks from the literature and includes AgentLab, a complementary framework that aids in agent creation, testing, and analysis. Our proposed ecosystem offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. This standardized approach seeks to reduce the time and complexity of developing web agents, supporting more reliable comparisons and facilitating in-depth analysis of agent behaviors, and could result in more adaptable, capable agents, ultimately accelerating innovation in LLM-driven automation. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across 6 popular web agent benchmarks made available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic’s latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models.},
  archive      = {J_TMLR},
  author       = {Thibault Le Sellier de Chezelles and Maxime Gasse and Alexandre Lacoste and Massimo Caccia and Alexandre Drouin and Léo Boisvert and Megh Thakkar and Tom Marty and Rim Assouel and Sahar Omidi Shayegan and Lawrence Keunho Jang and Xing Han Lù and Ori Yoran and Dehan Kong and Frank F. Xu and Siva Reddy and Graham Neubig and Quentin Cappart and Russ Salakhutdinov and Nicolas Chapados},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The BrowserGym ecosystem for web agent research},
  url          = {https://openreview.net/forum?id=5298fKGmv3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing estimators of squared calibration errors in classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BPDVZajOW5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a mean-squared error-based risk that enables the comparison and optimization of estimators of squared calibration errors in practical settings. Improving the calibration of classifiers is crucial for enhancing the trustworthiness and interpretability of machine learning models, especially in sensitive decision-making scenarios. Although various calibration (error) estimators exist in the current literature, there is a lack of guidance on selecting the appropriate estimator and tuning its hyperparameters. By leveraging the bilinear structure of squared calibration errors, we reformulate calibration estimation as a regression problem with independent and identically distributed (i.i.d.) input pairs. This reformulation allows us to quantify the performance of different estimators even for the most challenging calibration criterion, known as canonical calibration. Our approach advocates for a training-validation-testing pipeline when estimating a calibration error on an evaluation dataset. We demonstrate the effectiveness of our pipeline by optimizing existing calibration estimators and comparing them with novel kernel ridge regression-based estimators on standard image classification tasks.},
  archive      = {J_TMLR},
  author       = {Sebastian Gregor Gruber and Francis R. Bach},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimizing estimators of squared calibration errors in classification},
  url          = {https://openreview.net/forum?id=BPDVZajOW5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lean dataset for international math olympiad: Small steps towards writing math proofs for hard problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CrKMqRAhBo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using AI to write formal proofs for mathematical problems is a challenging task that has seen some advancements in recent years. Automated systems such as Lean can verify the correctness of proofs written in formal language, yet writing the proofs in formal language can be challenging for humans and machines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal proofs are available only for 6 of these problems (3 of which are only written by mathematicians). The model with best accuracy can only prove 2 of these 20 IMO problems, from 1950s and 60s, while its training set is a secret. In this work, we write complete, original formal proofs for the remaining IMO problems in Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands the availability of proof currently in the public domain by creating 5,880 lines of Lean proof. The goal of the paper is to pave the way for developing AI models that can automatically write the formal proofs for all the IMO problems in miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we devise a method to decompose the proofs of these problems into their building blocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean code. These lemmas are not trivial, yet they are approachable, providing the opportunity to evaluate and diagnose the failures and successes of AI models. We evaluate the ability of the SOTA LLMs on our dataset and analyze their success and failure modes from different perspectives. Our dataset and code is available at: https://github.com/roozbeh-yz/IMO-Steps.},
  archive      = {J_TMLR},
  author       = {Roozbeh Yousefzadeh and Xuenan Cao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A lean dataset for international math olympiad: Small steps towards writing math proofs for hard problems},
  url          = {https://openreview.net/forum?id=CrKMqRAhBo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual privacy auditing with diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=D3DA7pgpvn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data reconstruction attacks on machine learning models pose a substantial threat to privacy, potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) provides theoretical guarantees, determining appropriate DP parameters remains challenging. Current formal guarantees on the success of data reconstruction suffer from overly stringent assumptions regarding adversary knowledge about the target data, particularly in the image domain, raising questions about their real-world applicability. In this work, we empirically investigate this discrepancy by introducing a reconstruction attack based on diffusion models (DMs) that only assumes adversary access to real-world image priors and specifically targets the DP defense. We find that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as heuristic auditing tools for visualizing privacy leakage.},
  archive      = {J_TMLR},
  author       = {Kristian Schwethelm and Johannes Kaiser and Moritz Knolle and Sarah Lockfisch and Daniel Rueckert and Alexander Ziller},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Visual privacy auditing with diffusion models},
  url          = {https://openreview.net/forum?id=D3DA7pgpvn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out of spuriousity: Improving robustness to spurious correlations without group annotations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EEeVYfXor5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are known to learn spurious correlations, i.e., features that have strong correlations with class labels but no causal relationship. Relying on these correlations leads to poor performance in data groups that do not contain these correlations, and poor generalization. Approaches to mitigate spurious correlations either rely on the availability of group annotations or require access to different model checkpoints to approximate these group annotations. We propose PruSC, a method for extracting a spurious-free subnetwork from a dense network. PruSC does not require prior knowledge of the spurious correlations and is able to mitigate the effect of multiple spurious attributes. Specifically, we observe that ERM training leads to clusters in representation space that are induced by spurious correlations. We then define a supervised contrastive loss to extract a subnetwork that distorts such clusters, forcing the model to learn only class-specific clusters, rather than attribute-class specific clusters. Our method outperforms all annotation-free methods, achieves worst-group accuracy competitive with methods that require annotations and can mitigate the effect of multiple spurious correlations. Our results show that in a fully trained dense network, there exists a subnetwork that uses only invariant features in classification tasks, thereby eliminating the influence of spurious features.},
  archive      = {J_TMLR},
  author       = {Phuong Quynh Le and Jörg Schlötterer and Christin Seifert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Out of spuriousity: Improving robustness to spurious correlations without group annotations},
  url          = {https://openreview.net/forum?id=EEeVYfXor5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal discovery over high-dimensional structured hypothesis spaces with causal graph partitioning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FecsgPCOHk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way---without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of Directed Acyclic Graphs (DAG), to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees under the Maximal Ancestral Graph (MAG) class. We leverage the idea of a superstructure---a set of learned or existing candidate hypotheses---to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.},
  archive      = {J_TMLR},
  author       = {Ashka Shah and Adela Frances DePavia and Nathaniel C Hudson and Ian Foster and Rick Stevens},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causal discovery over high-dimensional structured hypothesis spaces with causal graph partitioning},
  url          = {https://openreview.net/forum?id=FecsgPCOHk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-exploring language models: Active preference elicitation for online alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FoQK84nwY3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings.},
  archive      = {J_TMLR},
  author       = {Shenao Zhang and Donghan Yu and Hiteshi Sharma and Han Zhong and Zhihan Liu and Ziyi Yang and Shuohang Wang and Hany Hassan Awadalla and Zhaoran Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-exploring language models: Active preference elicitation for online alignment},
  url          = {https://openreview.net/forum?id=FoQK84nwY3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational neural stochastic differential equations with change points. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GEilvtsFNV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we explore modeling change points in time-series data using neural stochastic differential equations (neural SDEs). We propose a novel model formulation and training procedure based on the variational autoencoder (VAE) framework for modeling time-series as a neural SDE. Unlike existing algorithms training neural SDEs as VAEs, our proposed algorithm only necessitates a Gaussian prior of the initial state of the latent stochastic process, rather than a Wiener process prior on the entire latent stochastic process. We develop two methodologies for modeling and estimating change points in time-series data with distribution shifts. Our iterative algorithm alternates between updating neural SDE parameters and updating the change points based on either a maximum likelihood-based approach or a change point detection algorithm using the sequential likelihood ratio test. We also discuss theoretical implications of the proposed change point detection scheme. Finally, we present an empirical evaluation that demonstrates the expressive power of our proposed model, showing that it can effectively model both classical parametric SDEs and some real datasets with distribution shifts.},
  archive      = {J_TMLR},
  author       = {Yousef El-Laham and Zhongchang Sun and Haibei Zhu and Tucker Balch and Svitlana Vyetrenko},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational neural stochastic differential equations with change points},
  url          = {https://openreview.net/forum?id=GEilvtsFNV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cycle conditioning for robust representation learning from categorical data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GkYOcbNLaW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel diffusion-based method for learning representations from categorical data. Conditional diffusion models have demonstrated their potential to extract meaningful representations from input samples. However, they often struggle to yield versatile, general-purpose information, limiting their adaptability to unforeseen tasks. To address this, we propose a cycle conditioning approach for diffusion models, designed to capture expressive information from conditioning samples. However, cycle conditioning alone can be insufficient. Diffusion models may ignore conditioning samples that vary across training iterations, an issue that occurs within cycle conditioning. To counter this limitation, we introduce additional "spelling" information to guide the conditioning process, ensuring that the conditioning sample remains influential during denoising. While this supervision enhances the generalizability of extracted representations, it is constrained by the sparse nature of spelling information in categorical data, leading to sparse latent conditions. This sparsity reduces the robustness of the extracted representations for downstream tasks or as effective guidance in the diffusion process. To overcome this challenge, we propose a linear navigation strategy within the latent space of conditioning samples, allowing dense representations to be extracted even with sparse supervision. Our experiments demonstrate that our method achieves at least a 1.42\% improvement in AUROC and a 4.12\% improvement in AUCPR over the best results from existing state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Mohsen Tabejamaat and Farzaneh Etminani and Mattias Ohlsson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cycle conditioning for robust representation learning from categorical data},
  url          = {https://openreview.net/forum?id=GkYOcbNLaW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized tangent kernel: A unified geometric foundation for natural gradient and standard gradient. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HOnL5hjaIt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gradients have been widely studied from both theoretical and empirical perspectives, and it is commonly believed that natural gradients have advantages over standard (Euclidean) gradients in capturing the intrinsic geometric structure of the underlying function space and being invariant under reparameterization. However, for function optimization, a fundamental theoretical issue regarding the existence of natural gradients on the function space remains underexplored. We address this issue by providing a geometric perspective and mathematical framework for studying both natural gradient and standard gradient that is more complete than existing studies. The key tool that unifies natural gradient and standard gradient is a generalized form of the Neural Tangent Kernel (NTK), which we name the Generalized Tangent Kernel (GTK). Using a novel orthonormality property of GTK, we show that for a fixed parameterization, GTK determines a Riemannian metric on the entire function space which makes the standard gradient as “natural" as the natural gradient in capturing the intrinsic structure of the parameterized function space. Many aspects of this approach relate to RKHS theory. For the practical side of this theory paper, we showcase that our framework motivates new solutions to the non-immersion/degenerate case of natural gradient and leads to new families of natural/standard gradient descent methods.},
  archive      = {J_TMLR},
  author       = {Qinxun Bai and Steven Rosenberg and Wei Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized tangent kernel: A unified geometric foundation for natural gradient and standard gradient},
  url          = {https://openreview.net/forum?id=HOnL5hjaIt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient mixture of experts: A holistic study of compression techniques. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HTpMOl6xSI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling large language models has driven remarkable advancements across various domains, yet the continual increase in model size presents significant challenges for real-world deployment. The Mixture of Experts (MoE) architecture offers a promising solution by dynamically selecting and activating only a subset of experts during inference, thus substantially reducing computational costs while preserving high performance. Despite these benefits, MoE introduces new inefficiencies, such as excessive parameters and communication overhead. In this work, we present a holistic study of compression techniques for Mixture of Experts to enhance both efficiency and scalability. While recent efforts have focused on Expert Trimming, which reduces the number of experts, these approaches still suffer from considerable communication and computational costs. To address this, we propose more aggressive strategies, such as Layer Drop, which removes entire MoE layers, and Block Drop, which eliminates transformer blocks. Surprisingly, these aggressive pruning techniques not only preserve model performance but also substantially improve computation and memory efficiency. Furthermore, beyond Expert Trimming, we also introduce Expert Slimming, which compresses individual experts to further boost performance and can be seamlessly integrated with Expert Trimming. Extensive experimental results demonstrate the effectiveness of our proposed methods—Layer Drop and Block Drop—along with the comprehensive recipe that integrates Expert Slimming and Expert Trimming, achieving a 6.05× speedup with 77.1% reduced memory usage while maintaining over 92% of performance on Mixtral-8×7B. Our code is released at https://github.com/CASE-Lab-UMD/Unified-MoE-Compression.},
  archive      = {J_TMLR},
  author       = {Shwai He and Daize Dong and Liang Ding and Ang Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards efficient mixture of experts: A holistic study of compression techniques},
  url          = {https://openreview.net/forum?id=HTpMOl6xSI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlabelled compressive sensing under sparse permutation and prior information. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HaAg9RN7Hi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of unlabelled compressed sensing, where the correspondence between the measurement values and the rows of the sensing matrix is lost, the number of measurements is less than the dimension of the regression vector, and the regression vector is sparse in the identity basis. Additionally, motivated by practical situations, we assume that we accurately know a small number of correspondences between the rows of the measurement matrix and the measurement vector. We propose a tractable estimator, based on a modified form of the \textsc{Lasso}, to estimate the regression vector, and we derive theoretical error bounds for the estimate. This is unlike previous approaches to unlabelled compressed sensing, which either do not produce theoretical bounds or which produce bounds for intractable estimators. We show that our algorithm outperforms a hard thresholding pursuit (\textsc{Htp}) approach and an $\ell_1$-norm estimator used to solve a similar problem across diverse regimes. We also propose a modified \textsc{Htp} based estimator which has superior properties to the baseline \textsc{Htp} estimator. Lastly, we show an application of unlabelled compressed sensing in image registration, demonstrating the utility of a few known point correspondences.},
  archive      = {J_TMLR},
  author       = {Garweet Sresth and Satish Mulleti and Ajit Rajwade},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlabelled compressive sensing under sparse permutation and prior information},
  url          = {https://openreview.net/forum?id=HaAg9RN7Hi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep active learning in the open world. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HkmymFPODz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models deployed in open-world scenarios often encounter unfamiliar conditions and perform poorly in unanticipated situations. As AI systems advance and find application in safety-critical domains, effectively handling out-of-distribution (OOD) data is crucial to building open-world learning systems. In this work, we introduce ALOE, a novel active learning algorithm for open-world environments designed to enhance model adaptation by incorporating new OOD classes via a two-stage approach. First, diversity sampling selects a representative set of examples, followed by energy-based OOD detection to prioritize likely unknown classes for annotation. This strategy accelerates class discovery and learning, even under constrained annotation budgets. Evaluations on three long-tailed image classification benchmarks demonstrate that ALOE outperforms traditional active learning baselines, effectively expanding known categories while balancing annotation cost. Our findings reveal a crucial tradeoff between enhancing known-class performance and discovering new classes, setting the stage for future advancements in open-world machine learning.},
  archive      = {J_TMLR},
  author       = {Tian Xie and Jifan Zhang and Haoyue Bai and Robert D Nowak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep active learning in the open world},
  url          = {https://openreview.net/forum?id=HkmymFPODz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing the convergence of game dynamics via potentialness. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Is9APiPg4V'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the convergence landscape of multi-agent learning is a fundamental problem of great practical relevance in many applications of artificial intelligence and machine learning. While it is known that learning dynamics converge to Nash equilibrium in potential games, the behavior of dynamics in many important classes of games that do not admit a potential is poorly understood. To measure how ``close'' a game is to being potential, we consider a distance function, that we call ``potentialness'', and which relies on a strategic decomposition of games introduced by Candogan et al. (2011). We introduce a numerical framework enabling the computation of this metric, which we use to calculate the degree of ``potentialness'' in generic matrix games, as well as (non-generic) games that are important in economic applications, namely auctions and contests. Understanding learning in the latter games has become increasingly important due to the wide-spread automation of bidding and pricing with no-regret learning algorithms. We empirically show that potentialness decreases and concentrates with an increasing number of agents or actions; in addition, potentialness turns out to be a good predictor for the existence of pure Nash equilibria and the convergence of no-regret learning algorithms in matrix games. In particular, we observe that potentialness is very low for complete-information models of the all-pay auction where no pure Nash equilibrium exists, and much higher for Tullock contests, first-, and second-price auctions, explaining the success of learning in the latter. In the incomplete-information version of the all-pay auction, a pure Bayes-Nash equilibrium exists and it can be learned with gradient-based algorithms. Potentialness nicely characterizes these differences to the complete-information version.},
  archive      = {J_TMLR},
  author       = {Martin Bichler and Davide Legacci and Panayotis Mertikopoulos and Matthias Oberlechner and Bary Pradelski},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Characterizing the convergence of game dynamics via potentialness},
  url          = {https://openreview.net/forum?id=Is9APiPg4V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online control-informed learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LDzvZEVl5H'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.},
  archive      = {J_TMLR},
  author       = {Zihao Liang and Tianyu Zhou and Zehui Lu and Shaoshuai Mou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online control-informed learning},
  url          = {https://openreview.net/forum?id=LDzvZEVl5H},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble and mixture-of-experts DeepONets for operator learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MGdydNfWzQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel deep operator network (DeepONet) architecture for operator learning, the ensemble DeepONet, that allows for enriching the trunk network of a single DeepONet with multiple distinct trunk networks. This trunk enrichment allows for greater expressivity and generalization capabilities over a range of operator learning problems. We also present a spatial mixture-of-experts (MoE) DeepONet trunk network architecture that utilizes a partition-of-unity (PoU) approximation to promote spatial locality and model sparsity in the operator learning problem. We first prove that both the ensemble and PoU-MoE DeepONets are universal approximators. We then demonstrate that ensemble DeepONets containing a trunk ensemble of a standard trunk, the PoU-MoE trunk, and/or a proper orthogonal decomposition (POD) trunk can achieve 2-4x lower relative $\ell_2$ errors than standard DeepONets and POD-DeepONets on both standard and challenging new operator learning problems involving partial differential equations (PDEs) in two and three dimensions. Our new PoU-MoE formulation provides a natural way to incorporate spatial locality and model sparsity into any neural network architecture, while our new ensemble DeepONet provides a powerful and general framework for incorporating basis enrichment in scientific machine learning architectures for operator learning.},
  archive      = {J_TMLR},
  author       = {Ramansh Sharma and Varun Shankar},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ensemble and mixture-of-experts DeepONets for operator learning},
  url          = {https://openreview.net/forum?id=MGdydNfWzQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning linear polytree structural equation model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=N28FdYO2sH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem of learning the directed acyclic graph (DAG) when data are generated from a linear structural equation model (SEM) and the causal structure can be characterized by a polytree. Under the Gaussian polytree models, we study sufficient conditions on the sample sizes for the well-known Chow-Liu algorithm to exactly recover both the skeleton and the equivalence class of the polytree, which is uniquely represented by a CPDAG. On the other hand, necessary conditions on the required sample sizes for both skeleton and CPDAG recovery are also derived in terms of information-theoretic lower bounds, which match the respective sufficient conditions and thereby give a sharp characterization of the difficulty of these tasks. We also consider the problem of inverse correlation matrix estimation under the linear polytree models, and establish the estimation error bound in terms of the dimension and the total number of v-structures. We also consider an extension of group linear polytree models, in which each node represents a group of variables. Our theoretical findings are illustrated by comprehensive numerical simulations, and experiments on benchmark data also demonstrate the robustness of polytree learning when the true graphical structures can only be approximated by polytrees.},
  archive      = {J_TMLR},
  author       = {Xingmei Lou and Yu Hu and Xiaodong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning linear polytree structural equation model},
  url          = {https://openreview.net/forum?id=N28FdYO2sH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active diffusion subsampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OGifiton47'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsampling is commonly used to mitigate costs associated with data acquisition, such as time or energy requirements, motivating the development of algorithms for estimating the fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum- entropy sampling, one selects measurement locations that are expected to have the highest entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model of the posterior distribution over future measurements, given the measurements observed so far. Recently, diffusion models have been shown to produce high-quality posterior samples of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a method for designing intelligent subsampling masks using guided dif- fusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout the reverse diffusion process, progressively decreasing its uncertainty by actively choosing to acquire measurements with maximum expected entropy, ultimately producing the pos- terior distribution $p(x | y)$. ADS can be applied using pre-trained diffusion models for any subsampling rate, and does not require task-specific retraining – just the specification of a measurement model. Furthermore, the maximum entropy sampling policy employed by ADS is interpretable, enhancing transparency relative to existing methods using black-box policies. Experimentally, we show that through designing informative subsampling masks, ADS significantly improves reconstruction quality compared to fixed sampling strategies on the MNIST and CelebA datasets, as measured by standard image quality metrics, includ- ing PSNR, SSIM, and LPIPS. Furthermore, on the task of Magnetic Resonance Imaging acceleration, we find that ADS performs competitively with existing supervised methods in reconstruction quality while using a more interpretable acquisition scheme design procedure. Code is available at https://active-diffusion-subsampling.github.io/.},
  archive      = {J_TMLR},
  author       = {Oisín Nolan and Tristan Stevens and Wessel L. van Nierop and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active diffusion subsampling},
  url          = {https://openreview.net/forum?id=OGifiton47},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence guarantees for RMSProp and adam in generalized-smooth non-convex optimization with affine noise variance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QIzRdjIWnS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides the first tight convergence analyses for RMSProp and Adam for non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. RMSProp is firstly analyzed, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to the dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and the first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in Arjevani et al. (2023).},
  archive      = {J_TMLR},
  author       = {Qi Zhang and Yi Zhou and Shaofeng Zou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convergence guarantees for RMSProp and adam in generalized-smooth non-convex optimization with affine noise variance},
  url          = {https://openreview.net/forum?id=QIzRdjIWnS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State space models can express $n$-gram languages. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QlBaDKb370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in recurrent neural networks (RNNs) have reinvigorated interest in their application to natural language processing tasks, particularly with the development of more efficient and parallelizable variants known as state space models (SSMs), which have shown competitive performance against transformer models while maintaining a lower memory footprint. While RNNs and SSMs (e.g., Mamba) have been empirically more successful than rule-based systems based on $n$-gram models, a rigorous theoretical explanation for this success has not yet been developed, as it is unclear how these models encode the combinatorial rules that govern the next-word prediction task. In this paper, we construct state space language models that can solve the next-word prediction task for languages generated from $n$-gram rules, thereby showing that the former are more expressive. Our proof shows how SSMs can encode $n$-gram rules using new theoretical results on their memorization capacity, and demonstrates how their context window can be controlled by restricting the spectrum of the state transition matrix. We conduct experiments with a small dataset generated from $n$-gram rules to show how our framework can be applied to SSMs and RNNs obtained through gradient-based optimization.},
  archive      = {J_TMLR},
  author       = {Vinoth Nandakumar and Qiang Qu and Peng Mi and Tongliang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {State space models can express $n$-gram languages},
  url          = {https://openreview.net/forum?id=QlBaDKb370},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-specific counterfactual fairness via dividend correction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RXoSmiyObR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual fairness is a fundamental principle in machine learning that allows the analysis of the effects of sensitive attributes in each individual decision by integrating the knowledge of causal graphs. An issue in dealing with counterfactual fairness is that unfair causal effects are often context-specific, influenced by religious, cultural, and national differences, making it difficult to create a universally applicable model. This leads to the challenge of dealing with frequent adaptation to changes in fairness assessments when localizing a model. Thus, applicability across a variety of models and efficiency becomes necessary to meet this challenge. We propose the first efficient post-process approach to achieve path-specific counterfactual fairness by adjusting a model's outputs based on a given causal graph. This approach is model-agnostic, prioritizing on flexibility and generalizability to deliver robust results across various domains and model architectures. By means of the mathematical tools in cooperative game, the Möbius inversion formula and dividends, we demonstrate that our post-process approach can be executed efficiently. We empirically show that proposed algorithm outperforms existing in-process approaches for path-specific counterfactual fairness and a post-process approach for counterfactual fairness.},
  archive      = {J_TMLR},
  author       = {Daisuke Hatano and Satoshi Hara and Hiromi Arai},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Path-specific counterfactual fairness via dividend correction},
  url          = {https://openreview.net/forum?id=RXoSmiyObR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variation matters: From mitigating to embracing zero-shot NAS ranking function variation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SbGt90dxdp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) is a powerful automatic alternative to manual design of a neural network. In the zero-shot version, a fast ranking function is used to compare architectures without training them. The outputs of the ranking functions often vary significantly due to different sources of randomness, including the evaluated architecture's weights' initialization or the batch of data used for calculations. A common approach to addressing the variation is to average a ranking function output over several evaluations. We propose taking into account the variation in a different manner, by viewing the ranking function output as a random variable representing a proxy performance metric. During the search process, we strive to construct a stochastic ordering of the performance metrics to determine the best architecture. Our experiments show that the proposed stochastic ordering can effectively boost performance of a search on standard benchmark search spaces.},
  archive      = {J_TMLR},
  author       = {Pavel Rumiantsev and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variation matters: From mitigating to embracing zero-shot NAS ranking function variation},
  url          = {https://openreview.net/forum?id=SbGt90dxdp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoSNNs: Adversarially-robust homeostatic spiking neural networks with adaptive firing thresholds. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UV58hNygne'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While spiking neural networks (SNNs) offer a promising neurally-inspired model of computation, they are vulnerable to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to design a threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model and utilize TA-LIF neurons to construct the adversarially robust homeostatic SNNs (HoSNNs) for improved robustness. The TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, offering a local feedback control solution to the minimization of each neuron's membrane potential error caused by adversarial disturbance. Theoretical analysis demonstrates favorable dynamic properties of TA-LIF neurons in terms of the bounded-input bounded-output stability and suppressed time growth of membrane potential error, underscoring their superior robustness compared with the standard LIF neurons. When trained with weak FGSM attacks (\(\epsilon = 2/255\)), our HoSNNs significantly outperform conventionally trained LIF-based SNNs across multiple datasets. Furthermore, under significantly stronger PGD7 attacks (\(\epsilon = 8/255\)), HoSNN achieves notable improvements in accuracy, increasing from 30.90% to 74.91% on FashionMNIST, 0.44% to 36.82% on SVHN, 0.54% to 43.33% on CIFAR10, and 0.04% to 16.66% on CIFAR100.},
  archive      = {J_TMLR},
  author       = {Hejia Geng and Peng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HoSNNs: Adversarially-robust homeostatic spiking neural networks with adaptive firing thresholds},
  url          = {https://openreview.net/forum?id=UV58hNygne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early directional convergence in deep homogeneous neural networks for small initializations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VNM6V1gi3k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. It is shown here that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in (Euclidean) norm and approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of the recently introduced neural correlation function. Additionally, this paper also studies the KKT points of the neural correlation function for feed-forward networks with (Leaky) ReLU and polynomial (Leaky) ReLU activations, deriving necessary and sufficient conditions for rank-one KKT points.},
  archive      = {J_TMLR},
  author       = {Akshay Kumar and Jarvis Haupt},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Early directional convergence in deep homogeneous neural networks for small initializations},
  url          = {https://openreview.net/forum?id=VNM6V1gi3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlearning personal data from a single image. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VxC4PZ71Ym'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning aims to erase data from a model as if the latter never saw them during training. While existing approaches unlearn information from complete or partial access to the training data, this access can be limited over time due to privacy regulations. Currently, no setting or benchmark exists to probe the effectiveness of unlearning methods in such scenarios. To fill this gap, we propose a novel task we call One-Shot Unlearning of Personal Identities (1-SHUI) that evaluates unlearning models when the training data is not available. We focus on unlearning identity data, which is specifically relevant due to current regulations requiring personal data deletion after training. To cope with data absence, we expect users to provide a portraiting picture to aid unlearning. We design requests on CelebA, CelebA-HQ, and MUFAC with different unlearning set sizes to evaluate applicable methods in 1-SHUI. Moreover, we propose MetaUnlearn, an effective method that meta-learns to forget identities from a single image. Our findings indicate that existing approaches struggle when data availability is limited, especially when there is a dissimilarity between the provided samples and the training data.},
  archive      = {J_TMLR},
  author       = {Thomas De Min and Massimiliano Mancini and Stéphane Lathuilière and Subhankar Roy and Elisa Ricci},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlearning personal data from a single image},
  url          = {https://openreview.net/forum?id=VxC4PZ71Ym},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed sparsity training: Achieving 4$\times$ FLOP reduction for transformer pretraining. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XosdLS7KVE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75$% of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\times$ without compromising performance.},
  archive      = {J_TMLR},
  author       = {Pihe Hu and Shaolong Li and Xun Wang and Longbo Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixed sparsity training: Achieving 4$\times$ FLOP reduction for transformer pretraining},
  url          = {https://openreview.net/forum?id=XosdLS7KVE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention overlap is responsible for the entity missing problem in text-to-image diffusion models!. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Xv3ZrFayIO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image diffusion models such as Stable Diffusion and DALL-E have exhibited impressive capabilities in producing high-quality, diverse, and realistic images based on textual prompts. Nevertheless, a common issue arises where these models encounter difficulties in faithfully generating every entity specified in the prompt, leading to a recognized challenge known as entity missing in visual compositional generation. While previous studies indicated that actively adjusting cross-attention maps during inference could potentially resolve the issue, there has been a lack of systematic investigation into the specific objective function required for this task. In this work, we thoroughly investigate three potential causes of entity missing from the perspective of cross-attention maps: insufficient attention intensity, excessive attention spread, and significant overlap between attention maps of different entities. Through comprehensive empirical analysis, we found that optimizing metrics that quantify the overlap between attention maps of entities is highly effective at mitigating entity missing. We hypothesize that during the denoising process, entity-related tokens engage in a form of competition for attention toward specific regions through the cross-attention mechanism. This competition may result in the attention of a spatial location being divided among multiple tokens, leading to difficulties in accurately generating the entities associated with those tokens. Building on this insight, we propose four overlap-based loss functions that can be used to implicitly manipulate the latent embeddings of the diffusion model during inference: Intersection over union (IoU), center-of-mass (CoM) distance, Kullback–Leibler (KL) divergence, and clustering compactness (CC). Extensive experiments on a diverse set of prompts demonstrate that our proposed training-free methods substantially outperform previous approaches on a range of compositional alignment metrics, including visual question-answering, captioning score, CLIP similarity, and human evaluation. Notably, our method outperforms the best baseline by $9\%$ in human evaluation.},
  archive      = {J_TMLR},
  author       = {Arash Mari Oriyad and Mohammadali Banayeeanzade and Reza Abbasi and Mohammad Hossein Rohban and Mahdieh Soleymani Baghshah},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attention overlap is responsible for the entity missing problem in text-to-image diffusion models!},
  url          = {https://openreview.net/forum?id=Xv3ZrFayIO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Buffer-based gradient projection for continual federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Xz5IcOizQ6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Federated Learning (CFL) is essential for enabling real-world applications where multiple decentralized clients adaptively learn from continuous data streams. A significant challenge in CFL is mitigating catastrophic forgetting, where models lose previously acquired knowledge when learning new information. Existing approaches often face difficulties due to the constraints of device storage capacities and the heterogeneous nature of data distributions among clients. While some CFL algorithms have addressed these challenges, they frequently rely on unrealistic assumptions about the availability of task boundaries (i.e., knowing when new tasks begin). To address these limitations, we introduce Fed-A-GEM, a federated adaptation of the A-GEM method, which employs a buffer-based gradient projection approach. Fed-A-GEM alleviates catastrophic forgetting by leveraging local buffer samples and aggregated buffer gradients, thus preserving knowledge across multiple clients. Our method is combined with existing CFL techniques, enhancing their performance in the CFL context. Our experiments on standard benchmarks show consistent performance improvements across diverse scenarios. For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%. Our code is available at https://github.com/shenghongdai/Fed-A-GEM.},
  archive      = {J_TMLR},
  author       = {Shenghong Dai and Jy-yong Sohn and Yicong Chen and S M Iftekharul Alam and Ravikumar Balakrishnan and Suman Banerjee and Nageen Himayat and Kangwook Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Buffer-based gradient projection for continual federated learning},
  url          = {https://openreview.net/forum?id=Xz5IcOizQ6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoMask3D: Geometrically informed mask selection for self-supervised point cloud learning in 3D. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Yk7GUlJwGa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model’s focus toward regions with higher geometric complexity. This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks. Our method also presents a feature-level knowledge distillation technique designed to guide the prediction of geometric complexity, which utilizes a comprehensive context from feature-level information. Extensive experiments confirm our method’s superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, segmentation, and few-shot tasks.},
  archive      = {J_TMLR},
  author       = {Ali Bahri and Moslem Yazdanpanah and Mehrdad Noori and Milad Cheraghalikhani and Gustavo Adolfo Vargas Hakim and David OSOWIECHI and Farzad Beizaee and Ismail Ben Ayed and Christian Desrosiers},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GeoMask3D: Geometrically informed mask selection for self-supervised point cloud learning in 3D},
  url          = {https://openreview.net/forum?id=Yk7GUlJwGa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An elementary concentration bound for gibbs measures arising in statistical learning theory. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZInwrlkQ3f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an elementary concentration bound for Gibbs measures whose log-likelihood is a function of the empirical risk. This bound controls the distance between samples from the (random) Gibbs measure and the minimizers of the population risk function. This bound is a generalization of a recent inequality developed by Ramsay et al., 2024. As a corollary, we obtain sample complexity bounds and bounds on the inverse temperature so that the samples are within a prescribed error of the population value. The latter bound on the inverse temperature is essentially sharp. We demonstrate our work on three canonical classes of examples: classification of two component mixture models, robust regression, and spiked matrix and tensor models.},
  archive      = {J_TMLR},
  author       = {Kelly Ramsay and Aukosh Jagannath and Shojaeddin Chenouri},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An elementary concentration bound for gibbs measures arising in statistical learning theory},
  url          = {https://openreview.net/forum?id=ZInwrlkQ3f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reset-free reinforcement learning with world models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZdMIXltJzK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://yangzhao-666.github.io/morefree},
  archive      = {J_TMLR},
  author       = {Zhao Yang and Thomas M. Moerland and Mike Preuss and Aske Plaat and Edward S. Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reset-free reinforcement learning with world models},
  url          = {https://openreview.net/forum?id=ZdMIXltJzK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to leverage predictive uncertainty estimates for reducing catastrophic forgetting in online continual learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dczXe0S1oL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications require machine-learning models to be able to deal with non-stationary data distributions and thus learn autonomously over an extended period of time, often in an online setting. One of the main challenges in this scenario is the so-called catastrophic forgetting (CF) for which the learning model tends to focus on the most recent tasks while experiencing predictive degradation on older ones. In the online setting, the most effective solutions employ a fixed-size memory buffer to store old samples used for replay when training on new tasks. Many approaches have been presented to tackle this problem and conflicting strategies are proposed to populate the memory. Are the easiest-to-forget or the easiest-to-remember samples more effective in combating CF? Furthermore, it is not clear how predictive uncertainty information for memory management can be leveraged in the most effective manner. Starting from the intuition that predictive uncertainty provides an idea of the samples' location in the decision space, this work presents an in-depth analysis of different uncertainty estimates and strategies for populating the memory. The investigation provides a better understanding of the characteristics data points should have for alleviating CF. Then, we propose an alternative method for estimating predictive uncertainty via the generalised variance induced by the negative log-likelihood. Finally, we demonstrate that the use of predictive uncertainty measures helps in reducing CF in different settings.},
  archive      = {J_TMLR},
  author       = {Giuseppe Serra and Ben Werner and Florian Buettner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How to leverage predictive uncertainty estimates for reducing catastrophic forgetting in online continual learning},
  url          = {https://openreview.net/forum?id=dczXe0S1oL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking knowledge transfer in learning using privileged information. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dg1tqNIWg3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised machine learning, privileged information (PI) is information that is unavailable at inference, but is accessible during training time. Research on learning using privileged information (LUPI) aims to transfer the knowledge captured in PI onto a model that can perform inference without PI. It seems that this extra bit of information ought to make the resulting model better. However, finding conclusive theoretical or empirical evidence that supports the ability to transfer knowledge using PI has been challenging. In this paper, we critically examine the assumptions underlying existing theoretical analyses and argue that there is little theoretical justification for when LUPI should work. We analyze two main LUPI methods - generalized distillation and marginalization with weight sharing - and reveal that apparent improvements in empirical risk may not directly result from PI. Instead, these improvements often stem from dataset anomalies or modifications in model design misguidedly attributed to PI. Our experiments for a wide variety of application domains further demonstrate that state-of-the-art LUPI approaches fail to effectively transfer knowledge from PI. Thus, we advocate for practitioners to exercise caution when working with PI to avoid unintended inductive biases.},
  archive      = {J_TMLR},
  author       = {Danil Provodin and Bram van den Akker and Christina Katsimerou and Maurits Clemens Kaptein and Mykola Pechenizkiy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking knowledge transfer in learning using privileged information},
  url          = {https://openreview.net/forum?id=dg1tqNIWg3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The time-energy model: Selective time-series forecasting using energy-based models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=iHYCdTAOqF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting is an important task in many domains, including finance, weather prediction, and energy consumption forecasting, and deep learning methods have emerged as the best-performing time-series forecasting methods over the last few years. However, most proposed time-series forecasting models are deterministic and are prone to errors when deployed in production, potentially causing significant losses and penalties when making predictions with low confidence. In this paper, we propose the Time-Energy Model (TEM), a framework that introduces so-called selective time-series forecasting using energy-based models. Selective forecasting estimates model confidence and allows the end-user to selectively reject forecasts while maintaining a desired target coverage. TEM is model-agnostic and can be used to improve forecasting accuracy of any encoder-decoder deterministic time-series forecasting model. TEM is trained using a combination of supervised and self-supervised learning, leveraging excellent single-point prediction accuracy while maintaining the ability to reject forecasts based on model confidence. Experimental results indicate that TEM generalizes well across 5 state-of-the-art deterministic time-series forecasting models and 5 benchmark time-series forecasting datasets. Using selective forecasting, TEM reduces prediction error by up to $49.1\%$ over 5 state-of-the-art deterministic models. Furthermore, TEM has up to $87.0\%$ lower error than selected baseline EBM models, and achieves significantly better performance than state-of-the-art selective deep learning models. Code for the proposed TEM framework is available at https://github.com/JonasBrusokas/Time-Energy-Model},
  archive      = {J_TMLR},
  author       = {Jonas Brusokas and Seshu Tirupathi and Dalin Zhang and Torben Bach Pedersen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The time-energy model: Selective time-series forecasting using energy-based models},
  url          = {https://openreview.net/forum?id=iHYCdTAOqF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards graph foundation models: A study on the generalization of positional and structural encodings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=mSoDRZXsqj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in integrating positional and structural encodings (PSEs) into graph neural networks (GNNs) have significantly enhanced their performance across various graph learning tasks. However, the general applicability of these encodings and their potential to serve as foundational representations for graphs remain uncertain. This paper investigates the fine-tuning efficiency, scalability with sample size, and generalization capability of learnable PSEs across diverse graph datasets. Specifically, we evaluate their potential as universal pre-trained models that can be easily adapted to new tasks with minimal fine-tuning and limited data. Furthermore, we assess the expressivity of the learned representations, particularly, when used to augment downstream GNNs. We demonstrate through extensive benchmarking and empirical analysis that PSEs generally enhance downstream models. However, some datasets may require specific PSE-augmentations to achieve optimal performance. Nevertheless, our findings highlight their significant potential to become integral components of future graph foundation models. We provide new insights into the strengths and limitations of PSEs, contributing to the broader discourse on foundation models in graph learning.},
  archive      = {J_TMLR},
  author       = {Billy Joe Franks and Moshe Eliasof and Semih Cantürk and Guy Wolf and Carola-Bibiane Schönlieb and Sophie Fellenz and Marius Kloft},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards graph foundation models: A study on the generalization of positional and structural encodings},
  url          = {https://openreview.net/forum?id=mSoDRZXsqj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain generalization for time series: Enhancing drilling regression models for stick-slip index prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nNN1pPJRVL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive comparison of domain generalization techniques applied to time series data within a drilling context, focusing on the prediction of a continuous Stick-Slip Index (SSI), a critical metric for assessing torsional downhole vibrations at the drill bit. The study aims to develop a robust regression model that can generalize across domains by training on $60$~ second labeled sequences of $1$~Hz surface drilling data to predict the SSI. The model is tested in wells that are different from those used during training. To fine-tune the model architecture, a grid search approach is employed to optimize key hyperparameters. A comparative analysis of the Adversarial Domain Generalization (ADG), Invariant Risk Minimization (IRM) and baseline models is presented, along with an evaluation of the effectiveness of transfer learning (TL) in improving model performance. The ADG and IRM models achieve performance improvements of $10\%$ and $8\%$, respectively, over the baseline model. Most importantly, severe events are detected $60\%$ of the time, against $20\%$ for the baseline model. Overall, the results indicate that both ADG and IRM models surpass the baseline, with the ADG model exhibiting a slight advantage over the IRM model. Additionally, applying TL to a pre-trained model further improves performance. Our findings demonstrate the potential of domain generalization approaches in drilling applications, with ADG emerging as the most effective approach.},
  archive      = {J_TMLR},
  author       = {Hana YAHIA and Bruno Figliuzzi and Florent Di Meglio and Gerbaud and Stephane Menand and Mohamed MAHJOUB},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Domain generalization for time series: Enhancing drilling regression models for stick-slip index prediction},
  url          = {https://openreview.net/forum?id=nNN1pPJRVL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrated probabilistic forecasts for arbitrary sequences. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nuIUTHGlM5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data streams can change unpredictably due to distribution shifts, feedback loops and adversarial actors, which challenges the validity of forecasts. We present a forecasting framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging the concept of Blackwell approachability from game theory, we introduce a forecasting framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g., classification or bounded regression). We extend this framework to recalibrate existing forecasters, guaranteeing calibration without sacrificing predictive performance. We implement both general-purpose gradient-based algorithms and algorithms optimized for popular special cases of our framework. Empirically, our algorithms improve calibration and downstream decision-making for energy systems.},
  archive      = {J_TMLR},
  author       = {Charles Marx and Volodymyr Kuleshov and Stefano Ermon},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Calibrated probabilistic forecasts for arbitrary sequences},
  url          = {https://openreview.net/forum?id=nuIUTHGlM5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unifying framework for generalised bayesian online learning in non-stationary environments. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=osesw2V10u'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a unifying framework for methods that perform probabilistic online learning in non-stationary environments. We call the framework BONE, which stands for generalised (B)ayesian (O)nline learning in (N)on-stationary (E)nvironments. BONE provides a common structure to tackle a variety of problems, including online continual learning, prequential forecasting, and contextual bandits. The framework requires specifying three modelling choices: (i) a model for measurements (e.g., a neural network), (ii) an auxiliary process to model non-stationarity (e.g., the time since the last changepoint), and (iii) a conditional prior over model parameters (e.g., a multivariate Gaussian). The framework also requires two algorithmic choices, which we use to carry out approximate inference under this framework: (i) an algorithm to estimate beliefs (posterior distribution) about the model parameters given the auxiliary variable, and (ii) an algorithm to estimate beliefs about the auxiliary variable. We show how the modularity of our framework allows for many existing methods to be reinterpreted as instances of BONE, and it allows us to propose new methods. We compare experimentally existing methods with our proposed new method on several datasets, providing insights into the situations that make each method more suitable for a specific task. We provide a Jax open source library to facilitate the adoption of this framework.},
  archive      = {J_TMLR},
  author       = {Gerardo Duran-Martin and Leandro Sánchez-Betancourt and Alex Shestopaloff and Kevin Patrick Murphy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unifying framework for generalised bayesian online learning in non-stationary environments},
  url          = {https://openreview.net/forum?id=osesw2V10u},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlashAttention on a napkin: A diagrammatic approach to deep learning IO-awareness. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pF2ukh7HxA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing deep learning algorithms currently requires slow, manual derivation, potentially leaving much performance untapped. Methods like FlashAttention have achieved a x6 performance improvement over native PyTorch by avoiding unnecessary data transfers, but required three iterations over three years to be developed. Automated compiled methods have consistently lagged behind. This paper extends Neural Circuit Diagrams for deep learning models to consider resource usage and the distribution of tasks across a GPU hierarchy. We show how diagrams can use simple relabellings to derive high-level streaming and tiling optimization strategies along with performance models. We show how this high-level performance model allows the effects of quantization and multi-level GPU hierarchies to be readily considered. We develop a methodology for representing intermediate-level pseudocode with diagrams, allowing hardware-aware algorithms to be derived step-by-step. Finally, we show how our methodology can be used to better understand existing techniques like FlashAttention. This work uses a theoretical framework to link assumptions about GPU behaviour to claims about performance. We aim to lay the groundwork for a scientific approach to GPU optimization where experiments can address clear hypotheses rather than post-hoc rationalizations.},
  archive      = {J_TMLR},
  author       = {Vincent Abbott and Gioele Zardini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlashAttention on a napkin: A diagrammatic approach to deep learning IO-awareness},
  url          = {https://openreview.net/forum?id=pF2ukh7HxA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shedding light on problems with hyperbolic graph learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=rKAkp1f3R7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent papers in the graph machine learning literature have introduced a number of approaches for hyperbolic representation learning. The asserted benefits are improved performance on a variety of graph tasks, node classification and link prediction included. Claims have also been made about the geometric suitability of particular hierarchical graph datasets to representation in hyperbolic space. Despite these claims, our work makes a surprising discovery: when simple Euclidean models with comparable numbers of parameters are properly trained in the same environment, in most cases, they perform as well, if not better, than all introduced hyperbolic graph representation learning models, even on graph datasets previously claimed to be the most hyperbolic as measured by Gromov $\delta$-hyperbolicity (i.e., perfect trees). This observation gives rise to a simple question: how can this be? We answer this question by taking a careful look at the field of hyperbolic graph representation learning as it stands today, and find that a number of results do not diligently present baselines, make faulty modelling assumptions when constructing algorithms, and use misleading metrics to quantify geometry of graph datasets. We take a closer look at each of these three problems, elucidate the issues, perform an analysis of methods, and introduce a parametric family of benchmark datasets to ascertain the applicability of (hyperbolic) graph neural networks.},
  archive      = {J_TMLR},
  author       = {Isay Katsman and Anna Gilbert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shedding light on problems with hyperbolic graph learning},
  url          = {https://openreview.net/forum?id=rKAkp1f3R7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Align and distill: Unifying and improving domain adaptive object detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ssXSrZ94sR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, increasing the diversity of available DAOD benchmarks, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes $\rightarrow$ Foggy Cityscapes, +5.7 AP50 on Sim10k $\rightarrow$ Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC-DAOD. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and method offer a critical reset for DAOD and provide a strong foundation for future research.},
  archive      = {J_TMLR},
  author       = {Justin Kay and Timm Haucke and Suzanne Stathatos and Siqi Deng and Erik Young and Pietro Perona and Sara Beery and Grant Van Horn},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Align and distill: Unifying and improving domain adaptive object detection},
  url          = {https://openreview.net/forum?id=ssXSrZ94sR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random walk diffusion for efficient large-scale graph generation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tSFpsfndE7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs. While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation. Our method encompasses two components in an iterative process of random walk sampling and graph pruning. We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs.},
  archive      = {J_TMLR},
  author       = {Tobias Bernecker and Ghalia Rehawi and Francesco Paolo Casale and Janine Knauer-Arloth and Annalisa Marsico},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Random walk diffusion for efficient large-scale graph generation},
  url          = {https://openreview.net/forum?id=tSFpsfndE7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CroissantLLM: A truly bilingual french-english language model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uA19Xo1o31'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework, and validate 81 % of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work in order to strengthen our understanding of multilinguality in language models.},
  archive      = {J_TMLR},
  author       = {Manuel Faysse and Patrick Fernandes and Nuno M Guerreiro and António Loison and Duarte Miguel Alves and Caio Corrro and Nicolas Boizard and João Alves and Ricardo Rei and Pedro Henrique Martins and Antoni Bigata Casademunt and François Yvon and Andre Martins and Gautier Viaud and CELINE HUDELOT and Pierre Colombo},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CroissantLLM: A truly bilingual french-english language model},
  url          = {https://openreview.net/forum?id=uA19Xo1o31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reheated gradient-based discrete sampling for combinatorial optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uPCvfyr2KP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, gradient-based discrete sampling has emerged as a highly efficient, general-purpose solver for various combinatorial optimization (CO) problems, achieving performance comparable to or surpassing the popular data-driven approaches. However, we identify a critical issue in these methods, which we term ``wandering in contours''. This behavior refers to sampling new different solutions that share very similar objective values for a long time, leading to computational inefficiency and suboptimal exploration of potential solutions. In this paper, we introduce a novel reheating mechanism inspired by the concept of critical temperature and specific heat in physics, aimed at overcoming this limitation. Empirically, our method demonstrates superiority over existing sampling-based and data-driven algorithms across a diverse array of CO problems.},
  archive      = {J_TMLR},
  author       = {Muheng Li and Ruqi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reheated gradient-based discrete sampling for combinatorial optimization},
  url          = {https://openreview.net/forum?id=uPCvfyr2KP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the robustness of kolmogorov-arnold networks: An adversarial perspective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uafxqhImPM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel paradigm for function approximation by leveraging univariate spline-based decompositions inspired by the Kolmogorov–Arnold theorem. Despite their theoretical appeal---particularly the potential for inducing smoother decision boundaries and lower effective Lipschitz constants---their adversarial robustness remains largely unexplored. In this work, we conduct the first comprehensive evaluation of KAN robustness in adversarial settings, focusing on both fully connected (FCKANs) and convolutional (CKANs) instantiations for image classification tasks. Across a wide range of benchmark datasets (MNIST, FashionMNIST, KMNIST, CIFAR-10, SVHN, and a subset of ImageNet), we compare KANs against conventional architectures using an extensive suite of attacks, including white-box methods (FGSM, PGD, C\&W, MIM), black-box approaches (Square Attack, SimBA, NES), and ensemble attacks (AutoAttack). Our experiments reveal that while small- and medium-scale KANs are not consistently more robust than their standard counterparts, large-scale KANs exhibit markedly enhanced resilience against adversarial perturbations. An ablation study further demonstrates that critical hyperparameters---such as number of knots and spline order---significantly influence robustness. Moreover, adversarial training experiments confirm the inherent safety advantages of KAN-based architectures. Overall, our findings provide novel insights into the adversarial behavior of KANs and lay a rigorous foundation for future research on robust, interpretable network designs.},
  archive      = {J_TMLR},
  author       = {Tal Alter and Raz Lapid and Moshe Sipper},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the robustness of kolmogorov-arnold networks: An adversarial perspective},
  url          = {https://openreview.net/forum?id=uafxqhImPM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Respecting the limit: Bayesian optimization with a bound on the optimal value. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=y5Hf0otJLk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world optimization problems, we have prior information about what objective function values are achievable. In this paper, we study the scenario that we have either exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We propose bound-aware Bayesian optimization (BABO), a Bayesian optimization method that uses a new surrogate model and acquisition function to utilize such prior information. We present SlogGP, a new surrogate model that incorporates bound information and adapts the Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety of benchmarks demonstrate the benefit of taking prior information about the optimal value into account, and that the proposed approach significantly outperforms existing techniques. Furthermore, we notice that even in the absence of prior information on the bound, the proposed SlogGP surrogate model still performs better than the standard GP model in most cases, which we explain by its larger expressiveness.},
  archive      = {J_TMLR},
  author       = {Hanyang Wang and Juergen Branke and Matthias Poloczek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Respecting the limit: Bayesian optimization with a bound on the optimal value},
  url          = {https://openreview.net/forum?id=y5Hf0otJLk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lower ricci curvature for efficient community detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EoiuRII7MQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, which makes it well suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through applications on multiple real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.},
  archive      = {J_TMLR},
  author       = {Yun Jin Park and Didong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lower ricci curvature for efficient community detection},
  url          = {https://openreview.net/forum?id=EoiuRII7MQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing maritime trajectory forecasting via h3 index and causal language modelling (CLM). <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tIfS6jyO9f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-temporal problem as a natural language processing problem. The latitude/longitude coordinates of AIS messages are transformed into cell identifiers using the H3 index. Thanks to the pseudo-octal representation, it becomes easier for language models to learn the spatial hierarchy of the H3 index. The method is qualitatively compared to a classical Kalman filter and quantitatively to Seq2Seq and TrAISformer models. The Fréchet distance is introduced as the main evaluation metric for these comparisons. We show that it is possible to predict ship trajectories quite precisely up to 8 hours ahead with 30 minutes of context, using solely GNSS positions, without relying on any additional information such as speed, course, or external conditions — unlike many traditional methods. We demonstrate that this alternative works well enough to predict trajectories worldwide.},
  archive      = {J_TMLR},
  author       = {Nicolas Drapier and Aladine Chetouani and Aurélien Chateigner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing maritime trajectory forecasting via h3 index and causal language modelling (CLM)},
  url          = {https://openreview.net/forum?id=tIfS6jyO9f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning optimizers for communication-efficient learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uRbf9ANAns'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication-efficient variants of SGD, specifically local SGD, have received a great deal of interest in recent years. These approaches compute multiple gradient steps locally on each worker, before averaging model parameters, helping relieve the critical communication bottleneck in distributed deep learning training. Although many variants of these approaches have been proposed, they can sometimes lag behind state-of-the-art adaptive optimizers for deep learning. In this work, we investigate if the recent progress in the emerging area of learned optimizers can potentially close this gap in homogeneous data and homogeneous device settings while remaining communication-efficient. Specifically, we meta-learn how to perform global updates given an update from local SGD iterations. Our results demonstrate that learned optimizers can substantially outperform local SGD and its sophisticated variants while maintaining their communication efficiency. Our learned optimizers can even generalize to unseen and much larger datasets and architectures, including ImageNet and ViTs, and to unseen modalities such as language modeling. We therefore show the potential of learned optimizers for improving communication-efficient distributed learning.},
  archive      = {J_TMLR},
  author       = {Charles-Étienne Joseph and Benjamin Thérien and Abhinav Moudgil and Boris Knyazev and Eugene Belilovsky},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning optimizers for communication-efficient learning},
  url          = {https://openreview.net/forum?id=uRbf9ANAns},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse decomposition of graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xdWP1d8BxI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks.},
  archive      = {J_TMLR},
  author       = {Yaochen Hu and Mai Zeng and Ge Zhang and Pavel Rumiantsev and Liheng Ma and Yingxue Zhang and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparse decomposition of graph neural networks},
  url          = {https://openreview.net/forum?id=xdWP1d8BxI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Which backbone to use: A resource-efficient domain specific comparison for computer vision. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XVSQnnf7QT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For computer vision applications on small, niche, and proprietary datasets, fine-tuning a neural network (NN) backbone that is pre-trained on a large dataset, such as the ImageNet, is a common practice. However, it is unknown whether the backbones that perform well on large datasets, such as vision transformers, are also the right choice for fine-tuning on smaller custom datasets. The present comprehensive analysis aims to aid machine learning practitioners in selecting the most suitable backbone for their specific problem. We systematically evaluated multiple lightweight, pre-trained backbones under consistent training settings across a variety of domains spanning natural, medical, deep space, and remote sensing images. We found that even though attention-based architectures are gaining popularity, they tend to perform poorly compared to CNNs when fine-tuned on small amounts of domain-specific data. We also observed that certain CNN architectures consistently perform better than others when controlled for network size. Our findings provide actionable insights into the performance trade-offs and effectiveness of different backbones for a broad spectrum of computer vision domains.},
  archive      = {J_TMLR},
  author       = {Pranav Jeevan P and Amit Sethi},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Which backbone to use: A resource-efficient domain specific comparison for computer vision},
  url          = {https://openreview.net/forum?id=XVSQnnf7QT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling datasets into less than one image. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qsipSdfWeV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset distillation aims to compress a dataset into a much smaller one so that a model trained on the distilled dataset achieves high accuracy. Current methods frame this as maximizing the distilled classification accuracy for a budget of K distilled images-per-class, where K is a positive integer. In this paper, we push the boundaries of dataset distillation, compressing the dataset into less than an image-per-class. It is important to realize that the meaningful quantity is not the number of distilled images-per-class but the number of distilled pixels-per-dataset. We therefore, propose Poster Dataset Distillation (PoDD), a new approach that distills the entire original dataset into a single poster. The poster approach motivates new technical solutions for creating training images and learnable labels. Our method can achieve comparable or better performance with less than an image-per-class compared to existing methods that use one image-per-class. Specifically, our method establishes a new state-of-the-art performance on CIFAR-10, CIFAR-100, and CUB200 on the well established 1 IPC benchmark, while using as little as 0.3 images-per-class.},
  archive      = {J_TMLR},
  author       = {Asaf Shul and Eliahu Horwitz and Yedid Hoshen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distilling datasets into less than one image},
  url          = {https://openreview.net/forum?id=qsipSdfWeV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using secure aggregation in differentially private federated learning with multiple local steps. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uxyWlXPuIg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential privacy and secure aggregation techniques are often combined with federated learning. However, with fine-grained protection granularities, e.g., with the common sample-level protection, the currently existing techniques generally require the parties to communicate for each local optimization step, if they want to fully benefit from the secure aggregation in terms of the resulting formal privacy guarantees. In this paper, we show how a simple new analysis allows the parties to perform multiple local optimization steps while still benefiting from using secure aggregation. We show that our analysis enables higher utility models with guaranteed privacy protection under limited number of communication rounds.},
  archive      = {J_TMLR},
  author       = {Mikko A. Heikkilä},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using secure aggregation in differentially private federated learning with multiple local steps},
  url          = {https://openreview.net/forum?id=uxyWlXPuIg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Illustrated landmark graphs for long-horizon policy learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0AOUWC4ss8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying learning-based approaches to long-horizon sequential decision-making tasks requires a human teacher to carefully craft reward functions or curate demonstrations to elicit desired behaviors. To simplify this, we first introduce an alternative form of task-specification, Illustrated Landmark Graph (ILG), that represents the task as a directed graph where each vertex corresponds to a region of the state space (a landmark), and each edge represents an easier to achieve sub-task. A landmark in the ILG is conveyed to the agent through a few illustrative examples grounded in the agent’s observation space. Second, we propose ILG-Learn, a human in the loop algorithm that interleaves planning over the ILG and sub-task policy learning. ILG-Learn adaptively plans through the ILG by relying on the human teacher’s feedback to estimate the success rates of learned policies. We conduct experiments on long-horizon block stacking and point maze navigation tasks, and find that our approach achieves considerably higher success rates (~ 50% improvement) compared to hierarchical reinforcement learning and imitation learning baselines. Additionally, we highlight how the flexibility of the ILG specification allows the agent to learn a sequence of sub-tasks that is better suited to its limited capabilities.},
  archive      = {J_TMLR},
  author       = {Christopher Watson and Arjun Krishna and Rajeev Alur and Dinesh Jayaraman},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Illustrated landmark graphs for long-horizon policy learning},
  url          = {https://openreview.net/forum?id=0AOUWC4ss8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Show or tell? effectively prompting vision-language models for semantic segmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0yPWtbR3MC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (VLMs) are increasingly being regarded as foundation models that can be instructed to solve diverse tasks by prompting, without task-specific training. We examine the seemingly obvious question: \emph{how to effectively prompt VLMs for semantic segmentation}. To that end, we systematically evaluate the segmentation performance of several recent models guided by either text or visual prompts on the out-of-distribution MESS dataset collection. We introduce a scalable prompting scheme, \emph{few-shot prompted semantic segmentation}, inspired by open-vocabulary segmentation and few-shot learning. It turns out that VLMs lag far behind specialist models trained for a specific segmentation task, by about 30\% on average on the Intersection-over-Union metric. Moreover, we find that text prompts and visual prompts are complementary: each one of the two modes fails on many examples that the other one can solve. Our analysis suggests that being able to anticipate the most effective prompt modality can lead to a 11\% improvement in performance. Motivated by our findings, we propose PromptMatcher, a remarkably simple training-free baseline that combines both text and visual prompts, achieving state-of-the-art results outperforming the best text-prompted VLM by 2.5\%, and the top visual-prompted VLM by 3.5\% on few-shot prompted semantic segmentation.},
  archive      = {J_TMLR},
  author       = {Niccolò Avogaro and Thomas Frick and Mattia Rigotti and Andrea Bartezzaghi and Filip Janicki and A. Cristiano I. Malossi and Konrad Schindler and Roy Assaf},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Show or tell? effectively prompting vision-language models for semantic segmentation},
  url          = {https://openreview.net/forum?id=0yPWtbR3MC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vector bernstein inequality for self-normalized martingales. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4ZJjr9YbBw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a Bernstein inequality for vector-valued self-normalized martingales. We first give an alternative perspective of the corresponding sub-Gaussian bound due to Abbasi-Yadkori et al. via a PAC-Bayesian argument with Gaussian priors. By instantiating this argument to priors drawn uniformly over well-chosen ellipsoids, we obtain a Bernstein bound.},
  archive      = {J_TMLR},
  author       = {Ingvar Ziemann},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A vector bernstein inequality for self-normalized martingales},
  url          = {https://openreview.net/forum?id=4ZJjr9YbBw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical insights into overparameterized models in multi-task and replay-based continual learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4zGPT0ZwnU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) is a machine learning paradigm that aims to improve the generalization performance of a model on multiple related tasks by training it simultaneously on those tasks. Unlike MTL, where the model has instant access to the training data of all tasks, continual learning (CL) involves adapting to new sequentially arriving tasks over time without forgetting the previously acquired knowledge. Despite the wide practical adoption of CL and MTL and extensive literature on both areas, there remains a gap in the theoretical understanding of these methods when used with overparameterized models such as deep neural networks. This paper studies the overparameterized linear models as a proxy for more complex models. We develop theoretical results describing the effect of various system parameters on the model's performance in an MTL setup. Specifically, we study the impact of model size, dataset size, and task similarity on the generalization error and knowledge transfer. Additionally, we present theoretical results to characterize the performance of replay-based CL models. Our results reveal the impact of buffer size and model capacity on the forgetting rate in a CL setup and help shed light on some of the state-of-the-art CL methods. Finally, through extensive empirical evaluations, we demonstrate that our theoretical findings are also applicable to deep neural networks, offering valuable guidance for designing MTL and CL models in practice.},
  archive      = {J_TMLR},
  author       = {Mohammadamin Banayeeanzade and Mahdi Soltanolkotabi and Mohammad Rostami},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Theoretical insights into overparameterized models in multi-task and replay-based continual learning},
  url          = {https://openreview.net/forum?id=4zGPT0ZwnU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision-focused surrogate modeling for mixed-integer linear optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=A6tOXkkE4Z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all of the original MILP’s linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, the resulting surrogate LPs outperform state-of-the-art neural-network-based optimization proxies.},
  archive      = {J_TMLR},
  author       = {Shivi Dixit and Rishabh Gupta and Qi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decision-focused surrogate modeling for mixed-integer linear optimization},
  url          = {https://openreview.net/forum?id=A6tOXkkE4Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering strong lottery tickets in graph transformers: A path to memory efficient and robust graph learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=B1q9po4LPl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformers (GTs) have recently demonstrated strong capabilities for capturing complex relationships in graph-structured data using global self-attention mechanisms. On the other hand, their high memory requirements during inference remain a challenge for practical deployment. In this study, we investigate the existence of strong lottery tickets (SLTs) — subnetworks within randomly initialized neural networks that can attain competitive accuracy without weight training — in GTs. Previous studies have explored SLTs in message-passing neural networks (MPNNs), showing that SLTs not only exist in MPNNs but also help mitigate over-smoothing problems and improve robustness. However, the potential of SLTs in GTs remains unexplored. With GTs having 4.5$\times$ more parameters than MPNNs, SLTs hold even greater application value in this context. We find that fixed random weights with a traditional SLT search method cannot adapt to imbalances of features in GTs, leading to highly biased attention that destabilizes model performance. To overcome this issue and efficiently search for SLTs, we introduce a novel approach called Adaptive Scaling. We empirically confirm the existence of SLTs within GTs and demonstrate their versatility through extensive experiments across different GT architectures, including NodeFormer, GRIT, and GraphGPS. Our findings demonstrate that SLTs achieve comparable accuracy while reducing memory usage by 2--32$\times$, effectively generalize to out-of-distribution data, and enhance robustness against adversarial perturbations. This work highlights that SLTs offer a resource-efficient approach to improving the scalability, efficiency, and robustness of GTs, with broad implications for applications involving graph data.},
  archive      = {J_TMLR},
  author       = {Hiroaki Ito and Jiale Yan and Hikari Otsuka and Kazushi Kawamura and Masato Motomura and Thiem Van Chu and Daichi Fujiki},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncovering strong lottery tickets in graph transformers: A path to memory efficient and robust graph learning},
  url          = {https://openreview.net/forum?id=B1q9po4LPl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Removing structured noise using diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BvKYsaOVEn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving ill-posed inverse problems requires careful formulation of prior beliefs over the signals of interest and an accurate description of their manifestation into noisy measurements. Handcrafted signal priors based on e.g. sparsity are increasingly replaced by data-driven deep generative models, and several groups have recently shown that state-of-the-art score-based diffusion models yield particularly strong performance and flexibility. In this paper, we show that the powerful paradigm of posterior sampling with diffusion models can be extended to include rich, structured, noise models. To that end, we propose a joint conditional reverse diffusion process with learned scores for the noise and signal-generating distribution. We demonstrate strong performance gains across various inverse problems with structured noise, outperforming competitive baselines using normalizing flows, adversarial networks and various posterior sampling methods for diffusion models. This opens up new opportunities and relevant practical applications of diffusion modeling for inverse problems in the context of non-Gaussian measurement models.},
  archive      = {J_TMLR},
  author       = {Tristan Stevens and Hans van Gorp and Faik C Meral and Junseob Shin and Jason Yu and Jean-luc Robert and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Removing structured noise using diffusion models},
  url          = {https://openreview.net/forum?id=BvKYsaOVEn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-agent cooperation learning through teammate lookahead. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CeNNIQ8GJf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative Multi-Agent Reinforcement Learning (MARL) is a rapidly growing research field that has achieved outstanding results across a variety of challenging cooperation tasks. However, existing MARL algorithms typically overlook the concurrent updates of teammate agents. An agent always learns from the data that it cooperates with one set of (current) teammates, but then practices with another set of (updated) teammates. This phenomenon, termed as ``teammate delay'', leads to a discrepancy between the agent's learning objective and the actual evaluation scenario, which can degrade learning stability and efficiency. In this paper, we tackle this challenge by introducing a lookahead strategy that enables agents to learn to cooperate with predicted future teammates, allowing the explicit awareness of concurrent teammate updates. This lookahead strategy is designed to seamlessly integrate with existing policy-gradient-based MARL methods, enhancing their performance without significant modifications to their underlying structures. The extensive experiments demonstrate the effectiveness of this approach, showing that the lookahead strategy can enhance the cooperation learning efficiency and achieve superior performance over the state-of-the-art MARL algorithms.},
  archive      = {J_TMLR},
  author       = {Feng Chen and Xinwei Chen and Rong-Jun Qin and Cong Guan and Lei Yuan and Zongzhang Zhang and Yang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient multi-agent cooperation learning through teammate lookahead},
  url          = {https://openreview.net/forum?id=CeNNIQ8GJf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-context LLMs struggle with long in-context learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Cw2xlg0e46'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have made significant strides in handling long sequences. Some models like Gemini could even be capable of dealing with millions of tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their true abilities in more challenging, real-world scenarios. We introduce a benchmark (LongICLBench) for long in-context learning in extreme-label classification using six datasets with 28 to 174 classes and input lengths from 2K to 50K tokens. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct predictions. We evaluate on 15 long-context LLMs and find that they perform well on less challenging classification tasks with smaller label space and shorter demonstrations. However, they struggle with more challenging task like Discovery with 174 labels, suggesting a gap in their ability to process long, context-rich sequences. Further analysis reveals a bias towards labels presented later in the sequence and a need for improved reasoning over multiple pieces of information. Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs. We believe LongICLBench could serve as a more realistic evaluation for the future long-context LLMs.},
  archive      = {J_TMLR},
  author       = {Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long-context LLMs struggle with long in-context learning},
  url          = {https://openreview.net/forum?id=Cw2xlg0e46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-modular classification: Learning to generalize with memory replacement. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DcIW0idrg8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel memory-modular learner for image classification that separates knowledge memorization from reasoning. Our model enables effective generalization to new classes by simply replacing the memory contents, without the need for model retraining. Unlike traditional models that encode both world knowledge and task-specific skills into their weights during training, our model stores knowledge in the external memory of web-crawled image and text data. At inference time, the model dynamically selects relevant content from the memory based on the input image, allowing it to adapt to arbitrary classes by simply replacing the memory contents. The key differentiator that our learner meta-learns to perform classification tasks with noisy web data from unseen classes, resulting in robust performance across various classification scenarios. Experimental results demonstrate the promising performance and versatility of our approach in handling diverse classification tasks, including zero-shot/few-shot classification of unseen classes, fine-grained classification, and class-incremental classification.},
  archive      = {J_TMLR},
  author       = {Dahyun Kang and Ahmet Iscen and Eunchan Jo and Sua Choi and Minsu Cho and Cordelia Schmid},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Memory-modular classification: Learning to generalize with memory replacement},
  url          = {https://openreview.net/forum?id=DcIW0idrg8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster tree for nearest neighbor search. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ELtNtkGXoK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-based algorithms are an important and widely used class of algorithms for Nearest Neighbor Search (NNS) with random partition (RP) tree being arguably the most well studied. However, in spite of possessing theoretical guarantees and strong practical performance, a major drawback of the RP tree is its lack of adaptability to the input dataset. Inspired by recent theoretical and practical works for NNS, we attempt to remedy this by introducing *ClusterTree*, a new tree based algorithm. Our approach utilizes randomness as in RP trees while adapting to the underlying cluster structure of the dataset to create well-balanced and meaningful partitions. Experimental evaluations on real world datasets demonstrate improvements over RP trees and other tree based methods for NNS while maintaining efficient construction time. In addition, we show theoretically and empirically that *ClusterTree* finds partitions which are superior to those found by RP trees in preserving the cluster structure of the input dataset.},
  archive      = {J_TMLR},
  author       = {Dan Kushnir and Sandeep Silwal},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cluster tree for nearest neighbor search},
  url          = {https://openreview.net/forum?id=ELtNtkGXoK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsified state-space models are efficient highway networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=G1p0YwrX8X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-space models (SSMs) offer a promising architecture for sequence modeling, providing an alternative to Transformers by replacing expensive self-attention with linear recurrences. In this paper, we propose a simple yet effective trick to enhance SSMs within given computational budgets by sparsifying them. Our intuition is that tokens in SSMs are highly redundant due to gradual recurrent updates, and dense recurrence operations block the delivery of past information. In particular, we observe that upper layers of SSMs tend to be more redundant as they encode global information, while lower layers encode local information. Motivated by this, we introduce Simba, a hierarchical sparsification method for SSMs based on token pruning. Simba sparsifies upper layers more than lower layers, encouraging the upper layers to behave like highways. To achieve this, we propose a novel token pruning criterion for SSMs, measuring the global impact of tokens on the final output by accumulating local recurrences. We demonstrate that Simba outperforms the baseline model, Mamba, with the same FLOPS in various natural language tasks. Moreover, we illustrate the effect of highways, showing that Simba not only enhances efficiency but also improves the information flow across long sequences. Code is available at https://github.com/woominsong/Simba.},
  archive      = {J_TMLR},
  author       = {Woomin Song and Jihoon Tack and Sangwoo Mo and Seunghyuk Oh and Jinwoo Shin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparsified state-space models are efficient highway networks},
  url          = {https://openreview.net/forum?id=G1p0YwrX8X},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient training of multi-task neural solver for combinatorial optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HJbcwRbMQQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently training a multi-task neural solver for various combinatorial optimization problems (COPs) has been less studied so far. Naive application of conventional multi-task learning approaches often falls short in delivering a high-quality, unified neural solver. This deficiency primarily stems from the significant computational demands and a lack of adequate consideration for the complexities inherent in COPs. In this paper, we propose a general and efficient training paradigm to deliver a unified combinarotial multi-task neural solver. To this end, we resort to the theoretical loss decomposition for multiple tasks under an encoder-decoder framework, which enables more efficient training via proper bandit task-sampling algorithms through an intra-task influence matrix. By employing theoretically grounded approximations, our method significantly enhances overall performance, regardless of whether it is within constrained training budgets, across equivalent training epochs, or in terms of generalization capabilities, when compared to conventional training schedules. On the real-world datasets of TSPLib and CVRPLib, our method also achieved the best results compared to single task learning and multi-task learning approaches. Additionally, the influence matrix provides empirical evidence supporting common practices in the field of learning to optimize, further substantiating the effectiveness of our approach. Our code is open-sourced and available at \url{https://github.com/LOGO-CUHKSZ/MTL-COP}.},
  archive      = {J_TMLR},
  author       = {Chenguang Wang and Zhang-Hua Fu and Pinyan Lu and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient training of multi-task neural solver for combinatorial optimization},
  url          = {https://openreview.net/forum?id=HJbcwRbMQQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent representations in networks trained with the forward-forward algorithm. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JhYbGiFn3Y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Backpropagation algorithm has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, the recently introduced Forward-Forward algorithm replaces the forward and backward passes of Backpropagation with two forward passes. In this work, we show that the internal representations obtained by the Forward-Forward algorithm can organise into category-specific ensembles exhibiting high sparsity -- composed of a low number of active units. This situation is reminiscent of what has been observed in cortical sensory areas, where neuronal ensembles are suggested to serve as the functional building blocks for perception and action. Interestingly, while this sparse pattern does not typically arise in models trained with standard Backpropagation, it can emerge in networks trained with Backpropagation on the same objective proposed for the Forward-Forward algorithm.},
  archive      = {J_TMLR},
  author       = {Niccolo Tosato and Lorenzo Basile and Emanuele Ballarin and Giuseppe De Alteriis and Alberto Cazzaniga and Alessio ansuini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent representations in networks trained with the forward-forward algorithm},
  url          = {https://openreview.net/forum?id=JhYbGiFn3Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRAP: Faithful and realistic text-to-image generation with adaptive prompt weighting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MKCwO34oIq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt. However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt's semantics. Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images. In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images. We design an online algorithm to adaptively update each token's weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs. Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&B on the COCO-Subject dataset. Furthermore, through visual comparisons and evaluation of the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances. We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality. We release the code at the following link: https://github.com/LiyaoJiang1998/FRAP/.},
  archive      = {J_TMLR},
  author       = {Liyao Jiang and Negar Hassanpour and Mohammad Salameh and Mohan Sai Singamsetti and Fengyu Sun and Wei Lu and Di Niu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FRAP: Faithful and realistic text-to-image generation with adaptive prompt weighting},
  url          = {https://openreview.net/forum?id=MKCwO34oIq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture-of-transformers: A sparse and scalable architecture for multi-modal foundation models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Nu6N69i8SB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline's performance using only 55.8% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT's practical benefits, achieving dense baseline image quality in 47.2% of the wall-clock time and text quality in 75.6% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs).},
  archive      = {J_TMLR},
  author       = {Weixin Liang and LILI YU and Liang Luo and Srini Iyer and Ning Dong and Chunting Zhou and Gargi Ghosh and Mike Lewis and Wen-tau Yih and Luke Zettlemoyer and Xi Victoria Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture-of-transformers: A sparse and scalable architecture for multi-modal foundation models},
  url          = {https://openreview.net/forum?id=Nu6N69i8SB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daphne: Multi-pass compilation of probabilistic programs into graphical models and neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OGCuDFab4b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daphne is a probabilistic programming system that provides an expressive syntax to denote a large, but restricted, class of probabilistic models. Programs written in the Daphne language can be compiled into a general graph data structure of a corresponding probabilistic graphical model with simple link functions that can easily be implemented in a wide range of programming environments. Alternatively Daphne can also further compile such a graphical model into understandable and vectorized PyTorch code that can be used to train neural networks for inference. The Daphne compiler is structured in a layered multi-pass compiler framework that allows independent and easy extension of the syntax by adding additional passes. It leverages extensive partial evaluation to reduce all syntax extensions to the graphical model at compile time.},
  archive      = {J_TMLR},
  author       = {Christian Dietrich Weilbach and Frank Wood},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Daphne: Multi-pass compilation of probabilistic programs into graphical models and neural networks},
  url          = {https://openreview.net/forum?id=OGCuDFab4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive incentive design for markov decision processes with unknown rewards. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Rwf31BYTAU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incentive design, also known as model design or environment design for Markov decision processes(MDPs), refers to a class of problems in which a leader can incentivize his follower by modifying the follower's reward function, in anticipation that the follower's optimal policy in the resulting MDP can be desirable for the leader's objective. In this work, we propose gradient-ascent algorithms to compute the leader's optimal incentive design, despite the lack of knowledge about the follower's reward function. First, we formulate the incentive design problem as a bi-level optimization problem and demonstrate that, by the softmax temporal consistency between the follower's policy and value function, the bi-level optimization problem can be reduced to single-level optimization, for which a gradient-based algorithm can be developed to optimize the leader's objective. We establish several key properties of incentive design in MDPs and prove the convergence of the proposed gradient-based method. Next, we show that the gradient terms can be estimated from observations of the follower's best response policy, enabling the use of a stochastic gradient-ascent algorithm to compute a locally optimal incentive design without knowing or learning the follower's reward function. Finally, we analyze the conditions under which an incentive design remains optimal for two different rewards which are policy invariant. The effectiveness of the proposed algorithm is demonstrated using a small probabilistic transition system and a stochastic gridworld.},
  archive      = {J_TMLR},
  author       = {Haoxiang Ma and Shuo Han and Ahmed Hemida and Charles A kamhoua and Jie Fu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive incentive design for markov decision processes with unknown rewards},
  url          = {https://openreview.net/forum?id=Rwf31BYTAU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based bayesian inference from privacy protected data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SB7JzhDG45'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern statistical analysis and machine learning applications require training models on sensitive user data. Under a formal definition of privacy protection, differentially private algorithms inject calibrated noise into the confidential data or during the data analysis process to produce privacy-protected datasets or queries. However, restricting access to only privatized data during statistical analysis makes it computationally challenging to make valid statistical inferences. In this work, we propose simulation-based inference methods from privacy-protected datasets. In addition to sequential Monte Carlo approximate Bayesian computation, we adopt neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and with ordinary linear regression models. Illustrating the privacy-utility trade-off, our experiments and analysis demonstrate the necessity and feasibility of designing valid statistical inference procedures to correct for biases introduced by the privacy-protection mechanisms.},
  archive      = {J_TMLR},
  author       = {Yifei Xiong and Nianqiao Ju and Sanguo Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simulation-based bayesian inference from privacy protected data},
  url          = {https://openreview.net/forum?id=SB7JzhDG45},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuron-based explanations of neural networks sacrifice completeness and interpretability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UWNa9Pv6qA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High quality explanations of neural networks (NNs) should exhibit two key properties. Completeness ensures that they accurately reflect a network’s function and interpretability makes them understandable to humans. Many existing methods provide explanations of individual neurons within a network. In this work we provide evidence that for AlexNet pretrained on ImageNet, neuron-based explanation methods sacrifice both completeness and interpretability compared to activation principal components. Neurons are a poor basis for AlexNet embeddings because they don’t account for the distributed nature of these representations. By examining two quantitative measures of completeness and conducting a user study to measure interpretability, we show the most important principal components provide more complete and interpretable explanations than the most important neurons. Much of the activation variance may be explained by examining relatively few high-variance PCs, as opposed to studying every neuron. These principal components also strongly affect network function, and are significantly more interpretable than neurons. Our findings suggest that explanation methods for networks like AlexNet should avoid using neurons as a basis for embeddings and instead choose a basis, such as principal components, which accounts for the high dimensional and distributed nature of a network's internal representations. Interactive demo and code available at https://ndey96.github.io/neuron-explanations-sacrifice.},
  archive      = {J_TMLR},
  author       = {Nolan Simran Dey and Eric Taylor and Alexander Wong and Bryan P. Tripp and Graham W. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neuron-based explanations of neural networks sacrifice completeness and interpretability},
  url          = {https://openreview.net/forum?id=UWNa9Pv6qA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using certified training towards empirical robustness. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UaaT2fI9DC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is arguably the most popular way to provide empirical robustness against specific adversarial examples. While variants based on multi-step attacks incur significant computational overhead, single-step variants are vulnerable to a failure mode known as catastrophic overfitting, which hinders their practical utility for large perturbations. A parallel line of work, certified training, has focused on producing networks amenable to formal guarantees of robustness against any possible attack. However, the wide gap between the best-performing empirical and certified defenses has severely limited the applicability of the latter. Inspired by recent developments in certified training, which rely on a combination of adversarial attacks with network over-approximations, and by the connections between local linearity and catastrophic overfitting, we present experimental evidence on the practical utility and limitations of using certified training towards empirical robustness. We show that, when tuned for the purpose, a recent certified training algorithm can prevent catastrophic overfitting on single-step attacks, and that it can bridge the gap to multi-step baselines under appropriate experimental settings. Finally, we present a conceptually simple regularizer for network over-approximations that can achieve similar effects while markedly reducing runtime.},
  archive      = {J_TMLR},
  author       = {Alessandro De Palma and Serge Durand and Zakaria Chihani and François Terrier and Caterina Urban},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using certified training towards empirical robustness},
  url          = {https://openreview.net/forum?id=UaaT2fI9DC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust symbolic regression for dynamical system identification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZfPbCFZQbx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world complex systems often miss high-fidelity physical descriptions and are typically subject to partial observability. Learning the dynamics of such systems is a challenging and ubiquitous problem, encountered in diverse critical applications which require interpretability and qualitative guarantees.Our paper addresses this problem in the case of sparsely observed probability distribution flows, governed by ODEs. Specifically, we devise a {\it white box} approach -dubbed Symbolic Distribution Flow Learner (\texttt{SDFL})- leveraging symbolic search with a Wasserstein-based loss function, resulting in a robust model-recovery scheme which naturally lends itself to cope with partial observability. Additionally, we furnish the proposed framework with theoretical guarantees on the number of required {\it snapshots} to achieve a certain level of fidelity in the model-discovery. We illustrate the performance of the proposed scheme on the prototypical problem of Kuramoto networks and a standard benchmark of single-cell RNA sequence trajectory data. The numerical experiments demonstrate the competitive performance of \texttt{SDFL} in comparison to the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Ramzi Dakhmouche and Ivan Lunati and Hossein Gorji},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust symbolic regression for dynamical system identification},
  url          = {https://openreview.net/forum?id=ZfPbCFZQbx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDr+: Stabilizing dot-regression with global feature distillation for federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=a6WthNFhL2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution. A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge. Recent studies have tackled the client drift issue by identifying significant divergence in the last linear (classifier) layer. To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective. Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes and underestimate the unobserved classes within each client. Therefore, our goals are twofold: (1) improving local alignment and (2) maintaining the representation of unseen class samples, ensuring that the solution seamlessly incorporates knowledge from individual clients, thus enhancing performance in both global and personalized FL. To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss. FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes. Our empirical results demonstrate that FedDr+ not only outperforms methods with a frozen classifier but also surpasses other state-of-the-art approaches, ensuring robust performance across diverse data distributions.},
  archive      = {J_TMLR},
  author       = {Seongyoon Kim and Minchan Jeong and Sungnyun Kim and Sungwoo Cho and Sumyeong Ahn and Se-Young Yun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedDr+: Stabilizing dot-regression with global feature distillation for federated learning},
  url          = {https://openreview.net/forum?id=a6WthNFhL2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified view of double-weighting for marginal distribution shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aPyJilTiIb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised classification traditionally assumes that training and testing samples are drawn from the same underlying distribution. However, practical scenarios are often affected by distribution shifts, such as covariate and label shifts. Most existing techniques for correcting distribution shifts are based on a reweighted approach that weights training samples, assigning lower relevance to the samples that are unlikely at testing. However, these methods may achieve poor performance when the weights obtained take large values at certain training samples. In addition, in multi-source cases, existing methods do not exploit complementary information among sources, and equally combine sources for all instances. In this paper, we establish a unified learning framework for distribution shift adaptation. We present a double-weighting approach to deal with distribution shifts, considering weight functions associated with both training and testing samples. For the multi-source case, the presented methods assign source-dependent weights for training and testing samples, where weights are obtained jointly using information from all sources. We also present generalization bounds for the proposed methods that show a significant increase in the effective sample size compared with existing approaches. Empirically, the proposed methods achieve enhanced classification performance in both synthetic and empirical experiments.},
  archive      = {J_TMLR},
  author       = {José I. Segovia-Martín and Santiago Mazuelas and Anqi Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified view of double-weighting for marginal distribution shift},
  url          = {https://openreview.net/forum?id=aPyJilTiIb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning population-based methods for reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=d9htascfP8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) algorithms are highly sensitive to their hyperparameter settings. Recently, numerous methods have been proposed to dynamically optimize these hyperparameters. One prominent approach is Population-Based Bandits (PB2), which uses time-varying Gaussian processes (GP) to dynamically optimize hyperparameters with a population of parallel agents. Despite its strong overall performance, PB2 experiences slow starts due to the GP initially lacking sufficient information. To mitigate this issue, we propose four different methods that utilize meta-data from various environments. These approaches are novel in that they adapt meta-learning methods to accommodate the time-varying setting. Among these approaches, MultiTaskPB2, which uses meta-learning for the surrogate model, stands out as the most promising approach. It outperforms PB2 and other baselines in both anytime and final performance across two RL environment families.},
  archive      = {J_TMLR},
  author       = {Johannes Hog and Raghu Rajan and André Biedenkapp and Noor Awad and Frank Hutter and Vu Nguyen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning population-based methods for reinforcement learning},
  url          = {https://openreview.net/forum?id=d9htascfP8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic neural operators for functional uncertainty quantification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gangoPXSRw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators aim to approximate the solution operator of a system of differential equations purely from data. They have shown immense success in modeling complex dynamical systems across various domains. However, the occurrence of uncertainties inherent in both model and data has so far rarely been taken into account\textemdash{}a critical limitation in complex, chaotic systems such as weather forecasting. In this paper, we introduce the probabilistic neural operator (PNO), a framework for learning probability distributions over the output function space of neural operators. PNO extends neural operators with generative modeling based on strictly proper scoring rules, integrating uncertainty information directly into the training process. We provide a theoretical justification for the approach and demonstrate improved performance in quantifying uncertainty across different domains and with respect to different baselines. Furthermore, PNO requires minimal adjustment to existing architectures, shows improved performance for most probabilistic prediction tasks, and leads to well-calibrated predictive distributions and adequate uncertainty representations even for long dynamical trajectories. Implementing our approach into large-scale models for physical applications can lead to improvements in corresponding uncertainty quantification and extreme event identification, ultimately leading to a deeper understanding of the prediction of such surrogate models.},
  archive      = {J_TMLR},
  author       = {Christopher Bülte and Philipp Scholl and Gitta Kutyniok},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Probabilistic neural operators for functional uncertainty quantification},
  url          = {https://openreview.net/forum?id=gangoPXSRw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-NID: Self-attention with normalizing-flow encodings for network intrusion detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hDywd5AbIM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are increasingly adopted to monitor network traffic and detect intrusions. In this work, we introduce SAFE-NID, a novel machine learning approach for real-time packet-level traffic monitoring and intrusion detection that includes a safeguard to detect zero day attacks as out-of-distribution inputs. Unlike traditional models, which falter against zero-day attacks and concept drift, SAFE-NID leverages a lightweight encoder-only transformer architecture combined with a novel normalizing flows-based safeguard. This safeguard not only quantifies uncertainty but also identifies out-of-distribution (OOD) inputs, enabling robust performance in dynamic threat landscapes. Our generative model learns class-conditional representations of the internal features of the deep neural network. We demonstrate the effectiveness of our approach by converting publicly available network flow-level intrusion datasets into packet-level ones. We release the labeled packet-level versions of these datasets with over 50 million packets each and describe the challenges in creating these datasets. We withhold from the training data certain attack categories to simulate zero-day attacks. Existing deep learning models, which achieve an accuracy of over 99% when detecting known attacks, only correctly classify 1% of the novel attacks. Our proposed transformer architecture with normalizing flows model safeguard achieves an area under the receiver operating characteristic curve of over 0.97 in detecting these novel inputs, outperforming existing combinations of neural architectures and model safeguards. The additional latency in processing each packet by the safeguard is a small fraction of the overall inference task. This dramatic improvement in detecting zero-day attacks and distribution shifts emphasizes SAFE-NID’s novelty and utility as a reliable and efficient safety monitoring tool for real-world network intrusion detection.},
  archive      = {J_TMLR},
  author       = {Brian Matejek and Ashish Gehani and Nathaniel D. Bastian and Daniel J Clouse and Bradford J Kline and Susmit Jha},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SAFE-NID: Self-attention with normalizing-flow encodings for network intrusion detection},
  url          = {https://openreview.net/forum?id=hDywd5AbIM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Posterior sampling for reinforcement learning on graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kd6CfmdPfX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Markov Decision Processes (MDPs) exhibit structure in their state and action spaces that is not exploited. We consider the case where the structure can be modelled using a directed acyclic graph (DAG) composed of nodes and edges. In this case, each node has a state, and the state transition dynamics are influenced by the states and actions at its parent nodes. We propose an MDP framework, \emph{Directed Acyclic Markov Decision Process} (DAMDP) that formalises this problem, and we develop algorithms to perform planning and learning. Crucially, DAMDPs retain many of the benefits of MDPs, as we can show that Dynamic Programming can find the optimal policy in known DAMDPs. We also demonstrate how to perform Reinforcement Learning in DAMDPs when the transition probabilities and the reward function are unknown. To this end, we derive a posterior sampling-based algorithm that is able to leverage the graph structure to boost learning efficiency. Moreover, we obtain a theoretical bound on the Bayesian regret for this algorithm, which directly shows the efficiency gain from considering the graph structure. We then conclude by empirically demonstrating that by harnessing the DAMDP, our algorithm outperforms traditional posterior sampling for Reinforcement Learning in both a maximum flow problem and a real-world wind farm optimisation task.},
  archive      = {J_TMLR},
  author       = {Arnaud Robert and Aldo A. Faisal and Ciara Pike-Burke},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Posterior sampling for reinforcement learning on graphs},
  url          = {https://openreview.net/forum?id=kd6CfmdPfX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositionality in time series: A proof of concept using symbolic dynamics and compositional data augmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=msI02LXVJX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates whether time series of natural phenomena can be understood as being generated by sequences of latent states which are ordered in systematic and regular ways. We focus on clinical time series and ask whether clinical measurements can be interpreted as being generated by meaningful physiological states whose succession follows systematic principles. Uncovering the underlying compositional structure will allow us to create synthetic data to alleviate the notorious problem of sparse and low-resource data settings in clinical time series forecasting, and deepen our understanding of clinical data. We start by conceptualizing compositionality for time series as a property of the data generation process, and then study data-driven procedures that can reconstruct the elementary states and composition rules of this process. We evaluate the success of this methods using two empirical tests originating from a domain adaptation perspective. Both tests infer the similarity of the original time series distribution and the synthetic time series distribution from the similarity of expected risk of time series forecasting models trained and tested on original and synthesized data in specific ways. Our experimental results show that the test set performance achieved by training on compositionally synthesized data is comparable to training on original clinical time series data, and that evaluation of models on compositionally synthesized test data shows similar results to evaluating on original test data. In both experiments, performance based on compositionally synthesized data by far surpasses that based on synthetic data that were created by randomization-based data augmentation. An additional downstream evaluation of the prediction task of sequential organ failure assessment (SOFA) scores shows significant performance gains when model training is entirely based on compositionally synthesized data compared to training on original data, with improvements increasing with the size of the synthesized training set.},
  archive      = {J_TMLR},
  author       = {Michael Hagmann and Michael Staniek and Stefan Riezler},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Compositionality in time series: A proof of concept using symbolic dynamics and compositional data augmentation},
  url          = {https://openreview.net/forum?id=msI02LXVJX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplayer information asymmetric contextual bandits. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nMCJ8bFq4B'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-player contextual bandits are a well-studied problem in reinforcement learning that has seen applications in various fields such as advertising, healthcare, and finance. In light of the recent work on information asymmetric bandits, we propose a novel multiplayer information asymmetric contextual bandit framework where there are multiple players each with their own set of actions. At every round, they observe the same context vectors and simultaneously take an action from their own set of actions, giving rise to a joint action. However, upon taking this action the players are subjected to information asymmetry in (1) actions and/or (2) rewards. We designed an algorithm mLinUCB by modifying the classical single-player algorithm LinUCB in \cite{chu2011contextual} to achieve the optimal regret $O(\sqrt{T})$ when only one kind of asymmetry is present. We then propose a novel algorithm ETC that is built on explore-then-commit principles to achieve the same optimal regret when both types of asymmetry are present.},
  archive      = {J_TMLR},
  author       = {William Chang and Yuanhao Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiplayer information asymmetric contextual bandits},
  url          = {https://openreview.net/forum?id=nMCJ8bFq4B},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and robustifying sub-domain alignment for domain adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=oAzu0gzUUb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised domain adaptation (UDA), aligning source and target domains improves the predictive performance of learned models on the target domain. A common methodological improvement in alignment methods is to divide the domains and align sub-domains instead. These sub-domain-based algorithms have demonstrated great empirical success but lack theoretical support. In this work, we establish a rigorous theoretical understanding of the advantages of these methods that have the potential to enhance their overall impact on the field. Our theory uncovers that sub-domain-based methods optimize an error bound that is at least as strong as non-sub-domain-based error bounds and is empirically verified to be much stronger. Furthermore, our analysis indicates that when the marginal weights of sub-domains shift between source and target tasks, the performance of these methods may be compromised. We therefore implement an algorithm to robustify sub-domain alignment for domain adaptation under sub-domain shift, offering a valuable adaptation strategy for future sub-domain-based methods. Empirical experiments across various benchmarks validate our theoretical insights, prove the necessity for the proposed adaptation strategy, and demonstrate the algorithm's competitiveness in handling label shift.},
  archive      = {J_TMLR},
  author       = {Yiling Liu and Juncheng Dong and Ziyang Jiang and Ahmed Aloui and Keyu Li and Michael Hunter Klein and Vahid Tarokh and David Carlson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding and robustifying sub-domain alignment for domain adaptation},
  url          = {https://openreview.net/forum?id=oAzu0gzUUb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship between batch size and number of steps needed for nonconvex optimization of stochastic gradient descent using armijo-line-search learning rate. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pqZ6nOm3WF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While stochastic gradient descent (SGD) can use various learning rates, such as constant or diminishing rates, previous numerical results showed that SGD performs better than other deep-learning optimizers when it uses learning rates given by line search methods. In this paper, we perform a convergence analysis on SGD with a learning rate given by an Armijo line search for nonconvex optimization indicating that the upper bound of the expectation of the squared norm of the full gradient becomes small when the number of steps and the batch size are large. Next, we show that, for SGD with the Armijo-line-search learning rate, the number of steps needed for nonconvex optimization is a monotone decreasing convex function of the batch size; that is, the number of steps needed for nonconvex optimization decreases as the batch size increases. Furthermore, we show that the stochastic first-order oracle (SFO) complexity, which is the stochastic gradient computation cost, is a convex function of the batch size; that is, there exists a critical batch size that minimizes the SFO complexity. Finally, we provide numerical results that support our theoretical results.},
  archive      = {J_TMLR},
  author       = {Yuki Tsukada and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relationship between batch size and number of steps needed for nonconvex optimization of stochastic gradient descent using armijo-line-search learning rate},
  url          = {https://openreview.net/forum?id=pqZ6nOm3WF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information theoretic approach to machine unlearning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=t1utIThKHD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. We explore unlearning from an information theoretic perspective, connecting the influence of a sample to the information gain a model receives by observing it. From this, we derive a simple but principled zero-shot unlearning method based on the geometry of the model. Our approach takes the form of minimising the gradient of a learned function with respect to a small neighbourhood around a target forget point. This induces a smoothing effect, causing forgetting by moving the boundary of the classifier. We explore the intuition behind why this approach can jointly unlearn forget samples while preserving general model performance through a series of low-dimensional experiments. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method is competitive with state-of-the-art performance under the strict constraints of zero-shot unlearning.},
  archive      = {J_TMLR},
  author       = {Jack Foster and Kyle Fogarty and Stefan Schoepf and Zack Dugue and Cengiz Oztireli and Alexandra Brintrup},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An information theoretic approach to machine unlearning},
  url          = {https://openreview.net/forum?id=t1utIThKHD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence learning in complex systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tUnyInYbjK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High sample complexity hampers the successful application of reinforcement learning methods, especially in real-world problems where simulating complex dynamics is computationally demanding. Influence-based abstraction (IBA) was proposed to mitigate this issue by breaking down the global model of large-scale distributed systems, such as traffic control problems, into small local sub-models. Each local model includes only a few state variables and a representation of the influence exerted by the external portion of the system. This approach allows converting a complex simulator into local lightweight simulators, enabling more effective applications of planning and reinforcement learning methods. However, the effectiveness of IBA critically depends on the ability to accurately approximate the influence of each local model. While there are a few examples showing promising results in benchmark problems, the question of whether this approach is feasible in more practical scenarios remains open. In this work, we take steps towards addressing this question by conducting an extensive empirical study of learning models for influence approximations in various realistic domains, and evaluating how these models generalize over long horizons. We find that learning the influence is often a manageable learning task, even for complex and large systems. Additionally, we demonstrate the efficacy of the approximation models for long-horizon problems. By using short trajectories, we can learn accurate influence approximations for much longer horizons.},
  archive      = {J_TMLR},
  author       = {Elena Congeduti and roberto rocchetta and Frans A Oliehoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Influence learning in complex systems},
  url          = {https://openreview.net/forum?id=tUnyInYbjK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building blocks for robust and effective semi-supervised real-world object detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vRYt8QLKqK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) based on pseudo-labeling significantly reduces dependence on large labeled datasets by effectively leveraging both labeled and unlabeled data. However, real-world applications of SSOD often face critical challenges, including class imbalance, label noise, and labeling errors. We present an in-depth analysis of SSOD under real-world conditions, uncovering causes of suboptimal pseudo-labeling and key trade-offs between label quality and quantity. Based on our findings, we propose four building blocks that can be seamlessly integrated into an SSOD framework. Rare Class Collage (RCC): a data augmentation method that enhances the representation of rare classes by creating collages of rare objects. Rare Class Focus (RCF): a stratified batch sampling strategy that ensures a more balanced representation of all classes during training. Ground Truth Label Correction (GLC): a label refinement method that identifies and corrects false, missing, and noisy ground truth labels by leveraging the consistency of teacher model predictions. Pseudo-Label Selection (PLS): a selection method for removing low-quality pseudo-labeled images, guided by a novel metric estimating the missing detection rate while accounting for class rarity. We validate our methods through comprehensive experiments on autonomous driving datasets, resulting in up to 6% increase in SSOD performance. Overall, our investigation and novel, data-centric, and broadly applicable building blocks enable robust and effective SSOD in complex, real-world scenarios. Code is available at https://mos-ks.github.io/publications.},
  archive      = {J_TMLR},
  author       = {Moussa Kassem Sbeyti and Nadja Klein and Azarm Nowzad and Fikret Sivrikaya and Sahin Albayrak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Building blocks for robust and effective semi-supervised real-world object detection},
  url          = {https://openreview.net/forum?id=vRYt8QLKqK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Salsa fresca: Angular embeddings and pre-training for ML attacks on learning with errors. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=w4nd5695sq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods---better preprocessing, angular embeddings and model pre-training---to improve these attacks, speeding up preprocessing by $25\times$ and improving model sample efficiency by $10\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed, albeit for larger modulus $q$. Our ML-based approach is the only attack which has successfully recovered secrets for these parameters.},
  archive      = {J_TMLR},
  author       = {Samuel Stevens and Emily Wenger and Cathy Yuanchen Li and Niklas Nolte and Eshika Saxena and Francois Charton and Kristin E. Lauter},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Salsa fresca: Angular embeddings and pre-training for ML attacks on learning with errors},
  url          = {https://openreview.net/forum?id=w4nd5695sq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A limitation on black-box dynamics approaches to reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wPHVijYksq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a fundamental limitation on the computational efficiency of a large class of Reinforcement Learning (RL) methods. This limitation applies to model-free RL methods as well as some model-based methods, such as AlphaZero. We provide a formalism that describes this class and present a family of RL problems provably intractable for these methods. Conversely, the problems in the family can be efficiently solved by toy methods. We identify several types of algorithms proposed in the literature that can avoid our limitation, including algorithms that construct an inverse dynamics model, and planning algorithms that leverage an explicit model of the dynamics.},
  archive      = {J_TMLR},
  author       = {Brieuc Pinon and Raphael Jungers and Jean-Charles Delvenne},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A limitation on black-box dynamics approaches to reinforcement learning},
  url          = {https://openreview.net/forum?id=wPHVijYksq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What’s left after distillation? how knowledge transfer impacts fairness and bias. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xBbj46Y2fN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Distillation is a commonly used Deep Neural Network (DNN) compression method, which often maintains overall generalization performance. However, we show that even for balanced image classification datasets, such as CIFAR-100, Tiny ImageNet and ImageNet, as many as 41% of the classes are statistically significantly affected by distillation when comparing class-wise accuracy (i.e. class bias) between a teacher/distilled student or distilled student/non-distilled student model. Changes in class bias are not necessarily an undesirable outcome when considered outside of the context of a model’s usage. Using two common fairness metrics, Demographic Parity Difference (DPD) and Equalized Odds Difference (EOD) on models trained with the CelebA, Trifeature, and HateXplain datasets, our results suggest that increasing the distillation temperature improves the distilled student model’s fairness, and the distilled student fairness can even surpass the fairness of the teacher model at high temperatures. Additionally, we examine individual fairness, ensuring similar instances receive similar predictions. Our results confirm that higher temperatures also improve the distilled student model’s individual fairness. This study highlights the uneven effects of distillation on certain classes and its potentially significant role in fairness, emphasizing that caution is warranted when using distilled models for sensitive application domains.},
  archive      = {J_TMLR},
  author       = {Aida Mohammadshahi and Yani Ioannou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What’s left after distillation? how knowledge transfer impacts fairness and bias},
  url          = {https://openreview.net/forum?id=xBbj46Y2fN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting sub-population specific viral evolution. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Mae23iEqPS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the change in the distribution of viral variants is crucial for therapeutic design and disease surveillance. This task poses significant modeling challenges due to the sharp differences in virus distributions across sub-populations (e.g., countries) and their dynamic interactions. Existing machine learning approaches that model the variant distribution as a whole are incapable of making location-specific predictions and ignore transmissions that shape the viral landscape. In this paper, we propose a sub-population specific protein evolution model, which predicts the time-resolved distributions of viral proteins in different locations. The algorithm explicitly models the transmission rates between sub-populations and learns their interdependence from data. The change in protein distributions across all sub-populations is defined through a linear ordinary differential equation (ODE) parametrized by transmission rates. Solving this ODE yields the likelihood of a given protein occurring in particular sub-populations. Multi-year evaluation on both SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms baselines in accurately predicting distributions of viral proteins across continents and countries. We also find that the transmission rates learned from data are consistent with the transmission pathways discovered by retrospective phylogenetic analysis.},
  archive      = {J_TMLR},
  author       = {Wenxian Shi and Menghua Wu and Regina Barzilay},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predicting sub-population specific viral evolution},
  url          = {https://openreview.net/forum?id=Mae23iEqPS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposing the dark matter of sparse autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sXq3Wb3vef'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse autoencoders (SAEs) are a promising technique for decomposing language model activations into interpretable linear features. However, current SAEs fall short of completely explaining model performance, resulting in ``dark matter'': unexplained variance in activations. This work investigates dark matter as an object of study in its own right. Surprisingly, we find that much of SAE dark matter---about half of the error vector itself and $>90\% $ of its norm---can be linearly predicted from the initial activation vector. Additionally, we find that the scaling behavior of SAE error norms at a per token level is remarkably predictable: larger SAEs mostly struggle to reconstruct the same contexts as smaller SAEs. We build on the linear representation hypothesis to propose models of activations that might lead to these observations, including postulating a new type of ``introduced error''; these insights imply that the part of the SAE error vector that cannot be linearly predicted (``nonlinear'' error) might be fundamentally different from the linearly predictable component. To validate this hypothesis, we empirically analyze nonlinear SAE error and show that 1) it contains fewer not yet learned features, 2) SAEs trained on it are quantitatively worse, 3) it helps predict SAE per-token scaling behavior, and 4) it is responsible for a proportional amount of the downstream increase in cross entropy loss when SAE activations are inserted into the model. Finally, we examine two methods to reduce nonlinear SAE error: inference time gradient pursuit, which leads to a very slight decrease in nonlinear error, and linear transformations from earlier layer SAE outputs, which leads to a larger reduction.},
  archive      = {J_TMLR},
  author       = {Joshua Engels and Logan Riggs Smith and Max Tegmark},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decomposing the dark matter of sparse autoencoders},
  url          = {https://openreview.net/forum?id=sXq3Wb3vef},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on the honesty of large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FJgtVfUxLQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Honesty is a fundamental principle for aligning large language models (LLMs) with human values, requiring these models to recognize what they know and don't know and be able to faithfully express their knowledge. Despite promising, current LLMs still exhibit significant dishonest behaviors, such as confidently presenting wrong answers or failing to express what they know. In addition, research on the honesty of LLMs also faces challenges, including varying definitions of honesty, difficulties in distinguishing between known and unknown knowledge, and a lack of comprehensive understanding of related research. To address these issues, we provide a survey on the honesty of LLMs, covering its clarification, evaluation approaches, and strategies for improvement. Moreover, we offer insights for future research, aiming to inspire further exploration in this important area.},
  archive      = {J_TMLR},
  author       = {Siheng Li and Cheng Yang and Taiqiang Wu and Chufan Shi and Yuji Zhang and Xinyu Zhu and Zesen Cheng and Deng Cai and Mo Yu and Lemao Liu and Jie Zhou and Yujiu Yang and Ngai Wong and Xixin Wu and Wai Lam},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey on the honesty of large language models},
  url          = {https://openreview.net/forum?id=FJgtVfUxLQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). $f$-divergence policy optimization in fully decentralized cooperative MARL. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Wj8yFjIpom'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Independent learning is a straightforward solution for fully decentralized learning in cooperative multi-agent reinforcement learning (MARL). The study of independent learning has a history of decades, and the representatives, such as independent Q-learning and independent PPO, can achieve good performances on several benchmarks. However, most independent learning algorithms lack convergence guarantees or theoretical support. In this paper, we propose a general formulation of independent policy optimization, $f$-divergence policy optimization. We hope that a more general policy optimization formulation will provide deeper insights into fully decentralized learning. We demonstrate the generality of this formulation and analyze its limitations. Based on this formulation, we further propose a novel independent learning algorithm, TVPO, which theoretically guarantees convergence. Empirically, we demonstrate that TVPO outperforms state-of-the-art fully decentralized learning methods on three popular cooperative MARL benchmarks, thereby verifying the efficacy of TVPO.},
  archive      = {J_TMLR},
  author       = {Kefan Su and Zongqing Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {$f$-divergence policy optimization in fully decentralized cooperative MARL},
  url          = {https://openreview.net/forum?id=Wj8yFjIpom},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implicit bias and fast convergence rates for self-attention. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pKilnjQsb0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fundamental optimization principles of self-attention, the defining mechanism of transformers, by analyzing the implicit bias of gradient-based optimizers in training a self-attention layer with a linear decoder in binary classification. Building on prior studies in linear logistic regression, recent findings demonstrate that the key-query matrix $W_t$ from gradient-descent (GD) converges in direction towards $W_{mm}$, which maximizes the margin between optimal and non-optimal tokens across sequences. However, this convergence is local, dependent on initial conditions, only holds asymptotically as the number of iterations increases, and leaves questions about the potential benefits of adaptive step-size rules unaddressed. To bridge this gap, we first establish scenarios for which convergence is provably global. We then analyze two adaptive step-size strategies: normalized GD and Polyak step-size, demonstrating finite-time convergence rates for $W_t$ to $W_{mm}$, and quantifying the sparsification rate of the attention map. These findings not only show that these strategies can accelerate parameter convergence over standard GD in a non-convex setting but also deepen the understanding of the implicit bias in self-attention, linking it more closely to the phenomena observed in linear logistic regression despite its intricate non-convex nature.},
  archive      = {J_TMLR},
  author       = {Bhavya Vasudeva and Puneesh Deora and Christos Thrampoulidis},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Implicit bias and fast convergence rates for self-attention},
  url          = {https://openreview.net/forum?id=pKilnjQsb0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-language models provide promptable representations for reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vQDKYYuqWA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can quickly learn new behaviors by leveraging background world knowledge. In contrast, agents trained with reinforcement learning (RL) typically learn behaviors from scratch. We thus propose a novel approach that uses the vast amounts of general and indexable world knowledge encoded in vision-language models (VLMs) pre-trained on Internet-scale data for embodied RL. We initialize policies with VLMs by using them as promptable representations: embeddings that encode semantic features of visual observations based on the VLM's internal knowledge and reasoning capabilities, as elicited through prompts that provide task context and auxiliary information. We evaluate our approach on visually-complex, long horizon RL tasks in Minecraft and robot navigation in Habitat. We find that our policies trained on embeddings from off-the-shelf, general-purpose VLMs outperform equivalent policies trained on generic, non-promptable image embeddings. We also find our approach outperforms instruction-following methods and performs comparably to domain-specific embeddings. Finally, we show that our approach can use chain-of-thought prompting to produce representations of common-sense semantic reasoning, improving policy performance in novel scenes by 1.5 times.},
  archive      = {J_TMLR},
  author       = {William Chen and Oier Mees and Aviral Kumar and Sergey Levine},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Vision-language models provide promptable representations for reinforcement learning},
  url          = {https://openreview.net/forum?id=vQDKYYuqWA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lognormal mutations and their use in detecting surreptitious fake images. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0RJvZY0h6O'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases, adversarial attacks against fake detectors employ algorithms specifically crafted for automatic image classifiers. These algorithms perform well, thanks to an excellent ad hoc distribution of initial attacks. However, these attacks are easily detected due to their specific initial distribution. Consequently, we explore alternative black-box attacks inspired by generic black-box optimization tools, particularly focusing on the \lognormal{} algorithm that we successfully extend to attack fake detectors. Moreover, we demonstrate that this attack evades detection by neural networks trained to flag classical adversarial examples. Therefore, we train more general models capable of identifying a broader spectrum of attacks, including classical black-box attacks designed for images, black-box attacks driven by classical optimization, and no-box attacks. By integrating these attack detection capabilities with fake detectors, we develop more robust and effective fake detection systems.},
  archive      = {J_TMLR},
  author       = {Olivier Teytaud and Mariia Zameshina and Tom Sander and Pierre Fernandez and Furong Ye and Laurent Najman and Thomas Bäck and Ismail Labiad},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lognormal mutations and their use in detecting surreptitious fake images},
  url          = {https://openreview.net/forum?id=0RJvZY0h6O},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss-to-loss prediction: Scaling laws for all datasets. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1Avb4jYjLb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While scaling laws provide a reliable methodology for predicting train loss across compute scales for a single data distribution, less is known about how these predictions should change as we change the distribution. In this paper, we derive a strategy for predicting one loss from another and apply it to predict across different pre-training datasets and from pre-training data to downstream task data. Our predictions extrapolate well even at 20x the largest FLOP budget used to fit the curves. More precisely, we find that there are simple shifted power law relationships between (1) the train losses of two models trained on two separate datasets when the models are paired by training compute (train-to-train), (2) the train loss and the test loss on any downstream distribution for a single model (train-to-test), and (3) the test losses of two models trained on two separate train datasets (test-to-test). The results hold up for pre-training datasets that differ substantially (some are entirely code and others have no code at all) and across a variety of downstream tasks. Finally, we find that in some settings these shifted power law relationships can yield more accurate predictions than extrapolating single-dataset scaling laws.},
  archive      = {J_TMLR},
  author       = {David Brandfonbrener and Nikhil Anand and Nikhil Vyas and Eran Malach and Sham M. Kakade},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Loss-to-loss prediction: Scaling laws for all datasets},
  url          = {https://openreview.net/forum?id=1Avb4jYjLb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust high-dimensional mean estimation with low data size, an empirical study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=1QeI99nH9k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust statistics aims to compute quantities to represent data where a fraction of it may be arbitrarily corrupted. The most essential statistic is the mean, and in recent years, there has been a flurry of theoretical advancement for efficiently estimating the mean in high dimensions on corrupted data. While several algorithms have been proposed that achieve near-optimal error, they all rely on large data size requirements as a function of dimension. In this paper, we perform an extensive experimentation over various mean estimation techniques where data size might not meet this requirement due to the high-dimensional setting. For data with inliers generated from a Gaussian with known covariance, we find experimentally that several robust mean estimation techniques can practically improve upon the sample mean, with the quantum entropy scaling approach from Dong \etal (NeurIPS 2019) performing consistently the best. However, this consistent improvement is conditioned on a couple of simple modifications to how the steps to prune outliers work in the high-dimension low-data setting, and when the inliers deviate significantly from Gaussianity. In fact, with these modifications, they are typically able to achieve roughly the same error as taking the sample mean of the uncorrupted inlier data, even with very low data size. In addition to controlled experiments on synthetic data, we also explore these methods on large language models, deep pretrained image models, and non-contextual word embedding models that do not necessarily have an inherent Gaussian distribution. Yet, in these settings, a mean point of a set of embedded objects is a desirable quantity to learn, and the data exhibits the high-dimension low-data setting studied in this paper. We show both the challenges of achieving this goal, and that our updated robust mean estimation methods can provide significant improvement over using just the sample mean. We additionally publish a library of Python implementations of robust mean estimation algorithms, allowing practitioners and researchers to apply these techniques and to perform further experimentation.},
  archive      = {J_TMLR},
  author       = {Cullen Anderson and Jeff M. Phillips},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust high-dimensional mean estimation with low data size, an empirical study},
  url          = {https://openreview.net/forum?id=1QeI99nH9k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DivIL: Unveiling and addressing over-invariance for out-of- distribution generalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2Zan4ATYsh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution generalization is a common problem that expects the model to perform well in the different distributions even far from the train data. A popular approach to addressing this issue is invariant learning (IL), in which the model is compiled to focus on invariant features instead of spurious features by adding strong constraints during training. However, there are some potential pitfalls of strong invariant constraints. Due to the limited number of diverse environments and over-regularization in the feature space, it may lead to a loss of important details in the invariant features while alleviating the spurious correlations, namely the over-invariance, which can also degrade the generalization performance. We theoretically define the over-invariance and observe that this issue occurs in various classic IL methods. To alleviate this issue, we propose a simple approach Diverse Invariant Learning (DivIL) by adding the unsupervised contrastive learning and the random masking mechanism compensatory for the invariant constraints, which can be applied to various IL methods. Furthermore, we conduct experiments across multiple modalities across 12 datasets and 6 classic models, verifying our over-invariance insight and the effectiveness of our DivIL framework. Our code is available at https://github.com/kokolerk/DivIL.},
  archive      = {J_TMLR},
  author       = {Jiaqi WANG and Yuhang Zhou and Zhixiong Zhang and Qiguang Chen and Yongqiang Chen and James Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DivIL: Unveiling and addressing over-invariance for out-of- distribution generalization},
  url          = {https://openreview.net/forum?id=2Zan4ATYsh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging causality, individual fairness, and adversarial robustness in the absence of structural causal model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2nRcWy3RLM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the essential need for comprehensive considerations in responsible AI, factors such as robustness, fairness, and causality are often studied in isolation. Adversarial perturbation, used to identify vulnerabilities in models, and individual fairness, aiming for equitable treatment of similar individuals, despite initial differences, both depend on metrics to generate comparable input data instances. Previous attempts to define such joint metrics often lack general assumptions about data and were unable to reflect counterfactual proximity. To address this, our paper introduces a \emph{causal fair metric} formulated based on causal structures encompassing sensitive attributes and protected causal perturbation. To enhance the practicality of our metric, we propose metric learning as a method for metric estimation and deployment in real-world problems in the absence of structural causal models. We also demonstrate the applications of the causal fair metric in classifiers. Empirical evaluation of real-world and synthetic datasets illustrates the effectiveness of our proposed metric in achieving an accurate classifier with fairness, resilience to adversarial perturbations, and a nuanced understanding of causal relationships.},
  archive      = {J_TMLR},
  author       = {Ahmad Reza Ehyaei and Golnoosh Farnadi and Samira Samadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging causality, individual fairness, and adversarial robustness in the absence of structural causal model},
  url          = {https://openreview.net/forum?id=2nRcWy3RLM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective prediction via training dynamics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=2wgnepQjyF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Prediction is the task of rejecting inputs a model would predict incorrectly on. This involves a trade-off between input space coverage (how many data points are accepted) and model utility (how good is the performance on accepted data points). Current methods for selective prediction typically impose constraints on either the model architecture or the optimization objective; this inhibits their usage in practice and introduces unknown interactions with pre-existing loss functions. In contrast to prior work, we show that state-of-the-art se- lective prediction performance can be attained solely from studying the (discretized) training dynamics of a model. We propose a general framework that, given a test input, monitors metrics capturing the instability of predictions from intermediate models (i.e., checkpoints) obtained during training w.r.t. the final model’s prediction. In particular, we reject data points exhibiting too much disagreement with the final prediction at late stages in training. The proposed rejection mechanism is domain-agnostic (i.e., it works for both discrete and real-valued prediction) and can be flexibly combined with existing selective prediction approaches as it does not require any train-time modifications. Our experimental evaluation on image classification, regression, and time series problems shows that our method beats past state-of-the-art accuracy/utility trade-offs on typical selective prediction benchmarks.},
  archive      = {J_TMLR},
  author       = {Stephan Rabanser and Anvith Thudi and Kimia Hamidieh and Adam Dziedzic and Israfil Bahceci and Akram Bin Sediq and HAMZA SOKUN and Nicolas Papernot},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Selective prediction via training dynamics},
  url          = {https://openreview.net/forum?id=2wgnepQjyF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APR-CNN: Convolutional neural networks for the adaptive particle representation of large microscopy images. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=5qKI2dkrjL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present APR-CNN, a novel class of convolutional neural networks designed for efficient and scalable three-dimensional microscopy image analysis. APR-CNNs operate natively on a sparse, multi-resolution image representation known as the Adaptive Particle Representation (APR). This significantly reduces memory and compute requirements compared to traditional pixel-based CNNs. We introduce APR-native layers for convolution, pooling, and upsampling, along with hybrid architectures that combine APR and pixel layers to balance accuracy and computational efficiency. We show in benchmarks that APR-CNNs achieve comparable segmentation accuracy to pixel-based CNNs while drastically reducing memory usage and inference time. We further showcase the potential of APR-CNNs in large-scale volumetric image analysis, reducing inference times from weeks to days. This opens up new avenues for applying deep learning to large, high-resolution, three-dimensional biomedical datasets with constrained computational resources.},
  archive      = {J_TMLR},
  author       = {Joel Jonsson and Bevan Leslie Cheeseman and Ivo Sbalzarini},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {APR-CNN: Convolutional neural networks for the adaptive particle representation of large microscopy images},
  url          = {https://openreview.net/forum?id=5qKI2dkrjL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimPLR: A simple and plain transformer for efficient object detection and segmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6LO1y8ZE0F'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing hand-crafted components and simplifying the architecture with transformers, multi-scale feature maps and pyramid designs remain a key factor for their empirical success. In this paper, we show that shifting the multiscale inductive bias into the attention mechanism can work well, resulting in a plain detector ‘SimPLR’ whose backbone and detection head are both non-hierarchical and operate on single-scale features. We find through our experiments that SimPLR with scale-aware attention is plain and simple architecture, yet competitive with multi-scale vision transformer alternatives. Compared to the multi-scale and single-scale state-of-the-art, our model scales better with bigger capacity (self-supervised) models and more pre-training data, allowing us to report a consistently better accuracy and faster runtime for object detection, instance segmentation, as well as panoptic segmentation. Code is released at \url{https://github.com/kienduynguyen/SimPLR}.},
  archive      = {J_TMLR},
  author       = {Duy Kien Nguyen and Martin R. Oswald and Cees G. M. Snoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SimPLR: A simple and plain transformer for efficient object detection and segmentation},
  url          = {https://openreview.net/forum?id=6LO1y8ZE0F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair principal component analysis (PCA): Minorization-maximization algorithms for fair PCA, fair robust PCA and fair sparse PCA. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=6jTQrr3APY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new iterative algorithm to solve the fair PCA (FPCA) problem. We start with the max-min fair PCA formulation originally proposed in \cite{samadi1} and derive a simple and efficient iterative algorithm which is based on the minorization-maximization (MM) approach. The proposed algorithm relies on the relaxation of a semi-orthogonality constraint which is proved to be tight at every iteration of the algorithm. The vanilla version of the proposed algorithm requires solving a semi-definite program (SDP) at every iteration, which can be further simplified to a quadratic program by formulating the dual of the surrogate maximization problem. We also propose two important reformulations of the fair PCA problem: a) fair robust PCA - which can handle outliers in the data, and b) fair sparse PCA - which can enforce sparsity on the estimated fair principal components. The proposed algorithms are computationally efficient and monotonically increase their respective design objectives at every iteration. An added feature of the proposed algorithms is that they do not require the selection of any hyperparameter (except for the fair sparse PCA case where a penalty parameter that controls the sparsity has to be chosen by the user). We numerically compare the performance of the proposed methods with two of the state-of-the-art approaches on synthetic data sets and real-life data sets.},
  archive      = {J_TMLR},
  author       = {Prabhu babu and Petre Stoica and Astha Saini},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fair principal component analysis (PCA): Minorization-maximization algorithms for fair PCA, fair robust PCA and fair sparse PCA},
  url          = {https://openreview.net/forum?id=6jTQrr3APY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining explainability: Recommendations for effective use of concept activation vectors. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=7CUluLpLxV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based explanations translate the internal representations of deep learning models into a language that humans are familiar with: concepts. One popular method for finding concepts is Concept Activation Vectors (CAVs), which are learnt using a probe dataset of concept exemplars. In this work, we investigate three properties of CAVs: (1) inconsistency across layers, (2) entanglement with other concepts, and (3) spatial dependency. Each property provides both challenges and opportunities in interpreting models. We introduce tools designed to detect the presence of these properties, provide insight into how each property can lead to misleading explanations, and provide recommendations to mitigate their impact. To demonstrate practical applications, we apply our recommendations to a melanoma classification task, showing how entanglement can lead to uninterpretable results and that the choice of negative probe set can have a substantial impact on the meaning of a CAV. Further, we show that understanding these properties can be used to our advantage. For example, we introduce spatially dependent CAVs to test if a model is translation invariant with respect to a specific concept and class. Our experiments are performed on natural images (ImageNet), skin lesions (ISIC 2019), and a new synthetic dataset, Elements. Elements is designed to capture a known ground truth relationship between concepts and classes. We release this dataset to facilitate further research in understanding and evaluating interpretability methods.},
  archive      = {J_TMLR},
  author       = {Angus Nicolson and Lisa Schut and Alison Noble and Yarin Gal},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining explainability: Recommendations for effective use of concept activation vectors},
  url          = {https://openreview.net/forum?id=7CUluLpLxV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph neural networks through the lens of message passing: A common perspective to homophily and architecture design. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8rxtL0kZnX'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current learning methodologies and benchmarking datasets in the hypergraph realm are obtained by \emph{lifting} procedures from their graph analogs, leading to overshadowing specific characteristics of hypergraphs. This paper attempts to confront some pending questions in that regard: Q1 Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HNNs)? Q2 How do models that employ unique characteristics of higher-order networks perform compared to lifted models? Q3 Do well-established hypergraph datasets provide a meaningful benchmark for HNNs? To address them, we first introduce a novel conceptualization of homophily in higher-order networks based on a Message Passing (MP) scheme, unifying both the analytical examination and the modeling of higher-order networks. Further, we investigate some natural strategies for processing higher-order structures within HNNs (such as keeping hyperedge-dependent node representations or performing node/hyperedge stochastic samplings), leading us to the most general MP formulation up to date --MultiSet. Finally, we conduct an extensive set of experiments that contextualize our proposals.},
  archive      = {J_TMLR},
  author       = {Lev Telyatnikov and Maria Sofia Bucarelli and Guillermo Bernardez and Olga Zaghen and Simone Scardapane and Pietro Lio},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hypergraph neural networks through the lens of message passing: A common perspective to homophily and architecture design},
  url          = {https://openreview.net/forum?id=8rxtL0kZnX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially personalized federated learning: Breaking the curse of data heterogeneity. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8tMMCf4YYn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a partially personalized formulation of Federated Learning (FL) that strikes a balance between the flexibility of personalization and cooperativeness of global training. In our framework, we split the variables into global parameters, which are shared across all clients, and individual local parameters, which are kept private. We prove that under the right split of parameters, it is possible to find global parameters that allow each client to fit their data perfectly, and refer to the obtained problem as overpersonalized. For instance, the shared global parameters can be used to learn good data representations, whereas the personalized layers are fine-tuned for a specific client. Moreover, we present a simple algorithm for the partially personalized formulation that offers significant benefits to all clients. In particular, it breaks the curse of data heterogeneity in several settings, such as training with local steps, asynchronous training, and Byzantine-robust training.},
  archive      = {J_TMLR},
  author       = {Konstantin Mishchenko and Rustem Islamov and Eduard Gorbunov and Samuel Horváth},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partially personalized federated learning: Breaking the curse of data heterogeneity},
  url          = {https://openreview.net/forum?id=8tMMCf4YYn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-pass detection of jailbreaking input in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=42v6I5Ut9a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defending aligned Large Language Models (LLMs) against jailbreaking attacks is a challenging problem, with existing approaches requiring multiple requests or even queries to auxiliary LLMs, making them computationally heavy. Instead, we focus on detecting jailbreaking input in a single forward pass. Our method, called SPD, leverages the information carried by the logits to predict whether the output sentence will be harmful. This allows us to defend in just a forward pass. SPD can not only detect attacks effectively on open-source models, but also minimizes the misclassification of harmless inputs. Furthermore, we show that SPD remains effective even without complete logit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a promising approach to efficiently safeguard LLMs against adversarial attacks.},
  archive      = {J_TMLR},
  author       = {Leyla Naz Candogan and Yongtao Wu and Elias Abad Rocamora and Grigorios Chrysos and Volkan Cevher},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Single-pass detection of jailbreaking input in large language models},
  url          = {https://openreview.net/forum?id=42v6I5Ut9a},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analytical model for overparameterized learning under class imbalance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=69RntSRF5K'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study class-imbalanced linear classification in a high-dimensional Gaussian mixture model. We develop a tight, closed form approximation for the test error of several practical learning methods, including logit adjustment and class dependent temperature. Our approximation allows us to analytically tune and compare these methods, highlighting how and when they overcome the pitfalls of standard cross-entropy minimization. We test our theoretical findings on simulated data and imbalanced CIFAR10, MNIST and FashionMNIST datasets.},
  archive      = {J_TMLR},
  author       = {Eliav Mor and Yair Carmon},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An analytical model for overparameterized learning under class imbalance},
  url          = {https://openreview.net/forum?id=69RntSRF5K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relax and penalize: A new bilevel approach to mixed-binary hyperparameter optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=A1R1cQ93Cb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for two specific machine learning problems, i.e., the estimation of the group-sparsity structure in regression problems and the data distillation problem. The reported results show that our method is competitive with state-of-the-art approaches based on relaxation and rounding.},
  archive      = {J_TMLR},
  author       = {Sara Venturini and Marianna De Santis and Jordan Patracone and Martin Schmidt and Francesco Rinaldi and Saverio Salzo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relax and penalize: A new bilevel approach to mixed-binary hyperparameter optimization},
  url          = {https://openreview.net/forum?id=A1R1cQ93Cb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density of states in neural networks: An in-depth exploration of learning in parameter space. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BLDtWlFKhn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in neural networks critically hinges on the intricate geometry of the loss landscape associated with a given task. Traditionally, most research has focused on finding specific weight configurations that minimize the loss. In this work, born from the cross-fertilization of machine learning and theoretical soft matter physics, we introduce a novel approach to examine the weight space across all loss values. Employing the Wang-Landau enhanced sampling algorithm, we explore the neural network density of states -- the number of network parameter configurations that produce a given loss value -- and analyze how it depends on specific features of the training set. Using both real-world and synthetic data, we quantitatively elucidate the relation between data structure and network density of states across different sizes and depths of binary-state networks. This work presents and illustrates a novel, informative analysis method that aims at paving the way for a better understanding of the interplay between structured data and the networks that process, learn, and generate them.},
  archive      = {J_TMLR},
  author       = {Margherita Mele and Roberto Menichetti and Alessandro Ingrosso and Raffaello Potestio},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Density of states in neural networks: An in-depth exploration of learning in parameter space},
  url          = {https://openreview.net/forum?id=BLDtWlFKhn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning from simulated interactions via multitask prospective rehearsal for bionic limb behavior modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Bmy82p2eez'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb amputations and neuromuscular impairments severely restrict mobility, necessitating advancements beyond conventional prosthetics. While motorized bionic limbs show promise, their effectiveness depends on replicating the dynamic coordination of human movement across diverse environments. In this paper, we introduce a model for human behavior in the context of bionic prosthesis control. Our approach leverages human locomotion demonstrations to learn the synergistic coupling of the lower limbs, enabling the prediction of the kinematic behavior of a missing limb during tasks such as walking, climbing inclines, and stairs. We propose a multitasking, continually adaptive model that anticipates and refines movements over time. At the core of our method is a technique which we call the multitask prospective rehearsal, that anticipates and synthesizes future movements based on the previous prediction and employs a corrective mechanism for subsequent predictions. Our evolving architecture merges lightweight, task-specific modules on a shared backbone, ensuring both specificity and scalability. We validate our model through experiments on real-world human gait datasets, including transtibial amputees, across a wide range of locomotion tasks. Results demonstrate that our approach consistently outperforms baseline models, particularly in scenarios with distributional shifts, adversarial perturbations, and noise.},
  archive      = {J_TMLR},
  author       = {Sharmita Dey and Benjamin Paassen and Sarath Ravindran Nair and Sabri Boughorbel and Arndt F. Schilling},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continual learning from simulated interactions via multitask prospective rehearsal for bionic limb behavior modeling},
  url          = {https://openreview.net/forum?id=Bmy82p2eez},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning for graphs with heterogeneous node attribute spaces for few-shot edge predictions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CAkt3DsAZs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of edges between nodes in graph data is useful for many applications, such as social network analysis and knowledge graph completion. Existing graph neural network-based approaches have achieved notable advancements, but encounter significant difficulty in building an effective model when there is an insufficient number of known edges in graphs. Although some meta-learning approaches were introduced to solve this problem, having an assumption that the nodes of training graphs and test graphs are in homogeneous attribute spaces, which limits the flexibility of applications. In this paper, we proposed a meta-learning method for edge prediction that can learn from graphs with nodes in heterogeneous attribute spaces. The proposed model consists of attribute-wise message-passing networks that transform information between connected nodes for each attribute, resulting in attribute-specific node embeddings. The node embeddings are obtained by calculating the mean of the attribute-specific node embeddings.The encoding operation can be repeated multiple times to capture complex patterns. The attribute-wise message-passing networks are shared across all graphs, allowing knowledge transfer between different graphs.The probabilities of edges are estimated by the Euclidian distance between node embeddings. Experimental results on 14 real-world data sets demonstrate that the proposed method outperforms existing methods in edge prediction problems with sparse edge information.},
  archive      = {J_TMLR},
  author       = {Zhong Chuang and Yusuke Tanaka and Tomoharu Iwata},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning for graphs with heterogeneous node attribute spaces for few-shot edge predictions},
  url          = {https://openreview.net/forum?id=CAkt3DsAZs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On memorization in diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=D3DBqvSDbj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their capacity to generate novel and high-quality samples, diffusion models have attracted significant research interest in recent years. Notably, the typical training objective of diffusion models, i.e., denoising score matching, has a closed-form optimal solution that can only generate training-data replicating samples. This indicates that a memorization behavior is theoretically expected, which contradicts the common generalization ability of state-of-the-art diffusion models, and thus calls for a deeper understanding. Looking into this, we first observe that memorization behaviors tend to occur on smaller-sized datasets, which motivates our definition of effective model memorization (EMM), a metric measuring the maximum size of training data at which a model approximates its theoretical optimum. Then, we quantify the impact of the influential factors on these memorization behaviors in terms of EMM, focusing primarily on data distribution, model configuration, and training procedure. Besides comprehensive empirical results identifying the influential factors, we surprisingly find that conditioning training data on uninformative random labels can significantly trigger the memorization in diffusion models. Our study holds practical significance for diffusion model users and offers clues to theoretical research in deep generative models.},
  archive      = {J_TMLR},
  author       = {Xiangming Gu and Chao Du and Tianyu Pang and Chongxuan Li and Min Lin and Ye Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On memorization in diffusion models},
  url          = {https://openreview.net/forum?id=D3DBqvSDbj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometry-aware visualization of high dimensional symmetric positive definite matrices. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DYCSRf3vby'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric Positive Definite (SPD) matrices are pervasive in machine learning, from data features (such as covariance matrices) to optimization process.These matrices induce a Riemannian structure, where the curvature plays a critical role in the success of approaches based on those geometries. Yet, for ML practitioners wanting to visualize SPD matrices, the existing (flat) Euclidean approaches will hide the curvature of the manifold. To overcome this lack of expressivity in the existing algorithms, we introduce Riemannian versions of two state-of-the-art techniques, namely t-SNE and Multidimensional Scaling. Therefore, we are able to reduce a set of $c \times c$ SPD matrices into a set of $2 \times 2$ SPD matrices in order to capture the curvature information and avoid any distortion induced by flattening the representation in an Euclidean setup. Moreover, our approaches pave the way for targeting more general dimensionality reduction applications while preserving the geometry of the data. We performed experiments on controlled synthetic dataset to ensure that the low-dimensional representation preserves the geometric properties of both SPD Gaussians and geodesics. We also conduct experiments on various real datasets, such as video, anomaly detection, brain signal and others.},
  archive      = {J_TMLR},
  author       = {Thibault de Surrel and Sylvain Chevallier and Fabien Lotte and Florian Yger},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Geometry-aware visualization of high dimensional symmetric positive definite matrices},
  url          = {https://openreview.net/forum?id=DYCSRf3vby},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein coreset via sinkhorn loss. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DrMCDS88IL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coreset selection, a technique for compressing large datasets while preserving performance, is crucial for modern machine learning. This paper presents a novel method for generating high-quality Wasserstein coresets using the Sinkhorn loss, a powerful tool with computational advantages. However, existing approaches suffer from numerical instability in Sinkhorn's algorithm. We address this by proposing stable algorithms for the computation and differentiation of the Sinkhorn optimization problem, including an analytical formula for the derivative of the Sinkhorn loss and a rigorous stability analysis of our method. Extensive experiments demonstrate that our approach significantly outperforms existing methods in terms of sample selection quality, computational efficiency, and achieving a smaller Wasserstein distance.},
  archive      = {J_TMLR},
  author       = {Haoyun Yin and Yixuan Qiu and Xiao Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wasserstein coreset via sinkhorn loss},
  url          = {https://openreview.net/forum?id=DrMCDS88IL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust preference optimization through reward model distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=E2zKNuwNDc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, the empirical evidence suggests that DPO typically assigns implicit rewards that overfit, and trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and use distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM such that its induced implicit reward, i.e., the scaled log-likelihood ratio of the model to the reference model, matches an explicit reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO.},
  archive      = {J_TMLR},
  author       = {Adam Fisch and Jacob Eisenstein and Vicky Zayats and Alekh Agarwal and Ahmad Beirami and Chirag Nagpal and Peter Shaw and Jonathan Berant},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust preference optimization through reward model distillation},
  url          = {https://openreview.net/forum?id=E2zKNuwNDc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Producers equilibria and dynamics in engagement-driven recommender systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EWT4GxjGDS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online platforms such as YouTube, Instagram heavily rely on recommender systems to decide what content to present to users. Producers, in turn, often create content that is likely to be recommended to users and have users engage with it. To do so, producers try to align their content with the preferences of their targeted user base. In this work, we explore the equilibrium behavior of producers who are interested in maximizing user engagement. We study two variants of the content-serving rule for the platform's recommender system, and provide a structural characterization of producer behavior at equilibrium: namely, each producer chooses to focus on a single embedded feature. We further show that specialization, defined as different producers optimizing for distinct types of content, naturally emerges from the competition among producers trying to maximize user engagement. We provide a heuristic for computing equilibria of our engagement game, and evaluate it experimentally. We highlight i) the performance and convergence of our heuristic, ii) the degree of producer specialization, and iii) the impact of the content-serving rule on producer and user utilities at equilibrium and provide guidance on how to set the content-serving rule.},
  archive      = {J_TMLR},
  author       = {Krishna Acharya and Juba Ziani and Jingyan Wang and Varun Vangala},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Producers equilibria and dynamics in engagement-driven recommender systems},
  url          = {https://openreview.net/forum?id=EWT4GxjGDS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative risk minimization for out-of-distribution generalization on graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=EcMVskXo1n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) generalization on graphs aims at dealing with scenarios where the test graph distribution differs from the training graph distributions. Compared to i.i.d. data like images, the OOD generalization problem on graph-structured data remains challenging due to the non-i.i.d. property and complex structural information on graphs. Recently, several works on graph OOD generalization have explored extracting invariant subgraphs that share crucial classification information across different distributions. Nevertheless, such a strategy could be suboptimal for entirely capturing the invariant information, as the extraction of discrete structures could potentially lead to the loss of invariant information or the involvement of spurious information. In this paper, we propose an innovative framework, named Generative Risk Minimization (GRM), designed to generate an invariant subgraph for each input graph to be classified, instead of extraction. To address the challenge of optimization in the absence of optimal invariant subgraphs (i.e., ground truths), we derive a tractable form of the proposed GRM objective by introducing a latent causal variable, and its effectiveness is validated by our theoretical analysis. We further conduct extensive experiments across a variety of real-world graph datasets for both node-level and graph-level OOD generalization, and the results demonstrate the superiority of our framework GRM.},
  archive      = {J_TMLR},
  author       = {Song Wang and Zhen Tan and Yaochen Zhu and Chuxu Zhang and Jundong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generative risk minimization for out-of-distribution generalization on graphs},
  url          = {https://openreview.net/forum?id=EcMVskXo1n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the regularization of learnable embeddings for time series forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=F5ALCh3GWG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In forecasting multiple time series, accounting for the individual features of each sequence can be challenging. To address this, modern deep learning methods for time series analysis combine a shared (global) model with local layers, specific to each time series, often implemented as learnable embeddings. Ideally, these local embeddings should encode meaningful representations of the unique dynamics of each sequence. However, when these are learned end-to-end as parameters of a forecasting model, they may end up acting as mere sequence identifiers. Shared processing blocks may then become reliant on such identifiers, limiting their transferability to new contexts. In this paper, we address this issue by investigating methods to regularize the learning of local learnable embeddings for time series processing. Specifically, we perform the first extensive empirical study on the subject and show how such regularizations consistently improve performance in widely adopted architectures. Furthermore, we show that methods attempting to prevent the co-adaptation of local and global parameters by means of embeddings perturbation are particularly effective in this context. In this regard, we include in the comparison several perturbation-based regularization methods, going as far as periodically resetting the embeddings during training. The obtained results provide an important contribution to understanding the interplay between learnable local parameters and shared processing layers: a key challenge in modern time series processing models and a step toward developing effective foundation models for time series.},
  archive      = {J_TMLR},
  author       = {Luca Butera and Giovanni De Felice and Andrea Cini and Cesare Alippi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the regularization of learnable embeddings for time series forecasting},
  url          = {https://openreview.net/forum?id=F5ALCh3GWG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Necessary and sufficient watermark for large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=FcyHZ6Q4k0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) can now generate texts that are indistinguishable from those written by humans. Such remarkable performance of LLMs increases their risk of being used for malicious purposes. Thus, it is necessary to develop methods for distinguishing texts written by LLMs from those written by humans. Watermarking is one of the most powerful methods for achieving this. Although existing methods have successfully detected texts generated by LLMs, they inevitably degrade the text quality. In this study, we propose the Necessary and Sufficient Watermark (NS-Watermark) for inserting watermarks into generated texts with minimum text quality degradation. More specifically, we derive minimum constraints required to be imposed on the generated texts to distinguish whether LLMs or humans write the texts, and we formulate the NS-Watermark as a constrained optimization problem. Through the experiments, we demonstrate that the NS-Watermark can generate more natural texts than existing watermarking methods and distinguish more accurately between texts written by LLMs and those written by humans. Especially in machine translation tasks, the NS-Watermark can outperform the existing watermarking method by up to 30 BLEU scores.},
  archive      = {J_TMLR},
  author       = {Yuki Takezawa and Ryoma Sato and Han Bao and Kenta Niwa and Makoto Yamada},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Necessary and sufficient watermark for large language models},
  url          = {https://openreview.net/forum?id=FcyHZ6Q4k0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics-inspired structure hallucination for protein-protein interaction modeling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GGHk5ukO6t'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-protein interaction (PPI) represents a central challenge within the biology field, and accurately predicting the consequences of mutations in this context is crucial for drug design and protein engineering. Deep learning (DL) has shown promise in forecasting the effects of such mutations but is hindered by two primary constraints. First, the structures of mutant proteins are often elusive to acquire. Secondly, PPI takes place dynamically, which is rarely integrated into the DL architecture design. To address these obstacles, we present a novel framework named Refine-PPI with two key enhancements. First, we introduce a structure refinement module trained by a mask mutation modeling (MMM) task on available wild-type structures, which is then transferred to hallucinate the inaccessible mutant structures. Second, we employ a new kind of geometric network, called the probability density cloud network (PDC-Net), to capture 3D dynamic variations and encode the atomic uncertainty associated with PPI. Comprehensive experiments on SKEMPI.v2 substantiate the superiority of Refine-PPI over all existing tools for predicting free energy change. These findings underscore the effectiveness of our hallucination strategy and the PDC module in addressing the absence of mutant protein structure and modeling geometric uncertainty.},
  archive      = {J_TMLR},
  author       = {Fang Wu and Stan Z. Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamics-inspired structure hallucination for protein-protein interaction modeling},
  url          = {https://openreview.net/forum?id=GGHk5ukO6t},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of best-of-N sampling strategies for language model alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=H4S4ETc8c9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) with human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Since the reward model is an imperfect proxy for the true objective, an excessive focus on optimizing its value can lead to a compromise of its performance on the true objective. Previous work proposes Regularized BoN sampling (RBoN), a BoN sampling with regularization to the objective, and shows that it outperforms BoN sampling so that it mitigates reward hacking and empirically (Jinnai et al., 2024). However, Jinnai et al. (2024) introduce RBoN based on a heuristic and they lack the analysis of why such regularization strategy improves the performance of BoN sampling. The aim of this study is to analyze the effect of BoN sampling on regularization strategies. Using the regularization strategies corresponds to robust optimization, which maximizes the worst case over a set of possible perturbations in the proxy reward. Although the theoretical guarantees are not directly applicable to RBoN, RBoN corresponds to a practical implementation. This paper proposes an extension of the RBoN framework, called Stochastic RBoN sampling (SRBoN), which is a theoretically guaranteed approach to worst-case RBoN in proxy reward. We then perform an empirical evaluation using the AlpacaFarm and Anthropic’s hh-rlhf datasets to evaluate which factors of the regularization strategies contribute to the improvement of the true proxy reward. In addition, we also propose another simple RBoN method, the Sentence Length Regularized BoN, which has a better performance in the experiment as compared to the previous methods.},
  archive      = {J_TMLR},
  author       = {Yuki Ichihara and Yuu Jinnai and Tetsuro Morimura and Kenshi Abe and Kaito Ariu and Mitsuki Sakamoto and Eiji Uchibe},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluation of best-of-N sampling strategies for language model alignment},
  url          = {https://openreview.net/forum?id=H4S4ETc8c9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking spectral augmentation for contrast-based graph self-supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HjpD5kpfa3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent surge in contrast-based graph self-supervised learning has prominently featured an intensified exploration of spectral cues. Spectral augmentation, which involves modifying a graph's spectral properties such as eigenvalues or eigenvectors, is widely believed to enhance model performance. However, an intriguing paradox emerges, as methods grounded in seemingly conflicting assumptions regarding the spectral domain demonstrate notable enhancements in learning performance. Through extensive empirical studies, we find that simple edge perturbations - random edge dropping for node-level and random edge adding for graph-level self-supervised learning - consistently yield comparable or superior performance while being significantly more computationally efficient. This suggests that the computational overhead of sophisticated spectral augmentations may not justify their practical benefits. Our theoretical analysis of the InfoNCE loss bounds for shallow GNNs further supports this observation. The proposed insights represent a significant leap forward in the field, potentially refining the understanding and implementation of graph self-supervised learning.},
  archive      = {J_TMLR},
  author       = {Xiangru Jian and Xinjian Zhao and Wei Pang and Chaolong Ying and Yimu Wang and Yaoyao Xu and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking spectral augmentation for contrast-based graph self-supervised learning},
  url          = {https://openreview.net/forum?id=HjpD5kpfa3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the stability of gradient descent with second order dynamics for time-varying cost functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=HlzjI2fn2T'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don’t always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu & Annaswamy 2022 for gradient descent with second order dynamics when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities.},
  archive      = {J_TMLR},
  author       = {Travis E Gibson and Sawal Acharya and Anjali Parashar and Joseph Emilio Gaudio and Anuradha Annaswamy},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the stability of gradient descent with second order dynamics for time-varying cost functions},
  url          = {https://openreview.net/forum?id=HlzjI2fn2T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nomic embed: Training a reproducible long context text embedder. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IPmzyQSiQE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on the short-context MTEB benchmark and the long context LoCo benchmark. We release the training code and model weights under an Apache 2.0 license. In contrast with other open-source models, we release the full curated training data and code that allows for full replication of nomic-embed-text-v1. You can find code and data to replicate the model at \href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}},
  archive      = {J_TMLR},
  author       = {Zach Nussbaum and John Xavier Morris and Andriy Mulyar and Brandon Duderstadt},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Nomic embed: Training a reproducible long context text embedder},
  url          = {https://openreview.net/forum?id=IPmzyQSiQE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metalearning continual learning algorithms. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IaUh7CSD3k'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF), i.e., previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to metalearn their own in-context continual (meta)learning algorithms. ACL encodes continual learning (CL) desiderata---good performance on both old and new tasks---into its metalearning objectives. Our experiments demonstrate that ACL effectively resolves "in-context catastrophic forgetting," a problem that naive in-context learning algorithms suffer from; ACL learned algorithms outperform both hand-crafted learning algorithms and popular meta-continual learning methods on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple standard image classification datasets. We also discuss the current limitations of in-context CL by comparing ACL with state-of-the-art CL methods that leverage pre-trained models. Overall, we bring several novel perspectives into the long-standing problem of CL.},
  archive      = {J_TMLR},
  author       = {Kazuki Irie and Róbert Csordás and Jürgen Schmidhuber},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Metalearning continual learning algorithms},
  url          = {https://openreview.net/forum?id=IaUh7CSD3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What makes ImageNet look unlike LAION. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IrBYuh9W3T'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ImageNet was famously created by querying several image search engines such as Flickr. What if we recreated ImageNet instead by searching the massive LAION dataset based on image captions alone? In this work, we carry out this counterfactual investigation. We find that the resulting ImageNet recreation, which we call LAIONet, looks distinctly unlike the original. Specifically, the intra-class similarity of images in the original ImageNet is dramatically higher than it is for LAIONet. Consequently, models trained on ImageNet perform significantly worse on LAIONet. We propose a rigorous explanation for the discrepancy in terms of a subtle, yet important, difference in two plausible causal data-generating processes for the respective datasets, that we support with systematic experimentation. In a nutshell, searching based on an image caption alone creates an information bottleneck that mitigates the selection bias otherwise present in image-based filtering. Our explanation formalizes a long-held intuition in the community that ImageNet images are stereotypical, unnatural, and overly simple representations of the class category. At the same time, it provides a simple and actionable takeaway for future dataset creation efforts.},
  archive      = {J_TMLR},
  author       = {Ali Shirali and Moritz Hardt},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What makes ImageNet look unlike LAION},
  url          = {https://openreview.net/forum?id=IrBYuh9W3T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fused gromov-wasserstein approach to subgraph contrastive learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=J7cY9Jr9WM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning has become a key method for training deep learning models when labeled data is scarce or unavailable. While graph machine learning holds great promise across various domains, the design of effective pretext tasks for self-supervised graph representation learning remains challenging. Contrastive learning, a popular approach in graph self-supervised learning, leverages positive and negative pairs to compute a contrastive loss function. However, current graph contrastive learning methods often struggle to fully use structural patterns and node similarities. To address these issues, we present a new method called Fused Gromov-Wasserstein Subgraph Contrastive Learning (FOSSIL). Our method integrates node-level and subgraph-level contrastive learning, seamlessly combining a standard node-level contrastive loss with the Fused Gromov-Wasserstein distance. This combination helps our method capture both node features and graph structure together. Importantly, our approach works well with both homophilic and heterophilic graphs and can dynamically create views for generating positive and negative pairs. Through extensive experiments on benchmark graph datasets, we show that FOSSIL outperforms or achieves competitive performance compared to current state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Amadou Siaka SANGARE and Nicolas Dunou and Jhony H. Giraldo and Fragkiskos D. Malliaros},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A fused gromov-wasserstein approach to subgraph contrastive learning},
  url          = {https://openreview.net/forum?id=J7cY9Jr9WM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JoIN: Joint GANs inversion for intrinsic image decomposition. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JEHIVfjmOf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic Image Decomposition (IID) is a challenging inverse problem that seeks to decompose a natural image into its underlying intrinsic components such as albedo and shading. While recent image decomposition methods rely on learning-based priors on these components, they often suffer from component cross-contamination owing to joint training of priors; or from Sim-to-Real gap since the priors trained on synthetic data are kept frozen during the inference on real images. In this work, we propose to solve the intrinsic image decomposition problem using a bank of Generative Adversarial Networks (GANs) as priors where each GAN is independently trained only on a single intrinsic component, providing stronger and more disentangled priors. At the core of our approach is the idea that the latent space of a GAN is a well-suited optimization domain to solve inverse problems. Given an input image, we propose to jointly invert the latent codes of a set of GANs and combine their outputs to reproduce the input. Contrary to all existing GAN inversion methods that are limited to inverting only a single GAN, our proposed approach, JoIN, is able to jointly invert multiple GANs using only a single image as supervision while still maintaining distribution priors of each intrinsic component. We show that our approach is modular, allowing various forward imaging models, and that it can successfully decompose both synthetic and real images. Further, taking inspiration from existing GAN inversion approaches, we allow for careful fine-tuning of the generator priors during the inference on real images. This way, our method is able to achieve excellent generalization on real images even though it uses only synthetic data to train the GAN priors. We demonstrate the success of our approach through exhaustive qualitative and quantitative evaluations and ablation studies on various datasets.},
  archive      = {J_TMLR},
  author       = {Viraj Shah and Svetlana Lazebnik and Julien Philip},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {JoIN: Joint GANs inversion for intrinsic image decomposition},
  url          = {https://openreview.net/forum?id=JEHIVfjmOf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A strong baseline for molecular few-shot learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JQ0agisXny'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has recently attracted significant interest in drug discovery, with a recent, fast-growing literature mostly involving convoluted meta-learning strategies. We revisit the more straightforward fine-tuning approach for molecular data, and propose a regularized quadratic-probe loss based on the the Mahalanobis distance. We design a dedicated block-coordinate descent optimizer, which avoid the degenerate solutions of our loss. Interestingly, our simple fine-tuning approach achieves highly competitive performances in comparison to state-of-the-art methods, while being applicable to black-box settings and removing the need for specific episodic pre-training strategies. Furthermore, we introduce a new benchmark to assess the robustness of the competing methods to domain shifts. In this setting, our fine-tuning baseline obtains consistently better results than meta-learning methods.},
  archive      = {J_TMLR},
  author       = {Philippe Formont and Hugo Jeannin and Pablo Piantanida and Ismail Ben Ayed},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A strong baseline for molecular few-shot learning},
  url          = {https://openreview.net/forum?id=JQ0agisXny},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards context and domain-aware algorithms for scene analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JQGmbVK4Fr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpersonal interactions and social situations in multimedia content encompass a rich blend of visual, textual, audio and contextual cues as well. However, contextual data integration in multimodal scene analysis research has often been overlooked, leading to incomplete interpretations. For instance, recognizing that two combatants in a video are positioned within a designated ring with a dedicated referee drastically alters the perception from a simple scuffle to a structured martial arts contest. This paper presents an innovative approach to scene analysis in video content, which not only incorporates contextual data but also emphasizes the most significant features during training. Additionally, we introduce a methodology for integrating domain knowledge into our framework. We evaluate our proposed methodology using two comprehensive datasets, demonstrating promising results compared to a baseline study using one of the datasets. These findings underscore the importance of integrating contextual data into multimodal video analysis, while also recognizing the challenges associated with their utilization.},
  archive      = {J_TMLR},
  author       = {Ibrahim Serouis and Florence Sèdes},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards context and domain-aware algorithms for scene analysis},
  url          = {https://openreview.net/forum?id=JQGmbVK4Fr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provable quantum algorithm advantage for gaussian process quadrature. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=K6CvWPtF62'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to develop novel quantum algorithms for Gaussian process quadrature methods. Gaussian process quadratures are numerical integration methods where Gaussian processes are used as functional priors for the integrands to capture the uncertainty arising from the sparse function evaluations. Quantum computers have emerged as potential replacements for classical computers, offering exponential reductions in the computational complexity of machine learning tasks. In this paper, we combine Gaussian process quadrature and quantum computing by proposing a quantum low-rank Gaussian process quadrature method based on a Hilbert space approximation of the Gaussian process kernel and enhancing the quadrature using a quantum circuit. The method combines the quantum phase estimation algorithm with the quantum principal component analysis technique to extract information up to a desired rank. Then, Hadamard and SWAP tests are implemented to find the expected value and variance that determines the quadrature. We use numerical simulations of a quantum computer to demonstrate the effectiveness of the method. Furthermore, we provide a theoretical complexity analysis that shows a polynomial advantage over classical Gaussian process quadrature methods. The code is available at https://github.com/cagalvisf/Quantum_HSGPQ.},
  archive      = {J_TMLR},
  author       = {Cristian A. Galvis-Florez and Ahmad Farooq and Simo Särkkä},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provable quantum algorithm advantage for gaussian process quadrature},
  url          = {https://openreview.net/forum?id=K6CvWPtF62},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformalized credal regions for classification with ambiguous ground truth. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=L7sQ8CW2FY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An open question in Imprecise Probabilistic Machine Learning is how to empirically derive a credal region (i.e., a closed and convex family of probabilities on the output space) from the available data, without any prior knowledge or assumption. In classification problems, credal regions are a tool that is able to provide provable guarantees under realistic assumptions by characterizing the uncertainty about the distribution of the labels. Building on previous work, we show that credal regions can be directly constructed using conformal methods. This allows us to provide a novel extension of classical conformal prediction to problems with ambiguous ground truth, that is, when the exact labels for given inputs are not exactly known. The resulting construction enjoys desirable practical and theoretical properties: (i) conformal coverage guarantees, (ii) smaller prediction sets (compared to classical conformal prediction regions) and (iii) disentanglement of uncertainty sources (epistemic, aleatoric). We empirically verify our findings on both synthetic and real datasets.},
  archive      = {J_TMLR},
  author       = {Michele Caprio and David Stutz and Shuo Li and Arnaud Doucet},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conformalized credal regions for classification with ambiguous ground truth},
  url          = {https://openreview.net/forum?id=L7sQ8CW2FY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterated $Q$-network: Beyond one-step bellman updates in deep reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Lt2H8Bd8jF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast majority of Reinforcement Learning methods is largely impacted by the computation effort and data requirements needed to obtain effective estimates of action-value functions, which in turn determine the quality of the overall performance and the sample-efficiency of the learning procedure. Typically, action-value functions are estimated through an iterative scheme that alternates the application of an empirical approximation of the Bellman operator and a subsequent projection step onto a considered function space. It has been observed that this scheme can be potentially generalized to carry out multiple iterations of the Bellman operator at once, benefiting the underlying learning algorithm. However, until now, it has been challenging to effectively implement this idea, especially in high-dimensional problems. In this paper, we introduce iterated $Q$-Network (i-QN), a novel principled approach that enables multiple consecutive Bellman updates by learning a tailored sequence of action-value functions where each serves as the target for the next. We show that i-QN is theoretically grounded and that it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate the advantages of i-QN in Atari $2600$ games and MuJoCo continuous control problems.},
  archive      = {J_TMLR},
  author       = {Théo Vincent and Daniel Palenicek and Boris Belousov and Jan Peters and Carlo D'Eramo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Iterated $Q$-network: Beyond one-step bellman updates in deep reinforcement learning},
  url          = {https://openreview.net/forum?id=Lt2H8Bd8jF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-step refinement network for robust point cloud registration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=M3SkSMfWcP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point Cloud Registration (PCR) estimates the relative rigid transformation between two point clouds of the same scene. Despite significant progress with learning-based approaches, existing methods still face challenges when the overlapping region between the two point clouds is small. In this paper, we propose an adaptive multi-step refinement network that refines the registration quality at each step by leveraging the information from the preceding step. To achieve this, we introduce a training procedure and a refinement network. Firstly, to adapt the network to the current step, we utilize a generalized one-way attention mechanism, which prioritizes the last step's estimated overlapping region, and we condition the network on step indices. Secondly, instead of training the network to map either random transformations or a fixed pre-trained model's estimations to the ground truth, we train it on transformations with varying registration qualities, ranging from accurate to inaccurate, thereby enhancing the network's adaptiveness and robustness. Despite its conceptual simplicity, our method achieves state-of-the-art performance on both the 3DMatch/3DLoMatch and KITTI benchmarks. Notably, on 3DLoMatch, our method reaches 80.4% recall rate, with an absolute improvement of 1.2%.},
  archive      = {J_TMLR},
  author       = {Zhi Chen and Yufan Ren and Tong Zhang and Zheng Dang and Wenbing Tao and Sabine Susstrunk and Mathieu Salzmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive multi-step refinement network for robust point cloud registration},
  url          = {https://openreview.net/forum?id=M3SkSMfWcP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REX: GPU-accelerated Sim2Real framework with delay and dynamics estimation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=O4CQ5AM5yP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sim2real, the transfer of control policies from simulation to the real world, is crucial for efficiently solving robotic tasks without the risks associated with real-world learning. However, discrepancies between simulated and real environments, especially due to unmodeled dynamics and latencies, significantly impact the performance of these transferred policies. In this paper, we address the challenges of sim2real transfer caused by latency and asynchronous dynamics in real-world robotic systems. Our approach involves developing a novel framework, REX (Robotic Environments with jaX), that uses a graph-based simulation model to incorporate latency effects while optimizing for parallelization on accelerator hardware. Our framework simulates the asynchronous, hierarchical nature of real-world systems, while simultaneously estimating system dynamics and delays from real-world data and implementing delay compensation strategies to minimize the sim2real gap. We validate our approach on two real-world systems, demonstrating its effectiveness in improving sim2real performance by accurately modeling both system dynamics and delays. Our results show that the proposed framework supports both accelerated simulation and real-time processing, making it valuable for robot learning.},
  archive      = {J_TMLR},
  author       = {Bas van der Heijden and Jens Kober and Robert Babuska and Laura Ferranti},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {REX: GPU-accelerated Sim2Real framework with delay and dynamics estimation},
  url          = {https://openreview.net/forum?id=O4CQ5AM5yP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum mean discrepancy on exponential windows for online change detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OGaTF9iOxi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting changes is of fundamental importance when analyzing data streams and has many applications, e.g., in predictive maintenance, fraud detection, or medicine. A principled approach to detect changes is to compare the distributions of observations within the stream to each other via hypothesis testing. Maximum mean discrepancy (MMD), a (semi-)metric on the space of probability distributions, provides powerful non-parametric two-sample tests on kernel-enriched domains. In particular, MMD is able to detect any disparity between distributions under mild conditions. However, classical MMD estimators suffer from a quadratic runtime complexity, which renders their direct use for change detection in data streams impractical. In this article, we propose a new change detection algorithm, called Maximum Mean Discrepancy on Exponential Windows (MMDEW), that combines the benefits of MMD with an efficient computation based on exponential windows. We prove that MMDEW enjoys polylogarithmic runtime and logarithmic memory complexity and show empirically that it outperforms the state of the art on benchmark data streams.},
  archive      = {J_TMLR},
  author       = {Florian Kalinke and Marco Heyden and Georg Gntuni and Edouard Fouché and Klemens Böhm},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maximum mean discrepancy on exponential windows for online change detection},
  url          = {https://openreview.net/forum?id=OGaTF9iOxi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DELTA: Dual consistency delving with topological uncertainty for active graph domain adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=P5y82LKGbY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph domain adaptation has recently enabled knowledge transfer across different graphs. However, without the semantic information on target graphs, the performance on target graphs is still far from satisfactory. To address the issue, we study the problem of active graph domain adaptation, which selects a small quantitative of informative nodes on the target graph for extra annotation. This problem is highly challenging due to the complicated topological relationships and the distribution discrepancy across graphs. In this paper, we propose a novel approach named Dual Consistency Delving with Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA consists of an edge-oriented graph subnetwork and a path-oriented graph subnetwork, which can explore topological semantics from complementary perspectives. In particular, our edge-oriented graph subnetwork utilizes the message passing mechanism to learn neighborhood information, while our path-oriented graph subnetwork explores high-order relationships from substructures. To jointly learn from two subnetworks, we roughly select informative candidate nodes with the consideration of consistency across two subnetworks. Then, we aggregate local semantics from its K-hop subgraph based on node degrees for topological uncertainty estimation. To overcome potential distribution shifts, we compare target nodes and their corresponding source nodes for discrepancy scores as an additional component for fine selection. Extensive experiments on benchmark datasets demonstrate that DELTA outperforms various state-of-the-art approaches. The code implementation of DELTA is available at https://github.com/goose315/DELTA.},
  archive      = {J_TMLR},
  author       = {Pengyun Wang and Yadi Cao and Chris Russell and Yanxin Shen and Junyu Luo and Ming Zhang and Siyu Heng and Xiao Luo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DELTA: Dual consistency delving with topological uncertainty for active graph domain adaptation},
  url          = {https://openreview.net/forum?id=P5y82LKGbY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the sample complexity of one hidden layer networks with equivariance, locality and weight sharing. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Q7aXOnEGgU'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contributes to the generalization error. Through the lens of statistical learning theory, we aim to provide insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. For a large class of activation functions, the bounds depend merely on the norm of filters and are dimension-independent. We also provide bounds for max-pooling and an extension to multi-layer networks, both with mild dimension dependence. We provide a few takeaways from the theoretical results. It can be shown that depending on the weight-sharing mechanism, the non-equivariant weight-sharing can yield a similar generalization bound as the equivariant one. We show that locality has generalization benefits, however the uncertainty principle implies a trade-off between locality and expressivity. We conduct extensive experiments and highlight some consistent trends for these models.},
  archive      = {J_TMLR},
  author       = {Arash Behboodi and Gabriele Cesa},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the sample complexity of one hidden layer networks with equivariance, locality and weight sharing},
  url          = {https://openreview.net/forum?id=Q7aXOnEGgU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Where do we stand with implicit neural representations? a technical and performance survey. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QTsJXSvAI2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit Neural Representations (INRs) have emerged as a paradigm in knowledge representation, offering exceptional flexibility and performance across a diverse range of applications. INRs leverage multilayer perceptrons (MLPs) to model data as continuous implicit functions, providing critical advantages such as resolution independence, memory efficiency, and generalisation beyond discretised data structures. Their ability to solve complex inverse problems makes them particularly effective for tasks including audio reconstruction, image representation, 3D object reconstruction, and high-dimensional data synthesis. This survey provides a comprehensive review of state-of-the-art INR methods, introducing a clear taxonomy that categorises them into four key areas: activation functions, position encoding, combined strategies, and network structure optimisation. We rigorously analyse their critical properties—such as full differentiability, smoothness, compactness, and adaptability to varying resolutions—while also examining their strengths and limitations in addressing locality biases and capturing fine details. Our experimental comparison offers new insights into the trade-offs between different approaches, showcasing the capabilities and challenges of the latest INR techniques across various tasks. In addition to identifying areas where current methods excel, we highlight key limitations and potential avenues for improvement, such as developing more expressive activation functions, enhancing positional encoding mechanisms, and improving scalability for complex, high-dimensional data. This survey serves as a roadmap for researchers, offering practical guidance for future exploration in the field of INRs. We aim to foster new methodologies by outlining promising research directions for INRs and applications.},
  archive      = {J_TMLR},
  author       = {Amer Essakine and Yanqi Cheng and Chun-Wun Cheng and Lipei Zhang and Zhongying Deng and Lei Zhu and Carola-Bibiane Schönlieb and Angelica I Aviles-Rivero},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Where do we stand with implicit neural representations? a technical and performance survey},
  url          = {https://openreview.net/forum?id=QTsJXSvAI2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On space folds of ReLU neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RfFqBXLDQk'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that the consecutive layers of ReLU neural networks can be understood geometrically as space folding transformations of the input space, revealing patterns of self-similarity. In this paper, we present the first quantitative analysis of this space folding phenomenon in ReLU neural networks. Our approach focuses on examining how straight paths in the Euclidean input space are mapped to their counterparts in the Hamming activation space. In this process, the convexity of straight lines is generally lost, giving rise to non-convex folding behavior. To quantify this effect, we introduce a novel measure based on range metrics, similar to those used in the study of random walks, and provide the proof for the equivalence of convexity notions between the input and activation spaces. Furthermore, we provide empirical analysis on a geometrical analysis benchmark (CantorNet) as well as an image classification benchmark (MNIST). Our work advances the understanding of the activation space in ReLU neural networks by leveraging the phenomena of geometric folding, providing valuable insights on how these models process input information.},
  archive      = {J_TMLR},
  author       = {Michal Lewandowski and Hamid Eghbalzadeh and Bernhard Heinzl and Raphael Pisoni and Bernhard A. Moser},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On space folds of ReLU neural networks},
  url          = {https://openreview.net/forum?id=RfFqBXLDQk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised discovery of object-centric neural fields. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ScEv13W2f1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inferring 3D object-centric scene representations from a single image. While recent methods have shown potential in unsupervised 3D object discovery, they are limited in generalizing to unseen spatial configurations. This limitation stems from the lack of translation invariance in their 3D object representations. Previous 3D object discovery methods entangle objects’ intrinsic attributes like shape and appearance with their 3D locations. This entanglement hinders learning generalizable 3D object representations. To tackle this bottleneck, we propose the unsupervised discovery of Object-Centric neural Fields (uOCF), which integrates translation invariance into the object representation. To allow learning object-centric representations from limited real-world images, we further introduce an object prior learning method that transfers object-centric prior knowledge from a synthetic dataset. To evaluate our approach, we collect four new datasets, including two real kitchen environments. Extensive experiments show that our approach significantly improves generalization and sample efficiency and enables unsupervised 3D object discovery in real scenes. Notably, uOCF demonstrates zero-shot generalization to unseen objects from a single real image. We attach our code in the supplementary file, and the project page is available at https://red-fairy.github.io/uOCF/},
  archive      = {J_TMLR},
  author       = {Rundong Luo and Hong-Xing Yu and Jiajun Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised discovery of object-centric neural fields},
  url          = {https://openreview.net/forum?id=ScEv13W2f1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preserving privacy in large language models: A survey on current threats and solutions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Ss9MTTN7OL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) represent a significant advancement in artificial intelligence, finding applications across various domains. However, their reliance on massive internet-sourced datasets for training brings notable privacy issues, which are exacerbated in critical domains (e.g., healthcare). Moreover, certain application-specific scenarios may require fine-tuning these models on private data. This survey critically examines the privacy threats associated with LLMs, emphasizing the potential for these models to memorize and inadvertently reveal sensitive information. We explore current threats by reviewing privacy attacks on LLMs and propose comprehensive solutions for integrating privacy mechanisms throughout the entire learning pipeline. These solutions range from anonymizing training datasets to implementing differential privacy during training or inference and machine unlearning after training. Our comprehensive review of existing literature highlights ongoing challenges, available tools, and future directions for preserving privacy in LLMs. This work aims to guide the development of more secure and trustworthy AI systems by providing a thorough understanding of privacy preservation methods and their effectiveness in mitigating risks.},
  archive      = {J_TMLR},
  author       = {Michele Miranda and Elena Sofia Ruzzetti and Andrea Santilli and Fabio Massimo Zanzotto and Sébastien Bratières and Emanuele Rodolà},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Preserving privacy in large language models: A survey on current threats and solutions},
  url          = {https://openreview.net/forum?id=Ss9MTTN7OL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Over-parameterised shallow neural networks with asymmetrical node scaling: Global convergence guarantees and feature learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Sx1khIIi95'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider gradient-based optimisation of wide, shallow neural networks, where the output of each hidden node is scaled by a positive parameter. The scaling parameters are non-identical, differing from the classical Neural Tangent Kernel (NTK) parameterisation. We prove that for large such neural networks, with high probability, gradient flow and gradient descent converge to a global minimum and can learn features in some sense, unlike in the NTK parameterisation. We perform experiments illustrating our theoretical results and discuss the benefits of such scaling in terms of prunability and transfer learning.},
  archive      = {J_TMLR},
  author       = {Francois Caron and Fadhel Ayed and Paul Jung and Hoil Lee and Juho Lee and Hongseok Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Over-parameterised shallow neural networks with asymmetrical node scaling: Global convergence guarantees and feature learning},
  url          = {https://openreview.net/forum?id=Sx1khIIi95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARVideo: Autoregressive pretraining for self-supervised video representation learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TRKwzPnXWQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new self-supervised video representation learning framework \textbf{ARVideo}, which \textit{autoregressively} predict the next video token in a tailored sequence order. Two key designs are included. First, we organize autoregressive video tokens into clusters that span both \textit{spatially} and \textit{temporally}, thereby enabling a richer aggregation of contextual information compared to the standard spatial-only or temporal-only clusters. Second, we adopt a randomized spatiotemporal prediction order to facilitate learning from multi-dimensional data, addressing the limitations of a handcrafted spatial-first or temporal-first sequence order. Extensive experiments establish ARVideo as an effective paradigm for self-supervised video representation learning. For example, when trained with the ViT-B backbone, ARVideo competitively attains 81.2\% on Kinetics-400 and 70.9\% on Something-Something V2, which are on par with the strong benchmark set by VideoMAE. Importantly, ARVideo also demonstrates higher training efficiency, \ie, it trains 14\% faster and requires 58\% less GPU memory compared to VideoMAE.},
  archive      = {J_TMLR},
  author       = {Sucheng Ren and Hongru Zhu and Chen Wei and Yijiang Li and Alan Yuille and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ARVideo: Autoregressive pretraining for self-supervised video representation learning},
  url          = {https://openreview.net/forum?id=TRKwzPnXWQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting benford's law for weight regularization of deep neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=TnT59yz7lc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic learning of Deep Neural Network (DNN) parameters is highly sensitive to training strategy, hyperparameters, and available training data. Many state-of-the-art solutions use weight regularization to adjust parameter distributions, prevent overfitting, and support generalization of DNNs. None of the existing regularization techniques have ever exploited a typical distribution of numerical datasets with respect to the first non-zero (or significant) digit, called Benford's Law (BL). In this paper, we show that the deviation of the significant digit distribution of the DNN weights from BL is closely related to the generalization of the DNN. In particular, when the DNN is presented with limited training data. To take advantage of this finding, we use BL to target the weight regularization of DNNs. Extensive experiments are performed on image, table, and speech data, considering convolutional (CNN) and Transformer-based neural network architectures with varying numbers of parameters. We show that the performance of DNNs is improved by minimizing the distance between the significant digit distributions of the DNN weights and the BL distribution along with L2 regularization. The improvements depend on the network architecture and how it deals with limited data. However, the proposed penalty term improves consistently and some CNN-based architectures gain up to $15\%$ test accuracy over the default training scheme with L2 regularization on subsets of CIFAR 100.},
  archive      = {J_TMLR},
  author       = {Julius Ott and Huawei Sun and Enrico Rinaldi and Gianfranco Mauro and Lorenzo Servadei and Robert Wille},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploiting benford's law for weight regularization of deep neural networks},
  url          = {https://openreview.net/forum?id=TnT59yz7lc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using representation balancing to learn conditional-average dose responses from clustered data. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=U8EMkndyq4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the response to an intervention with an associated dose conditional on a unit's covariates, the "conditional-average dose response" (CADR), is a relevant task in a variety of domains, from healthcare to business, economics, and beyond. Estimating such a response is challenging for several reasons: Firstly, it typically needs to be estimated from observational data, which can be confounded and negatively affect the performance of intervention response estimators used for counterfactual inference. Secondly, the continuity of the dose prevents the adoption of approaches used to estimate responses to binary-valued interventions. That is why the machine learning (ML) community has proposed several tailored CADR estimators. Yet, the proposal of most of these methods requires strong assumptions on the distribution of data and the assignment of interventions, which go beyond the standard assumptions in causal inference. Whereas previous works have so far focused on smooth shifts in covariate distributions across doses, in this work, we will study estimating CADR from clustered data and where different doses are assigned to different segments of a population. On a novel benchmarking dataset, we show the impacts of clustered data on model performance. Additionally, we propose an estimator, CBRNet, that enables the application of representation balancing for CADR estimation through clustering the covariate space and a novel loss function. CBRNet learns cluster-agnostic and hence dose-agnostic covariate representations through representation balancing for unbiased CADR inference. We run extensive experiments to illustrate the workings of our method and compare it with the state of the art in ML for CADR estimation.},
  archive      = {J_TMLR},
  author       = {Christopher Bockel-Rickermann and Toon Vanderschueren and Jeroen Berrevoets and Tim Verdonck and Wouter Verbeke},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Using representation balancing to learn conditional-average dose responses from clustered data},
  url          = {https://openreview.net/forum?id=U8EMkndyq4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-based denoising diffusion models for photon-starved image restoration problems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UYXPt7HUdl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based denoising diffusion models have recently emerged as a powerful strategy to solve image restoration problems. Early diffusion models required problem-specific training. However, modern approaches can combine a likelihood function that is specified during test-time with a foundational pretrained diffusion model, which is used as an implicit prior in a Plug-and-Play (PnP) manner. This approach has been shown to deliver state-of-the-art performance in a wide range of image restoration problems involving Gaussian and mild Poisson noise. With extreme computer vision applications in mind, this paper presents the first PnP denoising diffusion method for photon-starved imaging problems. These problems arise in new quantum-enhanced imaging systems that exploit the particle nature of light to exceed the limitations of classical imaging. The problems involve highly challenging noise statistics, such as binomial, geometric, and low-intensity Poisson noise, which are difficult because of high uncertainty about the solution and because the models exhibit poor regularity properties (e.g., exploding scores, constraints). The proposed method is demonstrated on a series of challenging photon-starved imaging experiments with as little as 1 photon per pixel, where it delivers remarkably accurate solutions and outperforms alternative strategies from the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Savvas Melidonis and Yiming Xi and Konstantinos C. Zygalakis and Yoann Altmann and Marcelo Pereyra},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Score-based denoising diffusion models for photon-starved image restoration problems},
  url          = {https://openreview.net/forum?id=UYXPt7HUdl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CNN interpretability with multivector tucker saliency maps for self-supervised models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VM8bNd5A09'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpreting the decisions of Convolutional Neural Networks (CNNs) is essential for understanding their behavior, yet it remains a significant challenge, particularly for self-supervised models. Most existing methods for generating saliency maps rely on reference labels, restricting their use to supervised tasks. EigenCAM is the only notable label-independent alternative, leveraging Singular Value Decomposition to generate saliency maps applicable across CNN models, but it does not fully exploit the tensorial structure of feature maps. In this work, we introduce the Tucker Saliency Map (TSM) method, which applies Tucker tensor decomposition to better capture the inherent structure of feature maps, producing more accurate singular vectors and values. These are used to generate high-fidelity saliency maps, effectively highlighting objects of interest in the input. We further extend EigenCAM and TSM into multivector variants—Multivec-EigenCAM and Multivector Tucker Saliency Maps (MTSM)—which utilize all singular vectors and values, further improving saliency map quality. Quantitative evaluations on supervised classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve competitive performance with label-dependent methods. Moreover, TSM enhances interpretability by approximately $50\%$ over EigenCAM for both supervised and self-supervised models. Multivec-EigenCAM and MTSM further advance state-of-the-art interpretability performance on self-supervised models, with MTSM achieving the best results.},
  archive      = {J_TMLR},
  author       = {Aymene Mohammed Bouayed and Samuel Deslauriers-gauthier and Adrian IACOVELLI and David Naccache},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CNN interpretability with multivector tucker saliency maps for self-supervised models},
  url          = {https://openreview.net/forum?id=VM8bNd5A09},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Why is constrained neural language generation particularly challenging?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Vwgjk5ysWn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce fluent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally define and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging field, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research.},
  archive      = {J_TMLR},
  author       = {Cristina Garbacea and Qiaozhu Mei},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Why is constrained neural language generation particularly challenging?},
  url          = {https://openreview.net/forum?id=Vwgjk5ysWn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-aware graph prompt learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=W50i7r3DHE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks stand as the predominant technique for graph representation learning owing to their strong expressive power, yet the performance highly depends on the availability of high-quality labels in an end-to-end manner. Thus the pretraining and fine-tuning paradigm has been proposed to mitigate the label cost issue. Subsequently, the gap between the pretext tasks and downstream tasks has spurred the development of graph prompt learning which inserts a set of graph prompts into the original graph data with minimal parameters while preserving competitive performance. However, the current exploratory works are still limited since they all concentrate on learning fixed task-specific prompts which may not generalize well across the diverse instances that the task comprises. To tackle this challenge, we introduce Instance-Aware Graph Prompt Learning (IA-GPL) in this paper, aiming to generate distinct prompts tailored to different input instances. The process involves generating intermediate prompts for each instance using a lightweight architecture, quantizing these prompts through trainable codebook vectors, and employing the exponential moving average technique to ensure stable training. Extensive experiments conducted on multiple datasets and settings showcase the superior performance of IA-GPL compared to state-of-the-art baselines.},
  archive      = {J_TMLR},
  author       = {Jiazheng Li and Jundong Li and Chuxu Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Instance-aware graph prompt learning},
  url          = {https://openreview.net/forum?id=W50i7r3DHE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmentation policy search for long-term forecasting. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Wnd0XY0twh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation serves as a popular regularization technique to combat overfitting challenges in neural networks. While automatic augmentation has demonstrated success in image classification tasks, its application to time-series problems, particularly in long-term forecasting, has received comparatively less attention. To address this gap, we introduce a time-series automatic augmentation approach named TSAA, which is both efficient and easy to implement. The solution involves tackling the associated bilevel optimization problem through a two-step process: initially training a non-augmented model for a limited number of epochs, followed by an iterative split procedure. During this iterative process, we alternate between identifying a robust augmentation policy through Bayesian optimization and refining the model while discarding suboptimal runs. Extensive evaluations on challenging univariate and multivariate forecasting benchmark problems demonstrate that TSAA consistently outperforms several robust baselines, suggesting its potential integration into prediction pipelines. Code is available at this repository: \href{https://github.com/azencot-group/TSAA}{https://github.com/azencot-group/TSAA}.},
  archive      = {J_TMLR},
  author       = {Liran Nochumsohn and Omri Azencot},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data augmentation policy search for long-term forecasting},
  url          = {https://openreview.net/forum?id=Wnd0XY0twh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding LLM embeddings for regression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Wt6Iz5XNIO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of large language models (LLMs) for flexibly processing information as strings, a natural application is regression, specifically by preprocessing string representations into LLM embeddings as downstream features for metric prediction. In this paper, we provide one of the first comprehensive investigations into embedding-based regression and demonstrate that LLM embeddings as features can be better for high-dimensional regression tasks than using traditional feature engineering. This regression performance can be explained in part due to LLM embeddings over numeric data inherently preserving Lipschitz continuity over the feature space. Furthermore, we quantify the contribution of different model effects, most notably model size and language understanding, which we find surprisingly do not always improve regression performance.},
  archive      = {J_TMLR},
  author       = {Eric Tang and Bangding Yang and Xingyou Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding LLM embeddings for regression},
  url          = {https://openreview.net/forum?id=Wt6Iz5XNIO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-based experience replay for task-agnostic continual reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WxHTSPS2pi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning uses a learned dynamics model to imagine actions and select those with the best expected outcomes. An experience replay buffer collects the outcomes of all actions executed in the environment, which is then used to iteratively train the dynamics model. However, as the complexity and scale of tasks increase, training times and memory requirements can grow drastically without necessarily retaining useful experiences. Continual learning proposes a more realistic scenario where tasks are learned in sequence, and the replay buffer can help mitigate catastrophic forgetting. However, it is not realistic to expect the buffer to infinitely grow as the sequence advances. Furthermore, storing every single experience executed in the environment does not necessarily provide a more accurate model. We argue that the replay buffer needs to have the minimal necessary size to retain relevant experiences that cover both common and rare states. Therefore, we propose using an uncertainty-based replay buffer filtering to enable an effective implementation of continual learning agents using model-based reinforcement learning. We show that the combination of the proposed strategies leads to reduced training times, smaller replay buffer size, and less catastrophic forgetting, all while maintaining performance.},
  archive      = {J_TMLR},
  author       = {Adrian Remonda and Cole Corbitt Terrell and Eduardo E. Veas and Marc Masana},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty-based experience replay for task-agnostic continual reinforcement learning},
  url          = {https://openreview.net/forum?id=WxHTSPS2pi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global convergence rate of deep equilibrium models with general activations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XPREcQlAM0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-homogeneous, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.},
  archive      = {J_TMLR},
  author       = {Lan V. Truong},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global convergence rate of deep equilibrium models with general activations},
  url          = {https://openreview.net/forum?id=XPREcQlAM0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time adaptation with source based auxiliary tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XWAXcxNg4n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work tackles a key challenge in Test Time Adaptation~(TTA): adapting on limited data. This challenge arises naturally from two scenarios. (i) Current TTA methods are limited by the bandwidth with which the stream reveals data, since conducting several adaptation steps on each revealed batch from the stream will lead to overfitting. (ii) In many realistic scenarios, the stream reveals insufficient data for the model to fully adapt to a given distribution shift. We tackle the first scenario problem with auxiliary tasks where we leverage unlabeled data from the training distribution. In particular, we propose distilling the predictions of an originally pretrained model on clean data during adaptation. We found that our proposed auxiliary task significantly accelerates the adaptation to distribution shifts. We report a performance improvement over the state of the art by 1.5\% and 6\% on average across all corruptions on ImageNet-C under episodic and continual evaluation, respectively. To combat the second scenario of limited data, we analyze the effectiveness of combining federated adaptation with our proposed auxiliary task across different models even when different clients observe different distribution shifts. We find that not only federated averaging enhances adaptation, but combining it with our auxiliary task provides a notable 6\% performance gains over previous TTA methods.},
  archive      = {J_TMLR},
  author       = {Motasem Alfarra and Alvaro Correia and Bernard Ghanem and Christos Louizos},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Test-time adaptation with source based auxiliary tasks},
  url          = {https://openreview.net/forum?id=XWAXcxNg4n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What is the relationship between tensor factorizations and circuits (and how can we exploit it)?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Y7dRmpGiHj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a rigorous connection between circuit representations and tensor factorizations, two seemingly distinct yet fundamentally related areas. By connecting these fields, we highlight a series of opportunities that can benefit both communities. Our work generalizes popular tensor factorizations within the circuit language, and unifies various circuit learning algorithms under a single, generalized hierarchical factorization framework. Specifically, we introduce a modular “Lego block” approach to build tensorized circuit architectures. This, in turn, allows us to systematically construct and explore various circuit and tensor factorization models while maintaining tractability. This connection not only clarifies similarities and differences in existing models, but also enables the development of a comprehensive pipeline for building and optimizing new circuit/tensor factorization architectures. We show the effectiveness of our framework through extensive empirical evaluations, and highlight new research opportunities for tensor factorizations in probabilistic modeling.},
  archive      = {J_TMLR},
  author       = {Lorenzo Loconte and Antonio Mari and Gennaro Gala and Robert Peharz and Cassio de Campos and Erik Quaeghebeur and Gennaro Vessio and Antonio Vergari},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What is the relationship between tensor factorizations and circuits (and how can we exploit it)?},
  url          = {https://openreview.net/forum?id=Y7dRmpGiHj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural lattice reduction: A self-supervised geometric deep learning approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YxXyRSlZ4b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. The Lenstra–Lenstra–Lovász (LLL) algorithm is the best algorithm in the literature for solving this problem. In light of recent research on algorithm discovery, in this work, we would like to answer this question: is it possible to parametrize the algorithm space for lattice reduction problem with neural networks and find an algorithm without supervised data? Our strategy is to use equivariant and invariant parametrizations and train in a self-supervised way. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant to isometries and scaling of the ambient space and equivariant with respect to the hyperocrahedral group permuting and flipping the lattice basis elements. We show that this approach yields an algorithm with comparable complexity and performance to the LLL algorithm on a set of benchmarks. Additionally, motivated by certain applications for wireless communication, we extend our method to a convolutional architecture which performs joint reduction of spatially-correlated lattices arranged in a grid, thereby amortizing its cost over multiple lattices.},
  archive      = {J_TMLR},
  author       = {Giovanni Luca Marchetti and Gabriele Cesa and Kumar Pratik and Arash Behboodi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural lattice reduction: A self-supervised geometric deep learning approach},
  url          = {https://openreview.net/forum?id=YxXyRSlZ4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning of probabilistic models: A PAC-bayesian approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZMliWjMCor'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) aims to infer a shared model from private and decentralized data stored by multiple clients. Personalized FL (PFL) enhances the model’s fit for each client by adapting the global model to the clients. A significant level of personalization is required for highly heterogeneous clients but can be challenging to achieve, especially when clients’ datasets are small. We introduce PAC-PFL for PFL of probabilistic models. PAC-PFL infers a shared hyper-posterior and treats each client’s posterior inference as the personalization step. Unlike previous PFL algorithms, PAC-PFL does not regularize all personalized models towards a single shared model, thereby greatly enhancing its personalization flexibility. By establishing and minimizing a PAC-Bayesian generalization bound on the average true loss of clients, PAC-PFL effectively mitigates overfitting even in data-poor scenarios. Additionally, PAC-PFL provides generalization bounds for new clients joining later. PAC-PFL achieves accurate and well-calibrated predictions, as supported by our experiments.},
  archive      = {J_TMLR},
  author       = {Mahrokh Ghoddousi Boroujeni and Andreas Krause and Giancarlo Ferrari-Trecate},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized federated learning of probabilistic models: A PAC-bayesian approach},
  url          = {https://openreview.net/forum?id=ZMliWjMCor},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TACO vision models can be efficiently specialized via few-shot task-aware compression. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Za9Tm07fig'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent vision architectures and self-supervised training methods have enabled training computer vision models that are extremely accurate, but come with massive computational costs. In settings such as identifying species in camera traps in the field, users have limited resources, and may fine-tune a pretrained model on (often limited) data from a small set of specific categories of interest. Such users may still wish to make use of highly-accurate large models, but are often constrained by the computational cost. To address this, we ask: can we quickly compress generalist models into accurate and efficient specialists given a small amount of data? Towards this goal, we propose a simple and versatile technique, which we call Few-Shot Task-Aware COmpression (TACO). Given a general-purpose model pretrained on a broad task, such as classification on ImageNet or iNaturalist datasets with thousands of categories, TACO produces a much smaller model that is accurate on specialized tasks, such as classifying across vehicle types or animal species, based only on a few examples from each target class. The method is based on two key insights - 1) a powerful specialization effect for data-aware compression, which we showcase for the first time; 2) a dedicated finetuning procedure with knowledge distillation, which prevents overfitting even in scenarios where data is very scarce. Specifically, TACO is applied in few-shot fashion, i.e. only a few task-specific samples are used for compression, and the procedure has low computational overhead. We validate this approach experimentally using highly-accurate ResNet, ViT/DeiT, and ConvNeXt models, originally trained on ImageNet and iNaturalist datasets, which we specialize and compress to a diverse set of ``downstream'' subtasks, with notable computational speedups on both CPU and GPU.},
  archive      = {J_TMLR},
  author       = {Denis Kuznedelev and Soroush Tabesh and Kimia Noorbakhsh and Elias Frantar and Sara Beery and Eldar Kurtic and Dan Alistarh},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TACO vision models can be efficiently specialized via few-shot task-aware compression},
  url          = {https://openreview.net/forum?id=Za9Tm07fig},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability-aware training of machine learning force fields with differentiable boltzmann estimators. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZckLMG00sO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning force fields (MLFFs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations, limiting their ability to model phenomena occurring over longer timescales and compromising the quality of estimated observables. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which leverages joint supervision from reference quantum-mechanical calculations and system observables. StABlE Training iteratively runs many MD simulations in parallel to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. We achieve efficient end-to-end automatic differentiation through MD simulations using our Boltzmann Estimator, a generalization of implicit differentiation techniques to a broader class of stochastic algorithms. Unlike existing techniques based on active learning, our approach requires no additional ab-initio energy and forces calculations to correct instabilities. We demonstrate our methodology across organic molecules, tetrapeptides, and condensed phase systems, using three modern MLFF architectures. StABlE-trained models achieve significant improvements in simulation stability, data efficiency, and agreement with reference observables. Crucially, the stability improvements cannot be matched by simply reducing the simulation timestep, meaning that StABlE Training effectively allows for larger timesteps in MD simulations. By incorporating observables into the training process alongside first-principles calculations, StABlE Training can be viewed as a general semi-empirical framework applicable across MLFF architectures and systems. This makes it a powerful tool for training stable and accurate MLFFs, particularly in the absence of large reference datasets. Our code is publicly available at https://github.com/ASK-Berkeley/StABlE-Training.},
  archive      = {J_TMLR},
  author       = {Sanjeev Raja and Ishan Amin and Fabian Pedregosa and Aditi S. Krishnapriyan},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stability-aware training of machine learning force fields with differentiable boltzmann estimators},
  url          = {https://openreview.net/forum?id=ZckLMG00sO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shapley values of structured additive regression models and application to RKHS weightings of functions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aWRMvXTvPf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shapley values are widely used in machine learning to interpret model predictions. However, they have an important drawback in their computational time, which is exponential in the number of variables in the data. Recent work has yielded algorithms that can efficiently and exactly calculate the Shapley values of specific model families, such as Decision Trees and Generalized Additive Models (GAMs). Unfortunately, these model families are fairly restricted. Consequently, we present STAR-SHAP, an algorithm for efficiently calculating the Shapley values of Structured Additive Regression (STAR) models, a generalization of GAMs which allow any number of variable interactions. While the computational cost of STAR-SHAP scales exponentially in the size of these interactions, it is independent of the total number of variables. This allows the interpretation of more complex and flexible models. As long as the variable interactions are moderately-sized, the computation of the Shapley values will be fast, even on high-dimensional datasets. Since STAR models with more than pairwise interactions (e.g. GA2Ms) are seldom used in practice, we also present a new class of STAR models built on the RKHS Weightings of Functions paradigm. More precisely, we introduce a new RKHS Weighting instantiation, and show how to transform it and other RKHS Weightings into STAR models. We therefore introduce a new family of STAR models, as well as the means to interpret their outputs in a timely manner.},
  archive      = {J_TMLR},
  author       = {Gabriel Dubé and Mario Marchand},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shapley values of structured additive regression models and application to RKHS weightings of functions},
  url          = {https://openreview.net/forum?id=aWRMvXTvPf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing the information content of probabilistic representation spaces. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=adhsMqURI1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic representation spaces convey information about a dataset and are shaped by factors such as the training data, network architecture, and loss function. Comparing the information content of such spaces is crucial for understanding the learning process, yet most existing methods assume point-based representations, neglecting the distributional nature of probabilistic spaces. To address this gap, we propose two information-theoretic measures to compare general probabilistic representation spaces by extending classic methods to compare the information content of hard clustering assignments. Additionally, we introduce a lightweight method of estimation that is based on fingerprinting a representation space with a sample of the dataset, designed for scenarios where the communicated information is limited to a few bits. We demonstrate the utility of these measures in three case studies. First, in the context of unsupervised disentanglement, we identify recurring information fragments within individual latent dimensions of VAE and InfoGAN ensembles. Second, we compare the full latent spaces of models and reveal consistent information content across datasets and methods, despite variability during training. Finally, we leverage the differentiability of our measures to perform model fusion, synthesizing the information content of weak learners into a single, coherent representation. Across these applications, the direct comparison of information content offers a natural basis for characterizing the processing of information.},
  archive      = {J_TMLR},
  author       = {Kieran A. Murphy and Sam Dillavou and Danielle Bassett},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Comparing the information content of probabilistic representation spaces},
  url          = {https://openreview.net/forum?id=adhsMqURI1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving consistency in large language models through chain of guidance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=asiBW1bB9b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistency is a fundamental dimension of trustworthiness in Large Language Models (LLMs). For humans to be able to trust LLM-based applications, their outputs should be consistent when prompted with inputs that carry the same meaning or intent. Despite this need, there is no known mechanism to control and guide LLMs to be more consistent at inference time. In this paper, we introduce a novel alignment strategy to maximize semantic consistency in LLM outputs. Our proposal is based on \textbf{Chain of Guidance} (CoG), a multistep prompting technique that generates highly consistent outputs from LLMs. For closed-book question-answering (Q\&A) tasks, when compared to direct prompting, the outputs generated using CoG show improved consistency. While other approaches like template-based responses and majority voting may offer alternative paths to consistency, our work focuses on exploring the potential of guided prompting. We use synthetic data sets comprised of consistent input-output pairs to fine-tune LLMs to produce consistent {\it and} correct outputs. Our fine-tuned models are more than twice as consistent compared to base models and show strong generalization capabilities by producing consistent outputs over datasets not used in the fine-tuning process. Code is available at \url{https://github.com/vijilAI/chain_of_guidance}.},
  archive      = {J_TMLR},
  author       = {Harsh Raj and Vipul Gupta and Domenic Rosati and Subhabrata Majumdar},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving consistency in large language models through chain of guidance},
  url          = {https://openreview.net/forum?id=asiBW1bB9b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QPO: Query-dependent prompt optimization via multi-loop offline reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bqMJToTkvT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt engineering has demonstrated remarkable success in enhancing the performance of large language models (LLMs) across diverse tasks. However, most existing prompt optimization methods only focus on the task-level performance, overlooking the importance of query-preferred prompts, which leads to suboptimal performances. Additionally, these methods rely heavily on frequent interactions with LLMs to obtain feedback for guiding the optimization process, incurring substantial redundant interaction costs. In this paper, we introduce Query-dependent Prompt Optimization ($\textbf{QPO}$), which leverages multi-loop offline reinforcement learning to iteratively fine-tune a small pretrained language model to generate optimal prompts tailored to the input queries, thus significantly improving the prompting effect on the large target LLM. We derive insights from offline prompting demonstration data, which already exists in large quantities as a by-product of benchmarking diverse prompts on open-sourced tasks, thereby circumventing the expenses of online interactions. Furthermore, we continuously augment the offline dataset with the generated prompts in each loop, as the prompts from the fine-tuned model are supposed to outperform the source prompts in the original dataset. These iterative loops bootstrap the model towards generating optimal prompts. Experiments on various LLM scales and diverse NLP and math tasks demonstrate the efficacy and cost-efficiency of our method in both zero-shot and few-shot scenarios.},
  archive      = {J_TMLR},
  author       = {Yilun Kong and Hangyu Mao and Zhao Qi and Bin Zhang and Jingqing Ruan and Li Shen and Yongzhe Chang and Xueqian Wang and Rui Zhao and Dacheng Tao},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {QPO: Query-dependent prompt optimization via multi-loop offline reinforcement learning},
  url          = {https://openreview.net/forum?id=bqMJToTkvT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution shift-aware prediction refinement for test-time adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=c7AAHdEYz5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-time adaptation (TTA) is an effective approach to mitigate performance degradation of trained models when encountering input distribution shifts at test time. However, existing TTA methods often suffer significant performance drops when facing additional class distribution shifts. We first analyze TTA methods under label distribution shifts and identify the presence of class-wise confusion patterns commonly observed across different covariate shifts. Based on this observation, we introduce label Distribution shift-Aware prediction Refinement for Test-time adaptation (DART), a novel TTA method that refines the predictions by focusing on class-wise confusion patterns. DART trains a prediction refinement module during an intermediate time by exposing it to several batches with diverse class distributions using the training dataset. This module is then used during test time to detect and correct class distribution shifts, significantly improving pseudo-label accuracy for test data. Our method exhibits 5-18% gains in accuracy under label distribution shifts on CIFAR-10C, without any performance degradation when there is no label distribution shift. Extensive experiments on CIFAR, PACS, OfficeHome, and ImageNet benchmarks demonstrate DART's ability to correct inaccurate predictions caused by test-time distribution shifts. This improvement leads to enhanced performance in existing TTA methods, making DART a valuable plug-in tool.},
  archive      = {J_TMLR},
  author       = {Minguk Jang and Hye Won Chung},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label distribution shift-aware prediction refinement for test-time adaptation},
  url          = {https://openreview.net/forum?id=c7AAHdEYz5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The sparse matrix-based random projection: A study of binary and ternary quantization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dNJmJ8bh1M'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random projection is a simple yet effective technique for dimension reduction, widely used in various machine learning tasks. Following the projection step, quantization is often applied to further reduce the complexity of projected data. In general, quantized projections are expected to approximately preserve the pairwise distances between the original data points, to avoid significant performance degradation in subsequent tasks. While this distance preservation property has been investigated for Gaussian matrices, our work further extends the analysis to hardware-friendly $\{0,1\}$-binary matrices, particularly focusing on cases where the projections are quantized into two types of low bit-width codes: $\{0,1\}$-binary codes and $\{0,\pm1\}$-ternary codes. It is found that the distance preservation property tends to be better maintained, when the binary projection matrices exhibit sparse structures. This is validated through classification and clustering experiments, where extremely sparse binary matrices, with only one nonzero entry per column, achieve superior or comparable performance to other denser binary matrices and Gaussian matrices. This presents an opportunity to significantly reduce the computational and storage complexity of the quantized random projection model, without compromising, and potentially even improving its performance.},
  archive      = {J_TMLR},
  author       = {Weizhi Lu and Zhongzheng Li and Mingrui Chen and Weiyu Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The sparse matrix-based random projection: A study of binary and ternary quantization},
  url          = {https://openreview.net/forum?id=dNJmJ8bh1M},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced mixed-type tabular data synthesis with diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dvRysCqmYQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have emerged as a robust framework for various generative tasks, including tabular data synthesis. However, current tabular diffusion models tend to inherit bias in the training dataset and generate biased synthetic data, which may influence discriminatory actions. In this research, we introduce a novel tabular diffusion model that incorporates sensitive guidance to generate fair synthetic data with balanced joint distributions of the target label and sensitive attributes, such as sex and race. The empirical results demonstrate that our method effectively mitigates bias in training data while maintaining the quality of the generated samples. Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data on fairness metrics such as demographic parity ratio and equalized odds ratio, achieving improvements of over $10\%$. Our implementation is available at https://github.com/comp-well-org/fair-tab-diffusion.},
  archive      = {J_TMLR},
  author       = {Zeyu Yang and Han Yu and Peikun Guo and Khadija Zanna and Xiaoxue Yang and Akane Sano},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Balanced mixed-type tabular data synthesis with diffusion models},
  url          = {https://openreview.net/forum?id=dvRysCqmYQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative minibatching in graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=f6yMdmrD2g'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training large scale Graph Neural Networks (GNNs) requires significant computational resources, and the process is highly data-intensive. One of the most effective ways to reduce resource requirements is minibatch training coupled with graph sampling. GNNs have the unique property that items in a minibatch have overlapping data. However, the commonly implemented Independent Minibatching approach assigns each Processing Element (PE, i.e., cores and/or GPUs) its own minibatch to process, leading to duplicated computations and input data access across PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which is the main bottleneck limiting scaling. To reduce the effects of NEP in the multi-PE setting, we propose a new approach called Cooperative Minibatching. Our approach capitalizes on the fact that the size of the sampled subgraph is a concave function of the batch size, leading to significant reductions in the amount of work as batch sizes increase. Hence, it is favorable for processors equipped with a fast interconnect to work on a large minibatch together as a single larger processor, instead of working on separate smaller minibatches, even though global batch size is identical. We also show how to take advantage of the same phenomenon in serial execution by generating dependent consecutive minibatches. Our experimental evaluations show up to 4x bandwidth savings for fetching vertex embeddings, by simply increasing this dependency without harming model convergence. Combining our proposed approaches, we achieve up to 64\% speedup over Independent Minibatching on single-node multi GPU systems, using same resources.},
  archive      = {J_TMLR},
  author       = {Muhammed Fatih Balin and Dominique LaSalle and Umit Catalyurek},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cooperative minibatching in graph neural networks},
  url          = {https://openreview.net/forum?id=f6yMdmrD2g},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual learning of stochastic policies with continuous actions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fC4bh1PmZr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual reasoning from logged data has become increasingly important for many applications such as web advertising or healthcare. In this paper, we address the problem of learning stochastic policies with continuous actions from the viewpoint of counterfactual risk minimization (CRM). While the CRM framework is appealing and well studied for discrete actions, the continuous action case raises new challenges about modelization, optimization, and~offline model selection with real data which turns out to be particularly challenging. Our paper contributes to these three aspects of the CRM estimation pipeline. First, we introduce a modelling strategy based on a joint kernel embedding of contexts and actions, which overcomes the shortcomings of previous discretization approaches. Second, we empirically show that the optimization aspect of counterfactual learning is important, and we demonstrate the benefits of proximal point algorithms and smooth estimators. Finally, we propose an evaluation protocol for offline policies in real-world logged systems, which is challenging since policies cannot be replayed on test data, and we release a new large-scale dataset along with multiple synthetic, yet realistic, evaluation setups.},
  archive      = {J_TMLR},
  author       = {Houssam Zenati and Alberto Bietti and Matthieu Martin and Eustache Diemert and Pierre Gaillard and Julien Mairal},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Counterfactual learning of stochastic policies with continuous actions},
  url          = {https://openreview.net/forum?id=fC4bh1PmZr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying axiomatic mathematical transformation steps using tree-structured pointer networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gLQ801ewwp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of mathematical relations has become a new area of research in deep learning. A major focus lies on determining mathematical equivalence. While previous work has simply approached the task as a binary classification without providing further insight into the underlying decision, we aim to iteratively find a sequence of necessary steps to transform a mathematical expression into an arbitrary equivalent form. Each step in this sequence is specified by an axiom together with its position of application. We denote this task as Stepwise Equation Transformation Identification (SETI) task. To solve the task efficiently, we further propose TreePointerNet, a novel architecture which exploits the inherent tree structure of mathematical equations and consists of three key building blocks: (i) a transformer model tailored to work on hierarchically tree-structured equations, making use of (ii) a copy-pointer mechanism to extract the exact location of a transformation in the tree and finally (iii) custom embeddings that map distinguishable occurrences of the same token type to a common embedding. In addition, we introduce new datasets of equations for the SETI task. We benchmark our model against various baselines and perform an ablation study to quantify the influence of our custom embeddings and the copy-pointer component. Furthermore, we test the robustness of our model on data of unseen complexity. Our results clearly show that incorporating the hierarchical structure, embeddings and copy-pointer into a single model is highly beneficial for solving the SETI task},
  archive      = {J_TMLR},
  author       = {Sebastian Wankerl and Jan Pfister and Andrzej Dulny and Gerhard Götz and Andreas Hotho},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identifying axiomatic mathematical transformation steps using tree-structured pointer networks},
  url          = {https://openreview.net/forum?id=gLQ801ewwp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When precision meets position: BFloat16 breaks down RoPE in long-context training. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gwXfZ3xkUq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extending context window sizes allows large language models (LLMs) to process longer sequences and handle more complex tasks. Rotary Positional Embedding (RoPE) has become the de facto standard due to its relative positional encoding properties that benefit long-context training. However, we observe that using RoPE with BFloat16 format results in numerical issues, causing it to deviate from its intended relative positional encoding, especially in long-context scenarios. This issue arises from BFloat16's limited precision and accumulates as context length increases, with the first token contributing significantly to this problem. Despite its limitations, BFloat16 remains desirable for its computational efficiency, particularly given the substantial memory overhead required to extend the context window. To improve long-context training under BFloat16, we develop AnchorAttention, a plug-and-play attention method that enhances long-context capabilities, and speeds up training. AnchorAttention reduces unnecessary attention computations, maintains semantic coherence, and boosts computational efficiency by treating the first token as a shared anchor with a consistent position ID, making it visible to all documents within the training context. Experiments on three types of LLMs demonstrate that AnchorAttention significantly improves long-context performance and reduces training time by over 50\% compared to standard full attention mechanisms, while preserving the original LLM's capabilities on general tasks.},
  archive      = {J_TMLR},
  author       = {Haonan Wang and Qian Liu and Chao Du and Tongyao Zhu and Cunxiao Du and Kenji Kawaguchi and Tianyu Pang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When precision meets position: BFloat16 breaks down RoPE in long-context training},
  url          = {https://openreview.net/forum?id=gwXfZ3xkUq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALTA: Compiler-based analysis of transformers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=h751wl9xiR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework --- language specification, symbolic interpreter, and weight compiler --- available to the community to enable further applications and insights.},
  archive      = {J_TMLR},
  author       = {Peter Shaw and James Cohan and Jacob Eisenstein and Kenton Lee and Jonathan Berant and Kristina Toutanova},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ALTA: Compiler-based analysis of transformers},
  url          = {https://openreview.net/forum?id=h751wl9xiR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent space energy-based neural ODEs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hCxtlfvL22'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions.},
  archive      = {J_TMLR},
  author       = {Sheng Cheng and Deqian Kong and Jianwen Xie and Kookjin Lee and Ying Nian Wu and Yezhou Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent space energy-based neural ODEs},
  url          = {https://openreview.net/forum?id=hCxtlfvL22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The RealHumanEval: Evaluating large language models’ abilities to support programmers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hGaWq5Buj7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of large language models for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), or more recently using human preferences of LLM responses. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks or more preferred LLM responses translate to programmer productivity when coding with LLMs, including time spent coding. We introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=243) using RealHumanEval in which users interacted with seven LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we find that improvements in benchmark performance lead to increased programmer productivity; however gaps in benchmark versus human performance are not proportional---a trend that holds across both forms of LLM support. In contrast, we find that programmer preferences do not correlate with their actual performance, motivating the need for better proxy signals. We open-source RealHumanEval to enable human-centric evaluation of new models and the study data to facilitate efforts to improve code models.},
  archive      = {J_TMLR},
  author       = {Hussein Mozannar and Valerie Chen and Mohammed Alsobay and Subhro Das and Sebastian Zhao and Dennis Wei and Manish Nagireddy and Prasanna Sattigeri and Ameet Talwalkar and David Sontag},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The RealHumanEval: Evaluating large language models’ abilities to support programmers},
  url          = {https://openreview.net/forum?id=hGaWq5Buj7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adapt then unlearn: Exploring parameter space semantics for unlearning in generative adversarial networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jAHEBivObO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the growing concerns about privacy and regulatory compliance, it is desirable to regulate the output of generative models. To that end, the objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained Generative Adversarial Network (GAN) where the underlying training data set is inaccessible. Our approach is inspired by the observation that the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed two-stage method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. In the initial stage, we adapt a pre-trained GAN on a set of negative samples (containing undesired features) provided by the user. Subsequently, we train the original pre-trained GAN using positive samples, along with a repulsion regularizer. This regularizer encourages the learned model parameters to move away from the parameters of the adapted model (first stage) while not degrading the generation quality. We provide theoretical insights into the proposed method. To the best of our knowledge, our approach stands as the first method addressing unlearning within the realm of high-fidelity GANs (such as StyleGAN). We validate the effectiveness of our method through comprehensive experiments, encompassing both class-level unlearning on the MNIST and AFHQ dataset and feature-level unlearning tasks on the CelebA-HQ dataset. Our code and implementation is available at: https://github.com/atriguha/Adapt_Unlearn.},
  archive      = {J_TMLR},
  author       = {Piyush Tiwary and Atri Guha and Subhodip Panda and Prathosh AP},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adapt then unlearn: Exploring parameter space semantics for unlearning in generative adversarial networks},
  url          = {https://openreview.net/forum?id=jAHEBivObO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video-language critic: Transferable reward functions for language-conditioned robotics. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jJOVpnNrEp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language is often the easiest and most convenient modality for humans to specify tasks for robots. However, learning to ground language to behavior typically requires impractical amounts of diverse, language-annotated demonstrations collected on each target robot. In this work, we aim to separate the problem of what to accomplish from how to accomplish it, as the former can benefit from substantial amounts of external observation-only data, and only the latter depends on a specific robot embodiment. To this end, we propose Video-Language Critic, a reward model that can be trained on readily available cross-embodiment data using contrastive learning and a temporal ranking objective, and use it to score behavior traces from a separate actor. When trained on Open X-Embodiment data, our reward model enables 2x more sample-efficient policy training on Meta-World tasks than a sparse reward only, despite a significant domain gap. Using in-domain data but in a challenging task generalization setting on Meta-World, we further demonstrate more sample-efficient training than is possible with prior language-conditioned reward models that are either trained with binary classification, use static images, or do not leverage the temporal information present in video data.},
  archive      = {J_TMLR},
  author       = {Minttu Alakuijala and Reginald McLean and Isaac Woungang and Nariman Farsad and Samuel Kaski and Pekka Marttinen and Kai Yuan},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Video-language critic: Transferable reward functions for language-conditioned robotics},
  url          = {https://openreview.net/forum?id=jJOVpnNrEp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combating inter-task confusion and catastrophic forgetting by metric learning and re-using a past trained model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jRbKsQ3sYO'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the vast research on class-incremental learning (IL), the critical issues have not yet been fully addressed. In this paper, utilizing metric learning, we tackle two fundamental issues of class-incremental learning (class-IL), inter-task confusion and catastrophic forgetting, which have not been fully addressed yet in the literature. To mitigate the inter-task confusion, we propose an innovative loss by utilizing the centroids of previously learned classes as negatives and current data samples as positives in the embedding space, which reduces overlaps between the classes of the current and past tasks in the embedding space. To combat catastrophic forgetting, we also propose that the past trained model is stored and re-used for generating past data samples for only one previous task. Based on this, we further propose a novel knowledge distillation approach utilizing inter-class embedding clusters, intra-class embedding clusters, and mean square embedding distances. Extensive experiments performed on MNIST, CIFAR-10, CIFAR-100, Mini-ImageNet, and TinyImageNet show that our proposed exemplar-free metric class-IL method achieves the state-of-the-art performance, beating all baseline methods by notable margins. We release our codes as the supplementary materials.},
  archive      = {J_TMLR},
  author       = {Sayedmoslem Shokrolahi and IL MIN KIM},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Combating inter-task confusion and catastrophic forgetting by metric learning and re-using a past trained model},
  url          = {https://openreview.net/forum?id=jRbKsQ3sYO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards measuring predictability: To which extent data-driven approaches can extract deterministic relations from data exemplified with time series prediction and classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jZBAVFGUUo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing loss functions is one important ingredient for machine learning to fit parameters such that the machine learning models extract relations hidden in the data. The smaller the loss function value on various splittings of a dataset, the better the machine learning model is assumed to perform. However, datasets are usually generated by dynamics consisting of deterministic components, where relations are clearly defined and consequently learnable, as well as stochastic parts where outcomes are random and thus not predictable. Depending on the amplitude of the deterministic and stochastic processes, the best achievable loss function value varies and is usually not known in real data science scenarios. In this research, a statistical framework is developed that provides measures to address the predictability of a target given the available input data and, after training a machine learning model, how much of the deterministic relations have been missed by the model. Consequently, the presented framework allows to differentiate model errors into unpredictable parts regarding the given input and a systematic miss of deterministic relations. The work extends the definition of model success or failure as well as the convergence of a training process. Moreover, it is demonstrated how such measures can enrich the procedure of model training. The framework is showcased with time series data on different synthetic and real-world datasets. The code is available at https://github.com/Saleh-Gholam-Zadeh/predictability_measure.},
  archive      = {J_TMLR},
  author       = {Saleh GHOLAM ZADEH and Vaisakh Shaj and Patrick Jahnke and Gerhard Neumann and Tim Breitenbach},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards measuring predictability: To which extent data-driven approaches can extract deterministic relations from data exemplified with time series prediction and classification},
  url          = {https://openreview.net/forum?id=jZBAVFGUUo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized negative reservoir for incremental learning in recommender systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=jrUUk5Fskm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the incremental learning framework. In this work, we propose a personalized negative reservoir strategy, which is used to obtain negative samples for the standard triplet loss of graph-based recommendation systems. Our technique balances alleviation of forgetting with plasticity by encouraging the model to remember stable user preferences and selectively forget when user interests change. We derive the mathematical formulation of a negative sampler to populate and update the reservoir. We integrate our design in three SOTA and commonly used incremental recommendation models. We show that these concrete realizations of our negative reservoir framework achieve state-of-the-art results for standard benchmarks using multiple top-k evaluation metrics.},
  archive      = {J_TMLR},
  author       = {Antonios Valkanas and Yuening Wang and Yingxue Zhang and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized negative reservoir for incremental learning in recommender systems},
  url          = {https://openreview.net/forum?id=jrUUk5Fskm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verbalized machine learning: Revisiting machine learning with language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k3Ab6RuJE9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the progress of large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning (ML) models that are typically optimized over a continuous parameter space, VML constrains the parameter space to be human-interpretable natural language. Such a constraint leads to a new perspective of function approximation, where an LLM with a text prompt can be viewed as a function parameterized by the text prompt. Guided by this perspective, we revisit classical ML problems, such as regression and classification, and find that these problems can be solved by an LLM-parameterized learner and optimizer. The major advantages of VML include (1) easy encoding of inductive bias: prior knowledge about the problem and hypothesis class can be encoded in natural language and fed into the LLM-parameterized learner; (2) automatic model class selection: the optimizer can automatically select a model class based on data and verbalized prior knowledge, and it can update the model class during training; and (3) interpretable learner updates: the LLM-parameterized optimizer can provide explanations for why an update is performed. We empirically verify the effectiveness of VML, and hope that VML can serve as a stepping stone to stronger interpretability.},
  archive      = {J_TMLR},
  author       = {Tim Z. Xiao and Robert Bamler and Bernhard Schölkopf and Weiyang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Verbalized machine learning: Revisiting machine learning with language models},
  url          = {https://openreview.net/forum?id=k3Ab6RuJE9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FaAlGrad: Fairness through alignment of gradients across different subpopulations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=k4AxEwTaHq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing deployment of Machine Learning systems has increased interest in systems optimized for other important criteria along with the expected task performance. For instance, machine learning models often exhibit biases that lead to unfair outcomes for certain protected subpopulations. This work aims to handle the bias in machine learning models and enhance their fairness by aligning the loss gradients. Specifically, leveraging the meta-learning technique, we propose a novel training framework that aligns the gradients computed across different subpopulations for learning fair classifiers. Aligning the gradients enables our framework to regularize the training process, thereby prioritizing fairness over predictive accuracy. Our experiments on multiple benchmark datasets demonstrate significant improvements in fairness metrics without having any exclusive regularizers for fairness. Thus our work contributes to developing fairer machine learning models with broader societal benefits.},
  archive      = {J_TMLR},
  author       = {Nikita Malik and Konda Reddy Mopuri},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FaAlGrad: Fairness through alignment of gradients across different subpopulations},
  url          = {https://openreview.net/forum?id=k4AxEwTaHq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maxwell's demon at work: Efficient pruning by leveraging saturation of neurons. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nmBleuFzaN'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training neural networks, dying neurons —units becoming inactive or saturated— are traditionally seen as harmful. This paper sheds new light on this phenomenon. By exploring the impact of various hyperparameter configurations on dying neurons during training, we gather insights on how to improve upon sparse training approaches to pruning. We introduce Demon Pruning (DemP), a method that controls the proliferation of dead neurons through a combination of noise injection on active units and a one-cycled schedule regularization strategy, dynamically leading to network sparsity. Experiments on CIFAR-10 and ImageNet datasets demonstrate that DemP outperforms existing dense-to-sparse structured pruning methods, achieving better accuracy-sparsity tradeoffs while speeding up training up to 3.56$\times$. These findings provide a novel perspective on dying neurons as a resource for efficient model compression and optimization.},
  archive      = {J_TMLR},
  author       = {Simon Dufort-Labbé and Pierluca D'Oro and Evgenii Nikishin and Irina Rish and Pierre-Luc Bacon and Razvan Pascanu and Aristide Baratin},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maxwell's demon at work: Efficient pruning by leveraging saturation of neurons},
  url          = {https://openreview.net/forum?id=nmBleuFzaN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private source-target clustering. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ojeCoOKwWp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a new private variant of the Source-Target Clustering (STC) setting, which was introduced by de Mathelin et al. (2022). In STC, there is a target dataset that needs to be clustered by selecting centers, in addition to centers that are already provided in a separate source dataset. The goal is to select centers from the target, such that the target clustering cost given the additional source centers is minimized. We consider private STC, in which the source dataset is private and should only be used under the constraint of differential privacy. This is motivated by scenarios in which the existing centers are private, for instance because they represent individuals in a social network. We derive lower bounds for the private STC objective, illustrating the theoretical limitations on worst-case guarantees for this setting. We then present a differentially private algorithm with asymptotically advantageous results under a data-dependent analysis, in which the guarantee depends on properties of the dataset, as well as more practical variants. We demonstrate in experiments the reduction in clustering cost that is obtained by our practical algorithms compared to baseline approaches.},
  archive      = {J_TMLR},
  author       = {Shachar Schnapp and Sivan Sabato},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private source-target clustering},
  url          = {https://openreview.net/forum?id=ojeCoOKwWp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture degree-corrected stochastic block model for multi-group community detection in multiplex graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=p9KSFrTLx0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex graphs have emerged as a powerful tool for modeling complex data structures due to their ability to handle multiple relational layers. Clustering within a multiplex graph can involve merging vertices into communities that are consistent across all layers, grouping similar layers into clusters, or creating overlapping clusters among vertices and layers. However, a multiplex graph may exhibit distinct vertex communities based on the specific layers to which a vertex is connected. This scenario, termed multi-group community detection, significantly enhances the accuracy of clustering processes and aids in the interpretation of partitions. To date, the current literature on state-of-the-art community detection has not extensively addressed this modeling approach. In this paper, we introduce a novel methodology referred to as the "Mixture Degree-Corrected Stochastic Block Model." This generative model, an extension of the widely utilized Degree-Corrected Stochastic Block Model (DCSBM), is designed to cluster similar layers by their community structures while simultaneously identifying communities within each layer's group. We provide a rigorous definition of the model and utilize an iterative technique to perform inference computations. Furthermore, we assess the identifiability of our proposed model and demonstrate the consistency of the maximum likelihood function through analytical analysis. The effectiveness of our method is evaluated using both real-word data sets and synthetic graphs.},
  archive      = {J_TMLR},
  author       = {Noureddine Henka and Mohamad Assaad and Sami Tazi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture degree-corrected stochastic block model for multi-group community detection in multiplex graphs},
  url          = {https://openreview.net/forum?id=p9KSFrTLx0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On training-conditional conformal prediction and binomial proportion confidence intervals. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pSk5qyt1ob'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the expectation of a Bernoulli random variable based on $N$ independent trials is a classical problem in statistics, typically addressed using Binomial Proportion Confidence Intervals (BPCI). In the control systems community, many critical tasks—such as certifying the statistical safety of dynamical systems—can be formulated as BPCI problems. Conformal Prediction (CP), a distribution-free technique for uncertainty quantification, has gained significant attention in recent years and has been applied to various control systems problems, particularly to address uncertainties in learned dynamics or controllers. A variant known as training-conditional CP was recently employed to tackle the problem of safety certification. In this note, we highlight that the use of training-conditional CP in this context does not provide valid safety guarantees. We demonstrate why CP is unsuitable for BPCI problems and argue that traditional BPCI methods are better suited for statistical safety certification.},
  archive      = {J_TMLR},
  author       = {Rudi Coppola and Manuel Mazo Espinosa},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On training-conditional conformal prediction and binomial proportion confidence intervals},
  url          = {https://openreview.net/forum?id=pSk5qyt1ob},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AttnGCG: Enhancing jailbreaking attacks on LLMs with attention manipulation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=prVLANCshF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the vulnerabilities of transformer-based Large Language Models (LLMs) to jailbreaking attacks, focusing specifically on the optimization-based Greedy Coordinate Gradient (GCG) strategy. We first observe a positive correlation between the effectiveness of attacks and the internal behaviors of the models. For instance, attacks tend to be less effective when models pay more attention to system prompts designed to ensure LLM safety alignment. Building on this discovery, we introduce an enhanced method that manipulates models' attention scores to facilitate LLM jailbreaking, which we term AttnGCG. Empirically, AttnGCG shows consistent improvements in attack efficacy across diverse LLMs, achieving an average increase of ~7% in the Llama-2 series and ~10% in the Gemma series. Our strategy also demonstrates robust attack transferability against both unseen harmful goals and black-box LLMs like GPT-3.5 and GPT-4. Moreover, we note our attention-score visualization is more interpretable, allowing us to gain better insights into how our targeted attention manipulation facilitates more effective jailbreaking. We release the code at https://github.com/UCSC-VLAA/AttnGCG-attack.},
  archive      = {J_TMLR},
  author       = {Zijun Wang and Haoqin Tu and Jieru Mei and Bingchen Zhao and Yisen Wang and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AttnGCG: Enhancing jailbreaking attacks on LLMs with attention manipulation},
  url          = {https://openreview.net/forum?id=prVLANCshF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How does code pretraining affect language model task performance?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pxxmUKKgel'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models are increasingly trained on corpora containing both natural language and non-linguistic data like source code. Aside from aiding programming-related tasks, anecdotal evidence suggests that including code in pretraining corpora may improve performance on other, unrelated tasks, yet to date no work has been able to establish a causal connection by controlling between language and code data. Here we do just this. We pretrain language models on datasets which interleave natural language and code in two different settings: competitive, in which the total volume of data seen during pretraining is held constant; and additive, in which the volume of language data is held constant. We study how the pretraining mixture affects performance on (a) compositionality, measured by generalization accuracy on semantic parsing and syntactic transformation tasks, and more broadly on (b) downstream non-code-related objectives, measured by performance on tasks from the BigBench benchmark. We find that pretraining on higher proportions of code improves performance on compositional tasks involving structured output (like semantic parsing), and mathematics. Conversely, increase code mixture can harm performance on other tasks, including on tasks that requires sensitivity to linguistic structure such as syntax or morphology, and tasks measuring real-world knowledge.},
  archive      = {J_TMLR},
  author       = {Jackson Petty and Sjoerd van Steenkiste and Tal Linzen},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How does code pretraining affect language model task performance?},
  url          = {https://openreview.net/forum?id=pxxmUKKgel},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are large language models really robust to word-level perturbations?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=rWSiBknwQa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift advancement in the scales and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLMs, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, potentially ignoring the superior generation capabilities of contemporary LLMs. To investigate the robustness of LLMs while using their generation ability, we propose a novel rational evaluation pipeline that leverages reward models as diagnostic tools to evaluate the long conversation generated from more challenging open questions by LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Longer conversations manifest the comprehensive grasp of language models in terms of their proficiency in understanding questions, a capability not entirely encompassed by individual words or letters.Our extensive empirical experiments demonstrate that TREvaL provides an identification for the lack of robustness of nowadays LLMs.Notably, we are surprised to discover that robustness tends to decrease as fine-tuning (SFT and RLHF) is conducted, calling for more attention on the robustness during alignment process.},
  archive      = {J_TMLR},
  author       = {Haoyu Wang and Guozheng Ma and Cong Yu and Ning Gui and Linrui Zhang and Zhiqi Huang and Suwei Ma and Yongzhe Chang and Sen Zhang and Li Shen and Xueqian Wang and Peilin Zhao and Dacheng Tao},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Are large language models really robust to word-level perturbations?},
  url          = {https://openreview.net/forum?id=rWSiBknwQa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty representations in state-space layers for deep reinforcement learning under partial observability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=rfPns0WJyg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal decision-making under partial observability requires reasoning about the uncertainty of the environment’s hidden state. However, most reinforcement learning architectures handle partial observability with sequence models that have no internal mechanism to incorporate uncertainty in their hidden state representation, such as recurrent neural networks, deterministic state-space models and transformers. Inspired by advances in probabilistic world models for reinforcement learning, we propose a standalone Kalman filter layer that performs closed-form Gaussian inference in linear state-space models and train it end-to-end within a model-free architecture to maximize returns. Similar to efficient linear recurrent layers, the Kalman filter layer processes sequential data using a parallel scan, which scales logarithmically with the sequence length. By design, Kalman filter layers are a drop-in replacement for other recurrent layers in standard model-free architectures, but importantly they include an explicit mechanism for probabilistic filtering of the latent state representation. Experiments in a wide variety of tasks with partial observability show that Kalman filter layers excel in problems where uncertainty reasoning is key for decision-making, outperforming other stateful models.},
  archive      = {J_TMLR},
  author       = {Carlos E. Luis and Alessandro Giacomo Bottero and Julia Vinogradska and Felix Berkenkamp and Jan Peters},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty representations in state-space layers for deep reinforcement learning under partial observability},
  url          = {https://openreview.net/forum?id=rfPns0WJyg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class incremental learning from first principles: A review. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sZdtTJInUg'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning systems attempt to efficiently learn over time without forgetting previously acquired knowledge. In recent years, there has been an explosion of work on continual learning, mainly focused on the class-incremental learning (CIL) setting. In this review, we take a step back and reconsider the CIL problem. We reexamine the problem definition and describe its unique challenges, contextualize existing solutions by analyzing non-continual approaches, and investigate the implications of various problem configurations. Our goal is to provide an alternative perspective to existing work on CIL and direct attention toward unexplored aspects of the problem.},
  archive      = {J_TMLR},
  author       = {Neil Ashtekar and Jingxi Zhu and Vasant G Honavar},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Class incremental learning from first principles: A review},
  url          = {https://openreview.net/forum?id=sZdtTJInUg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Increasing both batch size and learning rate accelerates stochastic gradient descent. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=sbmp55k6iE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of mini-batch stochastic gradient descent (SGD) strongly depends on setting the batch size and learning rate to minimize the empirical loss in training the deep neural network. In this paper, we present theoretical analyses of mini-batch SGD with four schedulers: (i) constant batch size and decaying learning rate scheduler, (ii) increasing batch size and decaying learning rate scheduler, (iii) increasing batch size and increasing learning rate scheduler, and (iv) increasing batch size and warm-up decaying learning rate scheduler. We show that mini-batch SGD using scheduler (i) does not always minimize the expectation of the full gradient norm of the empirical loss, whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore, schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides numerical results of supporting analyses showing that using scheduler (iii) or (iv) minimizes the full gradient norm of the empirical loss faster than using scheduler (i) or (ii).},
  archive      = {J_TMLR},
  author       = {Hikaru Umeda and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Increasing both batch size and learning rate accelerates stochastic gradient descent},
  url          = {https://openreview.net/forum?id=sbmp55k6iE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the robustness of analogical reasoning in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=t5cy5v9wph'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, there is debate on the extent to which they are performing general abstract reasoning versus employing shortcuts or other non-robust processes, such as ones that overly rely on similarity to what has been seen in their training data. Here we investigate the robustness of analogy-making abilities previously claimed for LLMs on three of four domains studied by Webb et al. (2023): letter-string analogies, digit matrices, and story analogies. For each of these domains we test humans and GPT models on robustness to variants of the original analogy problems—versions that test the same abstract reasoning abilities but that are likely dissimilar from tasks in the pre-training data. The performance of a system that uses robust abstract reasoning should not decline substantially on these variants. On simple letter-string analogies, we find that while the performance of humans remains high for two types of variants we tested, the GPT models’ performance declines sharply. This pattern is less pronounced as the complexity of these analogy problems is increased, as both humans and GPT models perform poorly on both the original and variant problems requiring more complex analogies. On digit-matrix problems, we find a similar pattern but only on one out of the two types of variants we tested. Lastly, we assess the robustness of humans and GPT models on story-based analogy problems, finding that, unlike humans, the performance of GPT models are susceptible to answer-order effects, and that GPT models also may be more sensitive than humans to paraphrasing. This work provides evidence that, despite previously reported successes of LLMs on zero-shot analogical reasoning, these models often lack the robustness of zero-shot human analogy- making, exhibiting brittleness on most of the variations we tested. More generally, this work points to the importance of carefully evaluating AI systems not only for accuracy but also robustness when testing their cognitive capabilities. Code, data, and results for all experiments is available at https://github.com/marthaflinderslewis/robust-analogy.},
  archive      = {J_TMLR},
  author       = {Martha Lewis and Melanie Mitchell},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating the robustness of analogical reasoning in large language models},
  url          = {https://openreview.net/forum?id=t5cy5v9wph},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing remaining useful life prediction with ensemble multi-term fourier graph neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tzFjcVqmxw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is crucial in predictive maintenance. Recently, deep learning forecasting methods, especially Spatio-Temporal Graph Neural Networks (ST-GNNs), have achieved remarkable performance in RUL prediction. Most existing ST-GNNs require searching for the graph structure before utilizing GNNs to learn spatial graph representation, and they necessitate a temporal model such as LSTM to leverage the temporal dependencies in a fixed lookback window. However, such an approach has several limitations. Firstly, it demands substantial computational resources to learn graph structures for the time series data. Secondly, independently learning spatial and temporal information disregards their inherent correlation, and thirdly, capturing information within a fixed lookback window ignores long-term dependencies across the entire time series. To mitigate the issues above, instead of treating the data within the lookback window as a sequence of graphs in ST-GNN methods, we regard it as a complete graph and employ a Fourier Graph Neural Network (FGN) to learn the spatiotemporal information within this graph in the frequency space. Additionally, we create training and test graphs with varying sizes of lookback windows, enabling the model to learn both short-term and long-term dependencies and provide multiple predictions for ensemble averaging. We also consider scenarios where sensor signals exhibit multiple operation conditions and design a sequence decomposition plugin to denoise input signals, aiming to enhance the performance of FGN. We evaluate the proposed model on two benchmark datasets, demonstrating its superior performance on the RUL prediction task compared to state-of-the-art approaches.},
  archive      = {J_TMLR},
  author       = {Ya Song and Laurens Bliek and Yaoxin Wu and Yingqian Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing remaining useful life prediction with ensemble multi-term fourier graph neural networks},
  url          = {https://openreview.net/forum?id=tzFjcVqmxw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion on graph: Augmentation of graph structure for node classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tzW948kU6x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph diffusion models have recently been proposed to synthesize entire graphs, such as molecule graphs. Although existing methods have shown great performance in generating entire graphs for graph-level learning tasks, no graph diffusion models have been developed to generate synthetic graph structures, that is, synthetic nodes and associated edges within a given graph, for node-level learning tasks. Inspired by the research in the computer vision literature using synthetic data for enhanced performance, we propose Diffusion on Graph (DoG), which generates synthetic graph structures to boost the performance of GNNs. The synthetic graph structures generated by DoG are combined with the original graph to form an augmented graph for the training of node-level learning tasks, such as node classification and graph contrastive learning (GCL). To improve the efficiency of the generation process, a Bi-Level Neighbor Map Decoder (BLND) is introduced in DoG. To mitigate the adverse effect of the noise introduced by the synthetic graph structures, a low-rank regularization method is proposed for the training of graph neural networks (GNNs) on the augmented graphs. Extensive experiments on various graph datasets for semi-supervised node classification and graph contrastive learning have been conducted to demonstrate the effectiveness of DoG with low-rank regularization. The code of DoG is available at \url{https://github.com/Statistical-Deep-Learning/DoG}.},
  archive      = {J_TMLR},
  author       = {Yancheng Wang and Changyu Liu and Yingzhen Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion on graph: Augmentation of graph structure for node classification},
  url          = {https://openreview.net/forum?id=tzW948kU6x},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PROXI: Challenging the GNNs for link prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=u9EHndbiVw'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, Graph Neural Networks (GNNs) have transformed graph representation learning. In the widely adopted message-passing GNN framework, nodes refine their representations by aggregating information from neighboring nodes iteratively. While GNNs excel in various domains, recent theoretical studies have raised concerns about their capabilities. GNNs aim to address various graph-related tasks by utilizing such node representations, however, this one-size-fits-all approach proves suboptimal for diverse tasks. Motivated by these observations, we conduct empirical tests to compare the performance of current GNN models with more conventional and direct methods in link prediction tasks. Introducing our model, PROXI, which leverages proximity information of node pairs in both graph and attribute spaces, we find that standard machine learning (ML) models perform competitively, even outperforming cutting-edge GNN models when applied to these proximity metrics derived from node neighborhoods and attributes. This holds true across both homophilic and heterophilic networks, as well as small and large benchmark datasets, including those from the Open Graph Benchmark (OGB). Moreover, we show that augmenting traditional GNNs with PROXI significantly boosts their link prediction performance. Our empirical findings corroborate the previously mentioned theoretical observations and imply that there exists ample room for enhancement in current GNN models to reach their potential.},
  archive      = {J_TMLR},
  author       = {Astrit Tola and Jack Myrick and Baris Coskunuzer},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PROXI: Challenging the GNNs for link prediction},
  url          = {https://openreview.net/forum?id=u9EHndbiVw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepRRTime: Robust time-series forecasting with a regularized INR basis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uDRzORdPT7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a simple, inexpensive, theoretically motivated regularization term to enhance the robustness of deep time-index models for time-series forecasting. Recently, DeepTime demonstrated that this class of models can rival state-of-the-art deep historical-value models on the long time-series forecasting (LTSF) benchmarks. The DeepTime framework comprises two key components: (1) a time-indexed basis parameterized as an implicit neural representation (INR), and (2) a meta-learning formulation that fits observed data to this basis via ridge regression, then extrapolates the result to generate forecasts. Our regularization term encourages the time-indexed basis elements to be more unit standardized and less mutually correlated, intended to enable more robust ridge regression. The regularized variant matches or outperforms DeepTime on all LTSF benchmarks. Moreover, it is significantly more resilient to missing values in the lookback window at test time, enhances forecast accuracy when applied to higher-frequency data than it was trained on, and boosts performance when trained on smaller datasets. Overall, we conclude that our regularized approach sets a new state-of-the-art for deep time-index models.},
  archive      = {J_TMLR},
  author       = {Chandramouli Shama Sastry and Mahdi Gilany and Kry Yik-Chau Lui and Martin Magill and Alexander Pashevich},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DeepRRTime: Robust time-series forecasting with a regularized INR basis},
  url          = {https://openreview.net/forum?id=uDRzORdPT7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wonderful team: Zero-shot physical task planning with visual LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=udVkqIDYSM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Wonderful Team, a multi-agent Vision Large Language Model (VLLM) framework for executing high-level robotic planning in a zero-shot regime. In our context, zero-shot high-level planning means that for a novel environment, we provide a VLLM with an image of the robot's surroundings and a task description, and the VLLM outputs the sequence of actions necessary for the robot to complete the task. Unlike previous methods for high-level visual planning for robotic manipulation, our method uses VLLMs for the entire planning process, enabling a more tightly integrated loop between perception, control, and planning. As a result, Wonderful Team's performance on real-world semantic and physical planning tasks often exceeds methods that rely on separate vision systems. For example, we see an average 40% success rate improvement on VimaBench over prior methods such as NLaP, an average 30% improvement over Trajectory Generators on tasks from the Trajectory Generator paper, including drawing and wiping a plate, and an average 70% improvement over Trajectory Generators on a new set of semantic reasoning tasks including environment rearrangement with implicit linguistic constraints. We hope these results highlight the rapid improvements of VLLMs in the past year, and motivate the community to consider VLLMs as an option for some high-level robotic planning problems in the future.},
  archive      = {J_TMLR},
  author       = {Zidan Wang and Rui Shen and Bradly C. Stadie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wonderful team: Zero-shot physical task planning with visual LLMs},
  url          = {https://openreview.net/forum?id=udVkqIDYSM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating interpretable methods via geometric alignment of functional distortions. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ukLxqA8zXj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability researchers face a universal question: without access to ground truth labels, how can the faithfulness of an explanation to its model be determined? Despite immense efforts to develop new evaluation methods, current approaches remain in a pre-paradigmatic state: fragmented, difficult to calibrate, and lacking cohesive theoretical grounding. Observ- ing the lack of a unifying theory, we propose a novel evaluative criterion entitled Generalised Explanation Faithfulness (GEF) which is centered on explanation-to-model alignment, and integrates existing perturbation-based evaluations to eliminate the need for singular, task-specific evaluations. Complementing this unifying perspective, from a geometric point of view, we reveal a prevalent yet critical oversight in current evaluation practice: the failure to account for the learned geometry, and non-linear mapping present in the model, and explanation spaces. To solve this, we propose a general-purpose, threshold-free faithfulness evaluator GEF that incorporates principles from differential geometry, and facilitates evaluation agnostically across tasks, and interpretability approaches. Through extensive cross-domain benchmarks on natural language processing, vision, and tabular tasks, we provide first-of-its-kind insights into the comparative performance of various interpretable methods. This includes local linear approximators, global feature visualisation methods, large language models as post-hoc explainers, and sparse autoencoders. Our contributions are important to the interpretability and AI safety communities, offering a principled, unified approach for evaluation.},
  archive      = {J_TMLR},
  author       = {Anna Hedström and Philine Lou Bommer and Thomas F Burns and Sebastian Lapuschkin and Wojciech Samek and Marina MC Höhne},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating interpretable methods via geometric alignment of functional distortions},
  url          = {https://openreview.net/forum?id=ukLxqA8zXj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-level representation learning with joint-embedding predictive architectures. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=v47f4DwYZb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal y from the latent representation of a context signal x. JEPAs bypass the need for negative and positive samples, traditionally required by contrastive learning while avoiding the overfitting issues associated with generative pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm by proposing a Graph Joint-Embedding Predictive Architecture (Graph-JEPA). In particular, we employ masked modeling and focus on predicting the latent representations of masked subgraphs starting from the latent representation of a context subgraph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative prediction objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2D plane. Through multiple experimental evaluations, we show that Graph-JEPA can learn highly semantic and expressive representations, as shown by the downstream performance in graph classification, regression, and distinguishing non-isomorphic graphs. The code is available at https://github.com/geriskenderi/graph-jepa.},
  archive      = {J_TMLR},
  author       = {Geri Skenderi and Hang Li and Jiliang Tang and Marco Cristani},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph-level representation learning with joint-embedding predictive architectures},
  url          = {https://openreview.net/forum?id=v47f4DwYZb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax lower bounds for estimating distributions on low-dimensional spaces. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wIgRV336hC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent statistical analyses of Generative Adversarial Networks (GAN) suggest that the error in estimating the target distribution in terms of the $\beta$-H\"{o}lder Integral Probability Metric (IPM) scales as $\mathcal{O}\left(n^{-\frac{\beta}{\overline{d}_{\mathbb{M}}+\delta}} \vee n^{-1/2} \log n \right)$. Here $\overline{d}_{\mathbb{M}}$ is the upper Minkowski dimension of the corresponding support $\mathbb{M}$ of the data distribution and $\delta$ is a positive constant. It is, however, unknown as to whether this rate is minimax optimal, i.e. whether there are estimators that achieve a better test-error rate. This paper demonstrates that the minimax rate for estimating unknown distributions in the $\beta$-H\"{o}lder IPM on $\mathbb{M}$ scales as $\Omega\left(n^{-\frac{\beta}{\underline{d}_{\mathbb{M}}-\delta}} \vee n^{-1/2}\right)$, where $\underline{d}_{\mathbb{M}}$ is the lower Minkowski dimension of $\mathbb{M}$. Thus if the low-dimensional structure $\mathbb{M}$ is regular in the Minkowski sense, i.e. $\overline{d}_{\mathbb{M}} = \underline{d}_{\mathbb{M}}$, GANs are roughly minimax optimal in estimating distributions on $\mathbb{M}$. Further, the paper shows that the minimax estimation rate in the $p$-Wasserstein metric scales as $\Omega\left(n^{-\frac{1}{\underline{d}_{\mathbb{M}}-\delta}} \vee n^{-1/(2p)}\right)$.},
  archive      = {J_TMLR},
  author       = {Saptarshi Chakraborty},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Minimax lower bounds for estimating distributions on low-dimensional spaces},
  url          = {https://openreview.net/forum?id=wIgRV336hC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The elusive pursuit of reproducing PATE-GAN: Benchmarking, auditing, debugging. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wcxrJcJ7vq'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data created by differentially private (DP) generative models is increasingly used in real-world settings. In this context, PATE-GAN has emerged as one of the most popular algorithms, combining Generative Adversarial Networks (GANs) with the private training approach of PATE (Private Aggregation of Teacher Ensembles). In this paper, we set out to reproduce the utility evaluation from the original PATE-GAN paper, compare available implementations, and conduct a privacy audit. More precisely, we analyze and benchmark six open-source PATE-GAN implementations, including three by (a subset of) the original authors. First, we shed light on architecture deviations and empirically demonstrate that none reproduce the utility performance reported in the original paper. We then present an in-depth privacy evaluation, which includes DP auditing, and show that \textit{all implementations leak more privacy than intended}. Furthermore, we uncover \textit{19 privacy violations} and 5 other bugs in these six open-source implementations. Lastly, our codebase is available from: \url{https://github.com/spalabucr/pategan-audit}.},
  archive      = {J_TMLR},
  author       = {Georgi Ganev and Meenatchi Sundaram Muthu Selva Annamalai and Emiliano De Cristofaro},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The elusive pursuit of reproducing PATE-GAN: Benchmarking, auditing, debugging},
  url          = {https://openreview.net/forum?id=wcxrJcJ7vq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpreting neurons in deep vision networks with language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=x1dXvvElVd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don’t train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2× as likely to be selected as the best explanation for a neuron than the best baseline. Finally, we present a use case providing critical insights into land cover prediction models for sustainability applications.},
  archive      = {J_TMLR},
  author       = {Nicholas Bai and Rahul Ajay Iyer and Tuomas Oikarinen and Akshay R. Kulkarni and Tsui-Wei Weng},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interpreting neurons in deep vision networks with language models},
  url          = {https://openreview.net/forum?id=x1dXvvElVd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 2023 foundation model transparency index. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=x6fXnsM9Ez'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.},
  archive      = {J_TMLR},
  author       = {Rishi Bommasani and Kevin Klyman and Shayne Longpre and Sayash Kapoor and Nestor Maslej and Betty Xiong and Daniel Zhang and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The 2023 foundation model transparency index},
  url          = {https://openreview.net/forum?id=x6fXnsM9Ez},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster diffusion through temporal attention decomposition. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xXs2GKXPnH'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the role of the attention mechanism during inference in text-conditional diffusion models. Empirical observations suggest that cross-attention outputs converge to a fixed point after several inference steps. The convergence time naturally divides the entire inference process into two phases: an initial phase for planning text-oriented visual semantics, which are then translated into images in a subsequent fidelity-improving phase. Cross-attention is essential in the initial phase but almost irrelevant thereafter. Self-attention, however, initially plays a minor role but becomes increasingly important in the second phase. These findings yield a simple and training-free method called TGATE which efficiently generates images by caching and reusing attention outputs at scheduled time steps. Experiments show TGATE’s broad applicability to various existing text-conditional diffusion models which it speeds up by 10-50%. The code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE.},
  archive      = {J_TMLR},
  author       = {Haozhe Liu and Wentian Zhang and Jinheng Xie and Francesco Faccio and Mengmeng Xu and Tao Xiang and Mike Zheng Shou and Juan-Manuel Perez-Rua and Jürgen Schmidhuber},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Faster diffusion through temporal attention decomposition},
  url          = {https://openreview.net/forum?id=xXs2GKXPnH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially frozen random networks contain compact strong lottery tickets. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=xpnPYfufhz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning—strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated that SLTs could also be found within a randomly pruned source network. This phenomenon can be exploited to further compress the small memory size required by SLTs. However, their method is limited to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method for reducing the SLT memory size without restricting the sparsity of the SLTs that can be found. A random subset of the initial weights is frozen by either permanently pruning them or locking them as a fixed part of the SLT, resulting in a smaller model size. Experimental results show that Edge-Popup (Ramanujan et al., 2020; Sreenivasan et al., 2022) finds SLTs with better accuracy-to-model size trade-off within frozen networks than within dense or randomly pruned source networks. In particular, freezing $70\%$ of a ResNet on ImageNet provides $3.3\times$ compression compared to the SLT found within a dense counterpart, raises accuracy by up to $14.12$ points compared to the SLT found within a randomly pruned counterpart, and offers a better accuracy-model size trade-off than both.},
  archive      = {J_TMLR},
  author       = {Hikari Otsuka and Daiki Chijiwa and Ángel López García-Arias and Yasuyuki Okoshi and Kazushi Kawamura and Thiem Van Chu and Daichi Fujiki and Susumu Takeuchi and Masato Motomura},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partially frozen random networks contain compact strong lottery tickets},
  url          = {https://openreview.net/forum?id=xpnPYfufhz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLaVA-OneVision: Easy visual task transfer. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zKv8qULV6n'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present LLaVA-OneVision, a family of open large multimodal models (LMMs) developed by consolidating our insights into data, models, and visual representations in the LLaVA-NeXT blog series. Our experimental results demonstrate that LLaVA-OneVision is the first single model that can simultaneously push the performance boundaries of open LMMs in three important computer vision scenarios: single-image, multi-image, and video scenarios. Importantly, the design of LLaVA-OneVision allows strong transfer learning across different modalities/scenarios, yielding new emerging capabilities. In particular, strong video understanding and cross-scenario capabilities are demonstrated through task transfer from images to videos.},
  archive      = {J_TMLR},
  author       = {Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLaVA-OneVision: Easy visual task transfer},
  url          = {https://openreview.net/forum?id=zKv8qULV6n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural material point method for particle-based emulation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zSK81A2hxQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mesh-free Lagrangian methods are widely used for simulating fluids, solids, and their complex interactions due to their ability to handle large deformations and topological changes. These physics simulators, however, require substantial computational resources for accurate simulations. To address these issues, deep learning emulators promise faster and scalable simulations, yet they often remain expensive and difficult to train, limiting their practical use. Inspired by the Material Point Method (MPM), we present NeuralMPM, a neural framework for particle-based emulation. NeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes updates on grid nodes using image-to-image neural networks, and interpolates back to the particles. Similarly to MPM, NeuralMPM benefits from the regular voxelized representation to simplify the computation of the state dynamics, while avoiding the drawbacks of mesh-based Eulerian methods. We demonstrate the advantages of NeuralMPM on 6 datasets, including fluid dynamics and fluid-solid interactions simulated with MPM and Smoothed Particles Hydrodynamics (SPH). Compared to GNS and DMCF, NeuralMPM reduces training time from 10 days to 15 hours, memory consumption by 10x-100x, and increases inference speed by 5x-10x, while achieving comparable or superior long-term accuracy, making it a promising approach for practical forward and inverse problems. A project page is available at https://neuralmpm.isach.be/.},
  archive      = {J_TMLR},
  author       = {Omer Rochman-Sharabi and Sacha Lewin and Gilles Louppe},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A neural material point method for particle-based emulation},
  url          = {https://openreview.net/forum?id=zSK81A2hxQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zjxKrb4ehr'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions avoiding any Lipschitzness assumption on the score function. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm. Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm.},
  archive      = {J_TMLR},
  author       = {Stefano Bruno and Ying Zhang and Dongyoung Lim and Omer Deniz Akyildiz and Sotirios Sabanis},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates},
  url          = {https://openreview.net/forum?id=zjxKrb4ehr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bigger is not always better: Scaling properties of latent diffusion models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0u7pWfjri5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the scaling properties of latent diffusion models (LDMs) with an emphasis on their sampling efficiency. While improved network architecture and inference algorithms have shown to effectively boost sampling efficiency of diffusion models, the role of model size---a critical determinant of sampling efficiency---has not been thoroughly examined. Through empirical analysis of established text-to-image diffusion models, we conduct an in-depth investigation into how model size influences sampling efficiency across varying sampling steps. Our findings unveil a surprising trend: when operating under a given inference budget, smaller models frequently outperform their larger equivalents in generating high-quality results. Moreover, we extend our study to demonstrate the generalizability of the these findings by applying various diffusion samplers, exploring diverse downstream tasks, evaluating post-distilled models, as well as comparing performance relative to training compute. These findings open up new pathways for the development of LDM scaling strategies which can be employed to enhance generative capabilities within limited inference budgets.},
  archive      = {J_TMLR},
  author       = {Kangfu Mei and Zhengzhong Tu and Mauricio Delbracio and Hossein Talebi and Vishal M. Patel and Peyman Milanfar},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bigger is not always better: Scaling properties of latent diffusion models},
  url          = {https://openreview.net/forum?id=0u7pWfjri5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Localize-and-stitch: Efficient model merging via sparse task arithmetic. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=9CWU8Oi86d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model merging offers an effective strategy to combine the strengths of multiple finetuned models into a unified model that preserves the specialized capabilities of each. Existing methods merge models in a global manner, performing arithmetic operations across all model parameters. However, such global merging often leads to task interference, degrading the performance of the merged model. In this work, we introduce Localize-and-Stitch, a novel approach that merges models in a localized way. Our algorithm works in two steps: i) Localization: identify tiny ($1\%$ of the total parameters) localized regions in the finetuned models containing essential skills for the downstream tasks, and ii) Stitching: reintegrate only these essential regions back into the pretrained model for task synergy. We demonstrate that our approach effectively locates sparse regions responsible for finetuned performance, and the localized regions could be treated as compact and interpretable representations of the finetuned models (tasks). Empirically, we evaluate our method on various vision and language benchmarks, showing that it outperforms existing model merging methods under different data availability scenarios. Beyond strong empirical performance, our algorithm also facilitates model compression and preserves pretrained knowledge, enabling flexible and continual skill composition from multiple finetuned models with minimal storage and computational overhead.},
  archive      = {J_TMLR},
  author       = {Yifei He and Yuzheng Hu and Yong Lin and Tong Zhang and Han Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Localize-and-stitch: Efficient model merging via sparse task arithmetic},
  url          = {https://openreview.net/forum?id=9CWU8Oi86d},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRIMO: Private regression in multiple outcomes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=34vtRA3Nvu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new private regression setting we call \textit{Private Regression in Multiple Outcomes} (PRIMO), inspired by the common situation where a data analyst wants to perform a set of $l$ regressions while preserving privacy, where the features $X$ are shared across all $l$ regressions, and each regression $i \in [l]$ has a different vector of outcomes $y_i$. Naively applying existing private linear regression techniques $l$ times leads to a $\sqrt{l}$ multiplicative increase in error over the standard linear regression setting. We apply a variety of techniques including sufficient statistics perturbation (SSP) and geometric projection-based methods to develop scalable algorithms that outperform this baseline across a range of parameter regimes. In particular, we obtain \textit{no dependence on l} in the asympotic error when $l$ is sufficiently large. We apply our algorithms to the task of private genomic risk prediction for multiple phenotypes. Empirically, we find that even for values of $l$ far smaller than the theory would predict, our projection-based method improves the accuracy relative to the variant that doesn't use the projection.},
  archive      = {J_TMLR},
  author       = {Seth Neel},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PRIMO: Private regression in multiple outcomes},
  url          = {https://openreview.net/forum?id=34vtRA3Nvu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slicing unbalanced optimal transport. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AjJTg5M0r8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal transport (OT) is a powerful framework to compare probability measures, a fundamental task in many statistical and machine learning problems. Substantial advances have been made in designing OT variants which are either computationally and statistically more efficient or robust. Among them, sliced OT distances have been extensively used to mitigate optimal transport's cubic algorithmic complexity and curse of dimensionality. In parallel, unbalanced OT was designed to allow comparisons of more general positive measures, while being more robust to outliers. In this paper, we bridge the gap between those two concepts and develop a general framework for efficiently comparing positive measures. We notably formulate two different versions of sliced unbalanced OT, and study the associated topology and statistical properties. We then develop a GPU-friendly Frank-Wolfe like algorithm to compute the corresponding loss functions, and show that the resulting methodology is modular as it encompasses and extends prior related work. We finally conduct an empirical analysis of our loss functions and methodology on both synthetic and real datasets, to illustrate their computational efficiency, relevance and applicability to real-world scenarios including geophysical data.},
  archive      = {J_TMLR},
  author       = {Clément Bonet and Kimia Nadjahi and Thibault Sejourne and Kilian FATRAS and Nicolas Courty},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Slicing unbalanced optimal transport},
  url          = {https://openreview.net/forum?id=AjJTg5M0r8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CORE-bench: Fostering the credibility of published research through a computational reproducibility agent benchmark. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BsMMc4MEGS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI agents have the potential to aid users on a variety of consequential tasks, including conducting scientific research. To spur the development of useful agents, we need benchmarks that are challenging, but more crucially, directly correspond to real-world tasks of interest. This paper introduces such a benchmark, designed to measure the accuracy of AI agents in tackling a crucial yet surprisingly challenging aspect of scientific research: computational reproducibility. This task, fundamental to the scientific process, involves reproducing the results of a study using the provided code and data. We introduce CORE-Bench (Computational Reproducibility Agent Benchmark), a benchmark consisting of 270 tasks based on 90 scientific papers across three disciplines (computer science, social science, and medicine). Tasks in CORE-Bench consist of three difficulty levels and include both language-only and vision-language tasks. We provide an evaluation system to measure the accuracy of agents in a fast and parallelizable way, saving days of evaluation time for each run compared to a sequential implementation. We evaluated two baseline agents: the general-purpose AutoGPT and a task-specific agent called CORE-Agent. We tested both variants using two underlying language models: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 19% on the hardest level of tasks, showing the vast scope for improvement in automating routine scientific tasks. Having agents that can reproduce existing work is a necessary step toward building agents that can conduct novel research and could verify and improve the performance of other research agents. We hope that CORE-Bench can improve the state of reproducibility and spur the development of future research agents.},
  archive      = {J_TMLR},
  author       = {Zachary S Siegel and Sayash Kapoor and Nitya Nadgir and Benedikt Stroebl and Arvind Narayanan},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CORE-bench: Fostering the credibility of published research through a computational reproducibility agent benchmark},
  url          = {https://openreview.net/forum?id=BsMMc4MEGS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S-TLLR: STDP-inspired temporal local learning rule for spiking neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CNaiJRcX84'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for deploying energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses significant challenges due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst the most widely used method for addressing these issues, incurs high computational cost due to its temporal dependency. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNs on event-based learning tasks. Furthermore, S-TLLR is designed to have low memory and time complexities, which are independent of the number of time steps, rendering it suitable for online learning on low-power edge devices. To demonstrate the scalability of our proposed method, we have conducted extensive evaluations on event-based datasets spanning a wide range of applications, such as image and gesture recognition, audio classification, and optical flow estimation. S-TLLR achieves comparable accuracy to BPTT (within $\pm2\%$ for most tasks), while reducing memory usage by $5-50\times$ and multiply-accumulate (MAC) operations by $1.3-6.6\times$, particularly when updates are restricted to the last few time-steps.},
  archive      = {J_TMLR},
  author       = {Marco Paul E. Apolinario and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {S-TLLR: STDP-inspired temporal local learning rule for spiking neural networks},
  url          = {https://openreview.net/forum?id=CNaiJRcX84},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective backdoor mitigation in vision-language models depends on the pre-training objective. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Conma3qnaT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the advanced capabilities of contemporary machine learning (ML) models, they remain vulnerable to adversarial and backdoor attacks. This vulnerability is particularly concerning in real-world deployments, where compromised models may exhibit unpredictable behavior in critical scenarios. Such risks are heightened by the prevalent practice of collecting massive, internet-sourced datasets for training multimodal models, as these datasets may harbor backdoors. Various techniques have been proposed to mitigate the effects of backdooring in multimodal models, such as CleanCLIP, which is the current state-of-the-art approach. In this work, we demonstrate that the efficacy of CleanCLIP in mitigating backdoors is highly dependent on the particular objective used during model pre-training. We observe that stronger pre-training objectives that lead to higher zero-shot classification performance correlate with harder to remove backdoors behaviors. We show this by training multimodal models on two large datasets consisting of 3 million (CC3M) and 6 million (CC6M) datapoints, under various pre-training objectives, followed by poison removal using CleanCLIP. We find that CleanCLIP, even with extensive hyperparameter tuning, is ineffective in poison removal when stronger pre-training objectives are used. Our findings underscore critical considerations for ML practitioners who train models using large-scale web-curated data and are concerned about potential backdoor threats.},
  archive      = {J_TMLR},
  author       = {Sahil Verma and Gantavya Bhatt and Avi Schwarzschild and Soumye Singhal and Arnav Mohanty Das and Chirag Shah and John P Dickerson and Pin-Yu Chen and Jeff Bilmes},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Effective backdoor mitigation in vision-language models depends on the pre-training objective},
  url          = {https://openreview.net/forum?id=Conma3qnaT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized privacy amplification via importance sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IK2cR89z45'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For scalable machine learning on large data sets, subsampling a representative subset is a common approach for efficient model training. This is often achieved through importance sampling, whereby informative data points are sampled more frequently. In this paper, we examine the privacy properties of importance sampling, focusing on an individualized privacy analysis. We find that, in importance sampling, privacy is well aligned with utility but at odds with sample size. Based on this insight, we propose two approaches for constructing sampling distributions: one that optimizes the privacy-efficiency trade-off; and one based on a utility guarantee in the form of coresets. We evaluate both approaches empirically in terms of privacy, efficiency, and accuracy on the differentially private $k$-means problem. We observe that both approaches yield similar outcomes and consistently outperform uniform sampling across a wide range of data sets. Our code is available on GitHub.},
  archive      = {J_TMLR},
  author       = {Dominik Fay and Sebastian Mair and Jens Sjölund},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized privacy amplification via importance sampling},
  url          = {https://openreview.net/forum?id=IK2cR89z45},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked capsule autoencoders. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JHxrh00W1j'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that utilises pretraining in a modern self-supervised paradigm, specifically the masked image modelling framework. Capsule Networks have emerged as a powerful alternative to Convolutional Neural Networks (CNNs). They have shown favourable properties when compared to Vision Transformers (ViT), but have struggled to effectively learn when presented with more complex data. This has led to Capsule Network models that do not scale to modern tasks. Our proposed MCAE model alleviates this issue by reformulating the Capsule Network to use masked image modelling as a pretraining stage before finetuning in a supervised manner. Across several experiments and ablations studies we demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit from self-supervised pretraining, paving the way for further advancements in this neural network domain. For instance, by pretraining on the Imagenette dataset---consisting of 10 classes of Imagenet-sized images---we achieve state-of-the-art results for Capsule Networks, demonstrating a 9\% improvement compared to our baseline model. Thus, we propose that Capsule Networks benefit from and should be trained within a masked image modelling framework, using a novel capsule decoder, to enhance a Capsule Network's performance on realistically sized images.},
  archive      = {J_TMLR},
  author       = {Miles Everett and Mingjun Zhong and Georgios Leontidis},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Masked capsule autoencoders},
  url          = {https://openreview.net/forum?id=JHxrh00W1j},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mental modelling of reinforcement learning agents by language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=JN7iNWaPTe'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models already exhibit some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pre-trained models have memorized can be utilised to comprehend an agent's behaviour in the physical world. This paper empirically examines, for the first time, how well large language models (LLMs) can build a mental model of reinforcement learning (RL) agents, termed agent mental modelling, by reasoning about an agent's behaviour and its effect on states from agent interaction history. This research attempts to unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in explainable RL. To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment. Our results disclose that LLMs are not yet capable of fully realising the mental modelling of agents through inference alone without further innovations. This work thus provides new insights into the capabilities and limitations of modern LLMs, highlighting that while they show promise in understanding agents with a longer history context, preexisting beliefs within LLMs about behavioural optimum and state complexity limit their ability to fully comprehend an agent's behaviour and action effects.},
  archive      = {J_TMLR},
  author       = {Wenhao Lu and Xufeng Zhao and Josua Spisak and Jae Hee Lee and Stefan Wermter},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mental modelling of reinforcement learning agents by language models},
  url          = {https://openreview.net/forum?id=JN7iNWaPTe},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fourier PINNs: From strong boundary conditions to adaptive fourier bases. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KqRnsEMYLx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interest is rising in Physics-Informed Neural Networks (PINNs) as a mesh-free alternative to traditional numerical solvers for partial differential equations (PDEs). However, PINNs often struggle to learn high-frequency and multi-scale target solutions. To tackle this problem, we first study a strong Boundary Condition (BC) version of PINNs for Dirichlet BCs and observe a consistent decline in relative error compared to the standard PINNs. We then perform a theoretical analysis based on the Fourier transform and convolution theorem. We find that strong BC PINNs can better learn the amplitudes of high-frequency components of the target solutions. However, constructing the architecture for strong BC PINNs is difficult for many BCs and domain geometries. Enlightened by our theoretical analysis, we propose Fourier PINNs --- a simple, general, yet powerful method that augments PINNs with pre-specified, dense Fourier bases. Our proposed architecture likewise learns high-frequency components better but places no restrictions on the particular BCs or problem domains. We develop an adaptive learning and basis selection algorithm via alternating neural net basis optimization, Fourier and neural net basis coefficient estimation, and coefficient truncation. This scheme can flexibly identify the significant frequencies while weakening the nominal frequencies to better capture the target solution's power spectrum. We show the advantage of our approach through a set of systematic experiments.},
  archive      = {J_TMLR},
  author       = {Madison Cooley and Varun Shankar and Mike Kirby and Shandian Zhe},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fourier PINNs: From strong boundary conditions to adaptive fourier bases},
  url          = {https://openreview.net/forum?id=KqRnsEMYLx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shared stochastic gaussian process latent variable models: A multi-modal generative model for quasar spectra. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LzmsvRTqaJ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a scalable probabilistic latent variable model based on Gaussian processes in the context of multiple observation spaces. We focus on an application in astrophysics where it is typical for data sets to contain both observed spectral features as well as scientific properties of astrophysical objects such as galaxies or exoplanets. In our application, we study the spectra of very luminous galaxies known as quasars, and their properties, such as the mass of their central supermassive black hole, their accretion rate and their luminosity, and hence, there can be multiple observation spaces. A single data point is then characterised by different classes of observations which may have different likelihoods. Our proposed model extends the baseline stochastic variational Gaussian process latent variable model (GPLVM) to this setting, proposing a seamless generative model where the quasar spectra and the scientific labels can be generatedsimultaneously when modelled with a shared latent space acting as input to different sets of Gaussian process decoders, one for each observation space. Further, this framework allows training in the missing data setting where a large number of dimensions per data point may be unknown or unobserved. We demonstrate high-fidelity reconstructions of the spectra and the scientific labels during test-time inference and briefly discuss the scientific interpretations of the results along with the significance of such a generative model.},
  archive      = {J_TMLR},
  author       = {Vidhi Lalchand and Anna-Christina Eilers},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shared stochastic gaussian process latent variable models: A multi-modal generative model for quasar spectra},
  url          = {https://openreview.net/forum?id=LzmsvRTqaJ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function basis encoding of numerical features in factorization machines. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=M4222IBHsh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factorization machine (FM) variants are widely used for large scale real-time content recommendation systems, since they offer an excellent balance between model accuracy and low computational costs for training and inference. These systems are trained on tabular data with both numerical and categorical columns. Incorporating numerical columns poses a challenge, and they are typically incorporated using a scalar transformation or binning, which can be either learned or arbitrarily chosen. In this work, we provide a systematic and theoretically-justified way to incorporate numerical features into FM variants by encoding them into a vector of function values for a set of functions of one's choice. We view FMs as approximators of segmentized functions, namely, functions from a field's value to the real numbers, assuming the remaining fields are assigned some given constants, which we refer to as the segment. From this perspective, we show that our technique yields a model that learns segmentized functions of the numerical feature spanned by the set of functions of one's choice, namely, the spanning coefficients vary between segments. Hence, to improve model accuracy we advocate the use of functions known to have powerful approximation capabilities, and offer the B-Spline basis due to its well-known approximation power, widespread availability in software libraries and its efficiency in terms of computational resources and memory usage. Our technique preserves fast training and inference, and requires only a small modification of the computational graph of an FM model. Therefore, incorporating it into an existing system to improve its performance is easy. Finally, we back our claims with a set of experiments that include a synthetic experiment, performance evaluation on several data-sets, and an A/B test on a real online advertising system which shows improved performance. We have made the code to reproduce the experiments available at https://github.com/alexshtf/cont_features_paper.},
  archive      = {J_TMLR},
  author       = {Alex Shtoff and Elie Abboud and Rotem Stram and Oren Somekh},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Function basis encoding of numerical features in factorization machines},
  url          = {https://openreview.net/forum?id=M4222IBHsh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear convergence of decentralized FedAvg for PL objectives: The interpolation regime. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Og3VxBFhwj'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a distributed learning paradigm where multiple clients each having access to a local dataset collaborate to solve a joint problem. Federated Averaging (FedAvg) the algorithm of choice has been widely explored in the classical {\em server} setting where the server coordinates the information sharing among clients. However, the performance of FedAvg in the {\em decentralized} setting where only the neighboring clients communicate with each other depending on the network topology is not well understood, especially in the interpolation regime, a common phenomenon observed in modern overparameterized neural networks. In this work, we address this challenge and perform a thorough theoretical performance analysis of FedAvg in the interpolation regime under {\em decentralized} setting. We consider a class of non-convex functions satisfying the Polyak-{\L}ojasiewicz (PL) inequality, a condition satisfied by overparameterized neural networks. For the first time, we establish that {\em Decentralized} FedAvg achieves linear convergence rates of $\mathcal{O}({T^2} \log ({1}/{\epsilon}))$, where $\epsilon$ is the solution accuracy, and $T$ is the number of local updates at each client. We also extend our analysis to the classical {\em Server} FedAvg and establish a convergence rate of $\mathcal{O}(\log ({1}/{\epsilon}))$ which significantly improves upon the best-known rates for the simpler strongly-convex setting. In contrast to the standard FedAvg analyses, our work does not require bounded heterogeneity and gradient assumptions. Instead, we show that sample-wise (and local) smoothness of the local objectives suffice to capture the effect of heterogeneity. Experiments on multiple real datasets corroborate our theoretical findings.},
  archive      = {J_TMLR},
  author       = {Shruti P Maralappanavar and Prashant Khanduri and Bharath B N},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Linear convergence of decentralized FedAvg for PL objectives: The interpolation regime},
  url          = {https://openreview.net/forum?id=Og3VxBFhwj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reward-based autonomous online learning framework for resilient cooperative target monitoring using a swarm of robots. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PzmaWLqK0e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of decentralized cooperative monitoring of an agile target using a swarm of robots undergoing dynamic sensor failures. Each robot is equipped with a proprioceptive sensor suite for the estimation of its own pose and an exteroceptive sensor suite for target detection and position estimation with a limited field of view. Further, the robots use broadcast-based communication modules with a limited communication radius and bandwidth. The uncertainty in the system and the environment can lead to intermittent communication link drops, target visual loss, and large biases in the sensors’ estimation output due to temporary or permanent failures. Robotic swarms often operate without leaders, supervisors, or landmarks, i.e., without the availability of ground truth regarding pose information. In such scenarios, each robot is required to exhibit autonomous learning by taking charge of its own learning process while making the most out of available information. In this regard, a novel Autonomous Online Learning (AOL) framework has been proposed, in which a decentralized online learning mechanism driven by reward-like signals, is intertwined with an implicit adaptive consensus-based, two-layered, weighted information fusion process that utilizes the robots’ observations and their shared information, thereby ensuring resilience in the robotic swarm. In order to study the effect of loss or reward design in the local and social learning layers, three AOL variants are presented. A novel perturbation-greedy reward design is introduced in the learning layers of two variants, leading to exploration-exploitation in their information fusion's weights' space. Convergence analysis of the weights is carried out, showing that the weights converge under reasonable assumptions. Simulation results show that the AOL variant using the perturbation-greedy reward in its local learning layer performs the best, doing $182.2\%$ to $652\%$ and $94.7\%$ to $150.4\%$ better than the baselines in terms of detection score and closeness score per robot, respectively, as the total number of robots is increased from $5$ to $30$. Further, AOL's Sim2Real implementation has been validated using a ROS-Gazebo setup.},
  archive      = {J_TMLR},
  author       = {Shubhankar Gupta and Saksham Sharma and Suresh Sundaram},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reward-based autonomous online learning framework for resilient cooperative target monitoring using a swarm of robots},
  url          = {https://openreview.net/forum?id=PzmaWLqK0e},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing the power of data tsunami: A comprehensive survey on data assessment and selection for instruction tuning of language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RJT1baPhdV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each category, representative methods are elaborated to describe the landscape of relevant research. In addition, comparison between the latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations. Finally, we summarize the open challenges and propose the promosing avenues for future studies. All related contents are available at https://github.com/yuleiqin/fantastic-data-engineering.},
  archive      = {J_TMLR},
  author       = {Yulei Qin and Yuncheng Yang and Pengcheng Guo and Gang Li and Hang Shao and Yuchen Shi and Zihan Xu and Yun Gu and Ke Li and Xing Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unleashing the power of data tsunami: A comprehensive survey on data assessment and selection for instruction tuning of language models},
  url          = {https://openreview.net/forum?id=RJT1baPhdV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diff-instruct++: Training one-step text-to-image generator model to align with human preferences. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=SeGNvJJjbs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-step text-to-image generator models offer advantages such as swift inference efficiency, flexible architectures, and state-of-the-art generation performance. In this paper, we study the problem of aligning one-step generator models with human preferences for the first time. Inspired by the success of reinforcement learning using human feedback (RLHF), we formulate the alignment problem as maximizing expected human reward functions while adding an Integral Kullback-Leibler divergence term to prevent the generator from diverging. By overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the first, fast-converging and image data-free human preference alignment method for one-step text-to-image generators. We also introduce novel theoretical insights, showing that using CFG for diffusion distillation is secretly doing RLHF with DI++. Such an interesting finding brings understanding and potential contributions to future research involving CFG. In the experiment sections, we align both UNet-based and DiT-based one-step generators using DI++, which use the Stable Diffusion 1.5 and the PixelArt-$\alpha$ as the reference diffusion processes. The resulting DiT-based one-step text-to-image model achieves a strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO validation prompt dataset. It also achieves a leading Human preference Score (HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\alpha$. Both theoretical contributions and empirical evidence indicate that DI++ is a strong human-preference alignment approach for one-step text-to-image models.},
  archive      = {J_TMLR},
  author       = {Weijian Luo},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diff-instruct++: Training one-step text-to-image generator model to align with human preferences},
  url          = {https://openreview.net/forum?id=SeGNvJJjbs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax posterior contraction rates for unconstrained distribution estimation on $[0,1]^d$ under wasserstein distance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=UrSgGSTM2J'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We obtain asymptotic minimax optimal posterior contraction rates for estimation of probability distributions on $[0,1]^d$ under the Wasserstein-$p$ metrics using Bayesian Histograms. To the best of our knowledge, our analysis is the first to provide minimax posterior contraction rates for every $p \geq 1$ and problem dimension $d \geq 1$. Our proof technique takes advantage of the conjugacy of the Bayesian Histogram.},
  archive      = {J_TMLR},
  author       = {Peter Matthew Jacobs and Lekha Patel and Anirban Bhattacharya and Debdeep Pati},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Minimax posterior contraction rates for unconstrained distribution estimation on $[0,1]^d$ under wasserstein distance},
  url          = {https://openreview.net/forum?id=UrSgGSTM2J},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pre-trained vision-language models learn discoverable visual concepts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Vq0wMFBjo2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Do vision-language models (VLMs) pre-trained to caption an image of a durian learn visual concepts such as brown (color) and spiky (texture) at the same time? We aim to answer this question as visual concepts learned “for free” would enable wide applications such as neuro-symbolic reasoning or human-interpretable object classification. We assume that the visual concepts, if captured by pre-trained VLMs, can be extracted by their vision-language interface with text-based concept prompts. We observe that recent works prompting VLMs with concepts often differ in their strategies to define and evaluate the visual concepts, leading to conflicting conclusions. We propose a new concept definition strategy based on two observations: First, certain concept prompts include shortcuts that recognize correct concepts for wrong reasons; Second, multimodal information (e.g. visual discriminativeness, and textual knowledge) should be leveraged when selecting the concepts. Our proposed concept discovery and learning (CDL) framework is thus designed to identify a diverse list of generic visual concepts (e.g. spiky as opposed to spiky durian), which are ranked and selected based on visual and language mutual information. We carefully design quantitative and human evaluations of the discovered concepts on nine diverse visual recognition datasets, which confirm that pre-trained VLMs do learn visual concepts that provide accurate and thorough descriptions for the recognized objects. All code and models are publicly released.},
  archive      = {J_TMLR},
  author       = {Yuan Zang and Tian Yun and Hao Tan and Trung Bui and Chen Sun},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Pre-trained vision-language models learn discoverable visual concepts},
  url          = {https://openreview.net/forum?id=Vq0wMFBjo2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving GFlowNets for text-to-image diffusion alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XDbY3qhM42'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have become the de-facto approach for generating visual data, which are trained to match the distribution of the training dataset. In addition, we also want to control generation to fulfill desired properties such as alignment to a text description, which can be specified with a black-box reward function. Prior works fine-tune pretrained diffusion models to achieve this goal through reinforcement learning-based algorithms. Nonetheless, they suffer from issues including slow credit assignment as well as low quality in their generated samples. In this work, we explore techniques that do not directly maximize the reward but rather generate high-reward images with relatively high probability --- a natural scenario for the framework of generative flow networks (GFlowNets). To this end, we propose the Diffusion Alignment with GFlowNet (DAG) algorithm to post-train diffusion models with black-box property functions. Extensive experiments on Stable Diffusion and various reward specifications corroborate that our method could effectively align large-scale text-to-image diffusion models with given reward information.},
  archive      = {J_TMLR},
  author       = {Dinghuai Zhang and Yizhe Zhang and Jiatao Gu and Ruixiang ZHANG and Joshua M. Susskind and Navdeep Jaitly and Shuangfei Zhai},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving GFlowNets for text-to-image diffusion alignment},
  url          = {https://openreview.net/forum?id=XDbY3qhM42},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximally expressive GNNs for outerplanar graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XxbQAsxrRC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a linear time graph transformation that enables the Weisfeiler-Leman (WL) algorithm and message passing graph neural networks (MPNNs) to be maximally expressive on outerplanar graphs. Our approach is motivated by the fact that most pharmaceutical molecules correspond to outerplanar graphs. Existing research predominantly enhances the expressivity of graph neural networks without specific graph families in mind. This often leads to methods that are impractical due to their computational complexity. In contrast, the restriction to outerplanar graphs enables us to encode the Hamiltonian cycle of each biconnected component in linear time. As the main contribution of the paper we prove that our method achieves maximum expressivity on outerplanar graphs. Experiments confirm that our graph transformation improves the predictive performance of MPNNs on molecular benchmark datasets at negligible computational overhead.},
  archive      = {J_TMLR},
  author       = {Franka Bause and Fabian Jogl and Patrick Indri and Tamara Drucks and David Penz and Nils Morten Kriege and Thomas Gärtner and Pascal Welke and Maximilian Thiessen},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maximally expressive GNNs for outerplanar graphs},
  url          = {https://openreview.net/forum?id=XxbQAsxrRC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformers in uniform TC$^0$. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZA7D4nQuQF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work has shown that the languages recognized by average-hard attention transformers (AHATs) and softmax-attention transformers (SMATs) are within the circuit complexity class TC$^0$. However, these results assume limited-precision arithmetic: using floating-point numbers with O(log n) bits (where n is the length of the input string), Strobl showed that AHATs can be approximated in L-uniform TC$^0$, and Merrill and Sabharwal showed that SMATs can be approximated in DLOGTIME-uniform TC$^0$. Here, we improve these results, showing that AHATs with no approximation, SMATs with O(poly(n)) bits of floating-point precision, and SMATs with at most $2^{−O(poly(n))}$ absolute error are all in DLOGTIME-uniform TC$^0$.},
  archive      = {J_TMLR},
  author       = {David Chiang},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transformers in uniform TC$^0$},
  url          = {https://openreview.net/forum?id=ZA7D4nQuQF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ZnWqtPhHM7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Vision-Language foundation models like CLIP and ALIGN, which are pre-trained on large-scale data have shown remarkable zero-shot generalization to diverse datasets with different classes and even domains. In this work, we take a step further and analyze whether these models can be adapted to target datasets having very different distributions and classes compared to what these models have been trained on, using only a few labeled examples from the target dataset. In such scenarios, finetuning large pretrained models is challenging due to problems of overfitting as well as loss of generalization, and has not been well explored in prior literature. Since, the pre-training data of such models are unavailable, it is difficult to comprehend the performance on various downstream datasets. First, we try to answer the question: Given a target dataset with a few labelled examples, can we estimate whether further fine-tuning can enhance the performance compared to zero-shot evaluation? by analyzing the common vision-language embedding space. Based on the analysis, we propose a novel prompt-tuning method, PromptMargin for adapting such large-scale VLMs directly on the few target samples. PromptMargin effectively tunes the text as well as visual prompts for this task, and has two main modules: 1) Firstly, we use a selective augmentation strategy to complement the few training samples in each task; 2) Additionally, to ensure robust training in the presence of unfamiliar class names, we increase the inter-class margin for improved class discrimination using a novel Multimodal Margin Regularizer. Extensive experiments and analysis across fifteen target benchmark datasets, with varying degrees of distribution shifts from natural images, shows the effectiveness of the proposed framework over the existing state-of-the-art approaches applied to this setting.},
  archive      = {J_TMLR},
  author       = {Debarshi Brahma and Anuska Roy and Soma Biswas},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts},
  url          = {https://openreview.net/forum?id=ZnWqtPhHM7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the impact of missing value handling on boosted trees and deep learning for tabular data: A claim reserving case study. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aV6dCg1VFV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning (DL) performance is exceptional for many applications, there is no consensus on whether DL or gradient boosted decision trees (GBDTs) are superior for tabular data. We compare TabNet (a DL model for tabular data), two simple neural networks inspired by ResNet (a DL model) and Catboost (a GBDT model) on a large UK insurer dataset for the task of claim reserving. This dataset is of particular interest for its large amount of informative missing values which are not missing completely at random, highlighting the impact of missing value handling on accuracy. Under certain missing value schemes a carefully optimised simple neural network performed comparably to Catboost with default settings. However, using less-than-minimum imputation, Catboost with default settings substantially outperformed carefully optimised DL models, achieving the best overall accuracy. We conclude that handling missing values is an important, yet often overlooked, step when comparing DL to GBDT algorithms for tabular data.},
  archive      = {J_TMLR},
  author       = {Alexander Larionov and Niall M. Adams and Kevin N. Webster},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Investigating the impact of missing value handling on boosted trees and deep learning for tabular data: A claim reserving case study},
  url          = {https://openreview.net/forum?id=aV6dCg1VFV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on generalization in variational autoencoders: How effective is synthetic data and overparameterization?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bwyHf5eery'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders (VAEs) are deep probabilistic models that are used in scientific applications. Many works try to mitigate this problem from the probabilistic methods perspective by new inference techniques or training procedures. In this paper, we approach the problem instead from the deep learning perspective by investigating the effectiveness of using synthetic data and overparameterization for improving the generalization performance. Our motivation comes from (1) the recent discussion on whether the increasing amount of publicly accessible synthetic data will improve or hurt currently trained generative models; and (2) the modern deep learning insights that overparameterization improves generalization. Our investigation shows how both training on samples from a pre-trained diffusion model, and using more parameters at certain layers are able to effectively mitigate overfitting in VAEs, therefore improving their generalization, amortized inference, and robustness performance. Our study provides timely insights in the current era of synthetic data and scaling laws.},
  archive      = {J_TMLR},
  author       = {Tim Z. Xiao and Johannes Zenn and Robert Bamler},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A note on generalization in variational autoencoders: How effective is synthetic data and overparameterization?},
  url          = {https://openreview.net/forum?id=bwyHf5eery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ask your distribution shift if pre-training is right for you. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=edULLIVnoc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training is a widely used approach to develop models that are robust to distribution shifts. However, in practice, its effectiveness varies: fine-tuning a pre-trained model improves robustness significantly in some cases but *not at all* in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training *can* and *cannot* address. In particular, we focus on two possible failure modes of models under distribution shift: poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting biases have complementary robustness benefits, and (2) fine-tuning on a (very) small, non-diverse but *de-biased* dataset can result in significantly more robust models than fine-tuning on a large and diverse but biased dataset.},
  archive      = {J_TMLR},
  author       = {Benjamin Cohen-Wang and Joshua Vendrow and Aleksander Madry},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ask your distribution shift if pre-training is right for you},
  url          = {https://openreview.net/forum?id=edULLIVnoc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BM$^2$: Coupled schrödinger bridge matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=fqkq1MgONB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Schrödinger bridge establishes a dynamic transport map between two target distributions via a reference process, simultaneously solving an associated entropic optimal transport problem. We consider the setting where samples from the target distributions are available, and the reference diffusion process admits tractable dynamics. We thus introduce Coupled Bridge Matching (BM$^2$), a simple \emph{non-iterative} approach for learning Schrödinger bridges with neural networks. A preliminary theoretical analysis of the convergence properties of BM$^2$ is carried out, supported by numerical experiments that demonstrate the effectiveness of our proposal.},
  archive      = {J_TMLR},
  author       = {Stefano Peluchetti},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {BM$^2$: Coupled schrödinger bridge matching},
  url          = {https://openreview.net/forum?id=fqkq1MgONB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization and generalization guarantees for weight normalization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gpHOtQQPJG'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight normalization (WeightNorm) is widely used in practice for the training of deep neural networks and modern deep learning libraries have built-in implementations of it. In this paper, we provide the first theoretical characterizations of both optimization and generalization of deep WeightNorm models with smooth activation functions. For optimization, from the form of the Hessian of the loss, we note that a small Hessian of the predictor leads to a tractable analysis. Thus, we bound the spectral norm of the Hessian of WeightNorm networks and show its dependence on the network width and weight normalization terms--the latter being unique to networks without WeightNorm. Then, we use this bound to establish training convergence guarantees under suitable assumptions for gradient decent. For generalization, we use WeightNorm to get a uniform convergence based generalization bound, which is independent from the width and depends sublinearly on the depth. Finally, we present experimental results which illustrate how the normalization terms and other quantities of theoretical interest relate to the training of WeightNorm networks.},
  archive      = {J_TMLR},
  author       = {Pedro Cisneros-Velarde and Zhijie Chen and Sanmi Koyejo and Arindam Banerjee},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimization and generalization guarantees for weight normalization},
  url          = {https://openreview.net/forum?id=gpHOtQQPJG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No detail left behind: Revisiting self-retrieval for fine-grained image captioning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=gqh0yzPYdo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning systems are unable to generate fine-grained captions as they are trained on data that is either noisy (alt-text) or generic (human annotations). This is further exacerbated by maximum likelihood training that encourages generation of frequently occurring phrases. Previous works have tried to address this limitation by fine-tuning captioners with a self-retrieval (SR) reward. However, we find that SR fine-tuning has a tendency to reduce caption faithfulness and even hallucinate. In this work, we circumvent this bottleneck by improving the MLE initialization of the captioning system and designing a curriculum for the SR fine-tuning process. To this extent, we present (1) Visual Caption Boosting, a novel framework to instill fine-grainedness in generic image captioning datasets while remaining anchored in human annotations; and (2) BagCurri, a carefully designed training curriculum that more optimally leverages the contrastive nature of the self-retrieval reward. Jointly, they enable the captioner to describe fine-grained aspects in the image while preserving faithfulness to ground-truth captions. Our approach outperforms previous work by +8.9% on SR against 99 random distractors (RD100) (Dessi et al., 2023); and +7.6% on ImageCoDe. Additionally, existing metrics to evaluate captioning systems fail to reward diversity or evaluate a model's fine-grained understanding ability. Our third contribution addresses this by proposing self-retrieval from the lens of evaluation. We introduce TrueMatch, a benchmark comprising bags of highly similar images that uses SR to assess the captioner's ability to capture subtle visual distinctions. We evaluate and compare several state-of-the-art open-source MLLMs on TrueMatch, and find that our SR approach outperforms them all by a significant margin (e.g. +4.8% - 7.1% over Cambrian) while having 1-2 orders of magnitude fewer parameters. We also outperform vanilla SR by +14.4% to +19.5%.},
  archive      = {J_TMLR},
  author       = {Manu Gaur and Darshan Singh S and Makarand Tapaswi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {No detail left behind: Revisiting self-retrieval for fine-grained image captioning},
  url          = {https://openreview.net/forum?id=gqh0yzPYdo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On inherent adversarial robustness of active vision systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=iVV7IzI55V'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are susceptible to adversarial inputs, such as imperceptible noise and naturally occurring challenging samples. This vulnerability likely arises from their passive, one-shot processing approach. In contrast, neuroscience suggests that human vision robustly identifies salient object features by actively switching between multiple fixation points (saccades) and processing surroundings with non-uniform resolution (foveation). This information is processed via two pathways: the dorsal (where) and ventral (what) streams, which identify relevant input portions and discard irrelevant details. Building on this perspective, we outline a deep learning-based active dorsal-ventral vision system and adapt two prior methods, FALcon and GFNet, within this framework to evaluate their robustness. We conduct a comprehensive robustness analysis across three categories: adversarially crafted inputs evaluated under transfer attack scenarios, natural adversarial images, and foreground-distorted images. By learning from focused, downsampled glimpses at multiple distinct fixation points, these active methods significantly enhance the robustness of passive networks, achieving a 2-21 % increase in accuracy. This improvement is demonstrated against state-of-the-art transferable black-box attack. On ImageNet-A, a benchmark for naturally occurring hard samples, we show how distinct predictions from multiple fixation points yield performance gains of 1.5-2 times for both CNN and Transformer based networks. Lastly, we qualitatively demonstrate how an active vision system aligns more closely with human perception for structurally distorted images. This alignment leads to more stable and resilient predictions, with lesser catastrophic mispredictions. In contrast, passive methods, which rely on single-shot learning and inference, often lack the necessary structural understanding.},
  archive      = {J_TMLR},
  author       = {Amitangshu Mukherjee and Timur Ibrayev and Kaushik Roy},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On inherent adversarial robustness of active vision systems},
  url          = {https://openreview.net/forum?id=iVV7IzI55V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond joint demonstrations: Personalized expert guidance for efficient multi-agent reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=kzPNHQ8ByY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of efficient exploration due to the exponential increase in the size of the joint state-action space. While demonstration-guided learning has proven beneficial in single-agent settings, its direct applicability to MARL is hindered by the practical difficulty of obtaining joint expert demonstrations. In this work, we introduce a novel concept of personalized expert demonstrations, tailored for each individual agent or, more broadly, each individual type of agent within a heterogeneous team. These demonstrations solely pertain to single-agent behaviors and how each agent can achieve personal goals without encompassing any cooperative elements, thus naively imitating them will not achieve cooperation due to potential conflicts. To this end, we propose an approach that selectively utilizes personalized expert demonstrations as guidance and allows agents to learn to cooperate, namely personalized expert-guided MARL (PegMARL). This algorithm utilizes two discriminators: the first provides incentives based on the alignment of individual agent behavior with demonstrations, and the second regulates incentives based on whether the behaviors lead to the desired outcome. We evaluate PegMARL using personalized demonstrations in both discrete and continuous environments. The results demonstrate that PegMARL learns near-optimal policies even when provided with suboptimal demonstrations and outperforms state-of-the-art MARL algorithms in solving coordinated tasks. We also showcase PegMARL’s capability of leveraging joint demonstrations in the StarCraft scenario and converging effectively even with demonstrations from non-co-trained policies.},
  archive      = {J_TMLR},
  author       = {Peihong Yu and Manav Mishra and Alec Koppel and Carl Busart and Priya Narayan and Dinesh Manocha and Amrit Singh Bedi and Pratap Tokekar},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Beyond joint demonstrations: Personalized expert guidance for efficient multi-agent reinforcement learning},
  url          = {https://openreview.net/forum?id=kzPNHQ8ByY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of model robustness across concurrent distribution shifts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nxQtoHHcj9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models, meticulously optimized for source data, often fail to predict target data when faced with distribution shifts (DSs). Previous benchmarking studies, though extensive, have mainly focused on simple DSs. Recognizing that DSs often occur in more complex forms in real-world scenarios, we broaden our study to include multiple concurrent shifts, such as unseen domain shifts combined with spurious correlations. We evaluate 26 algorithms that range from simple heuristic augmentations to zero-shot inference using foundation models, across 168 source-target pairs from eight datasets. Our analysis of over 100K models reveals that (i) concurrent DSs typically worsen performance compared to a single shift, with certain exceptions, (ii) if a model improves generalization for one distribution shift, it tends to be effective for others, (iii) heuristic data augmentations achieve the best overall performance on both synthetic and real-world datasets.},
  archive      = {J_TMLR},
  author       = {Myeongho Jeon and Suhwan Choi and Hyoje Lee and Teresa Yeo},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An analysis of model robustness across concurrent distribution shifts},
  url          = {https://openreview.net/forum?id=nxQtoHHcj9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the detection of reviewer-author collusion rings from paper bidding. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=o58uy91V2V'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collusion rings pose a significant threat to peer review. In these rings, reviewers who are also authors coordinate to manipulate paper assignments, often by strategically bidding on each other's papers. A promising solution is to detect collusion through these manipulated bids, enabling conferences to take appropriate action. However, while methods exist for detecting other types of fraud, no research has yet shown that identifying collusion rings is feasible. In this work, we consider the question of whether it is feasible to detect collusion rings from the paper bidding. We conduct an empirical analysis of two realistic conference bidding datasets and evaluate existing algorithms for fraud detection in other applications. We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders. In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders. These results suggest that collusion cannot be effectively detected from the bidding using popular existing tools, demonstrating the need to develop more complex detection algorithms as well as those that leverage additional metadata (e.g., reviewer-paper text-similarity scores).},
  archive      = {J_TMLR},
  author       = {Steven Jecmen and Nihar B Shah and Fei Fang and Leman Akoglu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the detection of reviewer-author collusion rings from paper bidding},
  url          = {https://openreview.net/forum?id=o58uy91V2V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AlgoFormer: An efficient transformer framework with algorithmic structures. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=oYP2Pd5aQt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides natural language processing, transformers exhibit extraordinary performance in solving broader applications, including scientific computing and computer vision. Previous works try to explain this from the expressive power and capability perspectives that standard transformers are capable of performing some algorithms. To empower transformers with algorithmic capabilities and motivated by the recently proposed looped transformer (Yang et al., 2024; Giannou et al., 2023), we design a novel transformer framework, dubbed Algorithm Transformer (abbreviated as AlgoFormer). We provide an insight that efficient transformer architectures can be designed by leveraging prior knowledge of tasks and the underlying structure of potential algorithms. Compared with the standard transformer and vanilla looped transformer, the proposed AlgoFormer can perform efficiently in algorithm representation in some specific tasks. In particular, inspired by the structure of human-designed learning algorithms, our transformer framework consists of a pre-transformer that is responsible for task preprocessing, a looped transformer for iterative optimization algorithms, and a post-transformer for producing the desired results after post-processing. We provide theoretical evidence of the expressive power of the AlgoFormer in solving some challenging problems, mirroring human-designed algorithms. Furthermore, some theoretical and empirical results are presented to show that the designed transformer has the potential to perform algorithm representation and learning. Experimental results demonstrate the empirical superiority of the proposed transformer in that it outperforms the standard transformer and vanilla looped transformer in some specific tasks. An extensive experiment on real language tasks (e.g., neural machine translation of German and English, and text classification) further validates the expressiveness and effectiveness of AlgoFormer.},
  archive      = {J_TMLR},
  author       = {Yihang Gao and Chuanyang Zheng and Enze Xie and Han Shi and Tianyang Hu and Yu Li and Michael Ng and Zhenguo Li and Zhaoqiang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AlgoFormer: An efficient transformer framework with algorithmic structures},
  url          = {https://openreview.net/forum?id=oYP2Pd5aQt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial-label learning with a reject option. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wS1fD0ofay'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting, where state-of-the-art methods already show good predictive performance. However, even the best algorithms give incorrect predictions, which can have severe consequences when they impact actions or decisions. We propose a novel risk-consistent nearest-neighbor-based partial-label learning algorithm with a reject option, that is, the algorithm can reject unsure predictions. Extensive experiments on artificial and real-world datasets show that our method provides the best trade-off between the number and accuracy of non-rejected predictions when compared to our competitors, which use confidence thresholds for rejecting unsure predictions. When evaluated without the reject option, our nearest-neighbor-based approach also achieves competitive prediction performance.},
  archive      = {J_TMLR},
  author       = {Tobias Fuchs and Florian Kalinke and Klemens Böhm},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partial-label learning with a reject option},
  url          = {https://openreview.net/forum?id=wS1fD0ofay},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse neural architectures via deterministic ramanujan graphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=x8wscCAJ2m'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method to construct sparse neural networks using the theory of expander graphs. Expanders are sparse but well connected graph structures that are used for designing resilient networks. A Ramanujan graph is an extremal expander in terms of the spectral gap of its eigenvalues. In this work, bipartite Ramanujan expanders are deterministically constructed and used as connection structures of the convolutional and fully connected layers of a neural network. The Ramanujan graphs occur either as Cayley graphs of certain algebraic groups or as Ramanujan $r$-coverings of the full $(k,l)$ bi-regular bipartite graph on $k + l$ vertices. The proposed sparse networks are found to provide comparable performance to a fully dense network on benchmark datasets achieving an extremely low network density.},
  archive      = {J_TMLR},
  author       = {Suryam Arnav Kalra and Arindam Biswas and Pabitra Mitra and BISWAJIT BASU},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparse neural architectures via deterministic ramanujan graphs},
  url          = {https://openreview.net/forum?id=x8wscCAJ2m},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DafnyBench: A benchmark for formal software verification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yBgTVWccIx'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce DafnyBench, the largest benchmark of its kind for training and evaluating machine learning systems for formal software verification. We test the ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough annotations for the Dafny formal verification engine to successfully verify over 750 programs with about 53,000 lines of code. The best model and prompting scheme achieved 68% success rate, and we quantify how this rate improves when retrying with error message feedback and how it deteriorates with the amount of required code and annotations. We hope that DafnyBench will enable rapid improvements from this baseline as LLMs and verification techniques grow in quality.},
  archive      = {J_TMLR},
  author       = {Chloe R Loughridge and Qinyi Sun and Seth Ahrenbach and Federico Cassano and Chuyue Sun and Ying Sheng and Anish Mudide and Md Rakib Hossain Misu and Nada Amin and Max Tegmark},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DafnyBench: A benchmark for formal software verification},
  url          = {https://openreview.net/forum?id=yBgTVWccIx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention mechanisms don’t learn additive models: Rethinking feature importance for transformers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yawWz4qWkF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the critical challenge of applying feature attribution methods to the transformer architecture, which dominates current applications in natural language processing and beyond. Traditional attribution methods to explainable AI (XAI) explicitly or implicitly rely on linear or additive surrogate models to quantify the impact of input features on a model's output. In this work, we formally prove an alarming incompatibility: transformers are structurally incapable of representing linear or additive surrogate models used for feature attribution, undermining the grounding of these conventional explanation methodologies. To address this discrepancy, we introduce the Softmax-Linked Additive Log Odds Model (SLALOM), a novel surrogate model specifically designed to align with the transformer framework. SLALOM demonstrates the capacity to deliver a range of insightful explanations with both synthetic and real-world datasets. We highlight SLALOM's unique efficiency-quality curve by showing that SLALOM can produce explanations with substantially higher fidelity than competing surrogate models or provide explanations of comparable quality at a fraction of their computational costs. We release code for SLALOM as an open-source project online at https://github.com/tleemann/slalom_explanations.},
  archive      = {J_TMLR},
  author       = {Tobias Leemann and Alina Fastowski and Felix Pfeiffer and Gjergji Kasneci},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attention mechanisms don’t learn additive models: Rethinking feature importance for transformers},
  url          = {https://openreview.net/forum?id=yawWz4qWkF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODNet: Opinion dynamics-inspired neural message passing for graphs and hypergraphs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ytKFKoCpyK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural message passing serves as a cornerstone framework in graph neural networks, providing a clear and intuitive mathematical guideline for the propagation and aggregation of information among interconnected nodes within graphs. Throughout this process, node representations undergo dynamic updates, considering both the individual states and connections of neighboring nodes. Concurrently, social networks, as prominent forms of interconnected data, form dynamic systems that achieve stability through continuous internal communications and opinion exchanges among social actors along their social ties. Drawing upon the shared concepts between these two domains, our study establishes an explicit connection between message passing and opinion dynamics in sociology. Moreover, we introduce a novel continuous message passing scheme termed ODNet, which integrates bounded confidence to refine the influence weight of local nodes for message propagation. By adjusting the similarity cutoffs of bounded confidence and influence weights within ODNet, we define opinion exchange rules that align with the characteristics of neural message passing and can effectively mitigate the oversmoothing issue. We extend the framework to hypergraphs and formulate corresponding continuous message passing rules, which reveal a close association with particle dynamics. Empirically, we showcase that ODNet enhances prediction performance across various social networks presented as homophilic graphs, heterophilic graphs, and hypergraphs. Notably, our proposed ODNet outperforms existing GNNs with its straightforward construction and robust theoretical foundation.},
  archive      = {J_TMLR},
  author       = {Bingxin Zhou and Outongyi Lv and Jing Wang and Xiang Xiao and Weishu Zhao},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ODNet: Opinion dynamics-inspired neural message passing for graphs and hypergraphs},
  url          = {https://openreview.net/forum?id=ytKFKoCpyK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SelfEval: Leveraging discriminative nature of generative models for evaluation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=0mGho8wrv5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an automated way to evaluate the text alignment of text-to-image generative diffusion models using standard image-text recognition datasets. Our method, called SelfEval, uses the generative model to compute the likelihood of real images given text prompts, and the likelihood can be used to perform recognition tasks with the generative model. We evaluate generative models on standard datasets created for multimodal text-image discriminative learning and assess fine-grained aspects of their performance: attribute binding, color recognition, counting, shape recognition, spatial understanding. Existing automated metrics rely on an external pretrained model like CLIP (VLMs) or LLMs, and are sensitive to the exact pretrained model and its limitations. SelfEval sidesteps these issues, and to the best of our knowledge, is the first automated metric to show a high degree of agreement for measuring text-faithfulness with the gold-standard human evaluations across multiple generative models, benchmarks and evaluation metrics. SelfEval also reveals that generative models showcase competitive recognition performance on challenging tasks such as Winoground image-score compared to discriminative models. We hope SelfEval enables easy and reliable automated evaluation for diffusion models.},
  archive      = {J_TMLR},
  author       = {Sai Saketh Rambhatla and Ishan Misra},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SelfEval: Leveraging discriminative nature of generative models for evaluation},
  url          = {https://openreview.net/forum?id=0mGho8wrv5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private fine-tuning of large language models with zeroth-order optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3Y3o0yFZfu'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially private stochastic gradient descent (DP-SGD) allows models to be trained in a privacy-preserving manner, but has proven difficult to scale to the era of foundation models. We introduce DP-ZO, a private fine-tuning method for large language models by privatizing zeroth order optimization methods. A key insight into the design of our method is that the direction of the gradient in the zeroth-order optimization we use is random and the only information from training data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO provides a strong privacy-utility trade-off across different tasks, and model sizes that are comparable to DP-SGD in $(\varepsilon,\delta)$-DP. Notably, DP-ZO possesses significant advantages over DP-SGD in memory efficiency, and obtains higher utility in $\varepsilon$-DP when using the Laplace mechanism.},
  archive      = {J_TMLR},
  author       = {Xinyu Tang and Ashwinee Panda and Milad Nasr and Saeed Mahloujifar and Prateek Mittal},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Private fine-tuning of large language models with zeroth-order optimization},
  url          = {https://openreview.net/forum?id=3Y3o0yFZfu},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highway graph to accelerate reinforcement learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=3mJZfL77WM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) algorithms often struggle with low training efficiency. A common approach to address this challenge is integrating model-based planning algorithms, such as Monte Carlo Tree Search (MCTS) or Value Iteration (VI), into the environmental model. However, VI faces a significant limitation: it requires iterating over a large tensor with dimensions $|\mathcal{S}|\times |\mathcal{A}| \times |\mathcal{S}|$, where $\mathcal{S}$ and $\mathcal{A}$ represent the state and action spaces, respectively. This process updates the value of the preceding state $s_{t-1}$ based on the succeeding state $s_t$ through value propagation, resulting in computationally intensive operations. To enhance the training efficiency of RL algorithms, we propose improving the efficiency of the value learning process. In deterministic environments with discrete state and action spaces, we observe that on the sampled empirical state-transition graph, a non-branching sequence of transitions—termed a \textit{highway}—can take the agent directly from $s_0$ to $s_T$ without deviation through intermediate states. On these non-branching highways, the value-updating process can be streamlined into a single-step operation, eliminating the need for iterative, step-by-step updates. Building on this observation, we introduce a novel graph structure called the \textit{highway graph} to model state transitions. The highway graph compresses the transition model into a compact representation, where edges can encapsulate multiple state transitions, enabling value propagation across multiple time steps in a single iteration. By integrating the highway graph into RL (as a model-based off-policy RL method), the training process is significantly accelerated, particularly in the early stages of training. Experiments across four categories of environments demonstrate that our method learns significantly faster than established and state-of-the-art model-free and model-based RL algorithms (often by a factor of 10 to 150) while maintaining equal or superior expected returns. Furthermore, a deep neural network-based agent trained using the highway graph exhibits improved generalization capabilities and reduced storage costs.},
  archive      = {J_TMLR},
  author       = {Zidu Yin and Zhen Zhang and Dong Gong and Stefano V Albrecht and Javen Qinfeng Shi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Highway graph to accelerate reinforcement learning},
  url          = {https://openreview.net/forum?id=3mJZfL77WM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExCeL: Combined extreme and collective logit information for out-of-distribution detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4Xz0WBAiX4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models often exhibit overconfidence in predicting out-of-distribution (OOD) data, underscoring the crucial role of OOD detection in ensuring reliability in predictions. Among various OOD detection approaches, post-hoc detectors have gained significant popularity, primarily due to their ease of implementation and competitive performance. However, recent benchmarks for OOD detection have revealed a lack of consistency in existing post-hoc methods. This inconsistency in post-hoc detectors can be attributed to their sole reliance either on extreme information, such as the maximum logit, or on collective information (i.e., information spanned across classes or training samples) embedded within the output layer. In this paper, we propose ExCeL, which combines both extreme and collective information within the output layer for enhanced and consistent performance in OOD detection. We leverage the logit of the top predicted class as the extreme information (i.e., the maximum logit), while the collective information is derived in a novel approach that involves assessing the probability of other classes appearing in subsequent ranks across various training samples. Our idea is motivated by the observation that, for in-distribution (ID) data, the ranking of classes beyond the predicted class is more deterministic compared to that in OOD data. Experiments conducted on CIFAR100, ImageNet-200, and ImageNet-1K datasets demonstrate that ExCeL consistently is among the five top-performing methods out of twenty-one existing post-hoc baselines when the joint performance on near-OOD and far-OOD is considered (i.e., in terms of AUROC and FPR95). Furthermore, ExCeL shows the best overall performance across all datasets, unlike other baselines that work best on one dataset but have a performance drop in others.},
  archive      = {J_TMLR},
  author       = {Naveen Karunanayake and Suranga Seneviratne and Sanjay Chawla},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ExCeL: Combined extreme and collective logit information for out-of-distribution detection},
  url          = {https://openreview.net/forum?id=4Xz0WBAiX4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). \copyright plug-in authorization for human copyright protection in text-to-image model. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=4o8lIFkpn2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the contentious issue of copyright infringement in images generated by text-to-image models, sparking debates among AI developers, content creators, and legal entities. State-of-the-art models create high-quality content without crediting original creators, causing concern in the artistic community and model providers. To mitigate this, we propose the ©Plug-in Authorization framework, introducing three operations: addition, extraction, and combination. Addition involves training a ©plug-in for specific copyright, facilitating proper credit attribution. The extraction allows creators to reclaim copyright from infringing models, and the combination enables users to merge different ©plug-ins. These operations act as permits, incentivizing fair use and providing flexibility in authorization. We present innovative approaches, ``Reverse LoRA'' for extraction and ``EasyMerge'' for seamless combination. Experiments in artist-style replication and cartoon IP recreation demonstrate ©plug-ins' effectiveness, offering a valuable solution for human copyright protection in the age of generative AIs. The code is available at \url{https://github.com/zc1023/-Plug-in-Authorization.git}},
  archive      = {J_TMLR},
  author       = {Chao Zhou and Huishuai Zhang and Jiang Bian and Weiming Zhang and Nenghai Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {\copyright plug-in authorization for human copyright protection in text-to-image model},
  url          = {https://openreview.net/forum?id=4o8lIFkpn2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series domain adaptation via channel-selective representation alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8C8LJIqF4y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building generalizable and robust multivariate time series models can be challenging for real-world settings that involve significant shifts between training and testing. Existing unsupervised domain adaptation methods often struggle with real world distribution shifts which are often much more severe in some channels than others. To overcome these obstacles, we introduce a novel method called Signal Selection and Screening via Sinkhorn alignment for Time Series domain Adaptation (SSSS-TSA). SSSS-TSA addresses channel-level variations by aligning both individual channel representations and selectively weighted combined channel representations. This dual alignment strategy based on channel selection not only ensures effective adaptation to new domains but also maintains robustness in scenarios with training and testing set shifts or when certain channels are absent or corrupted. We evaluate our method on several time-series classification benchmarks and find that it consistently improves performance over existing methods. These results demonstrate the importance of adaptively selecting and screening different channels to enable more effective alignment across domains.},
  archive      = {J_TMLR},
  author       = {Nauman Ahad and Mark A. Davenport and Eva L Dyer},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Time series domain adaptation via channel-selective representation alignment},
  url          = {https://openreview.net/forum?id=8C8LJIqF4y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Making self-supervised learning robust to spurious correlation via learning-speed aware sampling. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=8mgX3Uw2Ea'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has emerged as a powerful technique for learning rich representations from unlabeled data. The data representations can capture many underlying attributes of data, and are useful in downstream prediction tasks. In real-world settings, spurious correlations between some attributes (e.g. race, gender and age) and labels for downstream tasks often exist, e.g. disease findings are usually more prevalent among elderly patients. In this paper, we investigate SSL in the presence of spurious correlations and show that the SSL training loss can be minimized by capturing only a subset of conspicuous features relevant to those sensitive attributes, despite the presence of other important predictive features for the downstream tasks. To address this issue, we investigate the learning dynamics of SSL and observe that the learning is slower for samples that conflict with such correlations (e.g. elder patients without diseases). Motivated by these findings, we propose a learning-speed aware SSL (LA-SSL) approach, in which we sample each training data with a probability that is inversely related to its learning speed. We evaluate LA-SSL on three datasets that exhibit spurious correlations between different attributes, demonstrating the enhanced robustness of pretrained representations on downstream classification tasks.},
  archive      = {J_TMLR},
  author       = {Weicheng Zhu and Sheng Liu and Carlos Fernandez-Granda and Narges Razavian},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Making self-supervised learning robust to spurious correlation via learning-speed aware sampling},
  url          = {https://openreview.net/forum?id=8mgX3Uw2Ea},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed graph generation with heat kernels. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=60Gi1w6hte'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing work on graph generation has, so far, mainly focused on undirected graphs. In this paper we propose a denoising autoencoder-based generative model that exploits the global structure of directed graphs (also called digraphs) via their Laplacian dynamics and enables one-shot generation. Our noising encoder uses closed-form expressions based on the heat equation to corrupt its digraph input with uniform noise. Our decoder reconstructs the corrupted representation by exploiting the global topological information of the graph included in its random walk Laplacian matrix. Our approach generalizes a special class of exponential kernels over discrete structures, called diffusion kernels or heat kernels, to the non-symmetric case via Reproducing Kernel Banach Spaces (RKBS). This connection with heat kernels provides us with a geometrically motivated algorithm related to Gaussian processes and dimensionality reduction techniques such as Laplacian eigenmaps. It also allows us to interpret and exploit the eigenproperties of the Laplacian matrix. We provide an experimental analysis of our approach on different types of synthetic datasets and show that our model is able to generate directed graphs that follow the distribution of the training dataset even if it is multimodal.},
  archive      = {J_TMLR},
  author       = {Marc T. Law and Karsten Kreis and Haggai Maron},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Directed graph generation with heat kernels},
  url          = {https://openreview.net/forum?id=60Gi1w6hte},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A thorough reproduction and evaluation of $\mu$P. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=AFxEdJwQcp'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is an independent empirical reproduction of the claimed benefits of the $\mu$P parametrization proposed in \citet{yang2020feature} and \citet{yang2021tuning}. Under the so-called Standard Parametrization (SP), the weights of neural networks are initialized from the Gaussian distribution with variance scaling as the inverse of ``fan-in'', with the learning rate being the same for every layer. While this guarantees that (pre)activations are $\mathcal{O}(1)$ at initialization with respect to width, it causes their scale to be width-dependent during training. To address this, \citet{yang2020feature} and \citet{yang2021tuning} proposed the Maximal Update Parametrization ($\mu$P), which is also claimed to make the optimal value of various hyperparameters independent of width. However, despite its alleged benefits, $\mu$P has not gained much traction among practitioners. Possibly, this could stem from a lack of thorough independent evaluation of $\mu$P against SP. We address this by independently reproducing the empirical claims of the original works. At the same time, we substantially increase the scale of the experiments, by training $16000$ neural networks of sizes from $500$ to $1$B parameters, and empirically investigate $\mu$P's effect on outputs, gradient updates, weights, training loss and validation loss. We find that generally $\mu$P indeed delivers on its promises, even though this does not always translate to improved generalization.},
  archive      = {J_TMLR},
  author       = {Georgios Vlassis and David Belius and Volodymyr Fomichov},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A thorough reproduction and evaluation of $\mu$P},
  url          = {https://openreview.net/forum?id=AFxEdJwQcp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIND: Modality-informed knowledge distillation framework for multimodal clinical prediction tasks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BhOJreYmur'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion leverages information across modalities to learn better feature representations with the goal of improving performance in fusion-based tasks. However, multimodal datasets, especially in medical settings, are typically smaller than their unimodal counterparts, which can impede the performance of multimodal models. Additionally, the increase in the number of modalities is often associated with an overall increase in the size of the multimodal network, which may be undesirable in medical use cases. Utilizing smaller unimodal encoders may lead to sub-optimal performance, particularly when dealing with high-dimensional clinical data. In this paper, we propose the Modality-INformed knowledge Distillation (MIND) framework, a multimodal model compression approach based on knowledge distillation that transfers knowledge from ensembles of pre-trained deep neural networks of varying sizes into a smaller multimodal student. The teacher models consist of unimodal networks, allowing the student to learn from diverse representations. MIND employs multi-head joint fusion models, as opposed to single-head models, enabling the utilization of unimodal encoders in the case of unimodal samples without requiring imputation or masking of absent modalities. As a result, MIND generates an optimized multimodal model, enhancing both multimodal and unimodal representations. It can also be leveraged to balance multimodal learning during training. We evaluate MIND on binary classification and multilabel clinical prediction tasks using clinical time series data and chest X-ray images extracted from publicly available datasets. Additionally, we assess the generalizability of the MIND framework on three non-medical multimodal multiclass benchmark datasets. The experimental results demonstrate that MIND enhances the performance of the smaller multimodal network across all five tasks, as well as various fusion methods and multimodal network architectures, compared to several state-of-the-art baselines.},
  archive      = {J_TMLR},
  author       = {Alejandro Guerra-Manzanares and Farah Shamout},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {MIND: Modality-informed knowledge distillation framework for multimodal clinical prediction tasks},
  url          = {https://openreview.net/forum?id=BhOJreYmur},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of the noise schedule for score-based generative models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=BlYIPa0Fx1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based generative models (SGMs) aim at estimating a target data distribution by learning score functions using only noise-perturbed samples from the target. Recent literature has focused extensively on assessing the error between the target and estimated distributions, gauging the generative quality through the Kullback-Leibler (KL) divergence and Wasserstein distances. Under mild assumptions on the data distribution, we establish an upper bound for the KL divergence between the target and the estimated distributions, explicitly depending on any time-dependent noise schedule. Under additional regularity assumptions, taking advantage of favorable underlying contraction mechanisms, we provide a tighter error bound in Wasserstein distance compared to state-of-the-art results. In addition to being tractable, this upper bound jointly incorporates properties of the target distribution and SGM hyperparameters that need to be tuned during training. Finally, we illustrate these bounds through numerical experiments using simulated and CIFAR-10 datasets, identifying an optimal range of noise schedules within a parametric family.},
  archive      = {J_TMLR},
  author       = {Stanislas Strasman and Antonio Ocello and Claire Boyer and Sylvain Le Corff and Vincent Lemaire},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An analysis of the noise schedule for score-based generative models},
  url          = {https://openreview.net/forum?id=BlYIPa0Fx1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupled sequence and structure generation for realistic antibody design. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=CTkABQvnkm'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has made rapid progress in antibody design, which plays a key role in the advancement of therapeutics. A dominant paradigm is to train a model to jointly generate the antibody sequence and the structure as a candidate. However, the joint generation requires the model to generate both the discrete amino acid categories and the continuous 3D coordinates; this limits the space of possible architectures and may lead to suboptimal performance. In response, we propose an antibody sequence-structure decoupling (ASSD) framework, which separates sequence generation and structure prediction. Although our approach is simple, our idea allows the use of powerful neural architectures and demonstrates notable performance improvements. We also find that the widely used non-autoregressive generators promote sequences with overly repeating tokens. Such sequences are both out-of-distribution and prone to undesirable developability properties that can trigger harmful immune responses in patients. To resolve this, we introduce a composition-based objective that allows an efficient trade-off between high performance and low token repetition. ASSD shows improved performance in various antibody design experiments, while the composition-based objective successfully mitigates token repetition of non-autoregressive models.},
  archive      = {J_TMLR},
  author       = {Nayoung Kim and Minsu Kim and Sungsoo Ahn and Jinkyoo Park},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decoupled sequence and structure generation for realistic antibody design},
  url          = {https://openreview.net/forum?id=CTkABQvnkm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport for domain adaptation through gaussian mixture models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DCAeXwLenB'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning systems operate under the assumption that training and test data are sampled from a fixed probability distribution. However, this assumptions is rarely verified in practice, as the conditions upon which data was acquired are likely to change. In this context, the adaptation of the unsupervised domain requires minimal access to the data of the new conditions for learning models robust to changes in the data distribution. Optimal transport is a theoretically grounded tool for analyzing changes in distribution, especially as it allows the mapping between domains. However, these methods are usually computationally expensive as their complexity scales cubically with the number of samples. In this work, we explore optimal transport between Gaussian Mixture Models (GMMs), which is conveniently written in terms of the components of source and target GMMs. We experiment with 9 benchmarks, with a total of $85$ adaptation tasks, showing that our methods are more efficient than previous shallow domain adaptation methods, and they scale well with number of samples $n$ and dimensions $d$},
  archive      = {J_TMLR},
  author       = {Eduardo Fernandes Montesuma and Fred Maurice NGOLE MBOULA and Antoine Souloumiac},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimal transport for domain adaptation through gaussian mixture models},
  url          = {https://openreview.net/forum?id=DCAeXwLenB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From promise to practice: A study of common pitfalls behind the generalization gap in machine learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=DqWvxSQ1TK'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world of Machine Learning (ML) offers great promise, but often there is a noticeable gap between claims made in research papers and the model's practical performance in real-life applications. This gap can often be attributed to systematic errors and pitfalls that occur during the development phase of ML models. This study aims to systematically identify these errors. For this, we break down the ML process into four main stages: data handling, model design, model evaluation, and reporting. Across these stages, we have identified fourteen common pitfalls based on a comprehensive review of around 60 papers discussing either broad challenges or specific pitfalls within ML pipeline. Moreover, Using the Brain Tumor Segmentation (BraTS) dataset, we perform three experiments to illustrate the impacts of these pitfalls, providing examples of how they can skew results and affect outcomes. In addition, we also perform a review to study the frequency of unclear reporting regarding these pitfalls in ML research. The goal of this review was to assess whether authors have adequately addressed these pitfalls in their reports. For this, we review 126 randomly chosen papers on image segmentation from the ICCV (2013-2021) and MICCAI (2013-2022) conferences from the last ten years. The results from this review show a notable oversight of these issues, with many of the papers lacking clarity on how the pitfalls are handled. This highlights an important gap in current reporting practices within the ML community. The codes for the experiments will be published upon acceptance.},
  archive      = {J_TMLR},
  author       = {Saeideh Ghanbari Azar and Lorenzo Tronchin and Attila Simkó and Tufve Nyholm and Tommy Löfstedt},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {From promise to practice: A study of common pitfalls behind the generalization gap in machine learning},
  url          = {https://openreview.net/forum?id=DqWvxSQ1TK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjacency search embeddings. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=GDN5cFTNaL'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose two novel Adjacency Search Embeddings that are inspired by the theory of identifying s-t minimum cuts: Maximum Adjacency Search (MAS) and Threshold-based Adjacency Search (TAS), which leverage both the node and a subset of its neighborhood to discern a set of nodes well-integrated into higher-order network structures. This serves as context for generating higher-order representations. Our approaches, when used in conjunction with the skip-gram model, exhibit superior effectiveness in comparison to other shallow embedding techniques in tasks such as link prediction and node classification. By incorporating our mechanisms as a preprocessing technique, we show substantial improvements in node classification performance across GNNs like GCN, GraphSage, and Gatv2 on both attributed and non-attributed networks. Furthermore, we substantiate the applicability of our approaches, shedding light on their aptness for specific graph scenarios.},
  archive      = {J_TMLR},
  author       = {Meher Chaitanya and Kshitijaa Jaglan and Ulrik Brandes},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adjacency search embeddings},
  url          = {https://openreview.net/forum?id=GDN5cFTNaL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced federated optimization: Adaptive unbiased client sampling with reduced variance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Gb4HBGG9re'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a distributed learning paradigm to train a global model across multiple devices without collecting local data. In FL, a server typically selects a subset of clients for each training round to optimize resource usage. Central to this process is the technique of unbiased client sampling, which ensures a representative selection of clients. Current methods primarily utilize a random sampling procedure which, despite its effectiveness, achieves suboptimal efficiency owing to the loose upper bound caused by the sampling variance. In this work, by adopting an independent sampling procedure, we propose a federated optimization framework focused on adaptive unbiased client sampling, improving the convergence rate via an online variance reduction strategy. In particular, we present the first adaptive client sampler, K-Vib, employing an independent sampling procedure. K-Vib achieves a linear speed-up on the regret bound $\tilde{\mathcal{O}}\big(N^{\frac{1}{3}}T^{\frac{2}{3}}/K^{\frac{4}{3}}\big)$ within a set communication budget $K$. Empirical studies indicate that K-Vib doubles the speed compared to baseline algorithms, demonstrating significant potential in federated optimization.},
  archive      = {J_TMLR},
  author       = {Dun Zeng and Zenglin Xu and Yu Pan and Xu Luo and Qifan Wang and Xiaoying Tang},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhanced federated optimization: Adaptive unbiased client sampling with reduced variance},
  url          = {https://openreview.net/forum?id=Gb4HBGG9re},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifelong learning in StyleGAN through latent subspaces. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=I4IAwVOZrM'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {StyleGAN is one of the most versatile generative models that have emerged in recent times. However, when it is trained continually on a stream of data (potentially previously unseen distributions), it tends to forget the distribution it has learned, as is the case with any other generative model, due to catastrophic forgetting. Recent studies have shown that the latent space of StyleGAN is very versatile, as data from a variety of distributions can be inverted onto it. In this paper, we propose StyleCL, a method that leverages this property to enable lifelong learning in StyleGAN without forgetting. Specifically, given a StyleGAN trained on a certain task (dataset), we propose to learn a latent subspace characterized by a set of dictionary vectors in its latent space, one for each novel, unseen task (or dataset). We also learn a relatively small set of parameters (feature adaptors) in the weight space to complement the dictionary learning in the latent space. Furthermore, we introduce a method that utilizes the similarity between tasks to effectively reuse the feature adaptor parameters from the previous tasks, aiding in the learning process for the current task at hand. Our approach guarantees that the parameters from previous tasks are reused only if they contribute to a beneficial forward transfer of knowledge. Remarkably, StyleCL avoids catastrophic forgetting because the set of dictionary and the feature adaptor parameters are unique for each task. We demonstrate that our method, StyleCL, achieves better generation quality on multiple datasets with significantly fewer additional parameters per task compared to previous methods. This is a consequence of learning task-specific dictionaries in the latent space, which has a much lower dimensionality compared to the weight space. Code for this work is available at \href{https://github.com/kadarsh22/StyleCL}{link}},
  archive      = {J_TMLR},
  author       = {Adarsh Kappiyath and ANMOL GARG and Ramya Hebbalaguppe and Prathosh AP},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lifelong learning in StyleGAN through latent subspaces},
  url          = {https://openreview.net/forum?id=I4IAwVOZrM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed multi-agent lifelong learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IIVr4Hu3Oi'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning (LL) machines are designed to operate safely in dynamic environments by continually updating their knowledge. Conventional LL paradigms often assume that new data come labeled and that each LL machine has to learn independently from its environment. However, human labeling is expensive and impractical in remote conditions where automation is most desired. We introduce the Peer Parallel Lifelong Learning (PEEPLL) framework for distributed Multi-Agent Lifelong Learning, where agents continually learn online by actively requesting assistance from other agents instead of relying on the expensive environment to teach them. Unlike classical distributed AI, where communication scales poorly, lifelong learners need to communicate only on information they have not yet learned. Additionally, agents reply only if they are highly confident: Our TRUE confidence score uses a compute-efficient application of Variational Autoencoder to quantify confidence in prediction without needing data reconstruction. TRUE outperforms traditional Entropy-based confidence scores, reducing communication overhead by 18.05\% on CIFAR-100 and 5.8\% on MiniImageNet. To improve system resilience to low-quality or adversarial responses, our agents selectively accept a subset of received responses using the REFINE algorithm, which results in a 51.99\% increase in the percentage of correct accepted responses on CIFAR-100 and 25.79\% on MiniImageNet. Like traditional LL agents, PEEPLL agents store a subset of previously acquired knowledge as memory to learn alongside new information to prevent forgetting. We propose a Dynamic Memory-Update mechanism for PEEPLL agents that improves QA's classification performance by 44.17\% on CIFAR-100 and 26.8\% on MiniImageNet compared to the baseline Memory-Update mechanism. Our findings demonstrate that a PEEPLL agent can outperform an LL agent even if the latter has environmental supervision available, thus significantly reducing the need for labeling. PEEPLL provides a framework to facilitate research in distributed multi-agent LL, marking a substantial step towards practical, scalable lifelong learning technologies at the edge.},
  archive      = {J_TMLR},
  author       = {Prithviraj Tarale and Edward Rietman and Hava T Siegelmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributed multi-agent lifelong learning},
  url          = {https://openreview.net/forum?id=IIVr4Hu3Oi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preventing conflicting gradients in neural marked temporal point processes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=INijCSPtbQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Marked Temporal Point Processes (MTPP) are flexible models to capture complex temporal inter-dependencies between labeled events. These models inherently learn two predictive distributions: one for the arrival times of events and another for the types of events, also known as marks. In this study, we demonstrate that learning a MTPP model can be framed as a two-task learning problem, where both tasks share a common set of trainable parameters that are optimized jointly. We show that this often leads to the emergence of conflicting gradients during training, where task-specific gradients are pointing in opposite directions. When such conflicts arise, following the average gradient can be detrimental to the learning of each individual tasks, resulting in overall degraded performance. To overcome this issue, we introduce novel parametrizations for neural MTPP models that allow for separate modeling and training of each task, effectively avoiding the problem of conflicting gradients. Through experiments on multiple real-world event sequence datasets, we demonstrate the benefits of our framework compared to the original model formulations.},
  archive      = {J_TMLR},
  author       = {Tanguy Bosser and Souhaib Ben Taieb},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Preventing conflicting gradients in neural marked temporal point processes},
  url          = {https://openreview.net/forum?id=INijCSPtbQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving CLIP counting accuracy via parameter-efficient fine-tuning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=IZrt6hB2sI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on addressing the object counting limitations of vision-language models, with a particular emphasis on Contrastive Language-Image Pre-training (CLIP) models. Centered on our hypothesis that counting knowledge can be abstracted into linear vectors within the text embedding space, we develop a parameter-efficient fine-tuning method and several zero-shot methods to improve CLIP's counting accuracy. Through comprehensive experiments, we demonstrate that our learning-based method not only outperforms full-model fine-tuning in counting accuracy but also retains the broad capabilities of pre-trained CLIP models. Our zero-shot text embedding editing techniques are also effective in situations where training data is scarce, and can be extended to improve Stable Diffusion's ability to generate images with precise object counts. We also contribute two specialized datasets to train and evaluate CLIP’s counting capabilities. Our code is available at https://github.com/UW-Madison-Lee-Lab/CLIP_Counting.},
  archive      = {J_TMLR},
  author       = {Ruisu Zhang and Yicong Chen and Kangwook Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving CLIP counting accuracy via parameter-efficient fine-tuning},
  url          = {https://openreview.net/forum?id=IZrt6hB2sI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed quasi-newton method for fair and fast federated learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=KbteA50cni'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising technology that enables edge devices/clients to collaboratively and iteratively train a machine learning model under the coordination of a central server. The most common approach to FL is first-order methods, where clients send their local gradients to the server in each iteration. However, these methods often suffer from slow convergence rates. As a remedy, second-order methods, such as quasi-Newton, can be employed in FL to accelerate its convergence. Unfortunately, similarly to the first-order FL methods, the application of second-order methods in FL can lead to unfair models, achieving high average accuracy while performing poorly on certain clients' local datasets. To tackle this issue, in this paper we introduce a novel second-order FL framework, dubbed distributed quasi-Newton federated learning (DQN-Fed). This approach seeks to ensure fairness while leveraging the fast convergence properties of quasi-Newton methods in the FL context. Specifically, DQN-Fed helps the server update the global model in such a way that (i) all local loss functions decrease to promote fairness, and (ii) the rate of change in local loss functions aligns with that of the quasi-Newton method. We prove the convergence of DQN-Fed and demonstrate its \textit{linear-quadratic} convergence rate. Moreover, we validate the efficacy of DQN-Fed across a range of federated datasets, showing that it surpasses state-of-the-art fair FL methods in fairness, average accuracy and convergence speed. The Code for paper is publicly available at \url{https://anonymous.4open.science/r/DQN-Fed-FDD2}.},
  archive      = {J_TMLR},
  author       = {Shayan Mohajer Hamidi and Linfeng Ye},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distributed quasi-newton method for fair and fast federated learning},
  url          = {https://openreview.net/forum?id=KbteA50cni},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerically robust fixed-point smoothing without state augmentation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LVQ8BEL5n3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical implementations of Gaussian smoothing algorithms have received a great deal of attention in the last 60 years. However, almost all work focuses on estimating complete time series (``fixed-interval smoothing'', $\mathcal{O}(K)$ memory) through variations of the Rauch--Tung--Striebel smoother, rarely on estimating the initial states (``fixed-point smoothing'', $\mathcal{O}(1)$ memory). Since fixed-point smoothing is a crucial component of algorithms for dynamical systems with unknown initial conditions, we close this gap by introducing a new formulation of a Gaussian fixed-point smoother. In contrast to prior approaches, our perspective admits a numerically robust Cholesky-based form (without downdates) and avoids state augmentation, which would needlessly inflate the state-space model and reduce the numerical practicality of any fixed-point smoother code. The experiments demonstrate how a JAX implementation of our algorithm matches the runtime of the fastest methods and the robustness of the most robust techniques while existing implementations must always sacrifice one for the other.},
  archive      = {J_TMLR},
  author       = {Nicholas Krämer},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Numerically robust fixed-point smoothing without state augmentation},
  url          = {https://openreview.net/forum?id=LVQ8BEL5n3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards LifeSpan cognitive systems. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LZ9FmeFeLV'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building a human-like system that continuously interacts with complex environments—whether simulated digital worlds or human society—presents several key challenges. Central to this is enabling continuous, high-frequency interactions, where the interactions are termed experiences. We refer to this envisioned system as the LifeSpan Cognitive System (LSCS). A critical feature of LSCS is its ability to engage in incremental and rapid updates while retaining and accurately recalling past experiences. In this paper we focus on the domain of Large Language Models (LLMs), where we identify two major challenges: (1) Abstraction and Experience Merging, and (2) Long-term Retention with Accurate Recall. These properties are essential for storing new experiences, organizing past experiences, and responding to the environment in ways that leverage relevant historical data. Unlike language models with continual learning, which typically rely on large corpora for fine-tuning and focus on improving performance within specific domains or tasks, LSCS must rapidly and incrementally update with new information from its environment at a high frequency. Existing technologies with the potential of solving the above two major challenges can be classified into four classes based on a conceptual metric called Storage Complexity, which measures the relative space required to store past experiences. Each of these four classes of technologies has its own strengths and limitations while we argue none of them alone can achieve LSCS alone. To this end, we propose a potential instantiation for LSCS that can integrate all four classes of technologies. The new instantiation, serving as a conjecture, operates through two core processes: Absorbing Experiences and Generating Responses.},
  archive      = {J_TMLR},
  author       = {Yu Wang and Chi Han and Tongtong Wu and Xiaoxin He and Wangchunshu Zhou and Nafis Sadeq and Xiusi Chen and Zexue He and Wei Wang and Gholamreza Haffari and Heng Ji and Julian McAuley},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards LifeSpan cognitive systems},
  url          = {https://openreview.net/forum?id=LZ9FmeFeLV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the properties and estimation of pointwise mutual information profiles. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=LdflD41Gn8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pointwise mutual information profile, or simply profile, is the distribution of pointwise mutual information for a given pair of random variables. One of its important properties is that its expected value is precisely the mutual information between these random variables. In this paper, we analytically describe the profiles of multivariate normal distributions and show that for an expressive family of distributions, termed Bend and Mix Models, the profile can be accurately estimated using Monte Carlo methods. We then show how Bend and Mix Models can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how Bend and Mix Models can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary. The accompanying code is available at https://github.com/cbg-ethz/bmi.},
  archive      = {J_TMLR},
  author       = {Paweł Czyż and Frederic Grabowski and Julia E Vogt and Niko Beerenwinkel and Alexander Marx},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the properties and estimation of pointwise mutual information profiles},
  url          = {https://openreview.net/forum?id=LdflD41Gn8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explanation shift: How did the distribution shift impact the model?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MO1slfU9xy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning models on new data is critical for their success in real-world applications. Current methods to detect shifts in the input or output data distributions have limitations in identifying model behaviour changes when no labelled data is available. In this paper, we define \emph{explanation shift} as the statistical comparison between how predictions from training data are explained and how predictions on new data are explained. We propose explanation shift as a key indicator to investigate the interaction between distribution shifts and learned models. We introduce an Explanation Shift Detector that operates on the explanation distributions, providing more sensitive and explainable changes in interactions between distribution shifts and learned models. We compare explanation shifts with other methods that are based on distribution shifts, showing that monitoring for explanation shifts results in more sensitive indicators for varying model behavior. We provide theoretical and experimental evidence and demonstrate the effectiveness of our approach on synthetic and real data. Additionally, we release an open-source Python package, \texttt{skshift}, which implements our method and provides usage tutorials for further reproducibility.},
  archive      = {J_TMLR},
  author       = {Carlos Mougan and Klaus Broelemann and Gjergji Kasneci and Thanassis Tiropanis and Steffen Staab},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explanation shift: How did the distribution shift impact the model?},
  url          = {https://openreview.net/forum?id=MO1slfU9xy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reweighting improves conditional risk bounds. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=MvYddudHuE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the weighted empirical risk minimization (weighted ERM) schema, in which an additional data-dependent weight function is incorporated when the empirical risk function is being minimized. We show that under a general ``balanceable" Bernstein condition, one can design a weighted ERM estimator to achieve superior performance in certain sub-regions over the one obtained from standard ERM, and the superiority manifests itself through a data-dependent constant term in the error bound. These sub-regions correspond to large-margin ones in classification settings and low-variance ones in heteroscedastic regression settings, respectively. Our findings are supported by evidence from synthetic data experiments.},
  archive      = {J_TMLR},
  author       = {Yikai Zhang and Jiahe Lin and Fengpei Li and Songzhu Zheng and Anant Raj and Anderson Schneider and Yuriy Nevmyvaka},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reweighting improves conditional risk bounds},
  url          = {https://openreview.net/forum?id=MvYddudHuE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can AI-generated text be reliably detected? stress testing AI text detectors under various attacks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=OOgsAZdFOt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) can perform impressively well in various applications, such as document completion and question-answering. However, the potential for misuse of these models in activities such as plagiarism, generating fake news, and spamming has raised concerns about their responsible use. Consequently, the reliable detection of AI-generated text has become a critical area of research. Recent works have attempted to address this challenge through various methods, including the identification of model signatures in generated text outputs and the application of watermarking techniques to detect AI-generated text. These detectors have shown to be effective under their specific settings. In this paper, we stress-test the robustness of these AI text detectors in the presence of an attacker. We introduce recursive paraphrasing attack to stress test a wide range of detection schemes, including the ones using the watermarking as well as neural network-based detectors, zero-shot classifiers, and retrieval-based detectors. Our experiments conducted on passages, each approximately 300 tokens long, reveal the varying sensitivities of these detectors to our attacks. We also observe that these paraphrasing attacks add slight degradation to the text quality. We analyze the trade-offs between our attack strength and the resulting text quality, measured through human studies, perplexity scores, and accuracy on text benchmarks. Our findings indicate that while our recursive paraphrasing method can significantly reduce detection rates, it only slightly degrades text quality in many cases, highlighting potential vulnerabilities in current detection systems in the presence of an attacker. Additionally, we investigate the susceptibility of watermarked LLMs to spoofing attacks aimed at misclassifying human-written text as AI-generated. We demonstrate that an attacker can infer hidden AI text signatures without white-box access to the detection method, potentially leading to reputational risks for LLM developers. Finally, we provide a theoretical framework connecting the AUROC of the best possible detector to the Total Variation distance between human and AI text distributions. This analysis offers insights into the fundamental challenges of reliable detection as language models continue to advance.},
  archive      = {J_TMLR},
  author       = {Vinu Sankar Sadasivan and Aounon Kumar and Sriram Balasubramanian and Wenxiao Wang and Soheil Feizi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Can AI-generated text be reliably detected? stress testing AI text detectors under various attacks},
  url          = {https://openreview.net/forum?id=OOgsAZdFOt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization dynamics of equivariant and augmented neural networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PTTa3U29NR'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the optimization of neural networks on symmetric data, and compare the strategy of constraining the architecture to be equivariant to that of using data augmentation. Our analysis reveals that the relative geometry of the admissible and the equivariant layers, respectively, plays a key role. Under natural assumptions on the data, network, loss, and group of symmetries, we show that compatibility of the spaces of admissible layers and equivariant layers, in the sense that the corresponding orthogonal projections commute, implies that the sets of equivariant stationary points are identical for the two strategies. If the linear layers of the network also are given a unitary parametrization, the set of equivariant layers is even invariant under the gradient flow for augmented models. Our analysis however also reveals that even in the latter situation, stationary points may be unstable for augmented training although they are stable for the manifestly equivariant models.},
  archive      = {J_TMLR},
  author       = {Oskar Nordenfors and Fredrik Ohlsson and Axel Flinth},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimization dynamics of equivariant and augmented neural networks},
  url          = {https://openreview.net/forum?id=PTTa3U29NR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global safe sequential learning via efficient knowledge transfer. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=PtD2gVmb3J'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential learning methods, such as active learning and Bayesian optimization, aim to select the most informative data for task learning. In many applications, however, data selection is constrained by unknown safety conditions, motivating the development of safe learning approaches. A promising line of safe learning methods uses Gaussian processes to model safety conditions, restricting data selection to areas with high safety confidence. However, these methods are limited to local exploration around an initial seed dataset, as safety confidence centers around observed data points. As a consequence, task exploration is slowed down and safe regions disconnected from the initial seed dataset remain unexplored. In this paper, we propose safe transfer sequential learning to accelerate task learning and to expand the explorable safe region. By leveraging abundant offline data from a related source task, our approach guides exploration in the target task more effectively. We also provide a theoretical analysis to explain why single-task method cannot cope with disconnected regions. Finally, we introduce a computationally efficient approximation of our method that reduces runtime through pre-computations. Our experiments demonstrate that this approach, compared to state-of-the-art methods, learns tasks with lower data consumption and enhances global exploration across multiple disjoint safe regions, while maintaining comparable computational efficiency.},
  archive      = {J_TMLR},
  author       = {Cen-You Li and Olaf Dünnbier and Marc Toussaint and Barbara Rakitsch and Christoph Zimmer},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global safe sequential learning via efficient knowledge transfer},
  url          = {https://openreview.net/forum?id=PtD2gVmb3J},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can optimization trajectories explain multi-task transfer?. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QQE5j2OsLW'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread adoption of multi-task training in deep learning, little is understood about how multi-task learning (MTL) affects generalization. Prior work has conjectured that the negative effects of MTL are due to optimization challenges that arise during training, and many optimization methods have been proposed to improve multi-task performance. However, recent work has shown that these methods fail to consistently improve multi-task generalization. In this work, we seek to improve our understanding of these failures by empirically studying how MTL impacts the optimization of tasks, and whether this impact can explain the effects of MTL on generalization. We show that MTL results in a generalization gap (a gap in generalization at comparable training loss) between single-task and multi-task trajectories early into training. However, we find that factors of the optimization trajectory previously proposed to explain generalization gaps in single-task settings cannot explain the generalization gaps between single-task and multi-task models. Moreover, we show that the amount of gradient conflict between tasks is correlated with negative effects to task optimization, but is not predictive of generalization. Our work sheds light on the underlying causes for failures in MTL and, importantly, raises questions about the role of general purpose multi-task optimization algorithms.},
  archive      = {J_TMLR},
  author       = {David Mueller and Mark Dredze and Nicholas Andrews},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Can optimization trajectories explain multi-task transfer?},
  url          = {https://openreview.net/forum?id=QQE5j2OsLW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning on virtual heterogeneous data with local-global dataset distillation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=QplBL2pV4Z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Federated Learning (FL) is gaining popularity for training machine learning models in a decentralized fashion, numerous challenges persist, such as asynchronization, computational expenses, data heterogeneity, and gradient and membership privacy attacks. Lately, dataset distillation has emerged as a promising solution for addressing the aforementioned challenges by generating a compact synthetic dataset that preserves a model's training efficacy. However, we discover that using distilled local datasets can amplify the heterogeneity issue in FL. To address this, we propose Federated Learning on Virtual Heterogeneous Data with Local-Global Dataset Distillation (FedLGD), where we seamlessly integrate dataset distillation algorithms into FL pipeline and train FL using a smaller synthetic dataset (referred as virtual data). Specifically, to harmonize the domain shifts, we propose iterative distribution matching to inpaint global information to *local virtual data* and use federated gradient matching to distill *global virtual data* that serve as anchor points to rectify heterogeneous local training, without compromising data privacy. We experiment on both benchmark and real-world datasets that contain heterogeneous data from different sources, and further scale up to an FL scenario that contains a large number of clients with heterogeneous and class-imbalanced data. Our method outperforms *state-of-the-art* heterogeneous FL algorithms under various settings.},
  archive      = {J_TMLR},
  author       = {Chun-Yin Huang and Ruinan Jin and Can Zhao and Daguang Xu and Xiaoxiao Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated learning on virtual heterogeneous data with local-global dataset distillation},
  url          = {https://openreview.net/forum?id=QplBL2pV4Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware evaluation of auxiliary anomalies with the expected anomaly posterior. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Qq4ge9Qe31'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is the task of identifying examples that do not behave as expected. Because anomalies are rare and unexpected events, collecting real anomalous examples is often challenging in several applications. In addition, learning an anomaly detector with limited (or no) anomalies often yields poor prediction performance. One option is to employ auxiliary synthetic anomalies to improve the model training. However, synthetic anomalies may be of poor quality: anomalies that are unrealistic or indistinguishable from normal samples may deteriorate the detector's performance. Unfortunately, no existing methods quantify the quality of auxiliary anomalies. We fill in this gap and propose the expected anomaly posterior (EAP), an uncertainty-based score function that measures the quality of auxiliary anomalies by quantifying the total uncertainty of an anomaly detector. Experimentally on 40 benchmark datasets of images and tabular data, we show that EAP outperforms 12 adapted data quality estimators in the majority of cases. Code of EAP is available at: https://github.com/Lorenzo-Perini/ExpectedAnomalyPosterior.},
  archive      = {J_TMLR},
  author       = {Lorenzo Perini and Maja Rudolph and Sabrina Schmedding and Chen Qiu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty-aware evaluation of auxiliary anomalies with the expected anomaly posterior},
  url          = {https://openreview.net/forum?id=Qq4ge9Qe31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified risk analysis for weakly supervised learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=RGsdAwWuu6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the flourishing research of weakly supervised learning (WSL), we recognize the lack of a unified interpretation of the mechanism behind the weakly supervised scenarios, let alone a systematic treatment of the risk rewrite problem, a crucial step in the empirical risk minimization approach. In this paper, we introduce a framework providing a comprehensive understanding and a unified methodology for WSL. The formulation component of the framework, leveraging a contamination perspective, provides a unified interpretation of how weak supervision is formed and subsumes fifteen existing WSL settings. The induced reduction graphs offer comprehensive connections over WSLs. The analysis component of the framework, viewed as a decontamination process, provides a systematic method of conducting risk rewrite. In addition to the conventional inverse matrix approach, we devise a novel strategy called marginal chain aiming to decontaminate distributions. We justify the feasibility of the proposed framework by recovering existing rewrites reported in the literature.},
  archive      = {J_TMLR},
  author       = {Chao-Kai Chiang and Masashi Sugiyama},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unified risk analysis for weakly supervised learning},
  url          = {https://openreview.net/forum?id=RGsdAwWuu6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dependency-aware semi-structured sparsity of GLU variants in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=T5OuTgPxHS'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement in Large Language Models (LLMs) has markedly enhanced the capabilities of language understanding and generation. However, the substantial model size poses hardware challenges, affecting both memory size for serving and inference latency for token generation. To address those challenges, we propose Dependency-aware Semi-structured Sparsity (DaSS), a new method for the recent prevalent GLU-based LLMs pruning, which incorporates structural dependency into the weight magnitude-based unstructured pruning. We introduce an MLP-specific pruning metric that evaluates the importance of each weight by jointly considering its magnitude and its corresponding MLP intermediate activation norms. DaSS facilitates a balance between the adaptability offered by unstructured pruning and the structural consistency inherent in dependency-based structured pruning. Empirical evaluations on LLaMA2, Mistral, and Gemma model families demonstrate that DaSS not only achieves superior perplexity and accuracy compared to SparseGPT and Wanda in achieving hardware-friendly N:M sparsity patterns but also maintains the computational efficiency of Wanda.},
  archive      = {J_TMLR},
  author       = {Zhiyu Guo and Hidetaka Kamigaito and Taro Watanabe},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dependency-aware semi-structured sparsity of GLU variants in large language models},
  url          = {https://openreview.net/forum?id=T5OuTgPxHS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying spurious correlations using counterfactual alignment. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=Utjw2z1ale'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models driven by spurious correlations often yield poor generalization performance. We propose the counterfactual (CF) alignment method to detect and quantify spurious correlations of black box classifiers. Our methodology is based on counterfactual images generated with respect to one classifier being input into other classifiers to see if they also induce changes in the outputs of these classifiers. The relationship between these responses can be quantified and used to identify specific instances where a spurious correlation exists. This is validated by observing intuitive trends in face-attribute and waterbird classifiers, as well as by fabricating spurious correlations and detecting their presence, both visually and quantitatively. Furthermore, utilizing the CF alignment method, we demonstrate that we can evaluate robust optimization methods (GroupDRO, JTT, and FLAC) by detecting a reduction in spurious correlations.},
  archive      = {J_TMLR},
  author       = {Joseph Paul Cohen and Louis Blankemeier and Akshay S Chaudhari},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identifying spurious correlations using counterfactual alignment},
  url          = {https://openreview.net/forum?id=Utjw2z1ale},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot CLIP class forgetting via text-image space adaptation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=V2SD2uVKEE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient class forgetting has attracted significant interest due to the high computational cost of retraining models from scratch whenever classes need to be forgotten. This need arises from data privacy regulations, the necessity to remove outdated information, and the possibility to enhance model robustness and security. In this paper we address class forgetting in vision-language CLIP model. Modern class forgetting methods for CLIP have demonstrated that zero-shot forgetting is achievable by generating synthetic data and fine-tuning both visual and textual encoders with a regularization loss. Our approach shows that class forgetting in CLIP can be accomplished in a zero-shot manner without any visual data by adapting the shared vision-text space of CLIP, thereby making the class forgetting process more efficient. Our method delivers superior results, demonstrating strong performance and complete class removal, regardless of the visual encoder used in CLIP. Furthermore, we explore what exactly is being targeted by the class forgetting algorithm discovering some interesting properties of CLIP features.},
  archive      = {J_TMLR},
  author       = {Alexey Kravets and Vinay P. Namboodiri},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Zero-shot CLIP class forgetting via text-image space adaptation},
  url          = {https://openreview.net/forum?id=V2SD2uVKEE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). νSAM: Memory-efficient sharpness-aware minimization via nuclear norm constraints. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=V6ia5hWIMD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharpness-aware minimization (SAM) has been shown to improve the generalization of neural networks. However, the method comes at the expense of storing a perturbation of the model parameters, which can be restrictive when memory bound. We design a variant of SAM, called $\nu$SAM, which obtains a low-rank perturbation by modifying the perturbation constraint. The update almost entirely removes the memory footprint of the perturbation without increasing the computational complexity, thus achieving close to a $1/3$ memory saving regarding the parameters when using SGD as the base optimizer. We demonstrate comparable performance of $\nu$SAM with SAM on vision transformers both when training models from scratch and for fine-tuning. Interestingly, $\nu$SAM seems to significantly improve performance for MLP-Mixer architectures across both settings. The results are corroborated theoretically, where we show that SAM with an \emph{arbitrary} norm choice (which includes $\nu$SAM) can converge even with fixed perturbation radius.},
  archive      = {J_TMLR},
  author       = {Thomas Pethick and Parameswaran Raman and Lenon Minorics and Mingyi Hong and Shoham Sabach and Volkan Cevher},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {νSAM: Memory-efficient sharpness-aware minimization via nuclear norm constraints},
  url          = {https://openreview.net/forum?id=V6ia5hWIMD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Doubly robust conditional VAE via decoder calibration: An implicit KL annealing approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VIkycTWDWo'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several variants of Variational Autoencoders have been developed to address inherent limitations. Specifically, $\sigma$-VAE utilizes a scaled identity matrix $\sigma^2 I$ in the decoder variance, while $\beta$-VAE introduces a hyperparameter $\beta$ to reweight the negative ELBO loss. However, a unified theoretical and practical understanding of model optimality remains unclear. For example, existing learning theories on the global optimality of VAE provide limited insight into their empirical success. Previous work showed the mathematical equivalence between the variance scalar $\sigma^2$ and the hyperparameter $\beta$ in shaping the loss landscape. While $\beta$-annealing is widely used, how to implement $\sigma$-annealing is still unclear. This paper presents a comprehensive analysis of $\sigma$-CVAE, highlighting its enhanced expressiveness in parameterizing conditional densities while addressing the associated estimation challenges arising from suboptimal variational inference. In particular, we propose Calibrated Robust $\sigma$-CVAE, a doubly robust algorithm that facilitates accurate estimation of $\sigma$ while effectively preventing the posterior collapse of $\phi$. Our approach, leveraging functional neural decomposition and KL annealing techniques, provides a unified framework to understand both $\sigma$-VAE and $\beta$-VAE regarding parameter optimality and training dynamics. Experimental results on synthetic and real-world datasets demonstrate the superior performance of our method across various conditional density estimation tasks, highlighting its significance for accurate and reliable probabilistic modeling.},
  archive      = {J_TMLR},
  author       = {Chuanhui Liu and Xiao Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Doubly robust conditional VAE via decoder calibration: An implicit KL annealing approach},
  url          = {https://openreview.net/forum?id=VIkycTWDWo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive task planning with language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=VmfWywWuYQ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution. However, most traditional methods require predefined module design, which makes it hard to generalize to different goals. Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain specific pretrained models. To tackle this, we propose a simple framework that achieves interactive task planning with language models by incorporating both high-level planning and low-level skill execution through function calling, leveraging pretrained vision models to ground the scene in language. We verify the robustness of our system on the real world task of making milk tea drinks. Our system is able to generate novel high-level instructions for unseen objectives and successfully accomplishes user tasks. Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps. Our approach is easy to adapt to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering.},
  archive      = {J_TMLR},
  author       = {Boyi Li and Philipp Wu and Pieter Abbeel and Jitendra Malik},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interactive task planning with language models},
  url          = {https://openreview.net/forum?id=VmfWywWuYQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered time-varying bayesian optimization. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WEYMCLu8u7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Current approaches to TVBO require prior knowledge of a constant rate of change to cope with stale data arising from time variations. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function and then resets the dataset. This allows the algorithm to adapt online to realized temporal changes without the need for exact prior knowledge. The event trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We derive regret bounds for adaptive resets without exact prior knowledge of the temporal changes and show in numerical experiments that ET-GP-UCB outperforms competing GP-UCB algorithms on both synthetic and real-world data. The results demonstrate that ET-GP-UCB is readily applicable without extensive hyperparameter tuning.},
  archive      = {J_TMLR},
  author       = {Paul Brunzema and Alexander von Rohr and Friedrich Solowjow and Sebastian Trimpe},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Event-triggered time-varying bayesian optimization},
  url          = {https://openreview.net/forum?id=WEYMCLu8u7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on inverse constrained reinforcement learning: Definitions, progress and challenges. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WUQsBiJqyP'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse Constrained Reinforcement Learning (ICRL) is the task of inferring the implicit constraints that expert agents adhere to, based on their demonstration data. As an emerging research topic, ICRL has received considerable attention in recent years. This article presents a categorical survey of the latest advances in ICRL. It serves as a comprehensive reference for machine learning researchers and practitioners, as well as starters seeking to comprehend the definitions, advancements, and important challenges in ICRL. We begin by formally defining the problem and outlining the algorithmic framework that facilitates constraint inference across various scenarios. These include deterministic or stochastic environments, environments with limited demonstrations, and multiple agents. For each context, we illustrate the critical challenges and introduce a series of fundamental methods to tackle these issues. This survey encompasses discrete, virtual, and realistic environments for evaluating ICRL agents. We also delve into the most pertinent applications of ICRL, such as autonomous driving, robot control, and sports analytics. To stimulate continuing research, we conclude the survey with a discussion of key unresolved questions in ICRL that can effectively foster a bridge between theoretical understanding and practical industrial applications. The papers referenced in this survey can be found at https://github.com/Jasonxu1225/Awesome-Constraint-Inference-in-RL.},
  archive      = {J_TMLR},
  author       = {Guiliang Liu and Sheng Xu and Shicheng Liu and Ashish Gaurav and Sriram Ganapathi Subramanian and Pascal Poupart},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A comprehensive survey on inverse constrained reinforcement learning: Definitions, progress and challenges},
  url          = {https://openreview.net/forum?id=WUQsBiJqyP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the effects of similarity metrics in decentralized deep learning under distribution shift. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=WppTEs4Kkn'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized Learning (DL) enables privacy-preserving collaboration among organizations or users to enhance the performance of local deep learning models. However, model aggregation becomes challenging when client data is heterogeneous, and identifying compatible collaborators without direct data exchange remains a pressing issue. In this paper, we investigate the effectiveness of various similarity metrics in DL for identifying peers for model merging, conducting an empirical analysis across multiple datasets with distribution shifts. Our research provides insights into the performance of these metrics, examining their role in facilitating effective collaboration. By exploring the strengths and limitations of these metrics, we contribute to the development of robust DL methods.},
  archive      = {J_TMLR},
  author       = {Edvin Listo Zec and Tom Hagander and Eric Ihre-Thomason and Sarunas Girdzijauskas},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the effects of similarity metrics in decentralized deep learning under distribution shift},
  url          = {https://openreview.net/forum?id=WppTEs4Kkn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attribute-based method for video anomaly detection. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=XL1N6iLr0G'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) identifies suspicious events in videos, which is critical for crime prevention and homeland security. In this paper, we propose a simple but highly effective VAD method that relies on attribute-based representations. The base version of our method represents every object by its velocity and pose, and computes anomaly scores by density estimation. Surprisingly, this simple representation is sufficient to achieve state-of-the-art performance in ShanghaiTech, the most commonly used VAD dataset. Combining our attribute-based representations with an off-the-shelf, pretrained deep representation yields state-of-the-art performance with a $99.1\%, 93.7\%$, and $85.9\%$ AUROC on Ped2, Avenue, and ShanghaiTech, respectively.},
  archive      = {J_TMLR},
  author       = {Tal Reiss and Yedid Hoshen},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An attribute-based method for video anomaly detection},
  url          = {https://openreview.net/forum?id=XL1N6iLr0G},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversify, don't fine-tune: Scaling up visual recognition training with synthetic images. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YCt8lsIDwA'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in generative deep learning have enabled the creation of high-quality synthetic images in text-to-image generation. While prior research indicates that fine-tuning a pretrained diffusion model on ImageNet and generating synthetic training images can boost an ImageNet classifier's performance, when synthetic images start to outnumber real ones in training, the classifier performance starts to degrade, underscoring the scalability challenge of training with synthetic data. In this paper, we delve into the necessity of generative fine-tuning for achieving recognition performance improvements and investigate the scalability of training with large-scale synthetic images. We find that leveraging off-the-shelf generative models without fine-tuning, while addressing challenges of class name ambiguity, limited prompt diversity, and domain shifts effectively mitigates performance degradation from large-scale synthetic data. Specifically, we leverage large language models (LLMs) and CLIP to resolve class name ambiguity. To diversify images, we propose contextualized diversification (CD) and stylized diversification (SD) methods, also prompted by LLMs. Finally, to mitigate domain shifts, we leverage domain adaptation techniques with auxiliary batch normalization for synthetic images. Our framework consistently boosts recognition model performance with increased synthetic data, even up to 6 times the original ImageNet size. Models trained with our approach demonstrate significant in-domain improvement on ImageNet-val (1.20\% to 2.35\% across various architectures) and strong out-of-domain generalization on ImageNet-Sketch and -Rendition ($\sim$10\% improvement with large vision transformers).},
  archive      = {J_TMLR},
  author       = {Zhuoran Yu and Chenchen Zhu and Sean Culatana and Raghuraman Krishnamoorthi and Fanyi Xiao and Yong Jae Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diversify, don't fine-tune: Scaling up visual recognition training with synthetic images},
  url          = {https://openreview.net/forum?id=YCt8lsIDwA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep neural networks and brain alignment: Brain encoding and decoding (Survey). <em>TMLR</em>. (<a href='https://openreview.net/forum?id=YxKJihRcby'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can artificial intelligence unlock the secrets of the human brain? How do the inner mechanisms of deep learning models relate to our neural circuits? Is it possible to enhance AI by tapping into the power of brain recordings? These captivating questions lie at the heart of an emerging field at the intersection of neuroscience and artificial intelligence. Our survey dives into this exciting domain, focusing on human brain recording studies and cutting-edge cognitive neuroscience datasets that capture brain activity during natural language processing, visual perception, and auditory experiences. We explore two fundamental approaches: encoding models, which attempt to generate brain activity patterns from sensory inputs; and decoding models, which aim to reconstruct our thoughts and perceptions from neural signals. These techniques not only promise breakthroughs in neurological diagnostics and brain-computer interfaces but also offer a window into the very nature of cognition. In this survey, we first discuss popular representations of language, vision, and speech stimuli, and present a summary of neuroscience datasets. We then review how the recent advances in deep learning transformed this field, by investigating the popular deep learning based encoding and decoding architectures, noting their benefits and limitations across different sensory modalities. From text to images, speech to videos, we investigate how these models capture the brain's response to our complex, multimodal world. While our primary focus is on human studies, we also highlight the crucial role of animal models in advancing our understanding of neural mechanisms. Throughout, we mention the ethical implications of these powerful technologies, addressing concerns about privacy and cognitive liberty. We conclude with a summary and discussion of future trends in this rapidly evolving field. Given the large amount of recently published work in the computational cognitive neuroscience (CCN) community, we believe that this survey provides an invaluable entry point for deep neural network (DNN) researchers looking to diversify into CCN research, inviting them to join in unraveling the ultimate puzzle: the human brain.},
  archive      = {J_TMLR},
  author       = {SUBBA REDDY OOTA and Zijiao Chen and Manish Gupta and Bapi Raju Surampudi and Gael Jobard and Frederic Alexandre and Xavier Hinaut},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep neural networks and brain alignment: Brain encoding and decoding (Survey)},
  url          = {https://openreview.net/forum?id=YxKJihRcby},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private gradient flow based on the sliced wasserstein distance. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=aiOHc1LGpD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safeguarding privacy in sensitive training data is paramount, particularly in the context of generative modeling. This can be achieved through either differentially private stochastic gradient descent or a differentially private metric for training models or generators. In this paper, we introduce a novel differentially private generative modeling approach based on a gradient flow in the space of probability measures. To this end, we define the gradient flow of the Gaussian-smoothed Sliced Wasserstein Distance, including the associated stochastic differential equation (SDE). By discretizing and defining a numerical scheme for solving this SDE, we demonstrate the link between smoothing and differential privacy based on a Gaussian mechanism, due to a specific form of the SDE's drift term. We then analyze the differential privacy guarantee of our gradient flow, which accounts for both the smoothing and the Wiener process introduced by the SDE itself. Experiments show that our proposed model can generate higher-fidelity data at a low privacy budget compared to a generator-based model, offering a promising alternative.},
  archive      = {J_TMLR},
  author       = {Ilana Sebag and Muni Sreenivas Pydi and Jean-Yves Franceschi and Alain Rakotomamonjy and Mike Gartrell and Jamal Atif and Alexandre Allauzen},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private gradient flow based on the sliced wasserstein distance},
  url          = {https://openreview.net/forum?id=aiOHc1LGpD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic alignment for prompt-tuning in vision language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=avDr56QjSI'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Going beyond mere fine-tuning of vision-language models (VLMs), learnable prompt tuning has emerged as a promising, resource-efficient alternative. Despite their potential, effectively learning prompts faces the following challenges: (i) training in a low-shot scenario results in overfitting, limiting adaptability, and yielding weaker performance on newer classes or datasets; (ii) prompt-tuning's efficacy heavily relies on the label space, with decreased performance in large class spaces, signaling potential gaps in bridging image and class concepts. In this work, we investigate whether better text semantics can help address these concerns. In particular, we introduce a prompt-tuning method that leverages class descriptions obtained from Large Language Models (LLMs). These class descriptions are used to bridge image and text modalities. Our approach constructs part-level description-guided image and text features, which are subsequently aligned to learn more generalizable prompts. Our comprehensive experiments conducted across 11 benchmark datasets show that our method outperforms established methods, demonstrating substantial improvements.},
  archive      = {J_TMLR},
  author       = {Hari Chandana Kuchibhotla and Sai Srinivas Kancheti and Abbavaram Gowtham Reddy and Vineeth N. Balasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Semantic alignment for prompt-tuning in vision language models},
  url          = {https://openreview.net/forum?id=avDr56QjSI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning via classifier impact and greedy selection for interactive image retrieval. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=b68QOenPWy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Learning (AL) is a user-interactive approach aimed at reducing annotation costs by selecting the most crucial examples to label. Although AL has been extensively studied for image classification tasks, the specific scenario of interactive image retrieval has received relatively little attention. This scenario presents unique characteristics, including an open-set and class-imbalanced binary classification, starting with very few labeled samples. We introduce a novel batch-mode Active Learning framework named GAL (Greedy Active Learning) that better copes with this application. It incorporates new acquisition functions for sample selection that measure the impact of each unlabeled sample on the classifier. We further embed this strategy in a greedy selection approach, better exploiting the samples within each batch. We evaluate our framework with both linear (SVM) and non-linear MLP/Gaussian Process classifiers. For the Gaussian Process case, we show a theoretical guarantee on the greedy approximation. Finally, we assess our performance for the interactive content-based image retrieval task on several benchmarks and demonstrate its superiority over existing approaches and common baselines. Code is available at https://github.com/barleah/GreedyAL.},
  archive      = {J_TMLR},
  author       = {Leah Bar and Boaz Lerner and Nir Darshan and Rami Ben-Ari},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active learning via classifier impact and greedy selection for interactive image retrieval},
  url          = {https://openreview.net/forum?id=b68QOenPWy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with efficient local adaptation for realized volatility prediction. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bHdEtW5E7O'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial markets present unique challenges for Federated Learning (FL) due to fragmented datasets, dynamic participation, and the critical need for precise and reliable predictions. Isolated local datasets often fail to capture the full spectrum of market dynamics, blocking accurate realized volatility predictions. Unlike traditional FL methods that focus on improving convergence during the training process, we propose Federated Learning with Adaptive Robustness and Efficiency for Local Adaptation (FLARE-LA), a novel framework designed to optimize predictive performance after the global training phase. FLARE-LA leverages Taylor-based local linearization and probabilistic optimization to efficiently adapt global models to local data distributions, enabling fast responsiveness to new market conditions. This adaptability ensures trained local models align with real-world scenarios, making FLARE-LA particularly suited to dynamic financial applications. Extensive experimental evaluations demonstrate FLARE-LA's superior performance, showcasing its ability to significantly enhance post-FL outcomes compared to state-of-the-art FL algorithms. The results underscore FLARE-LA's unique capability to drive advancements in financial forecasting and other high-stakes, rapidly evolving domains.},
  archive      = {J_TMLR},
  author       = {Lei Zhao and Lin Cai and Wu-Sheng Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Federated learning with efficient local adaptation for realized volatility prediction},
  url          = {https://openreview.net/forum?id=bHdEtW5E7O},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADAPT to robustify prompt tuning vision transformers. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bZzXgheUSD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of deep models, including Vision Transformers, is known to be vulnerable to adversarial attacks. Many existing defenses against these attacks, such as adversarial training, rely on full-model fine-tuning to induce robustness in the models. These defenses require storing a copy of the entire model, that can have billions of parameters, for each task. At the same time, parameter-efficient prompt tuning is used to adapt large transformer- based models to downstream tasks without the need to save large copies. In this paper, we examine parameter-efficient prompt tuning of Vision Transformers for downstream tasks under the lens of robustness. We show that previous adversarial defense methods, when applied to the prompt tuning paradigm, suffer from gradient obfuscation and are vulnerable to adaptive attacks. We introduce ADAPT, a novel framework for performing adaptive adversarial training in the prompt tuning paradigm. Our method achieves competitive robust accuracy of ∼ 40% w.r.t. SOTA robustness methods using full-model fine-tuning, by tuning only ∼ 1% of the number of parameters},
  archive      = {J_TMLR},
  author       = {Masih Eskandar and Tooba Imtiaz and Zifeng Wang and Jennifer Dy},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ADAPT to robustify prompt tuning vision transformers},
  url          = {https://openreview.net/forum?id=bZzXgheUSD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards cross-tokenizer distillation: The universal logit distillation loss for LLMs. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=bwRxXiGO9A'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying large language models (LLMs) with billions of parameters is often impractical in industrial settings due to constraints like cost, latency, and hardware limitations. Knowledge distillation (KD) provides a solution by compressing the knowledge from large, resource-intensive models into task-specific smaller ones. Various strategies exist, some relying on the text generated by the teacher model, optionally, leveraging its output logits to improve learning. However, these logit-based methods usually require the teacher and student models to share the same tokenizer, which limits their applicability across different model families. In this paper, we propose the Universal Logit Distillation (ULD) loss, which uses optimal transport theory to enable distillation across different architectures and tokenizers. Our results demonstrate that ULD loss effectively facilitates the distillation process, paving the way for a more widespread use of distillation.},
  archive      = {J_TMLR},
  author       = {Nicolas Boizard and Kevin El Haddad and CELINE HUDELOT and Pierre Colombo},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards cross-tokenizer distillation: The universal logit distillation loss for LLMs},
  url          = {https://openreview.net/forum?id=bwRxXiGO9A},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning in $\ell_1$ regularized regression: Hyperparameter selection strategy based on sharp asymptotic analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=ccu0M3nmlF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning techniques aim to leverage information from multiple related datasets to enhance prediction quality against a target dataset. Such methods have been adopted in the context of high-dimensional sparse regression, and some Lasso-based algorithms have been invented: Trans-Lasso and Pretraining Lasso are such examples. These algorithms require the statistician to select hyperparameters that control the extent and type of information transfer from related datasets. However, selection strategies for these hyperparameters, as well as the impact of these choices on the algorithm's performance, have been largely unexplored. To address this, we conduct a thorough, precise study of the algorithm in a high-dimensional setting via an asymptotic analysis using the replica method. Our approach reveals a surprisingly simple behavior of the algorithm: Ignoring one of the two types of information transferred to the fine-tuning stage has little effect on generalization performance, implying that efforts for hyperparameter selection can be significantly reduced. Our theoretical findings are also empirically supported by \rev{applications on real-world and semi-artificial datasets using the IMDb and MNIST datasets, respectively.}},
  archive      = {J_TMLR},
  author       = {Koki Okajima and Tomoyuki Obuchi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Transfer learning in $\ell_1$ regularized regression: Hyperparameter selection strategy based on sharp asymptotic analysis},
  url          = {https://openreview.net/forum?id=ccu0M3nmlF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness through matching. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dHljjaNHh1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group fairness requires that different protected groups, characterized by a given sensitive attribute, receive equal outcomes overall. Typically, the level of group fairness is measured by the statistical gap between predictions from different protected groups. In this study, we reveal an implicit property of existing group fairness measures, which provides an insight into how the group-fair models behave. Then, we develop a new group-fair constraint based on this implicit property to learn group-fair models. To do so, we first introduce a notable theoretical observation: every group-fair model has an implicitly corresponding transport map between the input spaces of each protected group. Based on this observation, we introduce a new group fairness measure termed Matched Demographic Parity (MDP), which quantifies the averaged gap between predictions of two individuals (from different protected groups) matched by a given transport map. Then, we prove that any transport map can be used in MDP to learn group-fair models, and develop a novel algorithm called Fairness Through Matching (FTM), which learns a group-fair model using MDP constraint with an user-specified transport map. We specifically propose two favorable types of transport maps for MDP, based on the optimal transport theory, and discuss their advantages. Experiments reveal that FTM successfully trains group-fair models with certain desirable properties by choosing the transport map accordingly.},
  archive      = {J_TMLR},
  author       = {Kunwoong Kim and Insung Kong and Jongjin Lee and Minwoo Chae and Sangchul Park and Yongdai Kim},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fairness through matching},
  url          = {https://openreview.net/forum?id=dHljjaNHh1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein modality alignment makes your multimodal transformer more robust. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dbaGuiYsTl'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion with a multimodal transformer is an effective method for both early and late fusion paradigms. However, in a multimodal transformer, the modality fusion is performed solely through the self-attention mechanism, which is originally designed for unimodal token sequences. To improve the self-attention mechanism for handling multimodal input, a parametric adapter model, like the Q-former in BLIP-2, is often used to align tokens from different modalities. Our empirical study unveils that only using the self-attention layer to perform the modality fusion makes the model less robust to missing modalities and input noise, as the model will overly rely on one certain modality. To improve the robustness of the transformer, our paper proposes an implicit approach based on Wasserstein distance that aligns tokens from different modalities without using any additional trainable parameters. Our empirical study shows that the implicit modality alignment improves the effectiveness of the multimodal Transformer in discriminative tasks, as well as its robustness to input noise and missing modalities. We conduct experiments on four downstream task datasets, including 2-modalities and 3-modalities tasks. We also consider different fusion paradigms, i.e., early and late fusion. The experimental results show that our proposed method has a significant improvement in both performance and robustness over all baselines across all datasets and fusion paradigms.},
  archive      = {J_TMLR},
  author       = {zhuo zhi and Yuxuan Sun and Qiangqiang Wu and Ziquan Liu and Miguel R. D. Rodrigues},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wasserstein modality alignment makes your multimodal transformer more robust},
  url          = {https://openreview.net/forum?id=dbaGuiYsTl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic variance-reduced newton: Accelerating finite-sum minimization with large batches. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=dzQCRHKRdC'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic variance reduction has proven effective at accelerating first-order algorithms for solving convex finite-sum optimization tasks such as empirical risk minimization. Incorporating second-order information has proven helpful in further improving the performance of these first-order methods. Yet, comparatively little is known about the benefits of using variance reduction to accelerate popular stochastic second-order methods such as Subsampled Newton. To address this, we propose Stochastic Variance-Reduced Newton (SVRN), a finite-sum minimization algorithm that provably accelerates existing stochastic Newton methods from $O(\alpha\log(1/\epsilon))$ to $O\big(\frac{\log(1/\epsilon)}{\log(n)}\big)$ passes over the data, i.e., by a factor of $O(\alpha\log(n))$, where $n$ is the number of sum components and $\alpha$ is the approximation factor in the Hessian estimate. Surprisingly, this acceleration gets more significant the larger the data size $n$, which is a unique property of SVRN. Our algorithm retains the key advantages of Newton-type methods, such as easily parallelizable large-batch operations and a simple unit step size. We use SVRN to accelerate Subsampled Newton and Iterative Hessian Sketch algorithms, and show that it compares favorably to popular first-order methods with variance~reduction.},
  archive      = {J_TMLR},
  author       = {Michal Derezinski},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stochastic variance-reduced newton: Accelerating finite-sum minimization with large batches},
  url          = {https://openreview.net/forum?id=dzQCRHKRdC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning with non-ergodic reward increments: Robustness via ergodicity transformations. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=eakh1Edffd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Envisioned application areas for reinforcement learning (RL) include autonomous driving, precision agriculture, and finance, which all require RL agents to make decisions in the real world. A significant challenge hindering the adoption of RL methods in these domains is the non-robustness of conventional algorithms. In particular, the focus of RL is typically on the expected value of the return. The expected value is the average over the statistical ensemble of infinitely many trajectories, which can be uninformative about the performance of the average individual. For instance, when we have a heavy-tailed return distribution, the ensemble average can be dominated by rare extreme events. Consequently, optimizing the expected value can lead to policies that yield exceptionally high returns with a probability that approaches zero but almost surely result in catastrophic outcomes in single long trajectories. In this paper, we develop an algorithm that lets RL agents optimize the long-term performance of individual trajectories. The algorithm enables the agents to learn robust policies, which we show in an instructive example with a heavy-tailed return distribution and standard RL benchmarks. The key element of the algorithm is a transformation that we learn from data. This transformation turns the time series of collected returns into one for whose increments expected value and the average over a long trajectory coincide. Optimizing these increments results in robust policies.},
  archive      = {J_TMLR},
  author       = {Dominik Baumann and Erfaun Noorani and James Price and Ole Peters and Colm Connaughton and Thomas B. Schön},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reinforcement learning with non-ergodic reward increments: Robustness via ergodicity transformations},
  url          = {https://openreview.net/forum?id=eakh1Edffd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual fairness on graphs: Augmentations, hidden confounders, and identifiability. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hJHf7PCuVt'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider augmenting graph data with counterfactual generation in order to achieve fairness on downstream tasks. While this direction has been explored previously, existing methods invariably consider oversimplified causal relationships. Moreover, they often rely on unidentifiable models to encode causal relationships, making it hard to identify the true joint distribution and thus recover counterfactual graphs. To tackle these challenges, we introduce a causal model with hidden confounders on graphs, which considers the existence of hidden confounders affecting both node features and graph structures. We use an identifiable graph VAE model to simultaneously estimate hidden confounders and learn generation functions of the causal model. By incorporating a Gaussian mixture prior distribution, we improve the identifiability of our model to recover the joint distribution of observed data and hidden confounders. Using the generated counterfactual graphs, we enforce consistency in the predictions of classifiers for different counterfactual graphs, thereby achieving graph counterfactual fairness in these classifiers. Experimental results demonstrate the effectiveness of our method in improving the counterfactual fairness of classifiers on various graph tasks. Moreover, theoretical analysis, coupled with empirical results, illustrates the capability of our method to successfully identify hidden confounders.},
  archive      = {J_TMLR},
  author       = {Hongyi Ling and Zhimeng Jiang and Na Zou and Shuiwang Ji},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Counterfactual fairness on graphs: Augmentations, hidden confounders, and identifiability},
  url          = {https://openreview.net/forum?id=hJHf7PCuVt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Making reliable and flexible decisions in long-tailed classification. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=hMO8sT9qaD'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed classification is challenging due to its heavy imbalance in class probabilities. While existing methods often focus on overall accuracy or accuracy for tail classes, they overlook a critical aspect: certain types of errors can carry greater risks than others in real-world long-tailed problems. For example, misclassifying patients (a tail class) as healthy individuals (a head class) entails far more serious consequences than the reverse scenario. To address this critical issue, we introduce Making Reliable and Flexible Decisions in Long-tailed Classification (RF-DLC), a novel framework aimed at reliable predictions in long-tailed problems. Leveraging Bayesian Decision Theory, we introduce an integrated gain to seamlessly combine long-tailed data distributions and the decision-making procedure. We further propose an efficient variational optimization strategy for the decision risk objective. Our method adapts readily to diverse utility matrices, which can be designed for specific tasks, ensuring its flexibility for different problem settings. In empirical evaluation, we design a new metric, False Head Rate, to quantify tail-sensitivity risk, along with comprehensive experiments on multiple real-world tasks, including large-scale image classification and uncertainty quantification, to demonstrate the reliability and flexibility of our method.},
  archive      = {J_TMLR},
  author       = {Bolian Li and Ruqi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Making reliable and flexible decisions in long-tailed classification},
  url          = {https://openreview.net/forum?id=hMO8sT9qaD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A general framework of riemannian adaptive optimization methods with a convergence analysis. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=knv4lQFVoE'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general framework of Riemannian adaptive optimization methods. The framework encapsulates several stochastic optimization algorithms on Riemannian manifolds and incorporates the mini-batch strategy that is often used in deep learning. Within this framework, we also propose AMSGrad on embedded submanifolds of Euclidean space. Moreover, we give convergence analyses valid for both a constant and a diminishing step size. Our analyses also reveal the relationship between the convergence rate and mini-batch size. In numerical experiments, we applied the proposed algorithm to principal component analysis and the low-rank matrix completion problem, which can be considered to be Riemannian optimization problems. Python implementations of the methods used in the numerical experiments are available at https://github.com/iiduka-researches/202408-adaptive.},
  archive      = {J_TMLR},
  author       = {Hiroyuki Sakai and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A general framework of riemannian adaptive optimization methods with a convergence analysis},
  url          = {https://openreview.net/forum?id=knv4lQFVoE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable approach for mapper via efficient spatial search. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=lTX4bYREAZ'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological Data Analysis (TDA) is a branch of applied mathematics that studies the shape of high dimensional datasets using ideas from algebraic topology. The Mapper algorithm is a widely used tool in Topological Data Analysis, used for uncovering hidden structures in complex data. However, existing implementations often rely on naive and inefficient methods for constructing the open covers that Mapper is based on, leading to performance issues, especially with large, high-dimensional datasets. In this study, we introduce a novel, more scalable method for constructing open covers for Mapper, leveraging techniques from computational geometry. Our approach significantly enhances efficiency, improving Mapper's performance for large high-dimensional data. We will present theoretical insights into our method and demonstrate its effectiveness through experimental evaluations on well-known datasets, showcasing substantial improvements in visualization quality and computational performance. We implemented our method in a new Python library called \emph{tda-mapper}, which is freely available at \url{https://github.com/lucasimi/tda-mapper-python}, providing a powerful tool for TDA practitioners and researchers.},
  archive      = {J_TMLR},
  author       = {Luca Simi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A scalable approach for mapper via efficient spatial search},
  url          = {https://openreview.net/forum?id=lTX4bYREAZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPFormer: Enhancing vision transformer with superpixel representation. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=nu1SjVgSuy'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces SPFormer, a novel Vision Transformer architecture enhanced by superpixel representation. Addressing the limitations of traditional Vision Transformers' fixed-size, non-adaptive patch partitioning, SPFormer divides the input image into irregular, semantically coherent regions (i.e., superpixels), effectively capturing intricate details. Notably, this is also applicable to intermediate features, and our whole model supports end-to-end training, empirically yielding superior performance across multiple benchmarks. For example, on the challenging ImageNet benchmark, SPFormer outperforms DeiT by 1.4% at the tiny-model size and by 1.1% at the small-model size. Moreover, a standout feature of SPFormer is its inherent explainability — the superpixel structure offers a window into the model's internal processes, providing valuable insights that enhance the model's interpretability and stronger robustness against challenging scenarios like image rotations and occlusions.},
  archive      = {J_TMLR},
  author       = {Jieru Mei and Liang-Chieh Chen and Alan Yuille and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SPFormer: Enhancing vision transformer with superpixel representation},
  url          = {https://openreview.net/forum?id=nu1SjVgSuy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation rates and VC-dimension bounds for (P)ReLU MLP mixture of experts. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=oeg2ncuSPz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture-of-Experts (MoEs) can scale up beyond traditional deep learning models by employing a routing strategy in which each input is processed by a single ``expert'' deep learning model. This strategy allows us to scale up the number of parameters defining the MoE while maintaining sparse activation, i.e., MoEs only load a small number of their total parameters into GPU VRAM for the forward pass depending on the input. In this paper, we provide an approximation and learning-theoretic analysis of mixtures of expert MLPs with (P)ReLU activation functions. We first prove that for every error level $\varepsilon>0$ and every Lipschitz function $f:[0,1]^n\to \mathbb{R}$, one can construct a MoMLP model (a Mixture-of-Experts comprising of (P)ReLU MLPs) which uniformly approximates $f$ to $\varepsilon$ accuracy over $[0,1]^n$, while only requiring networks of $\mathcal{O}(\varepsilon^{-1})$ parameters to be loaded in memory. Additionally, we show that MoMLPs can generalize since the entire MoMLP model has a (finite) VC dimension of $\tilde{O}(L\max\{nL,JW\})$, if there are $L$ experts and each expert has a depth and width of $J$ and $W$, respectively.},
  archive      = {J_TMLR},
  author       = {Anastasis Kratsios and Haitz Sáez de Ocáriz Borde and Takashi Furuya and Marc T. Law},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Approximation rates and VC-dimension bounds for (P)ReLU MLP mixture of experts},
  url          = {https://openreview.net/forum?id=oeg2ncuSPz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the training-inference gap in LLMs by leveraging self-generated tokens. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pWSrm3oP8b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models are often trained to maximize the likelihood of the next token given past tokens in the training dataset. However, during inference time, they are utilized differently, generating text sequentially and auto-regressively by using previously \emph{generated} tokens as input to predict the next one. Marginal differences in predictions at each step can cascade over successive steps, resulting in different distributions from what the models were trained for and potentially leading to unpredictable behavior. This paper proposes two simple approaches based on model own generation to address this discrepancy between the training and inference time. Our first approach is Batch-Scheduled Sampling, where, during training, we stochastically choose between the ground-truth token from the dataset and the model's own generated token as input to predict the next token. This is done in an offline manner, modifying the context window by interleaving ground-truth tokens with those generated by the model. Our second approach is Reference-Answer-based Correction, where we explicitly incorporate a self-correction capability into the model during training. This enables the model to effectively self-correct the gaps between the generated sequences and the ground truth data without relying on an external oracle model. By incorporating our proposed strategies during training, we have observed an overall improvement in performance compared to baseline methods, as demonstrated by our extensive experiments using summarization, general question-answering, and math question-answering tasks.},
  archive      = {J_TMLR},
  author       = {Zhepeng Cen and Yao Liu and Siliang Zeng and Pratik Chaudhari and Huzefa Rangwala and George Karypis and Rasool Fakoor},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging the training-inference gap in LLMs by leveraging self-generated tokens},
  url          = {https://openreview.net/forum?id=pWSrm3oP8b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reviving life on the edge: Joint score-based graph generation of rich edge attributes. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=pxdSm7PW5Q'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation is integral to various engineering and scientific disciplines. Nevertheless, existing methodologies tend to overlook the generation of edge attributes. However, we identify critical applications where edge attributes are essential, making prior methods potentially unsuitable in such contexts. Moreover, while trivial adaptations are available, empirical investigations reveal their limited efficacy as they do not properly model the interplay among graph components. To address this, we propose a joint score-based model of nodes and edges for graph generation that considers all graph components. Our approach offers three key novelties: (1) node and edge attributes are combined in an attention module that generates samples based on the two ingredients, (2) node, edge and adjacency information are mutually dependent during the graph diffusion process, and (3) the framework enables the generation of graphs with rich attributes along the edges, providing a more expressive formulation for generative tasks than existing works. We evaluate our method on challenging benchmarks involving real-world and synthetic datasets in which edge features are crucial. Additionally, we introduce a new synthetic dataset that incorporates edge values. Furthermore, we propose a novel application that greatly benefits from the method due to its nature: the generation of traffic scenes represented as graphs. Our method outperforms other graph generation methods, demonstrating a significant advantage in edge-related measures.},
  archive      = {J_TMLR},
  author       = {Nimrod Berman and Eitan Kosman and Dotan Di Castro and Omri Azencot},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reviving life on the edge: Joint score-based graph generation of rich edge attributes},
  url          = {https://openreview.net/forum?id=pxdSm7PW5Q},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating posterior probabilities: Decision theory, proper scoring rules, and calibration. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=qbrE0LR7fF'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning classifiers are designed to output posterior probabilities for the classes given the input sample. These probabilities may be used to make the categorical decision on the class of the sample; provided as input to a downstream system; or provided to a human for interpretation. Evaluating the quality of the posteriors generated by these system is an essential problem which was addressed decades ago with the invention of proper scoring rules (PSRs). Unfortunately, much of the recent machine learning literature uses calibration metrics---most commonly, the expected calibration error (ECE)---as a proxy to assess posterior performance. The problem with this approach is that calibration metrics reflect only one aspect of the quality of the posteriors, ignoring the discrimination performance. For this reason, we argue that calibration metrics should play no role in the assessment of posterior quality. Expected PSRs should instead be used for this job, preferably normalized for ease of interpretation. In this work, we first give a brief review of PSRs from a practical perspective, motivating their definition using Bayes decision theory. We discuss why expected PSRs provide a principled measure of the quality of a system's posteriors and why calibration metrics are not the right tool for this job. We argue that calibration metrics, while not useful for performance assessment, may be used as diagnostic tools during system development. With this purpose in mind, we discuss a simple and practical calibration metric, called calibration loss, derived from a decomposition of expected PSRs. We compare this metric with the ECE and with the expected score divergence calibration metric from the PSR literature and argue, using theoretical and empirical evidence, that calibration loss is superior to these two metrics.},
  archive      = {J_TMLR},
  author       = {Luciana Ferrer and Daniel Ramos},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating posterior probabilities: Decision theory, proper scoring rules, and calibration},
  url          = {https://openreview.net/forum?id=qbrE0LR7fF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicitly disentangled representations in object-centric learning. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=r8UFp9olQ0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting structured representations from raw visual data is an important and long-standing challenge in machine learning. Recently, techniques for unsupervised learning of object-centric representations have raised growing interest. In this context, enhancing the robustness of the latent features can improve the efficiency and effectiveness of the training of downstream tasks. A promising step in this direction is to disentangle the factors that cause variation in the data. Previously, Invariant Slot Attention disentangled position, scale, and orientation from the remaining features. Extending this approach, we focus on separating the shape and texture components. In particular, we propose a novel architecture that biases object-centric models toward disentangling shape and texture components into two non-overlapping subsets of the latent space dimensions. These subsets are known a priori, hence before the training process. Experiments on a range of object-centric benchmarks reveal that our approach achieves the desired disentanglement while also numerically improving baseline performance in most cases. In addition, we show that our method can generate novel textures for a specific object or transfer textures between objects with distinct shapes.},
  archive      = {J_TMLR},
  author       = {Riccardo Majellaro and Jonathan Collu and Aske Plaat and Thomas M. Moerland},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explicitly disentangled representations in object-centric learning},
  url          = {https://openreview.net/forum?id=r8UFp9olQ0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalization bound for nearly-linear networks. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=tRpWaK3pWh'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonlinear networks as perturbations of linear ones. Based on this approach, we present a novel generalization bound that become non-vacuous for networks that are close to being linear. The main advantage over the previous works which propose non-vacuous generalization bounds is that our bound is *a priori*: performing the actual training is not required for evaluating the bound. To the best of our knowledge, it is the first non-vacuous generalization bound for neural nets possessing this property.},
  archive      = {J_TMLR},
  author       = {Eugene Golikov},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A generalization bound for nearly-linear networks},
  url          = {https://openreview.net/forum?id=tRpWaK3pWh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-distribution adversarial attacks on object recognition models using gradient-free search.. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=uF9ZdAwrCT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are susceptible to small perturbations in the form of 2D rotations and shifts, image crops, and even changes in object colors. Past works attribute these errors to dataset bias, claiming that models fail on these perturbed samples as they do not belong to the training data distribution. Here, we challenge this claim and present evidence of the widespread existence of perturbed images within the training data distribution, which networks fail to classify. We train models on data sampled from parametric distributions, then search inside this data distribution to find such in-distribution adversarial examples. This is done using our gradient-free evolution strategies (ES) based approach which we call CMA-Search. Despite training with a large-scale (0.5 million images), unbiased dataset of camera and light variations, CMA-Search can find a failure inside the data distribution in over 71% cases by perturbing the camera position. With lighting changes, CMA-Search finds misclassifications in 42% cases. These findings also extend to natural images from ImageNet and Co3D datasets. This phenomenon of in-distribution images presents a highly worrisome problem for artificial intelligence---they bypass the need for a malicious agent to add engineered noise to induce an adversarial attack. All code, datasets, and demos are available at https://github.com/Spandan-Madan/in_distribution_adversarial_examples.},
  archive      = {J_TMLR},
  author       = {Spandan Madan and Tomotake Sasaki and Hanspeter Pfister and Tzu-Mao Li and Xavier Boix},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {In-distribution adversarial attacks on object recognition models using gradient-free search.},
  url          = {https://openreview.net/forum?id=uF9ZdAwrCT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost-efficient online decision making: A combinatorial multi-armed bandit approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vZGZIIgcG4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online decision making plays a crucial role in numerous real-world applications. In many scenarios, the decision is made based on performing a sequence of tests on the incoming data points. However, performing all tests can be expensive and is not always possible. In this paper, we provide a novel formulation of the online decision making problem based on combinatorial multi-armed bandits and take the (possibly stochastic) cost of performing tests into account. Based on this formulation, we provide a new framework for cost-efficient online decision making which can utilize posterior sampling or BayesUCB for exploration. We provide a theoretical analysis of Thompson Sampling for cost-efficient online decision making, and present various experimental results that demonstrate the applicability of our framework to real-world problems.},
  archive      = {J_TMLR},
  author       = {Arman Rahbar and Niklas Åkerblom and Morteza Haghir Chehreghani},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cost-efficient online decision making: A combinatorial multi-armed bandit approach},
  url          = {https://openreview.net/forum?id=vZGZIIgcG4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging a simulator for learning causal representations from post-treatment covariates for CATE. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=vmmgFW3ztz'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment effect estimation involves assessing the impact of different treatments on individual outcomes. Current methods estimate Conditional Average Treatment Effect (CATE) using observational datasets where covariates are collected before treatment assignment and outcomes are observed afterward, under assumptions like positivity and unconfoundedness. In this paper, we address a scenario where both covariates and outcomes are gathered after treatment. We show that post-treatment covariates render CATE unidentifiable, and recovering CATE requires learning treatment-independent causal representations. Prior work shows that such representations can be learned through contrastive learning if counterfactual supervision is available in observational data. However, since counterfactuals are rare, other works have explored using simulators that offer synthetic counterfactual supervision. Our goal in this paper is to systematically analyze the role of simulators in estimating CATE. We analyze the CATE error of several baselines and highlight their limitations. We then establish a generalization bound that characterizes the CATE error from jointly training on real and simulated distributions, as a function of the real-simulator mismatch. Finally, we introduce SimPONet, a novel method whose loss function is inspired from our generalization bound. We further show how SimPONet adjusts the simulator’s influence on the learning objective based on the simulator’s relevance to the CATE task. We experiment with various DGPs, by systematically varying the real-simulator distribution gap to evaluate SimPONet’s efficacy against state-of-the-art CATE baselines.},
  archive      = {J_TMLR},
  author       = {Lokesh Nagalapatti and Pranava Singhal and Avishek Ghosh and Sunita Sarawagi},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Leveraging a simulator for learning causal representations from post-treatment covariates for CATE},
  url          = {https://openreview.net/forum?id=vmmgFW3ztz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate dense retrieval: A reproducibility study under a memory-limited setup. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wF3ZtSlOcT'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paradigm in dense retrieval is to represent queries and passages as low-dimensional real-valued vectors using neural language models, and then compute query-passage similarity as the dot product of these vector representations. A limitation of this approach is that these learned representations cannot capture or express uncertainty. At the same time, information retrieval over large corpora contains several sources of uncertainty, such as misspelled or ambiguous text. Consequently, retrieval methods that incorporate uncertainty estimation are more likely to generalize well to such data distribution shifts. The multivariate representation learning (MRL) framework proposed by Zamani & Bendersky (2023) is the first method that works in the direction of modeling uncertainty in dense retrieval. This framework represents queries and passages as multivariate normal distributions and computes query-passage similarity as the negative Kullback-Leibler (KL) divergence between these distributions. Furthermore, MRL formulates KL divergence as a dot product, allowing for efficient first-stage retrieval using standard maximum inner product search. In this paper, we attempt to reproduce MRL under memory constraints (e.g., an academic computational budget). In particular, we focus on a memory-limited, single GPU setup. We find that the original work (i) introduces a typographical/mathematical error early in the formulation of the method that propagates to the rest of the original paper’s mathematical formulations, and (ii) does not fully specify certain important design choices that can strongly influence performance. In light of the aforementioned, we address the mathematical error and make some reasonable design choices when important details are unspecified. Additionally, we expand on the results from the original paper with a thorough ablation study which provides more insight into the impact of the framework’s different components. While we confirm that MRL can have state-of-the-art performance, we could not reproduce the results reported in the original paper or uncover the reported trends against the baselines under a memory-limited setup that facilitates fair comparisons of MRL against its baselines. Our analysis offers insights as to why that is the case. Most importantly, our empirical results suggest that the variance definition in MRL does not consistently capture uncertainty. The source code for our reproducibility study is available at: https://github.com/samarthbhargav/multivariate_ir/.},
  archive      = {J_TMLR},
  author       = {Georgios Sidiropoulos and Samarth Bhargav and Panagiotis Eustratiadis and Evangelos Kanoulas},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multivariate dense retrieval: A reproducibility study under a memory-limited setup},
  url          = {https://openreview.net/forum?id=wF3ZtSlOcT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of recent backdoor attacks and defenses in large language models. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=wZLWuFHxt5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs), which bridge the gap between human language understanding and complex problem-solving, achieve state-of-the-art performance on several NLP tasks, particularly in few-shot and zero-shot settings. Despite the demonstrable efficacy of LLMs, due to constraints on computational resources, users have to engage with open-source language models or outsource the entire training process to third-party platforms. However, research has demonstrated that language models are susceptible to potential security vulnerabilities, particularly in backdoor attacks. Backdoor attacks are designed to introduce targeted vulnerabilities into language models by poisoning training samples or model weights, allowing attackers to manipulate model responses through malicious triggers. While existing surveys on backdoor attacks provide a comprehensive overview, they lack an in-depth examination of backdoor attacks specifically targeting LLMs. To bridge this gap and grasp the latest trends in the field, this paper presents a novel perspective on backdoor attacks for LLMs by focusing on fine-tuning methods. Specifically, we systematically classify backdoor attacks into three categories: full-parameter fine-tuning, parameter-efficient fine-tuning, and no fine-tuning. Based on insights from a substantial review, we also discuss crucial issues for future research on backdoor attacks, such as further exploring attack algorithms that do not require fine-tuning, or developing more covert attack algorithms.},
  archive      = {J_TMLR},
  author       = {Shuai Zhao and Meihuizi Jia and Zhongliang Guo and Leilei Gan and XIAOYU XU and Xiaobao Wu and Jie Fu and Feng Yichao and Fengjun Pan and Anh Tuan Luu},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A survey of recent backdoor attacks and defenses in large language models},
  url          = {https://openreview.net/forum?id=wZLWuFHxt5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison between humans and AI at recognizing objects in unusual poses. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=yzbAFf8vd5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is closing the gap with human vision on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen in unusual poses. We find that humans excel at recognizing objects in such poses. In contrast, state-of-the-art deep networks for vision (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) and state-of-the-art large vision-language models (Claude 3.5, Gemini 1.5, GPT-4) are systematically brittle on unusual poses, with the exception of Gemini showing excellent robustness to that condition. As we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) are necessary to identify objects in unusual poses. An analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. In conclusion, our comparison reveals that humans are overall more robust than deep networks and that they rely on different mechanisms for recognizing objects in unusual poses. Understanding the nature of the mental processes taking place during extra viewing time may be key to reproduce the robustness of human vision in silico. All code and data is available.},
  archive      = {J_TMLR},
  author       = {Netta Ollikka and Amro Kamal Mohamed Abbas and Andrea Perin and Markku Kilpeläinen and Stephane Deny},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A comparison between humans and AI at recognizing objects in unusual poses},
  url          = {https://openreview.net/forum?id=yzbAFf8vd5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing parameter efficiency and generalization in large models: A regularized and masked low-rank adaptation approach. <em>TMLR</em>. (<a href='https://openreview.net/forum?id=zg0hPlABfY'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large pre-trained models, such as large language models (LLMs), present significant resource challenges for fine-tuning due to their extensive parameter sizes, especially for applications in mobile systems. To address this, Low-Rank Adaptation (LoRA) has been developed to reduce resource consumption while maintaining satisfactory fine-tuning results. Despite its effectiveness, the original LoRA method faces the challenge of suboptimal performance. This paper investigates the intrinsic dimension of the matrix updates approximated by the LoRA method and reveals the performance benefits of increasing this intrinsic dimension. By employing regularization and a gradient masking method that encourages higher intrinsic dimension, the proposed method, termed Regularized and Masked LoRA (RM-LoRA), achieves superior generalization performance with the same or lower trainable parameter budget compared to the original LoRA and its latest variants across various open-source vision and language datasets.},
  archive      = {J_TMLR},
  author       = {Yuzhu Mao and Zihao Zhao and Siqi Ping and Yang Liu and Wenbo Ding},
  journal      = {Transactions on Machine Learning Research},
  month        = {1},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing parameter efficiency and generalization in large models: A regularized and masked low-rank adaptation approach},
  url          = {https://openreview.net/forum?id=zg0hPlABfY},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
