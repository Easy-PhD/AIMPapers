<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMIS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmis">TMIS - 27</h2>
<ul>
<li><details>
<summary>
(2025). Knowledge management in a world of generative AI: Impact and implications. <em>TMIS</em>, <em>16</em>(3), 1-14. (<a href='https://doi.org/10.1145/3719209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The management of organizational and worker knowledge is a critical part of any organization. Knowledge management recognizes the explicit knowledge that workers contribute to an organization, as well as the organizational knowledge and skills acquired over time. The potential impact of generative AI (GenAI) raises many issues and opportunities related to effective knowledge management as organizations explore the impact and implications of its adoption. This research explores issues related to an increasing world of GenAI and proposes a Framework for Knowledge Management in the GenAI Era . Knowledge management workers, who are novices, might be more inclined to use generative AI for performing their tasks. Expert knowledge workers might focus on quality evaluation and quality assessment. Adoption of GenAI may help with the progression from novice to expert, while freeing up time and resources for other work. Challenges include the potential loss of critical organizational knowledge, definition of job-related requirements, expectations, and tasks, as well as over-reliance and loss of tacit or unarticulated knowledge. These challenges must be balanced against available access to large amounts of general and domain-specific knowledge from GenAI to capture the value realized from its adoption.},
  archive      = {J_TMIS},
  author       = {Veda Catherine Storey},
  doi          = {10.1145/3719209},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {9},
  number       = {3},
  pages        = {1-14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Knowledge management in a world of generative AI: Impact and implications},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing visually-aware recommender systems: An adversarial image reconstruction and detection framework. <em>TMIS</em>, <em>16</em>(3), 1-29. (<a href='https://doi.org/10.1145/3743681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With rich visual data, such as images, becoming readily associated with items, visually-aware recommendation systems (VARS) have been widely used in different applications. Recent studies have shown that VARS are vulnerable to item-image adversarial attacks, which add human-imperceptible perturbations to the clean images associated with those items. Attacks on VARS pose new security challenges to a wide range of applications, such as e-commerce and social media, where VARS are widely used. How to secure VARS from such adversarial attacks becomes a critical problem. Currently, there is still a lack of systematic studies on how to design defense strategies against visual attacks on VARS. In this article, we attempt to fill this gap by proposing an adversarial image denoising and detection framework to secure VARS. Our proposed method can simultaneously (1) secure VARS from adversarial attacks characterized by local perturbations by image denoising based on global vision transformers; and (2) accurately detect adversarial examples using a novel contrastive learning approach. Meanwhile, our framework is designed to be used as both a filter and a detector so that they can be jointly trained to improve the flexibility of our defense strategy to a variety of attacks and VARS models. Our approach is uniquely tailored for VARS, addressing the distinct challenges in scenarios where adversarial attacks can differ across industries, for instance, causing misclassification in e-commerce or misrepresentation in real estate. We have conducted extensive experimental studies with two popular attack methods (FGSM and PGD). Our experimental results on two real-world datasets show that our defense strategy against visual attacks is effective and outperforms existing methods on different attacks. Moreover, our method demonstrates high accuracy in detecting adversarial examples, complementing its robustness across various types of adversarial attacks.},
  archive      = {J_TMIS},
  author       = {Minglei Yin and Bin Liu and Neil Zhenqiang Gong and Xin Li},
  doi          = {10.1145/3743681},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {9},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Securing visually-aware recommender systems: An adversarial image reconstruction and detection framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From stars to insights: Exploration and implementation of unified sentiment analysis with distant supervision. <em>TMIS</em>, <em>16</em>(3), 1-21. (<a href='https://doi.org/10.1145/3757747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is integral to understanding the voice of the customer and informing businesses’ strategic decisions. Conventional sentiment analysis involves three separate tasks: aspect-category detection, aspect-category sentiment analysis, and rating prediction. However, independently tackling these tasks can overlook their interdependencies and often requires expensive, fine-grained annotations. This article introduces unified sentiment analysis, a novel learning paradigm that integrates the three aforementioned tasks into a coherent framework. To achieve this, we propose the Distantly Supervised Pyramid Network (DSPN), which employs a pyramid structure to capture sentiment at word, aspect, and document levels in a hierarchical manner. Evaluations on multi-aspect review datasets in English and Chinese show that DSPN, using only star rating labels for supervision, demonstrates significant efficiency advantages while performing comparably well to a variety of benchmark models. Additionally, DSPN’s pyramid structure enables the interpretability of its outputs. Our findings validate DSPN’s effectiveness and efficiency, establishing a robust, resource-efficient, unified framework for sentiment analysis.},
  archive      = {J_TMIS},
  author       = {Wenchang Li and John P. Lalor and Yixing Chen and Vamsi K. Kanuri},
  doi          = {10.1145/3757747},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {From stars to insights: Exploration and implementation of unified sentiment analysis with distant supervision},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross project defect prediction using dropout regularized deep learning and unique matched metrics. <em>TMIS</em>, <em>16</em>(3), 1-32. (<a href='https://doi.org/10.1145/3698109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of software defect prediction (SDP) is to predict the software defects for a specific software using historical data or data from past releases of software projects. The existing state of arts on SDP primarily discusses two prediction scenarios: Within-project Defect Prediction (WPDP) and Cross-project Defect Prediction (CPDP). The prediction model belongs to the WPDP scenario, which means that the model is trained and tested on different parts of the same dataset or trained on the dataset belonging to the previous version of the same project. While in the CPDP scenario, training and testing occur on different software project datasets. Due to the unavailability of historical datasets or prior releases of software defect datasets, CPDP is more useful in real-life scenarios. So, CPDP analysis is a very challenging issue in the SDP domain. Sometimes, machine learning (ML) models perform poorly due to inadequate training in the CPDP scenario. To support better CPDP performance, we must carefully build an ML model focusing on lower training error and overfitting issues. To address these issues, we have proposed a cross-project data preprocessing method to correlate the metrics of different project datasets, namely, Unique Selection of Matched Metrics (USMM), using the KS test and Hungarian method. To further improve the CPDP performance, we have also used the dropout regularized deep learning (DRDL) model. We have deployed 34 software defect datasets to validate the DRDL model and USMM method. The experimental results demonstrate that the DRDL model using the USMM method (DRDL-USMM) is a promising model to enhance the prediction accuracy, and an improvement in the range of 3.3% to 8.5% as compared to the existing works in the CPDP scenario has been found.},
  archive      = {J_TMIS},
  author       = {Pravas Ranjan Bal and Sandeep Kumar},
  doi          = {10.1145/3698109},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-32},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Cross project defect prediction using dropout regularized deep learning and unique matched metrics},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IT service disruptions and provider choice. <em>TMIS</em>, <em>16</em>(3), 1-37. (<a href='https://doi.org/10.1145/3701040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital supply chains are increasingly interconnected and vulnerable to disruption, causing service interruptions impacting many firms and their customers. Combating threats to the digital supply chain is the top challenge for leaders in most supply chain industries, demonstrated by the tacit approval of nation-states for cyber-attacks on corporate supply chains to disrupt downstream firms. Disruptions to digital supply chains are not new. In April 2019, hundreds of flights in the United States were delayed when a critical service provider, AeroData, had a computer systems failure. AeroData delivers flight planning services to many airlines, including Southwest, United, American, and Delta. All flight operations for AeroData’s more than 100 clients simultaneously ceased, and thousands of customers were stranded at airports across the country. In an increasingly connected business environment, competitors may be simultaneously disrupted due to a common service provider, impacting all affected firms’ demand. The synchronization of disruptions for firms that use a common service provider has implications for service provider choice and investment. We use a two-stage game to model how a firm’s customer demand is impacted by disruptions at a service provider, and how this subsequently affects the firms’ choices in managing service provider risk. Considering downstream demand effects from upstream service disruptions, the contribution of this article is the examination of how risk synchronization impacts provider choice decisions and profits. In addition, we illustrate how these choices impact upstream industry concentration.},
  archive      = {J_TMIS},
  author       = {M. Lisa Yeo and Hooman Hidaji and Erik Rolland and Raymond A. Patterson and Barrie R. Nault and Bora Kolfal},
  doi          = {10.1145/3701040},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {IT service disruptions and provider choice},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conceptual service architecture to synchronise research data management services using machine-actionable data management plans. <em>TMIS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1145/3712014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers of all disciplines produce, share, and reuse data as part of everyday research. Most funders require them to manage and document their data using data management plans (DMPs). DMPs are often static documents that researchers create by answering questions in predefined templates at the beginning of the research and, therefore, may become outdated and obsolete as the project progresses. It is essential to keep the DMP up to date at all stages of the research lifecycle, since numerous stakeholders and various services participate in data management that depend on information from them. In this article, we propose a conceptual service architecture that uses machine-actionable data management plans to automate the exchange and synchronization of information between different semi-automated research data management services acting on behalf of different stakeholders. To solve the stated problem, we analyze typical use cases in which the DMPs change and formulate requirements based on which we developed the conceptual architecture. We depict the designed architecture through a set of views, namely physical, development, logical, and process, using Unified Modeling Language and Business Process Models and Notation representation that describe the processes required to synchronize DMP information among multiple services. We instantiate it by implementing a service that connects a data repository and a DMP tool. Thus, we evaluate to what extent the defined processes help in keeping DMP contents up to date and which criteria must be fulfilled to keep them highly automated. The result of the article feeds into a larger discussion on streamlining interconnectivity and machine-actionability across planning, tracking, and assessing research phases. It also facilitates consensus building on enhancing the Research Data Alliance’s recommendation for machine-actionable DMPs.},
  archive      = {J_TMIS},
  author       = {Filip Zoubek and Tomasz Miksa and Andreas Rauber},
  doi          = {10.1145/3712014},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Conceptual service architecture to synchronise research data management services using machine-actionable data management plans},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Examination process modeling for intelligent patent management: A multi-aspect neural sequential approach. <em>TMIS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1145/3712309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the booming growth of patent applications has brought an unprecedented challenge in performing efficient intellectual property management. Therefore, intelligent approaches are urgently needed to analyze intrinsic patterns of patents. However, a long-standing obstacle is the lack of effective methods for modeling the dynamic and diverse examination process of patent applications, which can benefit a wide range of downstream tasks for patent management. In fact, the major challenges lie in how to discover and integrate domain-specific properties from large-scale unlabeled examination data. To this end, in this article, we propose a Self-supervised Examination Process Modeling framework to learn the contextualized embedding for patents through modeling their examination processes. Specifically, we first design a multi-aspect event embedding layer, which leverages the fine-tuned language model, frequent-pattern embedding, and time encoding to capture the semantic, frequent-pattern and temporal information of examination events, respectively. Then, a mutual-information-aware integration layer is applied to fuse the extracted features into multi-aspect embedding considering their mutual interactions. Further, we develop a multi-objective sequential neural network for learning the contextualized patent representation, which is achieved through jointly learning two self-supervised objectives, namely, event code and event lag auto-regression. To explore the application potential of SEPM, we fine-tune the well-trained model for three important downstream tasks of patent management, including the prediction of next events, patent classification, and grant prediction. In the end, extensive experiments with real-world data from the US Patent and Trademark Office verify the effectiveness and application prospects of the proposed framework.},
  archive      = {J_TMIS},
  author       = {Han Wu and Le Zhang and Hengshu Zhu and Qi Liu and Enhong Chen and Hui Xiong},
  doi          = {10.1145/3712309},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Examination process modeling for intelligent patent management: A multi-aspect neural sequential approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unstructured data in process mining: A systematic literature review. <em>TMIS</em>, <em>16</em>(3), 1-34. (<a href='https://doi.org/10.1145/3727148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large proportion of available data is in unstructured form such as text, image, and video data. As data analysis methods continue to improve, it becomes easier to tap into and exploit unstructured data. Even in the process mining discipline, which is traditionally focused on structured data stored in process-aware information systems, solutions that integrate unstructured data receive increasing attention. To date, however, there is no empirical overview on how unstructured data is leveraged in process mining. This lack of insight also makes it difficult to identify the most promising avenues to advance process mining research. To address this issue, the study presents a systematic literature review, analyzing 24 primary studies selected from a total of 1,379 search results (i.e., research items) at the intersection of unstructured data and process mining. One of the main findings is that current research predominantly deals with textual data and concentrates on extracting event logs for process discovery. To guide future process mining research, the study proposes a research agenda that includes seven opportunities to address the identified research gaps.},
  archive      = {J_TMIS},
  author       = {Fabian König and Andreas Egger and Wolfgang Kratsch and Maximilian Röglinger and Niklas Wördehoff},
  doi          = {10.1145/3727148},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-34},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Unstructured data in process mining: A systematic literature review},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding digital risk from corporate disclosure: A neural network approach. <em>TMIS</em>, <em>16</em>(3), 1-44. (<a href='https://doi.org/10.1145/3728365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital risk —or the likelihood of losses from key digital activities (i.e., information system [IS] sourcing, digital infrastructure, data management, IS applications, IS use, and digital product offerings)—constitutes a key consideration in firm valuation. Firms’ public disclosures (e.g., 10-K reports, earnings conference calls) are a key source of data to learn about digital risks. Although text analytics approaches (e.g., word frequency, topic modeling, and sentiment analysis) have been applied to a firm's public disclosures to assess various types of risk (e.g., political risk, tax risk, cybersecurity), they do not consider the structural linguistic relations embedded in the text that are potentially relevant in measuring risk. We apply a neural network approach to address this gap and extract linguistic relations from a firm's 10-K disclosure (Section “Item 1A”). We develop novel firm-level digital risk measures based on these linguistic relations. Specifically, we measure firm-level digital risk from three perspectives: (1) presence (whether digital risk is mentioned or not), (2) intensity (text coverage of digital risk relative to other issues), and (3) diversity (the types of digital risk mentioned). We validate our digital risk measures by demonstrating their significant correlation with firm risk, proxied by stock market volatility. Our research reveals that investors’ perceptions of digital risk diversity and digital risk intensity differ between IT and non-IT companies. First, across all firms, digital risk intensity is negatively associated with firm risk, indicating that investors do not incorporate intensity of digital risk when assessing firm risk. Second, in non-IT firms, digital risk diversity is positively associated with firm risk, suggesting that managers in these firms may influence investor perceptions through strategic disclosure of digital risk types. Overall, our findings suggest that text-based digital risk measurement is practically feasible, scalable, and economically meaningful.},
  archive      = {J_TMIS},
  author       = {Yuan Long and Arun Rai},
  doi          = {10.1145/3728365},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {5},
  number       = {3},
  pages        = {1-44},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Decoding digital risk from corporate disclosure: A neural network approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot construction of chinese medical knowledge graph with GPT-3.5-turbo and GPT-4. <em>TMIS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1145/3657305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs have revolutionized the organization and retrieval of real-world knowledge, prompting interest in automatic natural language processing approaches for extracting medical knowledge from texts. However, the availability of high-quality Chinese medical knowledge remains limited, posing challenges for constructing Chinese medical knowledge graphs. As large language models like ChatGPT show promise in zero-shot learning for many natural language processing downstream tasks, their potential on constructing Chinese medical knowledge graphs remains uncertain. In this study, we create a Chinese medical knowledge graph by manually annotating textual data and using ChatGPT to automatically generate the graph. We refine the results using filtering and mapping rules to align with our schema. The manually generated graph serves as the ground truth for evaluation, and we explore different methods to enhance its accuracy through knowledge graph completion techniques. As a result, we emphasize the potential of employing ChatGPT for automated knowledge graph construction within the Chinese medical domain. While ChatGPT successfully identifies a larger number of entities, further enhancements are required to improve its performance in extracting more qualified relations.},
  archive      = {J_TMIS},
  author       = {Ling-I Wu and Yuxin Su and Guoqiang Li},
  doi          = {10.1145/3657305},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Zero-shot construction of chinese medical knowledge graph with GPT-3.5-turbo and GPT-4},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ShennongMGS: An LLM-based chinese medication guidance system. <em>TMIS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1145/3658451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly evolving field of Large Language Models (LLMs) holds immense promise for healthcare, particularly in medication guidance and adverse drug reaction prediction. Despite their potential, existing LLMs face challenges in dealing with complex polypharmacy scenarios and often grapple with data lag issues. To address these limitations, we introduce an LLM-based Chinese medication guidance system, called ShennongMGS, specifically tailored for robust medication guidance and adverse drug reaction predictions. Our system transforms multi-source heterogeneous medication information into a knowledge graph and employs a two-stage training strategy to construct a specialized LLM (ShennongGPT). This method enables the simulation of professional pharmacists’ decision-making processes and incorporates the capability for knowledge self-updating, thereby significantly enhancing drug safety and the overall quality of medical services. Rigorously evaluated by medical professionals and artificial intelligence experts, our method demonstrates superiority, outperforming existing general and specialized LLMs in performance.},
  archive      = {J_TMIS},
  author       = {Yutao Dou and Yuwei Huang and Xiongjun Zhao and Haitao Zou and Jiandong Shang and Ying Lu and Xiaolin Yang and Jian Xiao and Shaoliang Peng},
  doi          = {10.1145/3658451},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {ShennongMGS: An LLM-based chinese medication guidance system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language models for online depression detection: A review and benchmark analysis on remote interviews. <em>TMIS</em>, <em>16</em>(2), 1-35. (<a href='https://doi.org/10.1145/3673906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of machine learning (ML) to detect depression in online settings has emerged as an important health and wellness use case. In particular, the use of deep learning methods for depression detection from textual content posted on social media has garnered considerable attention. Conversely, there has been relatively limited evaluation of depression detection in clinical environments involving text generated from remote interviews. In this research, we review state-of-the-art feature-based ML, deep learning, and large language models for depression detection. We use a multidimensional analysis framework to benchmark various language models on a novel testbed comprising speech-to-text transcriptions of remote interviews. Our framework considers the impact of different transcription types and interview segments on depression detection performance. Finally, we summarize the key trends and takeaways from the review and benchmark evaluation and provide suggestions to guide the design of future detection methods.},
  archive      = {J_TMIS},
  author       = {Ruiyang Qin and Kai Yang and Ahmed Abbasi and David Dobolyi and Salman Seyedi and Emily Griner and Hyeokhyen Kwon and Robert Cotes and Zifan Jiang and Gari Clifford and Ryan A. Cook},
  doi          = {10.1145/3673906},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Language models for online depression detection: A review and benchmark analysis on remote interviews},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private low-rank adaptation of large language model using federated learning. <em>TMIS</em>, <em>16</em>(2), 1-24. (<a href='https://doi.org/10.1145/3682068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in interest and application of large language models (LLMs) has sparked a drive to fine-tune these models to suit specific applications, such as finance and medical science. However, concerns regarding data privacy have emerged, especially when multiple stakeholders aim to collaboratively enhance LLMs using sensitive data. In this scenario, federated learning becomes a natural choice, allowing decentralized fine-tuning without exposing raw data to central servers. Motivated by this, we investigate how data privacy can be ensured in LLM fine-tuning through practical federated learning approaches, enabling secure contributions from multiple parties to enhance LLMs. Yet, challenges arise: (1) despite avoiding raw data exposure, there is a risk of inferring sensitive information from model outputs, and (2) federated learning for LLMs incurs notable communication overhead. To address these challenges, this article introduces DP-LoRA, a novel federated learning algorithm tailored for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that adds noise in weight updates, maintaining individual data privacy while facilitating collaborative model training. Moreover, DP-LoRA optimizes communication efficiency via low-rank adaptation, minimizing the transmission of updated weights during distributed training. The experimental results across medical, financial, and general datasets using various LLMs demonstrate that DP-LoRA effectively ensures strict privacy constraints while minimizing communication overhead.},
  archive      = {J_TMIS},
  author       = {Xiao-Yang Liu and Rongyi Zhu and Daochen Zha and Jiechao Gao and Shan Zhong and Matt White and Meikang Qiu},
  doi          = {10.1145/3682068},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Differentially private low-rank adaptation of large language model using federated learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOSS-MED: A family of multimodal models serving medical image analysis. <em>TMIS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1145/3688005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable advancements in large language models (LLMs) and large-scale visual encoders have laid a solid foundation for enhancing the capabilities of artificial intelligence (AI) in various application scenarios. In this study, we introduce MOSS-MED, a suite of models designed for biomedical vision-language understandings. MOSS-MED includes two models currently: MOSS-MED-2.5B and MOSS-MED-LLaMA, with different scale of their underlying LLMs. We employ a two-stage training pipeline that involves visual-text alignment and visual-involved instruction fine-tuning from both general domains and the medical domain. We evaluate the performance of MOSS-MED family on medical visual question answering (VQA) benchmarks. The results and cases demonstrate the impressive proficiency in medical expertise that MOSS-MED embodies.},
  archive      = {J_TMIS},
  author       = {Junqi Dai and Qin Zhu and Jun Zhan and Bo Wang and Xipeng Qiu},
  doi          = {10.1145/3688005},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {MOSS-MED: A family of multimodal models serving medical image analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMs and their applications in medical artificial intelligence. <em>TMIS</em>, <em>16</em>(2), 1-7. (<a href='https://doi.org/10.1145/3711837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical artificial intelligence (AI) is a cross-disciplinary field focused on developing advanced computing and AI technologies to benefit medicine and healthcare. Globally, medical AI has tremendous potential to support the United Nations’ sustainable development goals pertaining to health and well-being. In particular, large language models (LLMs) afford opportunities for positively disrupting medical AI-related research and practice. We present a research framework for LLMs in medical AI. Our framework considers the interplay between health and well-being goals, disease lifecycle stages, and the important emerging role of LLMs in medical AI processes related to various lifecycle stages. As part of our framework, we describe the LLM multiplex—important multimodal, multi-model, multicultural, and multi-responsibility considerations for LLMs in medical AI. We discuss how the five articles in the special issue relate to this framework and are helping us learn about the opportunities and challenges for LLMs in medical AI.},
  archive      = {J_TMIS},
  author       = {Wenji Mao and Xipeng Qiu and Ahmed Abbasi},
  doi          = {10.1145/3711837},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-7},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {LLMs and their applications in medical artificial intelligence},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COTR: Efficient job task recognition for occupational information systems with class-incremental learning. <em>TMIS</em>, <em>16</em>(2), 1-30. (<a href='https://doi.org/10.1145/3712306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupation-specific job tasks (OSTs) refer to the duties, responsibilities, and activities associated with a particular occupation, which define the core functions and performance expectations for those engaged in that profession. Efficient recognition and extraction of OSTs from large-scale job description data are essential for establishing a continually updated occupational information system (OIS), such as O*NET, which serves as critical tools for advancing research in work and labor markets. However, this task presents substantial challenges due to its heavy reliance on domain experts for the labor-intensive annotation of job postings, rendering the process time-consuming and difficult to scale for large-scale implementation. To this end, in this article, we present COTR , a novel data-driven framework designed for the efficient recognition of OSTs from job postings, capable of continually identifying new tasks through class-incremental learning. Specifically, we first employ large language models (LLMs) and prompt learning to develop a three-phase process–“expansion, translation, and generation”–that addresses the critical challenge of the absence of predefined OSTs in non-English labor market data, leveraging O*NET as a foundational reference. Subsequently, we introduce a BERT-based model for OST recognition, incorporating a uniquely designed pair-wise loss function that distills valuable insights from ChatGPT or other LLMs, thereby substantially enhancing recognition performance. In addition, to achieve cost-effective training data annotation, we develop an LLM-based coarse-to-fine candidate OSTs generation algorithm, integrating contrastive active learning to optimize the annotation process through human-machine collaboration. Notably, we design a supervised fine-tuning strategy with a novel encoding technique to optimize LLMs, improving the recall rate of the generated candidate OSTs and achieving up to a 343-fold increase in annotation efficiency compared to traditional manual expert annotation in our experiments. Afterward, we propose an efficient class-incremental learning method that incorporates an out-of-distribution (OOD) detection module for identifying potential novel OSTs and a fine-tuning module to extend the model’s recognition capabilities to include newly discovered tasks. Finally, we construct two real-world datasets using job posting data collected from the labor markets of China and the United States, respectively. Extensive experiments on the real-world datasets, along with two publicly available datasets, have demonstrated the effectiveness of the proposed COTR. Furthermore, several case studies showcase the significant benefits of COTR for various downstream applications in labor market analysis, including analyzing the evolving demand for OSTs, assessing the value of OSTs, and recognizing the relationships between OSTs and associated skills.},
  archive      = {J_TMIS},
  author       = {Chuan Qin and Chuyu Fang and Kaichun Yao and Xi Chen and Fuzhen Zhuang and Hengshu Zhu},
  doi          = {10.1145/3712306},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {COTR: Efficient job task recognition for occupational information systems with class-incremental learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering IT career path patterns with job embedding-based sequence clustering. <em>TMIS</em>, <em>16</em>(2), 1-32. (<a href='https://doi.org/10.1145/3712705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting typical career paths from large-scale and unstructured talent profiles has recently attracted increasing research attention. However, various challenges arise in effectively analyzing self-reported career records. Inspired by recent advancements in neural networks and embedding models, we develop a novel career path clustering approach and apply it to uncover information technology (IT) career path patterns. Specifically, we construct employment profiles of over 60,000 IT professionals, and form their career path sequences by chaining the job records in each profile. Then we simultaneously learn cluster-wise job embeddings and construct career path clusters. The resultant cluster-wise likelihoods of career paths can quantify their soft bonding with different clusters, and the job embeddings can reveal connections among job titles within each cluster. With both real and simulated data, we conduct extensive experiments with our framework to establish the modeling performance and great improvement over the traditional optimal matching analysis methods. The empirical results from analyzing real data on career paths show that our approach can discover distinct IT career path patterns and reveal valuable insights.},
  archive      = {J_TMIS},
  author       = {Hao Zhong and Chuanren Liu and Chaojiang Wu},
  doi          = {10.1145/3712705},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-32},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Uncovering IT career path patterns with job embedding-based sequence clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint ability assessment for talent recruitment: A neural cognitive diagnosis approach. <em>TMIS</em>, <em>16</em>(2), 1-25. (<a href='https://doi.org/10.1145/3714414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ability assessment is a critical task in talent recruitment that aims at identifying the most suitable job candidates by evaluating the alignment of their skills with job requirements. Indeed, traditional ability assessment involves multiple staffing processes with various forms of evaluation methods, such as written tests and face-to-face interviews, which usually result in fragmented, noisy, and inconsistent conclusions. Therefore, a long-standing challenge in talent recruitment is how to comprehensively evaluate candidates by integrating multi-source heterogeneous assessment results. To this end, in this article, we propose a holistic framework, JCD-TR ( J oint C ognitive D iagnosis for T alent R ecruitment), for enhancing the performance of ability assessment in talent recruitment by jointly modeling the multi-source heterogeneous assessment results. Specifically, we first construct a skill graph based on the co-occurrence relations of skills in multi-source recruitment data. Along this line, we can learn the skill representations that maintain both the semantic and structural information with graph embedding. Then, we design a multi-source candidate ability profiling module with the guidance of item response theory in psychometrics and the neural topic model. As a result, the candidates’ ability profiles can be explored from their resumes, written tests, and interview assessment data, respectively. Furthermore, we propose a joint cognitive diagnosis module by integrating those multi-view ability profiles and skill representations to assess the candidates’ skill proficiency state. Extensive experiments on a real-world dataset demonstrate the effectiveness of our JCD-TR.},
  archive      = {J_TMIS},
  author       = {Haiping Ma and Manwei Li and Chuan Qin and Dazhong Shen and Hengshu Zhu and Xingyi Zhang and Hui Xiong},
  doi          = {10.1145/3714414},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Joint ability assessment for talent recruitment: A neural cognitive diagnosis approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for conducting advanced text analytics information systems research. <em>TMIS</em>, <em>16</em>(1), 1-27. (<a href='https://doi.org/10.1145/3682069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of digital content has generated massive textual datasets, necessitating the use of advanced analytical approaches. Large Language Models (LLMs) have emerged as tools that are capable of processing and extracting insights from massive unstructured textual datasets. However, how to leverage LLMs for text analytics Information Systems (IS) research is currently unclear. To assist the IS community in understanding how to operationalize LLMs, we propose a Text Analytics for Information Systems Research (TAISR) framework. Our proposed framework provides detailed recommendations grounded in IS and LLM literature on how to conduct meaningful text analytics IS research for design science, behavioral, and econometric streams. We conducted three business intelligence case studies using our TAISR framework to demonstrate its application in several IS research contexts. We also outline the potential challenges and limitations of adopting LLMs for IS. By offering a systematic approach and evidence of its utility, our TAISR framework contributes to future IS research streams looking to incorporate powerful LLMs for text analytics.},
  archive      = {J_TMIS},
  author       = {Benjamin Ampel and Chi-Heng Yang and James Hu and Hsinchun Chen},
  doi          = {10.1145/3682069},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Large language models for conducting advanced text analytics information systems research},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing heterogeneous LLM agents for financial sentiment analysis. <em>TMIS</em>, <em>16</em>(1), 1-24. (<a href='https://doi.org/10.1145/3688399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focus from massive data acquisition and new model training to human alignment and strategic elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA) due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage existing generative models in such a context. This study investigates the effectiveness of the new paradigm, that is, using LLMs without fine-tuning for FSA. Rooted in Minsky’s theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed and applied to FSA. The framework instantiates specialized agents using prior guiding knowledge from both linguistics and finance. Then, a summative agent reasons on the aggregated agent discussions. Comprehensive evaluations using six FSA datasets show that the framework yields better accuracies compared to many alternative multi-LLM agent settings, especially when the discussion contents are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA and potentially other tasks. Implications for business and management have also been discussed.},
  archive      = {J_TMIS},
  author       = {Frank Xing},
  doi          = {10.1145/3688399},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Designing heterogeneous LLM agents for financial sentiment analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On leveraging large language models for multilingual intent discovery. <em>TMIS</em>, <em>16</em>(1), 1-17. (<a href='https://doi.org/10.1145/3688400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent discovery is vital for any real-world dialogue systems such as chatbot. Since the intents of users naturally change over time, models only trained on a static training set of intents will inevitably fail to detect new intents. While this topic has been widely studied, existing work only focuses on monolingual datasets, rendering it less practical for international businesses, where it is far more common to work with multilingual data. In this work, we present a method for multilingual intent discovery through leveraging the multilingual capabilities of recent large language models. By performing joint extraction of intent and keyphrases, as well as a chain-of-thought–styled reasoning, our method is able to efficiently produce clustering results that are easy to interpret. Experimental results on two different datasets show that our proposed method consistently surpasses all baselines, with up to 15% gain in adjusted Rand index.},
  archive      = {J_TMIS},
  author       = {Rudolf Chow and King Yiu Suen and Albert Y.S. Lam},
  doi          = {10.1145/3688400},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {On leveraging large language models for multilingual intent discovery},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-AI synergy in survey development: Implications from large language models in business and research. <em>TMIS</em>, <em>16</em>(1), 1-39. (<a href='https://doi.org/10.1145/3700597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the novel integration of Large Language Models (LLMs) into the survey development process in business and research through the development and evaluation of the Behavioral Research Assistant (BRASS) Bot. We first analyzed the traditional scale development process to identify tasks suitable for LLM integration, including both human-in-the-loop and automated LLM data collection methods. Following this analysis, we developed the details of BRASS Bot, incorporating design principles of falsifiability and reproducibility. We then conducted a comprehensive evaluation of the BRASS Bot across a diverse set of LLMs, including GPT, Claude, Gemini, and Llama, to assess its usability, validity, and reliability. We further demonstrated the practical utility of the BRASS Bot by conducting a user study and a predictive validity simulation. Our research presents both theoretical and practical implications. The augmentation approach of the BRASS Bot enriches the theoretical foundations of behavioral constructs by identifying previously overlooked patterns. Additionally, the BRASS Bot offers significant time and resource efficiency gains while enhancing scale validity. Our work lays the foundation for future research on the broader application of LLMs as both assistants and collaborators in survey analysis and behavioral research design and execution, highlighting their potential for a transformative impact on the field.},
  archive      = {J_TMIS},
  author       = {Ping Fan Ke and Ka Chung Ng},
  doi          = {10.1145/3700597},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Human-AI synergy in survey development: Implications from large language models in business and research},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving workplace well-being in modern organizations: A review of large language model-based mental health chatbots. <em>TMIS</em>, <em>16</em>(1), 1-26. (<a href='https://doi.org/10.1145/3701041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global rise in mental disorders, particularly in workplaces, necessitated innovative and scalable solutions for delivering therapy. Large Language Model (LLM)-based mental health chatbots have rapidly emerged as a promising tool for overcoming the time, cost, and accessibility constraints often associated with traditional mental health therapy. However, LLM-based mental health chatbots are in their nascency, with significant opportunities to enhance their capabilities to operate within organizational contexts. To this end, this research seeks to examine the role and development of LLMs in mental health chatbots over the past half-decade. Through our review, we identified over 50 mental health-related chatbots, including 22 LLM-based models targeting general mental health, depression, anxiety, stress, and suicide ideation. These chatbots are primarily used for emotional support and guidance but often lack capabilities specifically designed for workplace mental health, where such issues are increasingly prevalent. The review covers their development, applications, evaluation, ethical concerns, integration with traditional services, LLM-as-a-Service, and various other business implications in organizational settings. We provide a research illustration of how LLM-based approaches could overcome the identified limitations and also offer a system that could help facilitate systematic evaluation of LLM-based mental health chatbots. We offer suggestions for future research tailored to workplace mental health needs.},
  archive      = {J_TMIS},
  author       = {Aijia Yuan and Edlin Garcia Colato and Bernice Pescosolido and Hyunju Song and Sagar Samtani},
  doi          = {10.1145/3701041},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Improving workplace well-being in modern organizations: A review of large language model-based mental health chatbots},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A metric-based detection system for large language model texts. <em>TMIS</em>, <em>16</em>(1), 1-19. (<a href='https://doi.org/10.1145/3704739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
  archive      = {J_TMIS},
  author       = {Linh Le and Dung Tran},
  doi          = {10.1145/3704739},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A metric-based detection system for large language model texts},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unraveling the impact of ChatGPT as a knowledge anchor in business education. <em>TMIS</em>, <em>16</em>(1), 1-30. (<a href='https://doi.org/10.1145/3705734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
  archive      = {J_TMIS},
  author       = {Amrita George and Veda Catherine Storey and Shuguang Hong},
  doi          = {10.1145/3705734},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Unraveling the impact of ChatGPT as a knowledge anchor in business education},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative analysis of instruction fine-tuning large language models for financial text classification. <em>TMIS</em>, <em>16</em>(1), 1-30. (<a href='https://doi.org/10.1145/3706119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated impressive capabilities across diverse Natural Language Processing (NLP) tasks, including language understanding, reasoning, and generation. However, general-domain LLMs often struggle with financial tasks due to the technical and specialized nature of financial texts. This study investigates the efficacy of instruction fine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini, to enhance their performance in financial text classification tasks. We fine-tuned both instruction-tuned and base models across four financial classification tasks, achieving significant improvements in task-specific performance. Furthermore, we evaluated the zero-shot capabilities of these fine-tuned models on three unseen complex financial tasks, including argument classification, deal completeness classification, and causal classification. Our results indicate while base model fine-tuning led to greater degradation, instruction-tuned models maintained more robust performance. To address this degradation, we employed model merging techniques, integrating single-task domain-specific fine-tuned models with the base model. Using this merging method resulted in significant enhancements in zero-shot performance, even exceeding the original model’s accuracy on certain datasets. Our findings underscore the effectiveness of instruction fine-tuning and model merging for adapting LLMs to specialized financial text classification tasks.},
  archive      = {J_TMIS},
  author       = {Sorouralsadat Fatemi and Yuheng Hu and Maryam Mousavi},
  doi          = {10.1145/3706119},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A comparative analysis of instruction fine-tuning large language models for financial text classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An IS research agenda on large language models: Development, applications, and impacts on business and management. <em>TMIS</em>, <em>16</em>(1), 1-11. (<a href='https://doi.org/10.1145/3713032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models have been advancing very rapidly and are making substantial impacts on all areas of business and management. We review the development of large language models and their applications in business and management, and identify the major issues and challenges faced by both practitioners and researchers. Based on our review, we propose an agenda for information systems researchers on large language models and discuss some of the potential directions for future research. Lastly, we present the articles in the special issue as exemplary research on large language models and discuss their implications.},
  archive      = {J_TMIS},
  author       = {Michael Chau and Jennifer Xu},
  doi          = {10.1145/3713032},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-11},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An IS research agenda on large language models: Development, applications, and impacts on business and management},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
