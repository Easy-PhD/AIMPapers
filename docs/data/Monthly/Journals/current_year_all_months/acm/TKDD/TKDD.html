<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDD</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkdd">TKDD - 136</h2>
<ul>
<li><details>
<summary>
(2025). Online learning from mix-typed, drifted, and incomplete streaming features. <em>TKDD</em>, <em>19</em>(8), 1-28. (<a href='https://doi.org/10.1145/3744712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online learning, where feature spaces can change over time, offers a flexible learning paradigm that has attracted considerable attention. However, it still faces three significant challenges. First, the heterogeneity of real-world data streams with mixed feature types presents challenges for traditional parametric modeling. Second, data stream distributions can shift over time, causing an abrupt and substantial decline in model performance. Additionally, the time and cost constraints make it infeasible to label every data instance in a supervised setting. To overcome these challenges, we propose a new algorithm Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features (OL-MDISF), which aims to relax restrictions on both feature types, data distribution, and supervision information. Our approach involves utilizing copula models to create a comprehensive latent space, employing an adaptive sliding window for detecting drift points to ensure model stability, and establishing label proximity information based on geometric structural relationships. To demonstrate the model’s efficiency and effectiveness, we provide theoretical analysis and comprehensive experimental results.},
  archive      = {J_TKDD},
  author       = {Shengda Zhuo and Di Wu and Yi He and Shuqiang Huang and Xindong Wu},
  doi          = {10.1145/3744712},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online learning from mix-typed, drifted, and incomplete streaming features},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New automated approach to selection of mapper clustering parameters. <em>TKDD</em>, <em>19</em>(8), 1-36. (<a href='https://doi.org/10.1145/3746065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological methods have recently gained traction as powerful tools for extracting insights from high-dimensional data, forming the foundation of an approach known as Topological Data Analysis (TDA). Among the key developments in TDA is the Mapper algorithm, which constructs graph-based representations of complex datasets, capturing their topological structure at a user-defined resolution. The Mapper algorithm has shown promise across various applications, particularly in biomedical data analysis. However, its application requires careful selection of several parameters, especially the clustering algorithm and its settings. Without prior knowledge and a deep understanding of the data, these choices are non-trivial and can be a major barrier for researchers aiming to leverage Mapper effectively. In this work, we introduce enhancements to the Mapper algorithm to address this challenge. Specifically, we investigate the integration of ensemble learning (EL) techniques into Mapper’s graph construction to eliminate the need for arbitrary parameter selection. Additionally, we propose a data-driven criterion for selecting the clustering method best suited to the Mapper algorithm. Our experimental results demonstrate that the proposed approach enables the construction of Mapper graphs that accurately capture the underlying structure of the input data, all without manual parameter tuning.},
  archive      = {J_TKDD},
  author       = {Padraig Fitzpatrick and Anna Jurek-Loughrey and Paweł Dłotko},
  doi          = {10.1145/3746065},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-36},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {New automated approach to selection of mapper clustering parameters},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A propagation model of derived topic based on cognitive accumulation and transfer learning. <em>TKDD</em>, <em>19</em>(8), 1-24. (<a href='https://doi.org/10.1145/3747187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The propagation of hot topics often gives rise to a series of derivative topics. In view of the sparsity of user behavior data and the cognitive accumulation of the original topic, a prediction model of derived topic propagation based on cognitive accumulation and transfer learning is proposed. First, for the complexity of the derived topic feature space, considering the relation and difference between derivative topics and original topics, this study designs I(Iterative)T(Topic)2vec, a topic iterative representation method based on original topics to get the low-dimensional representation of the derived topic feature space more richly from the perspectives of both original topics and derivative topics. Second, it aims at the problem of users’ cognitive accumulation of the original topic before the outbreak of derivative topic. The subjective game theory is introduced to construct the cognitive influence of users. At the same time, considering the timeliness of the propagation cycle of derivative topics, we discretized the derivative topic data, and further proposed a derivative topic propagation model based on Subjective Adapt-CNN (SA-CNN). Finally, the sparsity of effective behavior data of users at the beginning of the outbreak of derivative topics is discussed. Considering the rich user behavior data in the communication history of the original topic, data migration is carried out by using the original topic. At the same time, the domain adaptive method based on Transfer Component Analysis (TCA) is introduced to achieve feature adaptation from the original topic data to the derived topic data, further improving the accuracy of the derived topic propagation model. Experiments show that this model can not only effectively alleviate the problem of data sparsity but also perceive the propagation situation of derived topics well.},
  archive      = {J_TKDD},
  author       = {Qian Li and Wenhao Zhang and Bojian Hu and Tun Li and Rong Wang and Shihong Wei and Yunpeng Xiao},
  doi          = {10.1145/3747187},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A propagation model of derived topic based on cognitive accumulation and transfer learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing fairness and accuracy in data-restricted binary classification. <em>TKDD</em>, <em>19</em>(8), 1-40. (<a href='https://doi.org/10.1145/3747850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair decision-making in Machine Learning (ML) remains a critical challenge, particularly when access to sensitive information is restricted due to legal, ethical, or organizational constraints. These limitations affect both accuracy and fairness, creating tradeoffs central to the deployment of ML systems in the real world. While prior work has studied fairness-accuracy tradeoffs, most approaches focus on model outputs rather than directly examining how restricted data access impacts fairness. This leaves an important gap: understanding how fairness constraints affect model performance under real-world data restrictions . To address this gap, we propose a framework that explicitly models fairness-accuracy tradeoffs in data-restricted environments. Unlike prior work, our approach analyzes the behavior of the optimal Bayesian classifier using a discrete approximation of the data distribution, allowing us to systematically isolate the effects of fairness constraints. We evaluate our framework on three benchmark datasets—Adult, Law, and Dutch Census—revealing key insights: (1) enforcing equal accuracy on imbalanced datasets can substantially degrade performance under additional fairness constraints, (2) individual and group fairness often impose conflicting constraints, and (3) decorrelating sensitive attributes from features does not usually reduce accuracy. These findings demonstrate that our framework provides an effective, structured approach for practitioners to assess fairness constraints in decision-making pipelines.},
  archive      = {J_TKDD},
  author       = {Zachary McBride Lazri and Danial Dervovic and Antigoni Polychroniadou and Ivan Brugere and Dana Dachman-Soled and Furong Huang and Min Wu},
  doi          = {10.1145/3747850},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Balancing fairness and accuracy in data-restricted binary classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Growth scale-free networks by various generative ways. <em>TKDD</em>, <em>19</em>(8), 1-32. (<a href='https://doi.org/10.1145/3748512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the popularly discussed topic, i.e., how to construct available theoretical networked models that certainly capture some structural features popularly observed on realistic networks, is still our focus. Specifically, we first propose an evolving deterministic network \(N(t)\) using three types of growth ways. Then, we study some topological structural parameters including degree distribution, diameter, and clustering coefficient on network \(N(t)\) . The results demonstrate that the proposed network has scale-free feature and small-world property. In the meantime, we obtain an interesting finding, i.e., the first handshake between Fibonacci series and the “pure” preferential attachment mechanism. Next, we enumerate spanning trees on network \(N(t)\) and derive the closed-form solution of spanning trees number. Second, we introduce randomness into the growth process of network \(N(t)\) to further establish evolving stochastic networks \(\mathfrak{N}(t)\) that follow the same degree distribution as network \(N(t)\) and also determine some topological structural parameters so as to investigate effect of randomness on structural properties. We show analytically that such a randomization approach makes the resulting stochastic networks not only to greatly inherit some fundamental structural properties from deterministic network \(N(t)\) but also to considerably improve the robustness of network when encountering deliberate removal of edge. Lastly, we list out some open problems.},
  archive      = {J_TKDD},
  author       = {Fei Ma and Ping Wang},
  doi          = {10.1145/3748512},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Growth scale-free networks by various generative ways},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the use of relative validity indices for comparing clustering approaches. <em>TKDD</em>, <em>19</em>(8), 1-53. (<a href='https://doi.org/10.1145/3748726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relative Validity Indices (RVIs) such as the Silhouette Width Criterion, Calinski–Harabasz and Davies-Bouldin indices are the most widely used tools for evaluating and optimising clustering outcomes. Traditionally, their ability to rank collections of candidate dataset partitions has been used to guide the selection of the number of clusters and to compare partitions from different clustering algorithms. However, there is a growing trend in the literature to use RVIs when selecting a Similarity Paradigm (SP) for clustering—the combination of normalisation procedure, representation method and distance measure which affects the computation of object dissimilarities used in clustering. Despite the growing prevalence of this practice, there has been no empirical or theoretical investigation into the suitability of RVIs for this purpose. Moreover, since RVIs are computed using object dissimilarities, it remains unclear how they would need to be implemented for fair comparisons of different SPs. This study presents the first comprehensive investigation into the reliability of RVIs for SP selection. We conducted extensive experiments with seven popular RVIs on over 2.7 million clustering partitions of synthetic and real-world datasets, encompassing feature-vector and time-series data. We identified fundamental conceptual limitations undermining the use of RVIs for SP selection, and our empirical findings confirmed this predicted unsuitability. Among our recommendations, we suggest instead that practitioners select SPs by using external validation on high quality labelled datasets or carefully designed outcome-oriented objective criteria, both of which should be informed by careful consideration of dataset characteristics and domain requirements. Our findings have important implications for clustering methodology and evaluation, suggesting the need for more rigorous approaches to SP selection in clustering applications.},
  archive      = {J_TKDD},
  author       = {Luke W. Yerbury and Ricardo J. G. B. Campello and G. C. Livingston, Jr. and Mark Goldsworthy and Lachlan O’Neil},
  doi          = {10.1145/3748726},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-53},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {On the use of relative validity indices for comparing clustering approaches},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology augmented multi-band and multi-scale filtering for graph anomaly detection. <em>TKDD</em>, <em>19</em>(8), 1-27. (<a href='https://doi.org/10.1145/3748727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Anomaly Detection (GAD) has gained significant attention in areas such as financial risk control and social network security, becoming a critical research problem. Vanilla Graph Neural Networks (GNNs), a popular method for graph modeling, are known to perform poorly in GAD due to the assumption of homophily preferences. This article argues that the issue lies in the insufficient feature extraction ability caused by their single filtering property (low-pass filtering) and revealing the effectiveness of multi-band filtering to deal with GAD. From this, we note two other overlooked issues: (1) How can multi-band band-pass filtering further fuse multi-scale neighborhood information? (2) Adaptation between raw attributes of nodes and graph filters (graph topology). The former bridges the respective advantages of spectral domain and spatial domain, and the latter is an important bottleneck for the encoding capacity of the filters. To address these, we propose a new GAD method, Graph Perturbed Networks (GraphPN). Each hidden layer of GraphPN is a band-pass filter, enabling multi-band and multi-scale filtering through simple stacking and skip connections. We analyze its spectral locality and spatial locality to provide theoretical support. Additionally, GraphPN is supplemented with a tailored feature activation module to complete the adaptation of the above two. This module readjusts node indices and decouples graph convolution, introducing rich topological information to node attributes. In addition to further enhancing detection performance, another possibly counter-intuitive effect is that the distinguishability of the two classes of nodes is improved even before filtering. The proposed method performs well in real-world datasets compared with the current state-of-the-art baselines, which fully demonstrates its superiority. Codes are available at https://github.com/Thankstaro/GraphPN .},
  archive      = {J_TKDD},
  author       = {Jingyuan Zhang and Lei Yu and Zhirong Huang and Li Yang and Fengjun Zhang},
  doi          = {10.1145/3748727},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Topology augmented multi-band and multi-scale filtering for graph anomaly detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient federated learning with heterogeneous data and adaptive dropout. <em>TKDD</em>, <em>19</em>(8), 1-31. (<a href='https://doi.org/10.1145/3749376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a promising distributed machine learning approach that enables collaborative training of a global model using multiple edge devices. The data distributed among the edge devices are highly heterogeneous. Thus, FL faces the challenge of data distribution and heterogeneity, where non-Independent and Identically Distributed (non-IID) data across edge devices may yield in significant accuracy drop. Furthermore, the limited computation and communication capabilities of edge devices increase the likelihood of stragglers, thus leading to slow model convergence. In this article, we propose the FedDHAD FL framework, which comes with two novel methods: dynamic heterogeneous model aggregation (FedDH) and adaptive dropout (FedAD). FedDH dynamically adjusts the weights of each local model within the model aggregation process based on the non-IID degree of heterogeneous data to deal with the statistical data heterogeneity. FedAD performs neuron-adaptive operations in response to heterogeneous devices to improve accuracy while achieving superb efficiency. The combination of these two methods makes FedDHAD significantly outperform state-of-the-art solutions in terms of accuracy (up to 6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to 15.0% smaller).},
  archive      = {J_TKDD},
  author       = {Ji Liu and Beichen Ma and Qiaolin Yu and Ruoming Jin and Jingbo Zhou and Yang Zhou and Huaiyu Dai and Haixun Wang and Dejing Dou and Patrick Valduriez},
  doi          = {10.1145/3749376},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient federated learning with heterogeneous data and adaptive dropout},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding user perspectives for MOOC quality evaluation with hypergraph learning. <em>TKDD</em>, <em>19</em>(8), 1-19. (<a href='https://doi.org/10.1145/3749845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of Massive Open Online Course (MOOC) quality is crucial to enhance the educational resources, benefiting user services, and enhancing students’ learning efficiency. Despite achieving encouraging results, current efforts are hindered by complex relationships between entities and individual varies. To address the above problem, in this article, we frame the issue as a task of learning course representations and proceed to develop an U ser-Centric H ypergraph R epresentation L earning ( UHRL ) for online course quality evaluation. In particular, we initially construct a MOOC hypergraph to depict the interactions and connections between the entities and use cross-hyperedge alignment to reveal the semantics of courses. And then we incorporate an attention mechanism in the information transmission process to ensure semantic integrity. Furthermore, to tackle the bias of users’ preference, our framework exploits mutual information for preserving the fairness of representation learning. Finally, our comprehensive experiments on three real-world datasets confirm the effectiveness of our approach compared to cutting-edge methods in evaluating online course quality across various performance metrics.},
  archive      = {J_TKDD},
  author       = {Lu Jiang and Ruilou Zhang and Yanan Xiao and Kunpeng Liu and Kaidi Wang and Minghao Yin},
  doi          = {10.1145/3749845},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding user perspectives for MOOC quality evaluation with hypergraph learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating heterogeneous graph attention network with label propagation for detecting spammer groups on E-commerce platforms. <em>TKDD</em>, <em>19</em>(8), 1-28. (<a href='https://doi.org/10.1145/3749846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collusive fraudulent behaviors on e-commerce platforms lead to proliferation of fraudulent reviews, which disrupt fair competition among merchants and mislead consumers’ shopping decisions. Detection of spammer groups helps purify the e-commerce environment and enhances consumers’ shopping experience. However, existing graph-based methods for detecting spammer groups first learn user node vector representations from the graph, and then use clustering methods to obtain candidate groups. Such separate two-stage detection methods are difficult to obtain high-quality candidate groups, resulting in suboptimal detection performance. Additionally, current graph construction methods used in spammer group detection do not fully consider the characteristics of spammer groups, which limits the detection performance. Aiming these concerns, we integrate heterogeneous graph attention network (HGAN) with label propagation (LP) for detecting spammer groups. First, we build a heterogeneous weighted directed (HWD) graph by analyzing the dataset and assign an initial label to each node. Then, we integrate a HGAN-module with an LP-module to obtain the HWD graph’s node embeddings and simultaneously generate candidate groups. We enhance the quality of embeddings and groups through the collaborative optimization between the predicted labels obtained from the HGAN-module and the pseudo-labels obtained from the LP-module. Finally, we calculate the suspiciousness values of groups using the reconstruction loss of the autoencoder for spammer group identification. Experiments conducted on real-world review datasets, including Amazon, Yelp, and YelpChi, demonstrate that our method achieves significant improvements in average Precision@k and Recall@k metrics compared with state-of-the-art baseline approaches.},
  archive      = {J_TKDD},
  author       = {Xuchao Li and Peng Zhang and Ru Ma and Chenghang Huo and Fuzhi Zhang},
  doi          = {10.1145/3749846},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Integrating heterogeneous graph attention network with label propagation for detecting spammer groups on E-commerce platforms},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GFformer: A graph transformer for extracting all frequency information from large-scale graphs. <em>TKDD</em>, <em>19</em>(8), 1-20. (<a href='https://doi.org/10.1145/3750051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformers have demonstrated outstanding performance across various graph-based applications. Despite their success, applying them to large-scale graphs presents significant scalability challenges, limiting their practical use in industrial environments. Recent studies have attempted to overcome this challenge by focusing on the spatial domain of graphs, leading to the development of various scalable models. However, these approaches neglect the spectral characteristics of graphs, which are crucial for adaptively extracting information from full-frequency bands based on the graph’s inherent properties. As a result, existing scalable Graph Transformers tend to rely heavily on low-frequency features, overlooking valuable mid- and high-frequency information. This article proposes the Graph Filter Transformer (GFformer), a framework designed to effectively extract full-frequency information from large-scale graphs. Unlike existing Graph Transformers, GFformer integrates graph filters into the Transformer architecture, thereby enhancing its ability to model both structural and frequency-related properties. Utilizing the proposed Spectral Token Converter (ST-converter), GFformer generates a unique spectral token sequence for each node by incorporating features from diverse frequencies that act as tokens. This design enables the independent learning of node representations in parallel and supports mini-batch training with flexible batch sizes, making GFformer highly scalable. ST-converter employs spectral graph filters, including low-, mid-, and high-pass filters, to extract features serving as tokens. Consequently, each sequence encompasses features from various frequencies, enabling GFformer to capture comprehensive frequency information effectively. Extensive experiments on datasets of varying scales, including both homophilic and heterophilic graphs, consistently demonstrate that GFformer outperforms existing representative methods.},
  archive      = {J_TKDD},
  author       = {Qi Zhang and Mengmeng Si and Yanfeng Sun and Shaofan Wang and Junbin Gao and Baocai Yin},
  doi          = {10.1145/3750051},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {GFformer: A graph transformer for extracting all frequency information from large-scale graphs},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE-GCL: A semantic-enhanced graph contrastive learning framework for road network embedding. <em>TKDD</em>, <em>19</em>(8), 1-27. (<a href='https://doi.org/10.1145/3757921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning of road networks is essential for various downstream traffic-related tasks, as road network contain multi-modal data with rich information, and the learned embeddings can be directly used in machine learning models. However, due to the dynamic changes in road networks with respect to topology and associated data, as well as the local and long-range dependency caused by complex mobility semantics, learning robust and effective representations remains challenging. To this end, we exploit the properties of the road network and the mobility semantics embedded in trajectories, and propose a novel S emantic- E nhanced G raph C ontrastive L earning (SE-GCL) framework, for learning general-purpose embeddings of road networks. Specifically, in this framework, we propose (1) a multi-modal feature embedding module to capture both the attribute and visual information of road segments, (2) a semantic-enhanced graph augmentation strategy to simulate topological changes and data missing in the road network, and (3) a semantic-enhanced contrastive optimization module that leverages geo-locality and mobility semantics to guide representation learning. Extensive experiments are conducted on two real-world road networks with three representative downstream tasks. The result demonstrate that SE-GCL yields more robust and effective representations, outperforming the state-of-the-art baselines. The source code is available at https://github.com/csjiezhao/SE-GCL .},
  archive      = {J_TKDD},
  author       = {Jie Zhao and Chao Chen and Wanyi Zhang and Mingyu Deng and Huayan Pu and Jun Luo},
  doi          = {10.1145/3757921},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SE-GCL: A semantic-enhanced graph contrastive learning framework for road network embedding},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-grained spatial-temporal feature complementarity for accurate online cellular traffic prediction. <em>TKDD</em>, <em>19</em>(8), 1-27. (<a href='https://doi.org/10.1145/3758099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovered from telecom data can facilitate proactive understanding of network dynamics and user behaviors, which in turn empowers service providers to optimize cellular traffic scheduling and resource allocation. Nevertheless, the telecom industry still heavily relies on manual expert intervention. Existing studies have been focused on exhaustively exploring the spatial-temporal correlations. However, they often overlook the underlying characteristics of cellular traffic, which are shaped by the sporadic and bursty nature of telecom services. Additionally, concept drift creates substantial obstacles to maintaining satisfactory accuracy in continuous cellular forecasting tasks. To resolve these problems, we put forward an online cellular traffic prediction method grounded in Multi-Grained Spatial-Temporal feature Complementarity (MGSTC). The proposed method is devised to achieve high-precision predictions in practical continuous forecasting scenarios. Concretely, MGSTC segments historical data into chunks and employs the coarse-grained temporal attention to offer a trend reference for the prediction horizon. Subsequently, fine-grained spatial attention is utilized to capture detailed correlations among network elements, which enables localized refinement of the established trend. The complementarity of these multi-grained spatial-temporal features facilitates the efficient transmission of valuable information. To accommodate continuous forecasting needs, we implement an online learning strategy that can detect concept drift in real-time and promptly switch to the appropriate parameter update stage. Experiments carried out on four real-world datasets demonstrate that MGSTC outperforms eleven state-of-the-art baselines consistently.},
  archive      = {J_TKDD},
  author       = {Ningning Fu and Shengheng Liu and Weiliang Xie and Yongming Huang},
  doi          = {10.1145/3758099},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-grained spatial-temporal feature complementarity for accurate online cellular traffic prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCAKE: Memory-augmented autoencoder with contrastive learning for unsupervised anomaly detection. <em>TKDD</em>, <em>19</em>(8), 1-18. (<a href='https://doi.org/10.1145/3759460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, reconstruction-based deep models have gained widespread usage in unsupervised anomaly detection. However, they may overlook some anomalies owing to the over-generalization of neural networks. Several studies have incorporated memory networks to mitigate this problem. Nonetheless, some of them lack an explicit memory updating process, while others rely on data-driven updating methods that are sensitive to initial values and unsuitable for end-to-end training. Additionally, the traditional criterion for detection computed in the high-dimensional input space may collapse as the spike in the deviation score is averaged across numerous dimensions. To address these challenges, we propose MCAKE, a M emory-augmented C ontrastive A utoencoder with K NN-Based E xtraction. It is designed to highlight the deviation score for anomalies by reconstructing input using fixed normal prototypes recorded in the memory. We explicitly encourage the memory to be autonomously learned and effectively allocated through contrastive learning with multiple positive and multiple negative samples. Furthermore, we introduce a bivariate detection criterion that calculates anomaly scores considering both input and latent space to tackle the collapse. Extensive experiments on 50 datasets across various categories demonstrate the superiority of our approach, with a 2% relative improvement over the previous state-of-the-art models.},
  archive      = {J_TKDD},
  author       = {Chengsen Wang and Qi Qi and Jinming Wu and Haifeng Sun and Zirui Zhuang and Yuhan Jing and Lianyuan Li and Jingyu Wang},
  doi          = {10.1145/3759460},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MCAKE: Memory-augmented autoencoder with contrastive learning for unsupervised anomaly detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level contrastive learning for knowledge tracing. <em>TKDD</em>, <em>19</em>(8), 1-29. (<a href='https://doi.org/10.1145/3759920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is the task of predicting students’ future performance based on their past interactions with educational resources. A key aspect of KT is representation learning, which aims to capture meaningful features from students’ learning behaviors to improve prediction performance. Recently, contrastive learning methods have shown great promise in representation learning. As a result, KT models based on contrastive learning have been introduced to enhance representation learning for KT. However, these models have posed several challenges. Firstly, most of these models adopt the contrastive learning approach used in other fields, which involves data augmentation followed by contrastive learning, yet effectively applying data augmentation in KT remains an open challenge. Secondly, these models typically apply contrastive learning to only one of the fundamental components of KT: questions, interactions, or knowledge states, thereby limiting their overall performance. To address these issues, this article proposes a Multi-level Contrastive learning model for Knowledge Tracing (MCKT). MCKT (The code can be found at https://github.com/lilstrawberry/MCKT .) does not rely on data augmentation strategies; instead, it deeply integrates domain knowledge and performs contrastive learning at three levels: questions, interactions, and knowledge states. Experimental results on four publicly available datasets, compared against a total of 20 state-of-the-art KT models, demonstrate that MCKT consistently outperforms other models. Subsequent experiments further validate the effectiveness of the multi-level contrastive learning approach.},
  archive      = {J_TKDD},
  author       = {Xiaoxuan Shen and Fenghua Yu and Qian Wan and Ruxia Liang and Jianwen Sun},
  doi          = {10.1145/3759920},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-level contrastive learning for knowledge tracing},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive modality interaction transformer for multimodal knowledge graph completion. <em>TKDD</em>, <em>19</em>(8), 1-24. (<a href='https://doi.org/10.1145/3760786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are frequently confronted with the challenge of incompleteness, a problem that extends to multimodal knowledge graphs (MKGs). The primary goal of multimodal knowledge graph completion (MKGC) is to predict missing entities within MKGs. However, current MKGC methods face difficulties in adequately addressing modal preferences and imbalances in modal information. To overcome these issues, we introduce AdaMKGC, an innovative hybrid model incorporating an adaptive modality interaction transformer. This model employs a dynamic attention interaction strategy and a self-enhancing sampling approach. AdaMKGC achieves a more precise utilization of multimodal information by integrating modal preference information into modal interactions. Additionally, it effectively mitigates the issue of modal imbalance through targeted sampling and adjustment for entities with deficient information. Experimental evaluations demonstrate AdaMKGC’s superior performance in overcoming these prevalent challenges. Compared to existing state-of-the-art MKGC models, AdaMKGC shows a notable enhancement of 28% in MR on the WN18-IMG dataset and an improvement of 2.7% in Hits@1 on the FB15k-237-IMG dataset. Our code is available at https://github.com/HubuKG/AdaMKGC .},
  archive      = {J_TKDD},
  author       = {Yue Jian and Miao Zhang and Ziyue Qin and Chuyuan Xie and Kui Xiao and Yan Zhang and Zhifei Li},
  doi          = {10.1145/3760786},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive modality interaction transformer for multimodal knowledge graph completion},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional network integrated with frequency adaptive learning for multivariate time series classification. <em>TKDD</em>, <em>19</em>(8), 1-23. (<a href='https://doi.org/10.1145/3761818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification (MTSC) is a significant research topic in the realm of data mining, with broad applications in different industries, including healthcare, finance, meteorology, and traffic. While existing studies have designed many classifiers based on LSTMs, CNNs, and Transformer, the sophisticated architectures raise concerns regarding efficiency in computation. Additionally, most methods concentrate on a single dimension, typically temporal patterns, without fully considering multi-dimensional information such as the independence and interactions across variables that are essential in multivariate settings. To address these challenges, this article introduces FreConvNet, a lightweight convolutional network integrated with frequency adaptive learning. Inheriting the modular design paradigm of Transformer to achieve multi-view modeling of multivariate time series. FreConvNet consists of two key components: the frequency adaptive block (FAB) and the convolutional feed-forward network (ConvFFN). The FAB leverages the Fourier Transform in conjunction with adaptive filters to capture both long-term and short-term dependencies in the temporal dimension. Following that, ConvFFN captures cross-variable and cross-feature interactions by controlling inter-channel information flow through grouped pointwise convolutions, while introducing non-linearity to enhance representational capacity. Extensive experiments conducted on the well-known UEA archive validate that FreConvNet outperforms existing convolution-based, Transformer-based, and hybrid methods in classification performance and offers a computationally efficient solution.},
  archive      = {J_TKDD},
  author       = {Yingxia Tang and Yanxuan Wei and Yupeng Hu and Xiangwei Zheng and Cun Ji},
  doi          = {10.1145/3761818},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Convolutional network integrated with frequency adaptive learning for multivariate time series classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum: Diffusion models for tabular data imputation and synthetic data generation. <em>TKDD</em>, <em>19</em>(8), 1. (<a href='https://doi.org/10.1145/3761939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a corrigendum for the article “Diffusion Models for Tabular Data Imputation and Synthetic Data Generation” published in ACM Trans. Knowl. Discov. Data 19(6): 125:1-125:32 (2025).},
  archive      = {J_TKDD},
  author       = {Mario Villaizán-Vallelado and Matteo Salvatori and Carlos Segura and Ioannis Arapakis},
  doi          = {10.1145/3761939},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Corrigendum: Diffusion models for tabular data imputation and synthetic data generation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ORIC v2: Improved feature interaction detection model through online random interaction chains for click-through rate prediction. <em>TKDD</em>, <em>19</em>(8), 1-26. (<a href='https://doi.org/10.1145/3762667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the probability that a user clicks a specific item is fundamental in online advertising and recommendation. Further, it is crucial to use the latest and historical data appropriately in online scenarios to train CTR models. Online Random Interaction Chains (ORIC) was proposed to detect informative and interpretable feature interactions without retraining on historical data in online scenario, and the Streaming Integrated Model (SIM) framework was designed to integrate these time-varying feature interactions into CTR prediction models. Unfortunately, ORIC exhibits latency when provides the feature interactions used to evaluate SIM, and ORIC is not applicable for numerical features. For these reasons, we propose ORIC-V2 that uses time series models to predict the confidence of candidate evaluating feature interactions and selects reasonable feature interactions, and combines numerical features with ORIC-V2 through a discretization model to obtain DORIC-V2. Feeding the feature interactions found by ORIC-V2 and DORIC-V2 into SIM obtains significant experimental results on three datasets, demonstrating the effectiveness and interpretability of ORIC-V2 and DORIC-V2.},
  archive      = {J_TKDD},
  author       = {Yannian Kou and Qiuqiang Lin and Yunhao Wen and Di Fan and Chuanhou Gao},
  doi          = {10.1145/3762667},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {8},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {ORIC v2: Improved feature interaction detection model through online random interaction chains for click-through rate prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal meta-learning with multi-view graphs for cold-start recommendation. <em>TKDD</em>, <em>19</em>(7), 1-29. (<a href='https://doi.org/10.1145/3732943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold-start recommendation is a well-known problem in practical application scenarios. Generating reliable recommendations can be challenging when interactions are typically sparse. To mitigate the cold-start problem, some methods incorporate auxiliary information about users and items, and others adopt meta-learning to improve recommendation accuracy. However, these approaches overlook the fact that items are interdependent and likely to be related or similar. Moreover, user preference distributions in the meta-training and meta-testing phases are different in the cold-start scenario. To address these problems, we present a novel strategy called Causal Meta-learning with Multi-view Graphs (CausalMMG). Specifically, we first construct multi-view item-item graphs to explore the correlations and similarities between items from multiple perspectives. A multi-view item representer is then used to learn item representations, exploiting graph convolution neural networks to capture the structure of these different item–item graphs. We then resort to the structural causal models of causal inference and further develop a causality-enhanced bi-level adaptive meta-learner to eliminate bias caused by the different distributions of user preferences. Moreover, the meta-learner learns the user preferences for items in different orders through hierarchical and task-level adaptations. Finally, we evaluate CausalMMG on several real-world datasets, demonstrating its effectiveness in various scenarios. The results show that the proposed CausalMMG is significantly superior to competitive baseline methods for cold-start recommendation on all datasets, highlighting the importance of incorporating the multiple relationships between items and modeling different user preference distributions in recommender systems.},
  archive      = {J_TKDD},
  author       = {Huiting Liu and Wei Zhang and Peipei Li and Peng Zhao and Xindong Wu},
  doi          = {10.1145/3732943},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Causal meta-learning with multi-view graphs for cold-start recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent representation learning for attributed graph anomaly detection. <em>TKDD</em>, <em>19</em>(7), 1-22. (<a href='https://doi.org/10.1145/3733604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in attributed graph data has been widely applied in real applications. However, the intricate topology of graph data, high-dimensional attributes, and class imbalance inherent in anomaly detection tasks render attributed graph anomaly detection a challenging task. To detect anomalies using the intricate topology information of graph data, a dual-masked autoencoders is proposed for attributed graph anomaly detection, denoted as MAGAD. Specifically, in the MAGAD, the class imbalance in attributed graph data is dealt with by randomly masking the original graph data to obtain masked graph data for the anomaly detection task. And then, a latent representation of the graph data is obtained by training dual autoencoders, where one autoencoder is developed for reconstructing the original graph data, and another for reconstructing randomly masked graph data. This assists in identifying abnormal nodes in the attributed graph data. Subsequently, to capture anomalous information from relevant features, MAGAD uses a random re-masking strategy for latent representations learned from the masked graph. Finally, the anomaly scores of the nodes are calculated using the learned latent representations from the decoders of the dual autoencoders. Experimental results on five real-world datasets demonstrate that the MAGAD algorithm outperforms state-of-the-art anomaly detection algorithms.},
  archive      = {J_TKDD},
  author       = {Shichao Zhang and Penghui Xi and Mengqi Jiang and Guixian Zhang and Debo Cheng},
  doi          = {10.1145/3733604},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Latent representation learning for attributed graph anomaly detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph self-attention mechanism for interpretable multi-hop knowledge graph link prediction. <em>TKDD</em>, <em>19</em>(7), 1-22. (<a href='https://doi.org/10.1145/3737702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) are extensively used in recommendation systems and information retrieval but often suffer from incompleteness. A popular solution to this problem is multi-hop inference through a reinforcement learning framework, which provides an interpretable path for predicting missing links in KGs. Most previous work focuses on improving the performance of multi-hop link prediction. However, it has been observed that many multi-hop paths generated by these methods are irrational; they often fail to reasonably explain the predicted answer entities. To address this challenge, we introduce the Joint Multi-hop Link Prediction (JMLP) framework. The framework consists of a relation attention network and an entity attention network, which collaboratively generate the reasoning paths. The relation attention module utilizes an induction network to encode historical paths and employs the graph self-attention mechanism to refine the interaction of relation contextual information. The entity attention module uses the graph attention mechanism to obtain the aggregated contextual features and leverages self-attention to strengthen the correlation between local and global contextual entity features. Extensive experiments on five datasets validate the effectiveness of our approach, demonstrating significant improvements both in predictive performance and interpretability compared to state-of-the-art methods.},
  archive      = {J_TKDD},
  author       = {Hao Liu and Dong Li and Bing Zeng and Wei Liang and Dongjie Li},
  doi          = {10.1145/3737702},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph self-attention mechanism for interpretable multi-hop knowledge graph link prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and guiding weakly supervised entity alignment with potential isomorphism propagation. <em>TKDD</em>, <em>19</em>(7), 1-28. (<a href='https://doi.org/10.1145/3742436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent entities across diverse knowledge graphs (KGs) using only a limited number of seed alignments. Despite substantial advances in aggregation-based weakly supervised EA, the underlying mechanisms in this setting remain unexplored. In this article, we present a propagation perspective to analyze weakly supervised EA and explain the existing aggregation-based EA models. Our theoretical analysis reveals that these models essentially seek propagation operators for pairwise entity similarities. We further prove that, despite the structural heterogeneity across different KGs, the potentially aligned entities within aggregation-based EA models exhibit isomorphic subgraphs, a fundamental yet underexplored premise of EA. Leveraging this insight, we introduce a potential isomorphism propagation operator to enhance the propagation of neighborhood information across KGs. We develop a general EA framework, PipEA, incorporating this operator to improve the accuracy of every type of aggregation-based model without altering the learning process. Extensive experiments substantiate our theoretical findings and demonstrate PipEA’s significant performance gains over state-of-the-art weakly supervised EA methods. Our work advances the field and enhances our comprehension of aggregation-based weakly supervised EA.},
  archive      = {J_TKDD},
  author       = {Haifeng Sun and Yuanyi Wang and Han Li and Wei Tang and Zirui Zhuang and Qi Qi and Jingyu Wang},
  doi          = {10.1145/3742436},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding and guiding weakly supervised entity alignment with potential isomorphism propagation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagiNet: Mask-aware graph imputation network for incomplete traffic data. <em>TKDD</em>, <em>19</em>(7), 1-20. (<a href='https://doi.org/10.1145/3743141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to detector malfunctions and communication failures, missing data is ubiquitous during the collection of traffic data. Therefore, it is of vital importance to impute the missing values to facilitate data analysis and decision-making for Intelligent Transportation System (ITS) . However, existing imputation methods generally perform zero pre-filling techniques to initialize missing values, introducing inevitable noise. Moreover, we observe prevalent over-smoothed interpolations, falling short in revealing the intrinsic spatio-temporal correlations of incomplete traffic data. To this end, we propose Mask-Aware Graph Imputation Network (MagiNet) . Our method designs an adaptive mask spatio-temporal encoder to learn the latent representations of incomplete data, eliminating the reliance on pre-filling missing values. Furthermore, we devise a spatio-temporal decoder that stacks multiple blocks to capture the inherent spatial and temporal dependencies within incomplete traffic data, alleviating over-smoothed imputation. Extensive experiments demonstrate that our method outperforms state-of-the-art imputation methods on five real-world traffic datasets, yielding an average improvement of 4.31% in RMSE and 3.72% in MAPE under Missing Completely at Random (MCAR) pattern. Code is available at https://github.com/JeremyChou28/MagiNet .},
  archive      = {J_TKDD},
  author       = {Jianping Zhou and Bin Lu and Zhanyu Liu and Siyu Pan and Xuejun Feng and Hua Wei and Guanjie Zheng and Xinbing Wang and Chenghu Zhou},
  doi          = {10.1145/3743141},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MagiNet: Mask-aware graph imputation network for incomplete traffic data},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence-guaranteed federated learning through gradient trajectory smoothing with triple-objective decomposition. <em>TKDD</em>, <em>19</em>(7), 1-31. (<a href='https://doi.org/10.1145/3743142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has been widely adopted as a distributed machine learning paradigm aiming to derive a global model without transferring local data to the server. In the context of heterogeneous environments typical of many FL deployments, our research has identified the performance oscillation problem in existing FL methods, resulting in slow convergence and severe performance drop. In this article, we first investigate the global optimizing objective in FL and demonstrate that, due to data heterogeneity and partial client participation, the global updates in a single training epoch may diverge from the intended objectives of conventional FL methods. To address this problem, we introduce a triple-objective decomposition mechanism to decompose the overarching global objective into three distinct local objectives aimed at aligning client gradients. Subsequently, we propose a gradient trajectory smoothing technique known as FedGTS, which refines local updates by estimating a pseudo-gradient leveraging historical global update trajectories. This approach is designed to mitigate performance oscillations and enhance the stability of the learning process. We theoretically demonstrate that our approach reduces variance of local updates and achieves a guaranteed convergence rate. We experimentally show that the proposed method outperforms the baselines with faster convergence and higher accuracy. Extensive experiments validate the effectiveness of the proposed approach across various heterogeneity settings. Our codes are publicly available at GitHub ( https://github.com/ZongHR/FedGTS ).},
  archive      = {J_TKDD},
  author       = {Haoran Zong and Xiao Zhang and Ruichen Li and Jianhui Duan and Derun Zou and Wenzhong Li},
  doi          = {10.1145/3743142},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Convergence-guaranteed federated learning through gradient trajectory smoothing with triple-objective decomposition},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAT-LLM: Style-enhanced large language models with text style definition for chinese article-style transfer. <em>TKDD</em>, <em>19</em>(7), 1-33. (<a href='https://doi.org/10.1145/3744250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text style transfer plays a vital role in online entertainment and social media. However, existing models struggle to handle the complexity of Chinese long texts, such as rhetoric, structure, and culture, which restricts their broader application. To bridge this gap, we propose a Chinese Article-style Transfer (CAT-LLM) framework, which addresses the challenges of style transfer in complex Chinese long texts. At its core, CAT-LLM features a bespoke pluggable Text Style Definition (TSD) module that integrates machine learning algorithms to analyze and model article styles at both word and sentence levels. This module acts as a bridge, enabling large language models (LLMs) to better understand and adapt to the complexities of Chinese article styles. Furthermore, it supports the dynamic expansion of internal style trees, enabling the framework to seamlessly incorporate new and diverse style definitions, enhancing adaptability and scalability for future research and applications. Additionally, to facilitate robust evaluation, we created 10 parallel datasets using a combination of ChatGPT and various Chinese texts, each corresponding to distinct writing styles, significantly improving the accuracy of the model evaluation and establishing a novel paradigm for text style transfer research. Extensive experimental results demonstrate that CAT-LLM, combined with GPT-3.5-Turbo, achieves state-of-the-art performance, with a transfer accuracy F1 score of 79.36% and a content preservation F1 score of 96.47% on the “Fortress Besieged” dataset. These results highlight CAT-LLM’s innovative contributions to style transfer research, including its ability to preserve content integrity while achieving precise and flexible style transfer across diverse Chinese text domains. Building on these contributions, CAT-LLM presents significant potential for advancing Chinese digital media and facilitating automated content creation. Source code is available at GitHub ( https://github.com/TaoZhen1110/CAT-LLM ).},
  archive      = {J_TKDD},
  author       = {Zhen Tao and Dinghao Xi and Zhiyu Li and Liumin Tang and Wei Xu},
  doi          = {10.1145/3744250},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CAT-LLM: Style-enhanced large language models with text style definition for chinese article-style transfer},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRIME: Pretraining for patient condition representation with irregular multimodal electronic health records. <em>TKDD</em>, <em>19</em>(7), 1-39. (<a href='https://doi.org/10.1145/3744251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing collection of electronic health records (EHRs), deep learning has become a crucial tool for real-time treatment analysis. However, due to patient privacy concerns, the scarcity of labeled data limits the end-to-end models that rely on large training data. Self-supervised pretraining offers a promising solution. Nevertheless, applying pretraining to EHRs faces two key issues: (1) EHRs exhibit multimodality, including monitoring data and recorded clinical note. For multimodal pretraining, designing a self-supervised task that can establish cross-modal associations while preserving all modal-unique information remains challenging. (2) Both modalities are sequential and irregular, with varying intervals between monitoring or records. Aligning monitoring times with recorded times poses a significant issue for fine-grained cross-modal pretraining. Existing pretraining models either focus on a single modality or only models regular data, failing to address them together. To fill this gap and fully utilize unlabel EHR data, we propose a p retraining model to learn patient r epresentation using unlabel i rregular m ultimodal E HRs, named PRIME. We first utilize a multi-element encoding module to extract patient condition snapshots from both modalities. Then, to construct multiple aligned cross-modal positive sample pairs that span the entire treatment process from irregular data, we employ patient condition alignment modules that integrate time-aware and feature-aware components to transfer snapshots to the aligned timestamps. Next, to preserve both shared and unique information of each modality, our decoupled representation learning strategy first uses a constraint matrix to separate shared information. We then employ contrastive-based cross-modal learning and reconstruction-based intra-modal learning to model shared and complete information, respectively. Extensive experiments on two real-world tasks demonstrate the superiority of PRIME over the state-of-the-art models, especially with limited labels.},
  archive      = {J_TKDD},
  author       = {Bohao Li and Bowen Du and Junchen Ye},
  doi          = {10.1145/3744251},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {PRIME: Pretraining for patient condition representation with irregular multimodal electronic health records},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards sequence utility maximization under utility occupancy measure. <em>TKDD</em>, <em>19</em>(7), 1-27. (<a href='https://doi.org/10.1145/3744344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of utility-driven patterns is a valuable and difficult research topic. It can extract significant and interesting information from specific and varied databases, increasing the value of the services provided. In practice, the utility measure is often used to reflect the importance, profit, or risk of an object or pattern. In the database, while utility is a flexible criterion for patterns, it is also a somewhat limited criterion due to the overlook of utility sharing. This leads to the derived patterns only exploring partial and local knowledge in the database. Utility occupancy considers the problem of mining with high utility but low occupancy. However, existing studies are focused on itemsets that cannot reveal the temporal relationship of object occurrences. Therefore, this article first defines the concept of utility occupancy of sequence data and raises the problem of High-Utility Occupancy Sequential Pattern Mining (HUOSPM). Three dimensions, including frequency, utility, and occupancy, are comprehensively evaluated in HUOSPM. An algorithm called Sequence Utility Maximization with Utility occupancy measure (SUMU) is proposed. Furthermore, two data structures for storing pattern-related information, including Utility-Occupancy-List-Chain (UOL-Chain) and Utility-Occupancy-Table (UO-Table), are designed, and six upper bounds are proposed to improve efficiency. Extensive experiments are conducted to evaluate the efficiency and effectiveness of the novel algorithm. A specific case study is provided, and the effects of different upper bounds and pruning strategies are analyzed. The comprehensive results suggest that the HUOSPM task is useful and efficient.},
  archive      = {J_TKDD},
  author       = {Gengsen Huang and Wensheng Gan and Philip S. Yu},
  doi          = {10.1145/3744344},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards sequence utility maximization under utility occupancy measure},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical spatial decompositions under local differential privacy. <em>TKDD</em>, <em>19</em>(7), 1-37. (<a href='https://doi.org/10.1145/3744569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of smartphones, GPS-enabled devices, social networks, and connected vehicles all contribute to the increasing volume of spatial data. Spatial decompositions assist in handling big spatial data, and they have been commonly used in the Differential Privacy (DP) literature for range query answering, spatial indexing, count-of-counts histograms, data summarization, and visualization. However, their applications under the emerging Local DP (LDP) notion are scarce. In this article, we study the problem of building hierarchical spatial decompositions under LDP, focusing on two methods: quadtrees and kd-trees. We develop two solutions for quadtrees: a baseline solution that is inspired by the centralized DP literature, and a proposed solution that utilizes a single data collection step from users, propagates density estimates to remaining nodes, and performs structural corrections to the quadtree. Since kd-trees rely on node medians which are data-dependent, we observe that it is not feasible to build kd-trees using a single data collection step. We therefore propose an iterative solution that constructs kd-trees in top-down fashion by utilizing a novel algorithm for estimating node medians at each tree depth. We experimentally evaluate our quadtree and kd-tree algorithms using four real-world spatial datasets, multiple utility metrics, varying privacy budgets, and tree parameters. Results demonstrate that our algorithms enable the building of accurate spatial decompositions that provide high utility in practice. Notably, our quadtrees and kd-trees achieve substantially lower errors in answering spatial density queries (up to 10-fold improvement) when compared with a state-of-the-art method.},
  archive      = {J_TKDD},
  author       = {Ece Alptekin and Berkay Kemal Balioglu and M. Emre Gursoy},
  doi          = {10.1145/3744569},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hierarchical spatial decompositions under local differential privacy},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the robustness of deep recommendation under adversarial attacks. <em>TKDD</em>, <em>19</em>(7), 1-46. (<a href='https://doi.org/10.1145/3744570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been shown that deep recommendation models are susceptible to adversarial attacks, with this vulnerability potentially leading to significant economic losses in the e-commerce field. However, the robustness of deep recommendation models in response to adversarial attacks has not been systematically investigated. In this article, therefore, we comprehensively evaluate the adversarial robustness of various representative deep models in different settings, aiming to analyze their performance impact under adversarial attacks and compare it with traditional collaborative filtering models. Notably, we examine poisoning attacks under different proportions of fake users and various popularity conditions to understand why certain deep recommendation models perform exceptionally or sub-optimally. On this basis, we further proposed practical robustness improvement strategy for the problems found in the evaluation and fully verified it through rigorous experiments. Key findings include: (1) the sparser the training dataset, the weaker the robustness of a recommendation model’s performance under adversarial attacks; (2) deep recommendation models exhibit greater robustness in recommending popular items under adversarial attacks, while they are more vulnerable when attacked with non-popular items; (3) the robustness of deep recommendation models is not consistently weaker than that of traditional collaborative filtering models across all attack settings. These findings highlight the security concerns in deep recommendation systems and contribute to developing more reliable models.},
  archive      = {J_TKDD},
  author       = {Fulan Qian and Wenbin Chen and Hai Chen and Yan Cui and Shu Zhao and Yanping Zhang},
  doi          = {10.1145/3744570},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-46},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding the robustness of deep recommendation under adversarial attacks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive fusion label enhancement for multi-label learning. <em>TKDD</em>, <em>19</em>(7), 1-23. (<a href='https://doi.org/10.1145/3744571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Label Learning (MLL) involves the task of assigning a set of relevant labels to a given instance. Recently, Label Enhancement (LE) has gained significant attention in various MLL tasks, as it allows for effective mining the implicit relative importance information of different labels. However, in existing LE-based MLL methods, the LE process is decoupled from the MLL process. Consequently, the label distribution recovered by the LE process may not be suitable for training the predictive model, thus affecting the overall learning system. In this study, we propose a novel approach named interactive Fusion Label Enhancement for Multi-Label Learning ( Flem ) that seamlessly integrates the LE process with the MLL process. Specifically, we introduce a matching and interaction mechanism comprising a novel interaction label enhancement loss and a contrastive alignment approach to prevent object mismatch. Furthermore, we present a unified label distribution loss that establishes the relationship between the recovered label distribution and the training of the predictive model. By leveraging these losses, the label distributions obtained from the LE process can be efficiently utilized for training the predictive model. Experimental results on multiple benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDD},
  author       = {Xingyu Zhao and Yuexuan An and Ning Xu and Lei Qi and Xin Geng},
  doi          = {10.1145/3744571},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Interactive fusion label enhancement for multi-label learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Framework for variable-lag motif following relation inference in time series using matrix profile analysis. <em>TKDD</em>, <em>19</em>(7), 1-24. (<a href='https://doi.org/10.1145/3744652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing who follows whom and what patterns they are following are crucial steps to understand collective behaviors (e.g., a group of human, a school of fish, or a stock market). Time series is one of the resources that can be used to get insight regarding following relations. However, the concept of following patterns or motifs and the solution to find them in time series are not obvious. In this work, we formalize a concept of following motifs between two time series and present a framework to infer following patterns between two time series. The framework utilizes one of the efficient and scalable methods to retrieve motifs from time series called the Matrix Profile Inference Method. We compare our proposed framework with several baselines. The framework performs better than baselines in the simulation datasets. In the dataset of sound recording, the framework is able to retrieve the following motifs within a pair of time series in which two singers sing following each other. In the cryptocurrency dataset, the framework is capable of capturing the following motifs within a pair of time series from two digital currencies, which implies that the values of one currency follow the values of another currency patterns. Our framework can be utilized in any field of time series to get insight regarding following patterns between time series. The code and datasets can be found at https://github.com/hughnaaek/Following-Motif-Relation .},
  archive      = {J_TKDD},
  author       = {Naaek Chinpattanakarn and Chainarong Amornbunchornvej},
  doi          = {10.1145/3744652},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Framework for variable-lag motif following relation inference in time series using matrix profile analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph fine-grained modeling network with contrastive learning for recommendation. <em>TKDD</em>, <em>19</em>(7), 1-18. (<a href='https://doi.org/10.1145/3744926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is often introduced into recommendation systems because of its large amount of edge information. The method based on graph neural networks (GNNs) has gradually become the mainstream of KG-aware recommendation. However, traditional KG-aware recommendation models based on GNNs fail to utilize the dependencies of items and item attributes to model user preferences at a fine-grained level, which will result in a lack of interpretability in the model’s recommendations to users. In addition, traditional KG-aware recommendation models based on GNNs fail to mine supervision signals from the perspective of user preferences and item attributes, which will result in a lack of effective supervision signals in the model. In this study, we utilize a combination of items and attributes behind the items to model user preferences at a fine-grained level, so as to achieve independence between different user preferences. Furthermore, we utilize the KG and the user–item interaction graph (UIIG) to construct the user-specific preference similarity view and the item-specific attribute correlation views, respectively, and then apply the contrastive learning framework to effectively mine the association signals between users and between items. Based on this, we propose a novel model named Knowledge Graph Fine-grained Modeling Network with Contrastive Learning (KGFM-CL). Extensive experiments conducted on two real-world datasets demonstrate that KGFM-CL significantly outperforms state-of-the-art baseline models.},
  archive      = {J_TKDD},
  author       = {Xiya Bu and Yu Liu},
  doi          = {10.1145/3744926},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge graph fine-grained modeling network with contrastive learning for recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Raker: A relation-aware knowledge reasoning model for inductive relation prediction. <em>TKDD</em>, <em>19</em>(7), 1-20. (<a href='https://doi.org/10.1145/3745029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive relation prediction, an important task for knowledge graph completion, is to predict the relations between entities that are unseen at the training stage. The latest methods use Pre-Trained Language Models (PLMs) to encode the paths between the head entity and tail entity and achieve state-of-the-art prediction performance. However, these methods cannot handle no-path scenarios well and lack the capability to learn comprehensive relation representations for distinguishing different relations. To tackle this issue, we propose a novel R elation- a ware k nowledg e r easoning model entitled Raker, which introduces an adaptive reasoning information extraction method to identify relation-aware reasoning neighbors of entities in the target triple to handle no-path scenarios and enables the PLM to better distinguish different relations via the relation-specific soft prompting. Raker is evaluated on three public datasets and achieves SOTA performance in inductive relation prediction when compared with the baseline methods. Notably, the absolute improvement of Raker is even more than 5% on the FB15k-237 dataset in the inductive setting. Moreover, Raker also demonstrates the superiority in transductive, few-shot, and unseen relation settings. The code of Raker is available at https://github.com/ADMIS-TONGJI/Raker .},
  archive      = {J_TKDD},
  author       = {Jiaqi Wang and Wengen Li and Yulou Shu and Jihong Guan and Yichao Zhang and Shuigeng Zhou},
  doi          = {10.1145/3745029},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Raker: A relation-aware knowledge reasoning model for inductive relation prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards recommendation on good quality data science solutions. <em>TKDD</em>, <em>19</em>(7), 1-19. (<a href='https://doi.org/10.1145/3746235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science aims to solve real-world problems with the knowledge derived from data. Successfully tackling a data science problem requires practitioners to choose an appropriate solution, which potentially comprises various components such as pre-processing techniques, learning algorithms, hyper-parameters, and so on. Therefore, a problem-driven recommendation for the promising solution is invaluable, as it facilitates efficient and convenient problem-solving. However, existing solution recommendation approaches confront notable challenges when dealing with limited and sparse prior experience in practical applications. Learning from such prior easily leads to overfitting and poor generalization in solution recommendations. To address this issue, we propose a novel solution recommendation method that can predict a good-quality data science solution, including the pre-processing, the learning algorithm, and hyper-parameters, for a given problem. The foundation of our method is a carefully designed ranking model that exploits a weight-sharing structure and a newly proposed loss. The ranking model focuses on incorporating relative ranking information into the predicted performance score of each solution. With these techniques, our method can recommend the solution with the highest score and effectively mitigate the limitations of using sparse prior experience. Our experiments demonstrate the superiority of our method in predicting solutions with higher accuracy and rank, even trained on highly sparse historical performance records. It also reduces recommendation time significantly compared to the baselines, offering remarkable efficiency and convenience for practitioners.},
  archive      = {J_TKDD},
  author       = {Jian Chen and Yile Chen and Zeyi Wen and Yawen Chen and Jin Huang},
  doi          = {10.1145/3746235},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards recommendation on good quality data science solutions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly supervised open-domain aspect-based sentiment analysis. <em>TKDD</em>, <em>19</em>(7), 1-29. (<a href='https://doi.org/10.1145/3747849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Analysis (ABSA) comprises several subtasks: aspect term extraction (ATE), opinion term extraction (OTE), aspect term sentiment extraction (ATSE), aspect-opinion pair extraction (AOPE), and aspect sentiment triplet extraction (ASTE). Existing unified frameworks for ABSA rely heavily on large-scale annotated data, limiting scalability across domains. We propose UAOS, a double-layer unified span extraction framework that performs all five ABSA subtasks under weak supervision. Our approach first extracts aspect-opinion pairs using universal dependency-based rules from unannotated corpora. Sentiment labels for these pairs are generated via a novel zero-shot, domain-agnostic prompt-based method. The resulting weak labels train a unified span extraction architecture equipped with canonical correlation analysis for early stopping and a self-training mechanism to mitigate noise and bias in supervision. Extensive experiments on four ABSA benchmarks demonstrate that UAOS achieves competitive or superior performance compared to fully supervised baselines. It improves upon the state-of-the-art ODAO by +1.54 F1 for ATE, +0.56 for OTE, and +0.82 for AOPE. In ATSE and ASTE, where no weakly supervised baselines exist, UAOS outperforms several supervised models, setting new benchmarks. To assess domain generalizability, we evaluate UAOS on a psychology/education-domain dataset of student reflections spanning four instructional conditions. Without in-domain fine-tuning, it achieves macro F1 scores of 71.05 (ATE), 74.39 (OTE), 68.24 (AOPE), and 60.56 (ASTE). These results highlight the model’s ability to generalize to out-of-distribution, non-commercial text, underscoring its scalability for low-resource ABSA applications.},
  archive      = {J_TKDD},
  author       = {Mohna Chakraborty and Adithya Kulkarni and Qi Li},
  doi          = {10.1145/3747849},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Weakly supervised open-domain aspect-based sentiment analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal data mining for ocean science: Data, methodologies and opportunities. <em>TKDD</em>, <em>19</em>(7), 1-47. (<a href='https://doi.org/10.1145/3748259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid amassing of spatial-temporal (ST) ocean data, many spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, including climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data presents some unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models on ST ocean data. To the best of our knowledge, a comprehensive survey of existing studies remains missing in the literature, which hinders not only computer scientists from identifying the research issues in ocean data mining but also ocean scientists to apply advanced STDM techniques. In this article, we provide a comprehensive survey of existing STDM studies for ocean science. Concretely, we first review the widely used ST ocean datasets and highlight their unique characteristics. Then, typical ST ocean data quality enhancement techniques are discussed. Next, we classify existing STDM studies for ocean science into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks. Finally, promising research opportunities are discussed. This survey can help scientists from both computer science and ocean science better understand the fundamental concepts, key techniques, and open challenges of STDM for ocean science.},
  archive      = {J_TKDD},
  author       = {Hanchen Yang and Jiannong Cao and Wengen Li and Shuyu Wang and Hui Li and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1145/3748259},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-47},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Spatial-temporal data mining for ocean science: Data, methodologies and opportunities},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What are anomalies in a network?. <em>TKDD</em>, <em>19</em>(6), 1-34. (<a href='https://doi.org/10.1145/3723007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines a collection of assumptions used in the current literature on node anomaly detection in a network. The examination raises the question: What are anomalies in a network? Our attempt to answer this question has provided some interesting findings and led to some open questions. This is the first article which formally defines anomalies in a network and introduces the concept of self-verifiability of a detector without ground-truths in a network. They enable existing detectors to be categorized into two types along the line whether they are self-verifiable or not. We suggest a method to evaluate self-verifiable detectors without ground-truths as an alternative to the existing evaluation method that relies on ground-truths.},
  archive      = {J_TKDD},
  author       = {Kai Ming Ting and Zhong Zhuang and Guansong Pang and Zongyou Liu and Tianrun Liang and Qiuran Zhao},
  doi          = {10.1145/3723007},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-34},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {What are anomalies in a network?},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring and exploiting data heterogeneity in recommendation. <em>TKDD</em>, <em>19</em>(6), 1-34. (<a href='https://doi.org/10.1145/3737290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive amounts of data are the foundation of data-driven recommendation models. As an inherent nature of big data, data heterogeneity widely exists in real-world recommendation systems. It reflects the differences in the properties among sub-populations. Ignoring the heterogeneity in recommendation data could mislead the models, hurt the sub-populational robustness, and finally limit the performance of recommendation models. However, data heterogeneity has not received substantial attention within the recommendation community, prompting us to adequately explore and exploit data heterogeneity to solve these challenges and enhance data analysis. In this study, we specifically focus on two representative categories of heterogeneity in recommendation data: heterogeneity of prediction mechanism and covariate distribution. To explore the data heterogeneity, we propose an algorithm based on bilevel clustering. Additionally, we demonstrate how the explored data heterogeneity can be exploited for prediction and debias in recommendation scenarios, specifically by building models using multiple sub-models and augmenting the propensity score estimation. Extensive experiments conducted on real-world data substantiate the existence of heterogeneity in recommendation data and validate the effectiveness of exploring and exploiting data heterogeneity in improving recommendation performance.},
  archive      = {J_TKDD},
  author       = {Zimu Wang and Jiashuo Liu and Hao Zou and Xingxuan Zhang and Yue He and Dongxu Liang and Peng Cui},
  doi          = {10.1145/3737290},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-34},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploring and exploiting data heterogeneity in recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep code search with naming-agnostic contrastive multi-view learning. <em>TKDD</em>, <em>19</em>(6), 1-26. (<a href='https://doi.org/10.1145/3737878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software development is a repetitive task, as developers usually reuse or get inspiration from existing implementations. Code search, which refers to the retrieval of relevant code snippets from a codebase according to the developer’s intent that has been expressed as a query, has become increasingly important in the software development process. Due to the success of deep learning in various applications, a great number of deep learning-based code search approaches have sprung up and achieved promising results. However, developers may not follow the same naming conventions and the same variable may have different variable names in different implementations, bringing a challenge to deep learning-based code search methods that rely on explicit variable correspondences to understand source code. To overcome this challenge, we propose a Naming-Agnostic Code Search (NACS) method based on contrastive multi-view code representation learning. NACS strips information bound to variable names from Abstract Syntax Tree (AST), the representation of the abstract syntactic structure of source code, and focuses on capturing intrinsic properties solely from AST structures. We use semantic-level and syntax-level augmentation techniques to prepare realistically rational data and adopt contrastive learning to design a graph-view modeling component in NACS to enhance the understanding of code snippets. We further model ASTs in a path view to strengthen the graph-view modeling component through multi-view learning. Extensive experiments show that NACS provides superior code search performance compared to baselines and NACS can be adapted to help existing code search methods overcome the impact of different naming conventions. Our implementation is available at https://github.com/KDEGroup/NACS .},
  archive      = {J_TKDD},
  author       = {Jiadong Feng and Wei Li and Suhuang Wu and Zhao Wei and Yong Xu and Juhong Wang and Hui Li},
  doi          = {10.1145/3737878},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deep code search with naming-agnostic contrastive multi-view learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subgraph federated learning with information bottleneck constrained generative learning. <em>TKDD</em>, <em>19</em>(6), 1-23. (<a href='https://doi.org/10.1145/3737879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a groundbreaking approach that enables multiple clients to jointly train deep learning models by pooling their data, while addressing privacy and bandwidth issues that prevent direct data sharing. This approach is particularly suitable for building strong and widely applicable graph models, given the increasing amounts of graph data stored across different locations. However, FL for subgraph models faces significant challenges, such as the diversity of data and the risk of attacks, which can affect the strength and reliability of these models. In response to these challenges, our research delves into the complexities of FL for subgraphs from an information theory perspective. We identify a major issue that affects the performance of graph models: the bias in the optimization goal of the commonly used FedAVG training method. To address this, we propose InfoFedGNN, an innovative FL framework for subgraphs that is based on the Information Bottleneck principle. InfoFedGNN is designed to overcome the problem of Non-Independent and Identically Distributed (non-i.i.d.) data in FL and to significantly improve its defense against security threats. Our thorough evaluation of InfoFedGNN on five public datasets, with both uniform and diverse data distributions, highlights its improved defense capabilities and better training outcomes. These results confirm the effectiveness of InfoFedGNN in enhancing the security and efficiency of FL, demonstrating its potential to push forward the development of federated graph models.},
  archive      = {J_TKDD},
  author       = {Shangyang Li and Jiayan Guo},
  doi          = {10.1145/3737879},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Subgraph federated learning with information bottleneck constrained generative learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DisambiguART: A neural-based inference model for knowledge graph disambiguation. <em>TKDD</em>, <em>19</em>(6), 1-29. (<a href='https://doi.org/10.1145/3737880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One main challenge in constructing a Knowledge Graph (KG) is to deal with ambiguity. Specifically, an entity in the graph can be assigned with multiple meanings while two or more entities considered to have different meanings may actually be the same. Assigning an entity with the correct meaning may involve re-evaluation of its relevant contexts. This costly operation typically involves searching for other similar entities within the KG such that the context can be determined. In this article, a new model called DisambiguART is proposed leveraging multi-channel matching and inference in a self-organizing neural network for sense disambiguation in KGs. Unlike other disambiguation methods that rely on representation learning to identify the relevant contexts whereby similarities among entities are learned, DisambiguART extends the working principle of multi-channel Adaptive Resonance Theory (ART) to conduct inferences directly over the graph representation through bi-directional interactions of bottom-up activations and top-down matching to find similar entities and select the correct meaning according to the right context. The proposed method is evaluated on the tasks of entity sense disambiguation in three domain KGs (jet engine, biomedical, and kinship) and author name disambiguation in bibliographic KGs, demonstrating the effectiveness and efficiency of DisambiguART against the state-of-the-art methods.},
  archive      = {J_TKDD},
  author       = {Budhitama Subagdja and D. Shanthoshigaa and Ah-Hwee Tan},
  doi          = {10.1145/3737880},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DisambiguART: A neural-based inference model for knowledge graph disambiguation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed keyword-guided topic model with lexical knowledge supervision. <em>TKDD</em>, <em>19</em>(6), 1-19. (<a href='https://doi.org/10.1145/3737881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models are often used to discover latent semantic patterns from document collections. However, existing unsupervised approaches have the following drawbacks: (1) The mined topics may not match user interests; (2) They are prone to extract semantically similar topics and sacrifice diversity; (3) The mined topics often have low interpretability, which does not meet common sense knowledge. To address these limitations, we propose the Distributed Keyword-guided Topic Model (DiskTM) that incorporates Gaussian-distributed keyword prior knowledge into the modeling process to mine user-interested topics. Furthermore, to inject common-sense knowledge and improve the topic’s interpretability, we extend DiskTM and propose the Distributed Keyword-guided Topic Model with Lexical Knowledge (DiskTM-LK). Experimental results on three publicly available text corpora show that our proposed approaches could extract topics that match user interests (keywords). Moreover, DiskTM and DiskTM-LK could also obtain more coherent and diverse topics, outperforming the state-of-the-art baseline approaches.},
  archive      = {J_TKDD},
  author       = {Rui Wang and Yanan Wang and Ziang Li and Haitao Cheng and Guozi Sun},
  doi          = {10.1145/3737881},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Distributed keyword-guided topic model with lexical knowledge supervision},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion models for tabular data imputation and synthetic data generation. <em>TKDD</em>, <em>19</em>(6), 1-32. (<a href='https://doi.org/10.1145/3742435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imputation and data generation have important applications across many domains where incomplete or missing data can hinder accurate analysis and decision-making. Diffusion models have emerged as powerful generative models capable of capturing complex data distributions across various data modalities such as image, audio, and time series. Recently, they have been also adapted to generate tabular data. In this article, we propose a diffusion model for tabular data that introduces three key enhancements: (1) a conditioning attention mechanism, (2) an encoder–decoder transformer as the denoising network, and (3) dynamic masking. The conditioning attention mechanism is designed to improve the model’s ability to capture the relationship between the condition and synthetic data. The transformer layers help model interactions within the condition (encoder) or synthetic data (decoder), while dynamic masking enables our model to efficiently handle both missing data imputation and synthetic data generation tasks within a unified framework. We conduct a comprehensive evaluation by comparing the performance of diffusion models with transformer conditioning against state-of-the-art techniques such as Variational Autoencoders, Generative Adversarial Networks, and Diffusion Models, on benchmark datasets. Our evaluation focuses on the assessment of the generated samples with respect to three important criteria, namely: (1) machine learning efficiency, (2) statistical similarity, and (3) privacy risk mitigation. For the task of data imputation, we consider the efficiency of the generated samples across different levels of missing features. The results demonstrate average superior machine learning efficiency and statistical accuracy compared to the baselines, while maintaining privacy risks at a comparable level, particularly showing increased performance in datasets with a large number of features. By conditioning the data generation on a desired target variable, the model can mitigate systemic biases, generate augmented datasets to address data imbalance issues, and improve data quality for subsequent analysis. This has significant implications for domains such as healthcare and finance, where accurate, unbiased, and privacy-preserving data are critical for informed decision-making and fair model outcomes.},
  archive      = {J_TKDD},
  author       = {Mario Villaizán-Vallelado and Matteo Salvatori and Carlos Segura and Ioannis Arapakis},
  doi          = {10.1145/3742435},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Diffusion models for tabular data imputation and synthetic data generation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust distributed estimation for modal regression under least squares approximation. <em>TKDD</em>, <em>19</em>(6), 1-21. (<a href='https://doi.org/10.1145/3742477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive datasets pose a serious challenge to traditional statistical methods. Modal regression has greater robustness and high inference efficiency compared to mean regression and likelihood-based methods. In this article, we present a robust distributed least squares approximation (RDLSA) method for heterogeneously distributed massive datasets under the modal regression framework. Specifically, we first approximate the local objective function for each worker/server/machine by using the Taylor expansion, where it is necessary to remain the main quadratic term. Then, each of local machines calculates their corresponding estimates and uploads them to a master machine for obtaining the approximated aggregated estimator. This process yields a one-step global estimator such that one round of communication is required. Correspondingly, the consistency and asymptotic normality of the estimator are rigorously established under some mild conditions. To further reduce the estimation bias, we perform one Newton-Raphson iteration to obtain a two-step global aggregated estimator. In addition, we develop a variable selection procedure for the distributed modal regression under the robust least squares approximation procedure. Finally, we provide simulation experiments and a real data application to verify the superiority of our method.},
  archive      = {J_TKDD},
  author       = {Zhaodu Zhang and Yue Chao and Xuejun Ma},
  doi          = {10.1145/3742477},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Robust distributed estimation for modal regression under least squares approximation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FeadSeq: A personalized federated anomaly detection framework for discrete event sequences. <em>TKDD</em>, <em>19</em>(6), 1-26. (<a href='https://doi.org/10.1145/3742896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event sequence anomaly detection has garnered considerable attention in research, encompassing applications such as identifying anomalies in system logs, anomalous transaction users, and so on. Yet, prevailing anomaly detection methods often rely solely on local data for training, potentially leading to imperfect detection performance. In this article, we introduce a personalized Federated anomaly detection framework for discrete event Sequences, named FeadSeq. Specifically, we propose a separate architecture for sequence reconstruction networks (SEPRE) which partitions the network into two parts: a shared part and a standalone part, better suited for federated learning schemes. In tandem, we propose a novel partial shared federated learning scheme that employs a mask strategy to alleviate communication overhead and produce personalized local models to address the statistical heterogeneity of data among clients. This scheme dictates that a subset of weights is communicated between clients and servers for collaborative training, while the remaining weights are trained exclusively locally. To evaluate the effectiveness of FeadSeq, we conduct extensive experiments on both system logs and business process event logs. The results affirm the superiority of FeadSeq over existing personalized federated learning algorithms, showcasing not only improved performance but also reduced communication overhead.},
  archive      = {J_TKDD},
  author       = {Wei Guan and Jian Cao and Haiyan Zhao and Yang Gu and Shiyou Qian},
  doi          = {10.1145/3742896},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {FeadSeq: A personalized federated anomaly detection framework for discrete event sequences},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern-based graph classification: Comparison of quality measures and importance of preprocessing. <em>TKDD</em>, <em>19</em>(6), 1-49. (<a href='https://doi.org/10.1145/3743143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification aims to categorize graphs based on their structural and attribute features, with applications in diverse fields such as social network analysis and bioinformatics. Among the methods proposed to solve this task, those relying on patterns (i.e., subgraphs) provide good explainability, as the patterns used for classification can be directly interpreted. To identify meaningful patterns, a standard approach is to use a quality measure, i.e., a function that evaluates the discriminative power of each pattern. However, the literature provides tens of such measures, making it difficult to select the most appropriate for a given application. Only a handful of surveys try to provide some insight by comparing these measures, and none of them specifically focuses on graphs. This typically results in the systematic use of the most widespread measures, without thorough evaluation. To address this issue, we present a comparative analysis of 38 quality measures from the literature. We characterize them theoretically, based on four mathematical properties. We leverage publicly available datasets to constitute a benchmark, and propose a method to elaborate a gold standard ranking of the patterns. We exploit these resources to perform an empirical comparison of the measures, both in terms of pattern ranking and classification performance. Moreover, we propose a clustering-based preprocessing step, which groups patterns appearing in the same graphs to enhance classification performance. Our experimental results demonstrate the effectiveness of this step, reducing the number of patterns to be processed while achieving comparable performance. Additionally, we show that some popular measures widely used in the literature are not associated with the best results.},
  archive      = {J_TKDD},
  author       = {Lucas Potin and Rosa Figueiredo and Vincent Labatut and Christine Largeron},
  doi          = {10.1145/3743143},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {6},
  pages        = {1-49},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Pattern-based graph classification: Comparison of quality measures and importance of preprocessing},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic study and analysis of graph neural networks under noise. <em>TKDD</em>, <em>19</em>(6), 1-20. (<a href='https://doi.org/10.1145/3733605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown superb performance in handling networked data, mainly attributed to their message passing and convolution process across neighbors. For most literature, the performance of GNNs is mainly reported based on noise-free data environments. No study has systematically evaluated GNNs’ performance under noise. In this article, we carry out an empirical study and theoretical analysis of four types of GNNs, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Contrastive Networks (GCL), and graph UniFilter under three types of noise, including attribute noise, structure noise, and label noise. Our study shows that GNNs behave tremendously differently in response to different types of noise. Overall, GAT is the most noise vulnerable and sensitive, whereas GCL is the most noise resilient. We further carry out theoretical analysis to explain the reason causing GAT to be sensitive to noise, and propose a solution to enhance its noise resilience. Our study brings in-depth firsthand knowledge of GNNs under noise for researchers and practitioners to better utilize GNNs in real-world applications.},
  archive      = {J_TKDD},
  author       = {Yufei Jin and Xingquan Zhu},
  doi          = {10.1145/3733605},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A systematic study and analysis of graph neural networks under noise},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online learning for noisy labeled streams. <em>TKDD</em>, <em>19</em>(6), 1-29. (<a href='https://doi.org/10.1145/3734875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online learning, characterized by its feature space’s adaptability over time, has emerged as a flexible learning paradigm that has attracted widespread attention. However, existing online learning methods often overlook the distributional differences between instances and the presence of label noise in streaming data, thus significantly hindering the effectiveness and robustness of these algorithms. To overcome these challenges, we propose an online confidence learning algorithm for noisy labeled features, which aims to achieve robustness against arbitrary data streams and noisy labels. It employs two new strategies: online confidence inference, which applies the principle of empirical risk minimization to identify inconsistencies in spatial distributions, and geometric structure learning, which utilizes dynamic instance confidence to compute disparities between instances and their labels. Empirical findings demonstrate that our label correction mechanism enhances classification accuracy more effectively across various types of noisy labels (i.e., symmetric, asymmetric, and flipped). Additionally, a case study on image datasets was conducted to illustrate in detail the effectiveness of our OLNLS algorithm. Code is released in https://github.com/Zhuosd/OLNLS .},
  archive      = {J_TKDD},
  author       = {Jinjie Qiu and Shengda Zhuo and Philip S. Yu and Changdong Wang and Shuqiang Huang},
  doi          = {10.1145/3734875},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online learning for noisy labeled streams},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining linguistic styles in bilateral matching: A contrastive learning approach to reciprocal recommendation. <em>TKDD</em>, <em>19</em>(6), 1-25. (<a href='https://doi.org/10.1145/3736418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reciprocal recommendation systems are crucial for online dating platforms to provide quality matches and reduce choice overload. However, the design of reciprocal recommendation systems grapples with the challenges of estimating interpersonal compatibility and predicting the likelihood that two prospective partners will accept each other. Furthermore, despite the crucial role of users’ linguistic styles in determining user match decision-making, the contemporary design of such recommendation systems has not yet effectively incorporated this information. To bridge these gaps, we develop an end-to-end personalized Linguistic Style Matching-based Reciprocal Recommendation System (LS-RRS). We propose cross-user and within-user contrastive learning strategies combined with random masking to extract users’ linguistic styles and further integrate visual and textual information using an efficient convolution block. LS-RRS further models the matching probability using a conditional probability function and introduces a preference inflation factor on the receiver side to account for the asymmetric roles of the bilateral sides. The proposed model addresses the challenge of incorporating users’ linguistic styles into reciprocal recommendation and details the modeling of the two-stage matching process. Extensive experiments show that LS-RRS outperforms state-of-the-art models in recommendation performance, with a 29.35% increase in NDCG@10 when incorporating linguistic styles. Our follow-up analyses further validate the importance and effectiveness of the linguistic style extraction design through word-level and sentence-level visualizations, as well as qualitative case studies. This research contributes to the literature on reciprocal recommendation and offers a viable solution for alleviating user choice overload on online dating platforms.},
  archive      = {J_TKDD},
  author       = {Yue Guan and Yumei He and Ni Huang and Xunhua Guo and Guoqing Chen},
  doi          = {10.1145/3736418},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mining linguistic styles in bilateral matching: A contrastive learning approach to reciprocal recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient framework for epidemiological parameter estimation via graph reduction and graph neural networks. <em>TKDD</em>, <em>19</em>(6), 1-29. (<a href='https://doi.org/10.1145/3736727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an epidemiological parameter estimation framework based on contact networks and graph neural networks (GNNs). Contact network-based epidemiological models allow us to capture heterogeneity and individual-level details more effectively. Parameter estimation involves fitting real-world disease data to mathematical models. Traditionally, several likelihood-based methods that focus on compartment-based simulation models have been widely used to perform parameter estimation. However, these methods suffer from making assumptions such as homogeneous traits among the individuals of the population under consideration, which may cause them to fail in handling the complexity and diversity of real-world data. Our proposed framework estimates epidemiological parameters based on the availability of contact network data and individual-level disease time series data. We use supervised as well as self-supervised GNN architectures to incorporate the contact network information into the model. We also employed graph reduction methods such as sampling and coarsening to study scaling behavior and computational efficiency. We formulated the parameter estimation in two ways to study the predictive behavior better: classification and inference problems. We experimentally confirm improvements over the baselines chosen in this article. We also conducted ablation studies, explainability quantification, and scalability experiments to generate further insights into the GNN models.},
  archive      = {J_TKDD},
  author       = {Muhammad Alfas and Manoj Kumar and Shaurya Shriyam and Sandeep Kumar},
  doi          = {10.1145/3736727},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An efficient framework for epidemiological parameter estimation via graph reduction and graph neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A relation-constraint link prediction model for dynamic knowledge graphs with entity drift. <em>TKDD</em>, <em>19</em>(5), 1-38. (<a href='https://doi.org/10.1145/3725815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) often suffer from incompleteness and this issue motivates the task of Knowledge Graph Completion (KGC). Traditional KGC models mainly concentrate on static KGs with a fixed set of entities and relations, or dynamic KGs with temporal characteristics, faltering in their generalization to constantly evolving KGs with possible irregular entity drift. Thus, in this article, we propose a novel link prediction model based on the embedding representation to handle the incompleteness of KGs with entity drift, termed as DCEL. Unlike traditional link prediction, DCEL could generate precise embeddings for drifted entity without imposing any regular temporal characteristic. The drifted entity is added into the KG with its links to the existing entity predicted in an incremental fashion with no requirement to retrain the whole KG for computational efficiency. In terms of DCEL model, it fully takes advantages of unstructured textual description, and is composed of four modules, namely Machine Reading Comprehension (MRC), Relation Constraint Attentive Aggregator (RCAA), Relation-Specific Alignment (RSA), and Relation Constraint Embedding Optimization (RCEO). Specifically, the MRC module is first employed to extract short texts from long and redundant descriptions. Then, RCAA is used to aggregate the embeddings of textual description of drifted entity and the pre-trained word embeddings learned from corpus to a single text-based entity embedding while shielding the impact of noise and irrelevant information. After that, RSA is applied to align the text-based entity embedding to graph-based space to obtain the corresponding graph-based entity embedding, and then the learned embeddings are fed into the gate structure to be optimized based on the RCEO to improve the accuracy of representation learning. Finally, the graph-based model TransE is used to perform link prediction for drifted entity. Extensive experiments conducted on benchmark datasets in terms of evaluation protocols of MRR and Hits@ k reveal the superiority of DCEL model compared to its SOTAs.},
  archive      = {J_TKDD},
  author       = {Xiulin Zheng and Peipei Li and Zan Zhang and Jia Wu and Xindong Wu},
  doi          = {10.1145/3725815},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A relation-constraint link prediction model for dynamic knowledge graphs with entity drift},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tapping the potential of large language models as recommender systems: A comprehensive framework and empirical analysis. <em>TKDD</em>, <em>19</em>(5), 1-51. (<a href='https://doi.org/10.1145/3726871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Large Language Models (LLMs) such as ChatGPT have showcased remarkable abilities in solving general tasks, demonstrating the potential for applications in recommender systems. To assess how effectively LLMs can be used in recommendation tasks, our study primarily focuses on employing LLMs as recommender systems through prompt engineering. We propose a general framework for leveraging LLMs in recommendation tasks, focusing on the capabilities of LLMs as recommenders. To conduct our analysis, we formalize the input of LLMs for recommendation into natural language prompts with two key aspects and explain how our framework can be generalized to various recommendation scenarios. As for the use of LLMs as recommenders, we analyze the impact of public availability, tuning strategies, model architecture, parameter scale, and context length on recommendation results based on the classification of LLMs. As for prompt engineering, we further analyze the impact of four important components of prompts, i.e., task descriptions, user interest modeling, candidate items construction, and prompting strategies. In each section, we first define and categorize concepts in line with the existing literature. Then, we propose inspiring research questions followed by detailed experiments on two public datasets, in order to systematically analyze the impact of different factors on recommendation performance. Based on our empirical analysis, we finally summarize promising directions to shed lights on future research.},
  archive      = {J_TKDD},
  author       = {Lanling Xu and Junjie Zhang and Bingqian Li and Jinpeng Wang and Sheng Chen and Wayne Xin Zhao and Ji-Rong Wen},
  doi          = {10.1145/3726871},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-51},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Tapping the potential of large language models as recommender systems: A comprehensive framework and empirical analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDphormer: Beyond homophily with feature-difference position encoding. <em>TKDD</em>, <em>19</em>(5), 1-19. (<a href='https://doi.org/10.1145/3727882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformers have garnered significant attention due to their ability to address the challenges of long-distance interactions in previous GNNs. However, most current graph Transformers face difficulties when dealing with heterophilic graphs. To investigate this issue, we first analyzed the distribution of attention weights for homophilic and heterophilic graphs. We discovered that heterophily interferes with the allocation of attention weights, leading to errors in node classification. Further investigation revealed that the root cause may be the difficulty of current graph Transformers in capturing the difference between the features of each node and its neighbors. To alleviate this issue, we propose a position encoding strategy called DiSP to better capture the feature difference and introduce FDphormer, a new efficient and simple graph Transformer model based on DiSP. Additionally, we analyze the generalization error of existing graph Transformer models and provide an upper bound on the generalization error of current graph Transformers with the introduction of DiSP. Extensive experiments demonstrate that FDphormer not only outperforms state-of-the-art methods on diverse heterogeneous datasets but also exhibits competitive performance under homophily.},
  archive      = {J_TKDD},
  author       = {Dong Li and Aijia Zhang and Huan Xiong and Biqing Qi and Junqi Gao},
  doi          = {10.1145/3727882},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {FDphormer: Beyond homophily with feature-difference position encoding},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking natural language generation with layer-wise multi-view decoding. <em>TKDD</em>, <em>19</em>(5), 1-25. (<a href='https://doi.org/10.1145/3729536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural language generation, language models, particularly those based on decoder-only architectures as in popular Large Language Models (LLMs), have demonstrated impressive performance across a wide range of tasks. However, encoder-decoder architectures remain highly effective for tasks involving non-text data, such as images and time-series data. The decoder relies on the attention mechanism to efficiently extract information from the encoder. While it is common practice to draw information from only the last encoder layer, this might lead to insufficient training of the encoder layer stack due to the hierarchy bypassing problem. In this work, we propose layer-wise multi-view decoding for improved encoder-decoder language models, where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source inputs. Systematic experiments and analyses show that we successfully address the hierarchy bypassing problem, require almost negligible parameter increase, and improve the performance of sequence learning with deep representations on diverse tasks, i.e., machine translation, abstractive summarization, image captioning, video captioning, medical report generation, and paraphrase generation. In particular, our approach achieves new state-of-the-art results on benchmark datasets, including a low-resource machine translation dataset and low-resource medical report generation datasets.},
  archive      = {J_TKDD},
  author       = {Fenglin Liu and Xuancheng Ren and Guangxiang Zhao and Chenyu You and Sherry Ma and Xian Wu and Wei Fan and Xu Sun},
  doi          = {10.1145/3729536},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Rethinking natural language generation with layer-wise multi-view decoding},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COLANet: Cross-domain recommender systems with latent overlapping items on graph neural networks. <em>TKDD</em>, <em>19</em>(5), 1-33. (<a href='https://doi.org/10.1145/3730404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommender systems (CDRSs) enhance recommendations by transferring knowledge of overlapping users across two domains. Deep canonical correlation analysis (DCCA) shows promising results in CDRSs by maximizing correlations between representations of overlapping users, enabling cross-domain knowledge transfer that depends on the degree of relationship between domains. As a result, DCCA selectively shares only relevant knowledge, alleviating the problem of noisy representation found in traditional CDRSs, where they transfer knowledge regardless of the correlation strength between domains. Although DCCA is used for user transfer, item transfer, referring to the transfer of explicit knowledge of the same items between domains, is impossible due to the absence of overlapping items to facilitate direct knowledge transfer. Meanwhile, graph neural networks (GNNs) embed users and items from separate user and item graphs in each domain. Therefore, better representations are obtained from captured complex relationships and collaborative signals. To construct graphs of overlapping items, latent linkages among items between domains could be discovered by the neural topic model (NTM), forming new graphs representing the latent relationships. Therefore, COLANet, a GNN-based CDRS, is proposed to solve the DCCA limitation on item transfer by proposing the extraction of item representations that do not exist in another domain using latent characteristics. First, user-user graphs are constructed using user similarity, and the item-topic graph is constructed using latent topics learned from item descriptions with NTM. Hence, user and item graphs of each domain are constructed separately, preventing domain relationship misalignment. Second, these graphs are fed to GNN to obtain user and item representations. Third, these representations are fed to DCCA to transfer knowledge between user-user and item-item. Finally, correlated user and item representations of each domain are used to predict ratings. The experiments demonstrate that COLANet outperforms the baselines across four pairs of domains, including both similar and different domains.},
  archive      = {J_TKDD},
  author       = {Pongsakorn Jirachanchaisiri and Saranya Maneeroj and Atsuhiro Takasu},
  doi          = {10.1145/3730404},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {COLANet: Cross-domain recommender systems with latent overlapping items on graph neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intent-aware recommendation based on principal component analysis. <em>TKDD</em>, <em>19</em>(5), 1-21. (<a href='https://doi.org/10.1145/3731761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, exploring user intents allows for a better understanding and exploration of user preferences, thereby improving recommendation performance. However, existing methods for modeling user intents often do so by statically setting the intent count, which can result in redundancy or insufficiency in capturing the full range of user intents. In order to solve this problem, this article proposes a model named Intent-aware Recommendation Based on Principal Component Analysis (Intent PCA) . Intent PCA is a novel application of PCA in the field of recommender systems. This model defines intents as users’ preferences for some specific relations shown on a knowledge graph and constructs a user-relation matrix to calculate users’ preferences for relations. Then PCA is applied on the user-relation matrix to extract user intents. Benefit from good characteristics of PCA, our PCA-based user intent extraction model can comprehensively model user intents while simultaneously avoid intent redundancy. Moreover, by combining the user intents, this article designs an intent-based information propagation method to differentially aggregate information from surrounding neighbor nodes. Experiments conducted on three datasets validate the effectiveness of the proposed Intent PCA model.},
  archive      = {J_TKDD},
  author       = {Yuyan Ai and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1145/3731761},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Intent-aware recommendation based on principal component analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communities in streaming graphs: Small space data structure, benchmark data generation, and linear algorithm. <em>TKDD</em>, <em>19</em>(5), 1-24. (<a href='https://doi.org/10.1145/3735976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying and preserving community structures in a streaming graph is a very challenging task. However, many applications require the identification of these communities in very limited space and time. In this article, we design Community Sketch, a small space data structure that efficiently preserves communities. On query, it provides communities in constant time. With the use of community sketch data structure, a linear streaming community detection algorithm is proposed. Experimental results on the large real-world networks show that our algorithm outperforms other state-of-the-art algorithms in terms of quality metrics (NMI, F1-score, and WCC). Further, we propose an algorithm to produce benchmark network, namely, Temporal Community Benchmark Dataset (TCBD) which contains both true community labels and temporal information of edges. These synthetic networks are used to validate the proposed algorithm.},
  archive      = {J_TKDD},
  author       = {Shubham Gupta and Suman Kundu},
  doi          = {10.1145/3735976},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Communities in streaming graphs: Small space data structure, benchmark data generation, and linear algorithm},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering categorical data via multiple hypothesis testing. <em>TKDD</em>, <em>19</em>(5), 1-31. (<a href='https://doi.org/10.1145/3735977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical data clustering is a fundamental data mining problem, which has been extensively studied during the past decades. To date, many effective clustering algorithms for categorical data are available in the literature. However, almost all existing categorical data clustering algorithms did not address the issue of the statistical significance of detected clusters. In particular, how to assess the statistical significance of a set of non-overlapping categorical clusters still remains unaddressed. In this article, we formulate the categorical data clustering problem as a multiple hypothesis testing problem, where the null hypothesis is that each attribute is independent of the given partition of clusters. Then, all individual \(p\) -values from different attributes are integrated to obtain a consensus \(p\) -value through statistical meta-analysis. Thereafter, a significance-based clustering algorithm is proposed in which the combined \(p\) -value is efficiently optimized in an indirectly and incremental manner. Experimental results on 25 real-world datasets demonstrate that our method is capable of achieving comparable performance to state-of-the-art categorical data clustering algorithms. Furthermore, our method has a good capability of determining whether there really exists a clustering structure and assessing whether a given set of clusters is statistically significant.},
  archive      = {J_TKDD},
  author       = {Lianyu Hu and Mudi Jiang and Yan Liu and Quan Zou and Zengyou He},
  doi          = {10.1145/3735977},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Clustering categorical data via multiple hypothesis testing},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond static boundaries: Unraveling temporal overlapping communities with information bottleneck guidance. <em>TKDD</em>, <em>19</em>(5), 1-25. (<a href='https://doi.org/10.1145/3716391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection has gained significant research interest within the data mining field. It involves identifying subsets of nodes with dense internal connections and sparse external connections. Most studies on community detection focus solely on identifying non-overlapping communities in a static graph. However, in practice, communities often overlap, and the structure of the graphs is dynamically evolving. This dynamic nature leads to community changes and poses a significant challenge in detecting overlapping communities on temporal graphs (T-OCD). While graph neural networks have shown great performance in generating node representations for community detection, learning representations that capture temporal graph structures and support overlapping community detection remain an open question. To address these challenges, we present T-OCDIB , a novel approach for T emporal O verlapping C ommunity D etection guided by I nformation B ottleneck. Specifically, we first propose an overlapping community detection approach for static graphs, under the guidance of a community-oriented information bottleneck. This approach allows us to learn discriminative node representations specific to each community, facilitating the detection of overlapping communities. Following this, we extend this method to temporal graphs by presenting a temporal convolution module. This module uses adaptive weight matrices based on evolving graph structures to capture temporal dependencies for community detection. Additionally, to promote smooth transitions between consecutive communities, we introduce a temporal smoothing module to further constrain changes in community structure. We evaluate the proposed approach on both real-world and synthetic temporal networks. Experimental results illustrate the superiority of T-OCDIB over other community detection methods.},
  archive      = {J_TKDD},
  author       = {Moli Lu and Linhao Luo and Xiaofeng Zhang},
  doi          = {10.1145/3716391},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Beyond static boundaries: Unraveling temporal overlapping communities with information bottleneck guidance},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Principled mining, forecasting, and monitoring of honeybee time series with EBV+. <em>TKDD</em>, <em>19</em>(5), 1-30. (<a href='https://doi.org/10.1145/3719014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Honeybees, as natural crop pollinators, play a significant role in biodiversity and food production for human civilization. Bees actively regulate hive temperature (homeostasis) to maintain a colony’s proper functionality. Deviations from usual thermoregulation behavior due to external stressors (e.g., extreme environmental temperature, parasites, pesticide exposure) indicate an impending colony collapse. Anticipating such threats by forecasting hive temperature and finding changes in temperature patterns would allow beekeepers to take early preventive measures and avoid critical issues. In that case, how can we model bees’ thermoregulation behavior for an interpretable and effective hive monitoring system? In this article, we propose the principled Electronic Bee-Veterinarian Plus (EBV+) method based on the thermal diffusion equation and a novel “ sigmoid ” feedback-loop (P) controller for analyzing hive health with the following properties: (i) it is effective on multiple, real-world beehive time sequences (recorded and streaming), (ii) it is explainable with only a few parameters (e.g., hive health factor) that beekeepers can easily quantify and trust, (iii) it issues proactive alerts to beekeepers before any potential issue affecting homeostasis becomes detrimental, and (iv) it is scalable with a time complexity of \(O(t)\) for reconstructing and \(O(t\times m)\) for finding m cuts of a sequence with t time-ticks. Experimental results on multiple real-world time sequences showcase the potential and practical feasibility of EBV+. Our method yields accurate forecasting (up to 72% improvement in RMSE) with up to 600 times fewer parameters compared to baselines (ARX, seasonal ARX, Holt-winters, and DeepAR), as well as detects discontinuities and raises alerts that coincide with domain experts’ opinions. Moreover, EBV+ is scalable and fast, taking less than 1 minute on a stock laptop to reconstruct 2 months of sensor data.},
  archive      = {J_TKDD},
  author       = {Mst Shamima Hossain and Christos Faloutsos and Boris Baer and Hyoseung Kim and Vassilis J. Tsotras},
  doi          = {10.1145/3719014},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Principled mining, forecasting, and monitoring of honeybee time series with EBV+},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SED2AM: Solving multi-trip time-dependent vehicle routing problem using deep reinforcement learning. <em>TKDD</em>, <em>19</em>(5), 1-33. (<a href='https://doi.org/10.1145/3721983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL)-based frameworks, featuring Transformer-style policy networks, have demonstrated their efficacy across various Vehicle Routing Problem (VRP) variants. However, the application of these methods to the Multi-Trip Time-Dependent Vehicle Routing Problem (MTTDVRP) with maximum working hours constraints—a pivotal element of urban logistics—remains largely unexplored. This article introduces a DRL-based method called the Simultaneous Encoder and Dual Decoder Attention Model (SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The proposed method introduces a temporal locality inductive bias to the encoding module of the policy networks, enabling it to effectively account for the time dependency in travel distance/time. The decoding module of SED2AM includes a vehicle selection decoder that selects a vehicle from the fleet, effectively associating trips with vehicles for functional multi-trip routing. Additionally, this decoding module is equipped with a trip construction decoder leveraged for constructing trips for the vehicles. This policy model is equipped with two classes of state representations, fleet state, and routing state, providing the information needed for effective route construction in the presence of maximum working hours constraints. Experimental results using real-world datasets from two major Canadian cities not only show that SED2AM outperforms the current state-of-the-art DRL-based and metaheuristic-based baselines but also demonstrate its generalizability to solve larger scale problems.},
  archive      = {J_TKDD},
  author       = {Arash Mozhdehi and Yunli Wang and Sun Sun and Xin Wang},
  doi          = {10.1145/3721983},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SED2AM: Solving multi-trip time-dependent vehicle routing problem using deep reinforcement learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep disease label-guided graph convolutional network for medical report generation. <em>TKDD</em>, <em>19</em>(5), 1-23. (<a href='https://doi.org/10.1145/3722226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical report generation which extracts pathological information within medical images and subsequently produces diagnostic text autonomously aims to alleviate the workload of medical experts and offers auxiliary support in diagnoses. Despite some preliminary progress have been made, several limitations still persist, including lack of specificity in extracted visual features, insufficient consideration of cross-modal alignment and extensive preparatory work required for prior knowledge. To address these issues, we, in this article, propose a novel deep label-guided graph convolutional network for medical report generation which utilizes disease label to guide to extract pathological information from medical images. To be specific, we first construct graph convolutional network to guide the model to extract the specific visual features based on disease labels, which allowing us to selectively extract disease specificity information resided in medical images. Then, we develop cross-modal alignment module to guide the alignment across medical image, diagnose report and disease label, which enables more accurate generation with more precise description. Besides, we build pre-constructed relational matrix to guide report generation model to learn the relationship between visual features and disease types with minimal additional workload to further reduce intensive workload. Extensive experiments on three benchmark datasets, i.e., IU X-ray, MIMIC-CXR, and COV-CTR, demonstrate that the proposed method outperforms the recent state-of-the-art medical report generation methods. Ours shows a 9.2% improvement in BLEU-4 score on the IU X-ray dataset, and both BLEU-4 and CIDEr scores improve by 6.31% on the MIMIC-CXR dataset. Additionally, the results show that it can be easily to applied and extended to medical image report generation with different modalities.},
  archive      = {J_TKDD},
  author       = {Liming Xu and Yongheng Wang and Chunlin He and Quan Tang and Xianhua Zeng and Jiancheng Lv},
  doi          = {10.1145/3722226},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deep disease label-guided graph convolutional network for medical report generation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MA-GCL4SR: Improving graph contrastive learning-based sequential recommendation with model augmentation. <em>TKDD</em>, <em>19</em>(5), 1-21. (<a href='https://doi.org/10.1145/3722561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation (SR) has leveraged the advantages of graph contrastive learning (GCL) to enhance the representation of SR, which mitigates to some extent the constraint of scarce labeled data for supervision in SR. Existing work applies general graph data augmentation strategies to generate positive sample pairs, then further representation learning is conducted through a shared graph neural network. In this study, we identify limitations in applying traditional GCL to sequential recommendation: after the data augmentation, the shared graph neural network architecture used for feature learning fails to supply sufficiently diverse contrastive views, which are necessary to effectively identify and focus on the key information that is truly relevant for sequential recommendation. To ease this limitation, we propose a novel framework named Model Augmented Graph Contrastive Learning for Sequential Recommendation (MA-GCL4SR), which emphasizes modifying the internal architectures of the graph neural network through the use of model augmentation strategies, rather than focusing on making improvements during the data augmentation phase before encoding. Thereby, we construct a non-shared view encoder for SR, enriching the samples of user’s interaction sequences and strengthen the stability of the augmented sequence. Extensive experiments on four real-world datasets confirm the effectiveness of the proposed MA-GCL4SR paradigm, showcasing its consistent ability to elevate model performance across various real-world scenarios.},
  archive      = {J_TKDD},
  author       = {Chun-Yan Sang and Ming Gong and Shi-Gen Liao and Wei Zhou},
  doi          = {10.1145/3722561},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MA-GCL4SR: Improving graph contrastive learning-based sequential recommendation with model augmentation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiGraphMatch: A subgraph matching algorithm for multigraphs. <em>TKDD</em>, <em>19</em>(5), 1-36. (<a href='https://doi.org/10.1145/3728361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph matching is the problem of finding all the occurrences of a small graph, called the query, in a larger graph, called the target. Although the problem has been widely studied in simple graphs, few solutions have been proposed for multigraphs, in which two nodes can be connected by multiple edges, each denoting a possibly different type of relationship. In our new algorithm MultiGraphMatch (MGM), nodes and edges can be associated with labels and multiple properties. MGM introduces a novel data structure called bit matrix to efficiently index both the query and the target and filter the set of target edges that are matchable with each query edge. In addition, the algorithm proposes a new technique for ordering the processing of query edges based on the cardinalities of the sets of matchable edges. Using the CYPHER query definition language, MGM can perform queries with logical conditions on node and edge labels. We compare MGM with SuMGra and graph database systems Memgraph and Neo4J, showing comparable or better performance in all queries on a wide variety of synthetic and real-world graphs.},
  archive      = {J_TKDD},
  author       = {Giovanni Micale and Antonio Di Maria and Roberto Grasso and Vincenzo Bonnici and Alfredo Ferro and Dennis Shasha and Rosalba Giugno and Alfredo Pulvirenti},
  doi          = {10.1145/3728361},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-36},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MultiGraphMatch: A subgraph matching algorithm for multigraphs},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to reduce the scale of large graphs: A comprehensive survey. <em>TKDD</em>, <em>19</em>(5), 1-25. (<a href='https://doi.org/10.1145/3729427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data, prevalent across domains like social networks, biological systems, and recommendation systems, presents significant challenges due to its large scale and complex structure. The advent of Graph Neural Networks (GNNs) has revolutionized graph data mining by effectively capturing node dependencies and neighborhood information. However, the computational complexity of processing large-scale graphs remains a major hurdle, as real-world graphs often consist of millions or even billions of nodes and edges. Efficient techniques like message passing and sampling have helped mitigate this issue, but memory and processing constraints persist. A promising approach to addressing these challenges is learning to reduce the size of large-scale graphs while retaining essential information, thus facilitating faster and more efficient graph data mining tasks, such as graph condensation, reduction, coarsening, summarization, and so on. Despite the differences in terminology, approaches under these topics share the same motivation: to generate smaller yet informative graphs that can replace the original large-scale datasets. In this article, we unify these approaches under the concept of Graph Scaling (GS), highlighting the shared motivation across multiple topics. Alongside this definition, to clarify the question of what principles should be followed when scaling a graph and how a scaled graph was formulated, we propose a taxonomy to methodically categorize and understand existing methods. Moreover, by organizing the dataset and evaluation metrics, we aim to provide a more comprehensive understanding of the GS methods from a practical perspective. Moving forward, we delve into the limitations and challenges of GS methods, identifying the shortcomings and potential in the literature. Finally, we conclude this article by outlining future directions and offering concise guidelines to inspire future research in this field. A full paper list and online resources about GS are available at https://github.com/Frostland12138/Awesome-Graph-Scaling .},
  archive      = {J_TKDD},
  author       = {Hongjia Xu and Liangliang Zhang and Yao Ma and Sheng Zhou and Zhuonan Zheng and Jiajun Bu},
  doi          = {10.1145/3729427},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning to reduce the scale of large graphs: A comprehensive survey},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for demand-driven services in logistics and transportation systems: A survey. <em>TKDD</em>, <em>19</em>(4), 1-42. (<a href='https://doi.org/10.1145/3708325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent technology development brings the boom of numerous new Demand-Driven Services (DDS) into urban lives, including ridesharing, on-demand delivery, express systems, and warehousing. In DDS, a service loop is an elemental structure, including its service worker, the service providers, and corresponding service targets. The service workers should transport either people or parcels from the providers to the target locations. Various planning tasks within DDS can thus be classified into two individual stages: (1) Dispatching, which is to form service loops from demand/supply distributions, and (2) Routing, which is to decide specific serving orders within the constructed loops. Generating high-quality strategies in both stages is important to develop DDS but faces several challenges. Meanwhile, deep reinforcement learning (DRL) has been developed rapidly in recent years. It is a powerful tool to solve these problems since DRL can learn a parametric model without relying on too many problem-based assumptions and optimize long-term effects by learning sequential decisions. In this survey, we first define DDS, then highlight common applications and important decision/control problems within. For each problem, we comprehensively introduce the existing DRL solutions. We also introduce open simulation environments for development and evaluation of DDS applications. Finally, we analyze remaining challenges and discuss further research opportunities in DRL solutions for DDS.},
  archive      = {J_TKDD},
  author       = {Zefang Zong and Tao Feng and Jingwei Wang and Tong Xia and Yong Li},
  doi          = {10.1145/3708325},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-42},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deep reinforcement learning for demand-driven services in logistics and transportation systems: A survey},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressing deep neural networks with goal-specific pruning and self-distillation. <em>TKDD</em>, <em>19</em>(4), 1-27. (<a href='https://doi.org/10.1145/3721293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network (NN) compression aims at reducing the model size and receives much research attention. Nevertheless, we observe that when compressing convolutional neural networks (CNNs), previous approaches may not well measure the impact of filters to loss, resulting in a significant performance degradation after compression. On the other hand, for compressing the fully connected neural networks (FCNNs), we observe that converting the weight matrix to the block diagonal structure would result in better compression. Therefore, for compressing CNNs, we propose a new pipeline in this article, named Retraining-Aware Pruning (RAP) , with a new self-distillation approach, named High-Level Activation-Guided Attention-Preserving Self-Distillation (HAP) and a novel filter pruning strategy, named Normalized Gradients and Geometric Median (NGGM) to effectively improve the accuracy and reduce the model size. Further, for reducing the model size of FCNNs, we formulate a new research problem, i.e., Compression with Difference-Minimized Block Diagonal Structure (COMIS) , and propose a new algorithm, Memory-Efficient and Structure-Aware Compression (MESA) to effectively prune the weights into a block diagonal structure to significantly boost the compression rate. Extensive experiments on different models show that our approaches significantly outperform the state-of-the-art baselines in terms of compression rate, accuracy, and inference speed-up.},
  archive      = {J_TKDD},
  author       = {Fa-You Chen and Yun-Jui Hsu and Chia-Hsun Lu and Hong-Han Shuai and Lo-Yao Yeh and Chih-Ya Shen},
  doi          = {10.1145/3721293},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Compressing deep neural networks with goal-specific pruning and self-distillation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representation learning based on ordinary differential equations for dynamic networks. <em>TKDD</em>, <em>19</em>(4), 1-23. (<a href='https://doi.org/10.1145/3723359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning on networks, mapping the network into a low-dimensional vector space, has received signification attention recently due to its widespread application in graph data mining tasks. With the success of representation learning in static networks, we push further for practical scenarios of dynamic networks. Existing methods model the dynamic network by dividing the dynamic network into sequences of network snapshots, see each network snapshot as a static network, and utilize the dynamic evolution between snapshots, they capture the discrete dynamic evolution of dynamic networks. However, a dynamic network continuously evolves over time. Capturing the continuously dynamic evolution of dynamic networks is important for dynamic network representation. In this article, we regard a dynamic network as a dynamic system, use the ordinary differential equation (ODE) to model the dynamic evolution of dynamic networks, and integrate the ODE over continuous-time to capture continuously dynamic evolution of dynamic networks; and design a new encoder-decoder model for dynamic networks representation. We improve the gated recurrent unit (GRU) module (only capturing the discrete dynamic evolution of the dynamic network and structure information) by combining an ODE and a GRU. The improved GRU as the encoder can learn the continuously dynamic evolution, and structure information of the dynamic network, where the ODE parameterized by a graph neural network models the continuously dynamic evolution of each network snapshot. Use the ODE and Inner-Productor as the decoder, where the ODE is integrated over continuous-time to learn the continuous dynamic evolution of the latent representation of the whole dynamic network, and the Inner-Productor reconstructs the topological structure of each snapshot by doing the inner-product between nodes representation, the reconstructing errors as the objective function of our method. To assess our model, we expand the experiment on several real-world dynamic networks, and results show that our method consistently outperforms existing baselines in three dynamic link prediction tasks; the best is up to 6.54 \(%\) improvement. To our knowledge, our method is the first work using the ODE to capture the continuously dynamic evolution of dynamic networks.},
  archive      = {J_TKDD},
  author       = {Dongjie Li and Dong Li and Guang Lian},
  doi          = {10.1145/3723359},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Representation learning based on ordinary differential equations for dynamic networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-parallel story author-style transfer with disentangled representation learning. <em>TKDD</em>, <em>19</em>(4), 1-26. (<a href='https://doi.org/10.1145/3726870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parallel story author-style transfer is an important but challenging task in natural language process, which requires transferring an input story into another author-style while maintaining source semantics. Despite recent progress, current text style transfer systems still face the challenges of low robustness of the model and low quality of the generated stories. To address these challenges, we propose an end-to-end framework incorporating dual encoder components and a fusion mechanism, which can achieve explicit style-content disentanglement and effectively fusing source-domain content with target-domain stylistic features. First, we extract text from source stories containing content information using empirical extraction rules and prompt engineering. And then, we propose a novel generation model which achieves story-style transfer through capturing source content features and target style features and then fusing them. We use two additional training objectives to learn high-level discourse representations. Moreover, we have constructed a new dataset for this task. Extensive experiments based on automatic and human evaluation show that our model significantly outperforms state-of-the-art baselines, achieving approximately 8.5% average improvement in comprehensive performance metrics, demonstrating the effectiveness of our model in story-style transfer.},
  archive      = {J_TKDD},
  author       = {Hongbin Xia and Xiangzhong Meng and Yuan Liu},
  doi          = {10.1145/3726870},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Non-parallel story author-style transfer with disentangled representation learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale traffic pattern bank for cross-city few-shot traffic forecasting. <em>TKDD</em>, <em>19</em>(4), 1-24. (<a href='https://doi.org/10.1145/3727622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is crucial for intelligent transportation systems (ITS) , aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank (MTPB) . Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, the traffic data of the data-scarce target city could query the traffic pattern bank, facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn, assumes a pivotal role as a robust guide in subsequent processes involving graph reconstruction and forecasting. Empirical assessments conducted on real-world traffic datasets affirm the superior performance of MTPB, surpassing existing methods across various categories and exhibiting numerous attributes conducive to the advancement of cross-city few-shot forecasting methodologies. The code is available in https://github.com/zhyliu00/MTPB .},
  archive      = {J_TKDD},
  author       = {Zhanyu Liu and Guanjie Zheng and Yanwei Yu},
  doi          = {10.1145/3727622},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-scale traffic pattern bank for cross-city few-shot traffic forecasting},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully dynamic clustering and diversity maximization in doubling metrics. <em>TKDD</em>, <em>19</em>(4), 1-45. (<a href='https://doi.org/10.1145/3727881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present approximation algorithms for some variants of k -center clustering and diversity maximization in a fully dynamic setting, where the active pointset evolves through arbitrary insertions and deletions. All algorithms employ a coreset-based strategy and rely on the use of the cover tree data structure, which we crucially augment to maintain, at any time, some additional information enabling the efficient extraction of the solution for the specific problem. For all the problems under consideration, our algorithms compute \((\alpha+\varepsilon)\) -approximate solutions, where \(\alpha\) is the best-known approximation attainable in polynomial time in the standard static setting, and \(\varepsilon > 0\) is a user-provided accuracy parameter. Remarkably, and unlike previous works, the (cover tree) data structure used by our algorithms and the running times of the update procedures are both independent of the accuracy parameter \(\varepsilon\) and, for the k -center variants, also of parameter k . The analysis is performed in terms of the doubling dimension of the metric space which the points belong to, and it shows that, for spaces of bounded doubling dimension, the times required to extract solutions to the above problems are dramatically smaller than those that would be required to recompute solutions on the entire active pointset from scratch. To the best of our knowledge, ours are the first solutions for the matroid center and diversity maximization problems in the fully dynamic setting. The theoretical results are complemented by an extensive set of experiments, which demonstrate the efficiency and effectiveness of our algorithms for k -center without and with outliers against previously known ones.},
  archive      = {J_TKDD},
  author       = {Paolo Pellizzoni and Andrea Pietracaprina and Geppino Pucci},
  doi          = {10.1145/3727881},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-45},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fully dynamic clustering and diversity maximization in doubling metrics},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Have our cake and eat it: Augmentation diversity and semantic consistency balanced graph contrastive learning. <em>TKDD</em>, <em>19</em>(4), 1-25. (<a href='https://doi.org/10.1145/3728646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning on graph neural networks is receiving increasing attention due to the difficulty of obtaining graph labels in many real applications. Graph contrastive learning (GCL), a recently popular method for self-supervised learning on graphs, has achieved great success in many tasks. The key to the effectiveness of GCL is the construction of suitable contrasting pairs to capture important attributes of the data through the data augmentation modules. However, most of the existing approaches fail to fully consider both data diversity and the semantic consistency when conducting data augmentation. To fill this gap, we propose an augmentation diversity and semantic consistency balanced graph contrastive learning model (ADSCB for short), which enhances the representation ability of the CL model through richer contrasting objectives. In particular, we first introduce a semantic consistency module to extract the subgraph from the original graph through optimizing a carefully designed semantic consistency loss. Then, we introduce an augmentation diversity module and perform data augmentation and cross-scale mix-up operations on the original graph and the extracted semantic preserved subgraph to generate more diverse contrasting pairs. With the above two modules, our model ultimately achieves two contrasting objectives: diversity contrasting and semantic contrasting. The tradeoff between these two contrasting objectives allows our model to benefit from both the augmentation diversity and the semantic consistency. We evaluate ADSCB for graph classification in unsupervised, semi-supervised, and transfer learning settings using standard graph contrastive learning benchmarks. The results demonstrate the superiority of our method against several state-of-the-art baselines.},
  archive      = {J_TKDD},
  author       = {Hao Yan and Senzhang Wang and Chaozhuo Li and Jun Yin and Philip S. Yu and Jianxin Wang},
  doi          = {10.1145/3728646},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Have our cake and eat it: Augmentation diversity and semantic consistency balanced graph contrastive learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DyExplainer: Self-explainable dynamic graph neural network with sparse attentions. <em>TKDD</em>, <em>19</em>(4), 1-21. (<a href='https://doi.org/10.1145/3729173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs less explored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring structural relationships and temporal dependencies through a sparse attention technique. To preserve the desired properties of the explanation, such as structural consistency and temporal continuity, we augment our approach with contrastive learning techniques to provide a priori -guided regularization. To model longer-term temporal dependencies, we develop a buffer-based live-updating scheme for training. The results of our extensive experiments on various datasets demonstrate the superiority of DyExplainer, not only providing faithful explainability of the model predictions but also significantly improving the model prediction accuracy, as evidenced in the link prediction task.},
  archive      = {J_TKDD},
  author       = {Tianchun Wang and Dongsheng Luo and Wei Cheng and Haifeng Chen and Xiang Zhang},
  doi          = {10.1145/3729173},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DyExplainer: Self-explainable dynamic graph neural network with sparse attentions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving machine learning based on cryptography: A survey. <em>TKDD</em>, <em>19</em>(4), 1-33. (<a href='https://doi.org/10.1145/3729234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has profoundly influenced various aspects of our lives. However, privacy breaches have caused significant unease and concern among the general public. Preserving the privacy of sensitive data during the training and inference phases of machine learning is a key challenge. Cryptography-based privacy-preserving machine learning (crypto-based PPML) offers a viable solution to this challenge. In this article, we studied over 100 publications on crypto-based PPML frameworks published between 2016 and 2024, including 55 client-server architecture frameworks and 64 multi-party architecture frameworks. We provide a comprehensive overview of these frameworks, highlighting their features across various dimensions. Furthermore, we conduct an in-depth analysis, delving into scenarios, privacy goals, threat models, and optimization techniques that underpin these innovative solutions. We also discuss the challenges in the field of crypto-based PPML, including aspects of security and privacy , efficiency , and availability and usability . Finally, we offer an outlook on future research directions, aiming to provide valuable insights for both scholars and practitioners.},
  archive      = {J_TKDD},
  author       = {Congcong Chen and Lifei Wei and Jintao Xie and Yang Shi},
  doi          = {10.1145/3729234},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Privacy-preserving machine learning based on cryptography: A survey},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining repetitive negative sequential patterns with gap constraints. <em>TKDD</em>, <em>19</em>(4), 1-29. (<a href='https://doi.org/10.1145/3716390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential pattern mining (SPM) with gap constraints (or repetitive SPM or tandem repeat discovery in bioinformatics) can find frequent repetitive subsequences satisfying gap constraints, which are called positive sequential patterns with gap constraints (PSPGs). However, classical SPM with gap constraints cannot find the frequent missing items in the PSPGs. To tackle this issue, this article explores negative sequential patterns with gap constraints (NSPGs). We propose an efficient NSPG-Miner algorithm that can mine both frequent PSPGs and NSPGs simultaneously. To effectively reduce candidate patterns, we propose a pattern join strategy with negative patterns which can generate both positive and negative candidate patterns at the same time. To calculate the support (frequency of occurrence) of a pattern in each sequence, we explore a NegPair algorithm that employs a key-value pair array structure to deal with the gap constraints and the negative items simultaneously and can avoid redundant rescanning of the original sequence, thus improving the efficiency of the algorithm. To report the performance of NSPG-Miner, 11 competitive algorithms and 11 datasets are employed. The experimental results not only validate the effectiveness of the strategies adopted by NSPG-Miner but also verify that NSPG-Miner can discover more valuable information than the state-of-the-art algorithms. Algorithms and datasets can be downloaded from https://github.com/wuc567/Pattern-Mining/tree/master/NSPG-Miner .},
  archive      = {J_TKDD},
  author       = {Yan Li and Zhulin Wang and Jing Liu and Lei Guo and Philippe Fournier-Viger and Youxi Wu and Xindong Wu},
  doi          = {10.1145/3716390},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mining repetitive negative sequential patterns with gap constraints},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-mechanism-based neural latent-factorization-of-tensors model. <em>TKDD</em>, <em>19</em>(4), 1-27. (<a href='https://doi.org/10.1145/3719295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Dimensional and Incomplete (HDI) tensors contain a wealth of knowledge and patterns, which are typically utilized to characterize complex relationships between entities in a variety of industrial applications. Currently, the neural network-based tensor factorization model has shown superiority when handling the missing data in HDI tensors. However, it only uses the outer product of latent factors (LFs) of entities and neglects the interactions between the LF. In addition, the simple linear operation does not consider the nonlinear structure of the HDI tensor. To overcome the aforementioned issues, an Attention-mechanism-based Neural Latent-Factorization-of-Tensors (ANLFT) model is provided in this article. It encompasses three primary ideas: (a) incorporating the theory of neural networks with the latent factorization of tensor to construct the nonlinear structure in the HDI tensor effectively; (b) adopting the attention mechanism to depict the interactions between LF; (c) using the position-transitional particle swarm optimization backward propagation learning ( \(\rm{P}^{2}\) BP) scheme to train the ANLFT model efficiently. The experimental results on eight HDI datasets show that the ANLFT model can obtain higher estimation performance gain than state-of-the-art models. The convergence performance of the proposed model is also competitive with that of state-of-the-art models.},
  archive      = {J_TKDD},
  author       = {Xiuqin Xu and Mingwei Lin and Zeshui Xu and Xin Luo},
  doi          = {10.1145/3719295},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Attention-mechanism-based neural latent-factorization-of-tensors model},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal structural preserving with subtree attention in dynamic graph transformers. <em>TKDD</em>, <em>19</em>(4), 1-24. (<a href='https://doi.org/10.1145/3720549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph learning is a rapidly developing area of research due to its widespread application in various real-world networks. Most existing works combine graph neural networks and sequential models to exploit the graph topology and the temporal information of dynamic graphs. However, these methods exhibit certain limitations in extracting local and global information and capturing fine-grained temporal structure in dynamic graphs. In this article, we present our novel framework, Dynamic Graph Subtree Attention, which is centralized by a learnable temporal edge sampling module and a lightweight attention operator to address the aforementioned issues. Our approach first constructs a temporal union graph for each time step using an adaptive edge sampling module, which preserves relevant interactions for our graph encoder to directly exploit fine-gained interactions across different times. Based on the temporal union graph, we further propose a subtree attention module that leverages the multi-hop representation and the self-attention mechanism to properly extract the local and global information from first- to high-order neighborhoods. To further reduce the computation complexity, the subtree module is equipped with a kernelized attention operation, which scales linearly with respect to the number of edges. By performing extensive experiments, we demonstrate the superiority of our proposed model in dynamic graph representation learning, as it consistently outperforms existing methods in future link prediction tasks. The code is publicly available at: https://github.com/minhduc1122002/DySubTree .},
  archive      = {J_TKDD},
  author       = {Minh Duc Nguyen and Viet Cuong Ta},
  doi          = {10.1145/3720549},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Temporal structural preserving with subtree attention in dynamic graph transformers},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing matching for on-demand ride-pooling with stochastic day-to-day dynamics. <em>TKDD</em>, <em>19</em>(4), 1-29. (<a href='https://doi.org/10.1145/3721434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-pooling significantly reduces traffic congestion by enhancing fleet utilization through effective ride-matching. Real-world ride-pooling systems are dynamic, with fluctuations in driver availability and demand throughout the day. This necessitates adaptive ride-matching strategies that can quickly adjust to changing proximities and identify new carpooling opportunities by recalculating driver-rider correlations. However, most current methods primarily focus on static demand-supply scenarios and short-term accessibility, falling short in dynamic environment. In this study, we introduce a dynamic heterogeneous network model that captures the evolving nature of ride-pooling systems, where new requests and carpooling arrangements continuously emerge. We propose an embedding model-based matching decision process that operates online, adjusting to changes in the network’s structure. This process involves constructing a dynamic heterogeneous ride-pooling network that encompasses diverse node attributes and driver-rider connections, updating these representations to reflect the network’s evolution, and quickly identifying and ranking candidate riders for efficient online matching. Our approach demonstrates improved performance in offline evaluations using datasets from Austin, TX (RideAustin) and Chengdu, China (DiDi Chuxing). We observe a reduction in the necessary fleet size as new orders are placed, and an improvement in drivers’ matching probability compared to existing methods (e.g., an increase of 5.4–31.1% in the assignment rate on DiDi dataset), showcasing the advantage of employing dynamic network embedding to cut down on matching time (e.g., a decrease of 3.7–228.8 seconds in running time on DiDi dataset). Furthermore, we develop a simulated ride-pooling system (SRPool) that mimics dynamic demand-supply fluctuations and supports vehicle routing, providing a robust platform for evaluating ride-matching strategies. Our strategy not only excels in the SRPool environment but also effectively minimizes the total trip distance and rider waiting times.},
  archive      = {J_TKDD},
  author       = {Yaling Zhao and Lei Tang and Yunji Liang and Zeyu He and Junchi Ma},
  doi          = {10.1145/3721434},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Optimizing matching for on-demand ride-pooling with stochastic day-to-day dynamics},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting graph-based time-dependent data with graph sequence attention. <em>TKDD</em>, <em>19</em>(4), 1-26. (<a href='https://doi.org/10.1145/3721435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting graph-based, time-dependent data has broad practical applications but presents challenges. Effective models must capture both spatial and temporal dependencies in the data, while also incorporating auxiliary information to enhance prediction accuracy. In this article, we identify limitations in current state-of-the-art models regarding temporal dependency handling. To overcome this, we introduce GSA-Forecaster, a new deep learning model designed for forecasting in graph-based, time-dependent contexts. GSA-Forecaster utilizes graph sequence attention, a new attention mechanism proposed in this article, to effectively manage temporal dependencies. GSA-Forecaster integrates the data’s graph structure directly into its architecture, addressing spatial dependencies. Additionally, it incorporates auxiliary information to refine its predictions further. We validate its performance using real-world graph-based, time-dependent datasets, where it demonstrates superior effectiveness compared to existing state-of-the-art models.},
  archive      = {J_TKDD},
  author       = {Yang Li and Di Wang and José M. F. Moura},
  doi          = {10.1145/3721435},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Forecasting graph-based time-dependent data with graph sequence attention},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subclass-wise logit perturbation for multi-label learning. <em>TKDD</em>, <em>19</em>(3), 1-40. (<a href='https://doi.org/10.1145/3715919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logit perturbation refers to adding perturbation on logit, which has been shown to be capable of enhancing the robustness and generalization capabilities of deep neural networks in machine learning. However, studies on logit perturbation for multi-label learning are limited and they only consider the issue of class imbalance in the training data. Furthermore, the logit perturbation vectors in these methods are identical for negative classes containing different subclasses when multi-label learning is viewed as a multiple binary classification problem. This study investigates logit perturbation by exploring the characteristics of subclass-wise multi-label training data. First, the influence of the characteristics of multi-label training data on classification performance is analyzed in terms of the three data characteristics, namely, proportion, variance, and co-occurrence for each category (or subclass). Quantitative analyses reveal that variance differences among the subclasses in the negative class of a decomposed binary task also negatively impact the training performance, and if multiple characteristics affect simultaneously, the performance deterioration will be more severe. Second, theoretical analysis is performed for subclass-wise logit perturbation and a new subclass-wise logit perturbation method is proposed for multi-label learning. In our method, each class/subclass has a carefully designed perturbation implementation according to its proportion, variance, and co-occurrence. Finally, our proposed method is further explained through a regularization view. Extensive experiments demonstrate that our method consistently enhances the generalization performance of popular depth networks on multi-label benchmark datasets.},
  archive      = {J_TKDD},
  author       = {Yu Zhu and Ou Wu and Fengguang Su},
  doi          = {10.1145/3715919},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Subclass-wise logit perturbation for multi-label learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity metrics: Chebyshev coulomb force and resultant force for high-dimensional data. <em>TKDD</em>, <em>19</em>(3), 1-25. (<a href='https://doi.org/10.1145/3715963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity metric has garnered widespread attention thanks to its potential applications in the fields of data mining, machine learning, and so on. Due to the interference of “distance concentration” caused by “Curse of dimensionality,” however, existing similarity metrics are inadequate in high-dimensional data analysis. In this study, we propose two innovative similarity metrics—Chebyshev Coulomb force and Chebyshev Coulomb resultant force—anchored on Chebyshev p-norms. In the initial phase, we eliminate dependency relationships among attributes by applying a metric matrix—and the theoretical analysis reveals that the Chebyshev p-norms is capable of mitigating the effect of “distance concentration” among high-dimensional data objects. Next, we devise two similarity metrics—Chebyshev Coulomb force and Chebyshev Coulomb resultant force—by adopting the metric matrix and Chebyshev p-norms. Chebyshev Coulomb force and Chebyshev Coulomb resultant force, being effective in characterizing the similarity among data objects, quantify the deviation of data objects from their respective dataset centers. Additionally, the two metrics alleviate the interference of “distance concentration.” Importantly, the discrepancy of data objects in attribute dimensions is captured by Chebyshev Coulomb force vector, rendering the similarity metric interpretable. By utilizing the UCI dataset, the experimental validation demonstrates the superiority of our similarity metrics, confirming their efficacy in mitigating the interference of “distance concentration.” Compared with the existing similarity metric approaches, the AUC index of outlier detection shows an average improvement of 8.18%—and the ARI, NMI, and F_score indices of clustering are revamped by averages 6.56%, 6.87%, and 6.01%, respectively.},
  archive      = {J_TKDD},
  author       = {Jian Ying Liu and Chaowei Zhang and Min Zhang and Xiao Qin and Jifu Zhang},
  doi          = {10.1145/3715963},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Similarity metrics: Chebyshev coulomb force and resultant force for high-dimensional data},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ORIC: Feature interaction detection through online random interaction chains for click-through rate prediction. <em>TKDD</em>, <em>19</em>(3), 1-31. (<a href='https://doi.org/10.1145/3717070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate prediction aims to predict the ratio of clicks to impressions of a specific link, which is challenging due to (1) extremely high-dimensional categorical features; (2) both important original features and their interactions; and (3) reliance on different features and interactions in different time periods. To overcome these difficulties, we propose a new feature interaction detection method based on the idea of frequent itemset mining, named Online Random Intersection Chains (ORIC), which detects informative feature interactions with high interpretability. ORIC can be updated by controlling the importance of the historical and latest data with a tuning parameter, which saves computational burden and makes full use of historical information. Further, Streaming Integrated Model (SIM) is developed to feed the time-varying feature interactions into CTR prediction models. Empirical results on three benchmark datasets show that SIM achieves better performance than many CTR prediction models, as well as the efficiency, consistency, and interpretability of ORIC.},
  archive      = {J_TKDD},
  author       = {Yannian Kou and Qiuqiang Lin and Chuanhou Gao},
  doi          = {10.1145/3717070},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {ORIC: Feature interaction detection through online random interaction chains for click-through rate prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-enhanced multi-granularity stochastic weight completion in sparse road networks. <em>TKDD</em>, <em>19</em>(3), 1-23. (<a href='https://doi.org/10.1145/3719013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road network applications, such as navigation, incident detection, and Point-of-Interest (POI) recommendation, make extensive use of network edge weights (e.g., traveling times). Some of these weights can be missing, especially in a road network where traffic data may not be available for every road. In this article, we study the stochastic weight completion (SWC) problem, which computes the weight distributions of missing road edges. This is difficult, due to the intricate temporal and spatial correlations among neighboring edges. Besides, the road network can be sparse , i.e., there is a lack of traveling information in a large portion of the network. To tackle these challenges, we propose a multi-granularity framework for Region-Wise Graph Completion (RegGC) . To learn coarse spatial correlations among distantly located roads, we construct a region-wise hypergraph neural architecture based on semantic region dependencies. For finer spatial correlations, we incorporate contextual road network properties (e.g., speed limits, lane counts, and road types). Moreover, it incorporates recent and periodic dimensions of road traffic. We evaluate RegGC against 10 existing methods on 3 real road network datasets. They show that RegGC is more effective and efficient than state-of-the-art solutions.},
  archive      = {J_TKDD},
  author       = {Xiaolin Han and Yikun Zhang and Chenhao Ma and Xuequn Shang and Reynold Cheng and Tobias Grubenmann and Xiaodong Li},
  doi          = {10.1145/3719013},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hypergraph-enhanced multi-granularity stochastic weight completion in sparse road networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). : Efficient -order-based core maintenance in large-scale dynamic hypergraphs. <em>TKDD</em>, <em>19</em>(3), 1-33. (<a href='https://doi.org/10.1145/3719205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -core model has garnered widespread adoption for preserving essential cohesive subgraphs owing to its linear-time computability, making it particularly suitable for hypergraph analysis. However, considering the continuously evolving characteristics of real-world hypergraphs, recent research efforts have focused on developing efficient algorithms that can maintain the core value of each vertex amid structural alterations. Despite these efforts, frequent insertions and deletions in dynamic hypergraphs continue to pose significant inefficiencies, primarily due to the increased traversal overhead incurred by hyperedge insertion algorithms. This exacerbates performance disparities between handling hyperedge insertions and deletions, underscoring the persistent challenge of effective k -core analysis in hypergraphs. To effectively address these challenges, we have gained key insights that enable us to define a specific order, termed the hypergraph k -order, which significantly reduces redundant vertex traversal and narrows down the search space during hyperedge insertions. Based on the proposed hypergraph k -order, we define two indices, the order index and the pivotal index, aimed at minimizing traversal costs and expediting the hyperedge insertion algorithm. Moreover, it is essential to recognize that the recomputation of the support degree ( sd ) for all vertices following each hyperedge deletion can significantly diminish the performance efficiency of deletion algorithms. To address this, we introduce an optimized approach that leverages the incremental maintenance of the support degree ( sd ) value to expedite the hyperedge deletion process. By leveraging these optimizations, we introduce a novel Order-based Traversal core Maintenance methodology, designated as OTM , which markedly enhances the efficiency of core maintenance in dynamic hypergraphs. Our comprehensive evaluation, which covers 12 real-world hypergraph datasets and a synthetic dataset, reveals that OTM achieves staggering speedup, outperforming the state-of-the-art approach with a 41,420 \(\times\) speedup in the insertion algorithm and 8,284 \(\times\) speedup in the deletion algorithm, underscoring its remarkable efficiency and effectiveness.},
  archive      = {J_TKDD},
  author       = {Xiangfei Fang and Chengying Huan and Heng Zhang and Yongchao Liu and Shaonan Ma and Yanjun Wu and Chen Zhao},
  doi          = {10.1145/3719205},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {: Efficient -order-based core maintenance in large-scale dynamic hypergraphs},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting defenses against GAN-based feature inference attacks in federated learning. <em>TKDD</em>, <em>19</em>(3), 1-20. (<a href='https://doi.org/10.1145/3719350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a decentralized model training framework that aims to merge isolated data islands while maintaining data privacy. However, recent studies have revealed that Generative Adversarial Network (GAN)-based attacks can be employed in FL to learn the distribution of private datasets and reconstruct recognizable images. In this article, we exploit defenses against GAN-based attacks in FL and propose a framework, Anti-GAN, to prevent attackers from learning the real distribution of the victim’s data. The core idea of Anti-GAN is to manipulate the visual features of private training images to make them indistinguishable to human eyes even restored by attackers. Specifically, Anti-GAN projects the private dataset onto a GAN’s generator and combines the generated fake images with the actual images to create the training dataset, which is then used for federated model training. The experimental results demonstrate that Anti-GAN is effective in preventing attackers from learning the distribution of private images while causing minimal harm to the accuracy of the federated model.},
  archive      = {J_TKDD},
  author       = {Xinjian Luo and Xianglong Zhang},
  doi          = {10.1145/3719350},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting defenses against GAN-based feature inference attacks in federated learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal twitter data analysis for identifying offensive posts using a deep cross-attention–based transformer framework. <em>TKDD</em>, <em>19</em>(3), 1-30. (<a href='https://doi.org/10.1145/3713077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s society dissemination of information among the individuals occur very rapidly due to the widespread usage of social media platforms like Twitter (now-a-days acclaimed as X). However, information may pose challenges to maintaining a healthy online environment because often it contains harmful content. This article presents a novel approach to identify different categories of offensive posts such as hate speech, profanity, targeted insult, and derogatory commentary by analyzing multi-modal image and text data, collected from Twitter. We propose a comprehensive deep learning framework, “Value Mixed Cross-Attention Transformer” (VMCA-Trans) that leverage a combination of computer vision and natural language processing methodologies to effectively classify the posts into four classes with binary labels. We have created an in-house dataset (OffenTweet) comprising of Twitter posts having textual content, accompanying with images to build the proposed model. The dataset is carefully annotated by several experts with offensive labels such as hate speech, profanity, targeted insult, and derogatory commentary. VMCA-Trans utilizes fine-tuned state-of-the-art transformer-based backbones such as ViT, BERT, RoBERTA. The combined representation of image and text embeddings obtained by these fine-tuned transformer encoders is fed into a classifier to categorize the posts into offensive and non-offensive classes. To assess its effectiveness, we extensively evaluate the VMCA-Trans model using various performance metrics. The results indicate that the proposed multi-modal approach achieves superior performance compared to traditional unimodal methods.},
  archive      = {J_TKDD},
  author       = {Jayanta Paul and Siddhartha Mallick and Abhijit Mitra and Anuska Roy and Jaya Sil},
  doi          = {10.1145/3713077},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-modal twitter data analysis for identifying offensive posts using a deep cross-attention–based transformer framework},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GFairHint: Improving individual fairness for graph neural networks via fairness hint. <em>TKDD</em>, <em>19</em>(3), 1-22. (<a href='https://doi.org/10.1145/3714472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the growing concerns about fairness in machine learning and the impressive performance of Graph Neural Networks (GNNs) on graph data learning, algorithmic fairness in GNNs has attracted significant attention. While many existing studies improve fairness at the group level, only a few works promote individual fairness, which renders similar outcomes for similar individuals. A desirable framework that promotes individual fairness should (1) balance fairness and performance, (2) accommodate two commonly-used individual similarity measures (externally annotated and computed from input features), and, (3) generalize across various GNNs. Unfortunately, none of the prior work achieves all the desirables. In this work, we propose a novel method, GFairHint , which promotes individual fairness in GNNs and achieves all aforementioned desirables. GFairHint learns fairness representations through an auxiliary link prediction task, which is inspired by a theoretical analysis of the definition of individual fairness. We then concatenate the representations with the learned node embeddings in original GNNs as a “fairness hint” . Through extensive experimental investigations on five real-world graph datasets under three prevalent GNNs covering both individual similarity measures above, GFairHint achieves the best fairness results in almost all combinations of datasets with various backbone models, while generating comparable utility results, with much less computational cost compared to the previous state-of-the-art method.},
  archive      = {J_TKDD},
  author       = {Paiheng Xu and Yuhang Zhou and Bang An and Wei Ai and Furong Huang},
  doi          = {10.1145/3714472},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {GFairHint: Improving individual fairness for graph neural networks via fairness hint},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy weighted principal component analysis for anomaly detection. <em>TKDD</em>, <em>19</em>(3), 1-22. (<a href='https://doi.org/10.1145/3715148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal Component Analysis (PCA) is one of the most famous unsupervised dimensionality reduction algorithms and has been widely used in many fields. However, it is very sensitive to outliers, which reduces the robustness of the algorithm. In recent years, many studies have tried to employ \(\ell_{1}\) -norm to improve the robustness of PCA, but they all lack rotation invariance or the solution is expensive. In this article, we propose a novel robust PCA, namely, Fuzzy Weighted Principal Component Analysis (FWPCA), which still uses squared \(\ell_{2}\) -norm to minimize reconstruction error and maintains rotation invariance of PCA. The biggest bright spot is that the contribution of data is restricted by fuzzy weights, so that the contribution of normal samples is much greater than noise or abnormal data, and realizes anomaly detection. Besides, a more reasonable data center can be obtained by solving the optimal mean to make projection matrix more accurate. Subsequently, an effective iterative optimization algorithm is developed to solve this problem, and its convergence is strictly proved. Extensive experimental results on face datasets and RGB anomaly detection datasets show the superiority of our proposed method.},
  archive      = {J_TKDD},
  author       = {Sisi Wang and Feiping Nie and Zheng Wang and Rong Wang and Xuelong Li},
  doi          = {10.1145/3715148},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fuzzy weighted principal component analysis for anomaly detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation-free time-series forecasting model selection via meta-learning. <em>TKDD</em>, <em>19</em>(3), 1-41. (<a href='https://doi.org/10.1145/3715149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting models are invariably used in a variety of domains for crucial decision-making. Traditionally these models are constructed by experts with considerable manual effort. Unfortunately, this approach has poor scalability while generating accurate forecasts for new datasets belonging to diverse applications. Without access to skilled domain-knowledge, one approach is to train all the models on the new time-series data and then select the best one. However, this approach is nonviable in practice. In this work, we develop techniques for fast automatic selection of the best forecasting model for a new unseen time-series dataset, without having to first train (or evaluate) all the models on the new time-series data to select the best one. In particular, we develop a forecasting meta-learning approach called AutoForecast that allows for the quick inference of the best time-series forecasting model for an unseen dataset. Our approach learns both forecasting models’ performances over time horizon of the same dataset and task similarity across different datasets. The experiments demonstrate the effectiveness of the approach over state-of-the-art (SOTA) single and ensemble methods and several SOTA meta-learners (adapted to our problem) in terms of selecting better forecasting models (i.e., 2 \(\times\) gain) for unseen tasks for univariate and multivariate testbeds. AutoForecast has also significant reduction in inference time compared to the naïve approach (doing inference using all possible models and then selecting the best one), with median of 42 \(\times\) across the two testbeds. We release our meta-learning database corpus (348 datasets), performances of the 322 forecasting models on the database corpus, meta-features, and source codes for the community to access them for forecasting model selection and to build on them with new datasets and models which can help advance automating time-series forecasting problem. In our released database corpus, we unveil new traces of Adobe computing cluster usage for production workloads.},
  archive      = {J_TKDD},
  author       = {Mustafa Abdallah and Ryan A. Rossi and Kanak Mahadik and Sungchul Kim and Handong Zhao and Saurabh Bagchi},
  doi          = {10.1145/3715149},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-41},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Evaluation-free time-series forecasting model selection via meta-learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series classification with elasticity using augmented path signatures. <em>TKDD</em>, <em>19</em>(3), 1-32. (<a href='https://doi.org/10.1145/3715702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We often compare time-dependent data elastically such that some compression or dilation along the time dimension can be ignored, for example, spatial trajectories of vehicles moving at different speeds or accelerometer data for exercises completed at variable rhythms. Traditionally this is possible via an alignment-based elastic distance measure, such as dynamic time warping (DTW). We may also control the degree of allowable warping with warping constraints. However, these elastic distance measures are not easy to use in large-scale time series classification, as they need to be evaluated pairwise and often cannot be directly converted into feature sets that we may use with arbitrary classifiers or combine with other features. In this research, we focus on the study of path signatures, a transformation with time warping invariance property, and how we may augment a time series to make its signature space representation reflect common warping constraints. We demonstrate that the comparing signatures is analogous to comparing time series with elastic distances, and that augmented signature features can serve as warping invariant or insensitive features in time series classification. Finally, we construct multiple path signatures with constraining augmentations classifier (MultiPSCA), a general-purpose minimal tuning time series classifier using augmented signatures and show that it is able to beat existing best-performing elastic time series classification algorithms without per-dataset hyperparameter tuning.},
  archive      = {J_TKDD},
  author       = {Chenyang Wang and Ling Luo and Uwe Aickelin},
  doi          = {10.1145/3715702},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Time series classification with elasticity using augmented path signatures},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online stable streaming feature selection via feature aggregation. <em>TKDD</em>, <em>19</em>(3), 1-23. (<a href='https://doi.org/10.1145/3715918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an essential pre-process component in data mining that aims to select the most relevant features from the target dataset. Datasets are always dynamic in real-world applications, and features may exist in stream mode. Then, online streaming feature selection methods are proposed, which deal with streaming features arriving continuously in real-time. However, most existing algorithms prioritize high accuracy and low time-consumption but overlook the stability of the selected features. Stable feature selection results are crucial for users in practice. For instance, in the medical field, unstable feature selection results can make it challenging for experts to identify the main causative factors of a disease. Motivated by this, this article proposes a new online stable streaming feature selection method via feature aggregation named OSSFS. Specifically, inspired by the cohesive MeanShift approach, OSSFS applies an incremental aggregation strategy to partition the streaming features into multiple hyperellipsoids. Then, we incrementally update and merge these hyperellipsoids with new streaming features. Finally, we select representative features from each hyperellipsoid as the final selected feature subset. Extensive experiments are conducted on several real-world datasets to compare our new method with state-of-the-art competing algorithms in cases of stability and predictive accuracy. Experimental results indicate that OSSFS achieves optimal stability without losing prediction accuracy.},
  archive      = {J_TKDD},
  author       = {Peng Zhou and Qi Wang and Yunyun Zhang and Zhaolong Ling and Shu Zhao and Xindong Wu},
  doi          = {10.1145/3715918},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online stable streaming feature selection via feature aggregation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automating research synthesis with domain-specific large language model fine-tuning. <em>TKDD</em>, <em>19</em>(3), 1-39. (<a href='https://doi.org/10.1145/3715964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research pioneers the use of fine-tuned Large Language Models (LLMs) to automate Systematic Literature Reviews (SLRs), presenting a significant and novel contribution in integrating AI to enhance academic research methodologies. Our study employed advanced fine-tuning methodologies on open sourced LLMs, applying textual data mining techniques to automate the knowledge discovery and synthesis phases of an SLR process, thus demonstrating a practical and efficient approach for extracting and analyzing high-quality information from large academic datasets. The results maintained high fidelity in factual accuracy in LLM responses, and were validated through the replication of an existing PRISMA-conforming SLR. Our research proposed solutions for mitigating LLM hallucination and proposed mechanisms for tracking LLM responses to their sources of information, thus demonstrating how this approach can meet the rigorous demands of scholarly research. The findings ultimately confirmed the potential of fine-tuned LLMs in streamlining various labor-intensive processes of conducting literature reviews. As a scalable proof-of-concept, this study highlights the broad applicability of our approach across multiple research domains. The potential demonstrated here advocates for updates to PRISMA reporting guidelines, incorporating AI-driven processes to ensure methodological transparency and reliability in future SLRs. This study broadens the appeal of AI-enhanced tools across various academic and research fields, demonstrating how to conduct comprehensive and accurate literature reviews with more efficiency in the face of ever-increasing volumes of academic studies while maintaining high standards.},
  archive      = {J_TKDD},
  author       = {Teo Susnjak and Peter Hwang and Napoleon Reyes and Andre L. C. Barczak and Timothy McIntosh and Surangika Ranathunga},
  doi          = {10.1145/3715964},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Automating research synthesis with domain-specific large language model fine-tuning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradual drift detection in process models using conformance metrics. <em>TKDD</em>, <em>19</em>(3), 1-40. (<a href='https://doi.org/10.1145/3716169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changes, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the state-of-the-art focus on the detection of sudden changes, leaving aside other types of changes. In this article, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay, and change region overlapping than the main state-of-the-art algorithms.},
  archive      = {J_TKDD},
  author       = {Víctor Gallego-Fontenla and Pedro Gamallo-Fernandez and Juan C. Vidal and Manuel Lama},
  doi          = {10.1145/3716169},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Gradual drift detection in process models using conformance metrics},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Together is better: Knowledge-aware model with resume fusion for online job recommendation. <em>TKDD</em>, <em>19</em>(3), 1-15. (<a href='https://doi.org/10.1145/3716503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread adoption of online recruitment platforms has led to explosive growth in employment information, resulting in an ever-increasing demand from job seekers for accurate and effective job recommendations. Existing studies on the Person-Job Fit models focus on the correlation between resumes and job descriptions, with rare consideration given to user historical behavior such as click and application. On the contrary, job recommendation methods always ignore the crucial information lurking in the resume text. In addition, the continuous influx of a vast amount of job data poses challenges to the updating of online recommendation results. To this end, we propose a novel O nline J ob R ecommendation model via R esume F usion (OJRRF) in this article, aimed at making accurate and efficient online job recommendations with the merits of addressing job cold start and long tail problems. The key contribution lies in two facets: (1) incorporating resume text information into the knowledge graph attention framework to enhance job seekers’ vector representations jointly; (2) designing a hybrid recommender strategy by combining the knowledge-aware offline model with the content-based online model. Finally, we conducted extensive comparison experiments and online A/B test on the recruitment platform of JiuYeJie big data company to validate the effectiveness and real-time capability of OJRRF. The release code can be found in https://github.com/urnotada/OJRRF .},
  archive      = {J_TKDD},
  author       = {Xiao Gu and Ling Jian and Chongzhi Rao and Zhaohui Bu and Xianggang Cheng},
  doi          = {10.1145/3716503},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-15},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Together is better: Knowledge-aware model with resume fusion for online job recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CM-CaFE: A clustering method with causality-based feature embedding. <em>TKDD</em>, <em>19</em>(3), 1-23. (<a href='https://doi.org/10.1145/3717068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental technique widely used for exploring the inherent data structure. Many studies indicate that an appropriate feature representation can effectively improve clustering performance. However, the existing feature representation methods are based on correlation to select or extract features, which makes it hard to deal with spurious correlations. The spurious correlations mislead the correlation-based methods to consider features that have no causal relationship as being correlative, which limits the clustering performance and feature interpretability. To tackle this issue, inspired by causal learning, we propose a new joint optimization Clustering Method with Causal Feature Embedding (CM-CaFE) , which utilizes the causality of features to learn more discriminative representation for clustering. Specifically, to eliminate spurious correlations among features, we first employ any state-of-the-art Markov blanket learning method to learn an undirected causal graph. Next, we extract the maximal fully connected causal subgraphs from the learned undirected causal graph and propose an approach to merge them to generate the causal matrix. Based on the causal matrix, we present an objective function that consists of a clustering loss term and a causal matrix fitting term to learn a causal transformation matrix. The causal transformation matrix is utilized to map the original data into a new space for clustering. Finally, we comprehensively compare the proposed method with some state-of-the-art clustering approaches on several datasets to demonstrate the effectiveness and interpretability of the proposed method.},
  archive      = {J_TKDD},
  author       = {Xuechun Jing and Fuyuan Cao and Kui Yu and Jiye Liang},
  doi          = {10.1145/3717068},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CM-CaFE: A clustering method with causality-based feature embedding},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Momentum-accelerated and biased unconstrained non-negative latent factor model for handling high-dimensional and incomplete data. <em>TKDD</em>, <em>19</em>(3), 1-25. (<a href='https://doi.org/10.1145/3717069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional and incomplete (HDI) data are involved frequently in big data-related industrial applications. Latent factor (LF) analysis aims at extracting the knowledge of great value from such extremely sparse HDI data efficiently. Non-negative LF models based on the single LF-dependent, non-negative, and multiplicative update rules exactly are the representative of LF analysis. However, these models face low generalization dilemma due to incompatible with general unconstrained optimization techniques. To address this issue, this article proposes a novel momentum-accelerated and biased unconstrained non-negative latent factor (MBUNLF) model, which matches with unconstrained optimization techniques. The proposed MBUNLF model is built on three main ideas: (a) Improving the generalization through a non-negative mapping function; (b) Capturing information among different entities through linear biases; (c) Accelerating convergence during the training process through generalized momentum method. Empirical studies on six datasets from industrial applications indicate that the proposed MBUNLF model outperforms nine state-of-the-art models when processing HDI data, reducing the root mean square error by 19.47% on average. It demonstrates the validity of the MBUNLF model in extracting non-negative LFs from HDI data.},
  archive      = {J_TKDD},
  author       = {Mingwei Lin and Hengshuo Yang and Xiuqin Xu and Ling Lin and Zeshui Xu and Xin Luo},
  doi          = {10.1145/3717069},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Momentum-accelerated and biased unconstrained non-negative latent factor model for handling high-dimensional and incomplete data},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous hyperbolic hypergraph neural network for friend recommendation in location-based social networks. <em>TKDD</em>, <em>19</em>(3), 1-29. (<a href='https://doi.org/10.1145/3708999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Friend recommendation is an important real-world application in Location-based Social Networks (LBSN), helping users discover potential friends and enhance their overall happiness. LBSN mainly comprises two distinct data structures: spatio-temporal data for human mobility and graph data for social networks. These two data structures make it challenging to model the complex relationships between them, which are essential for comprehensively understanding users’ lives. Previous studies have either modeled user trajectories and social networks separately or used classical simple graph-based methods, where a simple edge links only two nodes, failing to capture the multiple relationships inherent in LBSN. Furthermore, most studies have relied on Euclidean space to train their graph models, which could result in significant distortion because of tree-like social network data structure. To address these limitations, we propose a novel heterogeneous LBSN hypergraph that represents user check-in records and continuous trajectories—comprising multiple Points of Interest (POI)—as hyperedges, enabling the representation of complex spatio-temporal relationships. This approach enables us to link multiple nodes of different types by hyperedges and use hyperbolic spaces to create more efficient graph representations. Additionally, we devise a new type-specific attention mechanism for our Heterogeneous Hyperbolic Hypergraph Neural Network (H 3 GNN), which is end-to-end trainable and employs supervised contrastive learning to learn hypergraph node embeddings for the subsequent friend recommendation task with the help of hyperbolic space. Finally, our model H 3 GNN achieves better results than existing methods on six real-world city datasets, and our ablation studies demonstrate the effectiveness of each component. Additionally, our experiments indicate that H 3 GNN requires less data storage and training time compared to previous methods.},
  archive      = {J_TKDD},
  author       = {Yongkang Li and Zipei Fan and Xuan Song},
  doi          = {10.1145/3708999},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Heterogeneous hyperbolic hypergraph neural network for friend recommendation in location-based social networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient distributed sparse relative similarity learning. <em>TKDD</em>, <em>19</em>(3), 1-27. (<a href='https://doi.org/10.1145/3712603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a good similarity measure for large-scale high-dimensional data is a crucial task in machine learning applications, yet it poses a significant challenge. Distributed minibatch Stochastic Gradient Descent (SGD) serves as an efficient optimization method in large-scale distributed training, allowing linear speedup in proportion to the number of workers. However, communication efficiency in distributed SGD requires a sufficiently large minibatch size, presenting two distinct challenges. Firstly, a large minibatch size leads to high memory usage and computational complexity during parallel training of high-dimensional models. Second, a larger batch size of data reduces the convergence rate. To overcome these challenges, we propose an Efficient Distributed Sparse Relative Similarity Learning ( \(\mathbf{\mathsf{EDSRSL}}\) ) framework. This framework integrates two strategies: local minibatch SGD and sparse relative similarity learning. By effectively reducing the number of updates through synchronous delay while maintaining a large batch size, we address the issue of high computational cost. Additionally, we incorporate sparse model learning into the training process, significantly reducing computational cost. This article also provides theoretical proof that the convergence rate does not decrease significantly with increasing batch size. Various experiments on six high-dimensional real-world datasets demonstrate the efficacy and efficiency of the proposed algorithms, with a communication cost reduction of up to \(90.89\%\) and a maximum wall time speedup of \(5.66\times\) compared to the baseline methods.},
  archive      = {J_TKDD},
  author       = {Dezhong Yao and Sanmu Li and Zhiwei Wang and Peilin Zhao and Gang Wu and Chen Yu and Hai Jin},
  doi          = {10.1145/3712603},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient distributed sparse relative similarity learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear correct and smooth for graph-based semi-supervised learning. <em>TKDD</em>, <em>19</em>(3), 1-32. (<a href='https://doi.org/10.1145/3712604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based semi-supervised learning (GSSL) has achieved significant success across various applications by leveraging the graph structure and labeled samples for classification tasks. In the field of GSSL, Label Propagation (LP) and Graph Neural Networks (GNNs) are two complementary methods, in which LP iteratively propagates and updates node labels through connected nodes, whereas GNNs aggregate node features by incorporating information from their neighbors. Recently, the complementary nature of LP and GNNs has been utilized to improve performance through the combination of two approaches. However, the utilization of higher-order graph structures within these combined approaches, such as triangles, is still under-explored. Therefore, to advance understanding in this ongoing research, we first model GSSL as a two-step feature-label process. Then, we introduce Nonlinear Correct and Smooth (NLCS) in the post-processing step, a combined method that incorporates nonlinearity and higher-order structures into the residual propagation to handle intricate node relationships effectively. We propose a new synthetic graph generator to deepen the analysis and broaden the experimentation, providing insights into the mechanisms that enable NLCS to handle intricate node relationships effectively. Our systematic evaluations across six synthetic graphs show that NLCS outperforms base predictions by an average of 12.44% and the existing state-of-the-art post-processing method by 8.04%. Furthermore, on six commonly used real-world datasets, NLCS demonstrates a 10.9% improvement over six base prediction models and a 1.6% over the state-of-the-art post-processing method. Our comparisons and analyses reveal that NLCS substantially enhances the prediction accuracy of nodes within complex graph structures by effectively utilizing higher-order structures of graphs.},
  archive      = {J_TKDD},
  author       = {Yuanhang Shao and Xiuwen Liu},
  doi          = {10.1145/3712604},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Nonlinear correct and smooth for graph-based semi-supervised learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view learning from crowds. <em>TKDD</em>, <em>19</em>(3), 1-21. (<a href='https://doi.org/10.1145/3712605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing services provide a fast and cheap way to obtain substantial labeled data by employing crowd workers on the Internet. In crowdsourcing learning, two-stage methods have been widely used, which first infer the integrated label for each instance and then build a learning model using instances with their integrated labels. However, existing two-stage methods mainly focus on how to infer more accurate integrated labels, after that, most of them directly regard the integrated labels as class labels to build a learning model, which loses the detailed worker labeling information in multiple noisy labels and thus results in sub-optimal model accuracy. To solve this problem, in this study, we take the multiple noisy labels of each instance as its attribute value vector to construct another view in addition to the original attribute view, and propose a novel two-stage method called dual-view learning from crowds (DVLFC). In DVLFC, we first pick out workers with sufficient number of labels and augment the multiple noisy label set for each instance, then we build a supervised learning model in each view and at last we fuse their class-membership probabilities to get the final classification result. Extensive experiments on both real-world and artificial crowdsourced datasets prove the effectiveness of DVLFC.},
  archive      = {J_TKDD},
  author       = {Huan Zhang and Liangxiao Jiang and Wenjun Zhang and Geoffrey I. Webb},
  doi          = {10.1145/3712605},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Dual-view learning from crowds},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic block models for complex network analysis: A survey. <em>TKDD</em>, <em>19</em>(3), 1-35. (<a href='https://doi.org/10.1145/3713076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex networks enable to represent and characterize the interactions between entities in various complex systems which widely exist in the real world and usually generate vast amounts of data about all the elements, their behaviors and interactions over time. The studies concentrating on new network analysis approaches and methodologies are vital because of the diversity and ubiquity of complex networks. The stochastic block model (SBM), based on Bayesian theory, is a statistical network model. SBMs are essential tools for analyzing complex networks since SBMs have the advantages of interpretability, expressiveness, flexibility and generalization. Thus, designing diverse SBMs and their learning algorithms for various networks has become an intensively researched topic in network analysis and data mining. In this article, we review, in a comprehensive and in-depth manner, SBMs for different types of networks (i.e., model extensions), existing methods (including parameter estimation and model selection) for learning optimal SBMs for given networks and SBMs combined with deep learning. Finally, we provide an outlook on the future research directions of SBMs.},
  archive      = {J_TKDD},
  author       = {Xueyan Liu and Wenzhuo Song and Katarzyna Musial and Yang Li and Xuehua Zhao and Bo Yang},
  doi          = {10.1145/3713076},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Stochastic block models for complex network analysis: A survey},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacking factorizing partitioned expressions in hybrid bayesian network models. <em>TKDD</em>, <em>19</em>(3), 1-28. (<a href='https://doi.org/10.1145/3714473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid Bayesian networks (HBN) contain complex conditional probability distributions (CPD) specified as partitioned expressions over discrete and continuous variables. The size of these CPDs grows exponentially with the number of parent nodes, and when using discrete inference methods, it results in significant execution time and space inefficiency. To reduce the CPD size, a binary factorization (BF) algorithm can be used to decompose the statistical or arithmetic functions in the CPD by factorizing the number of connected parent nodes into sets of size two. However, the BF algorithm was not designed to handle partitioned expressions. Therefore, we propose a new stacking factorization (SF) algorithm to decompose partitioned expressions. The SF algorithm creates intermediate nodes to incrementally reconstruct the conditional densities in the original partitioned expression, ensuring that no more than two continuous parent nodes are connected to each child node in the resulting HBN. It generally applies to both discrete and continuous child nodes with complex partitioned expressions. When we combine SF with a dynamic discretization (DD) inference algorithm, we achieve a significant improvement in inference efficiency. Experimental results demonstrate that the combination of SF and DD can effectively manage HBNs with complex CPDs that may challenge other algorithms, which also outperform competing inference algorithms in accuracy.},
  archive      = {J_TKDD},
  author       = {Peng Lin and Martin Neil and Norman Fenton},
  doi          = {10.1145/3714473},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Stacking factorizing partitioned expressions in hybrid bayesian network models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable deep learning-based model for decision-making through piecewise linear approximation. <em>TKDD</em>, <em>19</em>(3), 1-35. (<a href='https://doi.org/10.1145/3715150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full-complexity machine learning models, such as the deep neural network, are non-traceable black-box, whereas the classic interpretable models, such as linear regression models, are often over-simplified, leading to lower accuracy. Model interpretability limits the application of machine learning models in management problems, which requires high prediction performance, as well as the understanding of individual features’ contributions to the model outcome. To enhance model interpretability while preserving good prediction performance, we propose a hybrid interpretable model that combines a piecewise linear component and a nonlinear component. The first component describes the explicit feature contributions by piecewise linear approximation to increase the expressiveness of the model. The other component uses a multi-layer perceptron to increase the prediction performance by capturing the high-order interactions between features and their complex nonlinear transformations. The interpretability is obtained once the model is learned in the form of shape functions for the main effects. We also provide a variant to explore the higher-order interactions among features. Experiments are conducted on synthetic and real-world datasets to demonstrate that the proposed models can achieve good interpretability by explicitly describing the main effects and the interaction effects of the features while maintaining state-of-the-art accuracy.},
  archive      = {J_TKDD},
  author       = {Mengzhuo Guo and Qingpeng Zhang and Daniel Dajun Zeng},
  doi          = {10.1145/3715150},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An interpretable deep learning-based model for decision-making through piecewise linear approximation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled multi-graph convolution for cross-domain recommendation. <em>TKDD</em>, <em>19</em>(3), 1-28. (<a href='https://doi.org/10.1145/3715151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity poses a significant challenge for recommendation systems, prompting the research of Cross-Domain Recommendation ( CDR ). CDR aims to leverage more user-item interaction information from source domains to improve the recommendation performance in the target domain. However, a major challenge in CDR is the identification of transferable features. Traditional CDR methods struggle to distinguish between the various features of users, including domain-invariant features that are effective for feature transfer and domain-specific features that are detrimental to cross-domain information transfer. In this article, we aim to disentangle domain-invariant features and domain-specific features and effectively utilize these different features. This enables effective domain-to-domain information transfer by only transferring domain-invariant features while still considering the role of domain-specific features within their respective domains. Based on the superiority of graph structural feature learning and disentangled represent learning, we propose \(\mathbf{DMGCDR}\) —a model that learns D isentangled user feature representations and constructs a M ulti- G raph network for bidirectional knowledge transfer of shared features for CDR . Specifically, we designed two regularization terms to disentangle domain-invariant features and domain-specific features. Subsequently, we established a multi-graph convolutional network to enhance domain-specific features within single-domain graphs and transfer domain-invariant features across cross-domain graphs. Our approach also includes designing feature constraints to enhance the combination of features derived from different graphs and to uncover potential correlations among them. Extensive experiments on real-world datasets have demonstrated that our model significantly outperforms state-of-the-art CDR approaches.},
  archive      = {J_TKDD},
  author       = {Yibo Gao and Zhen Liu and Xinxin Yang and Sibo Lu and Yafan Yuan},
  doi          = {10.1145/3715151},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Disentangled multi-graph convolution for cross-domain recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-attentive rationalization for interpretable graph contrastive learning. <em>TKDD</em>, <em>19</em>(2), 1-21. (<a href='https://doi.org/10.1145/3665894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph augmentation is the key component to reveal instance-discriminative features of a graph as its rationale—an interpretation for it—in graph contrastive learning (GCL). Existing rationale-aware augmentation mechanisms in GCL frameworks roughly fall into two categories and suffer from inherent limitations: (1) non-heuristic methods with the guidance of domain knowledge to preserve salient features, which require expensive expertise and lack generality, or (2) heuristic augmentations with a co-trained auxiliary model to identify crucial substructures, which face not only the dilemma between system complexity and transformation diversitybut also the instability stemming from the co-training of two separated sub-models. Inspired by recent studies on transformers, we propose self-attentive rationale-guided GCL (SR-GCL), which integrates rationale generator and encoder together, leverages the self-attention values in transformer module as a natural guidance to delineate semantically informative substructures from both node- and edge-wise perspectives, and contrasts on rationale-aware augmented pairs. On real-world biochemistry datasets, visualization results verify the effectiveness and interpretability of self-attentive rationalization, and the performance on downstream tasks demonstrates the state-of-the-art performance of SR-GCL for graph model pre-training. Codes are available at https://github.com/lsh0520/SR-GCL .},
  archive      = {J_TKDD},
  author       = {Sihang Li and Yanchen Luo and An Zhang and Xiang Wang and Longfei Li and Jun Zhou and Tat-Seng Chua},
  doi          = {10.1145/3665894},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Self-attentive rationalization for interpretable graph contrastive learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting fair classifier generalization through adaptive priority reweighing. <em>TKDD</em>, <em>19</em>(2), 1-26. (<a href='https://doi.org/10.1145/3665895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing penetration of machine learning applications in critical decision-making areas, calls for algorithmic fairness are more prominent. Although there have been various modalities to improve algorithmic fairness through learning with fairness constraints, their performance does not generalize well in the test set. A performance-promising fair algorithm with better generalizability is needed. This article proposes a novel adaptive reweighing method to eliminate the impact of the distribution shifts between training and test data on model generalizability. Most previous reweighing methods propose to assign a unified weight for each (sub)group. Rather, our method granularly models the distance from the sample predictions to the decision boundary. Our adaptive reweighing method prioritizes samples closer to the decision boundary and assigns a higher weight to improve the generalizability of fair classifiers. Extensive experiments are performed to validate the generalizability of our adaptive priority reweighing method for accuracy and fairness measures (i.e., equal opportunity, equalized odds, and demographic parity) in tabular benchmarks. We also highlight the performance of our method in improving the fairness of language and vision models. The code is available at https://github.com/che2198/APW .},
  archive      = {J_TKDD},
  author       = {Zhihao Hu and Yiran Xu and Mengnan Du and Jindong Gu and Xinmei Tian and Fengxiang He},
  doi          = {10.1145/3665895},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Boosting fair classifier generalization through adaptive priority reweighing},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interdisciplinary fairness in imbalanced research proposal topic inference: A hierarchical transformer-based method with selective interpolation. <em>TKDD</em>, <em>19</em>(2), 1-21. (<a href='https://doi.org/10.1145/3671149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of topic inference in research proposals aims to obtain the most suitable disciplinary division from the discipline system defined by a funding agency. The agency will subsequently find appropriate peer-review experts from their database based on this division. Automated topic inference can reduce human errors caused by manual topic filling, bridge the knowledge gap between funding agencies and project applicants, and improve system efficiency. Existing methods focus on modeling this as a hierarchical multi-label classification problem, using generative models to iteratively infer the most appropriate topic information. However, these methods overlook the gap in scale between interdisciplinary research proposals and non-interdisciplinary ones, leading to an unjust phenomenon where the automated inference system categorizes interdisciplinary proposals as non-interdisciplinary, causing unfairness during the expert assignment. How can we address this data imbalance issue under a complex discipline system and hence resolve this unfairness? In this article, we implement a topic label inference system based on a Transformer encoder–decoder architecture. Furthermore, we utilize interpolation techniques to create a series of pseudo-interdisciplinary proposals from non-interdisciplinary ones during training based on non-parametric indicators, such as cross-topic probabilities and topic occurrence probabilities. This approach aims to reduce the bias of the system during model training. Finally, we conduct extensive experiments on a real-world dataset to verify the effectiveness of the proposed method. The experimental results demonstrate that our training strategy can significantly mitigate the unfairness generated in the topic inference task. To improve the reproducibility of our research, we have released accompanying code by Dropbox. 1},
  archive      = {J_TKDD},
  author       = {Meng Xiao and Min Wu and Ziyue Qiao and Yanjie Fu and Zhiyuan Ning and Yi Du and Yuanchun Zhou},
  doi          = {10.1145/3671149},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Interdisciplinary fairness in imbalanced research proposal topic inference: A hierarchical transformer-based method with selective interpolation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive understanding of the impact of data augmentation on the transferability of 3D adversarial examples. <em>TKDD</em>, <em>19</em>(2), 1-41. (<a href='https://doi.org/10.1145/3673232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D point cloud classifiers exhibit vulnerability to imperceptible perturbations, which poses a serious threat to the security and reliability of deep learning models in practical applications, making the robustness evaluation of deep 3D point cloud models increasingly important. Due to the difficulty in obtaining model parameters, black-box attacks have become a mainstream means of assessing the adversarial robustness of 3D classification models. The core of improving the transferability of adversarial examples generated by black-box attacks is to generate better generalized adversarial examples, where data augmentation has become one of the popular approaches. In this article, we employ five mainstream attack methods and combine six data augmentation strategies, namely point dropping, flipping, rotating, scaling, shearing, and translating, in order to comprehensively explore the impact of these strategies on the transferability of adversarial examples. Our research reveals that data augmentation methods generally improve the transferability of the adversarial examples, and the effect is better when the methods are stacked. The interaction between data augmentation methods, model characteristics, attack, and defense strategies collectively determines the transferability of adversarial examples. In order to comprehensively understand and improve the effectiveness of adversarial examples, it is necessary to comprehensively consider these complex interrelationships.},
  archive      = {J_TKDD},
  author       = {Fulan Qian and Yuanjun Zou and Mengyao Xu and Xuejun Zhang and Chonghao Zhang and Chenchu Xu and Hai Chen},
  doi          = {10.1145/3673232},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-41},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A comprehensive understanding of the impact of data augmentation on the transferability of 3D adversarial examples},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A question-centric multi-experts contrastive learning framework for improving the accuracy and interpretability of deep sequential knowledge tracing models. <em>TKDD</em>, <em>19</em>(2), 1-25. (<a href='https://doi.org/10.1145/3674840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) plays a crucial role in predicting students’ future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in modeling the individual question information. This is crucial because students’ knowledge acquisition on questions that share the same set of knowledge components (KCs) may vary significantly. However, due to the large question bank, the average number of interactions per question may not be sufficient. This limitation can potentially result in overfitting of the question embedding and inaccurate question knowledge acquisition state that relies on its corresponding question representation. Furthermore, there is a considerable portion of questions receiving relatively less interaction from students in comparison to the majority of questions. This can further increase the risk of overfitting and lower the accuracy of the obtained question knowledge acquisition state. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model’s prediction results in a manner that teachers find interpretable. This makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. However, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model’s prediction results. To address these challenges, we propose a Question-centric Multi-experts Contrastive Learning framework for KT called Q-MCKT. This framework explicitly models students’ knowledge acquisition state at both the question and concept levels. It leverages the mixture of experts technique to capture a more robust and accurate knowledge acquisition state in both question and concept levels for prediction. Additionally, a fine-grained question-centric contrastive learning task is introduced to enhance the representations of less interactive questions and improve the accuracy of their corresponding question knowledge acquisition states. Moreover, Q-MCKT utilizes an item response theory-based prediction layer to generate interpretable prediction results based on the knowledge acquisition states obtained from the question and concept knowledge acquisition modules. We evaluate the proposed Q-MCKT framework on four public real-world educational datasets. The experimental results demonstrate that our approach outperforms a wide range of deep learning-based KT models in terms of prediction accuracy while maintaining better model interpretability. To ensure reproducibility, we have provided all the datasets and code on our website at https://github.com/rattlesnakey/Q-MCKT .},
  archive      = {J_TKDD},
  author       = {Hengyuan Zhang and Zitao Liu and Chenming Shang and Dawei Li and Yong Jiang},
  doi          = {10.1145/3674840},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A question-centric multi-experts contrastive learning framework for improving the accuracy and interpretability of deep sequential knowledge tracing models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting pre-trained models and low-frequency preference for cost-effective transfer-based attack. <em>TKDD</em>, <em>19</em>(2), 1-18. (<a href='https://doi.org/10.1145/3680553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transferability of adversarial examples enables practical transfer-based attacks. However, existing theoretical analysis cannot effectively reveal what factors contribute to cross-model transferability. Furthermore, the assumption that the target model dataset is available together with expensive prices of training proxy models also leads to insufficient practicality. We first propose a novel frequency perspective to study the transferability and then identify two factors that impair the transferability: an unchangeable intrinsic difference term along with a controllable perturbation-related term. To enhance the transferability, an optimization task with the constraint that decreases the impact of the perturbation-related term is formulated and an approximate solution for the task is designed to address the intractability of Fourier expansion. To address the second issue, we suggest employing pre-trained models as proxy models, which are freely available. Leveraging these advancements, we introduce cost-effective transfer-based attack ( CTA ), which addresses the optimization task in pre-trained models. CTA can be unleashed against broad applications, at any time, with minimal effort and nearly zero cost to attackers. This remarkable feature indeed makes CTA an effective, versatile, and fundamental tool for attacking and understanding a wide range of target models, regardless of their architecture or training dataset used. Extensive experiments show impressive attack performance of CTA across various models trained in seven black-box domains, highlighting the broad applicability and effectiveness of CTA .},
  archive      = {J_TKDD},
  author       = {Mingyuan Fan and Cen Chen and Chengyu Wang and Jun Huang},
  doi          = {10.1145/3680553},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting pre-trained models and low-frequency preference for cost-effective transfer-based attack},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair-RGNN: Mitigating relational bias on knowledge graphs. <em>TKDD</em>, <em>19</em>(2), 1-18. (<a href='https://doi.org/10.1145/3681792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph data are prevalent in real-world applications, and knowledge graph neural networks (KGNNs) are essential techniques for knowledge graph representation learning. Although KGNN effectively models the structural information from knowledge graphs, these frameworks amplify the underlying data bias that leads to discrimination towards certain groups or individuals in resulting applications. Additionally, as existing debiasing approaches mainly focus on entity-wise bias, eliminating the multi-hop relational bias that pervasively exists in knowledge graphs remains an open question. However, it is very challenging to eliminate relational bias due to the sparsity of the paths that generate the bias and the non-linear proximity structure of knowledge graphs. To tackle the challenges, we propose Fair-KGNN, a KGNN framework that simultaneously alleviates multi-hop bias and preserves the proximity information of entity-to-relation in knowledge graphs. The proposed framework is generalizable to mitigate relational bias for all types of KGNN. Fair-KGNN is applicable to incorporate two state-of-the-art KGNN models, RGCN and CompGCN, to mitigate gender-occupation and nationality-salary bias. The experiments carried out on three benchmark knowledge graph datasets demonstrate that Fair-KGNN can effectively mitigate unfair situations during representation learning while preserving the predictive performance of KGNN models. The source code of the proposed method is available at: https://github.com/ynchuang/Mitigating-Relational-Bias-on-Knowledge-Graphs .},
  archive      = {J_TKDD},
  author       = {Yu-Neng Chuang and Kwei-Herng Lai and Ruixiang Tang and Mengnan Du and Chia-Yuan Chang and Na Zou and Xia Hu},
  doi          = {10.1145/3681792},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fair-RGNN: Mitigating relational bias on knowledge graphs},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient GNN explanation via learning removal-based attribution. <em>TKDD</em>, <em>19</em>(2), 1-23. (<a href='https://doi.org/10.1145/3685678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Graph Neural Networks (GNNs) have been widely used in real-world applications, model explanations are required not only by users but also by legal regulations. However, simultaneously achieving high fidelity and low computational costs in generating explanations has been a challenge for current methods. In this work, we propose a framework of GNN explanation named L e A rn R emoval-based A ttribution (LARA) to address this problem. Specifically, we introduce removal-based attribution and demonstrate its substantiated link to interpretability fidelity theoretically and experimentally. The explainer in LARA learns to generate removal-based attribution which enables providing explanations with high fidelity. A strategy of subgraph sampling is designed in LARA to improve the scalability of the training process. In the deployment, LARA can efficiently generate the explanation through a feed-forward pass. We benchmark our approach with other state-of-the-art GNN explanation methods on six datasets. Results highlight the effectiveness of our framework regarding both efficiency and fidelity. In particular, LARA is 3.1 \(\times\) faster and achieves higher fidelity than the state-of-the-art method on the large dataset ogbn-arxiv (more than 160K nodes and 1M edges), showing its great potential in real-world applications. Our source code is available at https://github.com/yaorong0921/LARA .},
  archive      = {J_TKDD},
  author       = {Yao Rong and Guanchu Wang and Qizhang Feng and Ninghao Liu and Zirui Liu and Enkelejda Kasneci and Xia Hu},
  doi          = {10.1145/3685678},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient GNN explanation via learning removal-based attribution},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-tuning large language models with structured medical knowledge bases for trustworthy response generation in chinese. <em>TKDD</em>, <em>19</em>(2), 1-17. (<a href='https://doi.org/10.1145/3686807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts. To address this challenge, we propose knowledge-tuning, which leverages structured medical knowledge bases for the LLMs to grasp domain knowledge efficiently and facilitate trustworthy response generation. We also release cMedKnowQA, a Chinese medical knowledge question-answering dataset constructed from medical knowledge bases to assess the medical knowledge proficiency of LLMs. Experimental results show that the LLMs which are knowledge-tuned with cMedKnowQA can exhibit higher levels of accuracy in response generation compared with vanilla instruction-tuning and offer a new trustworthy way for the domain adaptation of LLMs. We release our code and data at https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese .},
  archive      = {J_TKDD},
  author       = {Haochun Wang and Sendong Zhao and Zewen Qiang and Zijian Li and Chi Liu and Nuwa Xi and Yanrui Du and Bing Qin and Ting Liu},
  doi          = {10.1145/3686807},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge-tuning large language models with structured medical knowledge bases for trustworthy response generation in chinese},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards prototype-based self-explainable graph neural network. <em>TKDD</em>, <em>19</em>(2), 1-20. (<a href='https://doi.org/10.1145/3689647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown great ability in modeling graph-structured data for various domains. However, GNNs are known as black-box models that lack interpretability. Without understanding their inner working, we cannot fully trust them, which largely limits their adoption in high-stake scenarios. Though some initial efforts have been taken to interpret the predictions of GNNs, they mainly focus on providing post hoc explanations using an additional explainer, which could misrepresent the true inner working mechanism of the target GNN. The works on self-explainable GNNs are rather limited. Therefore, we study a novel problem of learning prototype-based self-explainable GNNs that can simultaneously give accurate predictions and prototype-based explanations on predictions. We design a framework which can learn prototype graphs that capture representative patterns of each class as class-level explanations. The learned prototypes are also used to simultaneously make prediction for a test instance and provide instance-level explanation. Extensive experiments on real-world and synthetic datasets show the effectiveness of the proposed framework for both prediction accuracy and explanation quality.},
  archive      = {J_TKDD},
  author       = {Enyan Dai and Suhang Wang},
  doi          = {10.1145/3689647},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards prototype-based self-explainable graph neural network},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDE-HNN: Accurate and well-calibrated forecasting using stochastic differential equations. <em>TKDD</em>, <em>19</em>(2), 1-23. (<a href='https://doi.org/10.1145/3691346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial yet challenging for deep learning models to properly characterize uncertainty that is pervasive in real-world environments. Heteroscedastic neural networks (HNNs) are promising methods that capture data uncertainty for forecasting problems while existing HNNs have difficulties in conjoining calibrated uncertainty estimation and satisfactory predictive performance due to the failure to construct an explicit interaction between the prediction and its associated uncertainty. This article develops SDE-HNN, an improved HNN equipped with stochastic differential equations (SDE), to characterize the interaction between the predictive mean and variance inside HNNs for accurate and reliable forecasting. The existence and uniqueness of the solution to the devised neural SDE are guaranteed. Moreover, based on the bias-variance tradeoff for the optimization in SDE-HNN, we design an enhanced numerical SDE solver to improve learning stability. Finally, we present two new diagnostic uncertainty metrics to systematically evaluate the predictive uncertainty. Experiments on various challenging datasets show that our method significantly outperforms state-of-the-art baselines on both predictive performance and uncertainty quantification, delivering well-calibrated and sharp prediction intervals in time-series forecasting.},
  archive      = {J_TKDD},
  author       = {Peng Cui and Zhijie Deng and Wenbo Hu and Jun Zhu},
  doi          = {10.1145/3691346},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SDE-HNN: Accurate and well-calibrated forecasting using stochastic differential equations},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuralCODE: Neural compartmental ordinary differential equations model with AutoML for interpretable epidemic forecasting. <em>TKDD</em>, <em>19</em>(2), 1-18. (<a href='https://doi.org/10.1145/3694688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to prevent the re-emergence of an epidemic, predicting its trend while gaining insight into the intrinsic factors affecting it is a key issue in urban governance. Traditional SIR-like compartment models provide insight into the explanatory parameters of an outbreak, and the vast majority of existing deep learning models can predict the course of an outbreak well, but neither performs well in the other’s domain. Simultaneously, studying the commonalities and diversities in the causes of outbreaks among different countrywide regions is also a way to interrupt outbreaks. To address the issues of outbreak intrinsic relationships and prediction, we propose the Neural Compartmental Ordinary Differential Equations (NeuralCODE) model to study the relationship between population movements and outbreak development in different regions. Furthermore, to incorporate the commonalities and diversities in causes among different regions into the prediction and intrinsic inquiry problem, we propose an AutoML framework. Our results found that simply using the NeuralCODE algorithm could obtain better prediction and insight capabilities within different regions. With the introduction of AutoML, it became possible to explore the factors inherent in the epidemic’s development across regions and further improve the original algorithm’s predictive performance.},
  archive      = {J_TKDD},
  author       = {Yuxi Huang and Huandong Wang and Guanghua Liu and Yong Li and Tao Jiang},
  doi          = {10.1145/3694688},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {NeuralCODE: Neural compartmental ordinary differential equations model with AutoML for interpretable epidemic forecasting},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy neural logic reasoning for robust classification. <em>TKDD</em>, <em>19</em>(2), 1-29. (<a href='https://doi.org/10.1145/3704728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacy of neural networks is widely recognized across a multitude of machine learning tasks, yet their black-box nature impedes the understanding of their decision-making processes. Such lack of explainability limits their use in high-stake fields such as medicine and finance, where transparent decision-making is essential. In contrast, traditional rule-based models offer clear input-output mappings, but often lag in performance when compared to their neural network counterparts. To address this challenge, this study introduces Fuzzy Neural Logic Reasoning (FNLR), a novel architecture that combines the best of both rule-based and deep learning models to achieve performance, interpretability, and noise robustness simultaneously. At its core, FNLR employs a “Symbolic Pre-Training \(+\) Neural Fine-Tuning” paradigm. Initially, the model adapts a pre-fitted binary decision tree. It then performs a “neuralization” process, replacing each node of the tree with a corresponding neural network equivalent. This transformation is facilitated through three shallow MLP modules, which are trained to emulate the relational operators intrinsic to decision trees. The model architecture is also extensible, allowing it to further boost expressiveness. Furthermore, FNLR incorporates fuzzy logic by proposing novel fuzzy relational operators, accounting for satisfaction degrees of propositions and thus eliminating rigid decision boundaries. This approach enhances model flexibility, enabling all paths of the decision tree to contribute to the target prediction in a weighted manner. Empirical evaluations on tabular datasets from various domains demonstrate that FNLR performs comparably to, or better than, state-of-the-art deep learning models designed for tabular data, while also exhibiting strong robustness to noise.},
  archive      = {J_TKDD},
  author       = {Guo Lin and Yongfeng Zhang},
  doi          = {10.1145/3704728},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fuzzy neural logic reasoning for robust classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple data augmentation for graph classification: A perspective of equivariance and invariance. <em>TKDD</em>, <em>19</em>(2), 1-24. (<a href='https://doi.org/10.1145/3706062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph classification, the out-of-distribution (OOD) issue is attracting great attention. To address this issue, a prevailing idea is to learn stable features, on the assumption that they are substructures causally determining the label and that their relationship with the label is stable to the distributional uncertainty. In contrast, the complementary parts termed environmental features, fail to determine the label solely and hold varying relationships with the label, thus ascribed to the possible reason for the distribution shift. Existing generalization efforts mainly encourage the model’s insensitivity to environmental features. While the sensitivity to stable features is promising to distinguish the crucial clues from the distributional uncertainty but largely unexplored. A paradigm of simultaneously exploring the sensitivity to stable features and insensitivity to environmental features is until-now lacking to achieve the generalizable graph classification, to the best of our knowledge. In this work, we conjecture that generalizable models should be sensitive to stable features and insensitive to environmental features. To this end, we propose a simple yet effective augmentation strategy for graph classification: Equivariant and Invariant Cross-Data Augmentation (EI-CDA). By employing equivariance, given a pair of input graphs, we first estimate their stable and environmental features via masks. Then, we linearly mix the estimated stable features of two graphs and encourage the model predictions faithfully reflect their mixed semantics. Meanwhile, by using invariance, we swap the estimated environmental features of two graphs and keep the predictions invariant. This simple yet effective strategy endows the models with both sensitivity to stable features and insensitivity to environmental features. Extensive experiments show that EI-CDA significantly improves performance and outperforms leading baselines. Our codes are available at: https://github.com/yongduosui/EI-GNN .},
  archive      = {J_TKDD},
  author       = {Yongduo Sui and Shuyao Wang and Jie Sun and Zhiyuan Liu and Qing Cui and Longfei Li and Jun Zhou and Xiang Wang and Xiangnan He},
  doi          = {10.1145/3706062},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A simple data augmentation for graph classification: A perspective of equivariance and invariance},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient latent-based scoring function search for N-ary relational knowledge bases. <em>TKDD</em>, <em>19</em>(2), 1-26. (<a href='https://doi.org/10.1145/3707644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing a proper scoring function is the key to ensuring the excellent performance of knowledge base (KB) embedding. Recently, the scoring function search method introduces the automated machine learning technique to design the data-aware scoring function for the given binary relational data (a.k.a. knowledge graph, KG), which can consistently achieve good performance on different data sets. However, the current data-aware search method is still not as good as desired. First, the existing model can only search scoring functions on the given binary relational data, which is a special form of N-ary relational KBs. Second, observing that existing scoring functions can exhibit distinct performance on different semantic patterns, we are motivated to explore such semantics by searching pattern-aware scoring functions. Unfortunately, it is hard to extend existing search approaches to the scenarios of N-ary and pattern-aware due to the search efficiency and effectiveness issues. In this paper, we propose latent-based factors to model relational patterns and an efficient search algorithm on the N-ary scenario, i.e., efficient LA tent-based SCO ring function search for N-ary relational KBs (LASCO). The empirical results of LASCO on binary and N-ary relational data sets demonstrate that the proposed method can efficiently search pattern-aware scoring functions and achieve better embedding performance than advanced baselines.},
  archive      = {J_TKDD},
  author       = {Shimin Di and Yongqi Zhang and Quanming Yao and Xiaofang Zhou and Lei Chen},
  doi          = {10.1145/3707644},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient latent-based scoring function search for N-ary relational knowledge bases},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building robust and trustworthy HGNN models: A learnable threshold approach for node classification. <em>TKDD</em>, <em>19</em>(2), 1-17. (<a href='https://doi.org/10.1145/3707645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message passing scheme is a general idea for Graph Neural Networks (GNNs) to learn node representations. During message passing, given a target node, we transform and aggregate the feature vectors of its neighbors and generate a representation vector for the target node. However, real-world graph data is usually constructed from complicated scenarios based on manually pre-defined rules; it is often the case that noisy information gets involved in message passing, thereby resulting in sub-optimal performance for GNNs and also impacting their trustworthiness and reliability. In this study, we present an effective learnable threshold technique that explicitly optimizes heterogeneous graph structure with the goal to maximize performance improvement of GNNs for downstream tasks. We give an explanation about the design of the learnable threshold and show the ability that our model can be applied to large-scale graphs. Experiments on seven datasets show that our model has a powerful ability to deal with homogeneous graphs with low homophily ratio and dense graphs. With the verification of robustness analysis, our model can resist the noisy information, which proves the robustness of our model.},
  archive      = {J_TKDD},
  author       = {Li Ma and Yongchao Liu and Xiaofeng Gao and Peng Zhang and Chuntao Hong},
  doi          = {10.1145/3707645},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Building robust and trustworthy HGNN models: A learnable threshold approach for node classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Means of hitting times for random walks on graphs: Connections, computation, and optimization. <em>TKDD</em>, <em>19</em>(2), 1-35. (<a href='https://doi.org/10.1145/3708561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For random walks on graph \(\mathcal{G}\) with \(n\) vertices and \(m\) edges, the mean hitting time \(H_{j}\) from a vertex chosen from the stationary distribution to vertex \(j\) measures the importance for \(j\) , while the Kemeny constant \(\mathcal{K}\) is the mean hitting time from one vertex to another selected randomly according to the stationary distribution. In this article, we first establish a connection between the two quantities, representing \(\mathcal{K}\) in terms of \(H_{j}\) for all vertices. We then develop an efficient algorithm estimating \(H_{j}\) for all vertices and \(\mathcal{K}\) in nearly linear time of \(m\) . Moreover, we extend the centrality \(H_{j}\) of a single vertex to \(H(S)\) of a vertex set \(S\) , and establish a link between \(H(S)\) and some other quantities. We further study the NP-hard problem of selecting a group \(S\) of \(k\ll n\) vertices with minimum \(H(S)\) , whose objective function is monotonic and supermodular. We finally propose two greedy algorithms approximately solving the problem. The former has an approximation factor \((1-\frac{k}{k-1}\frac{1}{e})\) and \(O(kn^{3})\) running time, while the latter returns a \((1-\frac{k}{k-1}\frac{1}{e}-\epsilon)\) -approximation solution in nearly-linear time of \(m\) , for any parameter \(0{\lt}\epsilon{\lt}1\) . Extensive experiment results validate the performance of our algorithms.},
  archive      = {J_TKDD},
  author       = {Haisong Xia and Wanyue Xu and Zuobai Zhang and Zhongzhi Zhang},
  doi          = {10.1145/3708561},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Means of hitting times for random walks on graphs: Connections, computation, and optimization},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple attention layer-shareable method for link prediction in multilayer networks. <em>TKDD</em>, <em>19</em>(2), 1-22. (<a href='https://doi.org/10.1145/3709142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in multilayer networks aims to predict missing links at the target layer by incorporating structural information from both auxiliary layers and the target layer. Existing methods tend to learn layer-specific knowledge to maximize the link prediction performance on a specific network layer. However, they have difficulty incorporating multilayer structural information to improve the link prediction performance. Therefore, we propose a Multiple Attention Layer-shareable Method (MALM) for link prediction in multilayer networks, which consists of a feature encoder, a knowledge learner, and a fusion predictor. The feature encoder introduces multiple attention mechanisms to encode the feature representations of links by differentiating the importance of structural information for each link. In cooperation with the feature encoder, the knowledge learner splits the link prediction tasks into different layers and employs meta-learning to learn layer-shareable knowledge from these link prediction tasks. Finally, the fusion predictor combines the learned layer-shareable knowledge with the layer-specific knowledge at the target layer for link prediction. Experiments on real-world datasets demonstrate that the proposed MALM outperforms existing state-of-the-art baselines in link prediction in multilayer networks.},
  archive      = {J_TKDD},
  author       = {Huan Wang and Yu Teng and Lingsong Qin and Xuan Guo and Po Hu},
  doi          = {10.1145/3709142},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A multiple attention layer-shareable method for link prediction in multilayer networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering time-aware hidden dependencies with personalized graphical structure in electronic health records. <em>TKDD</em>, <em>19</em>(2), 1-21. (<a href='https://doi.org/10.1145/3709143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, significant advancements in mining electronic health records (EHRs) have enabled a broad range of decision-support applications and offered an unprecedented capacity for predicting critical events such as disease prognosis and mortality in healthcare. Despite the availability of comprehensive coding systems in EHRs (e.g., ICD-9), which are designed to record diverse information on diseases, procedures, and medications over time, the complex and dynamic dependencies among the recorded data are usually not captured. This limitation often hinders the contextual understanding of medical observations for effective EHR representation learning. Therefore, there is a compelling need to discover a hidden “EHR graph” that represents the medical relationship between the observed features according to a patient’s history. These hidden graphs consisting of the medical codes from the same visits can offer a comprehensive insight derived from disease-to-disease, disease-to-drug, and drug-to-drug dependencies. However, it is still unclear how to address the challenge that the dependencies may vary from patient to patient, and they can dynamically evolve from one visit to another. To this end, we propose Time-aware Personalized Graph Transformer (TPGT), a novel attention-based time-aware hidden graph model, that captures the personalized graphical structures among observed medical codes and summarizes the temporal code dependencies over time to improve patient representation for outcome prediction. Built upon an intra-visit and an inter-visit dual-attention mechanism to model patients’ EHR graphs, our model offers an interpretability of what diagnosis or medication in a patient’s history can interact, and how those interactions may change over time. We conduct extensive experiments on two real-world EHR datasets for different healthcare predictive tasks: acute kidney injury (AKI) prediction and ICU mortality prediction. The experimental results demonstrate a significant performance improvement of the proposed model over baselines through multi-aspect quantitative evaluation. Furthermore, we perform various qualitative studies to validate the interpretability of the model which highlights the application of the proposed method in the context of personalized medicine.},
  archive      = {J_TKDD},
  author       = {Arya Hadizadeh Moghaddam and Mohsen Nayebi Kerdabadi and Bin Liu and Mei Liu and Zijun Yao},
  doi          = {10.1145/3709143},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Discovering time-aware hidden dependencies with personalized graphical structure in electronic health records},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction for the special issue on trustworthy artificial intelligence. <em>TKDD</em>, <em>19</em>(2), 1-6. (<a href='https://doi.org/10.1145/3712184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TKDD},
  author       = {Wenqi Fan and Shu Zhao and Jiliang Tang},
  doi          = {10.1145/3712184},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-6},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Introduction for the special issue on trustworthy artificial intelligence},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). -GAN+: Complex-condition-controlled generative adversarial networks with enhanced embedding. <em>TKDD</em>, <em>19</em>(2), 1-21. (<a href='https://doi.org/10.1145/3712264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given historical traffic distributions and associated urban conditions observed in a city, the conditional urban traffic estimation problem aims at estimating realistic future projections of the traffic under a set of new urban conditions, e.g., new bus routes, rainfall intensity, and travel demands. The problem is important in reducing traffic congestion, improving public transportation efficiency, and facilitating urban planning. However, solving this problem is challenging due to the strong spatial dependencies of traffic patterns and the complex relations between the traffic and urban conditions. Recently, we proposed a Complex-Condition-Controlled Generative Adversarial Network ( \(\boldsymbol{C^{3}}\) -GAN) , which tackles both of the challenges and solves the urban traffic estimation problem under various complex conditions by adding a fixed embedding network and an inference network on top of the standard conditional GAN model. The randomly chosen embedding network transforms the complex conditions to latent vectors, and the inference network enhances the connections between the embedded vectors and the traffic data. However, a randomly chosen embedding network cannot always successfully extract features of complex urban conditions, which indicates \(C^{3}\) -GAN is unable to uniquely map different urban conditions to proper latent distributions. Thus, \(C^{3}\) -GAN would fail in certain traffic estimation tasks. Besides, \(C^{3}\) -GAN is hard to train due to vanishing gradients and mode collapse problems. To address these issues, in this article, we extend our prior work by introducing a new deep generative model, namely, \(C^{3}\) -GAN \(+\) , which significantly improves the estimation performance and model stability. \(C^{3}\) -GAN \(+\) has new objective, architecture, and training algorithm. The new objective applies Wasserstein loss to the conditional generation case to encourage stable training. Shared convolutional layers between the discriminator and the inference network help to capture spatial dependencies of traffic more efficiently, part of the shared convolutional layers are used to update the embedding network periodically aiming to encourage good representation and avoid model divergence. Extensive experiments on real-world datasets demonstrate that our \(C^{3}\) -GAN \(+\) produces high-quality traffic estimations and outperforms state-of-the-art baseline methods.},
  archive      = {J_TKDD},
  author       = {Yingxue Zhang and Yanhua Li and Xun Zhou and Zhenming Liu and Jun Luo},
  doi          = {10.1145/3712264},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {-GAN+: Complex-condition-controlled generative adversarial networks with enhanced embedding},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern-oriented attention mechanism for multivariate time series forecasting. <em>TKDD</em>, <em>19</em>(2), 1-26. (<a href='https://doi.org/10.1145/3712606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting is applied in many domains, such as finance, transportation, and industry. The main challenge of precise forecasting lies in accurately capturing latent dependencies. Recent studies develop various frameworks to reduce computational complexity or to enhance the learning of intricate relationships, while lacking interpretability and generality. In this article, we aim to elucidate the capture of dependencies as the recognition of patterns. We believe that patterns can be formally described from two aspects: the shapes of segments that frequently repeat and the corresponding forms of repetitions. Drawing upon this idea, we design a multivariate time series forecasting model named PRformer , 1 which incorporates a pattern-oriented attention mechanism and a pattern-based projector. The attention mechanism can perceive different forms of repetitions by embedded with various similarity evaluation metrics between segments, and filter out noise from segments to extract potential patterns with a statistical-driven weighting scheme. The pattern-based projector is employed to form the forecasting results by deriving the representative patterns from the set of potential ones. By incorporating explicit definitions of patterns, PRformer is interpretable and general to various time series scenarios. Experimental results on seven datasets demonstrate that PRformer outperforms six state-of-the-art models by about 10.7% in forecasting accuracy.},
  archive      = {J_TKDD},
  author       = {Hanwen Hu and Zhangchi Han and Shiyou Qian and Dingyu Yang and Jian Cao and Guangtao Xue},
  doi          = {10.1145/3712606},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Pattern-oriented attention mechanism for multivariate time series forecasting},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive rumor suppression on social networks: A multi-round hybrid approach. <em>TKDD</em>, <em>19</em>(2), 1-24. (<a href='https://doi.org/10.1145/3701738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumor suppression is targeted at diminishing the impact of false and negative information within social networks by decreasing the prevalence of belief in such rumors among individuals, utilizing diverse strategies. Previous studies have broadly delineated rumor suppression strategies into two primary categories: targeting key nodes or edges for obstruction, and enlisting high-influence nodes to disseminate truth-related accurate information. Traditionally, employing a singular strategy involves utilizing a static algorithm throughout the rumor suppression endeavor. This method, however, encounters difficulties in adapting to fluctuating external conditions, rendering it less efficacious in the management of rumor proliferation. In response to these challenges, we introduce the concept of Adaptive Rumor Suppression (ARS), which aims to dynamically counter rumors by taking into account the nuances of propagation dynamics and the surrounding environmental context. We propose a multi-label state transition linear threshold model to more closely mirror the complex process of information diffusion across social networks. Furthermore, we advocate for a multi-round hybrid strategy that amalgamates blocking and clarification tactics to address the ARS problem within the confines of limited resource allocations. To navigate the complexities of ARS, we introduce the Hybrid Strategy of Each Round (HS-R) algorithm, which synergizes multiple strategies to effectively counter the spread of rumors. In extension, we present the Multi-Round Multi-Label (MRML) algorithm, designed to augment the efficiency of the HS-R algorithm. Experimental evaluations conducted on authentic social network datasets illustrate that our methodologies significantly outshine baseline algorithms, offering a more effective and adaptable solution to curb rumor propagation across varied environments.},
  archive      = {J_TKDD},
  author       = {Qiang He and Zelin Zhang and Tingting Bi and Hui Fang and Xiushuang Yi and Keping Yu},
  doi          = {10.1145/3701738},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive rumor suppression on social networks: A multi-round hybrid approach},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning knowledge-diverse experts for long-tailed graph classification. <em>TKDD</em>, <em>19</em>(2), 1-24. (<a href='https://doi.org/10.1145/3705323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown remarkable success in graph-level classification tasks. However, most of the existing GNN-based studies are based on balanced datasets, while many real-world datasets exhibit long-tailed distributions. In such datasets, the tail classes receive limited attention during training, leading to prediction bias and degraded performance. To address this issue, a range of long-tailed learning strategies have been proposed, such as data re-balancing and transfer learning. However, these approaches encounter several challenges, including insufficient representation capacity for tail classes and their evaluation solely on uniform test data, limiting their capacity to handle unknown class distributions. To tackle these challenges, we introduce a novel framework, namely Knowledge-diverse Experts (KDEX) for long-tailed graph classification. Our KDEX leverages a dynamic memory module to enable the transfer of knowledge from head to tail, which improves the representation ability of the tail. To deal with unknown test distributions, KDEX introduces a knowledge-diverse expert training approach to train experts with different capacities in managing various test distributions. Moreover, we train the hierarchical router in a self-supervised manner to dynamically aggregate each knowledge-diverse expert during testing. Experimental results on multiple benchmarks reveal that our KDEX outperforms current baselines in both standard and test-agnostic long-tailed graph classification.},
  archive      = {J_TKDD},
  author       = {Zhengyang Mao and Wei Ju and Siyu Yi and Yifan Wang and Zhiping Xiao and Qingqing Long and Nan Yin and Xinwang Liu and Ming Zhang},
  doi          = {10.1145/3705323},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning knowledge-diverse experts for long-tailed graph classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian frequency estimation under local differential privacy with an adaptive randomized response mechanism. <em>TKDD</em>, <em>19</em>(2), 1-40. (<a href='https://doi.org/10.1145/3706584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency estimation plays a critical role in many applications involving personal and private categorical data. Such data are often collected sequentially over time, making it valuable to estimate their distribution online while preserving privacy. We propose AdOBEst-LDP, a new algorithm for adaptive, online Bayesian estimation of categorical distributions under local differential privacy (LDP). The key idea behind AdOBEst-LDP is to enhance the utility of future privatized categorical data by leveraging inference from previously collected privatized data. To achieve this, AdOBEst-LDP uses a new adaptive LDP mechanism to collect privatized data. This LDP mechanism constrains its output to a subset of categories that “predicts” the next user’s data. By adapting the subset selection process to the past privatized data via Bayesian estimation, the algorithm improves the utility of future privatized data. To quantify utility, we explore various well-known information metrics, including (but not limited to) the Fisher information matrix, total variation distance, and information entropy. For Bayesian estimation, we utilize posterior sampling through stochastic gradient Langevin dynamics, a computationally efficient approximate Markov chain Monte Carlo (MCMC) method. We provide a theoretical analysis showing that (i) the posterior distribution of the category probabilities targeted with Bayesian estimation converges to the true probabilities even for approximate posterior sampling, and (ii) AdOBEst-LDP eventually selects the optimal subset for its LDP mechanism with high probability if posterior sampling is performed exactly. We also present numerical results to validate the estimation accuracy of AdOBEst-LDP. Our comparisons show its superior performance against non-adaptive and semi-adaptive competitors across different privacy levels and distributional parameters.},
  archive      = {J_TKDD},
  author       = {Soner Aydin and Sinan Yıldırım},
  doi          = {10.1145/3706584},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Bayesian frequency estimation under local differential privacy with an adaptive randomized response mechanism},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaptSel: Adaptive selection of biased and debiased recommendation models for varying test environments. <em>TKDD</em>, <em>19</em>(2), 1-39. (<a href='https://doi.org/10.1145/3706637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems are frequently challenged by pervasive biases in the training set that can compromise model effectiveness. To address this issue, various debiasing techniques have been developed to eliminate biases and produce debiased models. However, when encountering varying test environments, some data patterns manifested by the training data could be beneficial to the model’s performance. Completely removing biases may overlook the beneficial data patterns and consequently diminish recommendation accuracy. Thus, it is crucial to carefully integrate certain biases to optimize performance, while the ideal level of bias integration is highly dependent on the test environment. Moreover, these systems operate in dynamic scenarios where the test environments could vary, necessitating an adaptive integration strategy customized to the environment. Our research establishes that discrepancies in predictions of models can guide the selection of the most fitting model for specific situations. Building on this understanding, we present AdaptSel, a pioneering method for the adaptive selection of the superior model during the testing phase. Empirical evaluations substantiate the foundational assumptions of AdaptSel, accentuating its effectiveness in adaptively selecting the most suitable model for varying test environments.},
  archive      = {J_TKDD},
  author       = {Zimu Wang and Hao Zou and Jiashuo Liu and Jiayun Wu and Pengfei Tian and Yue He and Peng Cui},
  doi          = {10.1145/3706637},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {AdaptSel: Adaptive selection of biased and debiased recommendation models for varying test environments},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PREFER: A pre-trained model recommendation framework for edge computing enabled traffic flow prediction. <em>TKDD</em>, <em>19</em>(2), 1-26. (<a href='https://doi.org/10.1145/3707464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent years have witnessed a surge in the development of traffic flow prediction methods, often deployed on cloud platforms to offer predictive services for entire transportation networks. However, the processes of training and executing a model for the entire traffic network are both time-consuming and computationally expensive. As a result, the utilization of edge servers for local sub-network prediction services has gained prominence. Nevertheless, training prediction models for numerous sub-networks within the extensive traffic network remains a time-intensive and computing resource-consuming task. To tackle this challenge, this article introduces the Pre-trained model REcommendation Framework for Edge computing enabled tRaffic flow prediction (PREFER). PREFER trains a set of traffic flow prediction models on selected sub-networks, then recommends optimal pre-trained models for edge servers. The recommendation is specifically based on performance prediction, integrating neural collaborative filtering and traffic flow characteristics. Experiments conducted on real datasets reveal that the pre-trained models recommended by PREFER perform close to the actual optimal ones and significantly outperform existing recommendation algorithms.},
  archive      = {J_TKDD},
  author       = {Qiqi Cai and Jian Cao and Yirong Chen and Shiyou Qian and Liangxiao Yuan and Jie Wang},
  doi          = {10.1145/3707464},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {PREFER: A pre-trained model recommendation framework for edge computing enabled traffic flow prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling on-road trajectories with multi-task learning. <em>TKDD</em>, <em>19</em>(1), 1-26. (<a href='https://doi.org/10.1145/3705005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of GPS modules, there are various urban applications such as car navigation relying on trajectory data modeling. In this work, we study the problem of modeling on-road trajectories, which is to predict the next road segment given a partial GPS trajectory. Existing methods that model trajectories with Markov chain or recurrent neural network suffer from various issues, including limited capability of sequential modeling, insufficiency of incorporating the road network context, and lack of capturing the underlying semantics of trajectories. In this article, we propose a new trajectory modeling framework called Multi-task Modeling for Trajectories (MMTraj+), which avoids these issues. Specifically, MMTraj+ uses multi-head self-attention networks for sequential modeling, captures the overall road network as the context information for road segment embedding, and performs an auxiliary task of predicting the trajectory destination information (namely the ID and bearing angle) to better guide the main trajectory modeling task (controlled by a carefully designed gating mechanism). In addition, we tailor MMTraj+ for the cases where the destination information is known by dropping its auxiliary task of predicting the trajectory destination information. Extensive experiments conducted on real-world datasets demonstrate the superiority of the proposed method over the baseline methods.},
  archive      = {J_TKDD},
  author       = {Kaijun Liu and Sijie Ruan and Cheng Long and Liang Yu},
  doi          = {10.1145/3705005},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Modeling on-road trajectories with multi-task learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure amplification on multi-layer stochastic block models. <em>TKDD</em>, <em>19</em>(1), 1-26. (<a href='https://doi.org/10.1145/3706111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much of the complexity of social, biological, and engineering systems arises from the complicated interactions among the entities in the corresponding networks. A number of network analysis tools have been successfully used to discover latent structures termed communities in such networks. However, some communities with relatively weak structures can be difficult to uncover because they are obscured by other stronger connections. To cope with this situation, our previous work proposes an algorithm called HICODE to detect and amplify the dominant and hidden community structures. In this work, we conduct a comprehensive and systematic theoretical analysis on the impact of hidden community structure and the efficacy of the HICODE algorithm, as well as provide illustrations of the detection process and results. Specifically, we define a multi-layer stochastic block model and use this model to explain why the existence of hidden structure makes the detection of dominant structure harder than equivalent random noises, which can also explain why many community detection algorithms only focusing on the dominant structure do not work well as expected. We then provide theoretical analysis that the iterative reducing methods could help to enhance the discovery of hidden structure as well as the dominant structure in the multi-layer stochastic block model for the two cases of accurate and inaccurate detection. Finally, visual simulations and experimental results are presented to show the process of HICODE algorithm and the impact of different number of layers on the detection quality.},
  archive      = {J_TKDD},
  author       = {Kun He and Xiaodong Xin and Jialu Bao and Meng Wang and Bart Selman and John E. Hopcroft},
  doi          = {10.1145/3706111},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Structure amplification on multi-layer stochastic block models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defending federated recommender systems against untargeted attacks: A contribution-aware robust aggregation scheme. <em>TKDD</em>, <em>19</em>(1), 1-28. (<a href='https://doi.org/10.1145/3706112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated recommender systems (FedRSs) effectively tackle the tradeoff between recommendation accuracy and privacy preservation. However, recent studies have revealed severe vulnerabilities in FedRSs, particularly against untargeted attacks seeking to undermine their overall performance. Defense methods employed in traditional recommender systems are not applicable to FedRSs, and existing robust aggregation schemes for other federated learning-based applications have proven ineffective in FedRSs. Building on the observation that malicious clients contribute negatively to the training process, we design a novel contribution-aware robust aggregation scheme to defend FedRSs against untargeted attacks, named contribution-aware Bayesian knowledge distillation aggregation (ConDA), comprising two key components for the defense. In the first contribution estimation component, we decentralize the estimation from the server side to the client side and propose an ensemble-based Shapley value to enable the efficient calculation of contributions, addressing the limitations of lacking auxiliary validation data and high computational complexity. In the second contribution-aware aggregation component, we merge the decentralized contributions via a majority voting mechanism and integrate the merged contributions into a Bayesian knowledge distillation aggregation scheme for robust aggregation, mitigating the impact of unreliable contributions induced by attacks. We evaluate the effectiveness and efficiency of ConDA on two real-world datasets from movie and music service providers. Through extensive experiments, we demonstrate the superiority of ConDA over the baseline robust aggregation schemes.},
  archive      = {J_TKDD},
  author       = {Ruicheng Liang and Yuanchun Jiang and Feida Zhu and Ling Cheng and Huiwen Liu},
  doi          = {10.1145/3706112},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Defending federated recommender systems against untargeted attacks: A contribution-aware robust aggregation scheme},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-aware noise-robust contrastive learning for partially view-aligned problem. <em>TKDD</em>, <em>19</em>(1), 1-20. (<a href='https://doi.org/10.1145/3707646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a challenging problem in contrastive learning when just a portion of data is aligned in multi-view dataset due to temporal, spatial, or spatio-temporal asynchronism across views. It is important to study partially view-aligned data since this type of data is common in real-world application and easily leads to data inconsistency among different views. Such a Partially View-aligned Problem (PVP) in contrastive learning has been relatively less touched so far, especially in downstream tasks, i.e., classification and clustering. In order to solve this problem, we introduce a flexible margin and propose margin-aware noise-robust contrastive learning to simultaneously identify the within-category counterparts from the other view of one data point based on the established cross-view correspondence and learn a shared representation. To be specific, the proposed learning framework is built on a novel margin-aware noise-robust contrastive loss. Since data pairs are used as input for the proposed margin-aware noise-robust contrastive learning, we build positive pairs according to the known correspondences and negative pairs in the manner of random sampling. Our margin-aware noise-robust contrastive learning framework is able to effectively reduce or remove the impacts caused by the possible existing noise for the constructed pairs in a margin-aware manner, i.e., false negative pairs led by random sampling in PVP. We relax the proposed margin-aware noise-robust contrastive loss and then give a detailed mathematical analysis for the effectiveness of our loss. As an instantiation, we construct an example under the proposed margin-aware noise-robust contrastive learning framework for validation in this work. To the best of our knowledge, this is the first attempt of extending contrastive learning to a margin-aware noise-robust version for dealing with PVP. We also enrich the learning paradigm when there is noise in the data. Extensive experiments on different datasets demonstrate the promising performance of the proposed method in the classification and clustering tasks.},
  archive      = {J_TKDD},
  author       = {Yalan Qin and Nan Pu and Hanzhou Wu and Nicu Sebe},
  doi          = {10.1145/3707646},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Margin-aware noise-robust contrastive learning for partially view-aligned problem},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
