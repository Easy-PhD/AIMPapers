<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt">SIOPT - 82</h2>
<ul>
<li><details>
<summary>
(2025). Exact convergence rate of the last iterate in subgradient methods. <em>SIOPT</em>, <em>35</em>(3), 2182-2201. (<a href='https://doi.org/10.1137/24M1717762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the convergence of the last iterate in subgradient methods applied to the minimization of a nonsmooth convex function with bounded subgradients. Using a novel proof technique that tracks distances to varying reference points, we derive tight worst-case convergence rates for the (projected) subgradient method with constant step sizes or step lengths. We identify the optimal constant step size for a given number of iterations , yielding a last-iterate accuracy smaller than , where bounds subgradient norms and bounds the initial distance to a minimizer. We also propose a new optimal subgradient method based on a linearly decaying sequence of step sizes that achieves a rate for the last iterate equal to , matching the theoretical lower bound. Finally, we show that no universal step size sequence can attain this rate across all iterations, highlighting that the dependence of the step size sequence in is unavoidable.},
  archive      = {J_SIOPT},
  author       = {Moslem Zamani and François Glineur},
  doi          = {10.1137/24M1717762},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2182-2201},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact convergence rate of the last iterate in subgradient methods},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TS-RSR: A provably efficient approach for batch bayesian optimization. <em>SIOPT</em>, <em>35</em>(3), 2155-2181. (<a href='https://doi.org/10.1137/24M1675102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a new approach for batch Bayesian optimization (BO) called Thompson Sampling-Regret to Sigma Ratio directed sampling (TS-RSR), where we sample a new batch of actions by minimizing a TS approximation of a regret to uncertainty ratio. Our sampling objective is to coordinate the actions chosen in each batch in a way that minimizes redundancy between points while focusing on points with high predictive means or high uncertainty. Theoretically, we provide rigorous convergence guarantees on our algorithm’s regret, and numerically we demonstrate that our method attains state-of-the-art performance on a range of challenging synthetic and realistic test functions, where it outperforms several competitive benchmark batch BO algorithms.},
  archive      = {J_SIOPT},
  author       = {Zhaolin Ren and Na Li},
  doi          = {10.1137/24M1675102},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2155-2181},
  shortjournal = {SIAM J. Optim.},
  title        = {TS-RSR: A provably efficient approach for batch bayesian optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp global guarantees for nonconvex low-rank recovery in the noisy overparameterized regime. <em>SIOPT</em>, <em>35</em>(3), 2128-2154. (<a href='https://doi.org/10.1137/24M1697980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Recent work established that rank overparameterization eliminates spurious local minima in nonconvex low-rank matrix recovery under the restricted isometry property (RIP). But this does not fully explain the practical success of overparameterization, because real algorithms can still become trapped at nonstrict saddle points (approximate second-order points with arbitrarily small negative curvature) even when all local minima are global. Moreover, the result does not accommodate for noisy measurements, but it is unclear whether such an extension is even possible, in view of the many discontinuous and unintuitive behaviors already known for the overparameterized regime. In this paper, we introduce a novel proof technique that unifies, simplifies, and strengthens two previously competing approaches—one based on escape directions and the other based on the inexistence of counterexample—to provide sharp global guarantees in the noisy overparameterized regime. We show, once local minima have been converted into global minima through slight overparameterization, that near-second-order points achieve the same minimax-optimal recovery bounds (up to small constant factors) as significantly more expensive convex approaches. Our results are sharp with respect to the noise level and the solution accuracy, and hold for both the symmetric parameterization and the asymmetric parameterization under a balancing regularizer; we demonstrate that the balancing regularizer is indeed necessary.},
  archive      = {J_SIOPT},
  author       = {Richard Y. Zhang},
  doi          = {10.1137/24M1697980},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2128-2154},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharp global guarantees for nonconvex low-rank recovery in the noisy overparameterized regime},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity of zeroth- and first-order stochastic trust-region algorithms. <em>SIOPT</em>, <em>35</em>(3), 2098-2127. (<a href='https://doi.org/10.1137/24M1664484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Model update (MU) and candidate evaluation (CE) are classical steps incorporated inside many stochastic trust-region (TR) algorithms. The sampling effort exerted within these steps, often decided with the aim of controlling model error, largely determines a stochastic TR algorithm’s sample complexity. Given that MU and CE are amenable to variance reduction, we investigate the effect of incorporating common random numbers (CRN) within MU and CE on complexity. Using ASTRO and ASTRO-DF as prototype first-order and zeroth-order families of algorithms, we demonstrate that CRN’s effectiveness leads to a range of complexities depending on sample-path regularity and the oracle order. For instance, we find that in first-order oracle settings with smooth sample paths, CRN’s effect is pronounced—ASTRO with CRN achieves a.s. sample complexity compared to a.s. in the generic no-CRN setting. By contrast, CRN’s effect is muted when the sample paths are not Lipschitz, with the sample complexity improving from a.s. to and a.s. in the zeroth- and first-order settings, respectively. Since our results imply that improvements in complexity are largely inherited from generic aspects of variance reduction, e.g., finite-differencing for zeroth-order settings and sample-path smoothness for first-order settings within MU, we anticipate similar trends in other contexts.},
  archive      = {J_SIOPT},
  author       = {Yunsoo Ha and Sara Shashaani and Raghu Pasupathy},
  doi          = {10.1137/24M1664484},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2098-2127},
  shortjournal = {SIAM J. Optim.},
  title        = {Complexity of zeroth- and first-order stochastic trust-region algorithms},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized optimistic methods for convex-concave saddle point problems. <em>SIOPT</em>, <em>35</em>(3), 2066-2097. (<a href='https://doi.org/10.1137/24M1630475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The optimistic gradient method has seen increasing popularity as an efficient first-order method for solving convex-concave saddle point problems. To analyze its iteration complexity, a recent work [A. Mokhtari, A. E. Ozdaglar, and S. Pattathil, SIAM J. Optim., 30 (2020), pp. 3230–3251] proposed an interesting perspective that interprets the optimistic gradient method as an approximation to the proximal point method. In this paper, we follow this approach and distill the underlying idea of optimism to propose a generalized optimistic method, which encompasses the optimistic gradient method as a special case. Our general framework can handle constrained saddle point problems with composite objective functions. Moreover, we also develop a backtracking line search scheme to select the step sizes without knowledge of the smoothness coefficients. By instantiating our general framework with a second-order oracle, we propose a second-order optimistic method and prove a complexity bound of in terms of the primal-dual gap in the convex-concave setting and a complexity bound of in terms of the distance to the optimal solution in the strongly-convex-strongly-concave setting, where is the Lipschitz constant of the Jacobian, is the strong convexity parameter, and is the initial Euclidean distance to the saddle point. We also establish convergence rates in terms of the tangent residual, which generalizes the operator norm as a metric in the unconstrained setting. Moreover, our line search scheme provably only requires a constant number of calls to a subproblem solver per iteration on average.},
  archive      = {J_SIOPT},
  author       = {Ruichen Jiang and Aryan Mokhtari},
  doi          = {10.1137/24M1630475},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2066-2097},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized optimistic methods for convex-concave saddle point problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A symmetric Gauss–Seidel based majorized augmented lagrangian method for generalized nash equilibrium problems in hilbert spaces. <em>SIOPT</em>, <em>35</em>(3), 2040-2065. (<a href='https://doi.org/10.1137/24M1678143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new numerical method for solving a generalized Nash equilibrium problem (GNEP) involving players, incorporating general constraints formulated in Hilbert spaces. These constraints may include linear equality, linear inequality, or conic constraints. Instead of handling joint constraints and nonlinear objectives directly, we reformulate the problem as an equality-constrained GNEP with separable structure and then construct a quadratic majorization augmented Lagrangian function for the resulting GNEP. A majorized augmented Lagrangian method (ALM) is then designed to solve the equivalent GNEP. Each iteration requires solving a coupled Nash equilibrium problem (NEP). To address this, we introduce a symmetric Gauss–Seidel (sGS) decomposition method to decouple the NEP into a sequence of single-objective unconstrained quadratic programs. We establish the convergence of this ALM under mild assumptions in a weak topology and prove the strong convergence of the primal sequence under additional regularity assumptions. Finally, numerical experiments demonstrate the effectiveness and efficiency of our algorithm.},
  archive      = {J_SIOPT},
  author       = {Hailing Wang and Di Wu and Song Wang and Kok Lay Teo and Changjun Yu},
  doi          = {10.1137/24M1678143},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2040-2065},
  shortjournal = {SIAM J. Optim.},
  title        = {A symmetric Gauss–Seidel based majorized augmented lagrangian method for generalized nash equilibrium problems in hilbert spaces},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subdifferentials and penalty approximations of the obstacle problem. <em>SIOPT</em>, <em>35</em>(3), 2017-2039. (<a href='https://doi.org/10.1137/24M172202X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a framework for approximating the obstacle problem through a penalty approach by nonlinear PDEs. By using tools from capacity theory, we show that derivatives of the solution maps of the penalized problems converge in the weak operator topology to an element of the strong-weak Bouligand subdifferential. We are able to treat smooth penalty terms as well as nonsmooth ones involving, for example, the positive part function . Our abstract framework applies to several specific choices of penalty functions which are omnipresent in the literature. We conclude with consequences to the theory of optimal control of the obstacle problem.},
  archive      = {J_SIOPT},
  author       = {Amal Alphonse and Gerd Wachsmuth},
  doi          = {10.1137/24M172202X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2017-2039},
  shortjournal = {SIAM J. Optim.},
  title        = {Subdifferentials and penalty approximations of the obstacle problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex optimization problems inspired by geotechnical stability analysis. <em>SIOPT</em>, <em>35</em>(3), 1993-2016. (<a href='https://doi.org/10.1137/25M1723177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is motivated by the limit load, limit analysis, and shear strength reduction methods, which are commonly employed in geotechnical stability analysis or similar applications. The aim is to make these methods more approachable by introducing a unified framework based on abstract convex optimization and its parametric studies. We establish suitable assumptions on the abstract problems that capture the selected features of these methods and facilitate rigorous theoretical investigation. Further, we propose continuation techniques tailored to the resulting parametric problem formulations and show that the developed abstract framework could also be useful outside the domain of geotechnical stability analysis. The main results are illustrated with analytical and numerical examples. The numerical example deals with a 3D slope stability problem.},
  archive      = {J_SIOPT},
  author       = {Stanislav Sysala and Michal Béreš and Simona Bérešová and Jaroslav Haslinger and Jakub Kružík and Tomáš Luber},
  doi          = {10.1137/25M1723177},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1993-2016},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex optimization problems inspired by geotechnical stability analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the Bredies–Chenchene–Lorenz–Naldi algorithm: Linear relations and strong convergence. <em>SIOPT</em>, <em>35</em>(3), 1963-1992. (<a href='https://doi.org/10.1137/23M1587919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Monotone inclusion problems occur in many areas of optimization and variational analysis. Splitting methods, which utilize resolvents or proximal mappings of the underlying operators, are often applied to solve these problems. Bredies et al. [SIAM J. Optim., 32 (2022), pp. 2376–2401] introduced a new elegant algorithmic framework that encompasses various well-known algorithms, including Douglas–Rachford and Chambolle–Pock. They obtained powerful weak and strong convergence results, where the latter type relies on additional strong monotonicity assumptions. In this paper, we complement the analysis by Bredies et al. by relating the projections of the fixed point sets of the underlying operators that generate the (reduced and original) preconditioned proximal point sequences. We obtain a new strong convergence result when the underlying operator is a linear relation. We note that without assumptions such as linearity or strong monotonicity, one may encounter weak convergence without strong convergence. In the case of the Chambolle–Pock algorithm, we obtain a new result that yields strong convergence to the projection onto the intersection of a linear subspace and the preimage of a linear subspace. Splitting algorithms by Ryu and by Malitsky and Tam are also considered. Various examples are provided to illustrate the applicability of our results.},
  archive      = {J_SIOPT},
  author       = {Heinz H. Bauschke and Walaa M. Moursi and Shambhavi Singh and Xianfu Wang},
  doi          = {10.1137/23M1587919},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1963-1992},
  shortjournal = {SIAM J. Optim.},
  title        = {On the Bredies–Chenchene–Lorenz–Naldi algorithm: Linear relations and strong convergence},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grassmannian optimization is NP-hard. <em>SIOPT</em>, <em>35</em>(3), 1939-1962. (<a href='https://doi.org/10.1137/24M1672596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that unconstrained quadratic optimization over a Grassmannian is NP-hard. Our results cover all scenarios: (i) when and are both allowed to grow, (ii) when is arbitrary but fixed, and (iii) when is fixed at its lowest possible value 1. We then deduce the NP-hardness of unconstrained cubic optimization over the Stiefel manifold and the orthogonal group . As an addendum we demonstrate the NP-hardness of unconstrained quadratic optimization over the Cartan manifold, i.e., the positive definite cone regarded as a Riemannian manifold, another popular example in manifold optimization. We will also establish the nonexistence of in all cases.},
  archive      = {J_SIOPT},
  author       = {Zehua Lai and Lek-Heng Lim and Ke Ye},
  doi          = {10.1137/24M1672596},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1939-1962},
  shortjournal = {SIAM J. Optim.},
  title        = {Grassmannian optimization is NP-hard},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perturbation analysis for KKT point sets of constrained optimization problems. <em>SIOPT</em>, <em>35</em>(3), 1914-1938. (<a href='https://doi.org/10.1137/24M165884X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper first uses the subdifferential and coderivative to consider KKT optimality conditions for a generalized equation-constrained optimization problem (GEOP), which can cover most constrained optimization problems. Based on the technique of variational analysis, we establish quantitative analysis for the KKT stationary point sets of (GEOP) and a conic optimization problem when both the objective function and the constrained multifunctions undergo small Lipschitz perturbations. Without any constraint qualification, we prove that the KKT stationary point set of a piecewise linearity constrained optimization problem with the objective function being quasi-quadratic is always stable when the objective function undergoes small Lipschitz (not necessarily quasi-quadratic) perturbations. As an application, we provide some stability results on KKT stationary point sets for quasi-quadratic programs with piecewise linear complementary constraint or sparsity constraint.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng},
  doi          = {10.1137/24M165884X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1914-1938},
  shortjournal = {SIAM J. Optim.},
  title        = {Perturbation analysis for KKT point sets of constrained optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex ternary quartics are SOS-convex. <em>SIOPT</em>, <em>35</em>(3), 1899-1913. (<a href='https://doi.org/10.1137/24M1655834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that if a ternary quartic form is convex, then it must be sos-convex; i.e., if the Hessian of a ternary quartic form is positive semidefinite for all , then the biquadratic form in the variables and must be a sum of squares. This result is in a meaningful sense the convex analog of Hilbert’s celebrated theorem on ternary quartics. We show that exploiting the structure of the Hessian matrix is crucial in any possible proof of this result by presenting an explicit example of a biquadratic form that is symmetric in and , nonnegative, but not a sum of squares.},
  archive      = {J_SIOPT},
  author       = {Amir Ali Ahmadi and Grigoriy Blekherman and Pablo A. Parrilo},
  doi          = {10.1137/24M1655834},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1899-1913},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex ternary quartics are SOS-convex},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The lovász theta function for recovering planted clique covers and graph colorings. <em>SIOPT</em>, <em>35</em>(3), 1873-1898. (<a href='https://doi.org/10.1137/23M1609622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problems of computing graph colorings and clique covers are central challenges in combinatorial optimization. Both of these are known to be NP-hard and thus computationally intractable in the worst-case instance. A prominent approach for computing approximate solutions to these problems is the celebrated Lovász theta function , which is specified as the solution of a semidefinite program (SDP) and hence is tractable to compute. In this work, we move beyond the worst-case analysis and set out to understand whether the Lovász theta function recovers clique covers for random instances that have a latent clique cover structure, possibly obscured by noise. We answer this question in the affirmative and show that for graphs generated from the planted clique model we introduce in this work, the SDP formulation of has a unique solution that reveals the underlying clique cover structure with high probability. The main technical step is an intermediate result where we prove a deterministic condition of recovery based on an appropriate notion of sparsity.},
  archive      = {J_SIOPT},
  author       = {Jiaxin Hou and Yong Sheng Soh and Antonios Varvitsiotis},
  doi          = {10.1137/23M1609622},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1873-1898},
  shortjournal = {SIAM J. Optim.},
  title        = {The lovász theta function for recovering planted clique covers and graph colorings},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A four-operator splitting algorithm for nonconvex and nonsmooth optimization. <em>SIOPT</em>, <em>35</em>(3), 1846-1872. (<a href='https://doi.org/10.1137/24M1672067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we address a class of nonconvex nonsmooth optimization problems where the objective function is the sum of two smooth functions (one of which is proximable) and two nonsmooth functions (one proper, closed, and proximable, and the other continuous and weakly concave). We introduce a new splitting algorithm that extends the Davis–Yin splitting (DYS) algorithm to handle such four-term nonconvex nonsmooth problems. We prove that with appropriately chosen stepsizes, our algorithm exhibits global subsequential convergence to stationary points with a stationarity measure converging at a global rate of , where is the number of iterations. When specialized to the setting of the DYS algorithm, our results allow for larger stepsizes compared to existing bounds in the literature. Experimental results demonstrate the practical applicability and effectiveness of our proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Jan Harold Alcantara and Ching-pei Lee and Akiko Takeda},
  doi          = {10.1137/24M1672067},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1846-1872},
  shortjournal = {SIAM J. Optim.},
  title        = {A four-operator splitting algorithm for nonconvex and nonsmooth optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex quadratic sets and the complexity of mixed integer convex quadratic programming. <em>SIOPT</em>, <em>35</em>(3), 1822-1845. (<a href='https://doi.org/10.1137/24M1636782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In pure integer linear programming it is often desirable to work with polyhedra that are full-dimensional, and it is well known that it is possible to reduce any polyhedron to a full-dimensional one in polynomial time. More precisely, using the Hermite normal form, it is possible to map a non-full-dimensional polyhedron to a full-dimensional isomorphic one in a lower-dimensional space, while preserving integer vectors. In this paper, we extend the above result simultaneously in two directions. First, we consider mixed integer vectors instead of integer vectors, by leveraging on the concept of “integer reflexive generalized inverse.” Second, we replace polyhedra with convex quadratic sets, which are sets obtained from polyhedra by enforcing one additional convex quadratic inequality. We study structural properties of convex quadratic sets, and utilize them to obtain polynomial time algorithms to recognize full-dimensional convex quadratic sets, and to find an affine function that maps a non-full-dimensional convex quadratic set to a full-dimensional isomorphic one in a lower-dimensional space, while preserving mixed integer vectors. We showcase the applicability and the potential impact of these results by demonstrating that they can be used to prove that mixed integer convex quadratic programming is fixed parameter tractable with parameter the number of integer variables. Our algorithm unifies and extends the known polynomial time solvability of mixed integer convex quadratic programming in fixed dimension and of convex quadratic programming.},
  archive      = {J_SIOPT},
  author       = {Alberto Del Pia},
  doi          = {10.1137/24M1636782},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1822-1845},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex quadratic sets and the complexity of mixed integer convex quadratic programming},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRFD: A derivative-free trust-region method based on finite differences for composite nonsmooth optimization. <em>SIOPT</em>, <em>35</em>(3), 1792-1821. (<a href='https://doi.org/10.1137/24M1701587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we present TRFD, a derivative-free trust-region method based on finite differences for minimizing composite functions of the form , where is a black-box function assumed to have a Lipschitz continuous Jacobian, and is a known convex Lipschitz function, possibly nonsmooth, with a known Lipschitz constant. The method approximates the Jacobian of via forward finite differences. We establish an upper bound for the number of evaluations of that TRFD requires to find an -approximate stationary point. For L1 and Minimax problems, we show that our complexity bound reduces to for specific instances of TRFD, where is the number of variables of the problem. Assuming that is monotone and that the components of are convex, we also establish a worst-case complexity bound, which reduces to for Minimax problems. Numerical results are provided to illustrate the relative efficiency of TRFD in comparison with existing derivative-free solvers for composite nonsmooth optimization.},
  archive      = {J_SIOPT},
  author       = {D. Davar and G. N. Grapiglia},
  doi          = {10.1137/24M1701587},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1792-1821},
  shortjournal = {SIAM J. Optim.},
  title        = {TRFD: A derivative-free trust-region method based on finite differences for composite nonsmooth optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A jacobi-type newton method for nash equilibrium problems with descent guarantees. <em>SIOPT</em>, <em>35</em>(3), 1761-1791. (<a href='https://doi.org/10.1137/23M1575639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A common strategy for solving an unconstrained two-player Nash equilibrium problem with continuous variables is applying Newton’s method to the system obtained by the corresponding first-order necessary optimality conditions. However, when taking into account the game dynamics, it is not clear what is the goal of each player when considering they are taking their current decision following Newton’s iterates. In this paper we provide an interpretation for Newton’s iterate as follows: instead of minimizing the quadratic approximation of the objective functions parameterized by the other player current decision (the Jacobi-type strategy), we show that the Newton iterate follows this approach but with the objective function parameterized by a prediction of the other player action. This interpretation allows us to present a new Newtonian algorithm where a backtracking procedure is introduced in order to guarantee that the computed Newtonian directions, for each player, are descent directions for the corresponding parameterized functions. Thus, besides favoring global convergence, our algorithm also favors true minimizers instead of maximizers or saddle points, unlike the standard Newton method, which does not consider the minimization structure of the problem in the nonconvex case. Thus, our method is more robust compared to other Jacobi-type strategies or the pure Newtonian approach, which is corroborated by our numerical experiments. We also present a proof of the well-definiteness of the algorithm under some standard assumptions, together with a preliminary analysis of its convergence properties taking into account the game dynamics.},
  archive      = {J_SIOPT},
  author       = {L. F. Bueno and G. Haeser and O. Kolossoski},
  doi          = {10.1137/23M1575639},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1761-1791},
  shortjournal = {SIAM J. Optim.},
  title        = {A jacobi-type newton method for nash equilibrium problems with descent guarantees},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized iterative methods for generalized absolute value equations: Solvability and error bounds. <em>SIOPT</em>, <em>35</em>(3), 1731-1760. (<a href='https://doi.org/10.1137/24M1679306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Randomized iterative methods, such as the Kaczmarz method and its variants, have gained growing attention due to their simplicity and efficiency in solving large-scale linear systems. Meanwhile, absolute value equations (AVE) have attracted increasing interest due to their connection with the linear complementarity problem. In this paper, we investigate the application of randomized iterative methods to generalized AVE (GAVE). Our approach differs from most existing works in that we tackle GAVE with nonsquare coefficient matrices. We establish more comprehensive sufficient and necessary conditions for characterizing the solvability of GAVE and propose precise error bound conditions. Furthermore, we introduce a flexible and efficient randomized iterative algorithmic framework for solving GAVE, which employs randomized sketching matrices drawn from user-specified distributions. This framework is capable of encompassing many well-known methods, including the Picard iteration method and the randomized Kaczmarz method. Leveraging our findings on solvability and error bounds, we establish both almost sure convergence and linear convergence rates for this versatile algorithmic framework. Finally, we present numerical examples to illustrate the advantages of the new algorithms.},
  archive      = {J_SIOPT},
  author       = {Jiaxin Xie and Hou-Duo Qi and Deren Han},
  doi          = {10.1137/24M1679306},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1731-1760},
  shortjournal = {SIAM J. Optim.},
  title        = {Randomized iterative methods for generalized absolute value equations: Solvability and error bounds},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex approximations of random constrained markov decision processes. <em>SIOPT</em>, <em>35</em>(3), 1703-1730. (<a href='https://doi.org/10.1137/24M1660711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Constrained Markov decision processes (CMDPs) are used as a decision-making framework to study the long-run performance of a stochastic system. It is well known that a stationary optimal policy of a CMDP problem under discounted cost criterion can be obtained by solving a linear programming problem when running costs and transition probabilities are exactly known. In this paper, we consider a discounted cost CMDP problem where the running costs and transition probabilities are defined using random variables. Consequently, both the objective function and constraints become random. We use chance constraints to model these uncertainties and formulate the uncertain CMDP problem as a joint chance-constrained Markov decision process (JCCMDP). Under random running costs, we assume that the dependency among random constraint vectors is driven by a Gumbel–Hougaard copula. Using standard probability inequalities, we construct convex upper bound approximations of the JCCMDP problem under certain conditions on random running costs. In addition, we propose a linear programming problem whose optimal value gives a lower bound to the optimal value of the JCCMDP problem. When both running costs and transition probabilities are random, we define the latter variables as a sum of their means and random perturbations. Under mild conditions on the random perturbations and random running costs, we construct convex upper and lower bound approximations of the JCCMDP problem. We analyze the quality of the derived bounds through numerical experiments on a queueing control problem for random running costs. For the case when both running costs and transition probabilities are random, we choose randomly generated Markov decision problems called Garnets for numerical experiments.},
  archive      = {J_SIOPT},
  author       = {V Varagapriya and Vikas Vikram Singh and Abdel Lisser},
  doi          = {10.1137/24M1660711},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1703-1730},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex approximations of random constrained markov decision processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence analysis of the decentralized projected gradient descent method. <em>SIOPT</em>, <em>35</em>(3), 1673-1702. (<a href='https://doi.org/10.1137/23M1562032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we are concerned with the decentralized optimization problem: where is a convex domain and each is a local cost function only known to agent . A fundamental algorithm for this problem is the decentralized projected gradient method (DPG) given by where is the projection operator to and are communication weight among the agents. While this method has been widely used in the literature, its convergence property has not been established so far, except for the special case . This work establishes new convergence estimates of DPG when the aggregate cost is strongly convex and each function is smooth. If the stepsize is suitably small, we prove that each converges linearly to an -neighborhood of the minimizer. In addition, we further improve the convergence result by showing that the point converges linearly to an -neighborhood of the minimizer if the domain is given by the half-space for any dimension . Numerical experiments are provided to support the convergence results.},
  archive      = {J_SIOPT},
  author       = {Woocheol Choi and Jimyeong Kim},
  doi          = {10.1137/23M1562032},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1673-1702},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence analysis of the decentralized projected gradient descent method},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding optimal weight vectors for ridge function approximation in \(\boldsymbol{L}^{\boldsymbol{2}}\boldsymbol{(D)}\). <em>SIOPT</em>, <em>35</em>(3), 1655-1672. (<a href='https://doi.org/10.1137/24M166632X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ridge functions on a set are mappings of the form for given and function . We assume that is compact with nonempty interior and Lipschitz boundary. Given , let be the set of all functions of the form where , the set of continuous functions . Clearly is a subspace of . The task in this paper is, given , to characterize and find a set of weight vectors that minimizes . The maximizing is shown to exist and can be interpreted as the function “hardest to approximate” by . The value of is given in terms of the maximum eigenvalue of a self-adjoint compact operator . Computational methods are given for both computing , given , and finding that approximately minimizes through a gradient descent procedure.},
  archive      = {J_SIOPT},
  author       = {David E. Stewart},
  doi          = {10.1137/24M166632X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1655-1672},
  shortjournal = {SIAM J. Optim.},
  title        = {Finding optimal weight vectors for ridge function approximation in \(\boldsymbol{L}^{\boldsymbol{2}}\boldsymbol{(D)}\)},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certifying solutions of degenerate semidefinite programs. <em>SIOPT</em>, <em>35</em>(3), 1630-1654. (<a href='https://doi.org/10.1137/24M1664691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper deals with the algorithmic aspects of solving feasibility problems of semidefinite programming (SDP), aka linear matrix inequalities (LMIs). Since in some SDP instances all feasible solutions have irrational entries, numerical solvers that work with rational numbers can only find an approximate solution. We study the following question: Is it possible to certify feasibility of a given SDP using an approximate solution that is sufficiently close to some exact solution? Existing approaches make the assumption that there exist rational feasible solutions (and use techniques such as rounding and lattice reduction algorithms). We propose an alternative approach that does not need this assumption. More specifically, we show how to construct a system of polynomial equations whose set of real solutions is guaranteed to have an isolated correct solution (assuming that the target exact solution is maximum-rank). This allows, in particular, for us to use algorithms from real algebraic geometry for solving systems of polynomial equations, yielding a hybrid (or symbolic-numerical) method for SDPs. We experimentally compare it with a pure symbolic method in [D. Henrion, S. Naldi, and M. Safey El Din, SIAM J. Optim., 26 (2016), pp. 2512–2539]; the hybrid method was able to certify feasibility of many SDP instances on which the aforementioned paper failed. Our approach may have further applications, such as refining an approximate solution using methods of numerical algebraic geometry for systems of polynomial equations.},
  archive      = {J_SIOPT},
  author       = {Vladimir Kolmogorov and Simone Naldi and Jeferson Zapata},
  doi          = {10.1137/24M1664691},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1630-1654},
  shortjournal = {SIAM J. Optim.},
  title        = {Certifying solutions of degenerate semidefinite programs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal gradient \(\boldsymbol{\mathcal{VU}}\)-method with superlinear convergence for nonsmooth convex optimization. <em>SIOPT</em>, <em>35</em>(3), 1601-1629. (<a href='https://doi.org/10.1137/24M1697001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The -theory for nonsmooth functions and the associated space decomposition have been used for studying the smooth substructures and for developing algorithms with superlinear convergence in those settings, which are challenging for fast convergence. We extend the theory by defining a certain bivariate -Lagrangian function and partial -Hessian. Utilizing smoothness properties of the new -Lagrangian we develop the proximal gradient -method for continuous nonsmooth convex optimization and show its superlinear convergence under natural assumptions. The framework consists of a -step which is a prox-gradient step, followed by a -step which can be considered as a quasi-Newton step applied to the -Lagrangian. We show that partial -Hessians exist for most partly smooth functions. We exhibit the explicit process of constructing a basis of the -space and of calculating the -Hessian for -regularized problems. Numerical results illustrate the method’s performance.},
  archive      = {J_SIOPT},
  author       = {Shuai Liu and Claudia Sagastizabal and Mikhail V. Solodov},
  doi          = {10.1137/24M1697001},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1601-1629},
  shortjournal = {SIAM J. Optim.},
  title        = {Proximal gradient \(\boldsymbol{\mathcal{VU}}\)-method with superlinear convergence for nonsmooth convex optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the influence of digraphs on decentralized optimization: Effective metrics, lower bound, and optimal algorithm. <em>SIOPT</em>, <em>35</em>(3), 1570-1600. (<a href='https://doi.org/10.1137/24M1657341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the influence of directed networks on decentralized stochastic nonconvex optimization associated with column-stochastic mixing matrices. Surprisingly, we find that the canonical spectral gap, a widely used metric in undirected networks, is insufficient to characterize the impact of directed topology on decentralized algorithms. To overcome this limitation, we introduce a novel metric termed equilibrium skewness. This metric, together with the spectral gap, accurately and comprehensively captures the influence of column-stochastic mixing matrices on decentralized stochastic algorithms. With these two metrics, we clarify, for the first time, how the directed network topology influences the performance of prevalent algorithms such as Push-Sum and Push-DIGing. Furthermore, we establish the first lower bound of the convergence rate for decentralized stochastic nonconvex algorithms over directed networks. Since existing algorithms cannot match our lower bound, we further propose the MG-Push-DIGing algorithm, which integrates Push-DIGing with a multiround gossip technique. MG-Push-DIGing attains our lower bound up to logarithmic factors, demonstrating its near-optimal performance and the tightness of the lower bound. Numerical experiments verify our theoretical results.},
  archive      = {J_SIOPT},
  author       = {Liyuan Liang and Xinmeng Huang and Ran Xin and Kun Yuan},
  doi          = {10.1137/24M1657341},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1570-1600},
  shortjournal = {SIAM J. Optim.},
  title        = {Understanding the influence of digraphs on decentralized optimization: Effective metrics, lower bound, and optimal algorithm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Commutation principles for nonsmooth variational problems on euclidean jordan algebras. <em>SIOPT</em>, <em>35</em>(3), 1551-1569. (<a href='https://doi.org/10.1137/24M1646777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The commutation principle proved by Ramírez, Seeger, and Sossa (SIAM J. Optim. 23 (2013), pp. 687–694) in the setting of Euclidean Jordan algebras says that for a Fréchet differentiable function and a spectral function , any local minimizer or maximizer of over a spectral set operator commutes with the gradient of at . In this paper, we improve this commutation principle by allowing to be nonsmooth. For example, for the case of local minimizer, we show that operator commutes with some element of the limiting (Mordukhovich) subdifferential of at provided that is subdifferentially regular at satisfying a qualification condition. For the case of local maximizer, we prove that operator commutes with each element of the (Fenchel) subdifferential of at whenever this subdifferential is nonempty. As an application, we characterize local optimizers of shifted strictly convex spectral functions and norms over automorphism invariant sets.},
  archive      = {J_SIOPT},
  author       = {Juyoung Jeong and David Sossa},
  doi          = {10.1137/24M1646777},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1551-1569},
  shortjournal = {SIAM J. Optim.},
  title        = {Commutation principles for nonsmooth variational problems on euclidean jordan algebras},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New methods for parametric optimization via differential equations. <em>SIOPT</em>, <em>35</em>(3), 1524-1550. (<a href='https://doi.org/10.1137/23M1578462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop and analyze several different second-order algorithms for computing a near-optimal solution path of a convex parametric optimization problem with smooth Hessian. Our algorithms are inspired by a differential equation perspective on the parametric solution path and do not rely on the specific structure of the objective function. We present computational guarantees that bound the oracle complexity to achieve a near-optimal solution path under different sets of smoothness assumptions. Under the assumptions, the results are an improvement over the best-known results of the grid search methods. We also develop second-order conjugate gradient variants that avoid exact computations of Hessians and solving of linear equations. We present computational results that demonstrate the effectiveness of our methods over grid search methods on both real and synthetic datasets. On large-scale problems, we demonstrate significant speedups of the second-order conjugate variants as compared to the standard versions of our methods.},
  archive      = {J_SIOPT},
  author       = {Heyuan Liu and Paul Grigas},
  doi          = {10.1137/23M1578462},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1524-1550},
  shortjournal = {SIAM J. Optim.},
  title        = {New methods for parametric optimization via differential equations},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Homotopy methods for convex optimization. <em>SIOPT</em>, <em>35</em>(3), 1498-1523. (<a href='https://doi.org/10.1137/24M1693416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Convex optimization encompasses a wide range of optimization problems that contain many efficiently solvable subclasses. Interior point methods are currently the state-of-the-art approach for solving such problems, particularly effective for classes like semidefinite programming, quadratic programming, and geometric programming. However, their success hinges on the construction of self-concordant barrier functions for feasible sets. In this work, we investigate and develop a homotopy-based approach to solve convex optimization problems. While homotopy methods have been considered in optimization before, their potential for general convex programs remains underexplored. This approach gradually transforms the feasible set of a trivial optimization problem into the target one while tracking solutions by solving a differential equation, in contrast to traditional central path methods. We establish a criterion that ensures that the homotopy method correctly solves the optimization problem and prove the existence of such homotopies for several important classes, including semidefinite and hyperbolic programs. Furthermore, we demonstrate that our approach numerically outperforms state-of-the-art methods in hyperbolic programming, highlighting its practical advantages.},
  archive      = {J_SIOPT},
  author       = {Andreas Klingler and Tim Netzer},
  doi          = {10.1137/24M1693416},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1498-1523},
  shortjournal = {SIAM J. Optim.},
  title        = {Homotopy methods for convex optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approximation-based regularized extra-gradient method for monotone variational inequalities. <em>SIOPT</em>, <em>35</em>(3), 1469-1497. (<a href='https://doi.org/10.1137/23M1585258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a general extra-gradient scheme for solving monotone variational inequalities (VI), referred to here as the Approximation-based Regularized Extra-gradient method (ARE). The first step of ARE solves a VI subproblem, where the associated operator consists of an approximation operator satisfying a -order Lipschitz bound with respect to the original mapping, and the gradient of a -order regularization. The optimal global convergence is guaranteed by including an additional extra-gradient step, while a -order superlinear local convergence is shown to hold if the VI is strongly monotone. The proposed ARE is a broad scheme, in the sense that a variety of solution methods can be formulated within this framework as different manifestations of approximations, and their iteration complexities would follow through in a unified fashion. The ARE framework relates to the first-order methods, while opening up possibilities to developing higher-order methods specifically for structured problems that guarantee the optimal iteration complexity bounds.},
  archive      = {J_SIOPT},
  author       = {Kevin Huang and Shuzhong Zhang},
  doi          = {10.1137/23M1585258},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1469-1497},
  shortjournal = {SIAM J. Optim.},
  title        = {An approximation-based regularized extra-gradient method for monotone variational inequalities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected newton method for large-scale bayesian linear inverse problems. <em>SIOPT</em>, <em>35</em>(3), 1439-1468. (<a href='https://doi.org/10.1137/24M1645838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computing the regularized solution of Bayesian linear inverse problems as well as the corresponding regularization parameter is highly desirable in many applications. This paper proposes a novel iterative method, termed the Projected Newton method (PNT), that can simultaneously update the regularization parameter and solution step by step without requiring any expensive matrix inversions or decompositions. By reformulating the Tikhonov regularization as a constrained minimization problem and leveraging its Lagrangian function, a Newton-type method coupled with a Krylov subspace method is designed for the unconstrained Lagrangian function. The resulting PNT algorithm only needs solving a small-scale linear system to get a descent direction of a merit function at each iteration, thus significantly reducing computational overhead. Rigorous convergence results are proved, showing that PNT always converges to the unique regularized solution and the corresponding Lagrangian multiplier. Experimental results on both small-scale and large-scale Bayesian inverse problems demonstrate its excellent convergence property, robustness, and efficiency. Given that the most demanding computational tasks in PNT are primarily matrix-vector products, it is particularly well-suited for large-scale problems.},
  archive      = {J_SIOPT},
  author       = {Haibo Li},
  doi          = {10.1137/24M1645838},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1439-1468},
  shortjournal = {SIAM J. Optim.},
  title        = {Projected newton method for large-scale bayesian linear inverse problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonicity in quadratically regularized linear programs. <em>SIOPT</em>, <em>35</em>(2), 1419-1437. (<a href='https://doi.org/10.1137/24M1685171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In optimal transport, quadratic regularization is a sparse alternative to entropic regularization: the solution measure tends to have small support. Computational experience suggests that the support decreases monotonically to the unregularized counterpart as the regularization parameter is relaxed. We find it useful to investigate this monotonicity more abstractly for linear programs over polytopes, regularized with the squared norm. Here, monotonicity can be stated as an invariance property of the curve mapping the regularization parameter to the solution: once the curve enters a face of the polytope, does it remain in that face forever? We show that this invariance is equivalent to a geometric property of the polytope, namely that each face contains the minimum norm point of its affine hull. Returning to the optimal transport problem and its associated Birkhoff polytope, we verify this property for low dimensions but show that it fails for marginals with five or more point masses. As a consequence, the conjectured monotonicity of the support fails in general, even if experiments suggest that monotonicity holds for many cost matrices. Separately, we apply our geometric point of view to a problem of Erdős, namely to characterize the doubly stochastic matrices whose maximal trace equals their squared norm.},
  archive      = {J_SIOPT},
  author       = {Alberto González-Sanz and Marcel Nutz and Andrés Riveros Valdevenito},
  doi          = {10.1137/24M1685171},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1419-1437},
  shortjournal = {SIAM J. Optim.},
  title        = {Monotonicity in quadratically regularized linear programs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subdifferentially polynomially bounded functions and gaussian Smoothing–Based zeroth-order optimization. <em>SIOPT</em>, <em>35</em>(2), 1393-1418. (<a href='https://doi.org/10.1137/24M1659911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the class of subdifferentially polynomially bounded (SPB) functions, which is a rich class of locally Lipschitz functions that encompasses all Lipschitz functions, all gradient- or Hessian-Lipschitz functions, and even some nonsmooth locally Lipschitz functions. We show that SPB functions are compatible with Gaussian smoothing (GS), in the sense that the GS of any SPB function is well-defined and satisfies a descent lemma akin to gradient-Lipschitz functions, with the Lipschitz constant replaced by a polynomial function. Leveraging this descent lemma, we propose GS-based zeroth-order optimization algorithms with an adaptive stepsize strategy for minimizing SPB functions, and we analyze their convergence rates with respect to both relative and absolute stationarity measures. Finally, we also establish the iteration complexity for achieving a -approximate stationary point, based on a novel quantification of Goldstein stationarity via the GS gradient that could be of independent interest.},
  archive      = {J_SIOPT},
  author       = {Ming Lei and Ting Kei Pong and Shuqin Sun and Man-Chung Yue},
  doi          = {10.1137/24M1659911},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1393-1418},
  shortjournal = {SIAM J. Optim.},
  title        = {Subdifferentially polynomially bounded functions and gaussian Smoothing–Based zeroth-order optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On cutting plane algorithms for nonlinear binary optimization. <em>SIOPT</em>, <em>35</em>(2), 1364-1392. (<a href='https://doi.org/10.1137/23M1592493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The cutting plane method is known to converge for concave discrete maximization problems. This paper introduces a new condition for convergence that is weaker than concavity, allowing for extensions to generalized concave cases such as quasiconcavity and pseudoconcavity. More significantly, the new convergence condition enables the use of smaller penalty values in the standard concave reformulation technique for general nonconcave problems, yielding stronger cuts and faster convergence. In concave cases, this condition can even be applied to “deconcavify” concave problems to enhance convergence speed. Numerical results show that exploiting the new convergence condition can yield substantial computational improvements for complex, large-scale discrete optimization problems with up to one thousand variables.},
  archive      = {J_SIOPT},
  author       = {Hoa T. Bui and Ryan Loxton and Qun Lin},
  doi          = {10.1137/23M1592493},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1364-1392},
  shortjournal = {SIAM J. Optim.},
  title        = {On cutting plane algorithms for nonlinear binary optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast computation of optimal transport via entropy-regularized extragradient methods. <em>SIOPT</em>, <em>35</em>(2), 1330-1363. (<a href='https://doi.org/10.1137/23M1581443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Efficient computation of the optimal transport distance between two distributions serves as an algorithm subroutine that empowers various applications. This paper develops a scalable first-order optimization-based method that computes optimal transport to within additive accuracy with runtime , where denotes the dimension of the probability distributions of interest. Our algorithm achieves the state-of-the-art computational guarantees among all first-order methods, while exhibiting favorable numerical performance compared to classical algorithms like Sinkhorn and Greenkhorn. Underlying our algorithm designs are two key elements: (a) converting the original problem into a bilinear minimax problem over probability distributions; (b) exploiting the extragradient idea—in conjunction with entropy regularization and adaptive learning rates—to accelerate convergence.},
  archive      = {J_SIOPT},
  author       = {Gen Li and Yanxi Chen and Yu Huang and Yuejie Chi and H. Vincent Poor and Yuxin Chen},
  doi          = {10.1137/23M1581443},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1330-1363},
  shortjournal = {SIAM J. Optim.},
  title        = {Fast computation of optimal transport via entropy-regularized extragradient methods},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First-order methods for nonsmooth nonconvex functional constrained optimization with or without slater points. <em>SIOPT</em>, <em>35</em>(2), 1300-1329. (<a href='https://doi.org/10.1137/23M1569551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Constrained optimization problems where both the objective and constraints may be nonsmooth and nonconvex arise across many learning and data science settings. In this paper, we show for any Lipschitz, weakly convex objectives and constraints, a simple first-order method finds a feasible, -stationary point at a convergence rate of without relying on compactness or Constraint Qualification (CQ). When CQ holds, this convergence is measured by approximately satisfying the Karush–Kuhn–Tucker conditions. When CQ fails, we guarantee the attainment of weaker Fritz-John conditions. As an illustrative example, our method stably converges on piecewise quadratic SCAD regularized problems despite frequent violations of constraint qualification. The considered algorithm is similar to those of [D. Boob, Q. Deng, and G. Lan, Math. Program., 197 (2023), pp. 215–279, R. Ma, Q. Lin, and T. Yang, Quadratically regularized subgradient methods for weakly convex optimization with weakly convex constraints, in International Conference on Machine Learning, PMLR, 2020, pp. 6554–6564] (whose guarantees further assume compactness and CQ), iteratively taking inexact proximal steps, computed via an inner loop applying a switching subgradient method to a strongly convex constrained subproblem. Our non-Lipschitz analysis of the switching subgradient method appears to be new and may be of independent interest.},
  archive      = {J_SIOPT},
  author       = {Zhichao Jia and Benjamin Grimmer},
  doi          = {10.1137/23M1569551},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1300-1329},
  shortjournal = {SIAM J. Optim.},
  title        = {First-order methods for nonsmooth nonconvex functional constrained optimization with or without slater points},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New second-order optimality conditions for directional optimality of a general set-constrained optimization problem. <em>SIOPT</em>, <em>35</em>(2), 1274-1299. (<a href='https://doi.org/10.1137/24M1657493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we derive new second-order optimality conditions for a very general set-constrained optimization problem where the underlying set may be nonconvex. We consider local optimality in specific directions in pursuit of developing these new optimality conditions. Utilizing the classical and/or the lower generalized support function, we obtain new second-order necessary and sufficient conditions for local optimality of the general nonconvex constrained optimization problem in given directions via both the corresponding asymptotic second-order tangent cone and outer second-order tangent set. Our results do not require convexity and/or nonemptiness of the outer second-order tangent set. This is an important improvement to other results in the literature since the outer second-order tangent set can be nonconvex and empty even when the set is convex.},
  archive      = {J_SIOPT},
  author       = {Wei Ouyang and Jane J. Ye and Binbin Zhang},
  doi          = {10.1137/24M1657493},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1274-1299},
  shortjournal = {SIAM J. Optim.},
  title        = {New second-order optimality conditions for directional optimality of a general set-constrained optimization problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined TSSOS. <em>SIOPT</em>, <em>35</em>(2), 1246-1273. (<a href='https://doi.org/10.1137/24M1635296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The moment-sum of squares (SOS) hierarchy by Lasserre has become an established technique for solving polynomial optimization problems. It provides a monotonically increasing series of tight bounds; however, it has well-known scalability limitations. For structured optimization problems, the term-sparsity SOS (TSSOS) approach scales much better due to block-diagonal matrices, obtained by completing the connected components of adjacency graphs. This block structure can be exploited by semidefinite programming solvers, for which the overall runtime depends heavily on the size of the largest block. However, the first step of the TSSOS hierarchy may result in large diagonal blocks. Therefore, we propose a new approach that refines TSSOS iterations using combinatorial optimization and results in block-diagonal matrices with reduced maximum block sizes. Numerical results on a benchmark library show a large potential for computational speed-up for unconstrained and constrained polynomial optimization problems, while obtaining almost identical bounds in comparison to established methods.},
  archive      = {J_SIOPT},
  author       = {Daria Shaydurova and Volker Kaibel and Sebastian Sager},
  doi          = {10.1137/24M1635296},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1246-1273},
  shortjournal = {SIAM J. Optim.},
  title        = {Refined TSSOS},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentiability of probability functions involving star-shaped valued set-valued maps. <em>SIOPT</em>, <em>35</em>(2), 1216-1245. (<a href='https://doi.org/10.1137/24M1665465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In energy, mechanical engineering, and economics, the use of probability—or chance—constraints provides an intuitive way to deal with uncertainty. The careful study of analytical properties of the involved objects provides a stepping stone to improved numerical treatment. Probability functions consist of “measuring” that a given random vector belongs to a parameter dependent set. The analytical properties of the thus obtained probability function depend on the nature of the random vector and analytical properties of the parameter dependent set. In this paper we are concerned with the investigation of first-order information of probability functions wherein the parameter dependent sets are star-shaped. Under mild conditions we establish local Lipschitz continuity and provide formulae for the subdifferentials. We instantiate these formulae in concrete settings.},
  archive      = {J_SIOPT},
  author       = {Wim van Ackooij and Pedro Pérez-Aros and Claudia Soto},
  doi          = {10.1137/24M1665465},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1216-1245},
  shortjournal = {SIAM J. Optim.},
  title        = {Differentiability of probability functions involving star-shaped valued set-valued maps},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The stochastic conjugate subgradient algorithm for kernel support vector machines. <em>SIOPT</em>, <em>35</em>(2), 1194-1215. (<a href='https://doi.org/10.1137/23M156344X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Stochastic first-order (SFO) methods have been a cornerstone in addressing a broad spectrum of modern machine learning (ML) challenges. However, their efficacy is increasingly questioned, especially in large-scale applications where empirical evidence indicates potential performance limitations. In response, this paper proposes an innovative method specifically designed for kernel support vector machines (SVMs). This method not only achieves faster convergence per iteration but also exhibits enhanced scalability when compared to conventional SFO techniques. Diverging from traditional sample average approximation strategies that typically frame kernel SVM as an “all-in-one” quadratic program (QP), our approach adopts adaptive sampling. This strategy incrementally refines approximation accuracy on an “as-needed” basis. Crucially, this approach also inspires a decomposition-based algorithm, effectively decomposing parameter selection from error estimation, with the latter being independently determined for each data point. To exploit the quadratic nature of the kernel matrix, we introduce a stochastic conjugate subgradient method. This method preserves many benefits of first-order approaches while adeptly handling both nonlinearity and nonsmooth aspects of the SVM problem. Thus, it extends beyond the capabilities of standard SFO algorithms for nonsmooth convex optimization. The convergence rate of this novel method is thoroughly analyzed within this paper. Our experimental results demonstrate that the proposed algorithm not only maintains but potentially exceeds the scalability of SFO methods. Moreover, it significantly enhances both speed and accuracy of the optimization process.},
  archive      = {J_SIOPT},
  author       = {Di Zhang and Suvrajeet Sen},
  doi          = {10.1137/23M156344X},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1194-1215},
  shortjournal = {SIAM J. Optim.},
  title        = {The stochastic conjugate subgradient algorithm for kernel support vector machines},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating preconditioned ADMM via degenerate proximal point mappings. <em>SIOPT</em>, <em>35</em>(2), 1165-1193. (<a href='https://doi.org/10.1137/24M1650053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we aim to accelerate a preconditioned alternating direction method of multipliers (pADMM), whose proximal terms are convex quadratic functions, for solving linearly constrained convex optimization problems. To achieve this, we first reformulate the pADMM into a form of the proximal point method (PPM) with a positive semidefinite preconditioner which can be degenerate due to the lack of strong convexity of the proximal terms in the pADMM. Then we accelerate the pADMM by accelerating the reformulated degenerate PPM (dPPM). Specifically, we first propose an accelerated dPPM by integrating the Halpern iteration and the fast Krasnosel’skiĭ–Mann iteration into it, achieving asymptotic and nonasymptotic convergence rates. Subsequently, building upon the accelerated dPPM, we develop an accelerated pADMM algorithm that exhibits both asymptotic and nonasymptotic nonergodic convergence rates concerning the Karush–Kuhn–Tucker residual and the primal objective function value gap. Preliminary numerical experiments validate the theoretical findings, demonstrating that the accelerated pADMM outperforms the pADMM in solving convex quadratic programming problems.},
  archive      = {J_SIOPT},
  author       = {Defeng Sun and Yancheng Yuan and Guojun Zhang and Xinyuan Zhao},
  doi          = {10.1137/24M1650053},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1165-1193},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerating preconditioned ADMM via degenerate proximal point mappings},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of the SiMPL method for density-based topology optimization. <em>SIOPT</em>, <em>35</em>(2), 1134-1164. (<a href='https://doi.org/10.1137/24M1708863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a rigorous convergence analysis of a new method for density-based topology optimization that provides pointwise bound-preserving design updates and faster convergence than other popular first-order topology optimization methods. Due to its strong bound preservation, the method is exceptionally robust, as demonstrated in numerous examples here and in the companion article [D. Kim et al., Struct. Multidiscip. Optim., 68 (2025), 74]. Furthermore, it is easy to implement with clear structure and analytical expressions for the updates. Our analysis covers two versions of the method, characterized by the employed line search strategies. We consider a modified Armijo backtracking line search and a Bregman backtracking line search. For both line search algorithms, our algorithm delivers a strict monotone decrease in the objective function and further intuitive convergence properties, e.g., strong and pointwise convergence of the density variables on the active sets, norm convergence to zero of the increments, convergence of the Lagrange multipliers, and more. In addition, the numerical experiments demonstrate apparent mesh-independent convergence of the algorithm. We refer to the new algorithm as the SiMPL method (pronounced “simple”), which stands for Sigmoidal Mirror descent with a Projected Latent variable.},
  archive      = {J_SIOPT},
  author       = {Brendan Keith and Dohyun Kim and Boyan S. Lazarov and Thomas M. Surowiec},
  doi          = {10.1137/24M1708863},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1134-1164},
  shortjournal = {SIAM J. Optim.},
  title        = {Analysis of the SiMPL method for density-based topology optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A derivative-free method using a new underdetermined quadratic interpolation model. <em>SIOPT</em>, <em>35</em>(2), 1110-1133. (<a href='https://doi.org/10.1137/23M1582023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze the least norm type underdetermined quadratic interpolation model proposed by Conn and Toint [An algorithm using quadratic interpolation for unconstrained derivative free optimization, 1996] from the perspective of the property of trust-region iteration. We find the Karush–Kuhn–Tucker multiplier’s nondeterminacy when constructing a quadratic model considering the trust-region iteration in the case where the current iteration point is on the boundary of the trust region. The lack of the quadratic model’s uniqueness caused by the Karush–Kuhn–Tucker multiplier’s nondeterminacy leads us to propose a new model to consequently improve the model by selectively treating the previously obtained underdetermined quadratic model as a quadratic model or a linear one. A new derivative-free method is given by introducing the improved underdetermined quadratic interpolation model considering the optimality of the model based on the trust-region iteration. The theoretical motivation, property, computational details, and the quadratic model’s formula derived from the Karush–Kuhn–Tucker conditions are discussed. The formula is implementation-friendly for the existing model-based derivative-free methods. The numerical results with released codes support the advantages of our quadratic model in the derivative-free optimization methods. To the best of our knowledge, this is the first work considering the property of trust-region iteration and the model’s optimality when constructing the underdetermined quadratic model for derivative-free trust-region methods.},
  archive      = {J_SIOPT},
  author       = {Pengcheng Xie and Ya-xiang Yuan},
  doi          = {10.1137/23M1582023},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1110-1133},
  shortjournal = {SIAM J. Optim.},
  title        = {A derivative-free method using a new underdetermined quadratic interpolation model},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of ZH-type nonmonotone descent method for kurdyka–Łojasiewicz optimization problems. <em>SIOPT</em>, <em>35</em>(2), 1089-1109. (<a href='https://doi.org/10.1137/24M1669153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel iterative framework for minimizing a proper lower semicontinuous Kurdyka–Łojasiewicz (KL) function . It comprises a Zhang–Hager (ZH-type) nonmonotone decrease condition and a relative error condition. Hence, the sequence generated by the ZH-type nonmonotone descent methods will fall within this framework. Any sequence conforming to this framework is proved to converge to a critical point of . If in addition has the KL property of exponent at the critical point, the convergence has a linear rate for and a sublinear rate of exponent for . To the best of our knowledge, this is the first work to establish the full convergence of the iterate sequence generated by a ZH-type nonmonotone descent method for nonconvex and nonsmooth optimization problems. The obtained results are also applied to achieve the full convergence of the iterate sequences produced by the proximal gradient method and Riemannian gradient method with the ZH-type nonmonotone line-search.},
  archive      = {J_SIOPT},
  author       = {Yitian Qian and Ting Tao and Shaohua Pan and Houduo Qi},
  doi          = {10.1137/24M1669153},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1089-1109},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of ZH-type nonmonotone descent method for kurdyka–Łojasiewicz optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fisher–Rao gradient flows of linear programs and state-action natural policy gradients. <em>SIOPT</em>, <em>35</em>(2), 1060-1088. (<a href='https://doi.org/10.1137/24M1653422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Kakade’s natural policy gradient method has been studied extensively in recent years, showing linear convergence with and without regularization. We study another natural gradient method based on the Fisher information matrix of the state-action distributions which has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher–Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher–Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher–Rao gradient flows and natural gradient flows up to an approximation error. In particular, these general results cover the case of state-action natural policy gradients.},
  archive      = {J_SIOPT},
  author       = {Johannes Müller and Semih Çayci and Guido Montúfar},
  doi          = {10.1137/24M1653422},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1060-1088},
  shortjournal = {SIAM J. Optim.},
  title        = {Fisher–Rao gradient flows of linear programs and state-action natural policy gradients},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic-gradient-based interior-point algorithm for solving smooth bound-constrained optimization problems. <em>SIOPT</em>, <em>35</em>(2), 1030-1059. (<a href='https://doi.org/10.1137/23M1569460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A stochastic-gradient-based interior-point algorithm for minimizing a continuously differentiable objective function (that may be nonconvex) subject to bound constraints is presented, analyzed, and demonstrated through experimental results. The algorithm is unique from other interior-point methods for solving smooth nonconvex optimization problems since the search directions are computed using stochastic gradient estimates. It is also unique in its use of inner neighborhoods of the feasible region—defined by a positive and vanishing neighborhood-parameter sequence—in which the iterates are forced to remain. It is shown that with a careful balance between the barrier, step size, and neighborhood sequences, the proposed algorithm satisfies convergence guarantees in both deterministic and stochastic settings. The results of numerical experiments show that in both settings the algorithm can outperform projection-based methods.},
  archive      = {J_SIOPT},
  author       = {Frank E. Curtis and Vyacheslav Kungurtsev and Daniel P. Robinson and Qi Wang},
  doi          = {10.1137/23M1569460},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1030-1059},
  shortjournal = {SIAM J. Optim.},
  title        = {A stochastic-gradient-based interior-point algorithm for solving smooth bound-constrained optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected gradient descent accumulates at bouligand stationary points. <em>SIOPT</em>, <em>35</em>(2), 1004-1029. (<a href='https://doi.org/10.1137/24M1692782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper considers the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and algorithms are only expected to find a stationary point. PGD generates a sequence in the set whose accumulation points are known to be Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.},
  archive      = {J_SIOPT},
  author       = {Guillaume Olikier and Irène Waldspurger},
  doi          = {10.1137/24M1692782},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1004-1029},
  shortjournal = {SIAM J. Optim.},
  title        = {Projected gradient descent accumulates at bouligand stationary points},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving moment and polynomial optimization problems on sobolev spaces. <em>SIOPT</em>, <em>35</em>(2), 989-1003. (<a href='https://doi.org/10.1137/24M163133X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Using standard tools of harmonic analysis, we state and solve the problem of moments for nonnegative measures supported on the unit ball of a Sobolev space of multivariate periodic trigonometric functions. We describe outer and inner semidefinite approximations of the cone of Sobolev moments. They are the basic components of an infinite-dimensional moment–sums of squares hierarchy, allowing us to numerically solve nonconvex polynomial optimization problems on infinite-dimensional Sobolev spaces with global convergence guarantees.},
  archive      = {J_SIOPT},
  author       = {Didier Henrion and Alessandro Rudi},
  doi          = {10.1137/24M163133X},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {989-1003},
  shortjournal = {SIAM J. Optim.},
  title        = {Solving moment and polynomial optimization problems on sobolev spaces},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An inexact \({q}\)-order regularized proximal newton method for nonconvex composite optimization. <em>SIOPT</em>, <em>35</em>(2), 959-988. (<a href='https://doi.org/10.1137/23M1618697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper concerns the composite problem of minimizing the sum of a twice continuously differentiable function and a nonsmooth convex function. For this class of nonconvex and nonsmooth problems, by leveraging a practical inexactness criterion and a novel selection strategy for iterates, we propose an inexact -order regularized proximal Newton method for , which becomes an inexact cubic regularization (CR) method for . We prove that the whole iterate sequence converges to a stationary point for the KL objective function; and when the objective function has the KL property of exponent , the convergence has a local -superlinear rate of order . In particular, under a local Hölderian error bound of order on a second-order stationary point set, we show that the iterate and objective value sequences converge to a second-order stationary point and a second-order stationary value, respectively, with a local -superlinear rate of order , specified as the -quadratic rate for and . This is the first practical inexact CR method with -quadratic convergence rate for nonconvex composite optimization. We validate the efficiency of the CR method with ZeroFPR as the inner solver by applying it to composite optimization problems with highly nonlinear .},
  archive      = {J_SIOPT},
  author       = {Ruyu Liu and Shaohua Pan and Yitian Qian},
  doi          = {10.1137/23M1618697},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {959-988},
  shortjournal = {SIAM J. Optim.},
  title        = {An inexact \({q}\)-order regularized proximal newton method for nonconvex composite optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric characterizations of lipschitz stability for convex optimization problems. <em>SIOPT</em>, <em>35</em>(2), 927-958. (<a href='https://doi.org/10.1137/24M1637532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we mainly study tilt stability and Lipschitz stability of convex optimization problems. Our characterizations are geometric and fully computable in many important cases. As a result, we apply our theory to the group Lasso problem and the nuclear norm minimization problem and reveal that the Lipschitz stability of the solution mapping in these problems is automatic whenever the solution mapping is single-valued.},
  archive      = {J_SIOPT},
  author       = {Tran T. A. Nghia},
  doi          = {10.1137/24M1637532},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {927-958},
  shortjournal = {SIAM J. Optim.},
  title        = {Geometric characterizations of lipschitz stability for convex optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cutting planes for signomial programming. <em>SIOPT</em>, <em>35</em>(2), 899-926. (<a href='https://doi.org/10.1137/23M1599537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Cutting planes are of crucial importance when solving nonconvex nonlinear programs to global optimality, for example using the spatial branch-and-bound algorithms. In this paper, we discuss the generation of cutting planes for signomial programming. Many global optimization algorithms lift signomial programs into an extended formulation such that these algorithms can construct relaxations of the signomial program by outer approximations of the lifted set encoding nonconvex signomial term sets, i.e., hypographs, or epigraphs of signomial terms. We show that any signomial term set can be transformed into the subset of the difference of two concave power functions, from which we derive two kinds of valid linear inequalities. Intersection cuts are constructed using signomial term-free sets which do not contain any point of the signomial term set in their interior. We show that these signomial term-free sets are maximal in the nonnegative orthant, and use them to derive intersection sets. We then convexify a concave power function in the reformulation of the signomial term set, resulting in a convex set containing the signomial term set. This convex outer approximation is constructed in an extended space, and we separate a class of valid linear inequalities by projection from this approximation. We implement the valid inequalities in a global optimization solver and test them on MINLPLib instances. Our results show that both types of valid inequalities provide comparable reductions in running time, number of search nodes, and duality gap.},
  archive      = {J_SIOPT},
  author       = {Liding Xu and Claudia D’Ambrosio and Leo Liberti and Sonia Haddad-Vanier},
  doi          = {10.1137/23M1599537},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {899-926},
  shortjournal = {SIAM J. Optim.},
  title        = {Cutting planes for signomial programming},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On graphs with finite-time consensus and their use in gradient tracking. <em>SIOPT</em>, <em>35</em>(2), 872-898. (<a href='https://doi.org/10.1137/24M1661455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies sequences of graphs satisfying the finite-time consensus property (i.e., iterating through such a finite sequence is equivalent to performing global or exact averaging) and their use in the decentralized optimization algorithm Gradient Tracking. For each of the studied graph sequences, we provide an explicit weight matrix representation and prove their finite-time consensus property. Moreover, we incorporate such topology sequences into Gradient Tracking and present a new algorithmic scheme called Gradient Tracking for Finite-Time Consensus Topologies (GT-FT). We analyze the new scheme for nonconvex problems with stochastic gradient estimates. Our analysis shows that the convergence rate of GT-FT does not depend on the heterogeneity of the agents’ functions or the connectivity of any individual graph in the topology sequence. Furthermore, owing to the sparsity of the graphs, GT-FT requires lower communication costs than Gradient Tracking using the static counterpart of the topology sequence.},
  archive      = {J_SIOPT},
  author       = {Edward Duc Hien Nguyen and Xin Jiang and Bicheng Ying and César A. Uribe},
  doi          = {10.1137/24M1661455},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {872-898},
  shortjournal = {SIAM J. Optim.},
  title        = {On graphs with finite-time consensus and their use in gradient tracking},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Block majorization-minimization with diminishing radius for constrained nonsmooth nonconvex optimization. <em>SIOPT</em>, <em>35</em>(2), 842-871. (<a href='https://doi.org/10.1137/23M1604515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Block majorization-minimization (BMM) is a simple iterative algorithm for constrained nonconvex optimization that sequentially minimizes majorizing surrogates of the objective function in each block while the others are held fixed. BMM entails a large class of optimization algorithms such as block coordinate descent and its proximal-point variant, expectation-minimization, and block projected gradient descent. We first establish that for general constrained nonsmooth nonconvex optimization, BMM with -strongly convex and -smooth surrogates can produce an -approximate first-order optimal point within iterations and asymptotically converges to the set of first-order optimal points. Next, we show that BMM combined with a trust-region method with diminishing radius has an improved complexity of , independent of the inverse strong convexity parameter , allowing improved theoretical and practical performance with “flat” surrogates. Our results hold robustly even when the convex subproblems are solved inexactly as long as the optimality gaps are summable. Central to our analysis is a novel continuous first-order optimality measure, by which we bound the worst-case suboptimality in each iteration by the first-order improvement the algorithm makes. We apply our general framework to obtain new results on various algorithms such as the celebrated multiplicative update algorithm for nonnegative matrix factorization by Lee and Seung, regularized nonnegative tensor decomposition, and the classical block projected gradient descent algorithm. Lastly, we numerically demonstrate that the additional use of diminishing radius can improve the convergence rate of BMM in many instances.},
  archive      = {J_SIOPT},
  author       = {Hanbaek Lyu and Yuchen Li},
  doi          = {10.1137/23M1604515},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {842-871},
  shortjournal = {SIAM J. Optim.},
  title        = {Block majorization-minimization with diminishing radius for constrained nonsmooth nonconvex optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the fermat optimality rules. <em>SIOPT</em>, <em>35</em>(2), 818-841. (<a href='https://doi.org/10.1137/23M1578036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work proposes a general framework for analyzing the behavior at its extrema of an extended real-valued function assumed neither convex nor differentiable and for which the classical Fermat rules of optimality do not apply. The tools used for building this framework are the notions of sup-subdifferential, recently introduced by two of the authors together with Kruger, and partial sup-subdifferentials. The sup-subdifferential is a nonempty enlargement of the Moreau–Rockafellar subdifferential that satisfies most of its fundamental properties and enjoys certain calculus rules. The partial sup-subdifferentials are obtained by breaking down the sup-subdifferential into one-dimensional components through basis elements and play the same role as the partial derivatives in the Fermat optimality rules.},
  archive      = {J_SIOPT},
  author       = {Malek Abbasi and Sorin-Mihai Grad and Michel A. Théra},
  doi          = {10.1137/23M1578036},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {818-841},
  shortjournal = {SIAM J. Optim.},
  title        = {Beyond the fermat optimality rules},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized bayesian nash equilibrium with continuous type and action spaces. <em>SIOPT</em>, <em>35</em>(2), 789-817. (<a href='https://doi.org/10.1137/24M1653859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A Bayesian game is a strategic decision-making model where each player’s type parameter characterizing its own objective is private information: Each player knows its own type but not its rivals’ types, and a Bayesian Nash equilibrium is an outcome of this game where each player makes a strategic optimal decision according to its own type under the Nash conjecture. In this paper, we advance the literature by considering a generalized Bayesian game where each player’s action space depends on its own type parameter and its rivals’ actions. This reflects the fact that in practical applications, a player’s feasible action is often related to its own type (e.g., marginal cost) and the rivals’ actions (e.g., common resource constraints in a competitive market). Under some moderate conditions, we demonstrate the existence of a continuous generalized Bayesian Nash equilibrium (GBNE) and the uniqueness of such an equilibrium when each player’s action space is only dependent on its type. In the case that each player’s action space also depends on rivals’ actions, we give a simple example to show that the uniqueness of the GBNE is not guaranteed under standard monotone conditions. To compute an approximate GBNE, we restrict each player’s response function to the space of polynomial functions of its type parameter and subsequently convert the GBNE model to a stochastic generalized Nash equilibrium model. To justify the approximation, we discuss the convergence of the approximation scheme. Some preliminary numerical test results show that the approximation scheme works well.},
  archive      = {J_SIOPT},
  author       = {Yuan Tao and Huifu Xu},
  doi          = {10.1137/24M1653859},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {789-817},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized bayesian nash equilibrium with continuous type and action spaces},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A variational approach to weakly continuous relations in banach spaces. <em>SIOPT</em>, <em>35</em>(2), 767-788. (<a href='https://doi.org/10.1137/23M1589888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Optimization and equilibrium problems have been extensively studied when the involved preference relations admit a representation by means of real-valued functions. Although these problems have been analyzed under very minimal assumptions on the representation function, this context could appear to be quite restrictive in some practical situations. By using tools of variational analysis and normal operator techniques, very recently some authors have explored the properties of preference relations that do not necessarily admit a numerical representation. However, these contributions are limited to finite-dimensional settings. Our aim in the present work is to develop a new analysis of preference relations in topological spaces and to analyze, in Banach spaces, a suitable concept of a normal operator to the upper contour set. As an application of our theoretical developments, we analyze a particular preference equilibrium problem (of which a preference maximization problem is a particular case) by using a suitable quasi-variational inequality formulation; as an example, a preference allocation problem is also considered.},
  archive      = {J_SIOPT},
  author       = {Didier Aussel and Massimiliano Giuli and Monica Milasi and Domenico Scopelliti},
  doi          = {10.1137/23M1589888},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {767-788},
  shortjournal = {SIAM J. Optim.},
  title        = {A variational approach to weakly continuous relations in banach spaces},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonparametric robust optimization approach for chance-constrained knapsack problem. <em>SIOPT</em>, <em>35</em>(2), 739-766. (<a href='https://doi.org/10.1137/23M1620867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A chance-constrained knapsack problem (CCKP) is a knapsack problem restricted by a chance constraint, which ensures that the total capacity constraint under uncertain volume can be violated only up to a given probability threshold. CCKP is challenging to solve due to its combinatorial nature and the involvement of its chance constraint. Existing solution methods for CCKP with tractability guarantees mainly focus on two approaches: (1) a full-information approach (stochastic programming) that assumes the uncertain volume follows certain distributions, such as normal or empirical distribution; (2) a partial-information approach (robust optimization) that adopts specific statistics of the unknown distribution, such as the mean and variance. The existing full-information approach lacks robustness under limited samples due to its strong assumption; the existing partial-information approach can be further improved, as the uncertainty set or distributional ambiguity set can be ameliorated. With these concerns in mind, we propose a nonparametric robust approach for CCKP by involving a novel nonparametric statistic to form a new distributional ambiguity set. Furthermore, we develop an upper bound on the violation probability of the chance constraint under the distributional ambiguity set to approximate CCKP by a deterministic robust counterpart. In terms of solution methodology, we decompose the deterministic robust counterpart into cardinality-constrained knapsack problems, which can be efficiently solved by the proposed dynamic programming algorithm. Computational results show that our proposed solution methods produce better solutions to CCKP compared with existing approaches.},
  archive      = {J_SIOPT},
  author       = {Liang Xu and Chao Zhang and Zhou Xu and Daniel Zhuoyu Long},
  doi          = {10.1137/23M1620867},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {739-766},
  shortjournal = {SIAM J. Optim.},
  title        = {A nonparametric robust optimization approach for chance-constrained knapsack problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aubin property and strong regularity are equivalent for nonlinear second-order cone programming. <em>SIOPT</em>, <em>35</em>(2), 712-738. (<a href='https://doi.org/10.1137/24M1670676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper solves a fundamental open problem in variational analysis on the equivalence between the Aubin property and the strong regularity for nonlinear second-order cone programming (SOCP) at a locally optimal solution. We achieve this by introducing a reduction approach to the Aubin property characterized by the Mordukhovich criterion and a lemma of alternative choices on cones to replace the S-lemma used in Outrata and Ramírez [SIAM J. Optim., 21 (2011), pp. 789–823] and Opazo, Outrata, and Ramírez [SIAM J. Optim., 27 (2017), pp. 2143–2151], where the same SOCP was considered under the strict complementarity condition except for possibly only one block of constraints. As a byproduct, we also offer a new approach to the well-known result of Dontchev and Rockafellar [SIAM J. Optim., 6 (1996), pp. 1087–1105] on the equivalence of the two concepts in conventional nonlinear programming.},
  archive      = {J_SIOPT},
  author       = {Liang Chen and Ruoning Chen and Defeng Sun and Junyuan Zhu},
  doi          = {10.1137/24M1670676},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {712-738},
  shortjournal = {SIAM J. Optim.},
  title        = {Aubin property and strong regularity are equivalent for nonlinear second-order cone programming},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Second-order subdifferential optimality conditions in nonsmooth optimization. <em>SIOPT</em>, <em>35</em>(2), 678-711. (<a href='https://doi.org/10.1137/23M1627237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is devoted to deriving novel second-order necessary and sufficient optimality conditions for local minimizers in rather general classes of nonsmooth unconstrained and constrained optimization problems in finite-dimensional spaces. The established conditions are expressed in terms of second-order subdifferentials of lower semicontinuous functions and mainly concern prox-regular objectives that cover a large territory in nonsmooth optimization and its applications. Our tools are based on the machinery of variational analysis and second-order generalized differentiation. The obtained general results are applied to problems of nonlinear programming, where the derived second-order optimality conditions are new even for problems with twice continuously differential data, being expressed there in terms of the classical Hessian matrices.},
  archive      = {J_SIOPT},
  author       = {P. D. Khanh and V. V. H. Khoa and B. S. Mordukhovich and V. T. Phat},
  doi          = {10.1137/23M1627237},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {678-711},
  shortjournal = {SIAM J. Optim.},
  title        = {Second-order subdifferential optimality conditions in nonsmooth optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex quartic problems: Homogenized gradient method and preconditioning. <em>SIOPT</em>, <em>35</em>(2), 651-677. (<a href='https://doi.org/10.1137/23M1583363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a convex minimization problem for which the objective is the sum of a homogeneous polynomial of degree four and a linear term. Such a task arises as a subproblem in algorithms for quadratic inverse problems with a difference-of-convex structure. We design a first-order method called homogenized gradient, along with an accelerated version, which enjoy fast convergence rates of, respectively, and in relative accuracy, where is the iteration counter. The constant is the quartic condition number of the problem. Then, we show that for a certain class of problems, it is possible to compute a preconditioner for which this condition number is , where is the problem dimension. To establish this, we study the more general problem of finding the best quadratic approximation of an norm composed with a quadratic map. Our construction involves a generalization of the so-called Lewis weights.},
  archive      = {J_SIOPT},
  author       = {Radu-Alexandru Dragomir and Yurii Nesterov},
  doi          = {10.1137/23M1583363},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {651-677},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex quartic problems: Homogenized gradient method and preconditioning},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model construction for convex-constrained derivative-free optimization. <em>SIOPT</em>, <em>35</em>(2), 622-650. (<a href='https://doi.org/10.1137/24M1649113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a new approximation theory for linear and quadratic interpolation models, suitable for use in convex-constrained derivative-free optimization (DFO). Most existing model-based DFO methods for constrained problems assume the ability to construct sufficiently accurate approximations via interpolation, but the standard notions of accuracy (designed for unconstrained problems) may not be achievable by only sampling feasible points, and so may not give practical algorithms. In this work, we demonstrate that linear regression models and underdetermined quadratic interpolation models (in the minimum Frobenius sense) can be made sufficiently accurate (in a sense appropriate for convex-constrained problems) using only feasible points. For the underdetermined quadratic interpolation case, we provide a simple procedure for constructing such feasible interpolation sets, providing a theoretical basis for practical and strictly feasible methods for constrained DFO.},
  archive      = {J_SIOPT},
  author       = {Lindon Roberts},
  doi          = {10.1137/24M1649113},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {622-650},
  shortjournal = {SIAM J. Optim.},
  title        = {Model construction for convex-constrained derivative-free optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse polynomial optimization with unbounded sets. <em>SIOPT</em>, <em>35</em>(2), 593-621. (<a href='https://doi.org/10.1137/24M1636010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper considers sparse polynomial optimization with unbounded sets. When the problem possesses correlative sparsity, we propose a sparse homogenized moment-SOS hierarchy with perturbations to solve it. The new hierarchy introduces one extra auxiliary variable for each variable clique according to the correlative sparsity pattern. Under the running intersection property, we prove that this hierarchy asymptotically converges to a value close to the optimum. Furthermore, we also provide two sparse homogenized moment-SOS hierarchies without perturbations, each having asymptotic convergence to the exact optimum. As by-products, new Positivstellensätze are obtained for sparse positive polynomials on unbounded sets. Extensive numerical experiments demonstrate the power of our approaches in solving sparse polynomial optimization problems on unbounded sets with up to thousands of variables. Finally, we apply our approaches to tackle two trajectory optimization problems: block-moving with minimum work, and optimal control of Van der Pol.},
  archive      = {J_SIOPT},
  author       = {Lei Huang and Shucheng Kang and Jie Wang and Heng Yang},
  doi          = {10.1137/24M1636010},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {593-621},
  shortjournal = {SIAM J. Optim.},
  title        = {Sparse polynomial optimization with unbounded sets},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the complexity of matrix putinar’s positivstellensätz. <em>SIOPT</em>, <em>35</em>(1), 567-591. (<a href='https://doi.org/10.1137/24M1675461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the complexity of matrix Putinar’s Positivstellensätz on the semialgebraic set that is given by the polynomial matrix inequality. When the quadratic module generated by the constrained polynomial matrix is Archimedean, we prove a polynomial bound on the degrees of terms appearing in the representation of matrix Putinar’s Positivstellensätz. Estimates on the exponent and constant are given. As a byproduct, a polynomial bound on the convergence rate of matrix sum-of-squares relaxations is obtained, which resolves an open question raised by Dinh and Pham [J. Complexity, 41 (2017), pp. 58–71]. When the constraining set is unbounded, we also prove a similar bound for the matrix version of Putinar–Vasilescu’s Positivstellensätz by exploiting homogenization techniques.},
  archive      = {J_SIOPT},
  author       = {Lei Huang},
  doi          = {10.1137/24M1675461},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {567-591},
  shortjournal = {SIAM J. Optim.},
  title        = {On the complexity of matrix putinar’s positivstellensätz},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the connections between optimization algorithms, lyapunov functions, and differential equations: Theory and insights. <em>SIOPT</em>, <em>35</em>(1), 537-566. (<a href='https://doi.org/10.1137/23M1625287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We revisit the general framework introduced by Fazylab et al. [SIAM J. Optim., 28 (2018), pp. 2654–2689] to construct Lyapunov functions for optimization algorithms in discrete and continuous time. For smooth, strongly convex objective functions, we relax the requirements necessary for such a construction. As a result, we are able to prove for Polyak’s ordinary differential equations and for a two-parameter family of Nesterov algorithms rates of convergence that improve on those available in the literature. We analyze the interpretation of Nesterov algorithms as discretizations of the Polyak equation. We show that the algorithms are instances of additive Runge–Kutta integrators and discuss the reasons why most discretizations of the differential equation do not result in optimization algorithms with acceleration. We also introduce a modification of Polyak’s equation and study its convergence properties. Finally, we extend the general framework to the stochastic scenario and consider an application to random algorithms with acceleration for overparameterized models; again we are able to prove convergence rates that improve on those in the literature.},
  archive      = {J_SIOPT},
  author       = {Paul Dobson and Jesus M. Sanz-Serna and Konstantinos C. Zygalakis},
  doi          = {10.1137/23M1625287},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {537-566},
  shortjournal = {SIAM J. Optim.},
  title        = {On the connections between optimization algorithms, lyapunov functions, and differential equations: Theory and insights},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage distributionally robust conic linear programming over 1-wasserstein balls. <em>SIOPT</em>, <em>35</em>(1), 506-536. (<a href='https://doi.org/10.1137/23M1626839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies two-stage distributionally robust conic linear programming under constraint uncertainty over type-1 Wasserstein balls. We present optimality conditions for the dual of the worst-case expectation problem, which characterizes worst-case uncertain parameters for its inner maximization problem. This condition offers an alternative proof, a counterexample, and an extension to previous works. Additionally, the condition highlights the potential advantage of a specific distance metric for out-of-sample performance, as exemplified in a numerical study on a facility location problem with demand uncertainty. Furthermore, cutting-plane-based algorithms, equipped with a unified scenario generation framework, are proposed for addressing both unbounded support and second-stage dual feasible regions, with a finite convergence proof under less stringent assumptions.},
  archive      = {J_SIOPT},
  author       = {Geunyeong Byeon and Kaiwen Fang and Kibaek Kim},
  doi          = {10.1137/23M1626839},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {506-536},
  shortjournal = {SIAM J. Optim.},
  title        = {Two-stage distributionally robust conic linear programming over 1-wasserstein balls},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive partitioning for chance-constrained problems with finite support. <em>SIOPT</em>, <em>35</em>(1), 476-505. (<a href='https://doi.org/10.1137/24M1632772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies chance-constrained stochastic optimization problems with finite support. It presents an iterative method that solves reduced-size chance-constrained models obtained by partitioning the scenario set. Each reduced problem is constructed to yield a bound on the optimal value of the original problem. We show how to adapt the partitioning of the scenario set so that our adaptive method returns the optimal solution of the original chance-constrained problem in a finite number of iterations. At the heart of the method lie two fundamental operations: refinement and merging. A refinement operation divides a subset of the partition, whereas a merging operation combines a group of subsets into one. We describe how to use these operations to enhance the bound obtained in each step of the method while preserving the small size of the reduced model. Under mild conditions, we prove that, for specific refinement and merge operations, the bound obtained after solving each reduced model strictly improves throughout the iterative process. Our general method allows the seamless integration of various computational enhancements, significantly reducing the computational time required to solve the reduced chance-constrained problems. The method’s efficiency is assessed through numerical experiments on chance-constrained multidimensional knapsack problems. We study the impact of our method’s components and compare its performance against other methods from the recent literature.},
  archive      = {J_SIOPT},
  author       = {Marius Roland and Alexandre Forel and Thibaut Vidal},
  doi          = {10.1137/24M1632772},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {476-505},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive partitioning for chance-constrained problems with finite support},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing hierarchical jointly convex generalized nash equilibrium problems with nonsmooth payoffs. <em>SIOPT</em>, <em>35</em>(1), 445-475. (<a href='https://doi.org/10.1137/23M1574026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a generalized Nash equilibrium problem whose joint feasible region is implicitly defined as the solution set of another Nash game. This structure arises, e.g., in multiportfolio selection contexts, whenever agents interact at different hierarchical levels. We consider nonsmooth terms in all players’ objectives, to promote, for example, sparsity in the solution. Under standard assumptions, we show that the equilibrium problems we deal with have a nonempty solution set and turn out to be jointly convex. To compute variational equilibria, we devise different first-order projection Tikhonov-like methods whose convergence properties are studied. We provide complexity bounds and equip our analysis with numerical tests using real-world financial datasets.},
  archive      = {J_SIOPT},
  author       = {Lorenzo Lampariello and Simone Sagratella and Valerio Giuseppe Sasso},
  doi          = {10.1137/23M1574026},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {445-475},
  shortjournal = {SIAM J. Optim.},
  title        = {Addressing hierarchical jointly convex generalized nash equilibrium problems with nonsmooth payoffs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of discrete-time linear complementarity systems. <em>SIOPT</em>, <em>35</em>(1), 419-444. (<a href='https://doi.org/10.1137/20M1387377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A Discrete-Time Linear Complementarity System (DLCS) is a dynamical system in discrete time whose state evolution is governed by linear dynamics in states and algebraic variables that solve a Linear Complementarity Problem (LCP). The DLCS is the hybrid dynamical system that is the discrete-time counterpart of the well-known Linear Complementarity System (LCS). We derive sufficient conditions for Lyapunov stability of a DLCS when using a quadratic Lyapunov function that depends only on the state variables and a quadratic Lyapunov function that depends both on the state and the algebraic variables. The sufficient conditions require checking the feasibility of a copositive program over nonconvex cones. Our results only assume that the LCP is solvable and do not require the solutions to be unique. We devise a novel, exact cutting plane algorithm for the verification of stability and the computation of the Lyapunov functions. To the best of our knowledge, our algorithm is the first exact approach for stability verification of DLCS. A number of numerical examples are presented to illustrate the approach. Though our main object of study in this paper is the DLCS, the proposed algorithm can be readily applied to the stability verification of LCS. In this context, we show the equivalence between the stability of a LCS and the DLCS, resulting from a time-stepping procedure applied to the LCS for all sufficiently small time steps.},
  archive      = {J_SIOPT},
  author       = {Arvind U. Raghunathan and Jeffrey T. Linderoth},
  doi          = {10.1137/20M1387377},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {419-444},
  shortjournal = {SIAM J. Optim.},
  title        = {Stability analysis of discrete-time linear complementarity systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Everything is possible: Constructing spectrahedra with prescribed facial dimensions. <em>SIOPT</em>, <em>35</em>(1), 400-418. (<a href='https://doi.org/10.1137/24M164344X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given any finite set of nonnegative integers, there exists a closed convex set whose facial dimension signature coincides with this set of integers, that is, the dimensions of its nonempty faces comprise exactly this set of integers. In this work, we show that such sets can be realized as solution sets of systems of finitely many convex quadratic inequalities, and hence are representable via second-order cone programming problems, and are, in particular, spectrahedral. It also follows that these sets are facially exposed, in contrast to earlier constructions. We obtain a lower bound on the minimum number of convex quadratic inequalities needed to represent a closed convex set with prescribed facial dimension signature and show that our bound is tight for some special cases. Finally, we relate the question of finding efficient representations with indecomposability of integer sequences and other topics and discuss a substantial number of open questions.},
  archive      = {J_SIOPT},
  author       = {Vera Roshchina and Levent Tunçel},
  doi          = {10.1137/24M164344X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {400-418},
  shortjournal = {SIAM J. Optim.},
  title        = {Everything is possible: Constructing spectrahedra with prescribed facial dimensions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved guarantees for optimal nash equilibrium seeking and bilevel variational inequalities. <em>SIOPT</em>, <em>35</em>(1), 369-399. (<a href='https://doi.org/10.1137/23M1589402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of hierarchical variational inequality (VI) problems that subsumes VI-constrained optimization and several other problem classes, including the optimal solution selection problem and the optimal Nash equilibrium (NE) seeking problem. Our main contribution is threefold. (i) We consider bilevel VIs with monotone and Lipschitz continuous mappings and devise a single-timescale iteratively regularized extragradient method, named IR-EG. We improve the existing iteration complexity results for addressing both bilevel VI and VI-constrained convex optimization problems. (ii) Under the strong monotonicity of the outer-level mapping, we develop a method named IR-EG and derive faster guarantees than those in (i). We also study the iteration complexity of this method under a constant regularization parameter. These results appear to be new for both bilevel VIs and VI-constrained optimization. (iii) To our knowledge, complexity guarantees for computing the optimal NE in nonconvex settings do not exist. Motivated by this lacuna, we consider VI-constrained nonconvex optimization problems and devise an inexactly projected gradient method, named IPR-EG, where the projection onto the unknown set of equilibria is performed using IR-EG with a prescribed termination criterion and an adaptive regularization parameter. We obtain new complexity guarantees in terms of a residual map and an infeasibility metric for computing a stationary point. We validate the theoretical findings using preliminary numerical experiments for computing the best and the worst NEs.},
  archive      = {J_SIOPT},
  author       = {Sepideh Samadi and Farzad Yousefian},
  doi          = {10.1137/23M1589402},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {369-399},
  shortjournal = {SIAM J. Optim.},
  title        = {Improved guarantees for optimal nash equilibrium seeking and bilevel variational inequalities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Splitting the conditional gradient algorithm. <em>SIOPT</em>, <em>35</em>(1), 347-368. (<a href='https://doi.org/10.1137/24M1638008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel generalization of the conditional gradient (CG/Frank–Wolfe) algorithm for minimizing a smooth function under an intersection of compact convex sets, using a first-order oracle for and linear minimization oracles (LMOs) for the individual sets. Although this computational framework presents many advantages, there are only a small number of algorithms which require one LMO evaluation per set per iteration; furthermore, these algorithms require to be convex. Our algorithm appears to be the first in this class which is proven to also converge in the nonconvex setting. Our approach combines a penalty method and a product-space relaxation. We show that one CG step is a sufficient subroutine for our penalty method to converge, and we provide several analytical results on the product-space relaxation’s properties and connections to other problems in optimization. We prove that our average Frank–Wolfe gap converges at a rate of —only a log factor worse than the vanilla CG algorithm with one set.},
  archive      = {J_SIOPT},
  author       = {Zev Woodstock and Sebastian Pokutta},
  doi          = {10.1137/24M1638008},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {347-368},
  shortjournal = {SIAM J. Optim.},
  title        = {Splitting the conditional gradient algorithm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A solution method for arbitrary polyhedral convex set optimization problems. <em>SIOPT</em>, <em>35</em>(1), 330-346. (<a href='https://doi.org/10.1137/23M1608227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide a solution method for the polyhedral convex set optimization problem, that is, the problem to minimize a set-valued mapping with polyhedral convex graph with respect to a set ordering relation which is generated by a polyhedral convex cone . The method is proven to be correct and finite without any further assumption to the problem.},
  archive      = {J_SIOPT},
  author       = {Andreas Löhne},
  doi          = {10.1137/23M1608227},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {330-346},
  shortjournal = {SIAM J. Optim.},
  title        = {A solution method for arbitrary polyhedral convex set optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tight error bounds for the sign-constrained stiefel manifold. <em>SIOPT</em>, <em>35</em>(1), 302-329. (<a href='https://doi.org/10.1137/24M1659030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The sign-constrained Stiefel manifold in is a segment of the Stiefel manifold with fixed signs (nonnegative or nonpositive) for some entries of the matrices. It includes the nonnegative Stiefel manifold as a special case. We present global and local error bounds that provide an inequality with easily computable residual functions and explicit coefficients to bound the distance from matrices in to the sign-constrained Stiefel manifold. Moreover, we show that the error bounds cannot be improved except for the multiplicative constants under some mild conditions, which explains why two square-root terms are necessary in the bounds when and why the -norm can be used in the bounds when or for the sign constraints and orthogonality, respectively. The error bounds are applied to derive exact penalty methods for minimizing a Lipschitz continuous function with orthogonality and sign constraints.},
  archive      = {J_SIOPT},
  author       = {Xiaojun Chen and Yifan He and Zaikun Zhang},
  doi          = {10.1137/24M1659030},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {302-329},
  shortjournal = {SIAM J. Optim.},
  title        = {Tight error bounds for the sign-constrained stiefel manifold},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analyses of Davis–Yin splitting via scaled relative graphs. <em>SIOPT</em>, <em>35</em>(1), 270-301. (<a href='https://doi.org/10.1137/23M1621320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Davis–Yin splitting (DYS) has found a wide range of applications in optimization, but its linear rates of convergence have not been studied extensively. The scaled relative graph (SRG) simplifies the convergence analysis of operator splitting methods by mapping the action of the operator to the complex plane, but the prior SRG theory did not fully apply to the DYS operator. In this work, we formalize an SRG theory for the DYS operator and use it to obtain tighter contraction factors.},
  archive      = {J_SIOPT},
  author       = {Jongmin Lee and Soheun Yi and Ernest K. Ryu},
  doi          = {10.1137/23M1621320},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {270-301},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analyses of Davis–Yin splitting via scaled relative graphs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sequential quadratic programming method with high-probability complexity bounds for nonlinear equality-constrained stochastic optimization. <em>SIOPT</em>, <em>35</em>(1), 240-269. (<a href='https://doi.org/10.1137/23M1549006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A step-search sequential quadratic programming method is proposed for solving nonlinear equality-constrained stochastic optimization problems. It is assumed that constraint function values and derivatives are available, but only stochastic approximations of the objective function and its associated derivatives can be computed via inexact probabilistic zeroth- and first-order oracles. Under reasonable assumptions, a high probability bound on the number of iterations that the algorithm requires to reach a first-order -stationary iterate is derived, where is lower bounded by a positive quantity dictated by the noise level of the inexact probabilistic zeroth- and first-order oracles. Numerical results on standard nonlinear optimization test problems illustrate the advantages and limitations of our proposed method.},
  archive      = {J_SIOPT},
  author       = {Albert S. Berahas and Miaolan Xie and Baoyu Zhou},
  doi          = {10.1137/23M1549006},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {240-269},
  shortjournal = {SIAM J. Optim.},
  title        = {A sequential quadratic programming method with high-probability complexity bounds for nonlinear equality-constrained stochastic optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the geometric convergence of byzantine-resilient distributed optimization algorithms. <em>SIOPT</em>, <em>35</em>(1), 210-239. (<a href='https://doi.org/10.1137/23M1573410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problem of designing distributed optimization algorithms that are resilient to Byzantine adversaries has received significant attention. For the Byzantine-resilient distributed optimization problem, the goal is to (approximately) minimize the average of the local cost functions held by the regular (nonadversarial) agents in the network. In this paper, we provide a general algorithmic framework for Byzantine-resilient distributed optimization which includes some state-of-the-art algorithms as special cases. We analyze the convergence of algorithms within the framework, and derive a geometric rate of convergence of all regular agents to a ball around the optimal solution (whose size we characterize). Furthermore, we show that approximate consensus can be achieved geometrically fast under some minimal conditions. Our analysis provides insights into the relationship among the convergence region, distance between regular agents’ values, step size, and properties of the agents’ functions for Byzantine-resilient distributed optimization.},
  archive      = {J_SIOPT},
  author       = {Kananart Kuwaranancharoen and Shreyas Sundaram},
  doi          = {10.1137/23M1573410},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {210-239},
  shortjournal = {SIAM J. Optim.},
  title        = {On the geometric convergence of byzantine-resilient distributed optimization algorithms},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated minimax algorithms flock together. <em>SIOPT</em>, <em>35</em>(1), 180-209. (<a href='https://doi.org/10.1137/22M1504597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Several new accelerated methods in minimax optimization and fixed-point iterations have recently been discovered, and, interestingly, they rely on a mechanism distinct from Nesterov’s momentum-based acceleration. In this work, we show that these accelerated algorithms exhibit what we call the merging path (MP) property; the trajectories of these algorithms merge quickly. Using this novel MP property, we establish point convergence of existing accelerated minimax algorithms and derive new state-of-the-art algorithms for the strongly-convex-strongly-concave setup and for the prox-grad setup.},
  archive      = {J_SIOPT},
  author       = {TaeHo Yoon and Ernest K. Ryu},
  doi          = {10.1137/22M1504597},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {180-209},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerated minimax algorithms flock together},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic optimization over proximally smooth sets. <em>SIOPT</em>, <em>35</em>(1), 157-179. (<a href='https://doi.org/10.1137/20M1320225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a class of stochastic algorithms for minimizing weakly convex functions over proximally smooth sets. As their main building blocks, the algorithms use simplified models of the objective function and the constraint set, along with a retraction operation to restore feasibility. All the proposed methods come equipped with a finite time efficiency guarantee in terms of a natural stationarity measure. We discuss consequences for nonsmooth optimization over smooth manifolds and over sets cut out by weakly convex inequalities.},
  archive      = {J_SIOPT},
  author       = {Damek Davis and Dmitriy Drusvyatskiy and Zhan Shi},
  doi          = {10.1137/20M1320225},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {157-179},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic optimization over proximally smooth sets},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Policy mirror descent inherently explores action space. <em>SIOPT</em>, <em>35</em>(1), 116-156. (<a href='https://doi.org/10.1137/23M1560215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Explicit exploration in the action space was assumed to be indispensable for online policy gradient methods to avoid a drastic degradation in sample complexity, for solving general reinforcement learning problems over finite state and action spaces. In this paper, we establish for the first time an sample complexity for online policy gradient methods without incorporating any exploration strategies. The essential development consists of two new on-policy evaluation operators and a novel analysis of the stochastic policy mirror descent method (SPMD) [G. Lan, Math. Program., 198 (2022), pp. 1059–1106]. SPMD with the first evaluation operator, called value-based estimation, tailors to the Kullback–Leibler divergence. Provided the Markov chains on the state space of generated policies are uniformly mixing with a nondiminishing minimal visitation measure, an sample complexity is obtained with a linear dependence on the size of the action space. SPMD with the second evaluation operator, namely truncated on-policy Monte Carlo (TOMC), attains an sample complexity, where mildly depends on the effective horizon and the size of the action space with properly chosen Bregman divergence (e.g., Tsallis divergence). SPMD with TOMC also exhibits stronger convergence properties in that it controls the optimality gap with high probability rather than in expectation. In contrast to explicit exploration, these new policy gradient methods can prevent repeatedly committing to potentially high-risk actions when searching for optimal policies.},
  archive      = {J_SIOPT},
  author       = {Yan Li and Guanghui Lan},
  doi          = {10.1137/23M1560215},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {116-156},
  shortjournal = {SIAM J. Optim.},
  title        = {Policy mirror descent inherently explores action space},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability properties for parametric linear programs under data ambiguities. <em>SIOPT</em>, <em>35</em>(1), 92-115. (<a href='https://doi.org/10.1137/23M1618156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study a new parametric robust linear problem (PRLP) whose data are allowed to be perturbed not only on the objective and constraint functions but also on the size of the uncertainty sets. Using a dual approach, we examine the stability and sensitivity properties of PRLP by looking at how the behaviors of its optimal value function and solution map change according to the change of the parameters. More precisely, we examine the closedness and lower and upper semicontinuity of the solution map and the lower and upper semicontinuity as well as Lipschitz property of the optimal value function of PRLP varying around a reference parameter. In this way, we obtain the nonemptiness and boundedness of the solution sets and a characterization for the Lipschitz continuity of the optimal value function for semi-infinite linear programs when fixing the corresponding index sets.},
  archive      = {J_SIOPT},
  author       = {Thai Doan Chuong and Cao Thanh Tinh},
  doi          = {10.1137/23M1618156},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {92-115},
  shortjournal = {SIAM J. Optim.},
  title        = {Stability properties for parametric linear programs under data ambiguities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kurdyka–Łojasiewicz exponent via hadamard parametrization. <em>SIOPT</em>, <em>35</em>(1), 62-91. (<a href='https://doi.org/10.1137/24M1636186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of -regularized optimization problems and the associated smooth “overparameterized” optimization problems built upon the Hadamard parametrization, or equivalently, the Hadamard difference parametrization (HDP). We characterize the set of second-order stationary points of the HDP-based model and show that they correspond to some stationary points of the corresponding -regularized model. More importantly, we show that the Kurdyka–Łojasiewicz (KL) exponent of the HDP-based model at a second-order stationary point can be inferred from that of the corresponding -regularized model under suitable assumptions. Our assumptions are general enough to cover a wide variety of loss functions commonly used in -regularized models, such as the least squares loss function and the logistic loss function. Since the KL exponents of many -regularized models are explicitly known in the literature, our results allow us to leverage these known exponents to deduce the KL exponents at second-order stationary points of the corresponding HDP-based models, which were previously unknown. Finally, we demonstrate how these explicit KL exponents at second-order stationary points can be applied to deducing the explicit local convergence rate of a standard gradient descent method for minimizing the HDP-based model.},
  archive      = {J_SIOPT},
  author       = {Wenqing Ouyang and Yuncheng Liu and Ting Kei Pong and Hao Wang},
  doi          = {10.1137/24M1636186},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {62-91},
  shortjournal = {SIAM J. Optim.},
  title        = {Kurdyka–Łojasiewicz exponent via hadamard parametrization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency of sample-based stationary points for infinite-dimensional stochastic optimization. <em>SIOPT</em>, <em>35</em>(1), 42-61. (<a href='https://doi.org/10.1137/23M1600608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider stochastic optimization problems with possibly nonsmooth integrands posed in infinite-dimensional decision spaces and approximate these stochastic programs via a sample-based approaches. We establish the asymptotic consistency of approximate Clarke stationary points of the sample-based approximations. Our framework is applied to risk-averse semilinear PDE-constrained optimization using the average value-at-risk and risk-neutral bilinear PDE-constrained optimization.},
  archive      = {J_SIOPT},
  author       = {Johannes Milz},
  doi          = {10.1137/23M1600608},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {42-61},
  shortjournal = {SIAM J. Optim.},
  title        = {Consistency of sample-based stationary points for infinite-dimensional stochastic optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence properties of proximal (Sub)gradient methods without convexity or smoothness of any of the functions. <em>SIOPT</em>, <em>35</em>(1), 28-41. (<a href='https://doi.org/10.1137/23M1592158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We establish convergence properties for a framework that includes a variety of proximal subgradient methods, where none of the involved functions needs to be convex or differentiable. The functions are assumed to be Clarke-regular. Our results cover the projected and conditional variants for the constrained case, the use of the inertial/momentum terms, and incremental methods when each of the functions is itself a sum, and the methods process the components in this sum separately.},
  archive      = {J_SIOPT},
  author       = {Mikhail V. Solodov},
  doi          = {10.1137/23M1592158},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {28-41},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence properties of proximal (Sub)gradient methods without convexity or smoothness of any of the functions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derivative-free approaches for chance-constrained problems with right-hand side uncertainty. <em>SIOPT</em>, <em>35</em>(1), 1-27. (<a href='https://doi.org/10.1137/23M1622635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work addresses (mixed-integer) joint chance-constrained optimization problems in which the only uncertain parameter corresponds to the right-hand side coefficients in an inequality system. It exploits one-dimensional marginals to construct upper and lower models for the underlying joint probability function, which need not be differentiable or satisfy generalized concavity properties. Based on these models, two optimization methods are proposed. Neither of them requires the probability function’s (sub)gradients and can thus be considered derivative-free methods. The first approach iteratively enriches an upper model for the probability function within an outer approximation algorithm that is shown to compute, under mild assumptions, an approximate global solution to the nonconvex chance-constrained problem. When the problem’s data is linear, the outer approximation algorithm requires solving (approximately) a mixed-integer linear programming problem per iteration. The second method works with a lower model and penalization techniques to efficiently compute points satisfying a new criticality condition. The approach, which handles only continuous variables, defines iterates as critical points of a nonlinear master program that can be handled with off-the-shelf nonlinear programming solvers. Numerical experiments on academic chance-constrained problems highlight the approach’s potential and limitations.},
  archive      = {J_SIOPT},
  author       = {W. de Oliveira},
  doi          = {10.1137/23M1622635},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1-27},
  shortjournal = {SIAM J. Optim.},
  title        = {Derivative-free approaches for chance-constrained problems with right-hand side uncertainty},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
