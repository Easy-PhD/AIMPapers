<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SUPERC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="superc">SUPERC - 798</h2>
<ul>
<li><details>
<summary>
(2025). Graph-based adversarial training for rumor detection on social media. <em>SUPERC</em>, <em>81</em>(16), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07639-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of social media, while it offers numerous conveniences, it also facilitates the rapid spread of rumors. In recent years, deep learning techniques have made significant strides in identifying the structural features of rumor propagation. However, many rumors now employ various disguise strategies to bypass detection models, rendering most existing approaches unable to accurately identify them. To address these challenges, this paper proposes a more robust rumor detection model from the perspective of graph adversarial training. We introduce Bidirectional Graph Adversarial Training, a rumor detection method built on adversarial training, designed to identify disguised rumors. Our method begins by developing a virtual adversarial feature generation module based on the original propagation structural features to identify the worst-case perturbations. By incorporating adversarial samples during the training process, adversarial training enhances the model’s ability to resist various attacks in real-world scenarios. Specifically, we focus on the influence of node connections to define neighbor perturbations, control the perturbation direction of node features on their neighboring nodes, and introduce adversarial regularizers to defend against the worst-case perturbations. Experimental results on three public datasets demonstrate that our proposed model significantly outperforms state-of-the-art methods, enhancing the robustness of rumor detection.},
  archive      = {J_SUPERC},
  author       = {Guo, Ying and Jin, Yangqi and Zhang, Xiongfei and Liu, Jie},
  doi          = {10.1007/s11227-025-07639-3},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Graph-based adversarial training for rumor detection on social media},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ephemeral kubernetes: Dynamically deleting and recreating clusters using warewulf. <em>SUPERC</em>, <em>81</em>(16), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07668-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of LLMs, GPU acceleration has become essential for both training and serving AI models. This requires HPC systems to be highly flexible with assigning multi-GPU nodes while also maintaining high security standards. Existing approaches involve utilizing nodes with batch and service schedulers, e.g., Slurm and Kubernetes, by dynamically moving nodes between the schedulers either through negotiation between the systems or via an external system. However, such a multi-use approach also increases the attack surface as more scheduling components operate with root permission. Moreover, it becomes increasingly difficult to recover from a security incident as attackers might have infected parts of either scheduling system. In this work, we present Ephemeral Kubernetes as a way to dynamically deploy and remove Kubernetes clusters in Warewulf managed environments such that nodes can be booted to be either part of a Slurm or Kubernetes cluster while being wiped at shutdown.},
  archive      = {J_SUPERC},
  author       = {Decker, Jonathan and Kunkel, Julian},
  doi          = {10.1007/s11227-025-07668-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Ephemeral kubernetes: Dynamically deleting and recreating clusters using warewulf},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel sea surface salinity prediction model: Combining secondary decomposition, optimized hybrid parallel neural network and error correction. <em>SUPERC</em>, <em>81</em>(16), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07828-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of sea surface salinity provides a scientific basis for environmental risk assessment, process design optimization and emergency management of industrial activities. To address the nonlinear and nonstationary characteristics of sea surface salinity, prediction model based on modified singular spectrum decomposition (MSSD), refined composite multivariate multiscale fuzzy entropy, complete ensemble empirical mode decomposition with adaptive noise optimized by catch fish optimization algorithm (CFOACEEMDAN), optimized hybrid parallel neural network based on improved frilled lizard optimization (IFLOHPNN) with good point set and adaptive inertia weight and error correction (EC) using bidirectional gated recurrent unit, named MSSD-CFOACEEMDAN-IFLOHPNN-EC, is proposed. The hybrid neural network used in this paper adopts a parallel architecture, and each branch processes the decomposed subsequence independently, which significantly shortens the network training and prediction time. Salinity data collected at two sites in the Gulf of Mexico are used as an example and compared with 12 other models. The proposed model is shown to have good prediction effect of sea surface salinity, among which RMSE, MAE, MAPE and R2 of Site1 reached 0.01903, 0.01451, 1.4620% and 0.99954, respectively, which are better than those of the other comparison models.},
  archive      = {J_SUPERC},
  author       = {Li, Guohui and Gao, Ying and Yang, Hong},
  doi          = {10.1007/s11227-025-07828-0},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Novel sea surface salinity prediction model: Combining secondary decomposition, optimized hybrid parallel neural network and error correction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Language identification based on multi-scale feature recursive fusion and adaptive loss. <em>SUPERC</em>, <em>81</em>(16), 1--2. (<a href='https://doi.org/10.1007/s11227-025-07881-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Li, Weiwei and Chen, Chen and Chen, Yong and Chen, Deyun},
  doi          = {10.1007/s11227-025-07881-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--2},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Language identification based on multi-scale feature recursive fusion and adaptive loss},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAXMI: A novel AI-based system for smart, energy-efficient, and secure video footage processing. <em>SUPERC</em>, <em>81</em>(16), 1--54. (<a href='https://doi.org/10.1007/s11227-025-07900-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents LAXMI, a secure and lightweight hybrid video analytics pipeline for motion detection and real-time object classification. The end objective is to design a system that can perform computationally efficient scene analysis in the edge but securely transmit full video data to the cloud for archival or additional processing. The pipeline aims to minimize processing delay, minimize bandwidth usage, and guard surveillance content with a combination of optimized machine learning and cryptographic methods. LAXMI integrates a temporal gradient-based motion detection (TGMD) algorithm at the edge, which precisely identifies motion segments within continuous video streams. Upon detection of motion, the system conducts YOLOv8 object detection for classification and annotation of related entities such as people, cars, animals, and other moving objects. One of the key novelties is employing a hybrid tokenization strategy where the video is encrypted with AES-GCM, and the encryption key is securely transported using RSA public-key cryptography. This ensures data confidentiality as well as secure edge-to-cloud communications. The edge server then generates a JWT-based token for authenticating the cloud upload. Unlike conventional IoT frameworks, LAXMI explicitly targets scalable surveillance workloads at city or enterprise level, where real-time analytics over distributed networks, parallel processing across heterogeneous edge nodes, and secure high-speed archival to the cloud require coordination similar to high-performance computing (HPC)/supercomputing environments. The design leverages parallel inference and distributed edge-cloud scheduling to meet ultra-low-latency and high-throughput demands. An 8-week duration performance test reveals that the edge-based motion detection subsystem achieved a 92.7% accuracy and F1-score of 96.2%, while the YOLOv8 classifier achieved 94.8% accuracy and F1-score of 94.4%. Further, the edge pipeline outperformed the cloud baseline across processing latency, energy expense, and bandwidth consumption constantly, thereby setting the effectiveness of the proposed LAXMI architecture in actual smart surveillance applications.},
  archive      = {J_SUPERC},
  author       = {Bhattacharya, Tathagata and Ponaganti, Srikant and Vardhan, Adithya Peddi and Venkatesan, Yaswanth Sai},
  doi          = {10.1007/s11227-025-07900-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--54},
  shortjournal = {J. Supercomput.},
  title        = {LAXMI: A novel AI-based system for smart, energy-efficient, and secure video footage processing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Financial empirical dynamic modeling: A parameter-free sufficient approach for price model. <em>SUPERC</em>, <em>81</em>(16), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07915-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a parameter-free, sufficient approach for financial price modeling, grounded in Empirical Dynamic Modeling (EDM) theory. Unlike conventional time series models that depend on restrictive parametric assumptions, EDM reconstructs system dynamics directly from data, capturing nonlinear, non-stationary, and chaotic behaviors inherent in financial markets. However, EDM’s reliance on large-scale state-space reconstruction, neighbor search algorithms, and iterative multi-scale decomposition imposes substantial computational demands. To address this, we develop a high-performance computing (HPC) framework that leverages parallel and distributed architectures to accelerate embedding, decomposition, and forecasting steps. The proposed framework not only scales efficiently to massive financial datasets but also supports real-time forecasting, a critical requirement in high-frequency trading and risk management where millisecond-level responsiveness is essential. Empirical evaluations across diverse financial assets demonstrate superior predictive accuracy, robustness, and computational scalability compared to ARMA, ARIMA, GRU, LSTM, and 2DSL models. By integrating supercomputing resources with EDM’s parameter-free methodology, this work establishes a computationally sufficient paradigm for financial forecasting that bridges dynamical systems theory and large-scale financial analytics.},
  archive      = {J_SUPERC},
  author       = {Azizi, S. Pourmohammad},
  doi          = {10.1007/s11227-025-07915-2},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Financial empirical dynamic modeling: A parameter-free sufficient approach for price model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). $$CrossShard\hbox {-}X$$: Three-phase commit protocol for cross-shard transactions. <em>SUPERC</em>, <em>81</em>(16), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07935-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharding enhances blockchain scalability and throughput but poses significant challenges for cross-shard transactions, often limiting parallel execution and degrading real-time performance. This paper presents a sharded blockchain system that employs account-based partitioning, co-locating frequently interacting accounts within the same shard to reduce cross-shard overhead. To further improve cross-shard transaction processing, we introduce an enhanced three-phase commit protocol that extends the traditional two-phase commit by integrating global hash signatures and a dual-pipeline mechanism. In this design, transaction hashes are aggregated into a global hash, while validator signatures collectively form an availability certificate. The commit phase is refined into two sub-stages, enabling two transaction batches to be processed concurrently within a single round of computation and communication. Furthermore, a cross-shard commit protocol leveraging aggregated signatures is incorporated to minimize communication overhead. These improvements align closely with high-performance distributed systems, where reducing synchronization costs and achieving scalable parallel execution are essential for supercomputing-grade applications. Extensive evaluations on a dataset of one million real Ethereum transactions, performed using the BlockEmulator simulation framework, demonstrate the effectiveness of our approach. Compared to conventional hash-based partitioning schemes (Monoxide), the proposed system reduces the cross-shard transaction ratio by approximately 40% and lowers transaction confirmation latency by up to 80%.},
  archive      = {J_SUPERC},
  author       = {Yang, Xiaohui and Huang, Jingchao},
  doi          = {10.1007/s11227-025-07935-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {$$CrossShard\hbox {-}X$$: Three-phase commit protocol for cross-shard transactions},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Star-YOLO: A lightweight detection algorithm for UAV landing markers. <em>SUPERC</em>, <em>81</em>(16), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07938-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex urban environments with spatial constraints, clutter, and electromagnetic interference, precise and reliable unmanned aerial vehicle landing suffers from positioning errors and communication disruptions, making vision-based landing essential. To address this challenge, we propose Star-YOLO, a lightweight landing-marker detector for UAV applications. The method replaces the backbone with StarNet, reducing parameters (− 62.9%) and FLOPs (− 65.9%); introduces SRCELAN (Split-RepConv Efficient Layer Aggregation Network) to improve multi-scale fusion and information propagation with minimal overhead; and employs LSAD (Light Softmax Adaptive-Weight Downsampling) to preserve fine details and boost small-object accuracy. On an AirSim-based visible-light dataset covering diverse urban scenes and illumination conditions, Star-YOLO achieves 96.2% mAP@0.5 (+ 1.6% over the baseline) and improves CSI from 0.869 to 0.898. The compact 3.00-MB model runs at 365.6 FPS on PC and, after TensorRT acceleration, reaches 95.1% mAP@0.5 at 33.6 FPS on NVIDIA Jetson Orin Nano, exceeding the typical 25–30 FPS threshold for real-time detection.},
  archive      = {J_SUPERC},
  author       = {Yu, Deyang and Qu, Ruokun and Li, Chenglong and Liu, Xijun},
  doi          = {10.1007/s11227-025-07938-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Star-YOLO: A lightweight detection algorithm for UAV landing markers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task offloading based on deep reinforcement learning in edge computing network. <em>SUPERC</em>, <em>81</em>(16), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07940-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet-of-things applications are growing rapidly, which imposes stringent requirements for real-time, compute-intensive processing on resource-constrained user equipment (UE). Mobile edge computing addresses this challenge by enabling computation at the network edge and leveraging cloud resources when edge capacity is insufficient. However, most existing task offloading strategies rely on static or instantaneous resource states, limiting their adaptability to highly dynamic environments with fluctuating workloads and heterogeneous resources. To overcome this limitation, this study proposes a predictive and adaptive decision framework for task offloading that integrates LSTM-based resource prediction with a DDQN-based offloading policy. Specifically, the proposed TODRL integrates prediction-based resource allocation using long short-term memory with collaborative UE–edge–cloud offloading. This predictive capability enables the system to anticipate resource availability and optimally schedule delay-sensitive and computation-intensive tasks. The problem is presented as a dynamic optimization objective that minimizes a weighted system cost, jointly considering latency, energy consumption, service cost, and task acceptance ratio. Extensive simulations demonstrate that TODRL consistently outperforms state-of-the-art baselines by achieving lower energy consumption, reduced task execution delay, and improved system utility, validating the effectiveness of coupling resource prediction with reinforcement learning for adaptive edge computing.},
  archive      = {J_SUPERC},
  author       = {Kumari, Shailja and Gupta, Divya},
  doi          = {10.1007/s11227-025-07940-1},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Task offloading based on deep reinforcement learning in edge computing network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deeploc: A CNN-LSTM framework for NLOS-aware localization in underwater sensor networks. <em>SUPERC</em>, <em>81</em>(16), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07942-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater wireless sensor networks (UWSNs) face significant challenges in accurate node localization due to Non-Line-of-Sight (NLOS) conditions caused by multipath propagation, signal attenuation, and environmental factors. In order to solve these issues, this paper proposes a hybrid deep learning framework which integrates CNN, and LSTM networks. This system is able to identify if it is in NLOS or Line of sight condition, it is capable of classifying the type of NLOS it is experiencing, and is able to correct localization errors, all in a single pipeline. The model outperforms existing methods, as shown by experimental results, achieving 92–95% of accuracy and 0.92 $$-$$ 0.95 of F1-score, while also being robust in low signal-to-noise ratio (SNR) scenarios (65–70% of accuracy on 0–5dB). It also achieves 8–10% better performance than the baseline in SNR levels on the mid-range, between 7.5 and 12.5 dB. The hybrid architecture is also more energy efficient, with 15–30% lower energy use without sacrificing real-time processing, with inferencing times around 15–20 ms. These findings show the flexibility of this framework in a dynamic underwater environment and its potential for being a solution for UWSN localization.},
  archive      = {J_SUPERC},
  author       = {Shamshad, Nadia and Wang, Lei and Sarwr, Danish and Mohsan, Syed Agha Hassnain},
  doi          = {10.1007/s11227-025-07942-z},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Deeploc: A CNN-LSTM framework for NLOS-aware localization in underwater sensor networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint scalable quantum convolutional neural network and reverse fidelity training for high-accurate recognition in unmanned aerial vehicle surveillance. <em>SUPERC</em>, <em>81</em>(16), 1--15. (<a href='https://doi.org/10.1007/s11227-025-07948-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have demonstrated considerable potential in surveillance tasks, primarily owing to their high mobility and adaptability. However, these vehicles are often constrained by the extensive number of parameters required in conventional neural networks, which poses significant challenges under wireless communication conditions. To address these limitations, quantum neural networks (QNNs) have emerged as a promising solution, demonstrating capabilities that classical neural networks are unable to fully realize. Specifically, quantum convolutional neural networks (QCNNs) have garnered significant attention due to their capacity to process high-dimensional vector inputs. However, the capabilities of QCNNs in feature extraction are currently constrained by the limitations of quantum computing. In response to these challenges, a scalable quantum convolutional neural network (sQCNN) is proposed, accompanied by a reverse fidelity-Train (RF-Train). This algorithm utilizes quantum fidelity to enhance the performance of the sQCNN. In the context of UAV surveillance systems, the sQCNN and RF-train framework offer a lightweight, high-performance approach that is specifically optimized for UAV applications, ensuring efficient operation under demanding conditions.},
  archive      = {J_SUPERC},
  author       = {Roh, Emily Jimin and Kim, Joongheon and Jung, Soyi and Park, Soohyun},
  doi          = {10.1007/s11227-025-07948-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--15},
  shortjournal = {J. Supercomput.},
  title        = {Joint scalable quantum convolutional neural network and reverse fidelity training for high-accurate recognition in unmanned aerial vehicle surveillance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crossrecsmart: A cross-network anchor-based representation learning for the recommendation of smart services. <em>SUPERC</em>, <em>81</em>(16), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07950-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern smart cities, user request handling has evolved beyond conventional software solutions and electronic services. Companies now leverage a diverse range of cutting-edge technologies, such as Artificial Intelligence, the Internet of Things (IoT), Edge/Fog computing, and Cloud computing, to deliver various smart services. These services cover domains such as smart healthcare, smart buildings, smart transportation, smart living, and smart administration. However, a significant challenge hindering the widespread adoption and effective deployment of these services is the limited awareness among citizens of their availability and features, including aspects like pricing models, security policies, and service-level agreements. This issue largely stems from the lack of centralized public repositories where companies can showcase their smart offerings. Consequently, citizens often rely on traditional Web search tools (e.g., search engines and social networks), which limits their ability to fully benefit from the advantages of smart services. In addition, users are often connected to multiple service providers, meaning that their related knowledge (e.g., profiles, service usage, and ratings) is distributed across multiple information sources. To bridge the gap between smart service providers and citizens, and to effectively utilize user and service information across multiple networks, we propose CrossRecSmart, a cross-network recommender system built upon a multiplex network of smart services. This system can be conceptualized as a large-scale, distributed, domain-specific marketplace for available smart services. Our approach integrates graph neural networks (GNNs) with cross-network representation learning to construct this multiplex network. The complex and distributed nature of this task is addressed through a cross-network learning model that facilitates collaboration among multiple smart service providers and enables the aggregation of their knowledge. This is achieved by interconnecting multiple networks through bridge nodes, also referred to as anchor entities. Furthermore, we introduce an algorithm for the cross-network recommendation of top-rated smart services. Comparative analyses with existing recommender systems designed for smart cities demonstrate the superiority of our proposed approach, owing to the concept of anchor links.},
  archive      = {J_SUPERC},
  author       = {Mezni, Haithem and Sellami, Mokhtar and Algarni, Abeer D. and Elmannai, Hela},
  doi          = {10.1007/s11227-025-07950-z},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Crossrecsmart: A cross-network anchor-based representation learning for the recommendation of smart services},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kepler-aSI.v2: A blended heuristic framework for comprehensive semantic table interpretation. <em>SUPERC</em>, <em>81</em>(16), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07951-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabular data, frequently encountered on the Web, represents information organized in a tabular format composed of rows and columns. This format is extensively employed across various web-based contexts and data storage frameworks. Furthermore, the inherent structure of tabular data encapsulates substantial semantic information, which encourages ongoing analysis and application. Therefore, the process of deriving significant insights from structured data through semantic approaches, including ontologies or Knowledge Graphs, is typically referred to as Semantic Table Interpretation (STI) or Semantic Table Annotation. In this article, we introduce Kepler-aSI.v2, a matching methodology designed to resolve potential semantic inconsistencies between tabular data and a Knowledge Graph. This task continues to be a formidable challenge for computational systems, necessitating additional effort for the integration of cognitive capabilities into matching algorithms. The principal aim of our approach is to devise a rapid and efficient method for the annotation of tabular data using attributes extracted from a specified Knowledge Graph. Our method integrates filtering mechanisms and text pre-processing strategies. The evaluation conducted according to the SemTab challenge has yielded promising and encouraging results.},
  archive      = {J_SUPERC},
  author       = {Baazouzi, Wiem and Kachroudi, Marouen and Faiz, Sami},
  doi          = {10.1007/s11227-025-07951-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {Kepler-aSI.v2: A blended heuristic framework for comprehensive semantic table interpretation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODEMixer: An approach for modeling non-stationary time series with learnable fragment library. <em>SUPERC</em>, <em>81</em>(16), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07955-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series analysis plays a critical role in applications such as weather forecasting, anomaly detection, and action recognition. However, modeling non-stationary time series remains a challenging task due to their complex, time-varying patterns. Motivated by these challenges, this paper presents a novel series decomposition framework that extracts periodic components through a learnable period matching mechanism and captures smooth trend variations using ordinary differential equation (ODE)-based neural networks. We introduce the ODEMixer model, which incorporates a fragment similarity calculation module to effectively capture multi-periodic signals. Extensive experiments conducted on the MIT-BIH polysomnographic database demonstrate that ODEMixer achieves superior performance in modeling complex non-stationary time series.},
  archive      = {J_SUPERC},
  author       = {Wei, Bin and Chen, Jiejie and Jiang, Ping and Xiao, Zhiwei},
  doi          = {10.1007/s11227-025-07955-8},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {ODEMixer: An approach for modeling non-stationary time series with learnable fragment library},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser weld spot detection based on MMG-YOLO. <em>SUPERC</em>, <em>81</em>(16), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07958-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser weld spot detection is vital in industrial manufacturing but faces challenges like multi-scale target recognition and imprecise bounding box localization. To address these issues, we propose the MMG-YOLO model, featuring a multi-scale attention fusion module (MSAFM) for better texture and scale recognition, and a ghost feature fusion module to enhance detection accuracy while reducing computational load. We also designed a novel regression loss function, MidInnerSIoU (MISIoU), to improve bounding box precision. For large-scale, high-resolution inspection on industrial production lines, MMG-YOLO can run in real time on GPUs and supports distributed scaling. It is suitable for large-scale inspection in actual production. Our enhanced model shows a 12.6% increase in accuracy, 5.7% improvement in recall, and 8.7% increase in F1 score. The mAP@50 increases by 5% and FPS increases 2.2, while parameters drop by 3.9M and GFLOPS decrease by 13.9.},
  archive      = {J_SUPERC},
  author       = {Feng, Jianxin and Zhao, Xinyu and Wang, Jiahao and Liu, Zhiguo and Ding, Yuanming},
  doi          = {10.1007/s11227-025-07958-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Laser weld spot detection based on MMG-YOLO},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cybersecurity situation assessment based on fuzzy cluster analysis and fuzzy comprehensive judgment decision-making. <em>SUPERC</em>, <em>81</em>(16), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07960-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the limitations of current cybersecurity situational awareness indicators—namely, their rigidity, restricted generalization, insufficient correlation analysis, and inability to adapt rapidly to emerging threats—we propose a holistic framework that fuses fuzzy clustering with fuzzy comprehensive evaluation. Feature attributes of diverse network attack types are first standardized via a “shift–range transformation” and a fuzzy similarity matrix is built using the “similarity coefficient dot product” method. This matrix is then converted into a fuzzy equivalence relation through transitive closure, enabling fuzzy clustering of the latent associations among attack features. Thresholds derived from the clustering results and expert knowledge define primary and secondary situational factor sets. A cybersecurity evaluation set is subsequently established to map secondary factors, while Analytic Hierarchy Process determines the weights of both levels. An average weighted operator synthesizes the fuzzy mapping and the weight matrix, accounting for all fuzzy interactions to produce a situational score. Because constructing large-scale fuzzy similarity matrices, iteratively solving transitive closures, and performing dynamic clustering on real-time data streams are inherently compute-intensive tasks whose complexity grows polynomially—or even exponentially—with the number of network nodes and feature dimensions, traditional single-node sequential processing becomes infeasible. To deliver global situational awareness for national network infrastructures or large-scale cloud platforms and to enable rapid responses to sophisticated attacks such as APTs, massive parallel computing resources from supercomputers (HPC) are indispensable. Experimental results demonstrate that the framework attains high accuracy, credibility, real-time performance, and excellent scalability, fulfilling the supercomputing field’s demand for efficient, large-scale, real-time computation. Experimental results show that the proposed method achieves a situational value of 0.4693 on the UNSW-NB15 dataset and effectively reflects the network situation within the risk set defined in this study.},
  archive      = {J_SUPERC},
  author       = {Liu, Kesheng and Li, Binyong},
  doi          = {10.1007/s11227-025-07960-x},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Cybersecurity situation assessment based on fuzzy cluster analysis and fuzzy comprehensive judgment decision-making},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSF-net: A robust multi-scale feature fusion network for vehicle detection in challenging traffic environments. <em>SUPERC</em>, <em>81</em>(16), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07961-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection is a critical component in intelligent transportation systems (ITS), where its accuracy and real-time performance hold significant importance for the traffic management. However, complex factors in traffic environments, such as small objects, occlusion interference, and varying weather, pose significant challenges. This paper proposes the Reparameterized Multi-Scale Feature Fusion Network (RSF-Net), an improved model that leverages GPU-parallel computing capabilities, which are essential for high-performance computing (HPC) applications in real-time vehicle detection. The model incorporates several key innovations: a Reparameterized Multi-Scale Feature Fusion (RepHMS) module based on reparameterization principles to enhance feature extraction, a Boundary-Aware Feature Pyramid Network (BA-FPN) that reduces boundary information loss through bidirectional cross-scale connections and channel attention mechanisms, a Parallel Spatial Pyramid Pooling Fast (PSPPF) module to expand the receptive field, and a dedicated small object detection head. On the UA-DETRAC dataset, RSF-Net improves mean Average Precision (mAP@0.5) by 6.4% over YOLOv8s and reaches 186.8 FPS. On the BDD100K dataset, it improves mAP@0.5 by 3.9%. These results indicate the model’s effectiveness for vehicle detection in complex urban traffic scenarios.},
  archive      = {J_SUPERC},
  author       = {Dai, Lisi and Tang, Hao and Zhang, Yonghui and Xu, Bo and Bhatti, Uzair Aslam and Gao, Jinxiong},
  doi          = {10.1007/s11227-025-07961-w},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {RSF-net: A robust multi-scale feature fusion network for vehicle detection in challenging traffic environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure communication in distributed system using quantum key distribution. <em>SUPERC</em>, <em>81</em>(16), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07964-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of distributed systems has brought up a critical demand for robust security frameworks capable of resisting advanced cyber threats. Quantum key Distribution (QKD), facilitated by the laws of quantum mechanics is an emerging technology that promises theoretically unbreakable encryption. This paper proposes an advanced security architecture integrating QKD with distributed system communication protocols in order to ensure end-to-end data confidentiality and integrity. Therefore, this study discusses the issues of practical key management, scalability, and interoperability in a heterogeneous setting. Recent findings in the areas of quantum-resistant algorithms and hybrid classical quantum cryptographic protocols have been leveraged to increase the resistance against quantum-capable adversaries. The simulation results showed substantial gains in latency, fault tolerance, and security metrics. Therefore, this work is future-proof, as it shows the way ahead for secure communication in imminent quantum advancements in computing.},
  archive      = {J_SUPERC},
  author       = {Parihar, Ashish Singh},
  doi          = {10.1007/s11227-025-07964-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A secure communication in distributed system using quantum key distribution},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis of movie reviews based on quantum convolutional neural networks. <em>SUPERC</em>, <em>81</em>(16), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07965-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis has gained significant attention in the research domain of language understanding. It offers valuable insights into public opinion, customer feedback, and user experiences, but the quantum machine learning (QML) approaches used in it are still lacked and in the theoretical stages. In this paper, we focus on evaluating one of the QML approaches, which is QCNNs in movie reviews classification; this model represents a quantum neural network design inspired by Convolutional Neural Network (CNN) and exclusively employing parameterized quantum circuits. However, classical text data need to be converted into quantum states; for this, we use three quantum encoding techniques, which are angle encoding, amplitude encoding, and instantaneous quantum polynomial encoding. We investigate how different QCNN models distinguished by the number of qubits used and the structures of parameterized quantum circuits can improve the performance of sentiment analysis classification across both artificial and real datasets of movie reviews.},
  archive      = {J_SUPERC},
  author       = {Ouamane, Nour El Houda and Belhadef, Hacene and Haddad, Mohammed},
  doi          = {10.1007/s11227-025-07965-6},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Sentiment analysis of movie reviews based on quantum convolutional neural networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantum computing approach to model uncertainty in end-of-life prediction. <em>SUPERC</em>, <em>81</em>(16), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07970-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An approach is proposed to model uncertainty in a process by combining classical and quantum computing. The model of the process differs from a traditional stochastic process due to the prospect of using quantum superposition and entanglement for quantifying the uncertainty present. The model of the stochastic noise is developed based on multidimensional Hadamard gates which can be also implemented in terms of quantum Fourier transform (QFT). The process of degradation of quality of air filters used for environmental control in transportation systems is modeled and the application of the developed model is demonstrated with real-world data for transportation systems. The versatility of the combined classical–quantum uncertainty model is testified by several numerical experiments conducted under different conditions and prediction horizons. Additional models of uncertainty are developed with the introduction of rotational gates in the quantum circuits. End of life of air filters is predicted using the proposed classical–quantum analysis. The results show that the proposed approach is capable of predicting the uncertainty in the future behavior of the air filters and of capturing the inherent fluctuations within the process. The advantage in time complexity compared to classical computation is also evaluated and discussed.},
  archive      = {J_SUPERC},
  author       = {Basu, Biswajit and Staino, Andrea},
  doi          = {10.1007/s11227-025-07970-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {A quantum computing approach to model uncertainty in end-of-life prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fast and accurate simulation platform for advanced ARM- and RISC-V-based HPC systems. <em>SUPERC</em>, <em>81</em>(16), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07972-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new design paradigms of HPC systems utilizing newly developed CPUs (i.e., ARM and RISC-V) trigger an urgent need for simulators that can handle in an integrated manner both the processing and the network components of a system-under-design (SuD). The presented simulation framework is the first known open-source approach that efficiently integrates well-established simulation subsystems in a single framework with a single notion of time. The framework operates in a fully distributed manner, transparent to the user enabling accurate simulations of both ARM- and RISC-V-based HPC systems interconnected with different networks (e.g., InfiniBand and BXI). Our framework can work in two different modes; in the main one the processing systems and the interconnection networks are simulated at a cycle-accurate manner. The second option can be used if the designer wants to focus on the design space exploration of the architectures/topologies/technologies of the interconnection network, in which case the data collected when running the simulator on the main node, are utilized so as to model and simulate extremely fast different intercommunication infrastructures. The presented framework has been evaluated when simulating widely used benchmarks (HPCG & LAMMPS) on both ARM & RISC-V CPUs; the results demonstrate that our approach has up to 6% performance error in the reported SuD aspects, while the simulation times increase at a very slow pace, when the size of the HPC SuD gets bigger, due to the fully distributed nature of the proposed toolset.},
  archive      = {J_SUPERC},
  author       = {Tampouratzis, Nikolaos and Papaefstathiou, Ioannis and Gomez-Lopez, Gabriel and Sánchez De la Rosa, Miguel and Escudero-Sahuquillo, Jesus and Garcia, Pedro Javier},
  doi          = {10.1007/s11227-025-07972-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Distributed fast and accurate simulation platform for advanced ARM- and RISC-V-based HPC systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation of classical coupled Jaulent–Miodek system by RBF-PSM through the application of seventh-order nine-stage Runge–Kutta method. <em>SUPERC</em>, <em>81</em>(16), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07973-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study conducts a numerical investigation of the classical coupled Jaulent–Miodek (JM) system. The coupled JM system incorporates an energy dependent Schrödinger potential and has applications in fluid dynamics, condensed matter physics, optics, and various engineering systems. We present a geometric meshless approach for the nonlinear coupled JM system in this paper. Pseudo-spectral method is recognized for their high accuracy; however, they face constraints regarding geometric adaptability. The conjunction of radial basis function (RBF) with the pseudo-spectral method effectively addresses this limitation. The Radial basis function Pseudo-spectral method (RBF-PSM) was employed to approximate the coupled JM system by converting it into a set of ordinary differential equations (ODEs). The solution to this system of ODEs has been obtained using the (7,9) Runge–Kutta (RK) method, which is characterized by its seventh order and nine stages. The physical characteristics of these solutions are illustrated through three-dimensional and two-dimensional figures, which aid in understanding the physical phenomena associated with the dynamic models that emerge in mathematical physics. A comparative analysis has also been performed between the solutions derived from the proposed method, the exact solution, and several recently published methods in the literature. Numerical experiments demonstrate that the suggested method is both effective and precise for the JM coupled system.},
  archive      = {J_SUPERC},
  author       = {Jena, Saumya Ranjan and Sahu, Itishree},
  doi          = {10.1007/s11227-025-07973-6},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Approximation of classical coupled Jaulent–Miodek system by RBF-PSM through the application of seventh-order nine-stage Runge–Kutta method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable health state assessment method for aerospace equipment based on belief rule base with fuzzy credibility factor. <em>SUPERC</em>, <em>81</em>(16), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07975-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the aerospace sector, real-time, accurate, and interpretable health status assessments enable decision makers to make timely and accurate decisions. Belief rule base (BRB) is widely used in aerospace equipment health assessment due to its excellent qualitative and quantitative information processing capabilities. However, differences in the expert knowledge reliability can lead to differences in the extent to which parameters need to be optimized and over-optimization of parameters reduces interpretability. Therefore, an aerospace equipment health assessment method based on interpretable belief rule base with fuzzy credibility factor (IBRB-c) is proposed. First, a fuzzy credibility factor characterizing the expert knowledge accuracy is proposed to address the problem of not being able to quantify the extent to which parameters need to be optimized. Second, four new strategies for implementing model-interpretable optimization are proposed to address the problem of over-optimization of parameters. Finally, the IBRB-c is validated via lithium-ion battery and liquid launch vehicle experiments.},
  archive      = {J_SUPERC},
  author       = {Zhang, Zongjun and Wan, Haifeng and Li, Hongyu and Zhu, Hailong and He, Wei},
  doi          = {10.1007/s11227-025-07975-4},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {An interpretable health state assessment method for aerospace equipment based on belief rule base with fuzzy credibility factor},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale adaptive small and overlapping target detection in underwater images. <em>SUPERC</em>, <em>81</em>(16), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07976-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater target detection is crucial for marine monitoring, ecological assessment, and intelligent operations. However, there are significant challenges for existing detection algorithms, such as light attenuation, color distortion, background noise, and target scale variations. To address these issues, an underwater multi-scale adaptive detection network with cross-stage pyramid extraction, adaptive multi-scale fusion, and multi-granularity perception (CDM-YOLOv8n) is proposed. The network consists of three core components: the Efficient Cross-Stage Bottleneck with a Pyramid Structure Feature Extraction (Conv2CSP), the Multi-Scale Adaptive Information Enhancement and Fusion (DownCSRA), and the Multi-Granularity Information Awareness (MGIA). Firstly, Conv2CSP enhances feature extraction to resolve overlapping object boundaries in dense underwater scenes. Secondly, DownCSRA improves feature representation under complex backgrounds by adaptively integrating multi-scale information. Finally, MGIA employs dedicated fine-grained perception branches to better capture target features. Experiments on the URPC2020 and RUOD datasets show that CDM-YOLOv8n improves mAP@0.5 by 2.9% and 2.3% and mAP@0.5:0.95 by 2.1% and 2.3%. Evaluation on Small and Overlapping Objects highlights substantial improvements, with mAP@0.5 improving by 2.6% on URPC2020 and 3.5% on RUOD for overlapping objects and by 2.2% on URPC2020 and 3.0% on RUOD for small objects. Compared with state-of-the-art underwater methods, CDM-YOLOv8n achieves over 30 FPS on GPU, ensuring accurate real-time detection in compute-intensive underwater scenes and demonstrating scalability to HPC platforms.},
  archive      = {J_SUPERC},
  author       = {Luo, Lisha and Gao, Qiang and Liu, Qi and Li, Xuan and Yu, Xiao},
  doi          = {10.1007/s11227-025-07976-3},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Multi-scale adaptive small and overlapping target detection in underwater images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient image encryption using a new model of chaotic neural network. <em>SUPERC</em>, <em>81</em>(16), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07977-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel and scalable cryptographic framework for image encryption based on Chaotic Neural Networks (ChNNs). The key contribution lies in a hybrid architecture that combines a Chaotic Neural Network Long Short-Term Memory (ChNN-LSTM) model with a Chaotic Neural Network Multi-Layer Perceptron (ChNN-MLP). The ChNN-LSTM, trained on the Lorenz chaotic system, generates trainable chaotic features, which are then used to train the ChNN-MLP for predicting new chaotic sequences. These sequences, which lack explicit mathematical formulas, enable the generation of encryption keys and S-Boxes. To investigate the security and performance of the proposed cryptosystem, comprehensive statistical analyses—including entropy, NPCR, UACI, and correlation tests were conducted. The results demonstrate strong security, high randomness, and robustness against known cryptographic attacks. This makes the proposed method not only efficient but also practical for real-world applications such as secure communications, medical image protection, and biometric data encryption.},
  archive      = {J_SUPERC},
  author       = {Kadir, Amina and Azzaz, Mohamad Salah and Kaibou, Redouane and Alloun, Youcef},
  doi          = {10.1007/s11227-025-07977-2},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Efficient image encryption using a new model of chaotic neural network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dung beetle optimization algorithm with multi-strategy fusion for multi-UAV path planning. <em>SUPERC</em>, <em>81</em>(16), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07978-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planning of unmanned aerial vehicle (UAV) paths represents a crucial aspect of UAV technology. The primary goal is to ascertain the optimum non-collision route from the point of departure to the point of arrival, while satisfying various requirements including minimizing path length, addressing environmental complexity, and avoiding obstacles. However, traditional optimization methods and heuristic algorithms often encounter challenges in complex environments, such as the tendency to become trapped in local optimum and insufficient obstacle avoidance capabilities. To address these issues, a UAV path planning model that comprehensively considers factors including path length, collision between UAVs, threat levels, flight altitude, and path smoothness is constructed. A dung beetle optimization with multi-strategy fusion (DBOMF) algorithm is proposed. In DBOMF, position update strategy for rolling dung beetles based on the golden ratio coefficient combined with the sine function balances global exploration with local exploitation capabilities. Then, breeding dung beetles and small dung beetles position update mechanism based on spiral searching is presented, allowing individuals to investigate the solution space more extensively along spiral paths, thereby enhancing the algorithm's searching efficiency and robustness. What’s more, an age elimination mechanism is employed to enhance population diversity. Finally, a progressive scaling adjustment strategy is implemented to dynamically balance random perturbations and optimum solution perturbations, improving the algorithm's accuracy and rate of convergence. Experimental results across various algorithms in different scenarios demonstrate that the DBOMF algorithm is capable of planning paths of a shorter and more uniform length, while exhibiting stronger obstacle avoidance capabilities and global optimum performance in complex environment.},
  archive      = {J_SUPERC},
  author       = {Zong, Xinlu and Hao, Jiaxin and Liu, Fucai},
  doi          = {10.1007/s11227-025-07978-1},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Dung beetle optimization algorithm with multi-strategy fusion for multi-UAV path planning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale bidirectional spatial-temporal gated recurrent unit network for multisensor fault diagnosis under nonstationary conditions. <em>SUPERC</em>, <em>81</em>(16), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07979-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate fault diagnosis of rotating machinery is essential for ensuring reliability and safety in modern industrial systems. However, multisensor vibration signals typically exhibit strong spatiotemporal dependencies and nonstationary behavior, which limit the effectiveness of existing deep learning approaches. In particular, most prior methods process spatial and temporal features sequentially, leading to information loss and reduced robustness under time-varying operating conditions. To address these challenges, we propose a Multiscale Bidirectional Spatial-Temporal Gated Recurrent Unit (MB-STGRU) network for multisensor fault diagnosis under nonstationary conditions. The model introduces a spatial-temporal GRU cell that embeds lightweight spatial attention into temporal recurrence, enabling joint learning of inter-sensor correlations and bidirectional temporal dependencies. In addition, a multiscale convolution and adaptive fusion module is designed to capture fault signatures across both short-term and long-term horizons, enhancing robustness to complex operating variations. We evaluate MB-STGRU on two public benchmarks from Southeast University and Paderborn University, where it achieves accuracies of 99.17% and 99.04% on SU1 and SU2, and 98.82% and 98.79% on PU1 and PU2, respectively, outperforming strong baselines such as EGCN by up to 1.4%. All experiments were conducted on an NVIDIA Tesla T4 GPU using PyTorch 2.0.1 and CUDA 11.8, underscoring the importance of GPU-accelerated parallel computation for real-time and scalable industrial fault diagnosis.},
  archive      = {J_SUPERC},
  author       = {Wu, Zhangjun and Lai, Yuming and Guo, Yaguang and Chen, Mengyao},
  doi          = {10.1007/s11227-025-07979-0},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Multiscale bidirectional spatial-temporal gated recurrent unit network for multisensor fault diagnosis under nonstationary conditions},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Firing patterns of a multifunctional neural circuit with memristive membrane. <em>SUPERC</em>, <em>81</em>(16), 1--16. (<a href='https://doi.org/10.1007/s11227-025-07980-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The functionality of nonlinear circuits can be significantly enhanced by integrating specialized electrical elements, enabling them to emulate the firing behaviors of biological neurons through parameter modulation or external stimuli. In this study, we develop a multifunctional neural circuit by incorporating a photocell and a thermistor into a magnetic flux-controlled memristor (MFCM)-based circuit coupled with dual capacitors. The photocell and thermistor serve as sensors for detecting external light and temperature signals, respectively. MFCM describes the flexible organizational structure between cell membranes and two capacitors exprent the inner and outer membranes of the cell membranes. We derive the mathematical model and energy equations of the system, and validate the circuit’s neuronal dynamics through numerical simulations. Furthermore, this versatile neural circuit provides a scalable platform for studying collective behaviors in functional neuron networks, and offering potential applications in neuromorphic computing, adaptive sensing, and bio-inspired robotics.},
  archive      = {J_SUPERC},
  author       = {Yu, Zhenhua and Cui, Hongwei and Song, Xinlin and Yang, Feifei},
  doi          = {10.1007/s11227-025-07980-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {Firing patterns of a multifunctional neural circuit with memristive membrane},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCBNet: Positional crossing and broad features network for indoor scene semantic segmentation. <em>SUPERC</em>, <em>81</em>(16), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07982-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To understand the semantic segmentation task of complex indoor scenes more accurately, due to the information difference between RGB and depth modalities and the difficulty of effectively fusing RGB and depth image information, and to address the above problems, we propose a new RGB-D cross-modal feature semantic segmentation network (PCBNet) based on positional crossing and broad features. The network firstly extracts the positional correlation information between different modalities adaptively by the positional cross-attention regulation module (PCARM), so as to effectively align the RGB modalities with their complementary modalities. Secondly, the broad feature fusion module (BFFM) is proposed to further enhance and fuse the aligned features to mine long-distance contextual information to capture and integrate cross-modal feature information more comprehensively. Finally, the final segmentation prediction results are obtained by sending both low-level and high-level features together to the decoder for multi-scale information fusion. Test results on two public datasets, NYU Depth V2 (NYUDV2) and SUN RGB-D, show that our network has a good segmentation performance. Among them, the mean intersection and merger ratio (mIoU) can reach 52.6% 55.0% and 47.5% 50.1%, respectively.},
  archive      = {J_SUPERC},
  author       = {Hou, Huifang and Wenwen, Zhang and Zhang, Zihao and Wentao, Sun and Yang, Yale and Gang, Liu and Haipeng, Han and Tianyuan, Liu and Xiaofeng, Li},
  doi          = {10.1007/s11227-025-07982-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {PCBNet: Positional crossing and broad features network for indoor scene semantic segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FER-HA: A hybrid attention model for facial emotion recognition. <em>SUPERC</em>, <em>81</em>(16), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07983-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) is a fundamental task in affective computing, enabling machines to understand and respond to human emotions in domains such as mental health assessment, human–robot interaction, and intelligent tutoring systems. This study presents FER-HA, a hybrid attention-based model that integrates high-level visual features extracted from EfficientNet-B3 with geometric descriptors derived from 68 facial landmarks. An adaptive attention mechanism dynamically weights the multimodal representations to emphasize emotion-relevant information and mitigate challenges such as subtle expression variations and partial occlusions. Evaluated on the FER-2013 benchmark, FER-HA achieves a test accuracy of 72.32%, averaged over three independent runs, representing a 4.2% improvement over the baseline EfficientNet-B3. Notably, the model shows substantial gains for minority emotion classes such as disgust (F1 = 0.73) and fear (F1 = 0.53). With only 12.1 million parameters, the proposed model achieves a strong balance between accuracy and computational efficiency, making it suitable for real-time and resource-constrained systems. These results highlight the effectiveness of attention-guided multimodal fusion for scalable and efficient emotion recognition in supercomputing environments.},
  archive      = {J_SUPERC},
  author       = {Nemati, Reza and Shirini, Kimia and Gharehveran, Sina Samadi},
  doi          = {10.1007/s11227-025-07983-4},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {FER-HA: A hybrid attention model for facial emotion recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGDSAC: A scalable self-governing DSAC-based learning framework for on-chain sharding and off-chain cloud databases. <em>SUPERC</em>, <em>81</em>(16), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07883-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Query optimization (QO) in distributed relational database management system (RDBMS) faces enduring challenges, such as high latency, computational overhead, and poor scalability exacerbated by cross-shard (CS) communication demands. Existing QO approaches often rely on on-chain mechanisms that require consensus among all relevant shards, limiting scalability and efficiency due to the overuse of cross-shard transactions (CSTs). This study introduces SGDSAC, a scalable self-governor learning framework based on distributional soft actor-critic (DSAC) that optimizes query execution plans (QEPs) in the blockchain-augmented distributed databases. Its core innovations include (1) a dynamic relational scoring mechanism for CST minimization and (2) a dual policy-value deep reinforcement learning (DRL) optimizer balancing QEP efficiency with exploratory plan generation. The framework incorporates an Algorand-inspired verifiable random function (VRF) and a decentralized service committee for distributed ledger management. Evaluations were examined on PostgreSQL using JOB, IMDB, and TPC-H benchmarks. JOB assesses performance under complex join operations; IMDB provides a real-world dataset to examine practical applicability, and TPC-H, with varying scale factors, evaluates scalability and workload handling. The experiments demonstrate SGDSAC’s superiority, achieving 25–50% lower latency, 12–60% cost reduction, 20–50% higher throughput, 4–8% higher speedup, and 8–37% Q-error improvements over state-of-the-art baselines.},
  archive      = {J_SUPERC},
  author       = {Khosravi, M. and Erfani, S. H. and Deypir, M.},
  doi          = {10.1007/s11227-025-07883-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {SGDSAC: A scalable self-governing DSAC-based learning framework for on-chain sharding and off-chain cloud databases},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slicechain: A blockchain-based multi-domain resource orchestration in core network slicing. <em>SUPERC</em>, <em>81</em>(16), 1--73. (<a href='https://doi.org/10.1007/s11227-025-07917-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G introduces network slicing to deliver service-specific virtual networks on shared infrastructure. In multi-domain settings, efficient coordination is essential. However, existing approaches often overlook core saturation handling, lack secure, auditable inter-domain negotiations, and use opaque provider selection, risking suboptimal allocation and SLA violations. We present SliceChain, a distributed blockchain architecture for secure inter-provider resource sharing in 5G core slicing. SliceChain implements a Secure Resource Allocation Smart Contract (SRA-SC) that runs sealed-bid auctions over Fabric private channels and uses NLP-derived prioritization to score bids under 3GPP/ITU KPIs. In NS-3/Fabric co-simulation across diverse topologies and loads, SliceChain reduces latency by 22% for uRLLC and 19% for mMTC compared to DBNS, while increasing throughput and reliability. It also outperforms NSBchain, NetChain, BEAT, and TRADE-5G in latency, acceptance ratio, fairness, and resource utilization. These results show that SliceChain enables trustworthy, SLA-compliant cross-domain replacement with measurable performance gains.},
  archive      = {J_SUPERC},
  author       = {Mehdikhani Saatlou, Rouzbeh and Asgharian Sardroud, Asghar and Sadr Faridpour, Farshid and Yousefi, Saleh},
  doi          = {10.1007/s11227-025-07917-0},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--73},
  shortjournal = {J. Supercomput.},
  title        = {Slicechain: A blockchain-based multi-domain resource orchestration in core network slicing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMFTrack: An occlusion-aware and species-specific real-time tracking model for marine multi-fish. <em>SUPERC</em>, <em>81</em>(16), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07927-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine fish tracking is critical for sustainable fishery management; however, this task remains challenging due to visual similarities among conspecific fish, nonlinear motion patterns, and frequent occlusions. To address these challenges, we propose Marine Multi-Fish Tracking (MMFTrack), an efficient tracking model tailored for marine multi-fish scenarios, incorporating four key innovations: (1) a Fish-Xception-SPA appearance feature extractor that leverages depthwise separable convolutions and spatial attention mechanisms to enhance discriminative capability; (2) robust nonlinear motion modeling using an unscented Kalman filter (UKF); (3) a dynamic occlusion update strategy that adaptively adjusts the fusion weights between motion prediction and appearance observation based on the duration of occlusion; and (4) a category-gated association mechanism to prevent cross-species identity switches. Comprehensive evaluations on a proprietary South China Sea fish dataset demonstrate that MMFTrack achieves performance gains over the baseline StrongSORT model in HOTA (+2.8), MOTA (+0.7), and IDF1 (+7.9) while maintaining real-time performance at 83.3 FPS. Furthermore, rigorous generalization experiments on public benchmarks confirm the robustness of MMFTrack, reducing identity switches by 88.9% (4 vs. 36) on the FISHTRAC dataset and by 31.7% (1,618 vs. 2,369) on the SEAMAPD21 dataset. This study provides an efficient and robust solution for marine fish tracking, enabling deployment on marine robotic platforms for population abundance estimation and establishing a technical foundation for data-driven fishery governance.},
  archive      = {J_SUPERC},
  author       = {Li, Jiaxin and Li, Hualing and Huo, Jiaxin and Zhang, Yonglai},
  doi          = {10.1007/s11227-025-07927-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {MMFTrack: An occlusion-aware and species-specific real-time tracking model for marine multi-fish},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FT-YOLO: A UAV-oriented small-object detection algorithm based on feature enhancement and task synchronization. <em>SUPERC</em>, <em>81</em>(16), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07947-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) imagery plays a vital role across numerous applications. However, small-object detection performance often remains unsatisfactory due to low spatial resolution, large-scale variations, and complex backgrounds. To address the above issues, this paper proposes FT-YOLO, an algorithm designed for small-object detection in UAV imagery. First, we construct a feature extraction unit named C3K2-PF, which integrates the poly kernel inception block with the feature enhancement module to enhance fine-grained and directional features, improving the ability to represent small objects. Second, we incorporate the attention scale fusion strategy into the neck, enabling adaptive fusion of multi-level features. In addition, we designed a task-synchronized dynamic head, which employs a task decomposition mechanism to separate and optimize classification and regression tasks synchronously. This approach avoids conflicts and enhances detection accuracy. Finally, the Wise-IoU loss function is adopted to optimize bounding box regression and accelerate model convergence. Experimental results show that FT-YOLO achieves a mean average precision (mAP) of 37.8% and a real-time detection speed of 97.1 frames per second on the VisDrone2019 dataset. Compared to the baseline model YOLOv11, it improves mAP50 and mAP50–95 by 5.9% and 3.6%, respectively. Cross-dataset evaluation further demonstrates the model’s robustness and its ability to generalize to diverse scenarios.},
  archive      = {J_SUPERC},
  author       = {Jin, Bing and Lu, Zhimin and He, Lesheng and Yu, Pengfei},
  doi          = {10.1007/s11227-025-07947-8},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {FT-YOLO: A UAV-oriented small-object detection algorithm based on feature enhancement and task synchronization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian neural network study for virtual machine migration within cloud environment. <em>SUPERC</em>, <em>81</em>(16), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07974-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has generated a huge amount of data that puts enormous pressure on internet infrastructure. Companies are therefore struggling to find solutions to alleviate this pressure and solve the data problem. The concept of virtual machine (VM) migration and datacenter architecture for the cloud have a significant impact on latency and energy costs. Optimizing VM migration and dynamic resource allocation using advanced technical tools, such as Bayesian neural networks (BNNs), has therefore become a crucial issue for the cloud industry. This work focuses on using the dynamic Bayesian neural network (DBNN) approach to stabilize physical machine (PM) utilization to reduce energy consumption and latency. The novel MVMM modeling approach for VM migration presents statistical modeling and analysis via a DBNN study to determine where and when a specific virtual machine migrates, this is achieved by taking into account probabilistic dependencies between datacenter parameters. In order to evaluate the suggested approach, we integrated the MVMM scheduler into the GreenCloud simulator, while considering fundamental datacenter characteristics, such as scheduling mechanism, network architecture, connection, load, and inter-VM communication. Performance results demonstrate that the MVMM approach saves up to 35% energy compared to other scheduling algorithms.},
  archive      = {J_SUPERC},
  author       = {Kortas, Nawel and Youssef, Habib},
  doi          = {10.1007/s11227-025-07974-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {A bayesian neural network study for virtual machine migration within cloud environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAMA-DETR: A lightweight attention and multi-kernel feature fusion detection model for UAV images. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07985-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to small object sizes, dense distributions, and complex backgrounds in UAV imagery, existing object detection algorithms face significant challenges. This study introduces PAMA-DETR, an advanced object detection algorithm based on RT-DETR, designed for high precision and robustness. The designed efficient and lightweight Partial Attention Gate Network (PAGNet) improves extraction capabilities for small targets in complicated scenarios. PAGNet adopts an innovative single-head self-attention mechanism combined with convolutional gated linear unit (CGLU) to augment the capacity to distinguish small targets from the background. Recognizing the difficulty of fusing multi-scale features within dense scenes, we designed the multi-kernel adaptive feature fusion (MAFI) module. MAFI employs a multi-branch parallel architecture integrating diverse convolutional variants to establish multi-scale receptive fields, accommodating objects of various sizes. Additionally, we optimize the loss function by replacing GIoU with Inner-SIoU and further improve localization accuracy by constructing auxiliary bounding boxes. Experimental on VisDrone2019 and UAVDT datasets show that PAMA-DETR achieves superior performance compared to RT-DETR, with improvements of $$3.2\%$$ and $$3.9\%$$ in $$\text {mAP}_{50}$$ , and enhancements of $$2.4\%$$ and $$3.0\%$$ in $$\text {mAP}_{50:95}$$ , respectively. Notably, it decreases parameters by $$25.8\%$$ while achieving a $$97 \,\text {FPS}$$ inference speed, exhibiting an effective trade-off between computational efficiency and detection accuracy.},
  archive      = {J_SUPERC},
  author       = {Wei, Siwei and Li, Wei and Wei, Feifei and Wang, Chunzhi},
  doi          = {10.1007/s11227-025-07985-2},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {PAMA-DETR: A lightweight attention and multi-kernel feature fusion detection model for UAV images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stronger interaction brings better performance: Fine-grained alignment between different modalities for MNER. <em>SUPERC</em>, <em>81</em>(16), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07987-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal named entity recognition (MNER) aims to enhance entity representations and boost recognition performance by leveraging visual knowledge from images. However, previous methods mainly faced two limitations: insufficient fine-grained alignment between text and image regions, and difficulty in filtering irrelevant visual information. To address these issues, we propose fine-grained alignment (FGA) between different modalities for MNER. Firstly, FGA extracts visual objects and calculates accurate fine-grained correlations with textual entities. Secondly, we introduce a contrastive learning strategy to integrate relevant visual knowledge, thereby mitigating noise from irrelevant image regions. Finally, we propose a dynamic weight optimization mechanism to adaptively enhance or filter multi-modal information based on its relevance. Experimental results on three benchmark datasets show that our method achieves competitive performance compared to existing methods, validating the benefits of precise and adaptive multi-modal information fusion.},
  archive      = {J_SUPERC},
  author       = {You, Xindong and Jian, Jiang and Wang, Tao and Lv, Xueqiang},
  doi          = {10.1007/s11227-025-07987-0},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Stronger interaction brings better performance: Fine-grained alignment between different modalities for MNER},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Color image encryption scheme based on 2D chaotic mapping and circular shifting. <em>SUPERC</em>, <em>81</em>(16), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07992-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a color image encryption algorithm based on a two-dimensional chaotic map to enhance the security and attack resistance of image encryption. Traditional low-dimensional chaotic systems suffer from problems such as simple chaotic behavior and insufficient randomness. To address these issues, a 2D chaotic map (2D-CSLCM) is constructed by combining the logistic map and cubic map, which enhances the randomness and security of the image encryption process. Based on this chaotic map, a color image encryption algorithm (CSLCM-IE) is proposed. The algorithm employs circular shifting, row-column diffusion, and cross-plane scrambling and diffusion to effectively conceal image information and improve the security of the algorithm. Experimental results demonstrate that the proposed algorithm exhibits significant advantages in key sensitivity and resistance to attacks. In addition, compared with existing algorithms, CSLCM-IE requires less computation time, indicating that the algorithm possesses strong computational performance.},
  archive      = {J_SUPERC},
  author       = {Hu, Jie and Zhang, Jindong and Ye, Yuxin and Jia, Xiaoyan and Ma, Mingzhuo},
  doi          = {10.1007/s11227-025-07992-3},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Color image encryption scheme based on 2D chaotic mapping and circular shifting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational analysis of wollastonite graph structure via machine learning techniques. <em>SUPERC</em>, <em>81</em>(16), 1--16. (<a href='https://doi.org/10.1007/s11227-025-07998-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wollastonite is a mineral named after English chemist W. H. Wollaston, which has applications in tiles, ceramics, polymers, plastic, rubber industry, paints, coatings, metallurgy, as construction materials in cement and insulation boards, and other uses. In this article, we study the abstract structure of Wollastonite from a combinatorial point of view, discuss its properties, and find its topological indices and the associated graph energy. We carry machine learning analysis of topological indices with the properties of Wollastonite graph by using the regression technique. The observation is that for higher order regression, an exact coefficient of determination is achieved; however, the third-order regression is practically more fit with the dataset.},
  archive      = {J_SUPERC},
  author       = {Rather, Bilal Ahmad},
  doi          = {10.1007/s11227-025-07998-x},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {Computational analysis of wollastonite graph structure via machine learning techniques},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRF-YOLO: Small object detection for UAV and remote sensing images. <em>SUPERC</em>, <em>81</em>(16), 1--24. (<a href='https://doi.org/10.1007/s11227-025-08001-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant progress has been made in object detection within the field of computer vision, due to factors such as cluttered backgrounds, object overlaps, varying target scales, and arithmetic limitations, it is difficult for existing object detection algorithms to achieve ideal results in small object detection. Therefore, this paper proposes an enhanced small object detection method, MRF-yolo, which makes a series of improvements based on the YOLOv8 as the basic model. First, the multi-level re-parameter fusion module MRF is designed to effectively fuse cross-scale feature information. Second, the PPA attention mechanism is introduced in the backbone network instead of the traditional convolution module to extract local detail features and alleviate the feature dilution problem. Finally, using Wise-IoU v3 as the regression loss function aims to improve the localization accuracy and accelerate the convergence speed. To verify the effectiveness of the proposed algorithm, this paper uses the publicly available datasets Visdrone2019 and AI-TOD for evaluation. The mAP0.5 of MRF-YOLO on Visdrone2019 increases from 38.5 to 45.1%. On AI-TOD, the mAP0.5 increases from 40.2 to 49.1%. The significant improvement in detection accuracy demonstrates the effectiveness and generalization ability of the proposed algorithm.},
  archive      = {J_SUPERC},
  author       = {Wang, Yuying and Yang, Wenlu},
  doi          = {10.1007/s11227-025-08001-3},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {MRF-YOLO: Small object detection for UAV and remote sensing images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User location prediction using a multi-layered learning model with weighted feature context transition matrix attention mechanism. <em>SUPERC</em>, <em>81</em>(16), 1--22. (<a href='https://doi.org/10.1007/s11227-025-08002-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of the geolocation of users for various applications, including social networking, public health, safety, and marketing. Researchers have presented several approaches using diverse data sources such as textual data, social connections, and context. However, some challenges exist due to the large and diverse nature of data, which may result in lower prediction performance. Therefore, motivated by this, the paper presented a multi-layered attention-based learning model for location prediction, termed the spatio-temporal-friendship feature transition matrix attention model (STFFTMAM). This model is designed to effectively capture and integrate temporal, semantic, spatial, and social interaction features. For generating attention-weighted features, transition matrices are created using temporal, semantic, spatial, and friendship features to enhance the efficacy of location prediction. For the generation of these features, trajectory and friendship data are used that can identify users’ location patterns. To implement these, the entire model is divided into four layers: data aggregation layer (DAL), feature extraction transition matrix generation layer (FETMGL), weighted feature matrix generation layer (WFMGL), and learning layers (LL). DAL extracts the trajectory information and friendship information of users and pre-processes them. FETMGL extracts temporal, semantic, spatial, and friendship features and extracts transition matrices. WFMGL generates the weighted feature vector. The attention mechanism dynamically prioritizes features based on their relevance for accurate location forecasting. The LL layer used the bidirectional long short-term memory (BiLSTM) networks for more precise learning. The analysis of results was performed on the Foursquare dataset. The analysis of the proposed model’s results was compared with three baseline models. The proposed model achieved an accuracy of approximately 99% execution time of approx. 0.03 s. As compared to state-of-the-art models such as graph convolutional networks (GCNNs) and genetic programming (GP), the proposed model has achieved approximately the same performance. About 3% of improvement in prediction performance while maintaining low execution time (≈0.03 s). To support city-wide inference at high data rates, the STFFTMAM is engineered to benefit from HPC environments. Tasks such as distributed transition matrix computation, parallel graph embedding, and GPU-accelerated BiLSTM learning make STFFTMAM highly suitable for real-time deployment.},
  archive      = {J_SUPERC},
  author       = {Arora, Madhur and Agrawal, Sanjay and Patel, Ravindra},
  doi          = {10.1007/s11227-025-08002-2},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {User location prediction using a multi-layered learning model with weighted feature context transition matrix attention mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-performance intrusion detection using hybrid BiLSTM–TCN model with adaptive sine–cosine algorithm for hyperparameter optimization. <em>SUPERC</em>, <em>81</em>(16), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07911-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing sophistication of cyber-attacks, robust and adaptive network intrusion detection systems (NIDS) are essential for ensuring cybersecurity. Conventional NIDS models often struggle with high false positive rates and limited real-time detection capabilities, necessitating advanced deep learning solutions. This study presents an optimized network intrusion detection framework leveraging a hybrid BiLSTM–temporal convolutional network (BiLSTM–TCN) model, optimized with a sine–cosine algorithm with adaptive learning (SCA–AL) for hyperparameter tuning. The proposed framework consists of four key stages: (1) Feature extraction using principal component analysis and statistical feature engineering to enhance data representation, (2) feature selection via least absolute shrinkage and selection operator (LASSO) to eliminate redundant attributes, (3) classification using a bidirectional long short-term memory (BiLSTM) network coupled with temporal convolutional networks, which effectively captures both long-range dependencies and local temporal patterns in network traffic data, and (4) hyperparameter optimization using SCA–AL, which dynamically adjusts search parameters to improve convergence efficiency and reduce computational overhead. Experimental evaluation of CICIDS-2017 and TON-IoT datasets demonstrates that the BiLSTM–TCN model achieves an accuracy of 99.89%, outperforming traditional CNN–LSTM architectures. Performance assessment based on F1-score, precision, recall, and detection rate highlight the model’s effectiveness in cyber-attack mitigation. The results validate the framework’s potential to provide a scalable, real-time, and high-accuracy intrusion detection system for modern cybersecurity challenges.},
  archive      = {J_SUPERC},
  author       = {Alsuwat, Emad and Alsuwat, Hatim},
  doi          = {10.1007/s11227-025-07911-6},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {High-performance intrusion detection using hybrid BiLSTM–TCN model with adaptive sine–cosine algorithm for hyperparameter optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Providing a multi-step algorithm based on biometric information and hybrid encryption for secure data storage in cloud computing. <em>SUPERC</em>, <em>81</em>(16), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07956-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing offers scalability and flexibility but still suffers from critical security and privacy challenges. To address these issues, we propose a hybrid cryptographic scheme that integrates DES, RSA, and Blowfish, enhanced with genetic-algorithm-based sub-key generation and biometric-derived keys for user-specific confidentiality. In addition, a neural-network-based steganography technique is applied to conceal keys within image edges, providing an additional layer of protection. Experimental results show improved efficiency (encryption 0.2797 s, decryption 0.2630 s) and strong robustness against statistical and differential attacks (NPCR ~ 99.6%, UACI ~ 30–35%), while maintaining high image quality (PSNR). Overall, the proposed model combines multi-stage cryptography with intelligent steganography to enable secure and efficient data transmission in cloud environments.},
  archive      = {J_SUPERC},
  author       = {AL-Musawi, MohammedAltaqi Jasim Hasan and Navabifar, Farhad and majidi, Fariba and HAMMOOD MZEDAWEE, HAYDER KADHIM},
  doi          = {10.1007/s11227-025-07956-7},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Providing a multi-step algorithm based on biometric information and hybrid encryption for secure data storage in cloud computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel methodology for makeup invariant face recognition based on directional gradient and local derivative descriptors (DGLDD-FR). <em>SUPERC</em>, <em>81</em>(16), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07990-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Makeup Invariant Face Recognition is a global problem from the perspective of security and recognition. It has various applications like criminal identification, driving license or passport verification, etc. Makeup variation significantly alter the appearance of the face by affecting the texture, shape, contrast of the mouth and eye regions. This causes the inability of traditional face recognition methods to consistently identify individuals. The deep learning methods have improved performance; however, these are computationally intensive and require large annotated datasets. Therefore, to address the above problems, the objective of the paper is to propose a novel methodology DGLDD-FR which handles makeup variation using a local derivative descriptor and four directional gradient images. Initially, the image is preprocessed, followed by convolving four directional masks over the grayscale image to generate the gradient images. Subsequently, the local derivative descriptor is applied to the regions of the gradient images, allowing for the extraction of discriminative features. Finally, a Support Vector Machine is employed to recognize the face images of different individuals. The effectiveness and robustness of the proposed methodology have been evaluated on standard datasets YMU and VMU, and achieved accuracy 91.25% and 91.50% respectively. The proposed methodology outperforms existing discriminative methods (weber faces + LGBP by 0.61%, Gradient faces + PCA by 6.75%) and deep learning approaches (FGGNet by 1.21%) on YMU dataset and outperforms discriminative methods (LGBP by 9.30%, LBP by 13.20%, HOG by 17.90%) and deep learning methods (FGGNet by 3.02%, LSTM by 5.50%) on VMU dataset.},
  archive      = {J_SUPERC},
  author       = {Tripathi, Rajesh Kumar and Agrawal, Subhash Chand and Sharma, Kanhaiya and Nayyar, Anand},
  doi          = {10.1007/s11227-025-07990-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {A novel methodology for makeup invariant face recognition based on directional gradient and local derivative descriptors (DGLDD-FR)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-vehicle tracking in highway roadside surveillance videos via spatial–temporal fusion network with adaptive decay memory. <em>SUPERC</em>, <em>81</em>(16), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07991-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents spatial–temporal fusion network with adaptive decay memory for multi-vehicle tracking in highway scenarios (STFN-ADM-MTHS), a spatial–temporal fusion network with adaptive decay memory for robust multi-vehicle tracking in highway surveillance scenarios. Addressing challenges posed by camera vibrations, and occlusions, our framework includes four parts. Firstly, a last frame newborn module incorporating detection query self-attention to enhance detection-track coordination through temporal context; secondly, repulsion loss for improved occlusion handling via bounding box repulsion constraints; thirdly, spatial-guided cross-temporal feature aggregation (SCFA) using inter-frame interpolation and attention mechanisms to learn vibration-induced motion patterns; and lastly, adaptive decay memory (ADM) that dynamically adjusts memory retention based on motion stability, prioritizing recent observations during stable periods while relying on historical data during occlusions. We contribute the MTHS-SEU dataset containing 21,558 highway surveillance images with diverse environmental challenges. Comprehensive evaluations across MTHS-SEU, UA-DETRAC, and KITTI benchmarks demonstrate superior performance, achieving 72.197% HOTA on our dataset. Ablation studies confirm individual module effectiveness, with SCFA and ADM particularly effective for vibration compensation and occlusion handling, respectively. Given the high-dimensional spatiotemporal features and the need for long-sequence trajectory modeling under vibration and occlusion, our framework leverages GPU-accelerated parallel processing to sustain real-time inference. This capability is critical for meeting the safety-critical response needs of intelligent transportation systems. The framework maintains real-time capability at 10.5 FPS, showing significant improvements over state-of-the-art trackers in association metrics while balancing detection accuracy through joint query decoding optimization. The results show that the STFN-ADM-MTHS model effectively addresses the inter-frame trajectory displacement caused by camera vibrations.},
  archive      = {J_SUPERC},
  author       = {Li, Xuan and Zhao, Chihang and Xie, Xingpeng and Ma, Xinyi and Deng, Wenhao},
  doi          = {10.1007/s11227-025-07991-4},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Multi-vehicle tracking in highway roadside surveillance videos via spatial–temporal fusion network with adaptive decay memory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autofusion: An adaptive multi-positional encoding fusion framework for graph transformers. <em>SUPERC</em>, <em>81</em>(16), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07994-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph transformers (GTs) exhibit significant potential in graph representation learning (GRL), yet their performance is critically dependent on the effective encoding of graph topological structures. Existing methods employing a single positional encoding (PE) offer limited perspectives, while fixed PE combinations lack the necessary flexibility. To address these challenges, this work introduces AutoFusion, an adaptive framework for the fusion and selection of PEs. AutoFusion integrates a diverse set of heterogeneous PEs, derived from spectral methods, diffusion kernels, relative distances, and substructure patterns, to provide rich structural insights. Importantly, it incorporates a dual-level adaptive selection mechanism. During an efficient warmup phase on a data subset early in model training, AutoFusion utilizes learnable gates to concurrently optimize both the importance weights of different PE types and the selection weights for various fusion strategies. Upon completion of this warmup phase, the optimal PE subset and fusion strategy are fixed for subsequent, efficient model training. This automated mechanism transforms the computationally intensive architectural search for an optimal structural information scheme into an efficient optimization task. It thereby obviates the need for laborious manual tuning that would otherwise require high-performance computing environments, while ensuring the model leverages the most pertinent combination of structural information in a data-driven manner. We conduct extensive evaluations across multiple benchmarks, encompassing node classification, graph classification and graph regression tasks. Across a range of tasks including node classification, graph classification, and graph regression, AutoFusion-GT significantly outperforms strong baselines that employ single PEs or fixed fusion strategies. Ablation studies further corroborate the necessity of multi-PE fusion and underscore the effectiveness of AutoFusion’s dual selection mechanism and efficient warmup strategy.},
  archive      = {J_SUPERC},
  author       = {Yu, Tianming and Guan, Liyu and Zhang, Qiliang and Hu, Zongwei},
  doi          = {10.1007/s11227-025-07994-1},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Autofusion: An adaptive multi-positional encoding fusion framework for graph transformers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leuk-XAI-EDL: Explainable ensemble deep learning model for leukemia classification. <em>SUPERC</em>, <em>81</em>(16), 1--40. (<a href='https://doi.org/10.1007/s11227-025-08000-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia is among the leading causes of death globally, and early detection is critical. Current manual diagnostic methods, reliant on expert examination, are time-consuming and costly. They are also error-prone, particularly with less experienced practitioners. This study contributes to addressing these challenges by presenting an automated approach to detect leukemia using microscopic blood images. The method combines image processing and deep learning (DL)-based ensemble techniques to enhance classification accuracy. While ensemble of DL models can render accuracy, they require significant computational resources that necessitate supercomputing for low latency realizations. This study addresses these challenges by presenting a scalable and explainable ensemble of deep learning framework, favorable for the high-performance computing environments. The method’s reliance on supercomputing is driven by the need to train and evaluate ensemble of robust DL models in parallel, a task that is computationally prohibitive on standard systems due to extensive floating-point operations and memory requirements. First the performance of ten DL baseline models is evaluated. Onward, ensembles of the three best performing models (VGG16, VGG19, and DenseNet121) are designed respectively using max voting, averaging, and stacking. A rigorous performance evaluation on the ALL-IDB dataset confirms that the stacking-based ensemble with a support vector machine meta-learner outperforms the state-of-the-art counterparts by achieving an accuracy of 99.70% and a F1 score of 99.69%. It is demonstrated that leveraging supercomputing capabilities is crucial for managing the parallel workflows and high computational load of ensemble models, enabling the development of accurate, reliable, and clinically viable automated diagnostic tools that can operate at the scale required by contemporary healthcare systems. The interpretability of the findings is enhanced using gradient-weighted class activation mapping and Shapley additive eXplanations techniques.},
  archive      = {J_SUPERC},
  author       = {Syed, Saad Ahmed and Nisar, Humaira and Lee, Yu Jen and Mian Qaisar, Saeed and Hum, Yan Chai and Jaffari, Rabeea},
  doi          = {10.1007/s11227-025-08000-4},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Leuk-XAI-EDL: Explainable ensemble deep learning model for leukemia classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Hybrid event-triggered network-based synchronization of MSRDNNs with additive mode-dependent time-varying delays. <em>SUPERC</em>, <em>81</em>(16), 1. (<a href='https://doi.org/10.1007/s11227-025-07984-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Zhang, Weiyuan and Li, Junmin and Zhang, Rui and Xing, Keyi},
  doi          = {10.1007/s11227-025-07984-3},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Hybrid event-triggered network-based synchronization of MSRDNNs with additive mode-dependent time-varying delays},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WA-YOLO: A forest fire smoke detection method based on wavelet convolution and SimAM. <em>SUPERC</em>, <em>81</em>(16), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07997-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve accuracy and generalization in early forest fire smoke detection, this paper proposes a novel Wavelet-Attention YOLO (WA-YOLO) scheme based on wavelet convolution and the SimAM attention mechanism. The model integrates wavelet convolution to enhance multi-scale extraction of high- and low-frequency smoke features, and incorporates SimAM to enhance attention on smoke regions for precise localization. A Temporal Directional Spatial Enhancement (TDSE) structure is designed to optimize feature fusion and information flow, while a Dual-Branch Initialization Optimization (DBIO) strategy improves detection head initialization, accelerating convergence and reducing false positives. Experimental results on the both PFE-v8 and try123-v4 datasets show that the proposed WA-YOLO can improve precision by 3.6% and mAP@50% by 1.4% on try123-v4, and achieve 96.5% precision and 86.7% mAP@50% on PFE-v8, demonstrating strong generalization ability and practical value for early forest fire warning. GitHub: https://github.com/zel4539/WA-YOLO},
  archive      = {J_SUPERC},
  author       = {Chen, Xin and Zhu, Enliang and Zhu, Yaolin and Fu, Yan and Han, Kai and Liu, Bing},
  doi          = {10.1007/s11227-025-07997-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {WA-YOLO: A forest fire smoke detection method based on wavelet convolution and SimAM},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAI-YOLO: An underwater target detection algorithm based on enhanced feature representation and adaptive receptive field. <em>SUPERC</em>, <em>81</em>(16), 1--26. (<a href='https://doi.org/10.1007/s11227-025-08006-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater target detection is pivotal for marine resource exploration, environmental monitoring, and robotic applications. However, challenges such as low contrast, complex background interference, dense small targets, and multi-scale variations often lead to false or missed detections. To address these issues, this study proposes GAI-YOLO, an improved underwater object detection algorithm based on YOLO11n. First, a Global Edge Information Transfer Module (GEIT) is embedded into the backbone network. This module employs a Multi-Scale Edge Information Generator (MS-EIG) and an Edge Information Fusion Module (EIF) to efficiently propagate edge-enhanced features across the network, thereby strengthening feature representation and overall detection performance. Second, the Adaptive Receptive Field Enhancement (ARFE) module integrates dilated residual and re-parameterization techniques to dynamically adjust receptive fields, improving multi-scale target detection performance. Finally, Inner-WIoU is introduced as the loss function, which further improves small object localization accuracy and accelerates model convergence. Experiments on the DUO dataset demonstrate that GAI-YOLO achieves mAP@0.5, mAP@0.5:0.95, precision, and recall values of 86.0, 67.4, 87.5, and 76.8%, respectively. These results represent improvements of 1.6, 1.5, 1.9, and 0.6% over the baseline YOLO11n. Its generalization and robustness are further validated on the RUOD dataset, demonstrating the effectiveness of the proposed method for underwater detection tasks.},
  archive      = {J_SUPERC},
  author       = {Guo, Yongjie and Zhao, Xuefeng and Zhong, Zhaoman and Zhong, Xiaomin},
  doi          = {10.1007/s11227-025-08006-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {GAI-YOLO: An underwater target detection algorithm based on enhanced feature representation and adaptive receptive field},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-platform execution engine for the quantum intermediate representation. <em>SUPERC</em>, <em>81</em>(16), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07969-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid languages like the quantum intermediate representation (QIR) are essential for programming systems that mix quantum and conventional computing models, while execution of these programs is often deferred to a system-specific implementation. Here, we develop the QIR Execution Engine (QIR-EE) for parsing, interpreting, and executing QIR across multiple hardware platforms. QIR-EE uses LLVM to execute hybrid instructions specifying quantum programs and, by design, presents extension points that support customized runtime and hardware environments. We demonstrate an implementation that uses the XACC quantum hardware-accelerator library to dispatch prototypical quantum programs on different commercial quantum platforms and numerical simulators, and we validate execution of QIR-EE on IonQ, Quantinuum, and IBM hardware. Our results highlight the efficiency of hybrid executable architectures for handling mixed instructions, managing mixed data, and integrating with quantum computing frameworks to realize cross-platform execution.},
  archive      = {J_SUPERC},
  author       = {Wong, Elaine and Leyton-Ortega, Vicente and Claudino, Daniel and Johnson, Seth R. and Adams, Austin J. and Afrose, Sharmin and Gowrishankar, Meenambika and Cabrera, Anthony and Humble, Travis S.},
  doi          = {10.1007/s11227-025-07969-2},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {A cross-platform execution engine for the quantum intermediate representation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CDMM: Conditional diffusion model with mamba for low-light underwater image enhancement. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07981-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater photography is frequently characterized by low contrast, blurred edge details, and color distortions, primarily due to inadequate lighting. These factors impede the acquisition and analysis of underwater imagery using computer vision techniques. In the domain of improving visibility in underwater images taken under dim lighting, existing studies usually result in the introduction of artifacts, the loss of edge details, and an increase in noise. This research introduces a novel approach grounded in a diffusion model intended to optimize the quality of underwater imagery taken in dim conditions, utilizing low-light images and Gaussian noise as inputs to produce enhanced outputs. To enhance the denoising process within the diffusion model, a Time-aware Convolutional Mamba Block (TCM-Block) has been integrated as the denoising component, thus elevating the quality of the resultant images. Furthermore, the diffusion process is guided by the original image to preserve edge details and enhance visual perception. The experimental results indicate that our approach surpasses ten alternative methods in six metrics ranks second in the seventh, and demonstrates strong performance across a variety of low-light images, suggesting the potential advantages of our approach. This study not only provides an effective technical solution for enhancing low-light underwater images but also presents a novel perspective on image processing in such environments, facilitated by the application of the diffusion model and the Mamba block, with the iterative sampling process well-suited for acceleration on high-performance computing platforms.},
  archive      = {J_SUPERC},
  author       = {Zheng, Jianhua and Lu, Junde and Zhao, Ruolin and Fu, Yusha and Liu, Jinfang and Luo, Zhaoxi and Li, Xiaomin},
  doi          = {10.1007/s11227-025-07981-6},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {CDMM: Conditional diffusion model with mamba for low-light underwater image enhancement},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel I/O analysis in distributed deep learning applications on high-performance computing. <em>SUPERC</em>, <em>81</em>(16), 1--56. (<a href='https://doi.org/10.1007/s11227-025-07986-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed deep learning (DDL) applications generate heavy input/output (I/O) workloads that can create bottlenecks in high-performance computing (HPC) systems. Their optimal I/O configuration depends on factors such as access patterns, storage hardware, dataset size, and execution scale. This study proposes a systematic methodology for characterizing and optimizing I/O behavior in DDL applications, represented through the deep learning I/O benchmark (DLIO), and validated with the real DeepGalaxy application. We evaluate access modes, file formats, and Lustre file system configurations, demonstrating that stripe counts optimized for the access pattern and application scale can reduce I/O and execution times, achieving up to 18 GiB/s of bandwidth and a 5X increase in IOPS. HDF5 provides balanced performance, while TFRecord stands out in bandwidth-intensive scenarios. Shared access minimizes contention and improves scalability in multi-node executions. The results are consolidated into configuration guidelines that offer practical recommendations for practitioners to tune DDL applications for efficient execution in HPC environments.},
  archive      = {J_SUPERC},
  author       = {Parraga, Edixon and Leon, Betzabeth and Mendez, Sandra and Rexachs, Dolores and Luque, Emilio},
  doi          = {10.1007/s11227-025-07986-1},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--56},
  shortjournal = {J. Supercomput.},
  title        = {Parallel I/O analysis in distributed deep learning applications on high-performance computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAGShare: A DAG-based personal file sharing framework with off-chain IPFS and access control. <em>SUPERC</em>, <em>81</em>(16), 1--30. (<a href='https://doi.org/10.1007/s11227-025-08011-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many approaches have been proposed to share data in a decentralized manner using blockchain, which solves many security and data management issues but has some limitations, such as transaction fees, mining time, power consumption, etc. The alternative to a traditional blockchain is using IOTA, a directed acyclic graph (DAG) based system, but this also has the limitation of on-chain storage. To address these challenges we propose DAGShare, a DAG-based system with off-chain storage on an interplanetary file system (IPFS), a content-based addressable system. The DAGShare combines the IOTA network and IPFS to provide a secure and scalable personal file sharing system in which members can create new groups and join other groups. The system inherits blockchain features and resolves its limitations. The system also provides an access control mechanism to grant system access rights by using IPFS-cluster-service that is not present in the IPFS server and IOTA. We provide a security evaluation of our system using the AVISPA tool and show that it is not only secure but also scalable as compared with IOTA using file sharing and retrieval experiments. DAGShare’s design inherently relies on parallel and distributed execution across large-scale clusters, enabling real-time scheduling and data-intensive workload management. This makes it suitable for deployment in high-performance computing environments where scalability, throughput, and low-latency communication are critical.},
  archive      = {J_SUPERC},
  author       = {Arshad, Hira and Bhutta, Areeb Ahmed and Mian, Adnan Noor and Fatima, Sumbal and Kumari, Saru and Chen, Chien-Ming},
  doi          = {10.1007/s11227-025-08011-1},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {DAGShare: A DAG-based personal file sharing framework with off-chain IPFS and access control},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Excavator pose estimation under occlusion: A coordinate classification approach enhanced by kalman filtering. <em>SUPERC</em>, <em>81</em>(16), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07989-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel excavator pose estimation framework based on coordinate classification. The framework introduces three key innovations: 1) a coordinate classification network for accurate arm joint estimation under unobstructed conditions, 2) a Kalman filter for maintaining temporal coherence during occlusions, and 3) virtual trajectory-driven recalibration of Kalman parameters for stable pose recovery post-occlusion. The proposed method achieves a lightweight design with a reduction of approximately 80.8% in the number of parameters, while also decreasing the endpoint error (EPE) by 2.81 pixels. Experimental validation on an excavator dataset highlights the robustness and efficiency of the approach, demonstrating its potential for real-time deployment in challenging operational conditions.},
  archive      = {J_SUPERC},
  author       = {Li, Jian and Ding, Weili and Liu, Guoqing and Hua, Changchun and Cai, Dengsheng and Sun, Jinquan},
  doi          = {10.1007/s11227-025-07989-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Excavator pose estimation under occlusion: A coordinate classification approach enhanced by kalman filtering},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical simulation of two-dimensional fractional space–time partial differential equation arising from anomalous diffusion with zero magnetic field gradient. <em>SUPERC</em>, <em>81</em>(16), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07995-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel numerical scheme for solving the two-dimensional fractional space–time partial differential equation governing anomalous diffusion in the absence of magnetic field gradients. The generalized equation incorporates fractional derivatives in both time (order $$\gamma$$ ) and space (order $$\theta$$ ), along with a reaction/decay term, providing a comprehensive model for complex diffusion phenomena. For temporal discretization, we employ a high-order time stepping finite difference scheme, ensuring high accuracy in capturing memory effects. For spatial approximation, we propose a new class of shifted Chelyshkov polynomials (in case two dimensional) along to the operational matrices corresponding to left/right Riemann–Liouville and Riesz fractional derivative operators, uniquely constructed for this problem, enabling efficient and stable spectral convergence. The high computational cost of the proposed method, stemming from dense fractional derivative matrices, requires high-performance computing. Its inherent Kronecker structure enables efficient distributed-memory parallelization for large-scale simulations and parameter space exploration. A rigorous convergence analysis is presented for the time semi-discrete scheme, proving that the method achieves unconditional stability and convergence rate of order $$\mathcal{O}(\delta ^{3-\gamma })$$ under mild regularity conditions with the time step $$\delta$$ . Moreover, numerical experiments demonstrate the superiority of the proposed approach compared to existing techniques, showcasing significantly lower errors and enhanced computational efficiency.},
  archive      = {J_SUPERC},
  author       = {Azin, Hadis and Ordokhani, Yadollah and Kashkooly, Ali Iloon},
  doi          = {10.1007/s11227-025-07995-0},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Numerical simulation of two-dimensional fractional space–time partial differential equation arising from anomalous diffusion with zero magnetic field gradient},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OptimizedSwinUNet: A computationally efficient framework for joint semantic segmentation and 3D modeling of acoustic materials. <em>SUPERC</em>, <em>81</em>(16), 1--35. (<a href='https://doi.org/10.1007/s11227-025-08007-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of building acoustic materials is crucial for applications in Building Information Modeling (BIM) and digital twin construction, a task challenged by the high computational demands and architectural limitations of general-purpose models. To address this, this paper proposes a computationally efficient and accurate segmentation framework, named OptimizedSwinUNet. Our proposed architecture enhances the SwinUNet baseline through three targeted optimizations designed to improve both accuracy and efficiency: (1) a hybrid window attention (HWA) module that fuses local and global features with minimal overhead; (2) an integrated Squeeze-and-Excitation (SE) module for channel-wise feature refinement; and (3) an optimized sampling strategy using depthwise separable convolutions that significantly reduces the model’s parameter count. On our newly constructed acoustic material segmentation (AMS) dataset—a challenging benchmark comprising 1869 high-resolution images of five material categories, captured across diverse real-world construction sites and characterized by significant class imbalance and visually ambiguous boundaries—comprehensive experiments demonstrate the superiority of our framework. Compared to the baseline SwinUNet, our OptimizedSwinUNet achieves a mean Intersection over Union (IoU) of 89.5%, representing a notable improvement, while simultaneously reducing the parameter count by 1.9%. Furthermore, the utility of these high-fidelity segmentation results is demonstrated through their integration into a 3D reconstruction pipeline, where they lead to a 33.3% reduction in the geometric root mean square error (RMSE) of the final model. This work presents an effective and resource-aware framework for automated material analysis, showcasing strong potential for engineering applications. Validation on the public synapse dataset further confirms our model’s strong generalization ability, outperforming the baseline by a large margin.},
  archive      = {J_SUPERC},
  author       = {Ting, Zheng and Jinxiang, Pang and Xuewen, Liu and Zhenshan, Zhang},
  doi          = {10.1007/s11227-025-08007-x},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {OptimizedSwinUNet: A computationally efficient framework for joint semantic segmentation and 3D modeling of acoustic materials},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DX protocol: A high-performance sketch-based set reconciliation protocol for blockchain propagation. <em>SUPERC</em>, <em>81</em>(16), 1--35. (<a href='https://doi.org/10.1007/s11227-025-08009-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient block propagation is critical to the performance and scalability of blockchain networks. High propagation latency not only slows synchronization but also increases the risk of forks and orphaned blocks. Existing propagation protocols suffer from bandwidth inefficiency, high false-positive rates, or insufficient compression. In this work, we propose the DX protocol, a lightweight and high-performance sketch-based set reconciliation scheme that utilizes a novel data structure called the DX sketch to encode transactions as fingerprint-based structures, supporting subtraction and decoding, enabling fast and accurate set reconciliation. By reducing redundant data transmission, DX improves propagation efficiency in both optimistic (fully synchronized) and pessimistic (partially missing) mempool scenarios. Theoretical analysis shows that the DX sketch achieves lower space complexity and a lower false-positive probability compared to Bloom filters and IBLTs. Extensive experimental results indicate that DX reduces propagation latency by up to 10 times and bandwidth costs by up to 60% compared with state-of-the-art protocols, such as Graphene and Compact Blocks, while maintaining low false-positive rates, demonstrating that DX is a high- performance, practical solution for scalable blockchain propagation, improving upon existing designs without introducing radical changes to protocol flow.},
  archive      = {J_SUPERC},
  author       = {Ma, Xu and Meng, Xiangwei and Liang, Wei and Yang, Ce and Li, Kuanching and Zhang, Yanrong and Esposito, Antonio},
  doi          = {10.1007/s11227-025-08009-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {DX protocol: A high-performance sketch-based set reconciliation protocol for blockchain propagation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of hybrid optimization approach combined with AI-based techniques for prediction of electrical fields in overhead transmission lines. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-08013-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Getting a precise estimate of electric fields around extra-high-voltage (EHV) transmission lines is essential for keeping the public safe, ensuring environmental compliance, and planning infrastructure effectively. Unfortunately, traditional numerical methods often struggle with accuracy and can be slow to converge, which makes them less suitable for large-scale projects. This study introduces a hybrid computational framework that combines the Charge Simulation Method (CSM) with the Firefly Algorithm (FA). This combination helps optimize the number, position, and strength of simulation charges, leading to better modeling accuracy and efficiency. Additionally, we have trained three artificial intelligence (AI) models: Multilayer Perceptron Neural Network (MLPNN), Adaptive Neuro-Fuzzy Inference System (ANFIS), and Least Squares Support Vector Machine (LS-SVM) on real-world field data to reliably predict electric field values. Notably, LS-SVM is being used in this context for the first time and has shown to outperform the other models in accuracy, generalization, and speed. We evaluated the proposed CSM-FA hybrid model alongside AI predictions using metrics like Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), and the coefficient of determination (R2), revealing significant improvements over traditional methods. Given the heavy computational demands of the optimization and learning phases, we utilized high-performance computing (HPC) resources for implementation. This work not only advances algorithmic innovation and AI-assisted simulation but also enhances HPC applications, providing a scalable and precise solution for real-time field monitoring and regulatory assessments. The methodology aligns well with the scientific goals of The Journal of Supercomputing and fosters advanced research in intelligent power system modeling.},
  archive      = {J_SUPERC},
  author       = {Meriouma, Takieddine and Bessedik, Sid Ahmed and Djekidel, Rabah and El-Sehiemy, Ragab A.},
  doi          = {10.1007/s11227-025-08013-z},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Development of hybrid optimization approach combined with AI-based techniques for prediction of electrical fields in overhead transmission lines},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributed cooperative decision-making approach for multi-priority CAVs at unsignalized T-intersections. <em>SUPERC</em>, <em>81</em>(16), 1--28. (<a href='https://doi.org/10.1007/s11227-025-08014-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current research on multi-agent reinforcement learning (MARL) for optimizing the passage of connected and autonomous vehicles (CAVs) predominantly focuses on regular four-way intersections, often neglecting the heterogeneity of CAVs in terms of access rights and scheduling priorities. To address this gap, this paper targets unsignalized T-intersections and systematically investigates the optimization of multi-priority CAVs passage strategies. A distributed MARL framework is proposed, integrating priority awareness and a multi-dimensional reward mechanism. Priority information is embedded into the observation space via one-hot encoding, enabling agents to recognize social roles and learn differentiated strategies. A hierarchical reward function—incorporating basic driving, safe avoidance, neighbor cooperation, and priority courtesy—is designed to improve coordination efficiency and rule adaptability. A PPO-based distributed training structure is constructed to enhance convergence stability. Computational and communication complexity and scalability are analyzed, including distributed training throughput, latency, and parallel efficiency. Extensive experiments on the MetaDrive platform, compared with SAC, DDPG, and FIFO baselines, demonstrate that the proposed method significantly outperforms existing approaches in key metrics such as passage efficiency, safety, and priority responsiveness. These results validate the effectiveness of the “multi-priority mechanism + multi-dimensional reward structure” in guiding the evolution of CAV passage strategies and provide a feasible approach for intelligent decision-making in complex traffic environments.},
  archive      = {J_SUPERC},
  author       = {Li, Jianghong and Zhang, Huan and Zhao, Yanling and Liu, Guohui and Liu, Xin},
  doi          = {10.1007/s11227-025-08014-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A distributed cooperative decision-making approach for multi-priority CAVs at unsignalized T-intersections},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust multi-scale ship detection approach leveraging edge focus enhancement and dilated residual aggregation. <em>SUPERC</em>, <em>81</em>(16), 1--37. (<a href='https://doi.org/10.1007/s11227-025-08026-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancements in remote sensing techniques and deep learning, ship detection has become widely adopted in ocean monitoring. However, challenges such as background interference and multi-scale target features continue to hinder effective ship detection. To cope with these challenges, this paper proposes the multi-scale ship detection approach (MSDA) aimed to enable efficient multi-scale ship detection in remote sensing images with complex backgrounds. Firstly, this paper proposes the edge focus enhancement module (EFEM), which improves the model’s capability to capture ship details by enhancing edge features, thereby reducing background interference. Additionally, the proposed dilated residual aggregation network (DRAN) integrates the single-shot aggregation network and the dilation-wise residual module, significantly boosting the model’s capacity to learn and express multi-scale information. Finally, the paper employs the weighted bidirectional feature pyramid network (BiFPN) to optimize feature fusion, effectively accounting for the contributions of features across different resolutions, thereby further improving detection performance. Experimental results on the HRSC2016, Seaship7000, and SSDD datasets demonstrate that MSDA significantly improves performance, effectively addressing background interference and multi-scale target detection challenges. Furthermore, this paper validates the inference speed of the method in a high-performance computing environment, demonstrating its potential to support real-time ocean monitoring applications.},
  archive      = {J_SUPERC},
  author       = {You, Datao and Zhao, Bingbing and Lei, Deyu and Mao, Yanxu},
  doi          = {10.1007/s11227-025-08026-8},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {A robust multi-scale ship detection approach leveraging edge focus enhancement and dilated residual aggregation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying relationships in uncertain environments: Examining relations in binary soft sets for expressing inter-object correspondence. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-08036-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory has emerged as a powerful mathematical framework for effectively modeling uncertain and imprecise environments. While traditional soft sets adeptly represent objects within a single initial universe by associating them with parameters from a parameter set, their capacity to handle inter-object relationships spanning distinct universes is inherently limited. For instance, consider a traditional soft set defined over a single universe $$U_1$$ of students with parameters such as “hardworking” or “successful.” While this representation efficiently captures intra-object attributes within $$U_1$$ , it cannot express inter-object correspondences between two distinct universes, such as students ( $$U_1$$ ) and teachers ( $$U_2$$ ). For example, a soft set over $$U_1$$ may indicate that a particular student is hardworking, but it cannot represent a meaningful relationship like “a student is supervised by a teacher,” which inherently involves two different universes. This limitation motivates the need for binary soft sets to unify such cross-universe relations. To address this critical gap, binary soft sets extend this paradigm, offering a unified mathematical model to express parameters originating from elements in two separate initial universe sets. This study contributes to the literature by introducing and thoroughly developing the concept of a relation on binary soft sets. This novel framework enables the articulation of precise correspondences and interactions between objects residing in these dual universes. A binary soft relation is rigorously characterized as a binary soft subset of the Cartesian product of two binary soft sets. Furthermore, the paper extensively explores various fundamental related concepts, including blocks, partitions, compositions, and the core properties of reflexivity, symmetry, transitivity, and equivalence. The notion of binary soft functions is also meticulously defined. All theoretical concepts are comprehensively supported by illustrative examples and accompanying pertinent properties and theorems, ensuring clarity and practical understanding. This foundational work provides essential tools for advanced analysis in complex systems involving multi-source uncertainties.},
  archive      = {J_SUPERC},
  author       = {Dalkılıç, Orhan},
  doi          = {10.1007/s11227-025-08036-6},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Unifying relationships in uncertain environments: Examining relations in binary soft sets for expressing inter-object correspondence},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Splp-yolo: An all-weather real-time detector for airport runway foreign object debris. <em>SUPERC</em>, <em>81</em>(16), 1. (<a href='https://doi.org/10.1007/s11227-025-08037-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Zhang, Runze and Wang, Ce and Li, Bingru and Ye, Ouming and Xu, Xudong},
  doi          = {10.1007/s11227-025-08037-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Splp-yolo: An all-weather real-time detector for airport runway foreign object debris},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AgileEEG: A lightweight CNN enabling real-time BCI control of a portable rehabilitation exoskeleton. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-08016-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practical deployment of real-time brain–computer interface (BCI) systems is constrained by the significant computational cost of accurately decoding motor imagery (MI) on portable, resource-limited hardware. This inefficiency stems from conventional CNNs failing to address the inherent feature redundancy in electroencephalography (EEG) signals. We demonstrate the effectiveness of AgileEEG by using it to enable real-time, closed-loop control of a portable upper-limb rehabilitation exoskeleton powered by a Raspberry Pi 4B. On a public dataset, AgileEEG achieved an accuracy of 50.25% on a six-class motor imagery task, a significant 6.72% improvement over EEGNet with substantially lower computational cost. In real-time, closed-loop online tests using a task decomposition strategy for four functional movements, our system reached a functional accuracy of 70.56%. AgileEEG offers a practical and computationally efficient solution, enabling advanced BCI control for assistive devices like rehabilitation exoskeletons.},
  archive      = {J_SUPERC},
  author       = {Wang, Yifan and Yao, Jiangfan},
  doi          = {10.1007/s11227-025-08016-w},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {AgileEEG: A lightweight CNN enabling real-time BCI control of a portable rehabilitation exoskeleton},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RBC-GNN: A novel relation-aware graph-based learning framework for breast cancer classification using graph neural network. <em>SUPERC</em>, <em>81</em>(16), 1--34. (<a href='https://doi.org/10.1007/s11227-025-08023-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most commonly diagnosed cancer among women globally, and its early detection is essential for effective treatment and improved patient outcomes. Traditional diagnostic approaches often rely on imaging and statistical analysis techniques, which may not effectively capture complex relationships within clinical data. This study introduces a novel deep learning framework utilizing graph neural networks (GNNs) for breast cancer classification. The proposed model transforms structured data into a graph format, allowing for the representation of inter-feature dependencies through message-passing mechanisms. A weighted K-nearest neighbors algorithm is used to construct the graph, followed by a graph embedding process that encodes both local and global feature relationships. A two-layer graph convolutional network is employed to perform node-level classification, distinguishing between benign and malignant cases. The computational demands of graph construction, embedding, and hyperparameter optimization necessitated the use of high-performance computing (HPC) resources. Experiments were conducted on an HPC cluster featuring multi-core CPUs and GPUs to enable efficient data parallelism and reduced training latency. The parallelized implementation accelerated convergence, supported large-scale parameter tuning, and ensured the model’s scalability for future real-time clinical applications. The proposed model, RBC-GNN(Relation-aware Breast Cancer Classification using GNN), is evaluated using the Wisconsin Diagnostic Breast Cancer (WDBC) dataset. Key performance metrics, including accuracy, precision, recall, F1-score, confusion matrices, AUC–ROC, and loss curves, are used to assess effectiveness. RBC-GNN achieves a classification accuracy of 97.37%, demonstrating its superior performance and potential for clinical application. Comparative analysis with various optimizers confirms the robustness of the proposed approach. The results highlight the synergy between GNN architectures and HPC environments in enabling fast, scalable, and reliable computational pathology. This work underscores the potential of GNN-driven, HPC-accelerated frameworks for intelligent and resource-efficient breast cancer diagnosis in clinical practice.},
  archive      = {J_SUPERC},
  author       = {Shah, Hemali and Agrawal, Smita S and Oza, Parita and Tanwar, Sudeep},
  doi          = {10.1007/s11227-025-08023-x},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {RBC-GNN: A novel relation-aware graph-based learning framework for breast cancer classification using graph neural network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy logic system and VDF adaptive iteration-based metaverse secure authentication scheme. <em>SUPERC</em>, <em>81</em>(16), 1--31. (<a href='https://doi.org/10.1007/s11227-025-08024-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of metaverse technology, there is a growing demand for authentication and data transmission during the interaction between virtual digital people and intelligent medium devices. However, existing authentication schemes generally have problems such as poor security, low computational efficiency and insufficient adaptability. To solve the above problems, this paper proposes a fuzzy logic system and VDF adaptive iteration-based metaverse security authentication scheme. This scheme utilizes a fuzzy logic system to compute the trustworthiness of dynamic identity and introduces a verifiable delay termination based on RSA group construction (Loe-VDF) to achieve adaptive security authentication. During the computation and verification process, VDF iteration and fuzzy logic trustworthiness calculations demand extensive exponential operations and parallel modular exponentiation, which imposes very high demands on computational performance. Therefore, this scheme is inherently well suited to high-performance computing (HPC) platforms, significantly enhancing real-time performance and scalability through parallel and distributed computing frameworks. Furthermore, we choose the Coppersmith method and analytic combinatorics in the security analysis to demonstrate the religious security of the scheme. Finally, we perform our simulations in AVISPA software by using the online model checker (OFMC) and the constraint logic-based attack searcher (CL-AtSe). The experimental result shows that the scheme outperforms other methods in terms of attack resistance, communication cost and time cost while ensuring mutual authentication, anonymity, confidentiality and attack resistance. Supported by HPC, it satisfies the requirements for instantaneous interaction and dynamic authentication within metaverse scenarios.},
  archive      = {J_SUPERC},
  author       = {Bao, Shuang and Li, Lixiang and Peng, Haipeng and Zhang, Ran},
  doi          = {10.1007/s11227-025-08024-w},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {A fuzzy logic system and VDF adaptive iteration-based metaverse secure authentication scheme},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-quantum secure authentication protocol based on OTP and TEE. <em>SUPERC</em>, <em>81</em>(16), 1--33. (<a href='https://doi.org/10.1007/s11227-025-08029-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of emerging quantum threats, traditional authentication mechanisms—particularly those based on one-time passwords (OTP)—are becoming inadequate. This paper introduces a post-quantum authentication model that combines an OTP scheme derived from an ML-DSA signature (from the PQClean project) with a Trusted Execution Environment (TEE). The TEE ensures the secure generation, storage, and usage of critical cryptographic elements, thereby strengthening resilience against both software and hardware attacks. This approach provides a robust response to modern security challenges. A security analysis and in-depth discussion position this model as a credible and scalable alternative for authentication in a post-quantum world.},
  archive      = {J_SUPERC},
  author       = {Kasse, Mamadou Cherif and Mboup, El Hadj Modou},
  doi          = {10.1007/s11227-025-08029-5},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Post-quantum secure authentication protocol based on OTP and TEE},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware service migration using hybrid SA-DQN in edge computing. <em>SUPERC</em>, <em>81</em>(16), 1--38. (<a href='https://doi.org/10.1007/s11227-025-08030-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of mobile devices and IoT sensors demands robust edge computing frameworks capable of maintaining seamless service quality for users on the move. A central challenge is intelligent service migration, which must proactively relocate user services to optimal edge servers by anticipating mobility and adapting to user-specific needs. This paper introduces a comprehensive Context-Aware Service Migration (C-Migrate) framework that synergistically integrates high-fidelity trajectory prediction with context-aware optimization to address this challenge. We propose C-Migrate framework containing two main components: First, we propose SpatioFormer, an encoder-only transformer model that forecasts user mobility with high accuracy. These predictions then inform our Hybrid Simulated Annealing with Deep Q-network refinement (SA-DQN) algorithm, which formulates server selection as a constraint-based facility location problem. Our approach uniquely incorporates a multi-dimensional context model, enabling migrations that are not only spatially efficient but also personalized to dynamic user conditions, such as in mobile healthcare scenarios. Evaluated in a large-scale urban mobility case study with extensive experiments, our framework demonstrates a significant reduction of 9–11% in the number of service migrations with the use of trajectory prediction and a significant 68–73% reduction in service migrations considering the users’ context, compared to state-of-the-art baselines. This work establishes that the integrated trajectory prediction and context-aware optimization is essential for intelligent service migration, paving the way for more responsive and efficient edge computing ecosystems.},
  archive      = {J_SUPERC},
  author       = {Ayoubi, Majid and Li, Mingchu and Albishari, Mohammed},
  doi          = {10.1007/s11227-025-08030-y},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Context-aware service migration using hybrid SA-DQN in edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New algorithms for fully homomorphic matrix addition and multiplication. <em>SUPERC</em>, <em>81</em>(16), 1--38. (<a href='https://doi.org/10.1007/s11227-025-08032-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New algorithms are introduced for embedding matrices with integer or fixed-point real number entries into plaintexts and for performing matrix addition and multiplication on encrypted matrices. The encryption algorithms used for this purpose are fully homomorphic, such as BGV, BFV, and CKKS. These algorithms have the property of performing SIMD style parallel operations on plaintext values encrypted into a single ciphertext vector by a technique called “ciphertext packing” using the Chinese Remainder Theorem. This concept was introduced by Halevi and Shoup, and algorithms for homomorphic matrix operations were further improved by Jiang et al. (JKLS). Our algorithms improve both Halevi and Shoup and JKLS algorithms in terms of arithmetic and data rotation complexity. The proposed algorithms are designed on top of the BFV fully homomorphic encryption scheme. We describe our algorithms in detail step by step in this article, providing numerical examples in Appendix A. Experimental results demonstrate that our matrix multiplication algorithm achieves superior efficiency in terms of running time compared to JKLS algorithm. Real-world applications of FHE-based matrix computations often require matrix dimensions in the hundreds of thousands. Given typical FHE parameter settings (polynomial degree $$N = 2^{13}$$ , plaintext modulus $$t = 65537$$ ), the total number of arithmetic and data-rotation operations can easily reach the order of $$10^{12}$$ . This scale necessitates state-of-the-art high-performance computing practices.},
  archive      = {J_SUPERC},
  author       = {Ci, Shang and Wang, Yihan and Hu, Sen and Guan, Donghai and Koç, Çetin Kaya},
  doi          = {10.1007/s11227-025-08032-w},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {New algorithms for fully homomorphic matrix addition and multiplication},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-preserving point cloud simplification method based on cylindrical neighborhoods. <em>SUPERC</em>, <em>81</em>(16), 1--29. (<a href='https://doi.org/10.1007/s11227-025-08033-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In elongated underground tunnels, laser scanning systems acquire point clouds containing substantial redundant data, leading to heavy computational load and affecting the accuracy of subsequent data analysis. Therefore, this study proposes a feature-preserving point cloud simplification method based on cylindrical neighborhoods, which leverages parallel processing techniques, drawing on high-performance computing principles, to enable fast data handling and meet tunnel monitoring efficiency requirements. The method downsamples feature-redundant points by removing thickness-redundant points, simplifying the point cloud while preserving structural features. Experimental results show that across simplification rates, over 60% of points have roughness below 0.5 cm, and the feature preservation rate exceeds 90%. Compared with the random sampling method (RSM), the uniform simplification method (USM), and the feature-preserving method (FPM), the average roughness can be reduced by 45.8% and effectively improves the feature preservation rate, demonstrating that the proposed method can effectively simplify point clouds while retaining critical structural features.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yuan and Xu, Shaoyi and Wang, Chengtao and Sun, Tianshan and Wang, Hao},
  doi          = {10.1007/s11227-025-08033-9},
  journal      = {The Journal of Supercomputing},
  month        = {11},
  number       = {16},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Feature-preserving point cloud simplification method based on cylindrical neighborhoods},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image analysis: A systematization of knowledge on the convergence of AI and quantum computing. <em>SUPERC</em>, <em>81</em>(15), 1--52. (<a href='https://doi.org/10.1007/s11227-025-07789-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the interplay between artificial intelligence (AI) and quantum computing (QC) within the context of medical image analysis for modern diagnostics. In fact, while AI and particularly deep learning models have significantly advanced medical imaging, current limitations including non-polynomial computational complexity in training deep convolutional networks, scalability, and data heterogeneity are not yet completely resolved. However, QC, with its inherent parallelism and exceptional speedup capacity, presents a promising approach to address these limitations. The main aim of this study is therefore to take an in-depth look at the synergies between AI and QC, focusing on hybrid models that integrate quantum algorithms with AI capabilities for medical tasks such as segmentation, classification, and anomaly detection. To this end, we examine the theoretical foundations, emerging algorithmic paradigms, and practical frameworks that fuse AI and QC. This is conducted through a systematization of knowledge of recent advancements from both domains, while highlighting the significant potential of AI–QC integration to enable the principles of 5P Medicine: preventive, predictive, personalized, precision, and participatory health care. The proposed analysis lays a structured foundation for future research by identifying current gaps and offering insights that can guide the development of next-generation medical diagnostic tools powered by quantum AI technologies.},
  archive      = {J_SUPERC},
  author       = {ElBedoui, Khaoula and Ben Lakhal, Neila and Barhoumi, Walid},
  doi          = {10.1007/s11227-025-07789-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--52},
  shortjournal = {J. Supercomput.},
  title        = {Medical image analysis: A systematization of knowledge on the convergence of AI and quantum computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluations of signed and unsigned noisy approximate quantum fourier arithmetic. <em>SUPERC</em>, <em>81</em>(15), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07819-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quantum Fourier Transform (QFT) grants competitive advantages, especially in resource usage and circuit approximation, for performing arithmetic operations on quantum computers, and offers a potential route toward a numerical quantum-computational paradigm. In this paper, we utilize efficient techniques to implement QFT-based integer addition and multiplications. These operations are fundamental to various quantum applications including Shor’s algorithm, weighted-sum optimization problems in data processing and machine learning, and quantum algorithms requiring inner products. We carry out performance evaluations of these implementations based on IBM’s superconducting-qubit architecture using different compatible noise models. We isolate the sensitivity of the component quantum circuits on both one-/two-qubit gate error rates, and the number of the arithmetic operands’ superposed integer states. We analyze performance and identify the most effective approximation depths for unsigned quantum addition and quantum multiplication within the given context. We then perform a similar analysis of signed addition and compare to the unsigned results. We observe significant dependency of the optimal approximation depth on the degree of machine noise and the number of superposed states in certain performance regimes. Finally, we elaborate on the algorithmic challenges—relevant to signed, unsigned, modular and non-modular versions—that could also be applied to current implementations of QFT-based subtraction, division, exponentiation, and their potential tensor extensions. We analyze the performance trends in our results and speculate on possible future developments within this computational paradigm.},
  archive      = {J_SUPERC},
  author       = {Basili, Robert A. M. and Qian, Wenyang and Sarker, Shiplu and Tang, Shuo and Castellino, Austin and Eshaghian-Wilner, Mary and Khokhar, Ashfaq and Luecke, Glenn and Vary, James P.},
  doi          = {10.1007/s11227-025-07819-1},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Performance evaluations of signed and unsigned noisy approximate quantum fourier arithmetic},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based intelligent edge orchestration for IoT: Insights into performance and profitability. <em>SUPERC</em>, <em>81</em>(15), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07830-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing plays a key role in smart IoT systems by reducing network load and improving application responsiveness. This paper presents a reinforcement learning (RL)-driven orchestration framework that jointly optimizes task offloading and dynamic pricing to enhance both economic profitability and energy efficiency. Unlike existing methods that simply map traditional objectives into RL, we propose a closed-loop design based on profit–energy coupling, where pricing, idle power, and task granularity are unified into monetary cost to enable balanced decision-making. We also introduce a unified state–reward abstraction for centralized, decentralized, and hybrid topologies, allowing policy reuse across deployment settings. Implemented in an extended EISim simulator, our system features real-time dual-loop feedback between pricing (via DDPG) and offloading (via RL agents). The performance analysis reveals that reinforcement learning (RL)-based techniques can consistently adjust their offloading strategies to balance local execution and edge offloading, thereby enhancing overall network performance. Moreover, we demonstrate how the adaptive capabilities of RL in conjunction with the pricing strategy set by DDPG to significantly affect the profitability and computational efficiency of the edge service platforms. The findings highlight the nuanced relationship of pricing, task offloading, and system topology in edge computing environments.},
  archive      = {J_SUPERC},
  author       = {Luo, Qianhua and Xie, Bo and Cui, Haixia},
  doi          = {10.1007/s11227-025-07830-6},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Reinforcement learning-based intelligent edge orchestration for IoT: Insights into performance and profitability},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDFformer: A dual-domain fused transformer for polyp segmentation. <em>SUPERC</em>, <em>81</em>(15), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07846-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polyp segmentation plays a pivotal role in early colorectal cancer detection, where accurate and automated delineation of polyps can significantly enhance diagnostic precision. Existing convolutional neural network (CNN)-based approaches exhibit limitations in capturing long-range dependencies, while transformer-based models, though effective in global context modeling, often overlook vital frequency-domain information. Moreover, the highly variable and indistinct boundaries of polyps demand powerful multi-scale representation learning and substantial computational resources, highlighting the necessity of high-performance computing (HPC) support. To address these gaps, we propose DDFFormer, a novel dual-domain fused transformer architecture designed to integrate spatial- and frequency-domain contexts seamlessly. Our key contribution lies in the introduction of the dual-domain collaborative attention (DDCA) mechanism, which synergistically fuses multi-head self-attention (MHSA)-refined spatial-domain tokens and frequency-domain context-enriched tokens, ensuring comprehensive contextual representation. Through a hierarchical framework composed of dual-domain fused transformer blocks (DDFBs) and a mask transformer decoder, DDFFormer progressively refines feature representations across multiple scales. Extensive evaluations on three benchmark datasets—Kvasir-SEG, CVC-ClinicDB, and CVC-ColonDB—demonstrate that DDFFormer consistently outperforms state-of-the-art methods, achieving superior Dice, IoU, sensitivity, and specificity scores. Furthermore, ablation studies highlight the significant contribution of DDCA to performance gains. In addition, we report the computational efficiency of our model and emphasize that both the large-scale training and real-time inference require GPU acceleration and parallel optimization, underscoring the relevance of this work to supercomputing and HPC applications. These findings confirm the robustness and efficacy of DDFFormer, making it a promising solution for real-world clinical applications in gastrointestinal disease detection.},
  archive      = {J_SUPERC},
  author       = {Tong, Yao and Yong, Xi and Liang, Jingchen and Chen, Ziqi and Hu, Yun and Li, Xin and Gao, Hongmin and Zhou, Zuojian and Hu, Kongfa},
  doi          = {10.1007/s11227-025-07846-y},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {DDFformer: A dual-domain fused transformer for polyp segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault tolerance assessment of exchanged crossed cube based on structure fault pattern. <em>SUPERC</em>, <em>81</em>(15), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07866-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the scales of multiprocessor systems expand, the demand for high reliability and security grows proportionally. Network topology (or graph) modeling, which maps the interconnection patterns between processors and links in a multiprocessor system, serves as an effective methodology for investigating system reliability. Among various network robustness metrics, connectivity is a critical evaluation criterion. H-(sub)structure connectivity is a generalization of traditional connectivity, and numerous studies have been conducted the fault tolerability of to evaluate various networks. As an extended variant of the hypercube, the exchanged crossed cube combines the advantages of smaller diameter and fewer edges. These advantages enable the network to achieve lower hardware costs while maintaining more efficient data transmission. In this paper, we investigate the H-(sub)structure connectivity of the exchanged crossed cube ECQ(s, t) when H is isomorphic to $$P_k$$ , $$C_k$$ and $$K_{1, r}$$ .},
  archive      = {J_SUPERC},
  author       = {Li, Xiaowang and Tian, Lili and Zhou, Shuming and Jia, Leyi and Shi, Zihan},
  doi          = {10.1007/s11227-025-07866-8},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Fault tolerance assessment of exchanged crossed cube based on structure fault pattern},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupled graph neural network with spatially-aware gating selections. <em>SUPERC</em>, <em>81</em>(15), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07875-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks excel in representation learning on structured graphs, yet many decoupled frameworks ignore the intrinsic link between structure and features and offer limited means to mitigate noisy neighborhood aggregation. To address these limitations, we propose DGNN-SGS, a dual-graph, weight-tied GNN that constructs separate embeddings from the feature and topology spaces for fine-grained decoupling while sharing a single convolution–gating block across views. By integrating feature and topological graphs, we enhance node representation quality. In addition, a spatially-aware gating mechanism is incorporated to adaptively filter neighbor information, yielding not only superior predictive accuracy but also more efficient training compared with prior designs. Extensive experiments on benchmark datasets demonstrate that DGNN-SGS significantly improves node classification performance.},
  archive      = {J_SUPERC},
  author       = {Meng, Xin and Lu, ShuXia},
  doi          = {10.1007/s11227-025-07875-7},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Decoupled graph neural network with spatially-aware gating selections},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dialectic optimization algorithm (DOA): A novel metaheuristic inspired by dialectical philosophy. <em>SUPERC</em>, <em>81</em>(15), 1--64. (<a href='https://doi.org/10.1007/s11227-025-07879-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient optimization methods are essential for addressing large-scale and real-time problems in supercomputing environments. This paper presents the Dialectic Optimization Algorithm (DOA), a novel population-based metaheuristic inspired by Hegelian and Marxist dialectical philosophy. DOA simulates the ideological dynamics of three subpopulations: supporters, opponents, and neutrals—using logistic growth equations, influence matrices, contradiction analysis, and synthesis mechanisms. These components form a structured and adaptive search process that promotes diversity, mitigates premature convergence, and drives the population toward global optima. A formal algorithm analysis is also provided, including first-order logical axioms, lemmas on population dynamics, and convergence theorems that mathematically validate its soundness and stability. The proposed method is empirically evaluated on twelve standard benchmark functions and compared against eleven widely used metaheuristics, including GA, ACO, PSO, WOA, GWO, HHO, SSA, and others. Based on 100 independent runs per function, the DOA consistently outperformed all eleven comparative algorithms in accuracy, robustness, and convergence speed. A comprehensive statistical evaluation using Kolmogorov–Smirnov with p < 0.01, Mann–Whitney showing no statistical inferiority, Kruskal–Wallis with χ2 > 1 000 and a Friedman test yielding a mean rank of 1.08 confirmed DOA’s superior solution quality, efficiency and consistency across 12 benchmark functions, underscoring its philosophically grounded, formally validated framework for solving complex, multimodal optimization problems.},
  archive      = {J_SUPERC},
  author       = {Salami, Yashar},
  doi          = {10.1007/s11227-025-07879-3},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--64},
  shortjournal = {J. Supercomput.},
  title        = {Dialectic optimization algorithm (DOA): A novel metaheuristic inspired by dialectical philosophy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGP-IC: Graph neural networks via hotness-based partitioning and information compensation. <em>SUPERC</em>, <em>81</em>(15), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07880-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown strong performance in applications like social networks and recommender systems, especially on large-scale graphs. However, training GNNs on such graphs suffers from the neighbor explosion problem, leading to high memory consumption. To tackle this, the "graph partitioning $$ + $$ local learning" framework splits the global graph into smaller subgraphs for independent training. Existing graph partitioning methods fall into node and edge partitioning. Node partitioning drops inter-subgraph edges, causing incomplete information, while edge partitioning, though structure-preserving, introduces two major challenges: (1) Existing edge partitioning methods often rely on node degrees to divide subgraphs, ignoring the actual role of nodes in information propagation, which may result in the loss of critical information paths and affect training accuracy; (2) during subgraph training, nodes cannot access all their original neighbors, limiting the model’s expressive capacity and reducing predictive performance. To overcome these issues, we propose HGP-IC, a model combining a refined partitioning strategy (HGP) with an information compensation (IC). HGP not only resolves memory constraints during GNNs training on large-scale graph data-enabling tasks originally designed for limited resources to execute smoothly but also mitigates the impact of node partitioning during training. IC restores lost neighbor information between subgraphs, enhancing representation and predictive performance. Experiments on seven public datasets confirm that HGP-IC significantly improves GNNs accuracy and demonstrates strong effectiveness on large-scale graphs. https://github.com/huang-1314-xu/HGP-IC.git .},
  archive      = {J_SUPERC},
  author       = {Ji, Shengwei and Huang, Yue and Li, Shengjie and Zhang, Xiaoxue and Wang, Wenting},
  doi          = {10.1007/s11227-025-07880-w},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {HGP-IC: Graph neural networks via hotness-based partitioning and information compensation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFL-GS: Spatio-temporal feature-guided learning for 3D gaussian segmentation. <em>SUPERC</em>, <em>81</em>(15), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07884-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D Gaussian splatting has emerged as a promising technique for real-time scene representation, making interactive 3D segmentation increasingly important for scene manipulation. However, inconsistent 2D segmentation results across different viewpoints present significant challenges in learning 3D segmentation feature fields. When cross-view 2D segmentation results conflict, the accuracy of 3D segmentation decreases substantially. To address this, we present Spatio-temporal Feature-guided Learning for 3D Gaussian Segmentation (SFL-GS), an efficient interactive 3D segmentation framework. SFL-GS employs a novel Spatio-temporal Feature-guided Learning (SFL) strategy that captures spatio-temporally consistent features and masks from 2D segmentation results across multiple views, effectively guiding the learning of 3D segmentation feature fields. Given the computational complexity of 3D segmentation, high-performance computing (HPC) capabilities are essential to process complex scenes with high accuracy. Additionally, to refine feature and mask consistency in challenging scenarios, particularly under severe occlusion, our framework incorporates an enhanced optimization strategy that combines statistical filtering, dynamic scale growth, and edge-aware optimization. This approach results in clearer boundaries and significantly improves segmentation accuracy, even in difficult environments. Extensive experiments demonstrate that our method achieves superior accuracy in segmentation tasks, making it well-suited for precise and efficient 3D segmentation.},
  archive      = {J_SUPERC},
  author       = {Wan, Fang and Shi, Xianjin and Li, Tianyu and Lei, Guangbo and Xu, Li and Ye, Zhiwei},
  doi          = {10.1007/s11227-025-07884-6},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {SFL-GS: Spatio-temporal feature-guided learning for 3D gaussian segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Homotopic reinforcement learning for distributed consensus control of stochastic markov jump multi-agent systems. <em>SUPERC</em>, <em>81</em>(15), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07885-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the optimized consensus problem for a class of stochastic Markov jump multi-agent systems, with particular attention to the high computational demands that arise in large-scale implementations. Firstly, an error system is constructed based on the consensus objective, and a min-max strategy is introduced to transform the consensus problem into an optimized control problem of the error system. Subsequently, a set of parallel coupled game Lyapunov equations are developed to design the consensus controller, whose solution naturally requires significant parallel computation resources. Furthermore, to address the challenges posed by unknown system dynamics and the difficulty of obtaining an initial stable controller, a novel model-free consensus control approach based on homotopic reinforcement learning is proposed. By collecting state and input data, the proposed method enables the online computation of closed-loop stable controllers and optimized consensus controllers in a scalable and distributed manner. Finally, a numerical example is presented to demonstrate the effectiveness of the proposed approach, highlighting its suitability for real-time implementation on high-performance computing platforms.},
  archive      = {J_SUPERC},
  author       = {Yao, Zheng and Zhu, Qiwu and Qin, Pengjie and Luo, Min},
  doi          = {10.1007/s11227-025-07885-5},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Homotopic reinforcement learning for distributed consensus control of stochastic markov jump multi-agent systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verifiable privacy-preserving spatial-keyword range query in cloud. <em>SUPERC</em>, <em>81</em>(15), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07891-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of GPS-enabled mobile devices has resulted in a rapid increase in spatial text data, driving the growth of cloud-based spatial-keyword query services. However, reliance on untrusted cloud servers introduces serious challenges regarding data privacy and result integrity. To address these issues, we propose a verifiable privacy-preserving spatial-keyword range query (VPSRQ) scheme. We design a novel vectorization framework that simultaneously reduces vector dimensionality and enables efficient privacy-preserving query processing. Then we introduce a Homomorphic Inner Product Encryption (HIPE) scheme based on bilinear pairing, which allows secure inner product computation over encrypted vectors without leaking plaintext information. Besides, we construct a keyword object inverted index (KOI-index) and integrate it with a BP accumulator, providing both high query efficiency and lightweight verifiability of results. Through formal security analysis under the real-world/ideal world framework and comprehensive experiments on real-world datasets, VPSRQ is shown to significantly improve query performance and verification efficiency, while rigorously preserving the privacy and integrity of query results.},
  archive      = {J_SUPERC},
  author       = {Jiang, Mingfeng and Dai, Hua and Zhang, Zhengkai and Wang, Huaqun and Yang, Geng},
  doi          = {10.1007/s11227-025-07891-7},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Verifiable privacy-preserving spatial-keyword range query in cloud},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal task offloading policy in vehicular fog networks based on software-defined networking using deep reinforcement learning. <em>SUPERC</em>, <em>81</em>(15), 1--54. (<a href='https://doi.org/10.1007/s11227-025-07898-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A promising paradigm called vehicular fog computing (VFC) fully uses the processing capabilities of moving and idle vehicles acting as fog servers to increase computation capacity. Vehicles with limited resources can offload complex and computing-intensive applications to closer fog servers compared with the cloud, reducing the response time and price paid for application execution. Most current mechanisms in the VFC field focus on resources in coverage of a RoadSide Unit (RSU) or local cluster and do not consider idle computing resources in other clusters that lead to an increase in the application failure rate. Vehicular networks also face the challenge of handling applications with varying priorities and processing efficiencies. Therefore, predicting a cost-efficient task offloading solution while considering the priority, deadline, energy consumption, and budget of the application is an issue. We propose a two-tier VFC distributed architecture wherein neighboring clusters can share their idle computational resources for distributed task processing, therefore substantially improving the overall network computing resources. In this hierarchical architecture, we also use local Software-Defined Networking (SDN) and global SDN controllers to optimize intra- and inter-cluster task offloading policies. In addition, the task-offloading system is based on the priority of tasks, and priority queues in fog nodes are used to schedule the tasks of applications. Nevertheless, the global SDN controller uses the Double Deep Q-Network (DDQN)-based approach to reduce processing costs. The results indicate that the proposed strategy improves performance in terms of average processing cost, average response time, failure rate, and average energy consumption compared to other baselines.},
  archive      = {J_SUPERC},
  author       = {Behravan, Kobra and Hosseini Seno, Seyed Amin and Farzaneh, Nazbanoo and Jahanshahi, Mohsen},
  doi          = {10.1007/s11227-025-07898-0},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--54},
  shortjournal = {J. Supercomput.},
  title        = {Optimal task offloading policy in vehicular fog networks based on software-defined networking using deep reinforcement learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy quantum particle swarm optimization for efficient path planning of mobile robots. <em>SUPERC</em>, <em>81</em>(15), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07901-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantum-behaved particle swarm optimization (QPSO) algorithm utilizes quantum probability density functions to guide particles toward optimal states, rendering it an effective tool for mobile robot path planning. However, conventional QPSO algorithms often struggle with issues such as suboptimal convergence precision and a tendency to become trapped in local optima. To surmount these obstacles, this study proposes a multi-strategy QPSO scheme, termed MS-QPSO, which integrates a suite of innovative tactics, including a nonlinear cosine decreasing function, an improved local attractor mechanism, a novel particle position updating approach, and a robot trajectory smoothing technique. These strategies synergize to enhance accuracy, accelerate convergence, and strengthen the ability to escape local optima, resulting in a substantial improvement in mobile robot path planning. The effectiveness of the MS-QPSO algorithm is comprehensively validated using experiments on 49 benchmark test functions and two-dimensional grid maps of varying complexity. Experimental results indicate that MS-QPSO outperforms competing algorithms on 33 out of the 49 benchmarks, including classical test functions as well as those from the CEC-2017 and CEC-2020 test suites. In grid map path planning, MS-QPSO consistently achieves superior performance, reducing the path length by 23.8% (from 96.094 to 73.244) compared to classical QPSO, which demonstrates its significant advantages in both efficiency and path quality.},
  archive      = {J_SUPERC},
  author       = {Wang, Zeqian and Kawamoto, Kazuhiko and Hirota, Kaoru and Yan, Fei},
  doi          = {10.1007/s11227-025-07901-8},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {Multi-strategy quantum particle swarm optimization for efficient path planning of mobile robots},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gs-ocsvm: An APT attack detection method based on provenance graph. <em>SUPERC</em>, <em>81</em>(15), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07902-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the continuous evolution of APT attack techniques, intrusion detection systems based on fixed rules often fail to effectively identify new threats. To efficiently process the massive and continuously generated system audit logs, the method first constructs a provenance graph within a designated edge threshold period, reducing runtime memory consumption while providing a structured data foundation for parallelizable attack detection. An improved GraphSAGE model is then introduced to capture contextual relationships among system entities, extracting both topological and intrinsic node features in a manner suitable for distributed training. To enhance classification robustness under streaming conditions, a multi-period updated One-Class Support Vector Machine (OCSVM) is developed, enabling incremental anomaly detection with low latency. Comprehensive experiments on two public datasets, DARPA TC and StreamSpot, demonstrate that the proposed method achieves significant improvements in both detection accuracy and computational efficiency. More importantly, the design is inherently scalable to high-performance computing (HPC) platforms and real-time processing environments, making it well aligned with the demands of large-scale APT detection in supercomputing scenarios.},
  archive      = {J_SUPERC},
  author       = {Liu, Huixue and Liu, Xinqian and Zhao, Chuan and Ding, Jianguo},
  doi          = {10.1007/s11227-025-07902-7},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Gs-ocsvm: An APT attack detection method based on provenance graph},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A containerized edge AI predictive maintenance infrastructure for rotating components using continuous wavelet transform images and transformer UNet autoencoder for industry 4.0. <em>SUPERC</em>, <em>81</em>(15), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07904-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) technology and artificial intelligence (AI) are two main pillars of the fourth industrial revolution. Among their applications, predictive maintenance of rotating components has been receiving more attention in smart factories due to their widespread use. In this work, a container-based IIoT infrastructure along with a lightweight yet powerful AI model is proposed to address this topic. The serverless IIoT infrastructure is based on the KubeEdge (KE) platform for the edges and Kubernetes (K8s) in the cloud, which function as a monolithic containerized infrastructure. Predictive maintenance can be achieved by the distributed monitoring of rotating component’s vibration and its analysis at the edges. Specifically, health indicator (HI) criteria are constructed to reveal the degradation trends. For this purpose, the vibration signals are first transformed into RGB images using the continuous wavelet transform (CWT) and then fed into the proposed AI model named LITA (Lightweight IIoT Transformer UNet Autoencoder). LITA is a lightweight and powerful deep learning model based on a modified Transformer UNet model. The training process of LITA models is handled by the containers in the cloud with virtually unlimited computational resources, and the real-time inference of the predictive maintenance application is performed entirely in a distributed processing manner at the edges. To evaluate the performance of the proposed LITA model and compare it with other methods, standard intelligent maintenance systems (IMS) bearing data were used. The evaluation results demonstrate the effectiveness of the proposed method, achieving 6.84% and 3.57% improvements in monotonicity and robustness standard metrics compared to state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Keshavarz, Mohammad Ali and Sharifian, Saeed},
  doi          = {10.1007/s11227-025-07904-5},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {A containerized edge AI predictive maintenance infrastructure for rotating components using continuous wavelet transform images and transformer UNet autoencoder for industry 4.0},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy enhanced black-winged kite algorithm for UAV path planning. <em>SUPERC</em>, <em>81</em>(15), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07905-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problems of insufficient search range and optimization performance of UAVs in 3D path planning, as well as the defects that the existing black-winged kite algorithm has insufficient optimization accuracy and is prone to falling into the local optimum, a multi-strategy augmented black-winged kite algorithm (DBKA) is proposed as a method for UAV 3D path planning, which first establishes the constraints of the 3D topography, the threat zone, and the UAVs themselves; second, the Kent chaotic mapping is introduced to initialize the population to improve the diversity and quality of the population; second, the spiral foraging and tumbling foraging ideas of manta ray foraging algorithms are borrowed in the attack phase, and the position updating method is improved to improve the algorithm’s ability of global search; finally, the mixed strategy mechanism is added in the migration phase to enhance the algorithm’s ability of local optimization search. The results from solving the classical test set and the CEC2017 test set indicate that the DBKA, which incorporates the three strategies, significantly improves search accuracy, search speed, and robustness. Additionally, experiments on UAV path planning confirm that the DBKA outperforms the original BKA algorithm in search ability, producing shorter and smoother paths. The experimental results show that the improved algorithm can effectively solve the UAV path planning problem.},
  archive      = {J_SUPERC},
  author       = {Chen, Haiyang and Jia, Tong and Guo, Jinhui and Yang, Lei},
  doi          = {10.1007/s11227-025-07905-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {A multi-strategy enhanced black-winged kite algorithm for UAV path planning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plundervolt attack: A novel simulation-based fault injection attack against embedded systems for accelerating dependability analysis process. <em>SUPERC</em>, <em>81</em>(15), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07906-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electronic industry is critically analyzing embedded devices against fault injection attacks as it has become a precondition to detect attacks at the preproduction level. Performing dependability analysis and fault tolerance even before the physical prototype of the target device is available is quite challenging. Simulation-based techniques (SFI) provide valuable solutions for performing early analysis at the initial stage of the target device. However, current approaches still present some drawbacks, such as working for specific CPU architecture, requiring code instrumentation, or maybe a different target, i.e., design errors instead of dependability analysis. To overcome such issues, this work proposes a simulation-based setup mechanism for generating Plundervolt attacks so that industry experts can perform dependability analysis of fault injection attacks at the hardware level. Experimental results for generating a Plundervolt attack depict that the attack was effectively generated from time duration ( $$T_{p}$$ ) 18.003–180.043 ms for glitch voltage ( $$V_{g}$$ ) ranging from 5 to 0.3V at 2 KHz frequency. Constant/repeated Plundervolt attack was generated for time duration ( $$T_{p}$$ ) 198.0 5–306.085 ms from the 5–0.3–5 V supply voltage. An overvolting attack was also generated successfully for the time duration ( $$T_{p}$$ ) = 2 ms with glitch voltage $$V_{g}$$ = 306.1–382.9 pV. The device under test (DUT) taken was an 8051 microcontroller. The fault injection attack impact is observed and analyzed on the embedded device: microcontroller 8051 ( $$\mu$$ 51). Results found were constant/repeated glitching (from 198.050 to 306.085 ms) Plundervolt attack on the 8051 microcontroller successfully skips important instructions and causes bit flip.},
  archive      = {J_SUPERC},
  author       = {Kaur, Shaminder and Sachdeva, Ashish and Babu, J. Chinna},
  doi          = {10.1007/s11227-025-07906-3},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Plundervolt attack: A novel simulation-based fault injection attack against embedded systems for accelerating dependability analysis process},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed framework for high-quality graph partitioning. <em>SUPERC</em>, <em>81</em>(15), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07907-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph partitioning problem is increasing with the emergence of Big Data. Handling tremendous volumes of graph data requires an efficient graph processing system and especially a high-quality graph partitioning approach(s) to cope with graph application needs. However, all graph partitioning algorithms do not consider graph data volumes during graph partitioning. As a result, graph processing systems experience an imbalance in their workload and a decrease in system performance. For this purpose, we designed our distributed framework for high-quality graph partitioning including the volume metric. Also, it is created for scalable, high-availability, and fault tolerance. Using real-world datasets, we show that VF-Hammer performs a good graph partitioning quality and achieves better performance results against state-of-the-art graph partitioning.},
  archive      = {J_SUPERC},
  author       = {Sakouhi, Chayma and Khaldi, Abir and Ghezala, Henda Ben},
  doi          = {10.1007/s11227-025-07907-2},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Distributed framework for high-quality graph partitioning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-latency and energy-efficient FPGA accelerator for sparse neural networks in edge LiDAR-based 3D object detection. <em>SUPERC</em>, <em>81</em>(15), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07909-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR-based 3D object detection is crucial for accurate, low-latency perception in autonomous driving. However, the irregular sparsity of point clouds and inefficiencies in traditional architectures pose challenges for real-time deployment on embedded platforms. This paper presents a low-latency FPGA accelerator optimized for sparse neural networks. At the algorithm level, we propose adaptive hybrid sparse convolution (AHSC), which uses a lightweight predictor to dynamically choose between feature pruning, submanifold sparse convolution, or standard convolution, balancing accuracy and sparsity. A two-stage quantization scheme further reduces computation and memory footprint. At the hardware level, we co-design an FPGA accelerator with a fast point cloud preprocessing module, hierarchical pillar memory, and an AHSC-optimized compute array using block-wise fixed-weight dataflows. Implemented on the Xilinx ZCU104, the system achieves 58.36 mAP on KITTI, 34.18 ms latency, 6.287 W power, and 5.053 FPS/W, demonstrating state-of-the-art energy efficiency and validating the effectiveness of the algorithm-hardware co-design.},
  archive      = {J_SUPERC},
  author       = {Li, Jinyi and Chen, Yuchen and Yang, Xiaofeng and Hu, Hengrui and Lu, Shengli},
  doi          = {10.1007/s11227-025-07909-0},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Low-latency and energy-efficient FPGA accelerator for sparse neural networks in edge LiDAR-based 3D object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LG-prefetcher: A prefetcher combining local spatial and global performance information for CXL-SSD. <em>SUPERC</em>, <em>81</em>(15), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07910-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging and powerful approach to break through the memory wall, CXL-SSD bridges the performance gap between CPU and memory. To further reduce memory access latency, prefetching techniques have been introduced in the CXL-SSD system. However, modern prefetching techniques are mostly designed for DRAM and conventional storage devices, which are not suitable for predicting CXL-SSD access patterns. We propose a dynamic feedback prefetcher that combines local spatial and global performance information (LG-Prefetcher) for CXL-SSD. It learns some prefetch offsets by analyzing the differences between recent access history records and dynamically adjusts prefetch offset filtering criteria based on global performance of the current prefetcher, providing feedback for the next prefetching to adjust the prefetching range accordingly. Simulation results demonstrate that LG-Prefetcher exhibits superior performance compared to other prefetchers, with average memory access latency reduction of up to 62.86%.},
  archive      = {J_SUPERC},
  author       = {Li, Shibao and Wang, Chengzhi and Yang, Zhou and Zhang, Yunwu and Li, Longfei and Ma, Chenxu and Cui, Xuerong and Li, Lianghai and Liu, Jianhang},
  doi          = {10.1007/s11227-025-07910-7},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {LG-prefetcher: A prefetcher combining local spatial and global performance information for CXL-SSD},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LNBN: Layer-flexible non-blocking bypass network-on-chip for accelerating DNN inference. <em>SUPERC</em>, <em>81</em>(15), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07913-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-device artificial intelligence has increased the importance of energy-efficient inference in resource-constrained environments. Lightweight deep neural networks (DNNs) reduce computational complexity by decreasing the data dimensionality of layers, leading to reduced data reuse, causing global buffer bottlenecks and inadequate routing flexibility in accelerators. We propose the layer-flexible non-blocking bypass network-on-chip (LNBN) architecture, integrating (1) a configurable non-blocking bypass router that adapts to multicast in large-scale DNNs, and parallel transmission in lightweight DNNs; (2) a flexible conflict-free routing algorithm that minimizes congestion and distinguishes concurrently executable traffic through path allocation based on layer dimensionality; (3) a block-based versatile mapping scheme that enables systematic routing with irregular layer structures and increases data reuse. These techniques significantly improve the performance and energy efficiency of DNN accelerators during inference. LNBN enhances network throughput by 23.35%, leading to an18.36% reduction in inference time and a 22.08% improvement in energy efficiency compared with dataflow-flexible DNN accelerator.},
  archive      = {J_SUPERC},
  author       = {Kang, Suk Bong and Kim, Won Hyeok and Han, Tae Hee},
  doi          = {10.1007/s11227-025-07913-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {LNBN: Layer-flexible non-blocking bypass network-on-chip for accelerating DNN inference},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive post-quantum security framework for wireless sensor networks using lightweight cryptography and context-aware key management. <em>SUPERC</em>, <em>81</em>(15), 1--58. (<a href='https://doi.org/10.1007/s11227-025-07916-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) have emerged as a critical technology enabling pervasive monitoring and data collection in diverse domains such as smart cities, industrial automation, health care, and environmental sensing. However, their inherent constraints in energy, computation, and memory, combined with deployment in often hostile or unattended environments, make them highly vulnerable to a wide range of security threats. The imminent rise of quantum computing further exacerbates this challenge by rendering many classical cryptographic schemes obsolete. This paper proposes an adaptive post-quantum security framework for WSNs that leverages lightweight cryptography and context-aware key management to achieve quantum-resistant protection while maintaining resource efficiency. Unlike traditional static security mechanisms, the proposed framework dynamically adjusts cryptographic operations and key lengths in response to real-time network context, including node energy reserves, environmental conditions, detected attack vectors, and communication patterns. At its core, it employs efficient lattice-based encryption algorithms for secure key establishment and lightweight symmetric primitives for data confidentiality and integrity. The context-aware key management protocol optimizes the trade-off between security strength and resource utilization, extending network lifetime without compromising resilience against classical and quantum adversaries. A prototype implementation was evaluated on a representative WSN testbed using off-the-shelf low-power microcontrollers. Experimental results show that the framework reduces energy consumption by 14%, maintains CPU load under 24%, and completes adaptation cycles in under 200 $$\mu$$ s, while significantly improving resilience against quantum-capable attacks. These results demonstrate the practicality of the proposed approach for secure and efficient post-quantum WSN deployments.},
  archive      = {J_SUPERC},
  author       = {Hayouni, Haythem},
  doi          = {10.1007/s11227-025-07916-1},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--58},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive post-quantum security framework for wireless sensor networks using lightweight cryptography and context-aware key management},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CA-DDP: Congestion-aware dynamic dimension prioritization for power-efficient routing algorithm in 3D network-on-chip. <em>SUPERC</em>, <em>81</em>(15), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07918-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In microelectronics, three-dimensional Network-on-Chip (3D NoC) faces critical challenges in balancing performance and power efficiency due to traffic congestion and routing constraints. To address communication bottlenecks in many-core processors—the foundation of high-performance computing (HPC)—we propose the Congestion-Aware Dynamic Dimension Priority (CA-DDP) routing algorithm. CA-DDP performs three-dimensional collaborative optimization of routing paths, integrating adaptive dimension reconfiguration, non-turning diagonal partitioning, and intelligent load distribution. By applying context-aware, region-specific policies, CA-DDP enhances routing decisions, reduces static power, and improves traffic balance. Experiments show a 10.5% reduction in power and an 8.5% drop in peak latency under varied loads, while ensuring deadlock freedom. As a virtual-channel-free solution, CA-DDP offers a cost-effective paradigm for next-generation 3D NoC, achieving low latency, high throughput, and real-time responsiveness for HPC systems.},
  archive      = {J_SUPERC},
  author       = {Li, Jiao and Lu, Junyu and Ran, Feng and Guo, Aiying and Sun, Xuecheng},
  doi          = {10.1007/s11227-025-07918-z},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {CA-DDP: Congestion-aware dynamic dimension prioritization for power-efficient routing algorithm in 3D network-on-chip},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study about the performance of multi-language tools in computation offloading scenarios. <em>SUPERC</em>, <em>81</em>(15), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07921-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational offloading is a common technique used to alleviate the limitations of mobile devices. However, the programming languages used in this process can be inefficient and resource intensive. Multi-language offloading enables computational offloading between processes written with different languages through gRPC with ProtocolBuffers framework. However, there are few published experiments with infrastructures supporting multi-language offloading. This paper evaluates multi-language offloading with two new frameworks: (i) gRPC with FlatBuffers and (ii) Apache Thrift. Tests involved offloading three tasks (sorting integers, multiplying matrices, and filtering images) to remote processes developed in Go, C++, or Java using the aforementioned frameworks. The results validate earlier findings, demonstrating the advantages of adopting a multi-language approach in computational offloading and the significant impact of the network performance, regardless of the framework employed. They also offered new insights, such as the weak performance of gRPC with Protocol Buffers, being the slowest framework in 81% and the most energy consuming in 78% of cases, while Apache Thrift was the fastest framework in 83% and the most energy efficient in 66% of scenarios. The study suggests that Go is the best language to build server processes among the three and Apache Thrift is the preferred framework for multi-language offloading. However, further studies are required with additional devices and programming languages to improve the external validity of this study.},
  archive      = {J_SUPERC},
  author       = {de Matos, Filipe and Rego, Paulo A. L. and Trinta, Fernando and Castor, Fernando},
  doi          = {10.1007/s11227-025-07921-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A comparative study about the performance of multi-language tools in computation offloading scenarios},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hqsan: A hybrid quantum self-attention network for remote sensing image scene classification. <em>SUPERC</em>, <em>81</em>(15), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07922-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid quantum self-attention network (HQSAN) to address the challenge of modeling long-range dependencies in remote sensing image classification, a task where conventional CNNs are often limited. The HQSAN integrates a quantum processing layer (QPL) with a quantum self-attention layer (QSA). The QPL employs amplitude encoding and angle encoding to project features into high-dimensional quantum state space, enabling global feature transformation through parameterized quantum circuits. The QSA leverages quantum entanglement and superposition effects, incorporating all-to-all, ring, and circuit block topological configurations combined with Hadamard gates and controlled rotation gates to achieve long-range dependency modeling. Simulation experiments on PatternNet, RSI-CB256, and RSI-CB128 datasets show promising classification accuracies of 98.09%, 98.57%, and 98.50% respectively, surpassing the performance of traditional models including VGG-16, ResNet, and EfficientNet in the same noiseless setting. This quantum–classical collaborative framework demonstrates the potential to enhance non-local feature interactions, which could significantly improve the accuracy of remote sensing image classification upon future hardware realization.},
  archive      = {J_SUPERC},
  author       = {Wang, Ruiqi and Zhang, Zhongrong and Shen, Yulin and Sui, Zhenghao and Lin, Kang},
  doi          = {10.1007/s11227-025-07922-3},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Hqsan: A hybrid quantum self-attention network for remote sensing image scene classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hierarchical feature fusion and hadamard product LSTM for multivariate time series forecasting. <em>SUPERC</em>, <em>81</em>(15), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07923-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting aims to model dynamic dependencies among temporal variables for accurate future predictions. Despite advances in deep learning, two key issues persist: ineffective dynamic feature weighting leading to overfitting and poor generalization and the inability of LSTMs to integrate multi-scale temporal features, limiting their capacity to capture both short- and long-term patterns. To address these challenges, we propose the Hadamard product LSTM (HPLSTM) model, which integrates an adaptive hierarchical feature fusion mechanism. Specifically, shallow and deep LSTM layers are leveraged to extract low-level and high-level temporal features, respectively—enabling the model to capture both short-term variations and long-term dependencies inherent in the time series. To further enhance the model’s representational capacity and adaptively emphasize informative patterns, Hadamard products are employed to conduct fine-grained feature selection and dynamically modulate the importance of hidden states across different network layers. This dedicated mechanism empowers the model to highlight crucial temporal signals while suppressing irrelevant or redundant information, thereby yielding substantial improvements in overall forecasting performance. Experimental evaluations on nine real-world datasets demonstrate that HPLSTM consistently outperforms baseline models. Compared with state-of-the-art approaches in the field, our proposed HPLSTM achieves an average reduction of 8.9% in Mean Squared Error (MSE) and 3.9% in Mean Absolute Error (MAE), validating its superiority in multivariate time series forecasting tasks.},
  archive      = {J_SUPERC},
  author       = {Yang, Yaoyuan and Zhao, Chunna and Huang, Yaqun},
  doi          = {10.1007/s11227-025-07923-2},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive hierarchical feature fusion and hadamard product LSTM for multivariate time series forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-driven security framework for SDN-IoT networks: Integrating multi-headed self-attention with TB-SMOTE and attention-driven transfer learning. <em>SUPERC</em>, <em>81</em>(15), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07925-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networks offer scalable, high-speed data transmission for IoT and 5 G ecosystems but face cross-layer vulnerabilities due to dynamic infrastructure changes. Present intrusion detection system that utilizes deep learning struggles with imbalanced datasets, zero-day attack detection, and feature extraction inefficiencies in heterogeneous SDN-IoT environments. This study introduces a novel Transformer-based Multi-head Self-Attention Module (TMSAM) framework, integrating three key components: (i) to improve detection accuracy of Cross-Layer Feature Aggregation and reduce false positives in large-scale networks. (ii) To mitigate class imbalance and enhance the system’s generalization capacity using an integrated sampling technique called Tomek Borderline-Synthetic Minority Oversampling Technique (TB-SMOTE) for training samples, and (iii) Attention-Driven Transfer Learning (ATL) for swift model adaptation. Experiments on the InSDN and SDNFlow datasets show that TMSAM achieves 99.41% detection accuracy, with TB-SMOTE improving generalization by 0.3%, ATL reducing training time by 62% and quantization reduced the memory usage by $$\sim$$ 40% reduction. The computational demands of Transformer architectures and large-scale flow analysis necessitate high-performance computing with parallel and distributed processing. By leveraging these capabilities, TMSAM supports real-time, scalable intrusion detection in 5 G-IoT networks, offering improved resilience against polymorphic and adversarial attacks.},
  archive      = {J_SUPERC},
  author       = {Benitha Christinal, J. and Ameelia Roseline, A .},
  doi          = {10.1007/s11227-025-07925-0},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Transformer-driven security framework for SDN-IoT networks: Integrating multi-headed self-attention with TB-SMOTE and attention-driven transfer learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid event-triggered network-based synchronization of MSRDNNs with additive mode-dependent time-varying delays. <em>SUPERC</em>, <em>81</em>(15), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07926-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronization of neural networks (NNs) finds applications in various fields such as optimized intelligent computation, image encryption and information science. In this paper, a switching-based distributed spatiotemporal event-triggered method is proposed to address the synchronization control issue for Markovian switching neural networks subject to reaction–diffusion terms and additive mode-dependent time delays. The synchronization scheme focused on networked control, where the network-induced delays and spatiotemporal sampling are occurred. In addition, the delays are admitted to be longer than time sampling intervals. Combining input delay and dynamic delay interval ideas, by means of Wirtinger’s inequality, free weighting matrices and mutually convex combination techniques, synchronization criteria LMIs based are established, which can guarantee the synchronization of state trajectories for the considered NNs via a switching-based event-triggered approach under spatiotemporal sampling. The given examples are shown to support efficiency and potential synchronization mechanism.},
  archive      = {J_SUPERC},
  author       = {Zhang, Weiyuan and Li, Junmin and Zhang, Rui and Xing, Keyi},
  doi          = {10.1007/s11227-025-07926-z},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {Hybrid event-triggered network-based synchronization of MSRDNNs with additive mode-dependent time-varying delays},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensitivity analysis of advanced sleep mode energy-saving approach for cognitive radio networks using MAP/PH/1 G-queue model. <em>SUPERC</em>, <em>81</em>(15), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07928-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency in cellular networks has recently received more attention due to its environmental benefits and operational cost reductions. Also, the third-generation partnership project’s new radio specification aims to reduce energy consumption and greenhouse gas emissions in fifth-generation (5G) and future networks, supporting information and communication technology (ICT) sustainability targets. In this article, advanced sleep mode (ASM) as an energy-saving approach is proposed for the cognitive radio networks (CRN) of 5G and future networks, in which base station (BS) progressively enters into profound and less energy-consuming states during inoperative periods. In addition, the energy-saving approach is implemented on the heterogeneous and unreliable CRN using the discrete-time MAP/PH/1 priority G-queue model. Then, by modeling the entire system as a three-dimensional Markov chain, we conduct the system’s transient and steady-state analysis using the recursive and matrix analytic methods, respectively. So, in this work, high-performance computing is employed to efficiently handle large-scale matrix operations involving numerous states at the base station under heterogeneous CRN traffic. Thereafter, we randomly simulate the numerical results of various performance metrics with the transient and steady-state probability vector to provide validation of the proposed model as well as a comparison with the existing models. From the comparison plots, we present the impact of modeling CRN with the MAP/PH/1 queue model and the effect of reliability on the system’s performance metrics. Subsequently, a sensitivity analysis of the degree of energy savings is performed using the Monte Carlo simulation with a correlation-based method. Finally, a multi-objective analysis is carried out to explore the trade-off between the system’s quality of service and the degree of energy savings using Non-dominated Sorting Genetic Algorithm II and Multi-Objective Particle Swarm Optimization techniques.},
  archive      = {J_SUPERC},
  author       = {Singh, Ajay and Kulshrestha, Rakhee},
  doi          = {10.1007/s11227-025-07928-x},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Sensitivity analysis of advanced sleep mode energy-saving approach for cognitive radio networks using MAP/PH/1 G-queue model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new progressive belief rule-based model for imbalanced multi-classification. <em>SUPERC</em>, <em>81</em>(15), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07929-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem significantly impacts the performance of classification models due to differences in class frequencies. The belief rule base (BRB) is an interpretable classification model, where expert knowledge is incorporated, making it particularly effective in small-sample scenarios for alleviating the adverse effects of class imbalance, though its reasoning mechanism is often associated with high computational complexity. To leverage BRB for small-sample imbalanced multi-classification tasks, a progressive belief rule base (P-BRB) designed for parallel computing is proposed. The model performs classification progressively through a three-layer structure. First, the equilibrium layer applies multi-round, parallelizable ensemble undersampling combined with consistency constraints to reduce redundant samples while balancing class distributions and preserving key information. Second, the fusion layer employs the evidential reasoning (ER) rule to integrate the outputs of undersampled sub-models, providing more reliable coarse classification results. Finally, the binary classification layer further refines the coarse outputs by distinguishing adjacent classes. During training, optimization of undersampled sub-models can be executed in parallel; during inference and fusion, parallel reduction is adopted to significantly enhance computational efficiency. The proposed model is evaluated on five imbalanced benchmark datasets and two fault diagnosis tasks. Experimental results demonstrate that P-BRB excels in small-sample imbalanced classification, achieving superior minority class recognition and overall performance compared with baseline methods; moreover, its multi-round undersampling and fusion process exhibit strong parallelization potential, indicating feasibility for further efficiency gains in HPC environments.},
  archive      = {J_SUPERC},
  author       = {Li, Ning and Li, Yingmei and He, Wei and Niu, Yimeng and Guo, Naijia},
  doi          = {10.1007/s11227-025-07929-w},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {A new progressive belief rule-based model for imbalanced multi-classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient utterance-level context-aware fusion architecture for large-scale audio-text sentiment analysis. <em>SUPERC</em>, <em>81</em>(15), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07930-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of next-generation Intelligent Information Systems (IIS), such as large-scale customer service platforms, critically depends on their ability to understand human sentiment from massive, unstructured multimedia data streams. Processing this data in real-time presents a significant computational challenge, necessitating architectures that are both accurate and scalable. The training of such deep models on extensive datasets inherently requires high-performance computing (HPC) resources, while their deployment for low-latency inference at scale relies on parallel processing. To address this need, we propose UL-CAFNet (Utterance-Level Context-Aware Fusion Network). Our framework introduces a Utterance-Level Contextual Attention module that synergistically integrates attention mechanisms with convolutional layers, enabling the simultaneous modeling of global context and local structural patterns. Furthermore, we develop a deep cross-modal fusion mechanism with multi-layer iterative refinement, which is designed to facilitate robust alignment between audio and text representations. Experiments on the CMU-MOSI and CMU-MOSEI datasets show that our framework achieves a new state-of-the-art performance. The effectiveness of our design is further validated by comprehensive ablation studies and robustness analyses.},
  archive      = {J_SUPERC},
  author       = {Wei, Yuanxi and Chen, Jinpeng},
  doi          = {10.1007/s11227-025-07930-3},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {An efficient utterance-level context-aware fusion architecture for large-scale audio-text sentiment analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple artifacts detection based on channel masking and multi-feature domain semi-supervised network. <em>SUPERC</em>, <em>81</em>(15), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07932-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been increasingly applied in electroencephalogram (EEG) artifact research. However, existing research is generally limited to detecting specific types of artifacts and suffers from a shortage of labeled data. To address these issues, a multi-artifact detection method based on channel masking and a semi-supervised network across multiple feature domains was proposed in this paper. Firstly, the channel correlations of five different types of artifacts were analyzed, and their features were utilized to re-label and mask the channel tags. Then, a semi-supervised network with an attention mechanism was used to learn features from various feature domains in the data. Finally, a custom multi-class loss function was applied to further enhance the model’s focus on artifacts, aiming to reduce the impact of noisy labels. The EEG data used in this study were collected from patients diagnosed with benign epilepsy with centro-temporal spikes (BECTS) and sourced from the dataset provided by the Children’s Hospital of Zhejiang University School of Medicine (CHZU). Compared with recent multi-artifact detection approaches and commonly used classification loss functions, the proposed method achieved the shortest training time and an average inference latency of 35.52 ms per 1-second EEG segment, enabling real-time processing in continuous EEG monitoring scenarios. Moreover, it obtained an F1 score of 90.99% and a recall of 86.32%.},
  archive      = {J_SUPERC},
  author       = {Hu, Dinghan and Wang, Huijun and Gao, Feng and Lou, Xiaohui and Xie, Zuonian and Cao, Jiuwen},
  doi          = {10.1007/s11227-025-07932-1},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Multiple artifacts detection based on channel masking and multi-feature domain semi-supervised network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A walrus optimization algorithm for sustainable internet of robotic things based on Q-learning. <em>SUPERC</em>, <em>81</em>(15), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07933-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Robotic Things (IoRT) integrates cloud robotics, artificial intelligence, and the Internet of Things to work collaboratively and is popularly employed in various autonomous systems. However, these devices often struggle to meet real-time applicability due to limited battery, low computational capability, and high latency, which necessitate high-performance computing and distributed architectures. Therefore, the present work develops an efficient task offloading mechanism by considering a multi-objective optimization approach to reduce energy consumption based on sampling rate, transmission interval, and data processing while achieving the deadline constraints and load balancing. The methodology is executed via fog computing to lower the communication overhead among edge devices and the cloud. Further, the Q-learning approach is integrated with the walrus optimization algorithm to develop QWaOA. This integration helps improve the balance between exploration–exploitation by incorporating the intelligence of reinforcement learning. The effectiveness of the proposed work is confirmed by simulations, which show that the proposed strategy reduces the energy requirements by at least 27.14% compared to existing methods. The experimental findings validate the proposed schema compared to other existing approaches in enhancing the performance of IoRT devices.},
  archive      = {J_SUPERC},
  author       = {Varshney, Hirdesh and Singh, Avtar},
  doi          = {10.1007/s11227-025-07933-0},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A walrus optimization algorithm for sustainable internet of robotic things based on Q-learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced blockchain-based mutual authentication technique for the internet of vehicles environment. <em>SUPERC</em>, <em>81</em>(15), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07934-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet of vehicles (IoV), an evolution of vehicular ad hoc networks (VANETs), enhances vehicular intelligence and connectivity by enabling secure vehicle-to-vehicle and vehicle-to-infrastructure communication. However, the dependence on open wireless channels makes IoV vulnerable to attacks, such as replay attacks, impersonation attacks, and man-in-the-middle attacks, while most existing authentication schemes depend on a single trusted authority (TA), leading to scalability and performance bottlenecks. To overcome these limitations, this article proposes a lightweight and privacy-preserving mutual authentication and key agreement protocol that combines elliptic curve cryptography (ECC) with a consortium blockchain. In the proposed scheme, multiple TAs jointly maintain the ledger, while the road side unit (RSU) serves as a validator and the zone manager (ZM) provides localized supervision, ensuring decentralization and scalability. Furthermore, smart contracts enforce validation rules automatically, reducing the dependence on centralized control and enhancing trust. The security of the proposed model is analyzed and validated using the real-or-random (ROR) model and the AVISPA tool. Finally, performance evaluation demonstrates reduced latency, computation, and communication costs compared to related works, confirming that the proposed protocol ensures secure, scalable, and efficient authentication suitable for real-world IoV environments.},
  archive      = {J_SUPERC},
  author       = {Namasudra, Suyel and Das, Sangjukta and Datta, Sagnik and Crespo, Ruben Gonzalez and Taniar, David},
  doi          = {10.1007/s11227-025-07934-z},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {An advanced blockchain-based mutual authentication technique for the internet of vehicles environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LDD-CAP: Lightweight defect detection algorithms for class a priori. <em>SUPERC</em>, <em>81</em>(15), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07936-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial defect detection scenarios necessitate the use of efficient inference networks. However, high-precision segmentation algorithms utilizing self-attention mechanisms often face challenges related to quadratic complexity and prolonged inference times. To address these issues, this manuscript proposes LDD-CAP, a lightweight defect detection network featuring a dual-branch architecture and incorporating class prior information. To achieve optimal detection performance while balancing model size and inference speed, this study introduces an efficient category prior network (ECPN) designed to serve as the feature extraction backbone for the segmentation algorithm, effectively capturing a comprehensive combination of spatial and channel features. Specifically, to enhance semantic feature representation while simplifying computation, a Split Depth Mixed External Attention (SDMEA) strategy is proposed. Additionally, to strengthen the attention pairwise affinity toward defective samples, a Supervised Attention Focusing (SAF) method is introduced, which imposes hard constraints on category-level feature distributions, thereby enhancing global information parsing while extracting local features. Finally, a Dual Branch Segmentation Architecture (DBSA) is employed to produce the segmentation output. Experiments on three defect detection datasets demonstrate that the proposed LDD-CAP network outperforms state-of-the-art models in both mean Intersection-over-Union (mIoU) and mean Accuracy (mAcc) (NEU-seg: 88.49%, Magnetic-Tile: 87.00%, FSSD-12: 91.12%), confirming its effectiveness. Additionally, its lightweight structural design facilitates the efficient deployment of the model on high-performance computing platforms in industrial settings, enabling real-time industrial defect detection across large volumes of data, thus enhancing production efficiency and product quality.},
  archive      = {J_SUPERC},
  author       = {Shi, Dunhuang and Zhang, Tao and Duan, Yuntao},
  doi          = {10.1007/s11227-025-07936-x},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {LDD-CAP: Lightweight defect detection algorithms for class a priori},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimpDepth: A simple CNN-transformer architecture for self-supervised monocular depth estimation in autonomous vehicles. <em>SUPERC</em>, <em>81</em>(15), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07937-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised monocular depth estimation offers a practical solution for autonomous vehicles by eliminating dependency on ground truth data in training. However, existing methods often prioritize accuracy at the cost of computational efficiency, limiting their deployment on resource-constrained edge devices. To address this gap, we propose a novel hybrid architecture combining a simplified transformer with a convolutional neural network (CNN). The development and training of such models necessitate high-performance computing (HPC) resources for large-scale data processing and rapid experimentation. Our approach integrates a simplified transformer with a CNN to build a hybrid model that reduces computational complexity while retaining robust spatial reasoning capabilities. This approach enables a compact model design that significantly reduces computational cost compared to conventional approaches. For autonomous driving application, we validate our framework on the KITTI dataset, demonstrating competitive depth estimation accuracy against state-of-the-art methods. By achieving strong performance with reduced computational demands, our work provides a viable pathway for deploying efficient depth estimation models in real-world autonomous vehicle systems.},
  archive      = {J_SUPERC},
  author       = {Forouzesh, Arman and Nikoofard, Amirhossein},
  doi          = {10.1007/s11227-025-07937-w},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {SimpDepth: A simple CNN-transformer architecture for self-supervised monocular depth estimation in autonomous vehicles},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum-assisted cardiac diseases diagnosis and prediction using ECG images. <em>SUPERC</em>, <em>81</em>(15), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07939-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVD) have emerged as a leading cause of morbidity and mortality globally due to sedentary lifestyles and other inactive habits. Advancements in deep learning methods have markedly improved medical diagnostics; however, some challenges, such as lack of labeled datasets, high computational requirements, and limited interpretability, still persist and affect their usability, particularly in ECG-based cardiac disease prediction. In this study, we leverage the emerging capabilities of quantum machine learning (QML) to perform both multiclass and binary CVD classification across multiple datasets. Notably, two QML techniques are implemented, namely, the quantum support vector machine (QSVM) and the quantum convolution neural network (QCNN), and their performance is compared against their classical counterparts and other baseline methods under identical experimental conditions. Training and testing these models demand advanced computational resources because of the rapid growth in quantum circuit states, the high cost of constructing kernel matrices, and the large number of parallel circuit runs needed for gradient estimation. All of these factors require parallel and distributed execution on high-performance platforms to maintain practical run time and support latency-sensitive clinical decision-making. Extensive experimentation is carried out using IBM’s Qiskit library, and results show that QCNN outperformed classical CNN by approximately 5% achieving accuracies of 95.3%, 95.6%, and 96.5% across different datasets. Similarly, QSVM surpasses classical SVM by approximately 8% with 91.3%, 93.10%, and 95.20% accuracies, respectively. Beyond precision, cross-dataset validation, ablation study, error analysis, and statistical analysis are performed to validate the outcomes.},
  archive      = {J_SUPERC},
  author       = {Jain, Vibha and Arora, Nitin and Gupta, Aditya},
  doi          = {10.1007/s11227-025-07939-8},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Quantum-assisted cardiac diseases diagnosis and prediction using ECG images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMed-XAI: A collaborative and trustworthy framework for skin cancer detection using federated learning and explainable AI. <em>SUPERC</em>, <em>81</em>(15), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07941-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has appeared as a transformational technology in the medical imaging domain, offering powerful capabilities for complex diagnostic tasks. DL-based models, in particular, have greatly aided skin cancer diagnosis due to their capacity to understand complex patterns from large-scale image datasets. One of the major problems about DL models is their black-box character, which makes their decision-making processes difficult for doctors to understand or trust. This lack of transparency and concerns over the privacy of sensitive medical data present significant obstacles for deploying AI solutions in real-world healthcare environments. To handle the privacy constraints connected with centralized data training, federated learning (FL) has been introduced as a decentralized approach enabling organizations to train models collaboratively without transferring patient’s raw data. Although, while FL addresses privacy, the challenge of interpretability remains crucial in medical diagnostics. To address these issues, this research introduces FedMed-XAI, a collaborative and trustworthy framework that integrates FL and explainable AI (XAI) within a high-performance computing (HPC)-enabled environment to develop a privacy-preserving and interpretable AI system for skin cancer classification. Using the Skin Cancer MNIST: HAM10000 dataset, our framework was deployed across 20 decentralized clients over 200 communication rounds. The large-scale training and distributed nature of FL necessitate supercomputing resources to efficiently handle parallel processing, real-time performance requirements, and communication overhead across clients. Utilizing distributed HPC power, our framework not only ensures privacy and interpretability but also achieves scalability for real-world medical applications.},
  archive      = {J_SUPERC},
  author       = {Gupta, Mansi and Kumar, Mohit and Dhir, Renu},
  doi          = {10.1007/s11227-025-07941-0},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {FedMed-XAI: A collaborative and trustworthy framework for skin cancer detection using federated learning and explainable AI},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating intrusion attacks in VANETs through reliable communication with graph-based deep learning approaches. <em>SUPERC</em>, <em>81</em>(15), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07945-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of connected vehicles in vehicular ad-hoc networks (VANETs), with frequent data exchanges between vehicles and roadside units (RSUs) enhances traffic efficiency but also increases the attack surface, as adversaries can exploit the high communication density to launch malicious activities. Specifically, attacks such as denial-of-service (DoS), where attackers flood the RSU with excessive packets or fake requests, under dense traffic conditions where each vehicle already transmits periodic safety messages, this artificial load quickly overwhelms the RSU processing capacity, leading to congestion and service disruption. To mitigate such risks, intrusion detection systems (IDSs) are essential, as they monitor network traffic in real time, identify malicious patterns, and prevent attacks before they compromise critical services. Existing deep learning-based IDSs algorithm often treat these threats in isolation, overlooking the semantic relationships among different attack types. To address this gap, we propose a novel knowledge graph-based deep convolutional neural network (KG-DeepCNN) IDS for securing VANETs. The proposed IDS is deployed at the RSU level (RSU-IDS), where incoming vehicle and packet information are analyzed to distinguish legitimate requests from malicious ones, thereby strengthening vehicle-to-vehicle (V2V) communication security. The knowledge graph enriches raw data by capturing semantic correlations among attack patterns, which are then processed by an ensemble of CNN learners with diverse architectures for improved classification accuracy. The framework is evaluated on four benchmark datasets—BoT-IoT, ToN-IoT, UNSW-NB15, and NSL-KDD—achieving accuracies of 99%, 98%, 98%, and 99%, respectively. Notably, the model improves detection accuracy on the UNSW-NB15 dataset by 2.01% compared to state-of-the-art approaches, demonstrating its robustness and scalability for VANET security.},
  archive      = {J_SUPERC},
  author       = {Kumari, Ashish and Kumar, Shailender},
  doi          = {10.1007/s11227-025-07945-w},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Mitigating intrusion attacks in VANETs through reliable communication with graph-based deep learning approaches},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlation aware solution for merging small files based on similarity and clustering in HDFS. <em>SUPERC</em>, <em>81</em>(15), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07946-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In distributed processing environments and High-Performance Computing (HPC) systems, Hadoop Distributed File System (HDFS) is a popular open-source solution for storing and managing a massive number of files. However, both in traditional Hadoop-based data processing and in HPC environments integrating big data workloads, HDFS faces several issues when it comes to handling a large amount of small files. To overcome this drawback, we propose a new strategy CHAC (for Correlation and Hierarchical Ascending Clustering) dealing with the small files problem. The major contribution of our strategy is that considering correlations between small files is the criterion used in the merging process into large files. For this purpose, several criteria such as file size, requests number and requesting clients are taken into account through analyzing the user access pattern. In the current version of our proposal, a formula inspired from information retrieval is used to quantify the weight of each small file. Moreover, a Cosine similarity-based method coupled with a hierarchical ascending clustering algorithm is used as a shrewd grouping tool of correlated small files. To demonstrate the effectiveness of CHAC, a series of experiments were performed over ten distinct datasets. Compared with other solutions, the obtained results highlight that our proposal offers interesting performances for reducing the number of obtained large files as well as the NameNode memory consumption and consumes approximately 55% less memory than HPF. CHAC also optimizes the use of the DataNodes storage space by increasing the average disk utilization of data blocks. In most cases, our strategy uses about 98% of the data blocks size. Moreover, it reduces the storage time taken to store large files. As our solution is based on file correlations, an in-depth analysis of the quality of the obtained large files is carried out highlighting the effectiveness of CHAC.},
  archive      = {J_SUPERC},
  author       = {Chettaoui, Hanène and Hkiri, Farah},
  doi          = {10.1007/s11227-025-07946-9},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Correlation aware solution for merging small files based on similarity and clustering in HDFS},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSP-YOLO: An efficient and lightweight real-time algorithm for internal rail defect detection. <em>SUPERC</em>, <em>81</em>(15), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07949-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limited adaptability of existing rail internal defect detection algorithms on low-power, low-memory flaw detection devices, this paper proposes CSP-YOLO-a real-time detection algorithm based on an improved YOLOv8. First, a data augmentation strategy tailored to the characteristics of rail B-scan images is developed to expand the defect dataset and improve the algorithm’s robustness and generalization. Second, inspired by GhostNet and incorporating the GhostConv module, the proposed C2f-GG (C2f with GhostNet and GhostConv) module reduces model complexity and increases detection speed. Third, the SPPF-CA (SPPF with Coordinate Attention) module, which integrates a coordinate attention mechanism, is introduced to enhance focus on defect regions and suppress background noise, considering the strong spatial correlation of defects in B-scan images. Fourth, the P5 large-object detection head is removed to better support small-object detection. Meanwhile, the P3--P4 detection head is replaced with the Independent Normalization Shared Convolution Head (INSCH) to enhance multi-scale feature extraction and further simplify the model. Finally, a layer-adaptive pruning technique is employed to further simplify deployment. Experimental results show that the proposed algorithm reduces the number of parameters and computational cost by 93.69% and 74.07%, respectively, with only a 0.1% drop in average precision (mAP@0.5). In addition, detection speeds (Frames Per Second, FPS) on CPU and GPU increase by 74.07% and 92.79%, respectively, enabling real-time detection for railway applications.},
  archive      = {J_SUPERC},
  author       = {Wu, Xiaochun and Yu, Shuzhan},
  doi          = {10.1007/s11227-025-07949-6},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {CSP-YOLO: An efficient and lightweight real-time algorithm for internal rail defect detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient human pose keypoint detection algorithm base on YOLOv8. <em>SUPERC</em>, <em>81</em>(15), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07953-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keypoint detection is a core task in the visual domain, facing challenges such as occlusion, false detection, and complex poses. To address these issues, an efficient keypoint detection algorithm, EKD-YOLO, based on the YOLOv8s model, is proposed. Firstly, in case of enhancing the model’s feature fusion capability, the Fusion-Neck architecture is depicted to replace the original Neck part of YOLOv8. Secondly, for the purpose of improving model efficiency, the feature extraction module has been optimized by proposing a more lightweight C2fiAFF module and introduces the SCDown module. Furthermore, in order to improve accuracy and precision, an efficient attention mechanism, C2iEMA is designed. Experimental data indicate, compared to the YOLOv8s model, the improved EKD-YOLO algorithm achieved a 2.5% increase in mAP@0.5, a 4% improvement in P%, and a reduction in FLOPs and parameter count. The overall performance of the model was enhanced. Our code and models are available at https://github.com/geleerde/EKD-YOLO .},
  archive      = {J_SUPERC},
  author       = {Yang, Shengqi and Liu, Haiying and Du, Yifeng and Sun, Tao and Wang, Chaoqun and Lin, Fei and Liu, Lida},
  doi          = {10.1007/s11227-025-07953-w},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {An efficient human pose keypoint detection algorithm base on YOLOv8},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smooth gradient loss: A loss function for gradient regularization in deep learning optimization. <em>SUPERC</em>, <em>81</em>(15), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07954-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss functions are pivotal in deep learning optimization, directing the model training process by measuring the discrepancy between predicted and actual values. The smooth gradient loss (SGL) function is introduced as an innovative approach to enhance the stability and robustness of deep learning optimization. Traditional loss functions, such as Mean Squared Error (MSE) and Mean Absolute Error (MAE), often exhibit sensitivity to outliers and gradient instability, which can hinder performance in large-scale applications. SGL addresses these issues by incorporating a gradient penalty term, which encourages smoother and more stable gradient updates. Empirical evaluations on benchmark datasets, including MNIST and CIFAR-10, demonstrate that SGL not only accelerates convergence but also enhances generalization performance. Importantly, SGL requires efficient computation of second-order information (Hessian–vector products), which is practical only with high-performance computing (HPC) resources and parallelized training frameworks. This connection highlights the suitability of SGL for supercomputing environments, especially in large-scale and real-time applications such as autonomous systems, medical imaging, and recommendation engines. Theoretical analysis further confirms the benefits of SGL in maintaining gradient stability, positioning it as a robust and HPC-relevant contribution to the field of deep learning optimization.},
  archive      = {J_SUPERC},
  author       = {Dwivedi, Pulkit and Islam, Benazir and Kajal, Mansi},
  doi          = {10.1007/s11227-025-07954-9},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {Smooth gradient loss: A loss function for gradient regularization in deep learning optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CommentAgent: A LLM-powered agent framework for automated comment generation and opinion understanding. <em>SUPERC</em>, <em>81</em>(15), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07957-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality Chinese datasets for public opinion analysis are scarce, with most resources based on outdated English-language platforms like Twitter and Reddit, which are not relevant to Chinese social media. To address this, we introduce CommentAgent, a novel simulation framework that generates high-quality Chinese datasets for sentiment analysis, sarcasm detection, and stance detection. CommentAgent simulates the Weibo environment using a multi-agent architecture that models user behavior, information flow, and personality evolution, allowing for realistic and diverse comment generation. Unlike traditional data augmentation or basic generation methods, CommentAgent generates topic-driven data from scratch. Three benchmark datasets are released for the above tasks, with extensive experiments demonstrating that CommentAgent outperforms existing methods in data quality and generalizability. Moreover, lightweight models trained on these datasets achieve performance comparable to large language models (LLMs). CommentAgent offers a scalable solution for creating up-to-date Chinese datasets for robust public opinion analysis.},
  archive      = {J_SUPERC},
  author       = {Han, Xiao and Sun, Jingyun and Yu, Songhua and Qin, Libo and Luo, Hui and Li, Yang},
  doi          = {10.1007/s11227-025-07957-6},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {CommentAgent: A LLM-powered agent framework for automated comment generation and opinion understanding},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing e-commerce logistics efficiency and sustainability via quantum computing and artificial intelligence-based quantum hybrid models. <em>SUPERC</em>, <em>81</em>(15), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07959-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how quantum computing, quantum algorithms, and AI-quantum hybrid models enhance logistics efficiency and sustainability in e-commerce. Logistics optimization is analyzed to improve routing, scheduling, and resource allocation. The mixed-method design combines a cross-sectional survey of professionals with semi-structured interviews. Quantitative data were analyzed using structural equation modeling in SmartPLS, and qualitative data were thematically assessed. A perception-based analysis examined how professionals perceive quantum-based logistic models compared to traditional AI-driven approaches. Professionals believe that these models can enhance logistics optimization, increasing efficiency and sustainability. Respondents perceived that quantum models could outperform AI-driven approaches, particularly in routing and freight scheduling, but highlighted high implementation costs, limited expertise, and cross-industry collaboration. Logistic optimization mediates the relationship between quantum technology and performance outcomes. This study provides empirical evidence on industry perceptions and strategic guidance for firms considering quantum logistics. Quantum-enabled logistics enhance operational performance and support global sustainability goals. The findings underscore the opportunities and challenges of quantum logistics, offering guidance for research and adoption strategies.},
  archive      = {J_SUPERC},
  author       = {Khan, Muhammad and Amin, Farhan and Din, Minhaj Ud and Abid, Muhammad Ali and de la Torre, Isabel and Montero, Elisabeth Caro and Noya, Irene Delgado},
  doi          = {10.1007/s11227-025-07959-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing e-commerce logistics efficiency and sustainability via quantum computing and artificial intelligence-based quantum hybrid models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FABLSTM: An optimal resource allocation in SDVN networks with contextual variables integration. <em>SUPERC</em>, <em>81</em>(15), 1--63. (<a href='https://doi.org/10.1007/s11227-025-07962-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource allocation in Software-Defined Vehicular Networks (SDVNs) remains a major challenge due to the dynamic and heterogeneous nature of vehicular environments. Traditional methods often fall short in accurately predicting resource demands under fluctuating traffic conditions, particularly when contextual factors are overlooked. In this paper, we propose a novel Federated Adaptive Attention-based Bidirectional Long Short-Term Memory (FABLSTM) model to enhance resource prediction and task allocation in SDVNs. Each local controller employs an ABLSTM network to estimate resource needs within its subnetwork, while the federated learning structure enables decentralized training and knowledge aggregation across the network. By integrating contextual variables and long-term traffic patterns through an adaptive attention mechanism, the model achieves higher adaptability to real-world dynamics. Simulation experiments based on urban traffic data from Tehran show that the FABLSTM approach outperforms baseline methods, achieving a 13.64% reduction in energy consumption, a 13.72% decrease in response time, and an 18.92% increase in throughput. These results demonstrate the model’s efficiency in managing computational, memory, and bandwidth resources under varying traffic loads. The proposed framework provides a scalable and intelligent solution for optimizing resource allocation in SDVNs. Furthermore, the large-scale and real-time nature of SDVN environments, characterized by massive vehicular data streams and distributed control layers, inherently requires high-performance computing (HPC) and parallel processing capabilities. The proposed FABLSTM framework is designed to be aligned with this paradigm, ensuring scalability and timely decision-making.},
  archive      = {J_SUPERC},
  author       = {Matinfar, Ehsan and Mahmoudi, Marjan and Payamani, Abbas and Maghami, Elham and Janbozurgi, Mohammad and Barekatain, Behrang},
  doi          = {10.1007/s11227-025-07962-9},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--63},
  shortjournal = {J. Supercomput.},
  title        = {FABLSTM: An optimal resource allocation in SDVN networks with contextual variables integration},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient design of priority encoder-based median filter in QCA for impulse noise reduction. <em>SUPERC</em>, <em>81</em>(15), 1--16. (<a href='https://doi.org/10.1007/s11227-025-07963-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing, especially medical image processing, has gained huge research attention in the past decades. In case of medical imaging, huge refinement in image is not acceptable. Impulse noise reduction from specific pixels and normalization of blurring effect to enhance the resolution and contrast is the only need with no change in actual image. Hence, median filter is one of the well acceptable digital filtering techniques to be used in medical image processing for spot noise reduction. In the present work, the median filter based on one-hot encoding is designed in Quantum Cellular Automata (QCA) software on the basis of the majority gate concept. The one-hot coding is implemented using priority encoding technique. A basic unit with a total of four majority gates has been used to design a 1-bit median filter with 3 × 3 window. The design consists of 21 cells only with nine individual inputs. For implementation median filters with higher number of bits, 2n numbers of basic units with 9 × n numbers of inputs are needed, where n is the number of bits. Therefore, to implement 2-bit and 4-bit median filters, 4 and 16 numbers of basic units with 84 and 336 numbers of QCA cells are, respectively, deputed, whereas the number of inputs given is 36 and 144, respectively. However, the delay of the filter circuit is 0.5 clock cycle in each case irrespective of number of bits. Hence, the circuit is very fast. Moreover, it is a coplanar design with no crossover. In fact, the proposed 1-bit median filter needs a very low-energy consumption of 22.95 meV only. The energy consumption by 2-bit and 4-bit filters is expected to be proportional to the number of bits. After analyzing all the essential parameters, it can be noted that the proposed filter circuit design can be implemented for the faster filtering operation in near future.},
  archive      = {J_SUPERC},
  author       = {Kush, Lav and Singh, Satyendra Kumar and Kumar, Madhukar and Ranjan, Prem and Hazra, Purnima},
  doi          = {10.1007/s11227-025-07963-8},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {Energy-efficient design of priority encoder-based median filter in QCA for impulse noise reduction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AraBERT-QC: A novel quantum-based classification architecture to classify short arabic sentences. <em>SUPERC</em>, <em>81</em>(15), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07966-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of quantum computing to analyze text is still at a nascent stage, especially when dealing with low-resource languages like Arabic, which has a notably intricate structure. The current state of quantum technology still limits the development of powerful models for processing Arabic text. This paper introduces AraBERT-QC, a novel hybrid model that integrates the Arabic language model AraBERT with a quantum classifier. We leverage AraBERT to generate contextualized sentence embeddings that capture the semantic structure of Arabic text, which are subsequently processed by the quantum classifier. Our experimental study is structured in two parts. The first part investigates the impact of various quantum data embedding techniques on the accuracy and efficiency of the quantum support vector machine (QSVM) algorithm. The second part explores the performance and efficiency trade-offs between two hybrid quantum-classical approaches: Hybrid quantum-classical neural networks (H-QNN) and the variational quantum classifier (VQC). We evaluate our architecture on two distinct datasets, sarcasm detection and sentiment analysis, using metrics such as accuracy, macro F1-score, precision, recall, and computation time. Results show that complex quantum embeddings achieve better performance in some tasks, while the VQC trains faster than the H-QNN. Notably, AraBERT-QC achieves 86.25% accuracy in sarcasm detection and 84.33% in sentiment analysis, outperforming the classical SVM and neural network baselines by up to 2% in accuracy and F1-score. This study highlights the potential of integrating quantum techniques with classical models to tackle challenges in computational linguistics, particularly for morphologically rich languages.},
  archive      = {J_SUPERC},
  author       = {Djemmal, Islam and Belhadef, Hacene},
  doi          = {10.1007/s11227-025-07966-5},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {AraBERT-QC: A novel quantum-based classification architecture to classify short arabic sentences},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient domination problem: A quantum computing approach. <em>SUPERC</em>, <em>81</em>(15), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07967-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G(V, E), a dominating set D is a subset of V in which every vertex not in D is adjacent to at least one vertex in D. The concept of Efficient Domination (ED) introduces a variation of domination in a graph, ensuring that every vertex is dominated by exactly one vertex from the dominating set. This concept has been extended to Bi-Efficient Domination (BED), where each vertex is dominated by exactly two vertices in the dominating set. This paper presents a QUBO formulation for the efficient domination problem and transforms it into a Hamiltonian that is well-suited for quantum computing. The approach leverages the Quantum Approximate Optimization Algorithm (QAOA) to solve the problem. Additionally, the paper presents the results of a similar quantum-based approach applied to the bi-efficient domination problem, showcasing the effectiveness of quantum techniques. By bridging graph theory and quantum computing, this work provides a foundation for leveraging quantum algorithms to solve complex domination problems.},
  archive      = {J_SUPERC},
  author       = {Vidya, K. A. and Venugopal, K.},
  doi          = {10.1007/s11227-025-07967-4},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Efficient domination problem: A quantum computing approach},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling of shortest path of a graph in quantum computing. <em>SUPERC</em>, <em>81</em>(15), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07968-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem is the selection of edges for finding the optimal path between two specified nodes in a graph. There are well-known classical algorithms like Dijkstra, A*, Bellman-Ford, Floyd-Warshall, etc., although runtime grow for larger graphs. Other than the above, there are gate-based and non-gate-based quantum optimization approaches to solve in quantum computing. The problem is required to be encoded in quadratic unconstrained binary optimization and the Ising model for various quantum frameworks. In this paper to solve the shortest path problem, we have implemented models like the quantum approximate optimization algorithm known as QAOA, adiabatic quantum computing known as AQC, and quantum annealing known as QA, respectively. The models follow the unitary evolution of the Hamiltonian for the low-energy state of a solution. QAOA provides the solution by applying a sequence of quantum gates on a quantum circuit. Quantum tunneling is a basic phenomenon in both AQC and QA. The evolution cycle of the AQC and QA transforms the initial Hamiltonian to the encoded final Hamiltonian through a continuous interpolation over time. The state transformation goes through the evolution cycle for both AQC and QA. The aim of the paper demonstrates the quantum computing that can effectively encode and solve shortest path problem, with various analysis on noise effect, eigenspectra, and performance benchmark.},
  archive      = {J_SUPERC},
  author       = {Singh, Nongmeikapam Brajabidhu and Pachuau, Joseph L. and Saha, Anish Kumar},
  doi          = {10.1007/s11227-025-07968-3},
  journal      = {The Journal of Supercomputing},
  month        = {10},
  number       = {15},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Modeling of shortest path of a graph in quantum computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-attributive border approximation area comparison model based on yager weighted aggregation operators for circular pythagorean fuzzy information and their application in shortest path problems. <em>SUPERC</em>, <em>81</em>(14), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07327-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shortest path problems are a family or class of dilemmas in graph theory where the theme is to investigate or analyze the minimum distance or shortest way/route among two or more vertices in a graph. For the evaluation of the above problems, many people have used the algorithm of Dijkstra’s model, Floyd–Warshall model, and Bellman–Ford mode. The shortest path problems are also valuable collections of optimization theory problems that aim to evaluate the shortest path among any two points or nodes in a graph. This technique is utilized in various fields such as computer science, operation research, transportation problems, and network design. This manuscript proposes the technique of Yager aggregation operators for circular Pythagorean fuzzy information based on Yager norms. For this, first, we derive the model of circular Pythagorean fuzzy Yager operational laws, and then we derive the model of circular Pythagorean fuzzy Yager weighted averaging operator, circular Pythagorean fuzzy Yager ordered weighted averaging operator, circular Pythagorean fuzzy Yager hybrid weighted averaging operator, circular Pythagorean fuzzy Yager weighted geometric operator, circular Pythagorean fuzzy Yager ordered weighted geometric operator, circular Pythagorean fuzzy Yager hybrid weighted geometric operator, and described their valuable properties. Further, we design two different decision-making models, called the circular Pythagorean fuzzy multi-attributive border approximation area comparison technique and the circular Pythagorean fuzzy multi-attribute decision-making technique for the assessment of the shortest path problems among any two countries or cities. Finally, we illustrate some numerical examples for the investigation of the supremacy and rationality of the designed models with the help of comparative analysis among proposed ranking models with some prevailing ranking models.},
  archive      = {J_SUPERC},
  author       = {Ali, Zeeshan and Waqas, Muhammad and Hila, Kostaq},
  doi          = {10.1007/s11227-025-07327-2},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Multi-attributive border approximation area comparison model based on yager weighted aggregation operators for circular pythagorean fuzzy information and their application in shortest path problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prototype reduction method based on accelerated binary bare-bone particle swarm optimization for instance-based classifiers. <em>SUPERC</em>, <em>81</em>(14), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07518-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prototype reduction methods, as an important data pre-processing task, can improve instance-based classifiers by removing suspicious noise and/or redundant samples. Recently, a series of traditional non-evolutionary or evolutionary prototype reduction methods with traditional heuristic strategies or evolutionary algorithms have been developed. Despite having shown competitive performance, they still suffer from the following issues: (a) almost all traditional non-evolutionary prototype reduction methods heavily rely on specific assumptions about geometric and class information, leading to low robustness; (b) most evolutionary prototype reduction methods may face great challenges on search efficiency with increase in the sample number of the training set, leading to difficulties in extension and application; and (c) most evolutionary prototype reduction methods need to set too many parameters, leading to unstable performance. To advance the state-of-the-art prototype reduction methods by overcoming the above issues, a novel prototype reduction method based on an accelerated binary particle swarm (PRAB3PSO) is proposed. The main novelties are in the following. First, a new accelerated binary bare-bone particle swarm optimization (AB3PSO) with a new search space reduction strategy and a new particle update mechanism is proposed. Second, AB3PSO is used to select a global optimal reduced set from the original training set with no assumptions and few parameters. Intensive experiments have proven that (a) PRAB3PSO outperforms eight state-of-the-art non-evolutionary or evolutionary prototype reduction methods on UCI datasets from extensive industrial applications in weighing the instance reduction rate and classification accuracy of three instance-based classifiers and (b) PRAB3PSO is faster than state-of-the-art evolutionary prototype reduction methods.},
  archive      = {J_SUPERC},
  author       = {Huang, Xing and Wang, Kexin and Li, Junnan},
  doi          = {10.1007/s11227-025-07518-x},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Prototype reduction method based on accelerated binary bare-bone particle swarm optimization for instance-based classifiers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robustness and sparsity of extreme learning machine in regression problems using correntropy function. <em>SUPERC</em>, <em>81</em>(14), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07620-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) exemplifies a single-hidden layer feedforward neural network, offering many advantages, especially fast training speed, and has been successfully applied to classification and regression problems. However, it also has some shortcomings. When faced with data containing outliers, it is shown that ELM will be affected by the outliers, which results in poor robustness, and that the output weights of most ELM models do not exhibit sparse performance. In recent years, regularization techniques have been used to improve the robustness and sparsity of ELM. In this study, a correntropy function is utilized as a loss function and regularization term to improve robustness and sparsity. Under the condition that large outliers are present, the correntropy loss function can suppress the influence of these outliers on the objective function. For the correntropy function, if the parameter $$\sigma$$ is sufficiently small, it serves as a regularizer that approximates the zero-norm, resulting in good sparsity. Moreover, since the objective function is a non-convex function, it is difficult to solve it using the optimization method designed for convex functions. An effective approach is to solve the non-convex optimization problem of the objective function using the DC algorithm, which has been shown to be efficient in handling such problems. Experiments with benchmark datasets show that the proposed approach offers improved robustness and sparsity, particularly in cases where the dataset contains high outliers level.},
  archive      = {J_SUPERC},
  author       = {Jiang, Yuzhu and Wang, Kuaini and Li, Jinge},
  doi          = {10.1007/s11227-025-07620-0},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing robustness and sparsity of extreme learning machine in regression problems using correntropy function},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A many-objective evolutionary algorithm based on decision variable classification mutation and indicator. <em>SUPERC</em>, <em>81</em>(14), 1--75. (<a href='https://doi.org/10.1007/s11227-025-07705-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most many-objective evolutionary algorithms balance convergence and diversity by improving environmental selection strategies, with less attention paid to the contribution of offspring to the algorithm performance. This study proposes a many-objective evolutionary algorithm based on a decision variable classification mutation and indicator (MaOEA-DI) that improves the quality of offspring while balancing convergence and diversity to enhance the algorithm’s performance. In MaOEA-DI, a dual-archive guided decision variable classification mutation strategy is designed. This strategy utilizes the decision variable information of elite individuals from the convergence and diversity elite archives, which are updated every generation, to guide the mutation process in generating high-quality offspring. To enhance the quality of the candidate solution set, the newly generated offspring are filtered using the current population information. In addition, an indicator- and density-based environmental selection strategy is developed to balance convergence and diversity. Experimental results on 27 benchmark problems, two real-world optimization problems, and a multiline distance minimization problem show that MaOEA-DI outperforms six advanced algorithms.},
  archive      = {J_SUPERC},
  author       = {Ren, Wei and Ge, Fangzhen and Chen, Debao and Shen, Longfeng and Liu, Huaiyu},
  doi          = {10.1007/s11227-025-07705-w},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--75},
  shortjournal = {J. Supercomput.},
  title        = {A many-objective evolutionary algorithm based on decision variable classification mutation and indicator},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RIMS-RPL: RL-based intelligent mobility-support of RPL for IIoT-based networks. <em>SUPERC</em>, <em>81</em>(14), 1--47. (<a href='https://doi.org/10.1007/s11227-025-07723-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility is crucial in the industrial internet of things (IIoT), while the widely used IPv6 routing protocol for low-power and lossy networks (RPL) faces performance issues in the presence of mobile nodes (MNs). This paper presents methods to enhance mobility support and reliability in IIoT-based mobile networks while minimizing network overhead, energy consumption, and latency. Using a new cross-layer metric, sensor nodes select their next hop based on an objective function (OF) that considers node mobility. Additionally, a reinforcement learning (RL) approach allows nodes to predict their operational state -whether they are undergoing hand-offs, retaining outdated routes, or in a stable state- facilitating timely updates and reducing failures. Our protocol demonstrates lower computational complexity and superior performance compared to RPL and existing approaches under various mobility speeds and node densities. These results highlight the effectiveness and lightweight design of our proposed protocol for IIoT applications.},
  archive      = {J_SUPERC},
  author       = {Alem, Ismahene and Yessad, Samira and Bouallouche-Medjkoune, Louiza},
  doi          = {10.1007/s11227-025-07723-8},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {RIMS-RPL: RL-based intelligent mobility-support of RPL for IIoT-based networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedCK:addressing label distribution skew in federated learning via clustering-efficient and knowledge distillation. <em>SUPERC</em>, <em>81</em>(14), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07728-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning paradigm that allows multiple participants to collaboratively train a global model without sharing local data. However, the data of each participant are usually characterized by being non-independent and identically distributed (non-iid), especially in real-world scenarios where label distribution skew is prevalent. This problem can cause the optimization direction of the local model to be inconsistent with the global objective, thus significantly affecting the performance and stability of the global model. Furthermore, this problem can reduce the model’s generalization ability for certain classes and slow down the convergence rate during training. To solve these challenges, this paper proposes a novel FL algorithm via Clustering-Efficient and Knowledge Distillation (FedCK). First, we propose an improved Fuzzy C-Means (FCM) clustering algorithm. An intelligent centroid initialization strategy, inspired by K-Means++, is employed to initialize the cluster centroids. This prevents centroid overlap and mitigates the imbalance in the number of clients across clusters. Additionally, cosine distance is used to capture the similarity in label distributions among clients, thereby enhancing the clustering performance and improving the overall efficiency of the clustered model. Second, to strengthen the feature extraction capability of client-side encoders and accelerate the convergence of the global model, we introduce a knowledge distillation optimization strategy based on a conditional generator. To address the dependency on proxy data during the distillation process, a conditional generator is deployed on the server side, which generates synthetic data that aligns with the label distribution of participating clients. Last, extensive experiments on multiple image classification tasks under various label distribution skew scenarios demonstrate that FedCK achieves significant improvements in both model accuracy and convergence speed.},
  archive      = {J_SUPERC},
  author       = {Chen, Jinhua and Li, Mengmeng and He, Xin},
  doi          = {10.1007/s11227-025-07728-3},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {FedCK:addressing label distribution skew in federated learning via clustering-efficient and knowledge distillation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network-based vehicle trajectory prediction method. <em>SUPERC</em>, <em>81</em>(14), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07739-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of insufficient modeling of dynamic interaction behaviors between vehicles in existing vehicle trajectory prediction methods, this paper proposes a vehicle trajectory prediction method (STDGAT) based on a dynamic graph neural network that integrates spatiotemporal features. First, the core of the method lies in constructing a high-precision dual spatiotemporal graph structure and defining novel matrix weight coefficients to simulate real driving environments. Spatial interaction features are then extracted using the dynamic graph attention network (DGAT). Second, the temporal convolutional network (TCN) is employed to extract temporal features from the target vehicle’s historical trajectory. Subsequently, an adaptive gating unit is used to fuse the temporal and spatial features. These fused features are then embedded into an encoder–decoder structure incorporating an attention mechanism. The encoder generates spatiotemporal feature vectors, which are further refined by the attention mechanism to capture critical spatiotemporal features. Finally, the decoder takes these features as input and performs multi-step iterative decoding to predict the future trajectory of the target vehicle. Given the depth of the model and the scale and dynamic nature of the spatiotemporal graph data processed, this study leverages a high-performance computing environment. To validate the effectiveness of the proposed STDGAT method, iterative training is conducted on the open-source NGSIM dataset. Comparative experiments are performed against trajectory prediction models including GRIP++, HiVT,ADAPT , and GSTCN. The results demonstrate that, compared to other mainstream models, the proposed model achieves superior prediction accuracy in both highway and urban scenarios.},
  archive      = {J_SUPERC},
  author       = {Li, Muyang and Liu, Mingjian and Liu, Dianchen},
  doi          = {10.1007/s11227-025-07739-0},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic graph neural network-based vehicle trajectory prediction method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SVN-YOLO: A high-precision ship detection algorithm based on improved YOLOv10n. <em>SUPERC</em>, <em>81</em>(14), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07743-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship detection and identification are essential for effective maritime traffic management and the assurance of navigational safety. In light of the challenges posed by the presence of large targets, severe dense occlusion interference, and a considerable omission rate of small targets in marine scenes, this paper introduces a novel ship detection algorithm that builds upon the improved YOLOv10n, referred to as SVN-YOLO. The algorithm features three innovative optimizations compared to the benchmark model. First, the Spatial Pyramid Decomposition Convolution (SPDConv) module is introduced to reconstruct the feature pyramid network, enhancing multi-scale feature representation capability through spatial information compression and channel dimension extension. Next, the VoVNet and GSConv Cross-Stage Partial Connection (VOVGSCSP) with a variable receptive field feature fusion structure is employed to replace the traditional C2f module, utilizing a gating mechanism to enhance feature reuse efficiency and reduce computational redundancy. Furthermore, the boundary regression process is optimized using the Normalized Wasserstein Distance Loss (NWDLoss), thereby improving localization accuracy for dense targets. Experimental results from the SeaShips and InfiRay ship datasets show that SVN-YOLO significantly improves detection accuracy while maintaining real-time detection efficiency. Key performance metrics substantiate these advancements: mAP@0.5 achieves 98.9 %, while mAP@0.5:0.95 increases by 1.3–0.2%. An increase of 1% is observed in Precision, and Recall improves by 0.4%. Meanwhile, Params and FLOPs are reduced by 4% and 10.7%. The proposed algorithm offers a reliable technical solution for intelligent ship detection in complex marine environments.},
  archive      = {J_SUPERC},
  author       = {Wang, Zixuan and Han, Dezhi and Han, Bing and Wu, Zhongdai and Huang, Xiaohu},
  doi          = {10.1007/s11227-025-07743-4},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {SVN-YOLO: A high-precision ship detection algorithm based on improved YOLOv10n},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-guided alignment optimization and pseudo-label refinement for cross-domain few-shot object detection. <em>SUPERC</em>, <em>81</em>(14), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07750-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot object detection faces challenges of limited target domain samples and significant domain heterogeneity, which severely tests traditional pseudo-label-based transfer methods. Due to limited single-machine computational resources, traditional models struggle to handle large-scale cross-domain data, failing to capture the complex nonlinear structures and deep semantic relationships of the target domain, leading to increased domain differences, amplified prediction uncertainty, and reduced knowledge transfer efficiency. To address these issues, we propose a pseudo-label refinement and uncertainty-guided alignment optimization for cross-domain few-shot object detection. First, to address the issue of limited samples, we designed a dual-branch joint enhancement module to improve the expressive power of limited data, thereby acquiring more discriminative information. To improve the quality of pseudo-labels, we introduce a feedback-driven progressive pseudo-label optimization strategy. This approach iteratively improves pseudo-label quality through collaboration between a teacher and a student model. Second, to handle low-confidence pseudo-labels, we propose a soft-weighted balancing strategy. This method adjusts the weight of low-confidence pseudo-labels, reducing noise while preserving valuable weak supervision signals. To mitigate the uncertainty in pseudo-label generation, we also introduce an uncertainty alignment loss. Experimental results on six datasets demonstrate that our method outperforms baseline approaches, significantly improving pseudo-label quality and enhancing cross-domain transfer learning performance.},
  archive      = {J_SUPERC},
  author       = {Yan, Lirong and Zhang, Yongbing and Tang, Xiaofen},
  doi          = {10.1007/s11227-025-07750-5},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Uncertainty-guided alignment optimization and pseudo-label refinement for cross-domain few-shot object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential-optima guided adaptive neighborhood differential evolution algorithm for multimodal optimization problems. <em>SUPERC</em>, <em>81</em>(14), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07762-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood schemes are commonly embedded in evolutionary algorithms (EAs) to address multimodal optimization problems (MMOPs) because they explicitly or implicitly separate populations, enabling each subpopulation to evolve in parallel, thereby tracking different peaks. However, constructing neighborhoods that can aggregate similar individuals and efficiently guide coevolution remains challenging. To address this, this paper proposes a potential-optima guided adaptive neighborhood differential evolution algorithm, termed POGAN-DE. In POGAN-DE, an adaptive neighborhood mechanism (ANM) is designed to regulate the search behaviors of individuals with distinct characteristics across evolutionary stages, balancing exploration and exploitation capabilities. Furthermore, considering that multiple optima may coexist within a single neighborhood, a potential optimal identification (POI) scheme is developed using a flexible clustering method to detect undiscovered optima located on different peaks, thereby enhancing peak identification capability. A population crowding relieving technique is integrated to avoid the waste of fitness evaluations and enhance population diversity. Additionally, species-level historical success records are utilized to enable self-adaptation of F and CR parameters. Finally, POGAN-DE is validated on a benchmark suite of 20 multimodal problems and real-world applications. Comparative experiments with state-of-the-art algorithms confirm its robust and comprehensive performance.},
  archive      = {J_SUPERC},
  author       = {Shuai, Yong and Shen, Dingcai and Shen, Manman},
  doi          = {10.1007/s11227-025-07762-1},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Potential-optima guided adaptive neighborhood differential evolution algorithm for multimodal optimization problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient hybrid protocol for quantum secure multi-party summation, multiplication and comparison based on d-dimensional single-particle states. <em>SUPERC</em>, <em>81</em>(14), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07763-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum secure multi-party computation (QSMC) allows multiple participants to collaboratively compute a target function while ensuring that their private inputs remain confidential using quantum technologies, which holds significant practical value in fields such as data privacy, secure voting, and collaborative data analysis. However, existing QSMC protocols are limited to individual operations such as summation, multiplication, or comparison, and require excessive quantum resources. To address these challenges, an efficient hybrid quantum protocol for multi-party computation is proposed, enabling simultaneous summation, multiplication, and comparison with the assistance of a semi-honest quantum third party (TP), utilizing only d-dimensional single-particle states with efficient quantum state utilization. The single particles are transmitted in a circle-type transmission mode, avoiding complex operations such as entanglement swapping or shift operations. Keys are established among all the participants, as well as between each participant and TP, using these single states. Once the keys are established, with TP’s assistance, all three types of computation can be completed simultaneously. Security analysis demonstrates the protocol’s robustness against both internal and external attacks, and comparative evaluation with existing protocols highlights its superior efficiency in quantum resource utilization. Finally, the feasibility and correctness of the protocol are further demonstrated through simulations on the IBM Qiskit platform.},
  archive      = {J_SUPERC},
  author       = {Zhou, Yi-Hua and Pu, Wei-Yi and Yang, Yu-Guang and Shi, Wei-Min},
  doi          = {10.1007/s11227-025-07763-0},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {An efficient hybrid protocol for quantum secure multi-party summation, multiplication and comparison based on d-dimensional single-particle states},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective feature selection of radiomics and deep learning features for breast cancer subtype detection. <em>SUPERC</em>, <em>81</em>(14), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07768-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is a heterogeneous disorder distinguished by many subtypes determined by the expression of estrogen receptor (ER), progesterone receptor (PR), and human epidermal growth factor receptor 2 (HER2). These indications are crucial for guiding treatment protocols and predicting patient outcomes. Identifying these biomarkers remains challenging for researchers. This study addresses this challenge by introducing an innovative approach that integrates radiomics features with deep features. We use a trainable multi-objective optimizer to identify the optimal minimal feature set, thereby improving the detection of ER, PR, and HER2 expression. Initially, radiomic and deep learning (DL) characteristics are retrieved from magnetic resonance imaging (MRI) patients, and the demographic data are integrated with the radiomic characteristics. On the other side, the MobileNetV2 DL pretrained model is used to extract features, and principal component analysis (PCA) is utilized for dimensionality reduction of the retrieved DL features. In the second stage, the trainable multi-objective metaheuristic optimizer non-dominated sorting genetic algorithm II (NSGA-II) was used to pick optimum minimum features from radiomic and DL features. Ultimately, the ER/PR and HER2 statuses are categorized using support vector machine (SVM) and random forest (RF) classifiers. Using the RF classifier with combined radiomics and DL features, we achieved HER2 prediction (AUC: 0.913, accuracy: 89.19%), ER prediction (AUC: 0.790, accuracy: 77.32%), and PR prediction (AUC: 0.770, accuracy: 76.49%) on the DBC-MRI dataset. External validation on the BreastDM dataset confirmed generalizability (accuracy: 86.16%, AUC: 0.877). NSGA-II reduced feature dimensionality by 65% while maintaining performance, with significant improvement over single-modality approaches (p < 0.05). The Python code from our study is publicly accessible at: https://github.com/jafarMajidpour/Breast-Cancer-Biomarkers-using-NDGA-II-and-Deep-learning .},
  archive      = {J_SUPERC},
  author       = {Majidpour, Jafar and Beitollahi, Hakem},
  doi          = {10.1007/s11227-025-07768-9},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {Multi-objective feature selection of radiomics and deep learning features for breast cancer subtype detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sarcasm detection on news headlines using transformers. <em>SUPERC</em>, <em>81</em>(14), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07773-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm poses a linguistic challenge due to its figurative nature, where intended meaning contradicts literal interpretation. Sarcasm is prevalent in human communication, affecting interactions in literature, social media, news, e-commerce, etc. Identifying the true intent behind sarcasm is challenging but essential for applications in sentiment analysis. Detecting sarcasm in written text, as a challenging task, has attracted many researchers in recent years. This paper attempts to detect sarcasm in news headlines. Journalists prefer using sarcastic news headlines as they seem much more interesting to the readers. In the proposed methodology, we experimented with Transformers, namely the BERT model, and several Machine and Deep Learning models with different word and sentence embedding methods. The proposed approach inherently requires high-performance resources due to the use of large-scale pre-trained language models such as BERT. We also extended an existing news headlines dataset for sarcasm detection using augmentation techniques and annotating it with hand-crafted features. The proposed methodology could outperform almost all existing sarcasm detection approaches with a 98.86% F1-score when applied to the extended news headlines dataset, which we made publicly available on GitHub.},
  archive      = {J_SUPERC},
  author       = {Gumuşcekicci, Gizem and Dehkharghani, Rahim},
  doi          = {10.1007/s11227-025-07773-y},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Sarcasm detection on news headlines using transformers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UDS-YOLO: An improved instance segmentation network for traffic scenarios. <em>SUPERC</em>, <em>81</em>(14), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07779-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of urbanization and the continuous increase in vehicle ownership, traffic congestion and frequent accidents have become pressing challenges that demand urgent solutions. In this context, breakthroughs in intelligent vehicle technology, particularly in the field of forward visual perception, are especially critical. Traffic scene instance segmentation requires a balance between high precision and real-time performance in complex and dynamic environments, yet existing technologies exhibit significant limitations. This study aims to address the imbalance among accuracy, efficiency, and adaptability in traffic scene instance segmentation. To this end, we propose UDS-YOLO: an improved network based on YOLOv8-seg, which integrates three key components—the UniRepLknet feature extraction module for enhanced spatial feature capture, the Dysample dynamic upsampling technique for adaptive detail recovery, and the parameter-free SimAM attention mechanism for focused feature weighting. Experimental results on the Cityscapes dataset demonstrate that UDS-YOLO achieves a mAP@0.5 of 39.5% and a mAP@0.5:0.95 of 24%, outperforming mainstream models such as YOLOv5-seg and YOLOv8-seg, while maintaining a frame rate (FPS) of 106.6. The network requires only 11.4 GFLOPs, ensuring high efficiency and suitability for resource-constrained environments. Through the synergistic optimization of ‘feature extraction—upsampling—attention mechanism,’ it bridges the gap in ‘accuracy—efficiency—complex scene adaptability’ present in existing methods. This study provides a robust solution for real-time instance segmentation in autonomous driving, balancing lightweight design with high-precision requirements to meet the demands of complex traffic scenarios. The research offers a practical and feasible technical solution for instance segmentation tasks in autonomous driving systems, with broad application prospects.},
  archive      = {J_SUPERC},
  author       = {Qiang, Qiuxi and Zhang, Mingshu and Zhao, Bingyao and Li, Chuanyun and Hou, Alin},
  doi          = {10.1007/s11227-025-07779-6},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {UDS-YOLO: An improved instance segmentation network for traffic scenarios},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust dual space factorization for unsupervised feature selection (RDSF-UFS). <em>SUPERC</em>, <em>81</em>(14), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07780-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection is critical in high-dimensional data analysis, as it identifies the most informative features without relying on label information. In this paper, we propose a novel robust dual space factorization for unsupervised feature selection (RDSF-UFS) framework based on symmetric nonnegative matrix factorization and nonnegative matrix tri-factorization (NMTF). The proposed method explores sample and feature affinity matrices to capture intrinsic data structures in a dual latent space. Specifically, we introduce a robust objective function incorporating the Frobenius and $$\ell _{2,1}$$ -norms to enhance resistance to noise and outliers. We further impose an orthogonality constraint on the latent factor matrices to promote sparsity and improve clustering performance. RDSF-FS uses NMTF to create a bridge or connector that improves the latent representation, thereby strengthening the model’s ability to maintain the structural information within the data. An efficient optimization algorithm is derived to iteratively update the latent factors by solving the associated gradient-based equations. We evaluated the performance of RDSF-UFS on eight benchmark datasets, including biological microarray, face image, speech signal, and digit image datasets. Experimental results demonstrate that RDSF-UFS outperforms state-of-the-art feature selection methods in terms of normalized mutual information and accuracy in specific datasets, highlighting its ability to uncover meaningful feature patterns and improve clustering performance.},
  archive      = {J_SUPERC},
  author       = {Karimzadeh, Masoud and Moradi, Parham and Ghaderzadeh, Abdulbaghi},
  doi          = {10.1007/s11227-025-07780-z},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Robust dual space factorization for unsupervised feature selection (RDSF-UFS)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multivariate time series data classification method based on dual-branch structure GSTT. <em>SUPERC</em>, <em>81</em>(14), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07781-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of traditional multivariate time series classification (MTSC) methods in effectively integrating global context modeling with local feature extraction, this study proposes a dual-branch feature fusion GSTT model. The local feature extraction module (GAT-Shapelets) constructs a topological graph structure of temporal subsequences using the graph attention network (GAT) to derive Shapelets, focusing on capturing critical local features. The global feature extraction module (TSDRA-Transformer) employs a hierarchical convolutional architecture combined with a Time Series Dimensionality Reduction Attention (TSDRA) mechanism-based Transformer, which reduces the computational complexity of attention while capturing long-term dependencies across time steps. Through parallel computing optimization and distributed training frameworks, the GSTT model achieved efficient processing of large-scale data, significantly improving computational efficiency. Experimental evaluations on 30 datasets from the UEA multivariate time series benchmark demonstrate that the GSTT significantly outperforms baseline methods in classification accuracy. Ablation studies further validate the complementary synergy of local and global feature representations in the dual-branch architecture, underscoring the model’s robustness and efficacy. The experiments were conducted on a high-performance GPU cluster, utilizing parallel computing to accelerate model training and inference, demonstrating the superior performance of GSTT in a supercomputing environment.},
  archive      = {J_SUPERC},
  author       = {Zhang, Qifan and Yang, Houqun and Wang, Yizhen and Huang, Jianqiang},
  doi          = {10.1007/s11227-025-07781-y},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {A multivariate time series data classification method based on dual-branch structure GSTT},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-lightweight SAR ship object detection based on multi-scale fusion and pruning distillation. <em>SUPERC</em>, <em>81</em>(14), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07782-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) ship object detection is critical for ocean management and national security. The variability of image scales and the high computational cost of real-time detection are currently two important challenges for object detection. Multi-scale feature fusion is the current mainstream solution, however, most of the feature fusion only uses summation or cascade to fuse pyramidal features, ignoring the scale features of the image itself. Current mainstream methods often involve large backbone networks with a high number of parameters, which reduces inference speed and presents challenges for deployment on satellite platforms. To address these issues, we propose an ultra-lightweight SAR ship target detection model based on multi-scale feature fusion and pruning distillation. This model includes a multi-scale feature fusion module, an enhanced feature extraction module, a channel pruning network, and a knowledge distillation network. This model aims to achieve multi-scale feature extraction and fusion while maintaining lossless compression. The multi-scale feature fusion module performs feature extraction by enlarging and combining semantic information from different scales of the image. The enhanced feature extraction module reduces redundant computation through feature division and merging, while employing layer aggregation to enhance feature extraction capabilities. The channel pruning network uses a slim structured pruning model. The Multiple Knowledge Distillation (MKD) approach leverages SAR-HP as the teacher model and its pruned version as the student model, aiming to preserve detection accuracy while reducing the model’s parameters. Experimental results on the SSDD dataset demonstrate that our model significantly improves accuracy, reduces model size by 51.6%, and increases inference speed by 48.7%.},
  archive      = {J_SUPERC},
  author       = {Wu, Yuxiang and Zhao, Qianjin and Chen, Meng and Zhang, Shunxiang and Li, Kuan-Ching},
  doi          = {10.1007/s11227-025-07782-x},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Ultra-lightweight SAR ship object detection based on multi-scale fusion and pruning distillation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing controller placement in SD-IoT with dynamic heterogeneous switch traffic via weighted betweenness and GWO. <em>SUPERC</em>, <em>81</em>(14), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07783-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating Software-Defined Networking (SDN) into IoT (SD-IoT) emerges as a promising solution to the increasing complexity and scalability challenges of IoT networks. However, this convergence introduces significant challenges in network management. One of the critical challenges in SD-IoT is the controller placement problem (CPP), which has a substantial impact on network efficiency. Unlike traditional static controller placement strategies, CPP in SD-IoT becomes more challenging due to the heterogeneous and dynamic nature of IoT network infrastructure, where switches experience varying loads influenced by IoT device traffic patterns. In this paper, we propose a novel approach that combines the Grey Wolf Optimizer (GWO) with Weighted Betweenness Centrality (WBC)-based approach to address the controller placement problem. The approach leverages GWO to effectively explore the solution space, while WBC is used to strategically position controllers on nodes with high centrality. This ensures more effective controller deployment by minimizing network latency while optimizing switch assignment to controllers according to their loads. We evaluate the proposed method against existing approaches, including Optimal Placement, Betweenness Centrality with Hierarchical Clustering (HC-BC), and the Louvain Algorithm with Betweenness Centrality (Louvain-BC). The comparison is based on key performance metrics, such as switch to controller latency, inter-controller latency, flow rate, and execution time. Experimental results demonstrate that GWO-WBC-CPP achieves up to 19.89% reduction in switch-to-controller latency, 33.63% decrease in inter-controller latency, and 33.16% improvement in flow rate compared to HC-BC and Louvain-BC. Moreover, the GWO-WBC-CPP (50%) variant offers comparable performance while reducing inter-controller latency by up to 55.01%, making it highly suitable for large-scale or time-sensitive SD-IoT environments.},
  archive      = {J_SUPERC},
  author       = {Boudi, Raid and Lalou, Mohammed and Bouchemal, Nardjes},
  doi          = {10.1007/s11227-025-07783-w},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing controller placement in SD-IoT with dynamic heterogeneous switch traffic via weighted betweenness and GWO},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-classifier-assisted constrained optimization algorithm for obstacle avoidance trajectory planning of robotic arm. <em>SUPERC</em>, <em>81</em>(14), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07785-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arms play a crucial role in modern manufacturing and automation, where trajectory planning requires navigating waypoints, avoiding obstacles, and minimizing energy consumption, making it a constrained optimization problem. However, collision detection is a computationally intensive geometry problem, and the collision-free region can be narrow and discontinuous, which challenges traditional optimization algorithms in reducing computational time and increasing the number of feasible solutions. In this paper, a multi-classifier-assisted particle swarm optimization (MCAPSO) is proposed to address the expensive constrained optimization problem (ECOP) in the obstacle avoidance trajectory planning. Specifically, several CNN classifiers are constructed to predict the feasibility of generated trajectories, thereby accelerating collision detection. Throughout the optimization process, Q-learning is employed to maintain prediction accuracy by dynamically determining when to update the classifiers and controlling the frequency of using real evaluations. Meanwhile, a multi-strategy constraint repair technique is developed to accelerate the optimization of infeasible solutions toward feasible regions. Additionally, the particle swarm optimization algorithm has been extensively enhanced to improve global search capability and escape local optima. Experimental results demonstrate that MCAPSO effectively handles scenes with varying levels of obstacle complexity and exhibits competitive performance compared to some state-of-the-art methods, offering a promising new approach for real-world ECOPs.},
  archive      = {J_SUPERC},
  author       = {Tian, Wentao and Pan, Anqi and Ma, Yuhang and Liao, Yaqi},
  doi          = {10.1007/s11227-025-07785-8},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {A multi-classifier-assisted constrained optimization algorithm for obstacle avoidance trajectory planning of robotic arm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary multitask optimization algorithm based on block-level knowledge transfer and beluga whale optimization. <em>SUPERC</em>, <em>81</em>(14), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07787-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multitask optimization (EMTO) is an emerging topic in evolutionary computation. Compared with single-task optimization, EMTO can solve multiple related or similar tasks simultaneously by transferring knowledge between them. High-performance computing (HPC) provides powerful computational capabilities for solving complex multitask optimization problems, making EMTO possible for real-world applications. Although EMTO has shown great application potential, it still faces challenges in solving accuracy, requiring in-depth research and improvement. Therefore, we propose an EMTO algorithm based on block-level knowledge transfer (BLKT) and beluga whale optimization (BWO), namely BLKT–BWO. It mainly consists of a knowledge transfer module and an independent evolution module. Specifically, in the knowledge transfer module, we introduce a simple and efficient weighted average knowledge transfer rule to reduce computational complexity. In addition, by dividing and clustering individuals, the algorithm achieves knowledge transfer between similar but unaligned dimensions. This approach accelerates the solution process and helps tasks to escape from local optimum. In the independent evolution module, the BWO algorithm is employed as a solver for updating positions to enhance global convergence, owing to its strong search performance in single-objective optimization. Experimental results on benchmarks of CEC2017-MTSO and WCCI2020-MTSO, and a real-world multitask optimization problem all demonstrate that the performance of BLKT–BWO is superior to current state-of-the-art algorithms.},
  archive      = {J_SUPERC},
  author       = {Chen, Lei and Liu, Wenhao and Ma, Yunpeng and Zhao, Yikai and Hou, Jieru and Hao, Wenhui and Wang, Guanli},
  doi          = {10.1007/s11227-025-07787-6},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {An evolutionary multitask optimization algorithm based on block-level knowledge transfer and beluga whale optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing UAV object detection through multi-scale deformable convolutions and adaptive fusion attention. <em>SUPERC</em>, <em>81</em>(14), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07788-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) imagery presents challenges including small object size, significant geometric deformations, and background clutter due to unique perspectives and complex backgrounds. To address these challenges while adapting to resource-constrained UAV platforms, this paper proposes MSDC-DETR, a real-time object detection model. The multi-scale deformable channel convolution (MSDC) module decomposes multi-scale features and dynamically adjusts channel weights to generate precise sampling offsets, enabling convolutional kernels to adaptively focus on object regions for enhanced spatial flexibility and mitigated geometric deformations. The adaptive fusion attention module bridges cross-scale semantic gaps through interactive alignment, effectively suppressing background noise and boosting small object detection while reducing computational overhead and memory consumption. Extensive experiments on VisDrone and UAVDT datasets demonstrate 3.8% mAP50 and 2.5% mAP50:95 improvements while sustaining 60.1 FPS real-time inference, mitigating accuracy-speed trade-offs to provide a perception solution with improved efficiency-accuracy balance for most UAV systems. The source code is available at: https://github.com/13849446299/MSDC-DETR.},
  archive      = {J_SUPERC},
  author       = {Xu, Xuebin and Xing, Ziyang and Sun, Meiling and Zhang, Peiran and Yang, Kuihe},
  doi          = {10.1007/s11227-025-07788-5},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing UAV object detection through multi-scale deformable convolutions and adaptive fusion attention},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-phase deep learning method for image fusion-based extended depth of focus. <em>SUPERC</em>, <em>81</em>(14), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07791-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The depth of focus (DOF) in optical imaging is inherently limited, restricting the ability to capture sharp details across varying depth planes. Extended depth of focus (EDOF) techniques address this issue by fusing multiple images captured at different focal levels into a single all-in-focus image. However, traditional and handcrafted fusion methods often suffer from feature degradation, and limited adaptability to complex scenes. In this study, we propose a novel two-phase EDOF method that combines unsupervised deep feature extraction with spatial frequency-guided adaptive fusion. The first phase utilizes a lightweight auto-encoder architecture to extract hierarchical focus-aware features while preserving spatial resolution. In the second phase, a sharpness-aware fusion strategy based on local spatial frequency measurements integrates the extracted features to produce structurally coherent, all-in-focus images. Unlike prior fusion methods, our design explicitly separates feature learning from fusion, improving generalizability and efficiency. Extensive experiments on synthetic and real datasets demonstrate that our method outperforms state-of-the-art EDOF techniques, achieving higher PSNR and SSIM with lower MSE in synthetic settings, and superior perceptual quality in real datasets based on NIQE, BRISQUE, Entropy, and Perceptual Sharpness Index (PSI). The results confirm that the proposed method delivers a robust, adaptive, and computationally efficient solution for EDOF, with strong potential for applications in microscopy, remote sensing, and other precision imaging domains.},
  archive      = {J_SUPERC},
  author       = {Danismaz, Sibel and Dogan, Ramazan Ozgur and Dogan, Hulya},
  doi          = {10.1007/s11227-025-07791-w},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Two-phase deep learning method for image fusion-based extended depth of focus},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of the literature on recent trends in dynamic combinatorial optimization problems linked to meta-learning in metaheuristics and quantum computing. <em>SUPERC</em>, <em>81</em>(14), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07792-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a systematic literature review (SLR) on the use of meta-learning for the management of metaheuristics to solve dynamic combinatorial optimization problems (DCOP), as well as the role of emerging technologies such as quantum computing, multicore computing, and max-plus algebra in this context. The review was conducted following a modified version of Kitchenham’s methodology, formulating research questions, and applying inclusion and exclusion criteria to more than 500 publications between 2018 and 2025, allowing the selection of 22 relevant articles. The results show that meta-learning has been used mainly to improve the performance of optimization algorithms in dynamic environments through knowledge transfer between historical scenarios, although approaches that automate the selection or configuration of metaheuristics for DCOP have not yet been sufficiently explored. In the case of quantum computing, algorithms inspired by techniques such as annealing and particle swarm optimization (PSO) were identified and successfully applied to dynamic problems, although with little implementation in actual quantum hardware. Regarding max-plus algebra, relevant proposals for planning problems in discrete systems are recognized, but without considering the distributed nature or uncertainty inherent in many DCOPs. Finally, no studies were found that apply multicore computing specifically to DCOP, despite its potential. Future lines of research include the development of hybrid meta-learning and hyper-heuristic frameworks, the incorporation of quantum algorithms for metaheuristic management, and the exploration of parallelization and robust modeling techniques in dynamic and uncertain environments.},
  archive      = {J_SUPERC},
  author       = {Jiménez, Marvin and Aguilar, Jose and Montoya, Juan and Montoya, Edwin},
  doi          = {10.1007/s11227-025-07792-9},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {A systematic review of the literature on recent trends in dynamic combinatorial optimization problems linked to meta-learning in metaheuristics and quantum computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-quantum anonymous password authenticated key exchange with indirect public key validation. <em>SUPERC</em>, <em>81</em>(14), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07793-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As mobile devices become integral to daily life, ensuring secure communication between these devices and servers is crucial for protecting sensitive information and preventing unauthorized access. Password Authenticated Key Exchange (PAKE) protocols are widely used for secure authentication and key exchange in such environments. However, the advent of quantum computing has made classical PAKE schemes susceptible to quantum attacks. To overcome this, we introduce a post-quantum anonymous PAKE (APAKE) protocol tailored for mobile devices, which is secure against Key Compromise Impersonation (KCI) attacks and provides forward secrecy. This protocol utilizes lattice-based cryptography and incorporates indirect public key validation to provide robust security in the post-quantum era. Our protocol mitigates vulnerabilities, including signal leakage and key mismatch attacks, and enables secure key reuse. Experimental results demonstrate the balance between strong security and computational efficiency, supported by a formal security proof in the Random Oracle Model and an informal security analysis that further substantiates its resilience.},
  archive      = {J_SUPERC},
  author       = {Saeidi, Mohammad Reza and Mala, Hamid},
  doi          = {10.1007/s11227-025-07793-8},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Post-quantum anonymous password authenticated key exchange with indirect public key validation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WHANet: Wavelet and hybrid attention network for vessel segmentation in OCTA fundus images. <em>SUPERC</em>, <em>81</em>(14), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07794-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography angiography (OCTA) is a state-of-the-art, non-invasive imaging modality that enables high-resolution visualization of the retinal vasculature, playing a vital role in the early diagnosis of various retinal diseases, including diabetic retinopathy, glaucoma, and choroidal neovascularization. However, traditional OCTA image analysis methods face significant challenges due to the difficulty in detecting retinal microvasculature, the presence of blurred vessel edges, and the complex topological structure of vascular networks. These difficulties are further compounded by limited training data, the inadequate representational capacity of spatial-domain features alone, and the challenges associated with effectively integrating frequency-domain information. To address these limitations, this study introduces WHANet, a novel dual-branch segmentation framework that integrates spatial and frequency-domain feature representations. WHANet comprises two primary modules: the hybrid attention deep convolutional branch (HADCB) and the multi-scale wavelet feature fusion branch (MWFFB). The HADCB enhances spatial feature representation through multi-scale convolutional operations and attention mechanisms, improving the detection of fine vessels, reducing edge blurring and misclassification, and reinforcing local detail perception. In parallel, MWFFB leverages the discrete wavelet transform (DWT) to extract refined vascular structures while preserving global vessel morphology. By complementing spatial-domain features with frequency-domain information, MWFFB strengthens edge representation, enhances the separability of microvessels, and mitigates the effects of image noise. The synergistic integration of these two branches enables comprehensive feature extraction and fusion, significantly boosting the model’s ability to handle complex vascular networks. Extensive experiments conducted on three widely used public datasets demonstrate that WHANet consistently outperforms state-of-the-art methods across multiple evaluation metrics, exhibiting superior robustness and segmentation accuracy.},
  archive      = {J_SUPERC},
  author       = {Xue, Shuxin and Zhang, Zhaohui and Yan, Fen and Ma, Fei and Jia, Guangmei and Guo, Yanfei and Ma, Yuefeng and Ai, Xiaofei and Meng, Jing},
  doi          = {10.1007/s11227-025-07794-7},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {WHANet: Wavelet and hybrid attention network for vessel segmentation in OCTA fundus images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive dual-branch network based on adversarial knowledge distillation for compressed deepfake detection. <em>SUPERC</em>, <em>81</em>(14), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07795-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based forgery detection has made significant progress in deepfake identification. However, existing deepfake detection methods mostly focus on improving detection performance using high-quality images, while neglecting the detection of highly compressed forged images. To address this issue, we propose an interactive dual-branch network (IDBN) framework based on adversarial knowledge distillation (AKD). The teacher and student models in this distillation framework share the same architecture, each consisting of two branches: a convolutional neural network (CNN) as the spatial branch and a wavelet attention-based transformer (WABT) as the frequency branch. Features from these two branches interact and fuse via an attention mechanism. Compared to traditional knowledge distillation that uses a fixed temperature parameter, our AKD approach dynamically learns the temperature through an adversarial temperature module (ATM). The ATM includes a gradient reversal layer (GRL) that reverses the gradient during backpropagation to implement an adversarial mechanism. The distillation strength ( $$\lambda$$ ) is adaptively adjusted based on the student model’s learning status of the underlying task, simulating the human process of progressive learning from easy to difficult tasks. Furthermore, we optimize the training strategy to reduce the teacher model’s reliance on high-quality raw data. Leveraging spatial and frequency features along with soft labels, our approach relies on high-performance computing (HPC) to efficiently train with large-scale compressed data. We conduct comprehensive experiments on multiple benchmark datasets, successfully demonstrating the superior performance of our approach on compressed images.},
  archive      = {J_SUPERC},
  author       = {Yang, Gaoming and Zhu, Peng and Zhang, Ji and Yang, Xiangyu},
  doi          = {10.1007/s11227-025-07795-6},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Interactive dual-branch network based on adversarial knowledge distillation for compressed deepfake detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSFN: A time-series fusion network for keystroke authentication. <em>SUPERC</em>, <em>81</em>(14), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07797-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing urgency of information security needs, the traditional one-time authentication mechanism for identity verification has a significant flaw—it cannot provide continuous protection, and once breached, it leads to systemic risks. Keystroke authentication technology effectively addresses this issue by dynamically monitoring the entire session, capable of intercepting abnormal login attempts and potential threats in real time. However, existing methods, which rely on simple statistical features or single-scale temporal analysis, struggle to capture the dynamic patterns and multi-scale characteristics of keystroke behavior, resulting in insufficient accuracy in complex attack scenarios. To overcome these challenges, this paper proposes an innovative keystroke authentication model—TSFN. The model is centered around long short-term memory networks (LSTM) and Transformer encoders and ingeniously integrates our designed temporal gated convolutional block (TGBlock) and multi-scale dynamic weighted fusion block (MFBlock). These innovative designs enhance the model’s ability to process complex time-series data and extract features effectively. To validate the effectiveness of the TSFN model, we conducted experiments on both the Aalto desktop and mobile datasets. The results show that the model achieved ROC curve areas (AUC) of 99.17% and 99.06%, and the lowest equal error rates (EER) of 0.6% and 0.81% on the two datasets, respectively. Furthermore, the TSFN model achieves efficient real-time performance through parallel and distributed processing, meeting the demands for real-time identity verification on large-scale online platforms.},
  archive      = {J_SUPERC},
  author       = {Wang, Chang and Li, Peiyu and Lin, Yusong},
  doi          = {10.1007/s11227-025-07797-4},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {TSFN: A time-series fusion network for keystroke authentication},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient configuration of heterogeneous resources and task scheduling strategies in deep learning auto-tuning systems. <em>SUPERC</em>, <em>81</em>(14), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07798-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient hyperparameter tuning and model training in distributed heterogeneous environments remain challenging due to resource underutilization, training staleness, and checkpointing bottlenecks. This study addresses these issues by enhancing the Ray Tune framework with three key strategies. First, we propose an Automatic Heterogeneous Resource Allocation Strategy, which dynamically adapts resource distribution based on Node configurations, optimizing utilization while reducing manual setup complexity. Second, our Heterogeneous Resource Fusion Scheduling Algorithm classifies Workers by computational speed and employs generation-aware scheduling to minimize staleness, ensuring synchronized progress among Trials and enhancing Population-Based Training evolution. Third, an Optimized Checkpoint Management Mechanism integrates RAM and disk storage, reducing access delays while maintaining robust persistence. Experimental results validate the effectiveness of our approach. Optimizing checkpoint storage location reduces training time by 1.22×, while our heterogeneous resource fusion strategy improves overall performance by 2.36×, demonstrating enhanced workload balancing and resource efficiency. To foster further research, we open-source our implementation within Ray Tune, providing a scalable and adaptive solution for distributed hyperparameter optimization.},
  archive      = {J_SUPERC},
  author       = {Ken, Pao-Yi and Wu, Chao-Chin},
  doi          = {10.1007/s11227-025-07798-3},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Efficient configuration of heterogeneous resources and task scheduling strategies in deep learning auto-tuning systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing cloud virtualization: A comprehensive survey on integrating IoT, edge, and fog computing with FaaS for heterogeneous smart environments. <em>SUPERC</em>, <em>81</em>(14), 1--62. (<a href='https://doi.org/10.1007/s11227-025-07799-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study provides a comprehensive survey on the integration of FaaS with Internet of Things (IoT), edge, and fog computing in heterogeneous smart environments. It examines the theoretical foundations of cloud virtualization, IoT frameworks, and emerging computing paradigms, while analyzing the role of Artificial Intelligence of Things (AIoT) in enhancing these systems. The study highlights the benefits and challenges of combining FaaS with IoT, Edge, and Fog computing, including improved scalability, reduced latency, and efficient resource utilization. Additionally, it investigates real-world applications across diverse domains such as smart agriculture, healthcare, transportation, and smart homes. Through this extensive analysis, the research offers valuable insights into the advancement of cloud virtualization and its implications for developing more efficient and intelligent ecosystems.},
  archive      = {J_SUPERC},
  author       = {Ghaseminya, Mohammad Mahdi and Eslami, Elahe and Shahzadeh Fazeli, Seyed Abolfazl and Abouei, Jamshid and Abbasi, Elham and Karbassi, Seyed Mehdi},
  doi          = {10.1007/s11227-025-07799-2},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--62},
  shortjournal = {J. Supercomput.},
  title        = {Advancing cloud virtualization: A comprehensive survey on integrating IoT, edge, and fog computing with FaaS for heterogeneous smart environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speech organ disease classification using bidirectional block self-adaptive attention mechanism enabled quantum convolutional neural network. <em>SUPERC</em>, <em>81</em>(14), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07800-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pharyngitis and tonsillitis are common throat inflammations, with pharyngitis affecting the pharyngeal mucosa and tonsillitis targeting the tonsils. Both conditions present overlapping symptoms, complicating diagnosis and treatment. Oral cancer, a serious malignancy in the mouth or throat, poses significant health risks, often linked to tobacco, alcohol, or HPV, and requires early detection for better outcome. The research concerning the classification of pharyngitis, tonsillitis, and oral cancer encountered challenges such as model overfitting, suboptimal classifier training, and unreliable accuracy metrics, which collectively limited the robustness and generalizability of the existing approaches. Thus, to tackle the challenges of the existing method, Bidirectional Block Self-attention (BiBloSAN) and Self-adaptive pooling Enhanced attention (SPEM)-enabled Quantum Convolutional Neural Network ((BS)2Att-QCNN) is proposed in the research. The combination of attention mechanism into the QCNN enables accurate classification. Further, the segmentation in the research is performed with the optimization called Spheniscidae Spiral Huddling Algorithm (S2HA) that aids in obtaining the efficient segmentation of the inputs, which aids the overall research to obtain high classification accuracy. The overall efficiency of the research is evaluated on aggregated bench mark data sets with metrics such as precision, sensitivity, accuracy, recall, f1-score, and specificity with attained values of 95.07%, 96.22%, 95.78%, 96.22%, 95.64%, and 95.36% respectively.},
  archive      = {J_SUPERC},
  author       = {Swathi, M. and Regunathan, Rajeshkannan},
  doi          = {10.1007/s11227-025-07800-y},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Speech organ disease classification using bidirectional block self-adaptive attention mechanism enabled quantum convolutional neural network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An FPGA-based efficient accelerator for fault interaction of rupture dynamics. <em>SUPERC</em>, <em>81</em>(14), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07801-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently predicting aftershocks based on rupture dynamics simulation is a crucial task in high-performance computing, traditionally dependent on supercomputers. However, the constraints of power supply makes supercomputers impractical right after a primary earthquake event. This positions FPGAs, known for their high power efficiency and reconfigurability, as a highly promising alternative. Within rupture dynamics simulation, fault interaction is the most computationally intensive component, making its acceleration crucial for enhancing overall performance. By thoroughly considering both the computational characteristics of fault interaction and the reconfigurable capabilities of FPGAs, we have devised a high-performance, power-efficient accelerator for fault interaction. On one hand, we conduct an in-depth analysis of the algorithm’s data dependencies and exploit parallelization at multiple levels to maximize performance. On the other hand, we propose novel dataflow optimizations, such as prefetching and overlapping computations across different stages, to further enhance efficiency. Additionally, we implement a latency-matching strategy and a flag-based mechanism to ensure seamless coordination between computational stages. Experimental results demonstrate the superior efficiency of our FPGA accelerator across geological models. Against a 12-core Intel Xeon CPU, the FPGA achieves 12.3 $$\times$$ speedup and 27.1 $$\times$$ energy efficiency for the uniform Basin Model, delivering 1.8 $$\times$$ the energy efficiency of the contemporary RTX 2080 GPU. For the irregular Mountain Model, it delivers 15.4 $$\times$$ speedup and 35.8 $$\times$$ energy efficiency over the same CPU, exceeding the RTX 4080 by 5.0 $$\times$$ in efficiency while approaching its computational throughput.},
  archive      = {J_SUPERC},
  author       = {Yuan, Ming and Liu, Qiang and Gan, Lin},
  doi          = {10.1007/s11227-025-07801-x},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {An FPGA-based efficient accelerator for fault interaction of rupture dynamics},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TestLock: A testability logic locking method against machine learning-based oracle-less attacks. <em>SUPERC</em>, <em>81</em>(14), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07803-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic Locking (LL) is a crucial technique for safeguarding intellectual property (IP) within the semiconductor supply chain. However, the emergence of sophisticated machine learning-based attacks has posed significant challenges to the security of LL designs. This paper introduces TestLock, a novel LL method that leverages circuit testability metrics to enhance resistance against these advanced threats. By strategically selecting node pairs based on their controllability and observability, TestLock significantly obfuscates the circuit’s internal structure, making it considerably more difficult for attackers to identify and exploit vulnerabilities. The proposed method is lightweight in computation, while introducing only modest hardware overhead, making it applicable to a wide range of hardware designs. Furthermore, due to the systematic nature of SCOAP-guided node selection and the scalability of the approach, TestLock can be effectively integrated into large-scale systems. As modern security-critical applications increasingly rely on high-throughput and real-time performance, TestLock offers a logic-level defense mechanism that aligns with the requirements of secure implementations. Additionally, evaluation against state-of-the-art attacks, including MuxLink and SCOPE, demonstrates that TestLock’s superior performance in preserving IP integrity. Our results indicate a substantial reduction in attack accuracy, with a 57.13% decrease observed for MuxLink and a 24.22% reduction for SCOPE. TestLock offers a robust and effective defense against these attacks, safeguarding IP from unauthorized access and reverse engineering.},
  archive      = {J_SUPERC},
  author       = {Pandi, Marziye and Moghaddas, Mostafa and Beitollahi, Hakem},
  doi          = {10.1007/s11227-025-07803-9},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {TestLock: A testability logic locking method against machine learning-based oracle-less attacks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive evaluation framework for EMD-based steganography: Balancing capacity and security with upper bound analysis. <em>SUPERC</em>, <em>81</em>(14), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07804-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography is a technique to hide the presence of secret communication and can be used when one of the communication elements is under the enemy’s influence. The primary measure to evaluate steganography methods in a specific capacity is security. Therefore, in a certain capacity, reducing the number of changes in the cover media leads to a higher embedding efficiency and, thus, higher security of a steganography method. Generally, security and capacity conflict and the increase of one lead to the decrease of the other. A single criterion representing security and capacity simultaneously can help compare steganography methods. Exploiting modification direction (EMD) and methods based on it are a type of steganography techniques that optimize the number of changes resulting from embedding (security). Despite their effectiveness, existing evaluation metrics for EMD-based methods lack precision and comprehensiveness. The present study aims to provide an evaluation criterion for this group of steganography methods. In this study, after a general review and comparison of EMD-based steganography techniques, a method is presented for their precise comparison from the perspective of embedding efficiency. Initially, we conduct a thorough review and comparative analysis of existing EMD-based steganography methods to identify their strengths and limitations. Building on this foundation, we introduce an enhanced embedding efficiency formula that accurately quantifies the impact of one or more-pixel changes, providing a more nuanced assessment of embedding performance compared to traditional metrics. Our results demonstrate that the proposed embedding efficiency formula offers superior performance evaluation, particularly in scenarios involving multiple pixel alterations. Furthermore, we establish an upper bound analysis to determine the theoretical maximum embedding efficiency achievable for any given capacity. This upper bound serves as a benchmark for assessing the optimal performance of EMD-based methods. Finally, leveraging the upper bound, we present an additional evaluation criterion that facilitates a more precise and meaningful comparison of EMD-based steganography methods.},
  archive      = {J_SUPERC},
  author       = {Rafiei, Hanieh and Mahdavi, Mojtaba and NaghshNilchi, Ahmad Reza},
  doi          = {10.1007/s11227-025-07804-8},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {A comprehensive evaluation framework for EMD-based steganography: Balancing capacity and security with upper bound analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dense pyramid convolutional neural network for MRI brain tumor segmentation. <em>SUPERC</em>, <em>81</em>(14), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07805-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation is a crucial aspect of medical image analysis that distinguishes brain tumors from adjacent normal tissues in magnetic resonance imaging (MRI) scans. The objective of this task is to generate a binary or multi-class segmentation mask, meticulously delineating the precise location and extent of the identified tumor within the imaging data. Current paradigms for medical image segmentation, exemplified by variations of encoder–decoder architectures such as fully convolutional networks (FCNs) and a spectrum of U-shaped networks (e.g., U-Net and UNet++), have achieved notable success. However, they suffer from three persistent challenges: (1) the confinement of multi-scale feature extraction, (2) the encounter with feature map sparsity, and (3) the neglect of long-range dependencies. To address these limitations, we propose DensePyConvNet, a densely connected pyramid convolutional network tailored for accurate and efficient brain tumor segmentation in MRI. The model integrates multi-scale feature extraction, dense skip connection, and strip pooling strategy, achieving state-of-the-art performance on both Kaggle_3m and BraTS2019 datasets. Given the high-resolution, multi-modal nature of medical imaging data and the clinical imperative for real-time diagnosis, DensePyConvNet is designed with high-performance computing (HPC) deployment in mind. The proposed architecture exhibits strong parallelism and low-latency inference, making it well-suited for GPU acceleration, large-scale processing, and integration into time-critical diagnostic pipelines.},
  archive      = {J_SUPERC},
  author       = {Xiong, Wei and Song, Haina and Xie, Honggang and Li, Yan},
  doi          = {10.1007/s11227-025-07805-7},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {A dense pyramid convolutional neural network for MRI brain tumor segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient and efficient edge server placement in mobile edge computing: A dual-strategy approach for optimized performance and fault tolerance. <em>SUPERC</em>, <em>81</em>(14), 1--51. (<a href='https://doi.org/10.1007/s11227-025-07807-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) enhances quality of service (QoS) by offloading workloads to nearby edge servers (ESs). The performance of MEC networks critically depends on edge server placement (ESP), the strategic decision of where to locate ESs and how to assign base stations (BSs) to them. While many studies focus on minimizing latency, they often overlook network resilience, creating a critical performance gap. Addressing this, our study presents a framework that formulates ESP as a unified optimization problem to simultaneously minimize access delay, balance workload distribution, and provide fault tolerance. To solve this, we propose an efficient two-step heuristic algorithm. Step one determines the optimal physical locations for ESs by applying the K-medoids clustering algorithm to BS traffic data, placing servers at the center of demand clusters to minimize latency. Step two then implements a resilient assignment mechanism: A custom heuristic allocates each BS to both a primary ES for normal operation and hot-backup ES (dual-active) for failover, thereby embedding fault tolerance directly into the network topology. This integrated approach is governed by constraints on ES capacity, latency thresholds, and service-level agreements (SLAs). Extensive experiments using real-world datasets validate our approach. In a unified benchmark conducted on the Shanghai Telecom dataset, comprising 3000 BSs and 300 ESs, our Resilient Edge Server Placement (RESP) method achieves the lowest mean access delay of 0.038, with strong workload balance (variance σ = 6.8 × 105 requests per minute) and the highest resilience, with a failover success rate (FSR) of 0.90 and a redundancy coverage (RC) of 0.93. This performance approaches the FSR of a robust optimization baseline (0.93) while maintaining a lower delay. Under outage scenarios affecting up to 20% of ESs, RESP sustains an FSR of at least 0.90 for random outages and at least 0.85 for correlated outages, whereas the best competing baseline falls below 0.65. Additionally, RESP’s dual-active operation limits burst queuing delay to below 2 s at a load factor (λ) of approximately 0.8. Results demonstrate significant reductions in access delay and workload variance compared to baseline methods. Crucially, our model maintains reliable and responsive performance under simulated ES failure scenarios, confirming the effectiveness of the embedded resilience. These findings underscore the necessity of integrating resilience-aware placement and assignment strategies and highlight RESP’s practical impact for mission-critical, latency-sensitive MEC deployments.},
  archive      = {J_SUPERC},
  author       = {Asl, Arman Sanaei and Hashemi, Massoud Reza},
  doi          = {10.1007/s11227-025-07807-5},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--51},
  shortjournal = {J. Supercomput.},
  title        = {Resilient and efficient edge server placement in mobile edge computing: A dual-strategy approach for optimized performance and fault tolerance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language identification based on multi-scale feature recursive fusion and adaptive loss. <em>SUPERC</em>, <em>81</em>(14), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07808-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language identification is a core technology in the field of multilingual information processing, and its goal is to automatically identify the corresponding language by analyzing speech signals. However, existing approaches face three major challenges: (1) the limited representation capacity of single-scale features for complex speech patterns, (2) suboptimal model performance caused by single-objective optimization, and (3) the computational intensity of processing high-dimensional speech data. To effectively address these computational challenges, powerful supercomputing capabilities have become the key support for advancing research. Based on this, this study innovatively proposes a method based on multi-scale features recursive fusion and adaptive loss, which is referred to as MSFRF-AL. Specifically, the wav2vec2.0 pre-trained model is first used for feature extraction. The extracted features are then sent to the multi-scale feature recursive fusion network (MSFRF-Net) for fusion from different time scales. Then, the fused features are sent to the simple back-end architecture composed of the statistics pooling layer and the fully connected layer. Finally, the proposed adaptive loss is employed to optimize the model training process. This objective function consists of cross-entropy and efficient triplet loss, combining classification ability and feature representation ability to simultaneously enhance feature discrimination and classification accuracy. Experiments are verified on three tasks of the OLR2020 dataset. The experimental results show that this method can effectively reduce the interference of the external environment on language identification, especially demonstrating stronger robustness in cross-channel and noisy environments, and significantly improving the performance of language identification.},
  archive      = {J_SUPERC},
  author       = {Li, Weiwei and Chen, Chen and Chen, Yong and Chen, Deyun},
  doi          = {10.1007/s11227-025-07808-4},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Language identification based on multi-scale feature recursive fusion and adaptive loss},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STMACN: Spatial–temporal multi-scale auto-correlation network for traffic forecasting. <em>SUPERC</em>, <em>81</em>(14), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07809-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction, as a key technology in intelligent transportation systems, presents significant challenges due to numerous influencing factors, including the complexity of traffic conditions and the rapid, dynamic temporal changes they exhibit. Although several traffic prediction models have achieved promising results, there remains potential for improvement in spatial–temporal dynamic modeling and the integration of local and global information. This paper introduces a Spatial–Temporal Multi-scale Auto-Correlation Network (STMACN) for traffic prediction. STMACN includes a spatial–temporal embedding layer, a spatial attention module, a temporal auto-correlation module, and a multi-scale attention fusion module. The spatial–temporal embedding layer integrates graph node information and temporal cycles into the input data, thereby enhancing the prior knowledge. The spatial attention module adaptively mines spatial correlations between sensor nodes in the road network. The temporal auto-correlation module models long-term temporal dependencies and captures periodic features using the auto-correlation mechanism. The multi-scale attention fusion module further enhances the temporal auto-correlation module’s ability to capture periodic features at different time scales and improves the perception of local changes. Experimental results on four real-world traffic datasets show that our proposed STMACN outperforms state-of-the-art models. The source code and data are available at https://github.com/NathanZ137/STMACN .},
  archive      = {J_SUPERC},
  author       = {Hong, Yuling and Zhang, Jiaqi},
  doi          = {10.1007/s11227-025-07809-3},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {STMACN: Spatial–temporal multi-scale auto-correlation network for traffic forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum-inspired adaptive mutation operator enabled PSO (QAMO-PSO) for parallel optimization and tailoring parameters of Kolmogorov–Arnold network. <em>SUPERC</em>, <em>81</em>(14), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07810-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimizer (PSO) is a biomimetic optimization algorithm well-known for its potential in addressing diversified optimization problems (OP). Although PSO is based on swarm-cognitive, it often suffers from attaining the global optima and the balance between exploration and exploitation, leading to untimely convergence and compromised outcomes. To enhance such shortcomings, we have proposed the quantum adaptive mutation operator PSO (QAMO-PSO), where the QAMO is integrated with the standard PSO. In the suggested approach, the qubit dynamics and adaptable mutation concept are employed to amplify the search region of swarms, while preserving superior outcomes by altering the locations of swarms concerning the quanta rotation and including a dynamic quantum-inspired mutation mechanism. The QAMO frameworks concurrently modify the mutation likelihood regarding the global best fitness, adhering it to randomness to suppress the confined optima alongside accelerating optimal convergence. The competency of QAMO-PSO is rigorously quantified over the IEEE-CEC-2022 benchmark problem suite. The anticipated QAMO-PSO reveals commendable findings over the shifted and rotated (SR), hybrid and composition functions pertaining to CEC-2022. Furthermore, a cascade of statistical analysis is conducted to substantiate the distinctiveness of QAMO-PSO. Additionally, the applicability of QAMO-PSO is assessed in real-life constraints by tuning the hyperparameters of Kolmogorov–Arnold network (KAN), showcasing its efficacy in multivariate and nonlinear feature space. The QAMO-PSO as a trainer algorithm for KAN reveals prevailing results over the other baseline algorithms. Finally, the QAMO-PSO is a viable and reliable hybrid algorithm (HA) to tackle optimization problems related to engineering and computational cognition.},
  archive      = {J_SUPERC},
  author       = {Agrawal, Umang Kumar and Panda, Nibedan},
  doi          = {10.1007/s11227-025-07810-w},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Quantum-inspired adaptive mutation operator enabled PSO (QAMO-PSO) for parallel optimization and tailoring parameters of Kolmogorov–Arnold network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rtl design flaws revisited: A data-driven study of systematic bug patterns in verilog code. <em>SUPERC</em>, <em>81</em>(14), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07811-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware description languages are fundamental to modern digital circuit design, allowing engineers to model the structure, behavior, and functionality of complex systems at high levels of abstraction. As formal specifications bridging algorithmic design and physical implementation, HDLs support accurate modeling and efficient hardware development. However, HDL bugs can lead to functional failures, financial losses, and safety risks. Systematically identifying bug patterns in hardware designs provides valuable insights for bug benchmark construction, facilitating bug localization and the development of automated verification tools. Given that high-performance computing systems often rely on custom RTL designs, improving RTL correctness plays an important role in enhancing the efficiency of verification and debugging in HPC hardware development. Despite the growth of open-source hardware initiatives, empirical research in this field still lags behind established practices in software engineering. This paper presents a large-scale empirical study of RTL Verilog bugs, combining automated analysis with statistical pattern discovery. It makes three key contributions: (1) the development of an AST-based automated analysis tool for Verilog code; (2) an examination of over 300 open-source Verilog projects, analyzing more than 15,000 commits and extracting over 1000 bug-fix-related commits; and (3) a comprehensive statistical analysis of bug types and distributions, with a focus on statement-level and expression-level patterns.},
  archive      = {J_SUPERC},
  author       = {Meng, Xiankai and Ji, Xiang and Zhang, Guangda and He, Jiayu and Yang, Deheng and Chen, Fangshu and Wang, Jiahui and Yu, Chengcheng and Zhao, Xinlin and Wu, Jiang},
  doi          = {10.1007/s11227-025-07811-9},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Rtl design flaws revisited: A data-driven study of systematic bug patterns in verilog code},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fgcfl: A fine-grained clustering framework for federated learning with heterogeneity data. <em>SUPERC</em>, <em>81</em>(14), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07813-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered federated learning (CFL) addresses data heterogeneity in federated learning by grouping clients with similar data distributions into independent clusters, thus overcoming the limitations of a single global model that cannot meet the personalized needs of all devices. However, existing clustering methods face challenges due to the unknown number of clusters, which may not truly reflect the data distribution. Besides, most clustering methods focus on enabling collaboration among clients within the same cluster, without considering cooperation between similar clusters, which limits the scope of knowledge dissemination. To address these issues, we propose a fine-grained clustering framework (FGCFL) that introduces a benchmark distribution and refines cluster divisions by aggregating clients located between similar distribution clusters. Based on the refined clusters, self-attention is employed to facilitate collaboration among them, promoting inductive knowledge transfer between similar clusters. Experimental results on several datasets show that our proposed method considerably increases model performance under heterogeneity scenarios.},
  archive      = {J_SUPERC},
  author       = {Wang, Ying and Xu, Jiuyun and Yuan, Qianxi and Bai, Yulong and Yang, Yuhang and Xu, Xiangrui and Batool, Hina},
  doi          = {10.1007/s11227-025-07813-7},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Fgcfl: A fine-grained clustering framework for federated learning with heterogeneity data},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced road object detection with DFPD-YOLO: Focusing on small and occluded targets. <em>SUPERC</em>, <em>81</em>(14), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07815-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time detection of small and occluded objects in complex road scenes remains highly challenging, as models must simultaneously achieve accurate recognition, high throughput, and low latency. To tackle this issue, we propose DFPD-YOLO, an enhanced YOLOv8-based detector optimized for deployment efficiency. The model integrates a feature-focused diffusion pyramid neck to reinforce multi-scale contextual representation, a dynamic task alignment detection head to leverage joint features with reduced computational cost, and the WIoU loss to enhance localization precision. Extensive experiments demonstrate that on the KITTI dataset, DFPD-YOLO outperforms the baseline YOLOv8n by 4.5% mAP@50 while sustaining 242.4 FPS, and on the BDD100K dataset, it achieves a 2.2% mAP@50 improvement with 295.7 FPS. These results confirm the model’s capability to deliver both high detection accuracy and real-time performance, making it well suited for deployment in intelligent transportation and road safety systems on high-performance platforms, highlighting its suitability for HPC-oriented real-time applications.},
  archive      = {J_SUPERC},
  author       = {Liu, Zifeng and Li, Lujiao and Hu, Yongbin and Hu, Shigang},
  doi          = {10.1007/s11227-025-07815-5},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Enhanced road object detection with DFPD-YOLO: Focusing on small and occluded targets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-task test case optimization framework with integrated explainable AI for customer churn prediction. <em>SUPERC</em>, <em>81</em>(14), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07816-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel Test Case Optimization Framework for customer churn prediction, integrating multi-task deep learning and explainable artificial intelligence. The proposed model simultaneously predicts churn status, credit score category, and high-balance risk using a shared neural architecture with task-specific output heads. A systematic set of test cases was generated, each defined by distinct configurations of training epochs, batch size, loss weights, and focal loss strategies. The optimal model was selected based on an optimization score that combines F1-score, recall, and performance stability. Experiments conducted on a large-scale banking dataset of 1 million customers demonstrate the effectiveness of the framework. The model achieved 83.05% accuracy, 83.05% recall, and 83.37% F1-score on the churn task, outperforming classical baselines such as Logistic Regression, Support Vector Machine, and Multilayer Perceptrons. Additionally, it attained 96.20% and 98.75% accuracy on the auxiliary tasks of credit score classification and balance flag detection, respectively. To improve interpretability, a lightweight rule-based XAI module was embedded to generate global and local churn explanations, while a risk alert system proactively identified high-risk customers. The results highlight the framework’s potential for building accurate and trustworthy churn prediction systems in real-world applications. The computational demands of evaluating numerous deep multi-task configurations on a million customer dataset necessitate high-performance computing resources. By executing test case generation, training, and evaluation in parallel across multi-GPU or distributed HPC clusters, the framework reduces runtime from days to hours, enabling near real-time model updates. This is feasible because each test case configuration is independent, allowing concurrent execution of generation, training, and evaluation without any inter-process dependencies.},
  archive      = {J_SUPERC},
  author       = {Trinh, Thanh Binh and Vu, Van Hieu and Nguyen, Thi Van},
  doi          = {10.1007/s11227-025-07816-4},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {A multi-task test case optimization framework with integrated explainable AI for customer churn prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ELDM-EDSDN: A novel resource allocation method in edge-DSDN-based networks using improved manifold approach. <em>SUPERC</em>, <em>81</em>(14), 1--91. (<a href='https://doi.org/10.1007/s11227-025-07817-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The over-reliance of current methods for task allocation and resource management in distributed software-defined networks (DSDN) on constraints and predefined assumptions about network behavior leads to severe efficiency degradation in operational environments. This inefficiency is due to the dynamic and unpredictable nature of DSDN networks. Hampering assumptions, such as applying static task entry models, lead to suboptimal management and utilization in resource allocation and task distribution. To overcome these limitations, this study presents a novel approach called ELDM-EDSDN based on the effective improvement of dynamic mappings and manifold rules for resource management and allocation in Edge-DSDN networks for proper utilization of network resources and optimal task execution. The processing load status of controllers is initially monitored in real time. Once controllers with dense processing loads are identified, an adaptive threshold-based decision-making mechanism is activated. Then, additional tasks are transferred to less loaded controllers by considering criteria such as processing capacity, network latency, and topographic distance. Relying on minimal initial assumptions and the best possible strategy, this process achieves load balancing in the network and effectively manages resource allocation. Simulation of the proposed method on OMNET++ under various scenarios, including changing the number of controllers, task volume, and network load level, proves that ELDM-EDSDN improves the response time of controllers, network load balancing, and latency by 14.5, 21.17, and 14.64 percent, respectively, compared to peer methods. Also, the proposed method is less sensitive to changes in the number of controllers, servers, virtual machines, and input tasks, which is crucial in real dynamic networks.},
  archive      = {J_SUPERC},
  author       = {Matinfar, Ehsan and Mahmoudi, Marjan and Barekatain, Behrang},
  doi          = {10.1007/s11227-025-07817-3},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--91},
  shortjournal = {J. Supercomput.},
  title        = {ELDM-EDSDN: A novel resource allocation method in edge-DSDN-based networks using improved manifold approach},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Splp-yolo: An all-weather real-time detector for airport runway foreign object debris. <em>SUPERC</em>, <em>81</em>(14), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07818-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Foreign Object Debris (FOD) on airport runways often disrupts operations while taking off and landing flights, leading to accidents. Small-scale FOD cannot manually rule out on time, which threatens aviation safety. To address these issues, this article proposes an improved real-time detection model, SPLP-YOLO, based on the You Only Look Once (YOLO) architecture, which integrates multiple innovative designs for efficient and accurate FOD detection. Firstly, a spatial-to-depth (SPD) convolution module is introduced to preserve detailed information of small targets. Secondly, the novel Coarse-to-Fine Large Separable Kernel Attention (C2F-LSKA) module is proposed, combining multi-branch feature diversion with separable large-kernel attention mechanisms to enhance local and global feature modeling capabilities. Moreover, the Bi-level Routing Attention (BRA) mechanism is employed to refine attention modeling and improve small-object detection accuracy. Additionally, a Powerful-IoU (PIoU) loss function is designed to accelerate convergence and optimize bounding box regression. The model further enhances small-object detection by incorporating a fourth detection head. Experimental results demonsstrate superior performance of SPLP-YOLO on both self-constructed and open-source FOD-A datasets, achieving mAP@0.5:0.95 scores of 0.67 and 0.936, respectively, which represent improvements of over 10% compared to Baseline, while maintaining an inference time of just 4.2ms (240 Frames Per Second). The proposed model also exhibits robust performance in complex environments such as rain, fog, and low illumination, providing a lightweight, highly accurate real-time solution for airport runway safety monitoring.},
  archive      = {J_SUPERC},
  author       = {Zhang, Runze and Wang, Ce and Li, Binru and Ye, Ouming and Xu, Xudong},
  doi          = {10.1007/s11227-025-07818-2},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Splp-yolo: An all-weather real-time detector for airport runway foreign object debris},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing streaks of consecutive numbers with the same collatz height. <em>SUPERC</em>, <em>81</em>(14), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07820-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing high-performance computing, lookup tables, and the property of coalescence with respect to Collatz sequences, we present an approach to computing streaks of consecutive integers with the same Collatz height. Of particular interest is the extension of the OEIS (On-Line Encyclopedia of Integer Sequences) sequence A277109 through element 3950. At the time of publication, 9336 of the first 10000 elements of this sequence have been established. The current longest confirmed streak is for $$2^{3951}+1$$ , with a streak of length $$2^{47}-1 \approx 10^{14.148}$$ .},
  archive      = {J_SUPERC},
  author       = {Frinkle, Karl and Rowland, Saxon and Pack, James and Gordon, Madison and Eskue, John and Egbe, Sardonyx and Morris, Mike},
  doi          = {10.1007/s11227-025-07820-8},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Computing streaks of consecutive numbers with the same collatz height},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust and scalable intrusion detection framework for SDN with GAN-CL-STO. <em>SUPERC</em>, <em>81</em>(14), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07821-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study presents GAN-CL-STO, a novel intrusion detection framework that integrates Generative Adversarial Networks (GANs), a 1D Convolutional-Long Short-Term Memory (CL) network, and hyperparameter tuning via the Siberian Tiger Optimization (STO). The model was implemented in Keras and trained over 50 epochs with a batch size of 16, and evaluated on three benchmark datasets (UNSW-NB15, CIC-IDS2017, and NSL-KDD). GAN-CL-STO achieved consistently higher accuracy compared to existing methods such as Transformer, Graph Neural Networks (GNNs), Fuzzy System, Reinforcement Learning, CNN-LSTM, PSO-1D CNN and 1D CNN + BiLSTM, reaching an overall accuracy of 99.91%. Compared to previous approach, the framework improved classification accuracy by 4.06%, mainly due to better feature selection and dynamic hyperparameter adjustment, while keeping computational costs low. During testing, the model showed a fast interface response time of 1.42 ms and an average latency of 33.7 ms, making it suitable for real-time SDN intrusion detection. One-way ANOVA analysis confirmed the reliability of these results, with all p-values below 0.05. The outcomes suggest that GAN-CL-STO could be a practical and reliable solution for strengthening modern network security. Additionally, the framework incorporates a steganography-based blacklist sharing mechanism, ensuring both feasibility and security for real-time SDN deployment.},
  archive      = {J_SUPERC},
  author       = {Al-Sarray, Naseer Hameed Saadoon and Demirhan, Ayşe and Rahebi, Javad},
  doi          = {10.1007/s11227-025-07821-7},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {A robust and scalable intrusion detection framework for SDN with GAN-CL-STO},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing green development in 3D medical image segmentation: A novel lightweight, semi-supervised framework. <em>SUPERC</em>, <em>81</em>(14), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07824-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning-driven 3D medical image segmentation, designing deep and complex network structures has become the trend. This enhances segmentation accuracy; however, it results in computational complexity, increased parameters, and unnecessary dependencies. Facing the challenges of complex structures and labeling difficulties in 3D medical images, we propose a novel lightweight semi-supervised learning framework, namely NLNet. It aims to promote the green and sustainable development of deep learning-driven medical image segmentation. For network lightweight in semi-supervised learning, we explore the essential mechanism of lightweight and seek the optimal balance between model performance and lightweight architecture. In the superficial layer, efficient and lightweight convolutional modules (Lite3DConvBlock) and a lightweight encoder (Lite3DEncoder) architecture are designed to accurately capture the basic edge, color, and texture information of 3D medical images. In the middle layer, we design a deep kernel attention convolutional module (DKAC) and mine complex features such as shapes and patterns. In the deep layer, a lightweight decoder (Lite3DDecoder) is designed to efficiently differentiate high-level structure from background information. We conduct an experimental assessment of the proposed model against mainstream state-of-the-art methods on left atrial (MRI) and pancreas (CT) datasets. The results indicate that our model leads in MACs, FLOPs, Params and File Size metrics. Meanwhile, the Dice, HD95, and ASD scores of our model achieve a better performance.},
  archive      = {J_SUPERC},
  author       = {Chen, Lei and Zhao, Yikai and Yang, Dongxu and Hou, Jieru and Liu, Wenhao},
  doi          = {10.1007/s11227-025-07824-4},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Advancing green development in 3D medical image segmentation: A novel lightweight, semi-supervised framework},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdApTS: Adaptive approximate computing-based traffic sign recognition unit for self-driving cars. <em>SUPERC</em>, <em>81</em>(14), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07825-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive approximate computing-based traffic sign recognition unit for self-driving cars called AdApTS. Traffic sign recognition is one of the critical activities of self-driving vehicles that should be performed accurately on the cameras’ outputs. To this aim, deep learning-based image processing schemes provide acceptable accuracy, but their computation overhead is very high for the resource-constrained systems. The proposed AdApTS employs non-uniform approximations in the computations of a convolutional neural network as the best image processing option. To this aim, the redundant and unimportant computations in kernel and input image processing are derived and approximated. The important information about traffic signs is generally embedded in their shape and center; thus, the dynamic segmentation of them leads to appropriate results. This significantly decreases the computation cost and response time while maintaining an appropriate level of accuracy. To demonstrate the effectiveness of the proposed AdApTS, several experiments on real-world traffic signs are performed. Based on these experiments, AdApTS improves the response time by about 71% in cost of 2.1% accuracy degradation by focusing on approximate kernel or input computations. In the case of combining the kernel and input approximation, AdApTS provides 92.8% accuracy in 2.43 s. Compared to related approximation-based studies, our proposed AdApTS outperforms accuracy and response time by 13.03% and 14.8%, respectively.},
  archive      = {J_SUPERC},
  author       = {Omidian, Fatemeh and Abdi, Athena and Hamed-Rouhbakhs, Alireza},
  doi          = {10.1007/s11227-025-07825-3},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {AdApTS: Adaptive approximate computing-based traffic sign recognition unit for self-driving cars},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluation of diverse graph-based models on homogeneous datasets. <em>SUPERC</em>, <em>81</em>(14), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07826-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have emerged as powerful tools for analyzing graph-structured data with applications in social networks, bioinformatics, and recommender systems. However, existing GNNs struggle with (1) rigid edge weighting (e.g., GCN’s fixed normalization), (2) over-smoothing in deep layers, and (3) quadratic attention costs (e.g., GAT). MGCN introduces: (1) adaptive edge weighting to dynamically adjust neighbor influence, (2) residual connections to combat over-smoothing, and (3) a scalable attention mechanism. It also introduces a standardized evaluation framework that incorporates adaptive preprocessing techniques such as feature normalization, edge weighting, and graph augmentation. The proposed model demonstrated superior performance when compared to eight state-of-the-art GNN models such as GraphSAGE, GAT, Graph Transformer, GINConv, GCN, GraphCL, AGCN, and MGCN, across three widely used benchmark datasets: Cora, CiteSeer, and PubMed. All evaluation metrics–including Accuracy, Hit Ratio, Precision, Recall, and F1 Score–are reported as the mean ± standard deviation over 10 independent runs. The experimental results consistently demonstrate the superiority of the proposed MGCN model with approximately $$2\%$$ improvement on above datasets.},
  archive      = {J_SUPERC},
  author       = {Chitla, Vinay Santhosh and Kalluri, Hemantha Kumar and Nunna, Satya Krishna},
  doi          = {10.1007/s11227-025-07826-2},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Performance evaluation of diverse graph-based models on homogeneous datasets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REA-YOLO for small object detection in UAV aerial images. <em>SUPERC</em>, <em>81</em>(14), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07836-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in UAV aerial images faces challenges such as complex backgrounds, dense small objects, and mutual occlusion, resulting in blurred object-background boundaries and reduced localization accuracy. In this paper, we propose REA-YOLO, an object detection algorithm designed to enhance small object detection accuracy and achieve model lightweight. YOLOv11 serves as the base model for our improvements. We introduce the REA module, which addresses the blurring of small object-background boundaries by aggregating multi-scale information and recalibrating edge features. Subsequently, the small object detection layer and dynamic detection head are integrated into the model to adaptively optimize the detection strategy and enhance small object extraction. The requirements for real-time inference of the model on the UAV platform impose a computational load. After training, the model is pruned using a pruning algorithm to reduce its size. Finally, REA-YOLO is deployed and tested on embedded devices, improving small object detection accuracy while ensuring real-time performance. Extensive experiments on both public and self-built datasets demonstrate the effectiveness and sophistication of REA-YOLO for small object detection in aerial images.},
  archive      = {J_SUPERC},
  author       = {Zhang, Jinhang and Gao, Min and Song, Liqiang and Zhao, Haitao and Li, Wenzhao and Zhang, Zetian and Rong, Chenglin},
  doi          = {10.1007/s11227-025-07836-0},
  journal      = {The Journal of Supercomputing},
  month        = {9},
  number       = {14},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {REA-YOLO for small object detection in UAV aerial images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality medical image fusion by edge supervising and multi-scale attention features extraction. <em>SUPERC</em>, <em>81</em>(13), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07601-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the development of deep learning, multimodal medical image fusion (MMIF) has achieved both efficiency and real-time performance. However, most existing deep learning-based fusion methods primarily focus on the overall network architecture, often overlooking the intrinsic characteristics of the source images. From the perspectives of SPECT and PET imaging and the continuity of biological information, the edge regions of these functional images should receive greater attention during the fusion process. Furthermore, the pseudocolor should be separated before fusion and reintroduced afterward. Since functional images such as SPECT and PET typically suffer from low clarity, directly fusing them without proper processing may obscure texture details in the resulting image. To address these challenges, we propose an end-to-end encoder–decoder network for multimodal medical image fusion, termed EFCNet. The encoder comprises three main components: a smooth edge extraction module (SEEM), a multi-scale attention module (MSAM), and the E-Fusion module. The decoder reconstructs the fused image from these features. Specifically, SEEM extracts and smooths the edge information of functional source images (SPECT and PET), thereby mitigating the issues mentioned above. MSAM captures both local details and global contextual features while adaptively emphasizing more informative channels. E-Fusion then performs effective fusion of the extracted local and global features. Notably, our model is trained on a single dataset to obtain the pretrained weights, yet it achieves impressive results when tested on other datasets, demonstrating the strong generalization capability of the proposed method. The implementation of our proposed method is available on GitHub at https://github.com/VCMHE/EFCNet .},
  archive      = {J_SUPERC},
  author       = {Mei, Wencheng and He, Kangjian and Xu, Dan and Xie, Siqi and Zhou, Yiqiao},
  doi          = {10.1007/s11227-025-07601-3},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Multi-modality medical image fusion by edge supervising and multi-scale attention features extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAN-assisted data augmentation to enhance detection accuracy of evasive spectre attacks. <em>SUPERC</em>, <em>81</em>(13), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07691-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectre attacks exploit the speculative execution features of processors to leak sensitive information through side channels and has been a significant threat for hardware security recently. More importantly, Evasive Spectre attacks such as inserting Nop instructions or memory access delay instructions in the attack code further weaken the characteristics of Spectre attacks to reduce the detection accuracy. Therefore, it is significant to improve machine learning-based detection accuracy of Evasive Spectre attacks to minimize the extra performance loss of defenses. To address this challenge, this paper proposes a novel detector of Evasive Spectre attacks using generative adversarial network (GAN) assisted data augmentation (GAN-DES). The proposed detector GAN-DES trained with both the original Spectre data and the generated data by GAN can capture the potential characteristics of diverse Evasive Spectre attacks. Unlike existing work to select new features or redesign learning architectures, GAN-DES is the first work to enhance dataset for detecting Evasive Spectre attacks by leveraging GAN. Our experimental results show that GAN-DES achieves a 100% attack detection success rate and a non-attack detection success rate between 95.3 and 99.8%, higher than the state-of-the-art works for Nop and memory delay based Evasive Spectre attacks.},
  archive      = {J_SUPERC},
  author       = {Jiao, Jiajia and Jiang, Ling and Wen, Ran},
  doi          = {10.1007/s11227-025-07691-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {GAN-assisted data augmentation to enhance detection accuracy of evasive spectre attacks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid algorithm based on differential evolution for reliability–redundancy allocation problem of a series system under multiple brands. <em>SUPERC</em>, <em>81</em>(13), 1--59. (<a href='https://doi.org/10.1007/s11227-025-07708-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this work is to develop a hybrid algorithm based on differential evolution and Rao algorithms via tournamenting process and named this algorithm as TDERAO algorithm. The hybrid algorithm is applied to solve reliability–redundancy allocation problems (RRAP) for series system in which parallel redundancy is considered. The redundant components are selected from different brands so as to maximize the system reliability subject to budget, weight and volume. Several RRAPs are considered involving crisp as well as interval-valued objective functions and several constraints, based on cost, weight and volume, are considered. The problems having interval-valued functions are newly introduced in this work. In this connection, five RRAPs are formulated and four examples for each problem are considered and solved using TDERAO algorithm. The results obtained from the proposed algorithm are compared with those of the existing algorithms.},
  archive      = {J_SUPERC},
  author       = {Akhtar, Md and Mandal, Goutam and Bhunia, Asoke Kumar},
  doi          = {10.1007/s11227-025-07708-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--59},
  shortjournal = {J. Supercomput.},
  title        = {A hybrid algorithm based on differential evolution for reliability–redundancy allocation problem of a series system under multiple brands},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient partitioned semi-clairvoyant scheduling in mixed-criticality system with graceful degradation. <em>SUPERC</em>, <em>81</em>(13), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07711-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works have focused on non-clairvoyant task models in mixed-criticality systems (MCS) with multiprocessor platforms, where the completion of high-criticality (HI) tasks determines the behavioral changes of the system. In this research, we explore semi-clairvoyant scheduling in MCS with graceful degradation. Jobs will have the ability to know whether their execution time will exceed the worst-case execution time in the low-criticality (LO) mode at their arrival time. We propose an energy-aware algorithm to determine the optimal speed for energy efficiency in the LO mode on each processor, and then we present a novel energy-efficient partitioned semi-clairvoyant scheduling algorithm, named EEPSCMC, aimed at reducing the energy consumption of the system. We perform experiments to evaluate EEPSCMC in comparison with four other heuristic algorithms, and the experimental results demonstrate that EEPSCMC outperforms other algorithms, exhibiting superior performance in terms of normalized energy consumption, saving up to $$13.05\%$$ of energy compared to the existing algorithms.},
  archive      = {J_SUPERC},
  author       = {Ma, Jin-Peng and Zhang, Yi-Wen},
  doi          = {10.1007/s11227-025-07711-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Energy-efficient partitioned semi-clairvoyant scheduling in mixed-criticality system with graceful degradation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying vital spreaders in multiplex networks: Measurement of layer dominance and a closeness-based layer gravity method. <em>SUPERC</em>, <em>81</em>(13), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07713-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration of multiplex networks has become an emerging field of research due to the existence of different layers with diverse connectivity structures in almost every real network. Effectively managing a multiplex network is challenging, requiring the identification of vital spreaders (i.e., nodes) by measuring their importance. After reviewing the existing studies, it becomes clear that the dominance of individual layers has not been systematically evaluated in isolation in multiplex networks. In this study, we present a novel approach to measure the dominance of individual layers depending on two distinct parameters: node activeness and edge activeness. After that, we calculate the centrality value for each node on a per-layer basis and construct a centrality vector based on existing centrality methods and a novel Closeness-based Layer Gravity (CLG) method. Finally, the vital spreaders are identified by evaluating the importance of nodes through a mapping technique that aggregates the dominance of the layers with centrality values of the nodes from the respective layers. This proposed framework independently measures layer dominance and identifies vital spreaders, making it well suited for distributed and high-performance computing environments, and ensuring scalability across large multiplex networks. The performance of our proposed method is evaluated against the multiplex-based SIR epidemic simulator, and we observe that amalgamating our proposed layer dominance concept with the CLG method effectively identifies vital nodes, achieving a maximum average ranking similarity of $$80.93\%$$ across various percentages of identified spreaders, considering eight real multiplex networks. By evaluating network robustness through the normalized LCC (Largest Connected Component) value after removing various percentages of identified spreaders, our method achieves the lowest average normalized LCC value of 0.751, outperforming state-of-the-art approaches.},
  archive      = {J_SUPERC},
  author       = {Nandi, Suman and Maji, Giridhar and Dutta, Animesh},
  doi          = {10.1007/s11227-025-07713-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Identifying vital spreaders in multiplex networks: Measurement of layer dominance and a closeness-based layer gravity method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PLazyQML: A parallel package for efficient execution of QML models on classical computers. <em>SUPERC</em>, <em>81</em>(13), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07714-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning, positioned at the convergence of quantum computing and artificial intelligence, is an emerging and highly promising field, primarily due to its potential to enhance the performance of classical machine learning systems. As this area is developing at an exceptionally rapid pace, it is essential to remain up to date with the latest advancements and research. This paper introduces pLazyQML, a software package designed to accelerate, automate, and streamline experimentation with quantum machine learning models on classical computers. pLazyQML reduces the complexity and time required for developing and testing quantum-enhanced machine learning models. Comprehensive experiments on established models and datasets demonstrate the efficiency, scalability, and workflow simplification provided by pLazyQML, making it a valuable tool for researchers and practitioners in quantum machine learning.},
  archive      = {J_SUPERC},
  author       = {García-Vega, Diego and Plou-Llorente, Fernando and Leal-Castaño, Alejandro and Combarro, Elías F. and Ranilla, José},
  doi          = {10.1007/s11227-025-07714-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {PLazyQML: A parallel package for efficient execution of QML models on classical computers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–frequency consistency and bias-corrected for few-shot object detection. <em>SUPERC</em>, <em>81</em>(13), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07716-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning-based few-shot object detectors often face challenges like feature semantic bias and class distribution bias due to limited sample availability. These challenges stem from incomplete feature semantic representations and imbalanced class distributions. Spatial–frequency-domain fusion analysis, a powerful technique for extracting global features and enhancing key frequency-domain information, provides a new approach to address these issues. In this context, this paper introduces a spatial-frequency consistency and bias-corrected for few-shot object detection. To address feature semantic bias, we propose a multi-frequency feature fusion module that decouples image-level features into non-uniform low- and high-frequency components, which are then fused with multi-scale features to improve both local and global semantic understanding by leveraging semantic information at various frequency levels. For class distribution bias, we introduce a space-frequency distribution consistency module that jointly models structural information in the spatial domain with global properties in the frequency domain. By aligning the reconstruction process in the spatial domain with frequency-domain distribution consistency, our model becomes adaptable to diverse data distributions. Additionally, we propose a frequency-domain distribution alignment loss function to mitigate class imbalance by aligning class distributions across frequency layers. Experimental results in the PASCAL VOC and MS COCO datasets demonstrate that our approach outperforms traditional methods and baseline models such as VFA, showing significant improvements in detection accuracy, stability, and adaptability.},
  archive      = {J_SUPERC},
  author       = {Yan, Lirong and Zhang, Yongbing and Tang, Xiaofen},
  doi          = {10.1007/s11227-025-07716-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Spatial–frequency consistency and bias-corrected for few-shot object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel heterogeneous graph learning based internet of things multivariate time series anomaly detection and explanation via cross-channel feature fusion. <em>SUPERC</em>, <em>81</em>(13), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07717-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volume of data from internet of things (IoT) systems has increased dramatically, so anomaly detection for multivariate time series data collected by IoT systems is becoming particularly important. However, due to the lack of anomaly labels and the dimensional complexity of the data, it is a challenge to build an effective detection model with high accuracy and strong robustness. This paper proposes an unsupervised anomaly detection model based on heterogeneous graph neural networks, Parallel Heterogeneous Graph Learning based Unsupervised Anomaly Detection and Explanation via Cross-channel Feature Fusion. The model achieves outstanding anomaly detection accuracy and generalization through two instances of cross-channel feature fusion. Firstly, in terms of nonlinear feature extraction, we utilize temporal convolutional network connected with squeeze-and-excitation network for temporal dependency extraction and enhancement of crucial features. We employ heterogeneous graph neural network and graph attention network to extract local and global features in parallel. After cross-channel feature fusion, Transformer is embedded for contextual information extraction. Secondly, after extracting linear features using vector autoregression, we perform secondary cross-channel feature fusion of both nonlinear and linear features, to achieve better robustness. Lastly, we incorporate an interpretation module. We compare the performance of the proposed model with 10 baseline methods on 5 public datasets. The experimental results show that the proposed model can achieve 0.930 in terms of F1-score, which is superior to ten state-of-the-art methods by 4.83%. Our source code is available at: https://github.com/xiqinghui/PUC.git .},
  archive      = {J_SUPERC},
  author       = {Xi, Qinghui and Li, Xi and Chen, Peng and Chen, Juan and Niu, Xianhua and Xu, Lei},
  doi          = {10.1007/s11227-025-07717-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Parallel heterogeneous graph learning based internet of things multivariate time series anomaly detection and explanation via cross-channel feature fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-evaluation-mode local-search for the minimum dominating set problem on ultra-large sparse graphs. <em>SUPERC</em>, <em>81</em>(13), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07724-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum dominating set (MinDS) problem has gained significant attention in recent years due to its relevance in social and biological networks. This NP-hard problem poses significant computational challenges, especially on ultra-large sparse graphs commonly encountered in real-world applications. Solving such large-scale instances within practical timeframes often necessitates the use of high-performance computing resources. This paper introduces a dual-evaluation mode search algorithm (DemDS) specifically designed for the MinDS problem. For each evaluation mode, DemDS employs a distinct evaluation function for the neighborhood structure. Utilizing the fast incremental evaluation method, the two functions for each mode effectively direct the search process toward various promising areas, with the goal of achieving improved solutions. The proposed DemDS is rigorously tested on three large-scale graph benchmarks. Specifically, the DemDS algorithm achieved the best solution in 80 out of 103 problem instances, updating the upper bounds results in 21 problem instances. Results show that DemDS demonstrates a clear competitive advantage in handling very large graphs, while showing comparable performance with state-of-the art algorithms in smaller instances.},
  archive      = {J_SUPERC},
  author       = {Peng, Yexin and Luo, Mao and Wu, Xinyun and Xiong, Caiquan and Kong, Hui},
  doi          = {10.1007/s11227-025-07724-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {A dual-evaluation-mode local-search for the minimum dominating set problem on ultra-large sparse graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated control strategy for autonomous vehicle decision-making based on deep reinforcement learning. <em>SUPERC</em>, <em>81</em>(13), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07725-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving technology, as the core pillar of vehicle intelligence, shows great potential in improving road network vehicle speed, ride comfort, and traffic safety. However, this technology still faces many serious challenges, such as the high complexity of scenarios, insufficient coupling between decision-making and control, and the difficulty of ensuring safety in environments with dense vehicle interactions, especially in scenarios that require high computational power and real-time response. To address these challenges, this study proposes an integrated decision-making and control framework based on deep reinforcement learning. This framework cleverly combines the discrete double delayed deep Q-network (D3QN) for lane-changing decisions and the continuous twin delayed deep deterministic policy gradient (TD3) algorithm for car-following control. Additionally, the study introduces a context-aware lane-changing benefit function and a coordinated longitudinal control strategy to balance individual vehicle performance with the optimization of overall traffic flow. To achieve efficient coordination between the two layers, D3QN and TD3 are trained in a coupled manner. Experimental results on the simulation of urban mobility simulation platform show that under conditions of 2000 pcu/h traffic flow and 50% penetration rate of connected and autonomous vehicles (CAVs), this method can increase the average road network vehicle speed by up to 4.58% and improve the cruising speed of CAVs by 4.32% compared to the baseline model, with this advantage becoming more pronounced as traffic flow increases. These achievements fully validate that this framework can help CAVs make more intelligent and real-time decisions, thereby significantly improving the efficiency of the entire traffic system.},
  archive      = {J_SUPERC},
  author       = {Liu, Dexin and Zhao, Xin and Ge, Tenghui and Song, Li and Zhang, Xuequan},
  doi          = {10.1007/s11227-025-07725-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Integrated control strategy for autonomous vehicle decision-making based on deep reinforcement learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ifqa-llm: Intelligent intention-driven financial question-answering with large language models. <em>SUPERC</em>, <em>81</em>(13), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07726-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful application of large language models (LLMs) has expanded the development prospects of various fields, but the application of knowledge base question-answering (KBQA) in the financial field still suffers from insufficient recognition of specific professional question intentions and inadequate processing of multi-knowledge point aggregation, often leading to poor answer quality. This paper proposes an Intelligent Intention-driven Financial Question-Answering with Large Language Models (IFQA-LLM) framework, which innovatively integrates three modules to address these challenges. The intent processing module leverages data augmentation and chain-of-thought (CoT) prompting to iteratively clarify ambiguous intents through multi-round dialog, correcting grammatical errors, standardizing terminology (e.g., converting “PE ratio” to “Price Earnings Ratio”), and unifying temporal references, which surpasses traditional keyword-matching methods by enabling structured intent extraction. The information retrieval module employs a “multi-route retrieval” approach that combines vector-based recall (using a fine-tuned embedding model for semantic search, which captures contextual meaning beyond literal keywords) and inverted index-based recall (via BM25 scoring for keyword precision), merging results through the reciprocal rank fusion (RRF) algorithm to enhance accuracy in multi-knowledge aggregation scenarios. The interactive learning module utilizes “client ratings” (0–4 scores on answer accuracy and conciseness) to dynamically optimize retrieval thresholds and prompt engineering, with feedback below score 3 marked as difficult samples for embedding model fine-tuning. Compared with current LLM-based KBQA methods, IFQA-LLM is novel in its intent-first processing paradigm, hybrid multi-route retrieval strategy balancing semantic understanding and keyword matching, and feedback-driven closed-loop optimization, enabling it to handle complex queries, support local deployment for information security, and achieve an average prediction accuracy of 91% on real financial datasets, outperforming state-of-the-art models.},
  archive      = {J_SUPERC},
  author       = {Chen, Fangshu and Huang, Yilin and Wang, Jiahui and Yu, Chengcheng and Meng, Xiankai},
  doi          = {10.1007/s11227-025-07726-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Ifqa-llm: Intelligent intention-driven financial question-answering with large language models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy marine adaptive clustering with weighted similarity for accurate missing data imputation in electronic health records. <em>SUPERC</em>, <em>81</em>(13), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07729-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data in electronic health records poses a serious challenge. It leads to significant information loss, and traditional methods such as mean, mode, and median introduce bias in the result. This work proposes a novel combination imputation method called Fuzzy Marine Adaptive Clustering (FMAC), which combines optimization based on the Marine Predators Algorithm with fuzzy clustering. It presents a dynamic neighbor selection approach that uses membership score and weighted similarity to handle diverse healthcare data in an accurate way. This multi-step procedure yielded statistically more accurate and better performance than other existing methods. Experiments are done on benchmark healthcare datasets (Diabetes, Parkinson’s, Fetal Heart and H1N1 flu vaccine Disease) to evaluate the effectiveness of the proposed method. The proposed method significantly improves Mean Absolute Error, Mean Squared Error, Root Mean Squared Error, Normalized Root Mean Squared Error, Davies–Bouldin Index, Average Silhouette Coefficient and Friedman and Nemenyi Hypothesis Test. Simulation results show that the proposed algorithm performs better than existing methods. Due to its use of iterative optimization and hybrid similarity computation over large datasets, FMAC benefits from high-performance computing (HPC) resources for real-time imputation and scalability. By enhancing data quality, FMAC supports improved clinical decision-making and predictive analytics in healthcare.},
  archive      = {J_SUPERC},
  author       = {Nayak, Subhashish and Khilar, P. M.},
  doi          = {10.1007/s11227-025-07729-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Fuzzy marine adaptive clustering with weighted similarity for accurate missing data imputation in electronic health records},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-cue SORT: Integrating weak cues with appearance and motion for multi-object tracking. <em>SUPERC</em>, <em>81</em>(13), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07730-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of multi-object tracking (MOT) is to accurately detect and track all objects within a continuous sequence while maintaining unique identifiers for each object. Existing research predominantly relies on strong cues from motion and appearance to construct heuristic models, with limited attention given to weak cues arising from object overlap or shape changes as observed by advanced detectors. In this paper, we introduce a novel approach that leverages weak motion cues by adaptively integrating them into high-performance motion versus appearance-based methods. Moreover, by designing weak cue extraction and matching to run independently across targets, our method inherently supports parallelism and GPU acceleration, enabling efficient high-resolution video tracking and showing strong HPC potential. Building upon the appearance-based motion method Deep OC-SORT (in: IEEE International Conference on Image Processing, IEEE, 2023), our approach achieves superior performance on the challenging DanceTrack (in: Proceedings of the IEEE/CVF Conference on Computer 367 Vision and Pattern Recognition, 2022) benchmark, attaining a HOTA score of 61.9. Furthermore, compared to more complex methods, our approach achieves HOTA scores of 65.4 and 64.3 on the MOT17 (Milan in arXiv preprint , 2016) and MOT20 (Dendorfer in arXiv preprint, 2020) benchmarks.},
  archive      = {J_SUPERC},
  author       = {Liang, Hong and Xu, Mingchen and Zhang, Qian and Shao, Mingwen},
  doi          = {10.1007/s11227-025-07730-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {Multi-cue SORT: Integrating weak cues with appearance and motion for multi-object tracking},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous optimization of network-on-chip to improve reliability and reduce average packet latency considering buffer size constraints. <em>SUPERC</em>, <em>81</em>(13), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07733-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing network-on-chip (NoC) architectures is critical for balancing reliability and performance. This study simultaneously optimizes mesh-based NoC architectures with 5-port routers and XY routing algorithm and aims to improve reliability and reduce average packet latency using varying constraints on buffer size. Buffer size, which plays a pivotal role in affecting average packet latency, cost, and reliability, served as a central optimization variable. The Non-dominated Sorting Genetic Algorithm II was exploited to obtain a Pareto front (the set of optimal trade-off solutions) between multiple objectives. Performance validation using the Garnet 2.0 simulator confirmed the approach’s accuracy. Extensive simulations are provided with detailed insights across NoC dimensions ranging from $$3\times 3$$ to $$8\times 8$$ networks for both synthetic traffic (uniform and hotspot) and real traffic. For instance, in a $$4\times 4$$ mesh network with 22 Pareto front points under uniform traffic, we achieved the lowest average packet latency of 18.0001 cycles and a minimal Failures in Time rate of 4213 failures per billion hours.},
  archive      = {J_SUPERC},
  author       = {Abdolhosseini, Hesam and Zarandi, Hamid R. and Gheysari, Arman},
  doi          = {10.1007/s11227-025-07733-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Simultaneous optimization of network-on-chip to improve reliability and reduce average packet latency considering buffer size constraints},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing security in intelligent transport system network by integrating blockchain-based smart contracts. <em>SUPERC</em>, <em>81</em>(13), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07735-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of modern societies and smart cities, intelligent transport systems (ITS) are becoming increasingly complex and interconnected. ITS incorporate sensing, control, analysis, and communication technologies to enhance transportation efficiency, comfort, and safety. Nevertheless, these systems are susceptible to a wide range of malicious attacks that pose a serious threat to the availability, security, and integrity of data interchange, leading to accidents, traffic jams, and monetary losses. Traditional centralized security solutions are often inadequate to address these threats. Thus, blockchain technology, with its decentralized, transparent, and immutable nature, offers a promising alternative for improving security in ITS. This paper explores the potential of Ethereum blockchain-based smart contracts to improve security in ITS. The proposed system is built to manage large numbers of concurrent transactions and uses distributed consensus mechanisms to maintain high throughput and evaluate latency under real-time operational demands. Through representative ITS scenarios, we provide both qualitative and quantitative assessments highlighting the framework’s capabilities to enhance security, system resilience, and computing scalability.},
  archive      = {J_SUPERC},
  author       = {Bourian, Imad and Elfilali, Chaimae and Choughdali, Khalid},
  doi          = {10.1007/s11227-025-07735-4},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing security in intelligent transport system network by integrating blockchain-based smart contracts},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-quantum secure fog-edge computing using federated learning with blockchain. <em>SUPERC</em>, <em>81</em>(13), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07738-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era where the quantum technology revolution looms, safeguarding data security and privacy in decentralized and resource-constrained Fog-Edge environments has become the primary concern. Existing federated learning (FL) approaches, although promising for privacy-preserving model training, remain vulnerable to quantum-era attacks and face challenges in secure aggregation, trust, and data integrity. This paper addresses these challenges by proposing a novel integration of Post-Quantum Security (PQS) techniques with FL, supported by blockchain technology to enhance the resilience and security of Fog-Edge computing systems. The proposed approach leverages multivariate polynomial-based cryptography for post-quantum resilience and utilizes blockchain for immutable logging, secure aggregation, and access control of local model updates. Through extensive experimentation on real-world datasets, the method demonstrates improved performance over baseline FL systems in terms of communication efficiency, model accuracy, and quantum-resilient security guarantees. The results confirm the feasibility and effectiveness of the approach in enabling secure, privacy-preserving, and scalable FL in Fog-Edge environments under quantum threat models.},
  archive      = {J_SUPERC},
  author       = {Singh, Jagdeep and Singh, Parminder and Kaur, Avinash and Hedabou, Mustapha},
  doi          = {10.1007/s11227-025-07738-1},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Post-quantum secure fog-edge computing using federated learning with blockchain},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPTMono: Monocular depth estimation for underwater images using local perception transformer and global–local context fusion. <em>SUPERC</em>, <em>81</em>(13), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07740-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The depth information extracted from underwater images plays a crucial role in computer vision tasks such as underwater target tracking, image modeling and analysis, and precise target localization. Unlike terrestrial depth estimation, underwater monocular depth estimation faces unique challenges: low contrast and blurring effects impair the model’s ability to extract edge details, while uneven illumination causes inconsistent luminance distribution, making it difficult to establish stable depth mapping relationships. To address these challenges, this paper proposes an underwater monocular depth estimation model based on local perception transformer and global–local context fusion. Specifically, the local perception unit extracts fine-grained textures and local spatial features, while the vision Transformer component requires GPU acceleration to efficiently capture long-range dependencies and compensate for semantic information loss caused by local blurring. The global–local self-attention mechanism further demands high-performance computing resources to adaptively adjust regional attention weights in large-scale underwater datasets, thereby mitigating the impact of luminance variations on structural understanding and improving depth estimation accuracy. Experiments on the publicly available FLSea underwater dataset demonstrate that the model achieves an AbsRel value of 0.147, representing improvements of 30%, 55.6%, and 81.2% over AdaBins, PixelFormer, and LapDepth, respectively. This efficient yet computationally demanding architecture also exhibits excellent generalization performance on the Sea-thru dataset while maintaining practical deployability and meeting real-time processing requirements through high-performance computing capabilities.},
  archive      = {J_SUPERC},
  author       = {Liu, Dingshuo and Liu, Yiran and Li, Beibei and Duan, Qingling},
  doi          = {10.1007/s11227-025-07740-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {LPTMono: Monocular depth estimation for underwater images using local perception transformer and global–local context fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new optimization-based framework for enhanced feature selection with the narwal optimizer. <em>SUPERC</em>, <em>81</em>(13), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07741-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of relevant features is a critical step in many machine learning and data analysis tasks, as it can significantly impact the performance and interpretability of the resulting models. In this work, we introduce a novel feature selection approach that draws inspiration from the unique movement patterns of the narwhal, a fascinating marine mammal, and the power of binary optimization. The proposed method, named BNO-FS, is based on Narwhals optimizer (NO) which is a new meta-heuristic recently developed recently and never been tested on feature selection problem. A binary version is proposed in this study. A new fitness function is proposed composed of two important terms: the classification accuracy rate obtained by three classifiers and the number of selected features. The algorithm aims to identify the optimal subset of features that maximizes the predictive performance of the model while minimizing the number of selected features. The accuracy is measured using SVM, KNN, and decision tree classifiers to account for different learning biases. Averaging across these models helps reduce selection bias and ensures that the selected features are robust and generalizable, rather than overfitted to a single classifier. The effectiveness of the binary Narwhals optimizer approach is demonstrated through a series of experiments on benchmark datasets, where it is compared to other state-of-the-art feature selection techniques. The experimental result shows that BNO-FS achieved a mean classification accuracy of 97.65% on the MIAS dataset, outperforming PSO (97.54%) with a statistically significant improvement.},
  archive      = {J_SUPERC},
  author       = {Medjahed, Seyyid Ahmed and Boukhatem, Fatima},
  doi          = {10.1007/s11227-025-07741-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {A new optimization-based framework for enhanced feature selection with the narwal optimizer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SERDNet: Adaptive residual dense learning with dual-path fusion and squeeze-and-excitation for robust image denoising. <em>SUPERC</em>, <em>81</em>(13), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07742-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a fundamental challenge in image restoration and is crucial for medical imaging, photography, and remote sensing applications. However, current deep learning methods often struggle with multi-scale feature extraction, generalization to diverse noise types, and computational efficiency. To address these issues, we propose SERDNet, a dual-branch architecture that integrates Residual Dense Blocks, Attention-Based Feature Fusion modules, and a Multi-Scale U-Net Encoder–Decoder with Squeeze-and-Excitation attention. The SERD branch enhances local features via hierarchical dense connectivity, while the Encoder–Decoder branch captures global context with adaptive feature fusion and skip connections. Extensive experiments on standard benchmarks—including BSD68, Set12, CBSD68, Kodak24, McMaster, CC, and SIDD—confirm that SERDNet consistently delivers superior performance compared to recent deep models, particularly in real-noise scenarios. It achieves up to 33.18 dB on BSD68 at $$\sigma =15$$ , 39.32 dB on SIDD, and 35.60 dB on the real-noise CC dataset. Moreover, the model exhibits strong generalization on challenging non-Gaussian noise scenarios, including Poisson and Salt-and-Pepper noise, where it achieves visually and quantitatively competitive results. With a competitive inference time of 0.2126 s per image, SERDNet offers a robust, efficient solution for both blind and non-blind denoising across a wide range of real-world and synthetic noise conditions. In addition, SERDNet’s dual-path design supports efficient parallelization on GPU and multi-core HPC platforms, making it well-suited for high-throughput and real-time denoising in compute-intensive environments.},
  archive      = {J_SUPERC},
  author       = {Nasrat, Abdul Fatah and Çağlıkantar, Tuba and Barışçı, Necaattin},
  doi          = {10.1007/s11227-025-07742-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {SERDNet: Adaptive residual dense learning with dual-path fusion and squeeze-and-excitation for robust image denoising},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wearable sensor-based eye-rubbing monitoring: A hybrid CNN-attentionrub architecture for keratoconus prevention. <em>SUPERC</em>, <em>81</em>(13), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07744-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye rubbing constitutes a primary modifiable risk factor for keratoconus progression and post-refractive surgery ectasia. Current automated detection systems using single-paradigm architectures exhibit suboptimal performance in capturing complex spatiotemporal motion signatures, while facing significant computational constraints on resource-limited wearable devices. In this paper, we propose a hybrid CNN-Transformer architecture for eye-rubbing detection using inertial measurement unit sensor data from consumer smartwatches, addressing the critical challenge of real-time processing on edge devices with limited computational resources. We developed a smartwatch-based application that evaluates multiple deep learning architectures, including gated recurrent units, long-short-term memory networks, convolutional neural networks (CNNs), Transformers, and hybrid models, to analyze time-series sensor data, while optimizing for computational efficiency and real-time performance. Our approach uses signal segmentation to divide data into fixed-length segments, processed through a one-dimensional (1D) CNN with Transformer-based self-attention to extract temporal and spatial features. The proposed CNN-Transformer architecture achieved 99.92% accuracy, 99.93% sensitivity, and 99.97% specificity, while maintaining real-time inference latency below 50ms on resource-constrained smartwatches, outperforming existing methods that report 90.3–97% accuracy with significantly higher computational overhead. Statistical analysis confirmed significant improvements ( $$p\,<\,0.001$$ ) across evaluation metrics.},
  archive      = {J_SUPERC},
  author       = {Louja, Ayoub and Drira, Ines and Jamali, Abdellah and Naja, Najib and Sliman, Layth},
  doi          = {10.1007/s11227-025-07744-3},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Wearable sensor-based eye-rubbing monitoring: A hybrid CNN-attentionrub architecture for keratoconus prevention},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A layered stock prediction model based on novel feature selection and model parameter optimization. <em>SUPERC</em>, <em>81</em>(13), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07745-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the core subjects in the financial field, stock market forecasting has been attracting extensive attention from the academic and industry, and has promoted the development of many complex forecasting models. However, due to the inherent complexity and volatility of the stock market, existing models still have significant limitations in terms of forecasting accuracy and stability. For example, overly verbose features can lead to data redundancy; Inadequate optimization of model parameters may prevent the full capture of market dynamics, thus limiting the further improvement of forecasting performance. To address these challenges, this paper proposes a bi-directional gated cyclic unit layering model (HFSLS-PSO-BIGRU) based on local shuffling technology and particle swarm optimization. The innovative framework effectively perturbs the data set through a local shuffling method to accurately assess feature importance and achieve optimal feature subset selection. This strategy significantly reduces data redundancy and enhances the generalization ability of the model. In addition, by using PSO in BIGRU architecture for global parameter tuning, the optimal parameter configuration is ensured, which significantly improves the prediction effect. At the same time, the reweighting mechanism and hierarchical loss calculation strategy are implemented in the training process, so that we can optimize the overall model performance. Based on the data of Shanghai Stock Exchange Index and four individual stocks, the empirical study shows that the HFSLS-PSO-BIGRU model proposed in this paper shows significant performance advantages compared with six benchmark models in MSE, RMSE, MAE and $$R^{2}$$ evaluation indicators. In addition, the importance and necessity of each component within the framework is further validated through systematic ablation experiments, providing an innovative solution for stock market forecasting.},
  archive      = {J_SUPERC},
  author       = {Chen, Siying and Tang, Guoqiang},
  doi          = {10.1007/s11227-025-07745-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {A layered stock prediction model based on novel feature selection and model parameter optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-enabled one-stop efficient data retrieval privacy protection mechanism industry 4.0. <em>SUPERC</em>, <em>81</em>(13), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07746-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interaction between identity and data is the key fulcrum to promote the coordinated development and industrial transformation of the Industry 4.0. The existing research usually adopts the smokestack industrial production mode to solve the problem of identity and interaction but ignores the leakage in the process of massive data query and the query efficiency. As a core technology for privacy protection, blockchain provides a feasible solution for interaction between data sharing and identity, however, issues such as the scalability of blockchain, the efficiency of data retrieval on the chain, and the security of data off the chain have not been effectively addressed. To address these problems, we propose a method (BOEDR) for data retrieval in Industry 4.0 to improve the efficiency of data queries without revealing privacy information. In BOEDR, we put forward an effective data prefix hash and an improved red–black tree & buffer index without changing the characteristics of the blockchain to improve the efficiency of the retrieval interaction between the identity and its data in the blockchain. Moreover, the proposed BOEDR adopts SM4 to encrypt the Industrial identification data, which can provide the security of transmission and storage. In addition, we provide a security analysis of the Kafka consensus mechanism applied in the proposed scheme. Finally, we conduct a thorough experiment on the performance and interaction efficiency of the BOEDR. Compared with the existing industrial Internet identity resolution methods, the BOEDR improved the overall efficiency by 5%, optimized the time of 5ms per 10,000 queries, and delivered a 1.3s per million data insertions boost. At the same time, compared with existing solutions, there are significant improvements in blockchain performance and retrieval time.},
  archive      = {J_SUPERC},
  author       = {Zhang, Jiazheng and Li, Shouwei and Pei, Hongmei},
  doi          = {10.1007/s11227-025-07746-1},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Blockchain-enabled one-stop efficient data retrieval privacy protection mechanism industry 4.0},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention mechanism-based hybrid TimeAttentionBiLSTM architecture for long-term traffic forecasting. <em>SUPERC</em>, <em>81</em>(13), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07747-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term traffic flow forecasting in real time has become an important research problem due to the rapid development of public transport facilities. High-density transportation features of traffic flow forecasting provide a convenient, fast, accurate, and comfortable boarding environment for the public. The change in the traffic flow is an important indicator for public transportation to provide facilities for passengers. In this paper, we propose an attention mechanism-based hybrid TimeAttentionBiLSTM architecture for long-term traffic forecasting. The TimeAttentionBiLSTM is able to capture periodic and nonperiodic patterns of the temporal features of traffic data. This architecture uses the bidirectional long short-term memory as an encoder and gated recurrent unit as a decoder to capture the long-term traffic dependencies of the traffic patterns. The TimeAttentionBiLSTM focuses on the important features of time series due to the attention mechanism. The TimeAttentionBiLSTM architecture improves the performance of traffic forecasting for the granularities of 12-h, 24-h, 48-h, and 72-h prediction. The experiments conducted on the Madrid city traffic data show the superiority of the TimeAttentionBiLSTM over nine other state-of-the-art baseline approaches in terms of mean average error, accuracy, and root-mean-square error evaluation metrics.},
  archive      = {J_SUPERC},
  author       = {Chauhan, Vikas and Tiwari, Aruna and Kumar, Arun},
  doi          = {10.1007/s11227-025-07747-0},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {An attention mechanism-based hybrid TimeAttentionBiLSTM architecture for long-term traffic forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-subject domain adaptation for classifying working memory load with multi-frame EEG images. <em>SUPERC</em>, <em>81</em>(13), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07748-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working memory (WM), denoting the information temporally stored in the mind, is a fundamental research topic in the field of human cognition. Electroencephalograph (EEG), which can monitor the electrical activity of the brain, has been widely used in measuring the level of WM. However, one of the critical challenges is that individual differences may cause ineffective results, especially when the established model meets an unfamiliar subject. The development of high-performance computing (HPC) devices enables efficient implementation of deep domain learning technology, offering a viable solution to domain adaptation. To this end, we propose a cross-subject deep adaptation model with spatial attention (CS-DASA) to generalize the workload classifications across subjects. First, we transform EEG time series into multi-frame EEG images incorporating spatial, spectral, and temporal information. First, the subject-shared module in CS-DASA receives multi-frame EEG image data from both source and target subjects and learns the common feature representations. Then, in the subject-specific module, the maximum mean discrepancy is implemented to measure the domain distribution divergence in a reproducing kernel Hilbert space, which can add an effective penalty loss for domain adaptation. Additionally, the subject-to-subject spatial attention mechanism is employed to focus on the discriminative spatial features from the target image data. Experiments conducted on a public WM EEG dataset containing 13 subjects show that the proposed model is capable of achieving better performance than existing state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Chen, Junfu and Li, Sirui and Pi, Dechang},
  doi          = {10.1007/s11227-025-07748-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Cross-subject domain adaptation for classifying working memory load with multi-frame EEG images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward real-time IoT multi-sensor data orchestration on wireless sensor networks. <em>SUPERC</em>, <em>81</em>(13), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07749-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time internet of things applications, such as healthcare monitoring and industrial automation, require immediate data processing, making traditional asynchronous middleware-like queues unsuitable. Efficiently orchestrating heterogeneous sensors—including continuous, event-driven, and query-driven types—is a key challenge due to varying priority levels and resource constraints. This paper proposes RT-IMO, a real-time multi-sensor orchestration strategy that integrates priority-based, load-balanced, and adaptive scheduling strategies to ensure low latency and efficient resource allocation. The proposed RT-IMO dynamically adjusts scheduling priorities to balance latency, fairness, and resource constraints in real time. Designed for high-volume, distributed IoT environments, RT-IMO is suitable for deployment on edge-cloud platforms that require low-latency decisions and scalable scheduling under high data ingestion rates—making it well-aligned with the goals of real-time and high-performance systems. Experimental results demonstrate that RT-IMO improves responsiveness, fairness, and system efficiency compared to existing approaches. Future research will explore machine learning-based adaptive scheduling and its extension to heterogeneous edge computing environments. The results show that RT-IMO ensures low latency, efficient resource use, and fairness, prioritizing critical data while selectively dropping lower-priority tasks. It adapts dynamically to workload variations, outperforming static approaches in responsiveness and stability under high load.},
  archive      = {J_SUPERC},
  author       = {Garcia, Pedro Henrique Sachete and Luizelli, Marcelo Caggiani and Rossi, Fábio Diniz},
  doi          = {10.1007/s11227-025-07749-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Toward real-time IoT multi-sensor data orchestration on wireless sensor networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing renewable energy forecasting: A hybrid approach integrating MSADBO, BiGRU, and TCN for PV/wind power generation prediction. <em>SUPERC</em>, <em>81</em>(13), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07751-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing integration of renewable energy sources has heightened the need for accurate power forecasting. However, photovoltaic (PV) and wind power outputs remain highly volatile, and the complexity of environmental conditions poses significant challenges to hyperparameter tuning in predictive models. To address this, an improved sine algorithm and dung beetle optimization (MSADBO) is employed to automatically optimize model hyperparameters and enhance forecasting performance. A hybrid deep learning framework is proposed, which combines a bidirectional gated recurrent unit (BiGRU) for sequential modeling, a temporal convolutional network (TCN) for capturing long-range dependencies, and a self-attention mechanism to strengthen temporal feature extraction. These components are integrated into the proposed predictive model, named MSADBO-AT-BiGRU-TCN, with MSADBO used to optimize the architecture’s hyperparameters. Extensive experiments on real-world PV and wind datasets demonstrate that the proposed model consistently achieves lower prediction errors and greater robustness under abrupt power fluctuations. It outperforms both traditional deep learning baselines and recent optimization-based forecasting methods across multiple evaluation metrics. Furthermore, its modular and scalable design facilitates efficient deployment on high-performance computing platforms, enabling real-time, large-scale renewable energy forecasting.},
  archive      = {J_SUPERC},
  author       = {Wan, Hang and Qiu, Zhizhuo and Wang, Jiasong and Quan, Rui and Chang, Yufang and Derigent, William},
  doi          = {10.1007/s11227-025-07751-4},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing renewable energy forecasting: A hybrid approach integrating MSADBO, BiGRU, and TCN for PV/wind power generation prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot radar emitter signal recognition based on prototype network with filter system. <em>SUPERC</em>, <em>81</em>(13), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07752-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automotive radar needs to perceive various known and unknown targets in dynamic and complex environments. Moreover, the collection and annotation of radar data are usually costly, leading to a limited number of training samples. The existing methods suffer from two major limitations: inadequate handling of extreme samples and reliance on manually set thresholds for open-set recognition. To solve these two problems, a few-shot recognition method based on a filter system and prototype network (PN) is proposed. First, in the feature extraction stage, the mobile-ConViT network is proposed, which incorporates the MobileViTv2 Attention mechanism into the original PN structure, balancing model performance and real-time efficiency. Secondly, in the prototype computation module, a filtering system is employed to assign weights to samples based on their quality, thereby mitigating the impact of extreme samples. Furthermore, the metric module is extended for open-set recognition by introducing an adaptive threshold. Experimental results demonstrate that the proposed method improves recognition accuracy by approximately 3% compared to existing approaches and reduces the variance of accuracy across multiple runs by about 3%.},
  archive      = {J_SUPERC},
  author       = {Liao, Yanping and Lin, Shengwen and He, Yihan},
  doi          = {10.1007/s11227-025-07752-3},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Few-shot radar emitter signal recognition based on prototype network with filter system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCA-NCA based VIT features for classification of white blood cell images. <em>SUPERC</em>, <em>81</em>(13), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07753-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of white blood cells plays a crucial role in medical diagnostics, particularly for identifying hematological disorders. However, existing deep learning models often struggle to generalize across complex WBC morphologies due to limitations in local feature extraction and rigid classification heads. This study proposes a hybrid framework that integrates a Vision Transformer (ViT) with Principal Component Analysis (PCA), Neighborhood Components Analysis (NCA), and a fully connected (FC) classifier. The ViT model is fine-tuned using Bayesian Optimization to improve feature representation. Instead of relying solely on the [CLS] token, all class token features are aggregated, decorrelated via PCA, and projected through NCA to enhance class separability. The standard MLP head is replaced by a Bayesian-optimized FC classifier. Experiments on the Raabin-WBC dataset (14,514 images across five classes) show that the proposed method achieves 99.03% accuracy—outperforming the ViT baseline (97.86%) by 1.17%, or 50 additional correctly classified test samples. These results demonstrate that jointly optimizing the ViT architecture and applying supervised dimensionality reduction can significantly boost classification performance in complex biomedical image tasks.},
  archive      = {J_SUPERC},
  author       = {Elghandour, Mohamed},
  doi          = {10.1007/s11227-025-07753-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {PCA-NCA based VIT features for classification of white blood cell images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New design strategies for IoT intrusion detection using boosting and feature selection. <em>SUPERC</em>, <em>81</em>(13), 1--57. (<a href='https://doi.org/10.1007/s11227-025-07755-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of Internet of Things (IoT) technologies has introduced significant security challenges due to the diversity and number of connected devices. Although machine learning (ML) is widely used in intrusion detection systems (IDSs), it does not always ensure a good trade-off between bias and variance. This study presents a large-scale evaluation of ensemble learning methods, focusing on boosting techniques while considering feature types and transformation strategies. Five boosting algorithms (adaptive boosting (ADB), gradient boosting machines (GBM), category boosting (CATB), light gradient boosting machine (LGBM), and extreme gradient boosting (XGB)) were evaluated using two transformation strategies and five filter-based feature selection (FS) methods: analysis of variance (ANOVA), Kendall’s tau, mutual information (MI), maximum relevance minimum redundancy (mRMR), and Chi-square (Chi2). Experiments were conducted on two large NetFlow-based IoT datasets (NF-ToN-IoT-v2 and NF-BoT-IoT-v2). Each model was assessed using Matthews correlation coefficient (MCC), Cohen’s kappa, F1-score, and accuracy, and ranked using the Scott–Knott statistical test and Borda count voting system. A total of 1160 models were trained using the Toubkal Supercomputer, whose high-performance computing (HPC) infrastructure enabled scalable parallel and distributed processing. The best results were obtained using XGB with 200 estimators and 18 selected features under the standardization transformation. For the NF-ToN-IoT-v2 dataset, the combination of ANOVA and mRMR yielded an accuracy of 99.9%, an MCC of 0.98, and a prediction time of 4316.57 microseconds (μs) on a Raspberry Pi device. For the NF-BoT-IoT-v2 dataset, the combination of ANOVA and Chi2 achieved 100% accuracy, an MCC of 0.99, and a prediction time of 4385.69 μs on the same device.},
  archive      = {J_SUPERC},
  author       = {Hamdouchi, Abderahmane and Idri, Ali},
  doi          = {10.1007/s11227-025-07755-0},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--57},
  shortjournal = {J. Supercomput.},
  title        = {New design strategies for IoT intrusion detection using boosting and feature selection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy preservation through makeup transfer for facial feature obfuscation. <em>SUPERC</em>, <em>81</em>(13), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07756-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated facial recognition can infer sensitive attributes from facial images without consent, posing substantial privacy risks. Existing adversarial perturbation methods often degrade visual fidelity and compromise identity utility. We propose makeup-transfer obfuscation GAN (MTO-GAN), which uses makeup-inspired perturbations to obfuscate soft biometric traits while preserving realism and recognition performance. Methodologically, (i) an entropy-increase perspective motivates the use of adversarial noise; (ii) a density-ratio-to-probabilistic-classification reformulation with a Siamese objective estimates and mitigates domain shift while alleviating conflicts with cycle consistency; and (iii) a lightweight domain regularization module based on RRDB denoises and harmonizes features to stabilize the cycle. To address the challenges of large-scale facial image privacy computation and extreme computational load in deep learning, we employ GPU-accelerated parallel inference to meet throughput and latency requirements. Experiments across four public face datasets and five face recognizers show that MTO-GAN drives age and race predictability toward random-guessing levels while largely preserving identity verification, and it improves perceptual quality over prior perturbation approaches. Overall, MTO-GAN achieves a favorable balance among privacy protection, visual fidelity, and identity utility.},
  archive      = {J_SUPERC},
  author       = {Hu, Renyuan and Chen, Zheyu and Jin, Biao and Yao, Zhiqiang},
  doi          = {10.1007/s11227-025-07756-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Privacy preservation through makeup transfer for facial feature obfuscation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised tractive momentum: A novel unsupervised few-shot learning framework. <em>SUPERC</em>, <em>81</em>(13), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07757-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) aims at distilling transferable knowledge on existing concepts to cope with novel concepts for which only a few labeled data are available. Most of the popular FSL methods acquire this knowledge by learning on large-scale supervised data from the existing concepts. Considering obtaining supervised data might sometimes be difficult and heavy-burden, we pursue a relatively mild prerequisite for FSL, that is, using unsupervised instead of supervised data to acquire the transferable knowledge. We propose a novel easy-to-implement FSL framework, Unsupervised Tractive Momentum (UTM), composed of modular dual encoders, a combinatorial loss mechanism, and a classifier that together form a reusable and extensible learning system, that only requires unsupervised data of existing concepts. UTM randomly samples unsupervised data and augments them to create many synthetic query-key matching tasks on-the-fly, and deploys two different encoders while possessing identical architecture, named traction encoder and momentum encoder, to learn a representation space by a combinatorial parameter updating manner. The representation space learned on unsupervised data is expected to be a good fit to few-shot recognition on novel concepts. UTM is composed of parallelizable dual encoders and optimized for scalable training in GPU-based high-performance computing environments. Theoretical convergence and bound analysis further support its deployment in distributed systems. Theoretical justifications of the parameter updating mechanism in UTM are given from the perspective of convergence, and a theoretical loss bound for UTM is proved, which mathematically quantifies the relationship between our self-supervised UTM and the vanilla supervised method. Extensive experimental evaluation on several benchmark datasets demonstrates that UTM yields significant improvement to state-of-the-art unsupervised methods even very close to supervised methods, which can also be well explained using our theory.},
  archive      = {J_SUPERC},
  author       = {Cao, Zhong and Lu, Jiang and He, Liu and Luo, Yuheng},
  doi          = {10.1007/s11227-025-07757-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Unsupervised tractive momentum: A novel unsupervised few-shot learning framework},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power networks SCADA communication cybersecurity, a qiskit implementation. <em>SUPERC</em>, <em>81</em>(13), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07758-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power system operations are conducted through communication systems that are mapped to standards, protocols, ports, and source–destination addresses. Power networks supervisory control and data acquisition systems (SCADA) communication is part of the critical information infrastructure, subjected to increasing risk and vulnerability from cyberattacks. As information technology (IT) in internet-connected environments through optical fibre networks is intricately intertwined with operations technology (OT), it significantly increases complexity as a successful OT attack has the potential to damage power system equipment and cause a large-scale cascading outage. In the IT-OT interwoven regime, where some overlap is inevitable, securing the future ecosystem faces fresh challenges in the quantum endeavour, where traditional encryption is anticipated to be insufficient. Real-time situational awareness is a standard term with implications and applications in both power systems and cybersecurity for dealing with streaming data, a computational problem in essence. This paper demonstrates an integrated Qiskit through two different quantum circuit implementations for encoding, encrypting, and decrypting an open-source packet dataset of six fields treated as six variables for corresponding interconnected SCADA centres. It found that the results of encrypted and decrypted traffic data match with the identical keys of Alice and Bob for the dataset samples, and thus are encouraging for the possible future framework development of real-time streaming data. It highlights the opportunities and challenges in securing SCADA communication in a plausible quantum computing and communication regime. While the topic entails the intersection of many domains, in the end, the computational paradigm forms one of the building blocks of the ecosystem owing to the reality of managing huge data, real-time streaming in nature, and the adequacy of computational resources. Nonetheless, the inevitable trade-off scenario of software and hardware interface for achieving the required performance vis-à-vis computation time is another criterion.},
  archive      = {J_SUPERC},
  author       = {Biswas, Hillol},
  doi          = {10.1007/s11227-025-07758-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Power networks SCADA communication cybersecurity, a qiskit implementation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive surrogate-based approach for solving constrained optimization problems. <em>SUPERC</em>, <em>81</em>(13), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07759-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid progression in engineering design has intensified the need for robust optimization tools capable of managing complex simulations effectively. In response, the adaptive regional enhanced constrained lower confidence bounding (ARECLCB) surrogate model has been introduced to address the computational challenges inherent in constrained optimization problems (COPs). This approach dynamically selects between two surrogate models: one based on decision tree ensembles and the other using neural networks, to effectively explore both local and global regions. The adaptive selection allows the chosen model to be trained either on elite samples for infilling in local regions or on all samples for broader exploration of global regions. This strategy balances local refinement with global exploration, significantly reducing evaluation time while maintaining high accuracy. Extensive testing on multiple numerical examples demonstrates that ARECLCB is highly competitive with recent algorithms in terms of efficiency and effectiveness. To further validate its capabilities, the ARECLCB model was applied to the lightweight design of two 3D irregular steel frames. The results show that the proposed approach not only reduces the average weight by 1.6% compared to other methods, but also reduces the computational time by 66.5%. This highlights the proposed approach potential in solving real-world engineering problems.},
  archive      = {J_SUPERC},
  author       = {Ilchi Ghazaan, Majid and Laal Dehghani, Kasra},
  doi          = {10.1007/s11227-025-07759-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {An adaptive surrogate-based approach for solving constrained optimization problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise detection of surface defects on wind turbine blades for multi-scale target perception. <em>SUPERC</em>, <em>81</em>(13), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07761-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wind turbine blade surface defect detection model based on YOLOv5s is proposed to overcome the limitations of existing models in exploiting surface defect characteristics. It focuses on precise multi-scale defect target perception in complex backgrounds. The Convolution for Wind Turbine Blades (Conv_WTB) module is designed to capture multi-scale features, ensuring information integration and transmission, and addressing the issues of traditional receptive fields and alignment errors. The deformable spatially adaptive attention module is developed to enhance key feature sensitivity by utilizing deformable convolution and global average pooling to improve detection in complex scenes. The Smoothed Intersection over Union (SIoU) is introduced to optimize boundary errors and enhance defect target localization. Experiments conducted on a four-class defect dataset demonstrate that the improved model boosts F1-score by 4.04% to 96.58% and mAP@0.5 by 3.94% to 98.10%. It outperforms other existing models. When tested on the NVIDIA GeForce RTX 3090 GPU, the FPS reaches 41.67 frames·s−1, meeting real-time requirements. This model provides support for the intelligent operation and maintenance of wind power generation units.},
  archive      = {J_SUPERC},
  author       = {Liu, Yuhang and Zheng, Yuqiao and Wei, Tai and Zhang, Yanqiang},
  doi          = {10.1007/s11227-025-07761-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Precise detection of surface defects on wind turbine blades for multi-scale target perception},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NoTNER: Self-optimizing text reconstruction for open named entity recognition on social media. <em>SUPERC</em>, <em>81</em>(13), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07764-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) bring strong reasoning and understanding capabilities to various NLP tasks. However, recent studies show that existing LLMs still struggle with information extraction tasks, especially in noisy and low-resource settings. To address these challenges, we propose NoTNER, a novel framework for open-domain named entity recognition (NER) on social media texts without any fine-tuning. NoTNER integrates two key components: (1) a self-optimizing text reconstruction module based on Monte Carlo tree search to clean informal inputs through prompt optimization and (2) a zero-shot chain-of-thought reasoning template to guide entity extraction step by step. Extensive experiments on two benchmark datasets demonstrate that NoTNER achieves superior zero-shot performance compared to both fine-tuned and prompting-based baselines. Specifically, it improves F1 scores by 5–25 points over strong fine-tuned and zero-shot baselines on Tweebank-NER v1.0, and obtains competitive results on WNUT17. The framework also shows strong generalization across multiple LLMs, including ChatGPT, LLaMA2, and Yi-34B, highlighting its robustness and deployment efficiency in real-world noisy environments.},
  archive      = {J_SUPERC},
  author       = {Miao, JinFeng and Huang, Yanyi and Liu, Yuying and Tian, Lei and Zhao, Xuechen},
  doi          = {10.1007/s11227-025-07764-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {NoTNER: Self-optimizing text reconstruction for open named entity recognition on social media},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dangerous behavior detection algorithm with the fusion of RGB data and skeleton information. <em>SUPERC</em>, <em>81</em>(13), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07765-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel dangerous behavior detection algorithm aimed at addressing challenges in construction worker action recognition, such as low accuracy, limited behavior categories, complex models, and detection errors. The proposed method integrates RGB data and skeleton information to improve detection performance. It enhances detection precision through EGFaster R-CNN, which incorporates a global channel spatial attention module into the feature pyramid network and leverages EfficientNet for a better balance between accuracy and efficiency. On this basis, DMHRNet introduces a novel multidimensional grouped attention mechanism and adopts a classification-based coordinate discretization strategy to improve localization robustness. The detected keypoints are then converted into spatiotemporal representations and processed by 3D CNNs to capture motion dynamics. Additionally, depthwise separable convolutions reduce computational cost, while optional fusion with RGB features enhances semantic understanding, resulting in a more comprehensive and discriminative representation of dangerous behaviors. Experiments were conducted on a self-built DB dataset, the COCO2017 dataset, and the PASCAL VOC 2012 dataset. Moreover, in comparison with other vision-based methods, the proposed method shows great advantage in reducing the number of parameters while still achieving competitive estimation precision. The optimized lightweight architecture facilitates efficient deployment on HPC platforms, ensuring real-time responsiveness in large-scale construction site monitoring while balancing computational efficiency and detection accuracy.},
  archive      = {J_SUPERC},
  author       = {Yao, Daojin and Chen, Hanxin and Yang, Zichen and Chen, Yan and Yin, Xiong and Dong, Wentao and Yu, Yongxiang},
  doi          = {10.1007/s11227-025-07765-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {A dangerous behavior detection algorithm with the fusion of RGB data and skeleton information},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non parametric 3D point cloud understanding based on curvature guidance. <em>SUPERC</em>, <em>81</em>(13), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07766-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding 3D point clouds is a key challenge in the field of computer vision, with significant implications for applications such as autonomous navigation, robotics, and augmented reality. Traditional methods often rely on parametric models and heavily trained programs, which can be computationally expensive and difficult to generalize. To address these issues, we propose a new nonparametric approach to understanding 3D point clouds, utilizing curvature guidance to enhance geometric feature extraction. Our method comprises three key components: using spatial curvature information for local sampling to select information points; local encoding without training parameters, a robust encoding scheme that bypasses the need for parameter learning; and a knowledge warehouse that stores basic geometric information for efficient retrieval and processing. We validated the proposed method on the 3D classification dataset ScanObjectNN (three variants) and ModelNet40, as well as on the component/scene segmentation datasets ShapeNet and S3DIS, with and without parameter training. The experimental results demonstrate that our method achieves competitive accuracy in various point cloud segmentation and classification tasks while maintaining low computational overhead.},
  archive      = {J_SUPERC},
  author       = {Yuan, Xiao and Tian, Shengwei and Yu, Long and Yang, Qimeng and Song, Jinmiao and Fan, Xin and Zhu, Zhezhe},
  doi          = {10.1007/s11227-025-07766-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Non parametric 3D point cloud understanding based on curvature guidance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-CNNs with variational information bottleneck for chest X-ray classification. <em>SUPERC</em>, <em>81</em>(13), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07767-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have received much attention in the field of medical image classification due to their excellent feature extraction capability, parameter sharing mechanism and spatial structure preservation. Variational information bottleneck (VIB) has the advantages of feature compression, information preservation and prevention of model overfitting. Theoretically, embedding a VIB module into CNNs helps to improve the classification performance of the models. However, traditional methods usually embed VIB as an intermediate feature layer in neural networks. This can result in excessive feature compression, which can filter out information that is critical for classification tasks. Therefore, we propose embedding VIB in several CNNs to provide classification models for chest X-ray images. Specifically, VIB is embedded after the classification layers of DenseNet121, MobileNetV2 and ResNet50 to enhance the performance of medical image classification. First, three publicly available datasets are pre-processed using the contrast limited adaptive histogram equalization (CLAHE), which in turn spatially rotated and horizontal mirroring these datasets in two dimensions to increase the volume of data. Comparisons with other related models for classification of chest X-ray image are then performed. Finally, ablation experiments are performed with and without VIB, as well as with VIB embedded in the interlayer. The above experimental results show that the combination of CNNs with VIB, for binary and multi-classification tasks, achieves satisfactory results in accuracy, precision, recall and F1-score, respectively, which implies that our proposed model has a great potential for application in computer-aided pneumonia diagnosis.},
  archive      = {J_SUPERC},
  author       = {Guan, Chen and Ai, Haihong and Wang, Weiwei and Singh, Ravi P.},
  doi          = {10.1007/s11227-025-07767-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Multi-CNNs with variational information bottleneck for chest X-ray classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CELAT-DiffNet: Channel-enhanced local attention transformer for underwater image enhancement based on diffusion models. <em>SUPERC</em>, <em>81</em>(13), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07769-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel denoising diffusion probabilistic model for underwater image enhancement (UIE). It effectively addresses common issues in underwater images such as color distortion, low contrast, and detail blurring. We design an innovative Transformer denoising network that integrates a multidimensional collaborative attention (MCA) mechanism, which employs a three branch parallel structure to model feature interactions across channel, height, and width dimensions, further improving enhancement performance. Additionally, we propose the channel-enhanced local attention (CELA) module, which first performs global interaction at the channel level and then applies local neighborhood attention. This design ensures that local details are guided by global context, enabling effective integration of long-range dependencies and local semantics. To address the limitations of conventional feed-forward networks (FFNs) in spatial and channel interaction, we further design the channel-enhanced feed-forward network (CEFN). This module combines grouped convolution with a lightweight yet efficient channel attention mechanism, facilitating synergistic enhancement of spatial patterns and channel features. Extensive experimental results on diverse datasets (UIEB, LSUI, UFO, C60, U45) demonstrate that our method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations.},
  archive      = {J_SUPERC},
  author       = {Wang, Jiale and Liang, Yitao and Yang, Xuxu and Zhao, Mengjuan and Xia, Juan},
  doi          = {10.1007/s11227-025-07769-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {CELAT-DiffNet: Channel-enhanced local attention transformer for underwater image enhancement based on diffusion models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining unified model by test-time dynamic adaptation for domain shift problem. <em>SUPERC</em>, <em>81</em>(13), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07770-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current domain generalization (DG) and test-time adaptation (TTA) are two primary approaches to domain shift. However, DG lacks real-time target domain adaptation capability; TTA focuses on dynamic testing-phase adjustment but is constrained by pre-trained model performance and faces method adaptation issues. Combining their strengths provides a rational solution. DG builds a robust generalization foundation for real-time adaptation by exploiting source domain information; TTA achieves target domain adaptation via dynamic adjustment, compensating for DG’s real-time limitation. Based on this, we integrate DG and TTA. First, we construct a strong generalization model using DG; then, we perform real-time adjustments to this model via TTA-based on target domain samples, while preventing catastrophic forgetting. Meanwhile, to mitigate potential computational latency induced by TTA dynamic updates, we leverage parallel computing enabled by high performance computing (HPC) to further enhance its real-time adaptation efficiency. Specifically, we propose a test-time dynamic adaptation for unified model refining method, which has two phases: the unified model acquisition phase, where we devise a feature cross-domain fusion method to construct a unified model by learning domain-generic and domain-specific features; and the test-time adaptation phase, where we design a dynamic feature extractor to set migration boundaries for catastrophic forgetting prevention, a dynamic classifier to update weights in real time from test samples, and leverage HPC low-latency computing for real-time model adaptation. Extensive experimental results on the PACS, VLCS, OfficeHome, and TerraInc datasets validate the effectiveness and superiority of our method.},
  archive      = {J_SUPERC},
  author       = {Du, Haishun and Cao, Linbing and Li, Jieru and Zhang, Wenzhe},
  doi          = {10.1007/s11227-025-07770-1},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Refining unified model by test-time dynamic adaptation for domain shift problem},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRSBi-YOLO: Transformer based lightweight and high-performance model for PCB defects detection. <em>SUPERC</em>, <em>81</em>(13), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07771-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the reliability and high quality of electronic products necessitates accurate detection and classification of printed circuit board (PCB) defects. This study presents an enhanced defect detection model, TRSBi-YOLO. First, the incorporation of C3TR modules within the modified backbone structure improves multiscale feature extraction while significantly reducing computational complexity. Second, the integration of a simple parameter-free attention mechanism (SimAM) enhances feature representation without adding computational burden. Additionally, a bidirectional feature pyramid network (BiFPN) is employed in the neck section to optimize multi-level feature fusion and strengthen object detection capabilities. Experimental results demonstrate that the TRSBi-YOLO model achieves a remarkable mean average precision (mAP) of 98.1% with only 4.4G floating point operations (FLOPs) and 1.79M parameters. Compared to baseline model, TRSBi-YOLO shows substantial improvements, including a 2.40% increase in mAP, as well as enhancements in recall (0.62%), precision (0.73%), F1-score (1.12%), and accuracy (4.55%), along with a significant 11.99% increase in detection speed. These results demonstrate the effectiveness of the proposed TRSBi-YOLO model in improving both the detection and classification of PCB defects. The model offers a reliable and efficient solution for automated optical inspection (AOI), making it suitable for real-time quality control in industrial PCB manufacturing. Designed with deployment in mind, TRSBi-YOLO combines a lightweight architecture with high-speed performance, achieving an inference speed of 135.27 FPS. This makes it ideal for integration into high-throughput environments, including GPU-based systems and edge devices, supporting real-time and large-scale inspection tasks.},
  archive      = {J_SUPERC},
  author       = {Ancha, Vinod Kumar and Gonuguntla, Venkateswarlu and Vaddi, Ramesh},
  doi          = {10.1007/s11227-025-07771-0},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {TRSBi-YOLO: Transformer based lightweight and high-performance model for PCB defects detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multimodal named entity recognition with multi-granularity knowledge distillation. <em>SUPERC</em>, <em>81</em>(13), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07772-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) is essential for effective information extraction, yet traditional methods encounter several challenges. These include mismatches between text and images, insufficient utilization of image data, neglect of critical features, and difficulties in aligning semantic levels across modalities. Typically, these approaches focus on aligning and fusing multimodal data without integrating external knowledge. To address these shortcomings, we propose a Multi-Granularity Knowledge Distillation model for MNER (MKD), which consists of two stages: Coarse-Grained Modal Pre-training and Fine-Grained Modal Fine-tuning. In the Pre-training phase, we introduce a Self-Supervised Similarity Contrast Learning method to facilitate effective knowledge transfer. During the Fine-tuning phase, we employ a Multi-Task Knowledge Distillation Fine-tuning Network, leveraging a teacher model to generate pseudo-labels and incorporating auxiliary tasks to enhance knowledge extraction from multimodal data, ultimately improving MNER performance. Experimental results demonstrate that MKD outperforms existing methods on the Twitter2015 and Twitter2017 datasets, achieving state-of-the-art results. Additionally, our findings indicate that knowledge can be effectively transferred between modalities, and simultaneous multitasking learning further boosts MNER performance.},
  archive      = {J_SUPERC},
  author       = {He, Xinyu and Li, Shixin and Li, Binhe},
  doi          = {10.1007/s11227-025-07772-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing multimodal named entity recognition with multi-granularity knowledge distillation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedShield: Federated learning based robust online payment fraud detection. <em>SUPERC</em>, <em>81</em>(13), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07774-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of e-commerce and digital payment systems has brought significant convenience to users. Meanwhile, it has also led to a surge in fraudulent activities in online transactions. Existing fraud detection mechanisms often lack critical features like real-time alerts, transaction history, dynamic updates, fraud scoring, and continuous monitoring, all of which are vital for building an effective fraud detection system. This work proposes Fedshield, a decentralized, federated learning-based fraud detection system that ensures trust among participants while preserving data privacy in fintech environments. Fedshield used open source high performance computing (OpenMPI) library to manage model synchronization and real-time fraud detection. To handle dynamic shifts in transaction patterns, we introduce a moving time frame approach that keeps the risk prediction model resilient to evolving fraud tactics. Experimental results demonstrate that Fedshield surpasses existing state-of-the-art methods, achieving an impressive F1-score of 0.9903 using newly engineered features. A dashboard is designed with Django and integrated via a Flask API, enabling efficient data flow management, while SQLite is used to store transaction history. This dashboard supports real-time monitoring of suspicious activities and provides instant alerts to both users and issuing banks.},
  archive      = {J_SUPERC},
  author       = {Singh, Narendra and Tripathy, Somanath},
  doi          = {10.1007/s11227-025-07774-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {FedShield: Federated learning based robust online payment fraud detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-MTMYOLO: An explainable YOLOv5-based architecture for accurate detection of mandibular third molar using a novel expert-annotated dataset. <em>SUPERC</em>, <em>81</em>(13), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07775-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis and accurate treatment planning are critical in dentistry, as impacted mandibular third molars (MTMs) can lead to complications such as infection, pain, and damage to adjacent teeth. Panoramic radiographs (PRs), routinely used in clinical practice, require precise classification of MTM status (erupted or impacted) to support effective surgical decision-making. This study proposes the explainable mandibular third molar YOLO (E-MTMYOLO) architecture, which integrates YOLOv5 with EigenCAM—a eXplainable Artificial Intelligence (XAI) technique—to detect and interpret MTMs in PR images. For this purpose, a novel expert-annotated dataset named ExAn-MTM, consisting of 973 PRs, was developed and publicly released in this study. Image preprocessing techniques, including median filtering and gamma correction, were applied to enhance image quality, resulting in a preprocessed dataset. An ablation study was conducted to determine the optimal YOLOv5 variant and hyperparameter configuration. The best performance was achieved using YOLOv5s on the preprocessed dataset, yielding 97.77% accuracy, 95.91% sensitivity, 97.67% precision, 96.78% F1 score, and 99.21% mAP@50. To assess interpretability and clinical relevance, expert dentists from multiple institutions evaluated the model's predictions and the XAI visualizations via MTMX-CDSS, a clinical decision support system developed. The expert evaluations were analyzed using statistical methods, and the results revealed high inter-rater reliability along with strong internal consistency, confirming the clinical applicability of the proposed method. In conclusion, the proposed method not only surpasses existing approaches in core performance metrics and provides clinically validated, interpretable outputs, but also demonstrates the computational scalability and efficiency required for high-performance AI-driven diagnostic systems in dentistry.},
  archive      = {J_SUPERC},
  author       = {Kayadibi, İsmail and Köse, Utku and Güraksın, Gür Emre and Çetin, Bilgün},
  doi          = {10.1007/s11227-025-07775-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {E-MTMYOLO: An explainable YOLOv5-based architecture for accurate detection of mandibular third molar using a novel expert-annotated dataset},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-augmented web spam detection using evidential reasoning. <em>SUPERC</em>, <em>81</em>(13), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07778-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web spam persistently undermines search engine integrity through deceptive practices such as cloaking and link manipulation, incurring substantial economic costs. Existing detection approaches often contend with significant challenges, including the effective management of uncertainty in human judgments and the processing of high-dimensional feature spaces. To address these limitations, we propose Graph-Augmented Web Spam Evidential Reasoner (GAWSER). This innovative framework integrates Dempster–Shafer Theory (DST) for robust uncertainty quantification with advanced graph-based feature selection. This system dynamically assesses judge reliability through adaptive evidence aggregation while employing spectral clustering on a feature similarity graph to achieve noticeable dimensionality reduction without compromising discriminative power. Evaluated on the WEBSPAM-UK2006 and WEBSPAM-UK2007 datasets, GAWSER demonstrated notable performance improvements, achieving accuracy increases of 4.2% (to 0.952) and 3.2% (to 0.947), respectively, alongside a reduction in false negatives. The framework consistently demonstrates improved metrics over both traditional and deep learning-based methodologies, offering a novel solution for uncertainty-aware web spam detection. Furthermore, recognizing the inherent scalability challenges posed by massive, dynamic web datasets, GAWSER’s design is specifically engineered to leverage high-performance computing (HPC) paradigms. Its graph-based feature selection and evidential reasoning components are inherently adaptable for parallel and distributed processing, which is critical for real-time, web-scale spam detection. This architectural consideration renders GAWSER highly relevant to the field of Supercomputing, showcasing a novel application for advanced computational systems in mitigating web spam.},
  archive      = {J_SUPERC},
  author       = {Keyhanipour, Amir Hosein},
  doi          = {10.1007/s11227-025-07778-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {Graph-augmented web spam detection using evidential reasoning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSA-MEP: Layer-wise sparsity allocation multi-metric evaluation pruning. <em>SUPERC</em>, <em>81</em>(13), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07786-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep neural networks continue to grow in scale, their rising computational demands increasingly require high-performance computing (HPC) resources such as distributed clusters. This highlights the need for efficient, HPC-compatible models. Network pruning is a key technique for reducing model complexity, but most existing methods apply uniform sparsity and rely on single-criterion importance metrics, overlooking structural heterogeneity and the multi-dimensional nature of parameter significance. To address these limitations, we propose LSA-MEP: a pruning-at-initialization framework that integrates layer-wise sparsity allocation with multi-metric parameter evaluation. Pruning ratios are determined by each layer’s information content, while parameter importance is assessed through a multi-dimensional evaluation that incorporates static structural characteristics, dynamic optimization signals, and information propagation capacity, yielding a comprehensive and robust importance metric. The process is fully parallelizable, making it well-suited for large-scale models and distributed environments. Experiments across multiple datasets demonstrate that LSA-MEP consistently outperforms existing methods in accuracy preservation while achieving efficient execution through parallel computing.},
  archive      = {J_SUPERC},
  author       = {Liang, Hong and Guo, Quanyi and Shao, Mingwen and Zhang, Qian},
  doi          = {10.1007/s11227-025-07786-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {LSA-MEP: Layer-wise sparsity allocation multi-metric evaluation pruning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient fully parallel convolutional neural network architecture using 1-memristor and 1-transistor (1M1T). <em>SUPERC</em>, <em>81</em>(13), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07796-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are typically implemented using GPUs, but their power consumption and area efficiency become critical challenges as data complexity scales. In this work, we propose a fully parallel CNN (FP-CNN) architecture that employs single-memristor crossbar arrays per weight, unlike conventional designs requiring paired arrays, enabling the computation of multiple feature maps in one processing cycle. To optimize area and power, our design utilizes only three CNN layers and an absolute activation function to enhance feature extraction. We incorporate memristor synaptic modeling with noise and error injection to closely emulate realistic hardware behavior. Simulation results on the MNIST handwritten digit classification task demonstrate notable improvements over prior works, achieving up to 39.41% reduction in power consumption and 17.48% reduction in chip area, while maintaining a high CNN classification accuracy of 98.63% despite using a minimalist three-layer architecture. Moreover, using 128-level memristors, the network maintains 98.28% accuracy under chip simulation conditions, showcasing robustness to device-level non-idealities.},
  archive      = {J_SUPERC},
  author       = {Yosefzadeh Chari, Ahmadreza and Gholipour, Morteza and Hassanzadeh, Mohammadreza},
  doi          = {10.1007/s11227-025-07796-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {13},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Efficient fully parallel convolutional neural network architecture using 1-memristor and 1-transistor (1M1T)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety measures in automotive operating system: A comprehensive review of trends and defense frameworks. <em>SUPERC</em>, <em>81</em>(12), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07635-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of intelligent electric vehicles (IEVs), an increasing number of algorithms are being deployed on software platforms, progressively leading to the formation of automotive operating systems (OS). This paper introduces firstly the status of automotive OS and analyzes their development trends. As an emerging technology, automotive OS is a safety-critical system that plays a vital role in driving safety. To address the challenges associated with ensuring the safety of automotive OS, this paper proposes systematically safety measures across multiple perspectives, including software architecture, time protection, memory protection, software monitoring, and communication. Furthermore, a system safety mode is proposed from an engineering implementation perspective. Finally, experimental results validate the feasibility of deploying multiple communication protocols within automotive OS, effectively addressing the challenges posed by big data and high-concurrency demands in IEVs.},
  archive      = {J_SUPERC},
  author       = {Li, Zhenpeng and Bian, Jingwei and Li, Wei and Zhang, Lihua},
  doi          = {10.1007/s11227-025-07635-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Safety measures in automotive operating system: A comprehensive review of trends and defense frameworks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowLoader: An efficient large language model loader via parallel transmissions and local multi-tier caching. <em>SUPERC</em>, <em>81</em>(12), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07646-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The checkpoint of large language models (LLMs) typically range from tens of gigabytes to terabytes in storage size, with loading processes often requiring several seconds to minutes. This substantial latency issue significantly impacts service level objective compliance for providers of large-scale model services. To address the LLM loading cold-start problem, we present LLM FlowLoader, a model loader featuring multi-tier local caching and parallel communication pipeline optimization. By strategically leveraging GPU servers’ heterogeneous network resources and storage hierarchies, our system accelerates checkpoint loading through two key innovations: (1) An asynchronous pipeline transporter based on task stealing and affinity domain awareness, which transforms complex network transmission into simplified chain-structured transmission by introducing affinity domains, and adaptively enhances I/O bandwidth through a task-stealing algorithm. (2) A multi-tier caching system co-designed with the transporter that exploits GPU servers’ multi-tier memory/storage architecture to accelerate data accessibility and reduce cold-start latency. Experimental results demonstrate that LLM FlowLoader not only achieves significant loading speed improvements but also provides novel insights for optimizing GPU resource utilization.},
  archive      = {J_SUPERC},
  author       = {Yin, Jun and Wu, Fei and Li, Shihao and Huang, Peng},
  doi          = {10.1007/s11227-025-07646-4},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {FlowLoader: An efficient large language model loader via parallel transmissions and local multi-tier caching},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-enhanced long short-term memory earthquake prediction method based on improved and hybrid rice-inspired gray wolf optimizers. <em>SUPERC</em>, <em>81</em>(12), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07677-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquakes, as a natural phenomenon, have caused significant catastrophic losses to humanity throughout history. Many machine learning and deep learning methods have been widely applied in earthquake prediction; however, the performance of these methods is often limited by redundant seismic data features and hyperparameter optimization, resulting in low prediction accuracy. To tackle these issues, we propose a Dual-Enhanced Long Short-Term Memory(LSTM) Earthquake Prediction Method Based on Improved and Hybrid Rice-Inspired Gray Wolf Optimizers(HIGWO-LSTM). Specifically, the Hybrid Rice Optimization algorithm inspired Gray Wolf Optimizer (HROGWO) algorithm is employed for feature selection of seismic data to identify the most representative subset of features. Then, the LSTM model excels at capturing long-term dependencies in time series data, thus enabling LSTM for training and predicting earthquake data. And an improved Gray Wolf Optimizer (IGWO) with Worst Individual Disturbance (WID) is used for hyperparameter optimization of the LSTM to obtain the best hyperparameter combination and improve the model’s prediction accuracy. To validate the performance of the proposed method, we use geomagnetic and seismoacoustic data from our self-developed Acoustic & Electromagnetism to AI (AETA) system, and evaluate it using the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared (R2) metrics. Experimental results show that the proposed HIGWO-LSTM earthquake magnitude prediction model outperforms state-of-the-art methods on these evaluation metrics. Due to the high-dimensional seismic data and the iterative nature of both LSTM training and metaheuristic optimization, our method demands significant computational resources. The use of dual optimizers further increases complexity, making High-Performance Computing (HPC) essential for efficient model training and real-time prediction. The reproducible code that supports the findings of this study can be accessed at https://github.com/fight123456/papercode .},
  archive      = {J_SUPERC},
  author       = {Sun, Yi and Huang, Ruoxuan and Yi, Xinchun and Zhou, Wen and Wang, Han and He, Qiyi and Ming, Zhe},
  doi          = {10.1007/s11227-025-07677-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A dual-enhanced long short-term memory earthquake prediction method based on improved and hybrid rice-inspired gray wolf optimizers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional information entropy-based feature selection for partially labeled heterogeneous data via matrix operation and prediction label using k-nearest neighbor. <em>SUPERC</em>, <em>81</em>(12), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07680-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since labeling data is expensive and time-consuming, partially labeled data is very common. Exploring such data can unlock its potential value and reduce reliance on large amounts of missing labels. k-nearest neighbor rule as an instance-based learning method, is highly effective in predicting missing labels when dealing with partially labeled data, offering significant advantages. This paper uses k-nearest neighbor rule to predict labels for partially labeled heterogeneous data and studies feature selection through conditional information entropy and matrix operations. First, the distance function with respect to each type of feature of partially labeled heterogeneous data is defined, and the tolerance classes are constructed. Then, a new method of predicting the labels for partially labeled heterogeneous data is raised. The core idea of this method is to calculate the distance between the target object and other objects, identify the k-nearest neighbors to the target object, and make predictions based on their labels. By predicting the missing labels, the completeness and usability of the label information can be improved. Next, the tolerance relation matrix, tolerance diagonal matrix and decision relation matrix are defined, and some properties of these matrices are obtained. Moreover, the fact that conditional information entropy for partially labeled heterogeneous data is calculated by matrix operations is proved. Finally, a feature selection algorithm based on the matrix form of conditional information entropy is proposed and compared with six existing algorithms. The experimental results confirm that the algorithm performs excellently and possesses strong robustness and adaptability.},
  archive      = {J_SUPERC},
  author       = {Nong, Yumei and Tian, Liwei and Lin, Yonghua and Li, Zhaowen},
  doi          = {10.1007/s11227-025-07680-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Conditional information entropy-based feature selection for partially labeled heterogeneous data via matrix operation and prediction label using k-nearest neighbor},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-agnostic ordinal regression pipeline for length of stay prediction. <em>SUPERC</em>, <em>81</em>(12), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07681-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of hospitalization duration, known as length of stay (LoS), is a critical aspect of optimizing healthcare resource allocation. To solve this problem, several earlier studies divided LoS into different buckets and predicted them using classification methods. Nonetheless, these studies overlook the skewed distribution and the intrinsic ordinal nature of the various categories. Besides, the highly sparse Electronic Health Records (EHRs) degrade the prediction accuracy. To overcome the aforementioned challenges, in this paper, we propose a model-agnostic ordinal regression pipeline for length of stay prediction (MORE) in ICUs. Initially, we introduce a variable selection module aimed at pruning marginal and sparse features from the original input data. This approach directs the model’s focus toward important features, thereby reducing noise influence and enhancing computational efficiency. Subsequently, we present a multi-task learning-based optimization module where we integrate cross-entropy loss and an accumulated link loss into a unified loss function. Finally, we carry out a comprehensive series of experiments across two publicly available datasets, MIMIC-III and PhysioNet. The experimental results show that MORE can improve the performance of existing classification methods in terms of mean absolute error and accuracy.},
  archive      = {J_SUPERC},
  author       = {Huang, Xiaoxiao and He, Kaibo and Hou, Chenyu and Zhou, Min and Zheng, Dingchang},
  doi          = {10.1007/s11227-025-07681-1},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {A model-agnostic ordinal regression pipeline for length of stay prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed Deutsch–Jozsa algorithm. <em>SUPERC</em>, <em>81</em>(12), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07683-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deutsch–Jozsa (DJ) problem is one of the most important problems demonstrating the power of quantum algorithms, which can be described as a Boolean function $$f: \{0,1\}^n\rightarrow \{0,1\}$$ promised to be either constant or balanced, and the purpose is to determine which type it is. The DJ algorithm can compute it exactly with one query. However, classical deterministic algorithm requires $$2^{n-1} + 1$$ queries to compute it in the worse case. Therefore, the DJ algorithm is essentially faster than any possible classical deterministic algorithm for computing DJ problem. In this paper, we discover the intrinsic structure of DJ problem in distributed scenario by giving a number of equivalence characterizations between f being constant (balanced) and some properties of f’s subfunctions. We propose three distributed DJ algorithms, which have exponential speedup over distributed classical deterministic DJ algorithm. In comparison with the DJ algorithm, our algorithms can reduce the number of qubits for a single computing node. Furthermore, compared to distributed DJ algorithm with errors, our algorithms possess accuracy and improved scalability.},
  archive      = {J_SUPERC},
  author       = {Li, Hao and Qiu, Daowen and Luo, Le},
  doi          = {10.1007/s11227-025-07683-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Distributed Deutsch–Jozsa algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-scale contrast-aware dynamic feature fusion transformer for image dehazing method. <em>SUPERC</em>, <em>81</em>(12), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07686-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the image dehazing method based on deep learning is difficult to take into account the global features and local details when dealing with uneven haze, resulting in the loss of details and the decrease of contrast in the restored image. Therefore, a multi-scale contrast-aware dynamic feature fusion dehazing method based on transformer is proposed. The transformer in the network encoder consists of a multi-head proxy attention block (MPAB), a residual multi-scale attention block (RMAB), and a feed-forward network (FFN). Among them, MPAB introduces a multi-head proxy attention mechanism with low computational overhead to extract multi-scale global features, so as to significantly improve the inference efficiency while ensuring the dehazing quality (FLOPs is 35.6G, running time is 0.095 s), showing excellent computational performance. RMAB uses the residual structure to capture local features and context information to enhance the ability of multi-scale feature modeling. Between the encoder and the decoder, a channel-spatial dynamic fusion block (CSDF) is introduced to integrate low-level and high-level features through a dynamic fusion mechanism to prevent information loss. At the same time, the adaptive contrast-aware enhancement block (ACEB) is added to the middle layer, and four modules with different expansion rates are stacked to adapt to the uneven distribution of haze in the real scene. The experimental results show that the method performs well on multiple synthetic and real fog map datasets and has both accuracy and efficiency. It can effectively solve the problem of detail feature loss and contrast reduction.},
  archive      = {J_SUPERC},
  author       = {Wang, Yan and Wang, Huan and Li, Jiayi and Li, Shurong},
  doi          = {10.1007/s11227-025-07686-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive multi-scale contrast-aware dynamic feature fusion transformer for image dehazing method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrative machine learning approaches for enhanced cardiovascular disease prediction: A comparative analysis of XGBoost and ANFIS algorithms. <em>SUPERC</em>, <em>81</em>(12), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07687-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVDs) remain the leading cause of mortality worldwide, highlighting the urgent need for advanced diagnostic tools to improve early detection and patient outcomes. This study evaluates the predictive performance of two machine learning models—Extreme Gradient Boosting (XGBoost) and the Adaptive Neuro-Fuzzy Inference System (ANFIS)—across five datasets from the UCI Machine Learning Repository: Cleveland, Hungary, Switzerland, Long Beach VA, and Statlog Heart. Comprehensive preprocessing steps—including imputation, standardization, one-hot encoding, and SMOTEENN—were applied to ensure data consistency and address class imbalance. XGBoost achieved perfect accuracy (100%) on the Switzerland and Statlog datasets, reflecting its strength in structured data environments and consistent predictive performance. Conversely, ANFIS outperformed XGBoost on the Cleveland dataset, demonstrating its effectiveness in modeling complex, nonlinear relationships. Performance evaluation metrics included accuracy, precision, recall, F1 score, F2 score, and ROC-AUC. XGBoost consistently delivered high precision and recall, which are essential for minimizing false positives and negatives in clinical settings. ANFIS yielded high F2 scores, indicating a stronger emphasis on reducing false negatives—a critical concern in CVD diagnosis. This comparative analysis suggests that while XGBoost is well suited for scalable, high-throughput diagnostic applications, ANFIS offers greater interpretability and is more effective in nuanced clinical scenarios. These findings underscore the potential of integrating advanced machine learning models into cardiovascular disease prediction frameworks to enhance diagnostic accuracy and support real-world healthcare decision-making.},
  archive      = {J_SUPERC},
  author       = {Muhyi, Diyar Fadhil and Ata, Oğuz},
  doi          = {10.1007/s11227-025-07687-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {Integrative machine learning approaches for enhanced cardiovascular disease prediction: A comparative analysis of XGBoost and ANFIS algorithms},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FO-YOLO for small object detection in drone aerial imagery. <em>SUPERC</em>, <em>81</em>(12), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07688-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the huge differences in object scale, frequent occlusions, and few pixels occupied by targets, small object detection in drone aerial imagery remains challenging. To address these challenges, we propose feature optimization YOLO (FO-YOLO), a method for improving the detection accuracy of small objects in drone imagery. FO-YOLO consists of three main modules: feature augment module (FAM), dynamic detail-aware feature pyramid network (DDAFPN), and optimal transport assignment-EIoU (OTA-E). Firstly, FAM is a feature-rich module that can balance the richness and refinement of feature extraction. Secondly, we designed DDAFPN to tackle the issue of insufficient utilization of detailed information in traditional feature pyramid networks. Meanwhile, it can also reduce the redundant information when fusing features. Thirdly, OTA-E is a label assignment method, designed to optimize the global label allocation strategy and assign labels more accurately. Extensive experiments on the VisDrone and Tinyperson datasets demonstrate the effectiveness and advancement of our method.},
  archive      = {J_SUPERC},
  author       = {Zhou, Huaping and Yin, Wei and Sun, Kelei and Wu, Tao and Deng, Bin},
  doi          = {10.1007/s11227-025-07688-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {FO-YOLO for small object detection in drone aerial imagery},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLTPPM: A dual-layer model for trajectory privacy protection in autonomous driving. <em>SUPERC</em>, <em>81</em>(12), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07689-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of autonomous driving technology, precise user trajectory data has become critical for vehicles. Current privacy-preserving methodologies predominantly focus on spatial feature extraction while insufficiently addressing temporal dimension vulnerabilities, a security-critical oversight that disrupts the privacy-utility trade-off. We propose a Dual-Layer Temporal Privacy Protection Model (DLTPPM) featuring: (1) A modified Trajectory Chain Variational Autoencoder (TCVAE) combining Long Short-Term Memory (LSTM) with enhanced variational inference for expressive spatiotemporal pattern learning; (2) A Random Forest-Laplace Time Protector (RF-LTP) applying context-aware differential privacy via adaptive temporal noise injection. Experimental validation confirms DLTPPM’s capability to simultaneously enhance privacy protection and data utility, demonstrating significant balanced improvement over conventional approaches.},
  archive      = {J_SUPERC},
  author       = {Shang, Fanshu and Wang, Yong and Yang, Jing and Wang, Shuo and Liu, Jiaqi},
  doi          = {10.1007/s11227-025-07689-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {DLTPPM: A dual-layer model for trajectory privacy protection in autonomous driving},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image fusion and denoising of optical coherence tomography based on ResNet and truncated huber filter. <em>SUPERC</em>, <em>81</em>(12), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07690-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT), which is highly regarded, serves as a valuable instrument in both biological research and clinical diagnosis, and it is capable of providing high-resolution tissue images. However, the presence of speckle noise in OCT images can significantly reduce their quality, potentially leading to inaccurate study results and diagnostic procedures. To solve this problem, a fusion denoising algorithm based on ResNet and truncated Huber filtering is proposed. The source image is initially decomposed into base and detail layers using a truncated Huber filter. In order to achieve detail layer fusion, the multilayer features of the detail layer are initially extracted using a ResNet network. Subsequently, a set of candidate features is generated by applying the $${l}_{1}$$ -norm and weighted average rule. Then, a feature fusion scheme based on the average pixel intensity energy operator is employed to fuse these candidate features in order to achieve more accurate and comprehensive detail layer information fusion. For the base layer fusion, a fusion scheme based on spatial frequency similarity and structural similarity is proposed. Finally, the fused detail and base layers are synthesized to reconstruct the fused image. The results of experimental studies demonstrate that the algorithm exhibits comparable performance to some of the most advanced speckle noise removal techniques, as evidenced by both objective metrics and subjective visual inspection.},
  archive      = {J_SUPERC},
  author       = {Chen, Huaiguang and Wei, Wenyu and Li, Hehe and Gao, Jing},
  doi          = {10.1007/s11227-025-07690-0},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {Image fusion and denoising of optical coherence tomography based on ResNet and truncated huber filter},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SOG-YOLO: An infrared road scene small object detection model. <em>SUPERC</em>, <em>81</em>(12), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07692-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent transportation and safety monitoring, infrared road object detection technology holds significant value due to its low-light environmental advantages. However, inherent limitations such as low image resolution and blurred textures cause severe feature information loss and insufficient small object detection accuracy in existing algorithms. This study proposes an infrared road small object detection model integrating super-resolution reconstruction with improved YOLOv10n called SOG-YOLO. The Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) is employed to reconstruct image details. A Dynamic Generalized Efficient Layer Aggregation Network (D-GELAN) enhances feature fusion, combined with Omni-Dimensional Dynamic Convolution (OD-Conv) for adaptive feature extraction. A neck structure (DD-PAN) that combines D-GELAN and DySample has been designed to capture weak small object features with low computational cost. Experiments on two infrared road datasets demonstrate that SOG-YOLO achieves recall improvements of 7.4% and 10.4%, respectively, compared to baseline models, with $$\text {mAP}_\text {50}$$ increasing by 7.4% and 10.3% correspondingly. This provides a high-performance solution for infrared road object detection.},
  archive      = {J_SUPERC},
  author       = {Peng, Ende and Ai, Qing and Li, Ziqiang and Mao, Shaoyu and Han, Tao},
  doi          = {10.1007/s11227-025-07692-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {SOG-YOLO: An infrared road scene small object detection model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task classification offloading strategy based on reinforcement learning for mobile edge computing. <em>SUPERC</em>, <em>81</em>(12), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07693-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the resource competition issue caused by multi-task concurrent computation offloading in the Internet of Vehicles (IoV), this paper proposes the MCO-DQN strategy, which collaborates with vehicles and edge servers to establish a multi-task concurrent classification offloading model. The model constructs a constrained multi-objective optimization problem with latency and energy consumption as dual objectives, aiming to achieve dual optimization and dynamic balance between both performance metrics. Based on the task characteristics, different state coefficient weights are assigned, and computation offloading is formalized as a Markov Decision Process to meet the classification offloading requirements of different types of tasks. By combining real-time task status with high-dimensional state modeling and the adaptive capabilities of the DQN algorithm, the global optimal offloading decision is determined, accurately and efficiently implementing multi-task classification offloading in the dynamic and complex scenarios of IoV. Experimental results show that the proposed strategy demonstrates superior performance in terms of latency, energy consumption, success rate, and convergence, making it a practical and optimal solution for multi-task classification offloading in IoV.},
  archive      = {J_SUPERC},
  author       = {Wei, Lei and Wang, Pan and Ren, Shaoxi and Wang, Anhua},
  doi          = {10.1007/s11227-025-07693-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Multi-task classification offloading strategy based on reinforcement learning for mobile edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time ZNN model with noise reduction for solving quadratic programming and its application to binary assignment problem in logistics. <em>SUPERC</em>, <em>81</em>(12), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07694-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural networks (ZNNs), a specialized class of recurrent neural networks, have demonstrated remarkable effectiveness in matrix computation and dynamic optimization problems due to their inherent parallel computing capabilities. In this paper, a predefined-time and noise reduction ZNN (PTNRZNN) model is proposed for solving convex quadratic programming problems with equality and inequality constraints. Additionally, a new activation function is proposed, demonstrating enhanced accelerated convergence and noise reduction performance compared to previous models. The convergence and robustness of the PTNRZNN model are effectively proven through theoretical assessment. Furthermore, the performance of the PTNRZNN model is further validated through simulation experiments. Finally, the PTNRZNN model is applied to the binary assignment problem in logistics (BAPL), yielding optimized results with an error margin as low as $$10^{-2}$$ compared to theoretical values. The strong robustness of the method makes it an excellent performer in solving BAPL under noise interference.},
  archive      = {J_SUPERC},
  author       = {Liao, Bolin and Xu, Jinsha and Hua, Cheng and Wang, Tinglei and Li, Shuai},
  doi          = {10.1007/s11227-025-07694-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Predefined-time ZNN model with noise reduction for solving quadratic programming and its application to binary assignment problem in logistics},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OFSPNet: ODE-guided fusion network with the same paradigm for infrared small target detection. <em>SUPERC</em>, <em>81</em>(12), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07695-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection (ISTD) remains a challenging task due to the complex backgrounds and indistinct structural features of small targets. Current ISTD methods have the following limitations: on the one hand, both CNN-based and transformer-based methods have deficiencies in feature extraction. On the other hand, current fusion methods cannot effectively utilize global information to enhance the local features of the target, which hampers further improvement in detection performance. This paper proposes the OFSPNet model, which significantly improves detection accuracy and detail-capturing ability through diversified feature representation and adaptive fusion. Firstly, the model employs a parallel architecture integrating CNN, transformer, and Mamba—CNN is adept at extracting low-level local details, while transformers focus on capturing global information. Meanwhile, Mamba relies on its unique selection mechanism to filter out irrelevant data and retain the important features of key visual cues in the image. Secondly, an ODE-inspired adaptive feature fusion module was designed as an information bottleneck to suppress high-frequency noise, while simultaneously strengthening target features through backpropagated gradients. Then, a modular design is carried out for the transformer and Mamba structures. A MLP is added to enhance the ability to handle nonlinear problems, and a gating mechanism is introduced to dynamically adjust information flow, suppressing noise and irrelevant background information. Finally, considering the real-time requirements in practical applications, the model has achieved a balance between inference speed and performance. Through optimization strategies, the inference speed has been increased by 15.28%, ultimately achieving the dual advantages of efficient inference and high detection accuracy.The code are available at https://github.com/1yanchen3/12.git.},
  archive      = {J_SUPERC},
  author       = {Xue, Songdong and Chen, Yan and Wang, Bin and Gao, Gaimei and Qiao, Gangzhu and Zhao, Xinyu},
  doi          = {10.1007/s11227-025-07695-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {OFSPNet: ODE-guided fusion network with the same paradigm for infrared small target detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An incremental algorithm for dynamic graph coloring based on graph reduction and adaptive recoloring strategies. <em>SUPERC</em>, <em>81</em>(12), 1--52. (<a href='https://doi.org/10.1007/s11227-025-07696-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic graph coloring problem, an important variant of the classic graph coloring problem, demands the assignment of colors to vertices within a dynamic setting, ensuring that no two adjacent vertices share the same color. This problem holds considerable practical significance, as numerous real-world scenarios can be modeled as dynamic graphs, thus underscoring the critical need for robust solutions. Two main factors influence the effectiveness of solutions: the initial solution during the static process and the recoloring method during the dynamic process. Existing approaches often face limitations by either achieving high efficiency with unsatisfactory solutions or generating high-quality solutions with low efficiency. The primary aim of this research is to balance the efficiency and solution quality in addressing dynamic graph coloring challenges. Specifically, we introduce an incremental algorithm grounded in graph reduction to address the dynamic coloring of large-scale graphs. Our approach leverages the maximum independent set rule to simplify the graph, followed by k-core decomposition and saturation sorting techniques to produce an initial solution of high quality. When the graph undergoes structural modifications, an adaptive recoloring algorithm is employed to recolor it with minimal computational efforts. Comparative results against state-of-the-art dynamic graph coloring algorithms reveal that our approach achieves a superior balance between the number of colors utilized and computational efficiency, surpassing existing methods while maintaining consistent coloring. Moreover, we have designed and implemented a parallel version of the algorithm, further enhancing its computational efficiency.},
  archive      = {J_SUPERC},
  author       = {Zhou, Yupeng and Liu, Hanhui and Jin, Xi and Yin, Yue and Hu, Shuli and Yin, Minghao},
  doi          = {10.1007/s11227-025-07696-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--52},
  shortjournal = {J. Supercomput.},
  title        = {An incremental algorithm for dynamic graph coloring based on graph reduction and adaptive recoloring strategies},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReDepthNet: A radar and camera depth estimation model based on semantic segmentation mask region alignment. <em>SUPERC</em>, <em>81</em>(12), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07697-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel depth estimation model, ReDepthNet, based on the alignment of semantic segmentation masks for generating radar depth projections. The model aims to fuse image and radar data to achieve a high-precision depth estimation. A key innovation is the design of a Fusion Encoder that integrates the Efficient Multi-Scale Attention Module (EMA), which efficiently fuses RGB images and radar data. This approach not only captures global features, but also significantly improves the stripe-like artifacts in depth maps and enhances the clarity of object boundaries. Comprehensive experiments conducted on the nuScenes dataset show that, compared to our baseline model, ReDepthNet achieves MAE improvements of 8.2%, 5.5%, and 4.8% at distances of 50 m, 70 m, and 80 m, respectively, and RMSE improvements of 8.2%, 5.4%, and 4.6%, showing significant performance advantages. Furthermore, our experiments highlight the importance of effectively utilizing semantic segmentation mask information and radar point distribution characteristics for depth estimation tasks.},
  archive      = {J_SUPERC},
  author       = {Liang, Hong and Zhang, Xu and Zhang, Qian and Shao, Mingwen},
  doi          = {10.1007/s11227-025-07697-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {ReDepthNet: A radar and camera depth estimation model based on semantic segmentation mask region alignment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directing model attention to the discriminative foreground features. <em>SUPERC</em>, <em>81</em>(12), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07698-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays deep neural networks have surpassed human recognition abilities on significant image datasets. However, due to the limitations and biases in training samples, post hoc explanation methods reveal that models rely on background information for decision-making, regardless of the correctness of the decisions. Models can maintain stable performance under test distribution shifts only if they learn causally relevant features of the target from the training data. To address distributional shift problems, out-of-distribution generalization approaches improve model generalization on unseen domains based on domain label information. Recently, the emerging paradigm of explanation-guided learning, which integrates explanations into model training, has significantly reduced the learning of spurious correlations and effectively improved model generalization on unseen distributions, performing comparably to related out-of-distribution generalization methods. Explanation-guided learning primarily incorporates prior knowledge or bounding boxes. However, explanation-guided learning with prior knowledge can still focus on spurious features, and using bounding boxes as ground truth incurs high manual annotation costs. To address these issues, we divide the image dataset into foreground-dominant and background-dominant subsets. For the foreground-dominant dataset, we propose an Annotation-based Explanation Consistency (AEC) method to constrain the model to focus on the most discriminative foreground regions. For the background-dominant dataset, we propose a Class-wise Feature Reweighting Explanation Consistency (CFWEC) method to guide the model in learning causally relevant features. We validate the effectiveness of these methods on both foreground-dominant and background-dominant datasets, demonstrating that they effectively reduce the learning of spurious correlations. We also analyze the current limitations of the method in terms of manual annotation and hyperparameter tuning, while discussing prospective solutions involving high-performance computing or distributed platforms for implementing automated model annotation and distributed training in future work.},
  archive      = {J_SUPERC},
  author       = {Mi, Jian-Xun and Pan, Lu and Fu, Qiang and Shi, Shenglei and Chen, Tao and Cheng, Xiao},
  doi          = {10.1007/s11227-025-07698-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Directing model attention to the discriminative foreground features},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speed-accuracy trade-off in lightweight-based hand pose estimation. <em>SUPERC</em>, <em>81</em>(12), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07699-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand pose estimation plays a vital role in the domain of human–computer interaction. However, achieving accurate predictions in real-world scenarios, handling multi-sized targets, reducing computational burden, and striking a balance between speed and accuracy remain significant challenges for existing approaches. In this paper, we propose a MSIPA-HandNet method to address these issues. Moreover, the MSIPA-HandNet provides better speed support within the speed-accuracy trade-off. Our method consists of a lightweight encoder–decoder network architecture that is suitable for practical applications and distribution-aware coordinate representations to fine-tune the location information of gesture keypoints, with a primary emphasis on enhancing accuracy within the speed-accuracy trade-off. We also introduce a comprehensive speed-accuracy trade-off evaluation model to guide future hardware platform selection. Comprehensive experiments on two public datasets show that the proposed method outperforms current state-of-the-art approaches to hand pose estimation. Finally, we suggest that the computer terminal is a preferable deployment hardware platform, as it provides an optimal balance between speed and accuracy, and can support gesture-based location information for control applications.},
  archive      = {J_SUPERC},
  author       = {Zhang, Mingyue and Zhou, Zhiheng},
  doi          = {10.1007/s11227-025-07699-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Speed-accuracy trade-off in lightweight-based hand pose estimation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MA-MSTNet: Mixed attention-based multi-scale temporal network for stock trend prediction. <em>SUPERC</em>, <em>81</em>(12), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07700-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate stock trend prediction is vital for financial decision-making, yet existing methods struggle to jointly model multivariate correlations and multi-scale temporal patterns. We propose MA-MSTNet, a novel Mixed Attention-based Multi-Scale Temporal Network that integrates Maximal Information Coefficient-guided attention to quantify feature dependencies while suppressing noise, multi-scale sliding window attention capturing high-to-low frequency features, and dynamic gated fusion for adaptive feature integration. Experiments on four stock indices (S&P 500, Nasdaq, etc.) demonstrate state-of-the-art performance (R $$^2$$ up to 0.984), outperforming seven baselines. Crucially, the model achieves 6.5ms inference latency and 39% faster training per epoch, enabling real-time high-frequency trading.},
  archive      = {J_SUPERC},
  author       = {Wang, Xin and Zhang, Xiang and Liu, Jifei and Zuo, Zhenyu},
  doi          = {10.1007/s11227-025-07700-1},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {MA-MSTNet: Mixed attention-based multi-scale temporal network for stock trend prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated reinforcement learning-based multi-UAV cooperative dynamic caching replacement strategy. <em>SUPERC</em>, <em>81</em>(12), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07701-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing mobile edge computing caching strategies face several challenges, including privacy leakage due to centralized training, the lack of consideration for the age of cached content, and issues such as poor content freshness, low cache hit rate, and high system energy consumption, which arise from the randomness and high dynamics of user requests in emergency scenarios. To address these issues, a federated reinforcement learning-based multi-unmanned aerial vehicle cooperative dynamic caching replacement strategy is proposed. Firstly, a comprehensive utility objective function is developed, considering user access delay, the age of cached content, and system energy consumption. Secondly, BiLSTM is employed to capture the dynamic dependencies in user request time series, combined with an attention mechanism to focus on key features. Federated learning is used to achieve distributed training across UAVs, ensuring user privacy while improving the accuracy of content popularity prediction. Subsequently, a weighted caching scoring mechanism based on content popularity and information age is proposed to dynamically adjust the cache replacement order. Finally, the cache replacement and user association problems are modeled as a Markov decision process, and the TD3 reinforcement learning algorithm is applied, utilizing double Q-networks and a delayed policy update mechanism, to derive the optimal cache replacement strategy. The experimental results demonstrate that the proposed method outperforms comparison approaches in terms of cache hit rate, access delay, and content freshness, demonstrating strong performance advantages and application potential.},
  archive      = {J_SUPERC},
  author       = {Liu, Yanpei and Zhao, Haoyang and He, Yanqiang and Zhang, Weiwei and Zhu, Liang and Li, Hongchan},
  doi          = {10.1007/s11227-025-07701-0},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Federated reinforcement learning-based multi-UAV cooperative dynamic caching replacement strategy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Hybrid and parallel GAN architecture with non-IID noise input. <em>SUPERC</em>, <em>81</em>(12), 1--3. (<a href='https://doi.org/10.1007/s11227-025-07703-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Gohel, Prashant and Joshi, Manjunath},
  doi          = {10.1007/s11227-025-07703-y},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--3},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Hybrid and parallel GAN architecture with non-IID noise input},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WARNs: A time series model integrating wavelet convolution and channel attention mechanism. <em>SUPERC</em>, <em>81</em>(12), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07704-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting has wide applications in various fields. The primary goal is to extract patterns from historical data and predict future trends. Convolutional neural networks are extensively used in time series forecasting due to their ability to identify local patterns. However, they encounter challenges when it comes to capturing long-term patterns. To solve this problem, we propose a model named WARNs, which integrates wavelet convolution layers and channel attention mechanism. This model is capable of detecting long-term trends, short-term fluctuations and periodic characteristics of time series data while dynamically adjusting feature weights. Experiments on public datasets show that WARNs outperforms existing models in time series forecasting, achieving lower error metrics such as MSE and MAE.},
  archive      = {J_SUPERC},
  author       = {Chen, Jie and Zhang, Xinran and Gao, Ke and Zha, Dongshan and Han, Yanting and Guo, Jiahao},
  doi          = {10.1007/s11227-025-07704-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {WARNs: A time series model integrating wavelet convolution and channel attention mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batched data layout optimization for im2col-based convolutions on CPUs. <em>SUPERC</em>, <em>81</em>(12), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07706-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Im2col-based convolution is a widely used technique in deep learning frameworks to efficiently implement convolution operators. However, in batched input scenarios, it suffers from inefficient weight reuse due to large reuse distances, often becoming a performance bottleneck. Particularly for CPUs with cache, large reuse distances of convolution weight data lead to increased memory access latency and degraded performance. To address this issue, we propose a novel batched-data-layout-optimization (BDLO) method. BDLO optimizes the input matrix layouts during the Im2col phase to reduce reuse distances of weight data, thereby enhancing memory access efficiency in batched Im2col-based convolutions. This method improves performance of batched convolutions on CPUs and is available for both NCHW and NHWC data layouts. Experimental results demonstrate that BDLO outperforms the standard batched Im2col-based convolutions implemented in the widely used open-source deep learning framework LibTorch, while the weight matrix size is larger than the input matrix size. Specifically, BDLO achieves up to 1.40 $$\times$$ speedup for the NCHW layout and 1.37 $$\times$$ for the NHWC layout on the Kunpeng 920 CPU (ARM architecture), and up to 1.81 $$\times$$ for NCHW and 2.33 $$\times$$ for NHWC on the Intel Xeon Platinum 8260L CPU (x86 architecture).},
  archive      = {J_SUPERC},
  author       = {Zhao, Hongzhi and Liu, Xun and Chen, Ruiyang and Tang, Chao and He, Yangyang and Wang, Deyang and Xie, Jinxiang},
  doi          = {10.1007/s11227-025-07706-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Batched data layout optimization for im2col-based convolutions on CPUs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient algorithm to find a shorter fault-tolerant path in cycle composition networks. <em>SUPERC</em>, <em>81</em>(12), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07707-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle composition networks (CCNs) are a class of topological structure, which not only contains k-ary n-cube and BC graph, but also includes the data center network CamCube and many other future networks. As the number of vertices in the network increases, successfully transmitting data between any two fault-free vertices becomes an important issue in network communication. This paper studies fault-tolerant path of CCNs, designs corresponding construction algorithms, proves the correctness of the algorithms, analyzes the performance of the algorithm, and conducts corresponding simulation experiments to verify the theoretical results. Numerous experiments have shown that the algorithm proposed in this paper has significant advantages over other algorithms in terms of average running time, and the difference between the average fault-free path length and the length obtained by the BFS algorithm is minimal.},
  archive      = {J_SUPERC},
  author       = {Tang, Yaqian and Yin, Bai and Cheng, Baolei and Wang, Yan and Yu, Jia and Fan, Jianxi},
  doi          = {10.1007/s11227-025-07707-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {An efficient algorithm to find a shorter fault-tolerant path in cycle composition networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEDDR-YOLO: A lightweight and efficient distracted driving recognition algorithm with a particular pruning method. <em>SUPERC</em>, <em>81</em>(12), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07709-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road safety conditions are highly dynamic. Even split-second distracted driving behaviors (DDB) can cause disastrous consequences. Therefore, developing an algorithm that can accurately identify DDB in real time is critical for enhancing road safety. To address the issues of excessive model complexity, low detection accuracy, and poor real-time performance in traditional methods, this paper proposes a lightweight and efficient DDB recognition algorithm LEDDR-YOLO based on YOLO11. First, in order to better capture both detailed features of DDB and overall driving posture characteristics, an innovative multi-scale information fusion Neck structure, LMIFFPN, is designed, along with a new feature extraction module, CSP-PGHCB. Second, aiming to reduce model complexity, this paper introduces a more efficient LUP upsampling module and incorporates shared convolution in the detection head, proposing a novel detection head, LSCDetector. Finally, considering the structural characteristics of the LEDDR-YOLO model, a dedicated structured pruning algorithm, LEDDR-Pruning, is developed. This method effectively reduces model size with minimal accuracy loss, and then knowledge distillation strategies are employed to compensate for the accuracy degradation caused by pruning. Experimental results demonstrate that LEDDR-YOLO achieves an accuracy of 99.2% on the StateFarm dataset while maintaining a low computational cost of 1.4 GFLOPs, 404,793 parameters, and 1050 frames per second. Generalization experiments conducted on the 100-Drivers dataset demonstrate that LEDDR-YOLO outperforms YOLO11 in generalization capability. Therefore, the proposed algorithm maintains high accuracy while significantly reducing computational complexity.},
  archive      = {J_SUPERC},
  author       = {Shen, Qian and Zhang, Lei and Zhang, Yan and Zhang, Yuxiang and Liu, Shihao},
  doi          = {10.1007/s11227-025-07709-6},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {LEDDR-YOLO: A lightweight and efficient distracted driving recognition algorithm with a particular pruning method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generic framework for minimizing cold start times in serverless applications via resource serialization. <em>SUPERC</em>, <em>81</em>(12), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07710-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a serverless architecture cold start optimization solution based on resource serialization. The performance of this technology was evaluated through experiments across multiple cloud platforms, testing different function types and resource configurations. The results demonstrate that resource serialization reduces serverless function cold start time and memory consumption. In web service scenarios, the optimization achieved an 86.78% reduction, decreasing cold start time from 42266.35ms to 5585.97ms. Cross-platform testing shows optimization rates exceeding 53% across different cloud environments. Analysis indicates that this technology’s effectiveness varies by application type: I/O-intensive applications and functions with complex environment configurations showed higher optimization rates compared to compute-intensive tasks, with AI inference functions showing a 25.67% reduction. The combination of this technology with existing optimization strategies, such as Layer implementation, produced additional performance improvements. The research also addresses security considerations and implementation constraints in production environments and provides implementation guidelines. These findings contribute to the optimization of serverless applications and provide implementation reference for cloud service providers and developers.},
  archive      = {J_SUPERC},
  author       = {Liu, Yu and Li, Fu and Kong, Chenhao},
  doi          = {10.1007/s11227-025-07710-z},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A generic framework for minimizing cold start times in serverless applications via resource serialization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Service reliability prediction methodology based on multivariate time series and improved AdaRNN model. <em>SUPERC</em>, <em>81</em>(12), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07712-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring reliable operation in dynamic and uncertain service systems is a major challenge. This study aims to improve service system reliability by predicting reliability in advance to eliminate potential risks, especially addressing the temporal covariate shift problem, and proposes an efficient solution. This paper proposes a service reliability prediction method based on multivariate time series and an improved adaptive recurrent neural network (AdaRNN) model. Multiple reliability indicators, including service response time, service throughput, system response rate, and service reliability, are used to construct multivariate time series to represent service reliability, while the improved AdaRNN model is employed to effectively handle the temporal covariate shift problem. The improved AdaRNN model utilizes a dynamic programming algorithm to achieve optimal temporal domain partitioning and employs the self-attention mechanism to learn the multivariate temporal features and their interrelationships. The model learns the maximum similarity of multivariate temporal features from different time domains during the training phase, and then, by applying the concept of temporal domain adaptation, it is used for the prediction task on the test set. To support large-scale multivariate time-series data and enable efficient training of the improved AdaRNN model, this work utilizes high-performance computing (HPC) infrastructure. The computational demands of model training, temporal domain adaptation, and multivariate sequence alignment make HPC resources essential for ensuring real-time performance and model scalability across diverse service systems. The experimental results show that the proposed service reliability prediction method, based on transfer learning, demonstrates excellent robustness in predicting reliability across different services. Additionally, it outperforms mainstream methods in terms of both accuracy and model adaptation ability.},
  archive      = {J_SUPERC},
  author       = {Zhang, Xiuguo and Cao, Yuhang and Wang, Peipeng and Cao, Zhiying and Chen, Zhiwei},
  doi          = {10.1007/s11227-025-07712-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Service reliability prediction methodology based on multivariate time series and improved AdaRNN model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementing a hybrid deep learning technique for detecting malicious DNS over HTTPS (DoH) traffic. <em>SUPERC</em>, <em>81</em>(12), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07715-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cybersecurity, the detection of malicious activities within domain name system (DNS) over HTTPS (DoH) traffic is of paramount importance. However, traditional classification methods often struggle to generalize across diverse network environments and effectively handle the complexities inherent in DNS traffic data. To solve these challenges, this article proposes a novel deep learning based on DoH traffic classification. A hybrid deep learning technique is proposed for detecting malicious DNS traffic. This approach forces the strengths of graph neural networks and capsule networks for effective classification. The method aims to enhance detection accuracy and improve response times in identifying threats. This study focuses on enhancing performance through optimal hyperparameter selection. The golden jackal optimization algorithm is employed for this purpose, hybridized with capsule networks. This approach aims to improve classification accuracy and efficiency in the targeted application. For the L1-DoH-NonDoH dataset, results show strong performance across metrics with an accuracy of 99.7%, precision of 98.5%, recall of 99.7%, and F1-score of 99.3%. Similarly, for the L2-Benign DoH-Malicious DoH dataset, the model achieved an accuracy of 99.8%, precision of 98.9%, recall of 99.8%, and F1-score of 99%. These results validate the efficacy of the method in distinguishing both benign and malicious traffic across various metrics.},
  archive      = {J_SUPERC},
  author       = {Sha, Mohemmed and Binbusayyis, Adel},
  doi          = {10.1007/s11227-025-07715-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Implementing a hybrid deep learning technique for detecting malicious DNS over HTTPS (DoH) traffic},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sac-lstm: Optimal resource allocation based on user intent in computility networks. <em>SUPERC</em>, <em>81</em>(12), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07718-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of novel application scenarios within the Industrial Internet of Things (IIoT) necessitates a reevaluation of resource distribution strategies within Computility Networks. Existing researches show that allocating computational resources in alignment with user intent has been demonstrated to improve the efficiency of resource distribution significantly. Existing research fails to adequately address the dynamics and heterogeneity of nodes, as well as the ambiguity of user intent in Computility Networks, leading to suboptimal resource allocation results. To address these challenges, this research introduces a novel Soft Actor-Critic Long Short-Term Memory (SAC-LSTM) framework, which seamlessly translates user intents into concrete resource allocation strategies. Specifically, the proposed framework integrates natural language processing (NLP) techniques for intent modeling with deep reinforcement learning (DRL) for decision-making, enabling an end-to-end optimization of intent-driven resource allocation. To mitigate the scarcity of sufficiently annotated corpora in various scenarios, we employ large-scale unsupervised corpora for pre-training. The experiments are conducted on the EdgeCloudSim simulation platform. For intent detection, the alpha and CAMPI datasets are utilized. Resource allocation experiments are carried out within both the EdgeCloudSim and Mininet simulation environments. Experimental results indicate that the proposed framework not only accurately identifies user intents but also showcases outstanding performance in managing resource allocation tasks within both continuous and discrete action spaces. The efficacy of the framework is corroborated by tests on diverse datasets, which confirm its potential to optimize resource distribution in the dynamic IIoT environment.},
  archive      = {J_SUPERC},
  author       = {Zheng, Yingying and Chen, Ningjiang and Yin, Yin and Huang, Zizhan and Wang, Jingwei and Wang, Weijing and Gan, Xinghui},
  doi          = {10.1007/s11227-025-07718-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Sac-lstm: Optimal resource allocation based on user intent in computility networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RCCS: Resource clustering-based container scheduling for serverless edge intelligence. <em>SUPERC</em>, <em>81</em>(12), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07719-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge intelligence represents an emerging computing paradigm that processes data in real time and performs artificial intelligence tasks at the network edge. Using containerized serverless computing on edge devices can further achieve more real-time and efficient computing. However, the limited and heterogeneous computing resources in the edge, coupled with the geographical dispersion of devices and data, have seriously hindered the advancement of edge intelligence. Consequently, how to fully utilize the computing resources at the network edge while ensuring low delay of containers is a major challenge currently faced. To address this challenge, this paper proposes a resource clustering-based container scheduling (RCCS) algorithm. The RCCS achieves efficient heterogeneous resource management through resource clustering and models the container scheduling problem as a multi-criteria decision-making problem. The problem of solving the weight coefficients between the criteria is transformed into a mixed-integer linear programming problem. The optimal weight vector is then obtained through the CBC solver. Subsequently, the scores of each edge node can be calculated, and the container request is scheduled to the node with the highest score for execution. The results of a large number of simulation experiments based on real-world data demonstrate RCCS achieves an effective trade-off between reducing delay and improving edge resource utilization. Compared with existing container scheduling algorithms, the RCCS improves the average GPU utilization of edge clusters by 23.54% and reduces the average completion time of containers by 18.35–31.44%.},
  archive      = {J_SUPERC},
  author       = {Lin, Yufeng and Liu, Bo and Lin, Weiwei and Zhu, Tiehan and Guo, Chunli and Fong, Simon James},
  doi          = {10.1007/s11227-025-07719-4},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {RCCS: Resource clustering-based container scheduling for serverless edge intelligence},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple yet effective enhanced collaborative filtering framework for mitigating noise and data sparsity: Evidence from pervasive digital platform datasets. <em>SUPERC</em>, <em>81</em>(12), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07720-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In collaborative filtering, numerous studies concentrate on the development of novel similarity measures to enhance predictive accuracy. However, through our extensive case studies, we have identified that these approaches frequently fail to adequately cope with the challenges posed by intrinsic noise and data sparsity, which can significantly impact the reliability of similarity calculations, leading to inaccurate predictions. To address these issues, we propose a straightforward yet effective similarity-enhanced collaborative filtering framework. Initially, we account for item popularity bias when adjusting co-rated items between users and subsequently eliminate rare co-rated items based on a predefined noise threshold. This approach mitigates the influence of unreliable co-rated items (i.e., noise) on similarity results, thereby enhancing the reliability of similarity calculations. Following this step, we employ a simple and effective matrix factorization technique that can be substituted with alternative deep learning approaches to accurately fit and fill the sparse similarity matrix after noise reduction. This strategy alleviates the effects of insufficient nearest neighbors and excessive deviations in similarity due to data sparsity, ensuring high-quality neighborhoods in rating predictions. Experimental results on three public datasets with varying sizes and sparsity levels demonstrate that our framework significantly improves the performance of existing methods using similarity measure. Specifically, compared with traditional similarity methods, our approach achieves notable improvements with average maximum gains of 38.4%, 16.6%, and 18.5% in MAE, HR, and NDCG, respectively. This methodology effectively balances the trade-off between noise reduction and data density while providing a comprehensive solution for optimizing similarity calculations and improving collaborative filtering performance.},
  archive      = {J_SUPERC},
  author       = {Deng, Jiangzhou and Zheng, Lei and Zhang, Zhiqiang and Ye, Jianmei and Wang, Yong},
  doi          = {10.1007/s11227-025-07720-x},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {A simple yet effective enhanced collaborative filtering framework for mitigating noise and data sparsity: Evidence from pervasive digital platform datasets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature selection method based on salp swarm algorithm with a multi-round voting mechanism. <em>SUPERC</em>, <em>81</em>(12), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07721-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the salp swarm algorithm (SSA) has become an efficient tool for feature selection (FS) problems. However, the algorithm has drawbacks, including local optimality and a limited convergence rate. Therefore, we propose NSSA, an enhanced version of SSA that integrates four strategies. Firstly, a multi-round voting mechanism based on three filter methods is presented to achieve a high-quality initial population. Furthermore, an adaptive Lagrange interpolation inertia weight is introduced to promote the adaptative capability by defining a testing phase. Additionally, the position updates mathematical models of leader and followers are modified by taking advantage of more important positions to enhance the search performance. Finally, a novel elite generalized opposition-based learning is presented to accelerate the convergence rate. The NSSA is compared with 7 metaheuristic algorithms on 16 benchmark datasets. The outcomes indicate that the NSSA achieves better fitness values and smaller feature sizes on the majority of datasets.},
  archive      = {J_SUPERC},
  author       = {Zhang, Hongbo and Nan, Haohuan and Yue, Xiaofeng and Gao, Xueliang},
  doi          = {10.1007/s11227-025-07721-w},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A feature selection method based on salp swarm algorithm with a multi-round voting mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QAT-LOADng: QoS aware trusted lightweight on-demand adhoc distance-vector routing-next generation. <em>SUPERC</em>, <em>81</em>(12), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07722-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant role of routing in the Internet of Things (IoT) has led to the introduction of various routing protocols tailored for this crucial network. Among these protocols is LOADng-IoT, an on-demand routing protocol designed specifically for IoT environments. While LOADng-IoT aligns well with IoT requirements, it lacks inherent security mechanisms, leaving it vulnerable despite its efficiency. To address this limitation, a more advanced protocol named QAT-LOADng (QoS Aware Trusted Lightweight On-demand Adhoc Distance-vector routing-Next Generation) has been developed as an enhancement to LOADng-IoT. QAT-LOADng leverages the Ant algorithm and incorporates a reputation system to bolster security. The primary objective of QAT-LOADng is to establish trust in routing and data transmission through a two-stage process. The first stage focuses on trust-based routing using the Ant algorithm, while the second stage involves data transmission with trust evaluation. Simulation results demonstrate that QAT-LOADng not only ensures reliable routing and data exchange but also enhances the overall quality of routing and data transmission. Specifically, it shows a 7.9% improvement in packet delivery ratio (PDR) compared to LOADng-IoT, along with lower energy consumption and overhead when compared to existing protocols.},
  archive      = {J_SUPERC},
  author       = {Nazarian Parizi, Mostafa and Ghafouri, Seyyed Hamid and Hajmohammadi, Mohammad Sadegh},
  doi          = {10.1007/s11227-025-07722-9},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {QAT-LOADng: QoS aware trusted lightweight on-demand adhoc distance-vector routing-next generation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slerp-opt: Merging large language models via adaptive strategies. <em>SUPERC</em>, <em>81</em>(12), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07727-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a considerable number of studies have centered on enhancing the efficacy of Large Language Models (LLMs) in cross-domain tasks. Existing approaches frequently depend on large-scale data training or multi-model collaboration strategies. However, these methods encounter challenges such as imbalanced performance across domains and substantial deployment costs. To address these issues, this paper proposes a model-merging approach that integrates two domain-specific expert LLMs to train a cross-domain LLM. Specifically, we have designed a two-stage workflow, LoRA-Merge, to facilitate cross-domain training of LLMs. In the fine-tuning stage, we employ LoRA (Low-Rank Adaptation) to efficiently adapt the base LLM to the target domain. Subsequently, in the merging stage, we introduce a weight-optimization-driven merging algorithm, Slerp-Opt (Optimized Spherical Linear Interpolation), which dynamically adjusts the weight ratios of different modules within the model layers to achieve optimal integration. Slerp-Opt requires only 5% of the GPU memory and training time of LoRA fine-tuning. These improvements allow Slerp‑Opt to run comfortably within the tight memory and latency constraints of modern supercomputing hardware—delivering fast LLM merges on a single NVIDIA A40 node without additional infrastructure. Extensive experiments on diverse benchmarks demonstrate that Slerp‑Opt enhances the downstream task performance while significantly lowering resource demands. Together, these characteristics position Slerp‑Opt as an efficient, HPC‑friendly solution for fast training of large-scale LLMs.},
  archive      = {J_SUPERC},
  author       = {Jiang, Haiyin and Wang, Ruilin and Liang, Weijie and Sun, Qi and Zhang, Xiang and Liu, Yanan},
  doi          = {10.1007/s11227-025-07727-4},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Slerp-opt: Merging large language models via adaptive strategies},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infrared and visible military image fusion strategies and applications based on composite decomposition and multi-fuzzy theory. <em>SUPERC</em>, <em>81</em>(12), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07731-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of military target detection, due to the limitations of acquisition conditions in complex battlefield environments, some images still suffer from insufficient clarity even after preprocessing. This not only makes it difficult to provide accurate target feature information required for effective detection, but also significantly reduces real-time computing efficiency due to data redundancy and noise interference. To address this, this paper proposes a military image fusion strategy based on composite decomposition and multi-fuzziness theory, aiming to balance image quality improvement and computational accuracy optimization supported by high-performance computing. Firstly, the two-scale composite method is combined with LatLRR to decompose the source infrared and visible images into low-frequency details, low-frequency significant, and high-frequency images, respectively, to excavate the deep information of the images. Secondly, three fusion strategies based on fuzzy theory, GFVSM weighting, CFEOE adaptive, and improved GSSIFS function, are proposed to fuse the decomposed images in the following manner: the low-frequency detail images are fused using a Gaussian fuzzy function that adjusts the visual saliency map weighting function; the low-frequency salient images are fused using a Cauchy fuzzy function that adjusts the image energy weight; the high-frequency images are fused employing a proposed improved intuitionistic fuzzy set function. Finally, four sets of typical military images in the infrared–visible dataset are used to test the efficacy of our method and to compare it against four mainstream fusion methods, both subjectively and objectively. The comparison experiments results show that the images fused using our method show improvements of 9.56%, 42.12%, 47.46%, 44.94%, and 28.82% in five key performance indices, respectively, over the average values produced by the four mainstream fusion algorithms. The three-dimensional image reveals that the image fused by this method has enhanced rich detail information, prominent target, and obvious edge features. The application experiments results indicate that the military target detection rate of the fused image is improved by 9.04% and 6.87% compared with that of the infrared and visible images before fusion, respectively. This military image fusion strategy effectively retains the key information of the source image thus improving the accuracy of military target detection.},
  archive      = {J_SUPERC},
  author       = {Wang, Shuai and Zhu, Yifan and Du, Yuhong and Yang, Ming},
  doi          = {10.1007/s11227-025-07731-8},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Infrared and visible military image fusion strategies and applications based on composite decomposition and multi-fuzzy theory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent eyes on water: YOLOv11-based real-time drowning detection system. <em>SUPERC</em>, <em>81</em>(12), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07732-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drowning remains a critical public health issue, particularly among children and young adults, often due to delays in recognizing and responding to emergencies. There are many previous methodologies for drowning detection that have predominantly utilized conventional techniques, including human observation, closed-circuit television monitoring, and rudimentary alarm systems. Despite their widespread implementation, these approaches are often limited by critical limitations such as susceptibility to human error, observer fatigue, and latency in incident recognition. To address these limitations, this study proposes an intelligent drowning detection system utilizing the YOLOv11 model, optimized for real-time, low-power operation on a Raspberry Pi 5 (8GB RAM). A custom dataset was developed to represent different real-world drowning scenarios. The dataset was prepared through cleaning, annotation, and augmentation, followed by model training. To improve model robustness and generalization, augmentation techniques such as scaling, rotation, brightness adjustment, and noise reduction were applied. The proposed system continuously analyzes live video streams to detect potential drowning incidents. Upon detection, the system immediately activates an alarm and sends mobile alarms to lifeguards or emergency personnel, enabling prompt intervention. The model achieved a high mAP@50 score of 0.98 while maintaining a lightweight architecture with 2.58 million parameters and 6.3 GFLOPs (Giga Floating Point Operations Per Second). Due to its affordability, efficiency, and strong performance, the system is well-suited for deployment in swimming pools, beaches, and water parks, providing a practical solution for enhancing safety and facilitating rapid emergency response.},
  archive      = {J_SUPERC},
  author       = {Amer, Dina A. and Ibrahim, Nader Y. and Ibrahim, Ibrahim K. and Mohamed, Ahmed M. and Soliman, Sarah A.},
  doi          = {10.1007/s11227-025-07732-7},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Intelligent eyes on water: YOLOv11-based real-time drowning detection system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic GPU memory access optimization for AoSoA-based application in OP2 framework. <em>SUPERC</em>, <em>81</em>(12), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07734-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portable parallel programming methods are attractive for application developers as hardware architectures are increasingly diverse. OP2 is a domain-specific programming framework for unstructured mesh applications that supports unified programming for multiple hardware platforms. Structure, as a user-defined data type that groups items of possibly different types into a single type, is commonly used in many applications. Current OP2 implementations face limitations in leveraging GPU memory hierarchies when handling complex data organizations, specifically the Array of Structure of Array (AoSoA) patterns, in which each element of the top-level array is a structure of multi-dimensional arrays. To address this issue, we first propose a new SoA (Structure of Array) layout transformation algorithm for AoSoA-based application to optimize the data access locality. Then, we introduce new OP2 primitives to enable CUDA codes to utilize the local memory and the shared memory. These enhancements, integrated into OP2’s library and source-to-source translator, enable automatic generation of optimized CUDA code. We evaluate the proposed approaches with a high-order unstructured CFD application on representative GPUs. Compared to the original implementation, the optimized implementation improves the performance for up to 25.68x on NVIDIA V100S, 4.74x on NVIDIA A100 and 3.7x on Hygon Z100 DCU. We also measure a selected set of GPU low-level performance metrics to better explain the results.},
  archive      = {J_SUPERC},
  author       = {Lei, Tong and Chen, Zongjing and Che, Yonggang and Xu, Chuanfu and Dai, Zhe and Zhang, Jian},
  doi          = {10.1007/s11227-025-07734-5},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Automatic GPU memory access optimization for AoSoA-based application in OP2 framework},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HIDE: High-integrity data embedding using dynamic carrier control in H.266/VVC streams. <em>SUPERC</em>, <em>81</em>(12), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07736-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents HIDE, a novel and high-integrity data embedding method designed for H.266/VVC video streams. HIDE leverages a dynamic carrier control mechanism to achieve efficient, secure, and high-fidelity data hiding while maintaining minimal impact on video quality. The proposed method introduces an entropy-based complexity analysis of Coding Tree Units (CTUs), enabling adaptive classification into high- and low-complexity regions. This classification facilitates intelligent carrier selection and dynamic adjustment of the embedding capacity based on texture characteristics. A Carrier Selection Criterion (CSC) is defined to probabilistically select CTUs for embedding using a reproducible random function initialized with a shared seed. Within each selected CTU, the smallest N PUs with directional intra prediction modes are identified as carriers, forming a structured carrier vector used for data embedding. A key feature of HIDE is its modular architecture, which inherently supports parallel processing and GPU acceleration—making it suitable for deployment in large-scale and real-time video streaming systems where high-performance computing capabilities are essential. A binary stream derived from the secret data is mapped onto this vector through a controlled mode-based modification process, where only one prediction mode is adjusted by ± 1 to embed the data. This minimal change ensures high integrity and imperceptibility, preserving both visual quality and compression efficiency. The data extraction process in H.266/VVC involves extracting hidden data embedded within the compressed video stream, ensuring efficient retrieval of the embedded hidden data. Experimental results demonstrate that HIDE achieves excellent performance in terms of embedding capacity, security, and robustness, making it a promising solution for secure and reliable data embedding applications in modern video coding environments.},
  archive      = {J_SUPERC},
  author       = {Noori, Sarah-Ahmad and Ramezanpour, Mohammadreza and Alomari, Esraa-Saleh and Khorsand, Reihaneh},
  doi          = {10.1007/s11227-025-07736-3},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {HIDE: High-integrity data embedding using dynamic carrier control in H.266/VVC streams},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-inspired framework to accelerate reinforcement learning. <em>SUPERC</em>, <em>81</em>(12), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07737-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is crucial for data science decision-making but suffers from sample inefficiency, particularly in real-world scenarios with costly physical interactions. This paper introduces a novel human-inspired framework to enhance the RL algorithm’s sample efficiency. It achieves this by initially exposing the learning agent to simpler tasks that progressively increase in complexity, ultimately leading to the main task. This method requires no pre-training and involves learning simpler tasks for just one episode. The resulting knowledge can facilitate various transfer learning approaches, such as value and policy transfer, without increasing computational complexity. It can be applied across different goals, environments, and RL algorithms, including value-based, policy-based, tabular, and deep RL methods. Experimental evaluations demonstrate the framework’s effectiveness in enhancing sample efficiency, especially in challenging main tasks, demonstrated through both a simple random walk and more complex optimal control problems with constraints.},
  archive      = {J_SUPERC},
  author       = {Beikmohammadi, Ali and Magnússon, Sindri},
  doi          = {10.1007/s11227-025-07737-2},
  journal      = {The Journal of Supercomputing},
  month        = {8},
  number       = {12},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Human-inspired framework to accelerate reinforcement learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exaptation as a strategic mechanism in public R&D: Challenges and solutions at the barcelona supercomputing center. <em>SUPERC</em>, <em>81</em>(11), 1--16. (<a href='https://doi.org/10.1007/s11227-025-07588-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Barcelona Supercomputing Center (BSC) is a leading public R&D institution in high-performance computing (HPC), yet it faces challenges such as budget constraints, misaligned recruitment strategies, and technical experts’ reluctance to assume leadership roles. Through interviews with 20 BSC experts, this study identifies exaptation—repurposing internal roles and external collaborations—as a pivotal strategy to address these challenges. Findings reveal that interdisciplinary team structures and proactive engagement with technology developers enhance innovation, while budgetary cycles and support-service limitations hinder efficiency. The study contributes a novel framework for public R&D institutions to leverage exaptation, balancing structural flexibility with performance metrics. Key recommendations include aligning HR practices with strategic goals and fostering adaptive leadership.},
  archive      = {J_SUPERC},
  author       = {Toscani, Giulio},
  doi          = {10.1007/s11227-025-07588-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {Exaptation as a strategic mechanism in public R&D: Challenges and solutions at the barcelona supercomputing center},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy improved coati optimization algorithm. <em>SUPERC</em>, <em>81</em>(11), 1--74. (<a href='https://doi.org/10.1007/s11227-025-07617-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of slow convergence and susceptibility to local optima in the coati optimization algorithm (COA), this study proposes a multi-strategy enhanced variant named WOCOA. WOCOA incorporates a hybrid initialization strategy combining random initialization and lens opposition-based learning (LOBL), further enhanced by Tent mapping to increase population diversity. The golden sine strategy is introduced in the search phase to balance exploration and exploitation, while a spiral bubble-net strategy from whale optimization algorithm (WOA) is applied in the exploitation phase to enhance global search capability. Ablation experiments validate the individual and collective contributions of these strategies to performance improvement. Furthermore, comparative experiments across 18 UCI datasets, 23 benchmark test functions, and the CEC-2017 suite demonstrate the effectiveness and superiority of WOCOA in feature selection and numerical optimization. Finally, two scalability experiments confirm its applicability and robustness in solving high-dimensional and complex real-world optimization problems.},
  archive      = {J_SUPERC},
  author       = {Xu, Yujie and Jiang, Yao and Xu, Jialing and Wang, Lan and Liu, Xingchen and Jia, Liyun},
  doi          = {10.1007/s11227-025-07617-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--74},
  shortjournal = {J. Supercomput.},
  title        = {Multi-strategy improved coati optimization algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing IoT intrusion detection with genetic algorithm-optimized convolutional neural networks. <em>SUPERC</em>, <em>81</em>(11), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07626-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity and volume of cyberattacks necessitate the development of advanced Intrusion Detection Systems that are capable of efficient and scalable threat detection. As network infrastructures expand exponentially and the proliferation of Internet of Things (IoT) devices, traditional intrusion detection systems face significant challenges in adapting to evolving attack patterns. This paper introduces a novel intrusion detection framework, leveraging Neural Architecture Search to optimize the design of a convolutional neural network (CNN). Specifically, it proposes a system that integrates CNN with genetic algorithm for both synthesizing the neural architecture and systematically optimizing associated hyperparameters. This approach improves model performance by automating the search for the most effective neural architecture. The proposed approach was evaluated on UNSW-NB15, TON_IoT, and CICIoT2023 datasets. Experimental results demonstrate the efficacy and scalability of the method, with 85.7%, 99.93%, and 90.13% classification accuracies, respectively. Moreover, the high classification results on the TON_IoT and CICIoT2023 datasets confirm the approach efficiency and suitability for real-time applications, addressing the practical challenges of securing IoT networks.},
  archive      = {J_SUPERC},
  author       = {Hakiki, Racha Ikram and Azerine, Abdennour and Tlemsani, Redouane and Golabi, Mahmoud and Idoumghar, Lhassane},
  doi          = {10.1007/s11227-025-07626-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing IoT intrusion detection with genetic algorithm-optimized convolutional neural networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault tolerant and mobility-aware task offloading and scheduling model for IoT logistics. <em>SUPERC</em>, <em>81</em>(11), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07627-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of the Internet of Things (IoT) has resulted in the widespread deployment of interconnected devices that frequently depend on external fog nodes for computational support due to limitations in battery life, processing power, and storage capacity. In such environments, ensuring efficient and reliable task offloading and scheduling mechanisms is critical to maintain system performance and service quality. However, the task scheduling problem—especially within dynamic logistics scenarios involving mobile IoT devices, is NP-hard and computationally intensive, due to the continuous movement and heterogeneity of devices. To address these challenges, this study proposes a novel Fault-Tolerant and Mobility-Aware Task Offloading and Scheduling Model (FTM-TOSM) tailored for IoT-enabled logistics systems. The model introduces mobility awareness by dynamically assessing the relative proximity of mobile IoT devices (e.g., vehicles, drones) to fog nodes using Euclidean distance, enabling location-optimized task assignments. A multi-criteria decision-making approach, based on the Analytic Hierarchy Process (AHP), is employed to determine task priorities. Tasks are then categorized as follows: low-priority tasks are executed locally on IoT devices, Medium-priority tasks are offloaded to nearby fog nodes, and High-priority tasks are routed to cloud servers for advanced processing. To enhance fault tolerance, the model incorporates dynamic re-clustering techniques, allowing the system to recover from node failures during offloading operations. Furthermore, Virtual Machine (VM) selection for task execution is guided by a multi-criteria strategy that considers execution cost, energy consumption, and available resources. Performance assessments conducted using the iFogSim2 simulation platform reveal that the FTM-TOSM framework substantially outperforms traditional approaches like Ant Colony Optimization (ACO). Specifically, the model delivers up to a 10.4% reduction in energy usage, a 25.2% drop in SLA violations, a 16.28% enhancement in response time, and a 22.1% decrease in task failure rates. These findings confirm the model’s capability to improve the reliability, operational efficiency, and flexibility of fog-based IoT logistics environments.},
  archive      = {J_SUPERC},
  author       = {Umer, Asif and Ali, Mushtaq and Jehangiri, Ali Imran},
  doi          = {10.1007/s11227-025-07627-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {Fault tolerant and mobility-aware task offloading and scheduling model for IoT logistics},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing edge intelligence: A DRL-driven service migration approach with enhanced feedback in mobile edge computing. <em>SUPERC</em>, <em>81</em>(11), 1--53. (<a href='https://doi.org/10.1007/s11227-025-07630-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing, service migration promises intelligent task placement as well as maintaining seamless functionality in bandwidth-intensive, latency-sensitive applications. Despite the promise of service migration offered by deep reinforcement learning (DRL), existing techniques lack topology awareness and dynamic adaptability. This research proposes a novel graph convolutional network (GCN)-based DRL framework enhanced with multi-parameter feedback (energy, delay, bandwidth) for intelligent service migration in MEC. Unlike prior DRL methods, our GCN-based framework models server topologies as spatial relationships and adapts feedback weights dynamically in response to changing system conditions. Experimental evaluation using EdgeSimPy and EdgeAISim shows that our proposed method reduces power consumption by 27% compared to traditional DRL (DQN) and by 44% compared to heuristic approaches (Worst-Fit). Moreover, the framework consistently outperforms existing state-of-the-art DRL algorithms in terms of energy efficiency, latency reduction, and resource optimization. Our key contributions include: (1) A topology-aware GCN-DRL architecture; (2) Dynamic multi-parameter feedback-driven reward formulation that improve energy efficiency by 15% under high network stress; and (3) Comprehensive benchmarking against six algorithm classes in varied MEC scenarios.},
  archive      = {J_SUPERC},
  author       = {Kansal, Puneet and Kumar, Manoj and Verma, O. P.},
  doi          = {10.1007/s11227-025-07630-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--53},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing edge intelligence: A DRL-driven service migration approach with enhanced feedback in mobile edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint relational triple extraction based on topic constraints and multicore attention fusion. <em>SUPERC</em>, <em>81</em>(11), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07631-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is a fundamental task in natural language processing, closely linked with named entity recognition. While existing methods for extracting relational triples can improve performance to some extent, they often treat identified entities as discrete categorical labels, overlooking the contextual and thematic attributes of those entities. Additionally, current models frequently ignore the textual content outside the entities, resulting in poor interaction between sub-modules and the underutilization of valuable semantic information. To address these shortcomings, we propose a novel joint entity-relation extraction model named Topic Constraint and Multicore Attention-based Joint Extraction (TCMA $$\_$$ JE). Our model introduces the Subject Topic Filtering module, which enriches entity representations by leveraging subject vectors to derive contextually relevant features. Furthermore, the Multicore Semantic Fusion module employs convolutional neural networks to establish an attention-based fusion mechanism, integrating entity vectors, rich-typed features, and global text representations in a comprehensive manner. This deep semantic fusion significantly enhances the model’s ability to utilize textual information. Extensive experiments conducted on the NYT and WebNLG datasets demonstrate that our model achieves superior performance.},
  archive      = {J_SUPERC},
  author       = {Chen, Zhe and Xing, Sihao and Zhang, Yinyang},
  doi          = {10.1007/s11227-025-07631-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Joint relational triple extraction based on topic constraints and multicore attention fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAFormer: Multivariate time series forecasting combining channel attention and transformer in the frequency domain. <em>SUPERC</em>, <em>81</em>(11), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07634-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency-domain modeling has emerged as a powerful paradigm for time series forecasting, yet existing Transformer-based approaches face a fundamental challenge. While they effectively capture temporal dependencies, they cannot model the time-varying importance of frequency-domain features. To address this significant gap, we propose FCAFormer, a frequency-aware Transformer architecture that enhances frequency-domain modeling through two key innovations. First, our novel frequency-channel attention mechanism uniquely integrates multihead self-attention with frequency-adaptive channel attention, enabling the simultaneous learning of long-term temporal patterns and the dynamic importance of frequency features. Second, we introduce SparseCoreFFN, a computationally efficient feedforward network that employs strategic parameter sparsification to maintain model capacity while significantly reducing computational overhead. Extensive experiments across eight diverse real-world datasets demonstrate the effectiveness of FCAFormer: It achieves superior forecasting accuracy while effectively addressing the frequency-domain learning bias that has constrained previous approaches. Compared to existing baselines, FCAFormer consistently demonstrates notable improvements, offering a promising advancement in frequency-aware time series modeling.},
  archive      = {J_SUPERC},
  author       = {Xiao, Bin and Ge, Zehao and Zhang, Xingpeng and Wang, Min and Chen, Zheng and Yang, Zhou and Wu, Yanxue},
  doi          = {10.1007/s11227-025-07634-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {FCAFormer: Multivariate time series forecasting combining channel attention and transformer in the frequency domain},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A replacement for the scaling axiomatic approach to scheduling dependent tasks on DVFS computing platforms. <em>SUPERC</em>, <em>81</em>(11), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07637-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Voltage and Frequency Scaling (DVFS) platforms are highly effective in reducing energy consumption, as they allow the adjustment of operating frequency and voltage in predefined pairs. Lowering a task’s execution frequency proportionally reduces the voltage, thereby decreasing overall energy usage. This article presents the design of a low-complexity, energy-efficient frequency scaling mechanism for executing dependent tasks on DVFS-enabled platforms. In such applications, energy can be minimized using the Scaling Axiomatic Approach (SAA), which reduces task frequencies while respecting dependency constraints. However, this method suffers from high time complexity, often exceeding that of standard scheduling algorithms, which limits its practicality. To address this, we introduce GinGa, a lower-bound frequency scaling mechanism for DVFS-enabled platforms that serve as an efficient replacement for SAA. GinGa achieves energy savings close to those of SAA, with only minor performance degradation. GinGa was evaluated on a large set of randomly generated task graphs and three real-world applications, demonstrating its ability to effectively replace SAA while retaining most of its energy-saving benefits. Additionally, GinGa can be combined with slack extender mechanisms to further enhance frequency scaling. These results highlight GinGa as a low-complexity, efficient solution for energy-aware scheduling in DVFS-enabled platforms.},
  archive      = {J_SUPERC},
  author       = {Hagras, Tarek and El-Sayed, Gamal A.},
  doi          = {10.1007/s11227-025-07637-5},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {A replacement for the scaling axiomatic approach to scheduling dependent tasks on DVFS computing platforms},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST–FPN: A swin transformer-based lightweight model for accurate VLSI congestion prediction. <em>SUPERC</em>, <em>81</em>(11), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07641-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Placement and Routing (PnR), a computationally intensive NP-hard challenge in Very Large-Scale Integration (VLSI) design, is often bottlenecked by the lengthy simulation times of conventional EDA tools. Machine learning-driven congestion prediction provides an effective approach to speed up PnR. Current methods, relying on CNN and GNN architectures, struggle to balance accuracy and efficiency. To address this, we propose ST–FPN, a novel framework integrating Swin Transformer and Feature Pyramid Network (FPN) to enhance congestion prediction. We further enhance congestion-related features, such as Rectangular Uniform wire Density. Built on a streamlined architecture with just 2.74M parameters, $$70 \%$$ smaller than Swin Transformer UNet, our model improves score by $$72.2 \%$$ and $$19.3 \%$$ over GAN and RouteNet, respectively. Additionally, the model is extended to CircuitNet-N14 (14nm dataset), achieving a Structural Similarity Index Measure of 0.89, showcasing robust generalization across diverse process nodes.},
  archive      = {J_SUPERC},
  author       = {Cai, Qiang and Zhang, Shizeng and Ding, Ping and Wu, Xinyu and Huang, Pingyang and Zhang, Tianyi and You, Haitao and Cheng, Zhiyuan and Cui, Qiang},
  doi          = {10.1007/s11227-025-07641-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {ST–FPN: A swin transformer-based lightweight model for accurate VLSI congestion prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy aware-based multi-task learning for user location prediction. <em>SUPERC</em>, <em>81</em>(11), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07643-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in high-precision positioning technology and the availability of commercial map services, LBSNs can now acquire both geographic coordinates and precise category information of locations. However, most existing models for user location prediction suffer from two significant limitations: neglecting category information and overlooking the hierarchical relationship between specific locations and their corresponding categories. To overcome these challenges, we propose the hierarchy aware-based multi-task learning (HAMTL) framework, which jointly predicts the next location and its category. HAMTL extracts hierarchy information by constructing a hierarchy tree, which is then fused with other feature information before encoding. Finally, a hierarchical decoder is designed for prediction. Extensive experiments conducted on two real-world datasets demonstrate that HAMTL outperforms seven baselines across all evaluation metrics, achieving a maximum Acc@1 improvement of over 18% compared with the state-of-the-art method. In addition, we show that the hierarchical decoder provides advantages over HAMTL on the basis of the effective modeling of hierarchy information.},
  archive      = {J_SUPERC},
  author       = {Wang, Yahui and Chen, Hongchang and Liu, Shuxin and Zhang, Junjie and Wu, Lan and Cui, Xiaoyan and Hu, Yuxiang},
  doi          = {10.1007/s11227-025-07643-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Hierarchy aware-based multi-task learning for user location prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum computing-inspired resource distribution in healthcare. <em>SUPERC</em>, <em>81</em>(11), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07644-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in the internet of things technology have significantly improved the quality of healthcare services, particularly through the integration of artificial intelligence. However, the healthcare sector continues to face persistent challenges, such as the increasing population, the rising burden of diseases, and the limited availability of critical medical resources. These challenges are especially pronounced during medical emergencies, where the timely and optimal allocation of healthcare resources is vital. To address this pressing issue, the current research explores the use of quantum computing in conjunction with fog computing to optimize resource distribution in emergency scenarios. The study proposes a quantum-based mapping framework that utilizes quantum-inspired techniques to calculate the medical resource availability index for individual hospitals and healthcare centers. This enables real-time prediction and efficient allocation of resources during emergencies. In addition, an intelligent quantum neural network is developed to forecast the future demand for medical resources based on dynamic emergency conditions. To validate the proposed system, a 60-day controlled simulation was conducted involving four healthcare centers. The results demonstrate that the proposed technique outperforms existing state-of-the-art resource allocation methods across multiple performance metrics. It achieves a low temporal delay of 4.59 ms with 2.15% performance gain and exhibits high quantum mapping efficacy with a precision of 96.05%, sensitivity of 96.93%, and specificity of 97.46%. The decision-making component also shows strong performance, with a precision of 92.69%, sensitivity of 91.65%, specificity of 94.26%, and an F-measure of 95.26%, resulting in an average performance gain of 3.25% in comparison to state-of-the-art models. Furthermore, the system achieves a reliability score of 94.86% and a stability measure of 0.82. These findings highlight the potential of quantum computing technologies in transforming healthcare emergency response systems through intelligent and efficient resource management.},
  archive      = {J_SUPERC},
  author       = {Alqahtani, Abdullah and Bhatia, Munish},
  doi          = {10.1007/s11227-025-07644-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Quantum computing-inspired resource distribution in healthcare},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filling space swarm optimization (FSSO): A metaheuristic algorithm with divided agent strategies and diamond crossover. <em>SUPERC</em>, <em>81</em>(11), 1--60. (<a href='https://doi.org/10.1007/s11227-025-07645-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing exploration and exploitation remains a fundamental challenge in the design of metaheuristic algorithms, as agents typically cannot perform both tasks simultaneously. To address this issue, this article introduces the filling space swarm optimization (FSSO) algorithm that explicitly segregates the population into two distinct groups—explorers and exploiters—each governed by specialized, purpose-driven mechanisms. The exploration process is guided by a virtual particle that traces a trajectory defined by a space-filling curve, ensuring systematic coverage of the entire search space. Acting as a dynamic, centralized reference, this virtual particle coordinates the movement of explorer agents, enhancing global search efficiency and avoiding redundant evaluations. In parallel, the exploitation process is driven by a new diamond crossover operator, which intensifies the search around elite solutions by generating candidate solutions within a diamond-shaped neighborhood. This operator promotes fine-grained local optimization, boosting the algorithm’s ability to refine high-quality solutions. The adaptive balance between exploration and exploitation is maintained through the adjustable ratio of explorers to exploiters, enabling the algorithm to respond dynamically to different search phases. Extensive validation using a diverse set of 30 benchmark functions, including shifted functions designed to challenge center-biased strategies, confirms the superiority of the proposed approach, by comparing it with eight well-known metaheuristics schemes. The results reveal that the algorithm achieves faster convergence and higher solution quality compared to state-of-the-art metaheuristics outperforming them in 80% of the benchmark functions, while successfully avoiding the limitations associated with center-biased search behaviors.},
  archive      = {J_SUPERC},
  author       = {Cuevas, Erik and González-Sánchez, Óscar A. and Escobar, Héctor and Ayala, L. Ernesto and Zaldívar, Daniel},
  doi          = {10.1007/s11227-025-07645-5},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--60},
  shortjournal = {J. Supercomput.},
  title        = {Filling space swarm optimization (FSSO): A metaheuristic algorithm with divided agent strategies and diamond crossover},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient offloading framework for mobile edge/cloud computing based on convex optimization and deep Q-network. <em>SUPERC</em>, <em>81</em>(11), 1--49. (<a href='https://doi.org/10.1007/s11227-025-07647-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency is one of the most critical aspects of modern computing paradigms due to minimizing carbon footprint and lowering operational costs. To achieve efficiency, the typical approach is to address the source of energy consumption and apply the appropriate strategies for energy savings. In this paper, based on an offloading framework for edge and cloud computing, we propose a comprehensive methodology that leverages predictive analysis and convex optimization techniques to achieve efficiency in power utilization. This methodology aimed to reduce the power consumption of edge/cloud computing clusters while maintaining an acceptable quality of service. The core idea was to enhance the historical data in the first place by using the prediction. This predictive historical data revealed the trend of computational resource allocation. Subsequently, the convex optimization technique coupled with the Deep Q-Network model was employed to formulate and schedule the distribution of the offloaded tasks. By engaging this combination, the offloading framework could produce a near-optimal and adaptive energy decision, which helps achieve energy efficiency. The experimental results showed that the proposed methodology could obtain significant energy savings while maintaining a suitable level of performance compared to other state-of-the-art approaches.},
  archive      = {J_SUPERC},
  author       = {Madiyev, Askar and Bulegenov, Daulet and Karzhaubayev, Anuar and Murzabulatov, Meiram and Bui, Dinh Mao},
  doi          = {10.1007/s11227-025-07647-3},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--49},
  shortjournal = {J. Supercomput.},
  title        = {Energy-efficient offloading framework for mobile edge/cloud computing based on convex optimization and deep Q-network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The EfficientNetV2-based correction localization combining CSI and RSSI. <em>SUPERC</em>, <em>81</em>(11), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07648-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, WiFi has garnered increasing attention due to its fine-grained Channel State Information (CSI). Theoretically, more information from the transmitter implies greater potential for accurate localization. To enhance indoor positioning accuracy, this paper proposes an EfficientNetV2-based calibration localization system that integrates Physical Layer (PHY) information from CSI and Medium Access Control Layer (MAC) information from Received Signal Strength Indicator (RSSI), referred to as the Effrf system. The system first eliminates outliers using the Robust Random Cut Forest (RRCF) algorithm and then constructs an extended grid fingerprint database through radial basis function interpolation. In the offline phase, three-dimensional feature map fingerprints based on CSI amplitude, CSI phase, and RSSI are constructed, referred to as CSR feature map fingerprints. The EfficientNetV2 model is then trained to establish the correspondence between the fingerprints and their corresponding positions. During the online phase, to reduce data preprocessing time and ensure real-time positioning, the RRCF streaming anomaly detection method is employed to eliminate outliers. The EfficientNetV2 model, accelerated by GPU, is then used for position estimation. To further enhance accuracy, a random forest (RF) model is utilized to correct high-error localization results generated by the EfficientNetV2 model. Under indoor Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) conditions, the proposed system achieves average localization errors of 0.5962 m and 1.0306 m, respectively.},
  archive      = {J_SUPERC},
  author       = {Lu, Chundong and Shang, Junna and Liao, Wei and Su, Mingkun and Ding, Yanzhao},
  doi          = {10.1007/s11227-025-07648-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {The EfficientNetV2-based correction localization combining CSI and RSSI},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Workflow ensemble scheduling in IaaS cloud: A gap analysis perspective under deadline and budget constraints. <em>SUPERC</em>, <em>81</em>(11), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07649-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing provides a scalable and flexible platform for executing scientific workflows. Workflow ensembles, which consist of workflows with similar structures but varying input data and sizes, require efficient scheduling to optimize resource utilization, reduce costs, and improve workflow completion rates. Traditional scheduling methods often leave idle time slots between tasks, leading to resource wastage and decreased system efficiency. This paper presents Workflow Ensemble Scheduling with Gap analysis (WESG), a novel approach designed to overcome these challenges while adhering to budget and deadline constraints. WESG employs a five-step algorithm to analyze and reduce resource idleness, optimizing task allocation and resource provisioning. By effectively utilizing these gaps, WESG enhances resource efficiency, prioritizes high-priority workflows, and increases the overall number of completed workflows. Experimental results show that WESG outperforms traditional scheduling techniques, achieving better resource utilization, reducing idle gaps, and significantly improving workflow completion rates.},
  archive      = {J_SUPERC},
  author       = {Shafinezhad, Negin and Abrishami, Hamid and Zolfaghari, Behrooz and Abrishami, Saeid and Morvaridi, Anahita},
  doi          = {10.1007/s11227-025-07649-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Workflow ensemble scheduling in IaaS cloud: A gap analysis perspective under deadline and budget constraints},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph knowledge distillation-guided few-shot learning for hyperspectral image classification. <em>SUPERC</em>, <em>81</em>(11), 1--46. (<a href='https://doi.org/10.1007/s11227-025-07653-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification focuses on accurately classifying each pixel in hyperspectral images using partially labeled data, which is crucial for the precise identification and differentiation of various land cover types. In recent years, Graph Neural Networks (GNNs)-based hyperspectral image classification have exhibited exceptional performance when a substantial number of labeled samples are available. However, the acquisition of annotation data is often a labor-intensive and time-consuming process in practical scenarios. When the number of available labeled samples is limited, the model’s performance can easily degrade. To tackle the above issue, a Graph Knowledge Distillation-guided Few-Shot Learning method (GKDFSL) is proposed for hyperspectral image classification. Specifically, for a comprehensive modeling of hyperspectral image features, a graph structure is first constructed from segmented superpixels. Subsequently, graph augmentation is performed to generate two separate graph perspectives. Teacher and student GNNs are then applied to each perspective to extract superpixel features. Knowledge distillation techniques are then utilized to transmit diverse knowledge learned by the teacher GNNs to the student GNNs, thereby enabling the student model to effectively capture the latent associations between unlabeled superpixels. To further enhance the model’s understanding and learning capabilities, GNNs are integrated with the mean teacher framework to improve generalization. Moreover, ensemble learning is introduced to bolster the robustness of the method. Extensive experiments conducted on four benchmark datasets have demonstrated that the proposed method surpasses other competitive approaches in both classification accuracy and generalization capabilities.},
  archive      = {J_SUPERC},
  author       = {Li, Xiaolong and Ma, Huifang and Guo, Shuheng and Zhang, Di and Li, Zhixin},
  doi          = {10.1007/s11227-025-07653-5},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--46},
  shortjournal = {J. Supercomput.},
  title        = {Graph knowledge distillation-guided few-shot learning for hyperspectral image classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A complementary time-frequency domain approach for short-term photovoltaic power forecasting. <em>SUPERC</em>, <em>81</em>(11), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07654-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term photovoltaic (PV) power forecasting is challenged under cloudy conditions. Recent deep learning-based methods utilize time-frequency modeling offer promise, yet they ignore either spectral bias or redundancy, limiting prediction accuracy. Therefore, we propose a complementary time-frequency domain approach for this task, which integrates PV and meteorological data into two learners in both domains. Moreover, both learners are guided by intra- and inter-domain constraints to enhance representation quality, while a specialized attention module fuses features for final prediction. Experiments on two real-world datasets, conducted with GPU-based parallelization, demonstrate that CTFD outperforms fourteen state-of-the-art baselines, reducing MAE by 12.50% and 12.75%, and RMSE by 11.38% and 12.99% on cloudy test sets. These results not only validate the effectiveness of our complementary time-frequency modeling, but also imply that accurate forecasting of PV power fluctuations inherently demands parallel or high-performance computing capabilities, making such computational cost a necessary trade-off in practical deployments.},
  archive      = {J_SUPERC},
  author       = {Wang, Wentao and Lu, Haiyan and Ubaid, Ayesha and Wang, Jianzhou},
  doi          = {10.1007/s11227-025-07654-4},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {A complementary time-frequency domain approach for short-term photovoltaic power forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-satellite link allocation in low-earth-orbit mega-constellation networks. <em>SUPERC</em>, <em>81</em>(11), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07655-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by technological advancements and cost reductions, the rapid deployment of low-Earth-orbit (LEO) satellites has led to the emergence of mega-constellations based on inter-satellite links (ISLs). However, the communication performance of satellite networks is easily affected by the time-varying network topology and the link constraints caused by the limited computational resources of satellite nodes. Consequently, the design of ISL allocation algorithms for LEO satellites has become a critical challenge for current mega-constellations. To address this issue, this paper proposes a Non-Dominated Sorting Genetic Algorithm II based on elite selection criteria (ENSGA-II). The satellite network’s ISL allocation problem is modeled as a multi-objective optimization model, where elite selection criteria are employed to preserve solutions with lower delays while optimizing both the average and maximum delays. This approach enhances the overall effectiveness of ISL allocation in satellite networks. Simulation results demonstrate that ENSGA-II exhibits faster link optimization capabilities during the allocation process and significantly improves the communication delay performance of the network topology. Compared to single-point and two-point crossover-based NSGA-II algorithms, the maximum delay was reduced by 3 ms and 9 ms, and the average delay was reduced by 1 ms compared to single-point crossover and was the same as two-point crossover. These findings indicate that ENSGA-II is well suited for ISL allocation in mega-constellations.},
  archive      = {J_SUPERC},
  author       = {Ren, Weiwu and Wang, Bingsen and Sun, Jie and Hong, Yu},
  doi          = {10.1007/s11227-025-07655-3},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Inter-satellite link allocation in low-earth-orbit mega-constellation networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic penetration testing model based on reinforcement learning for complex network environments. <em>SUPERC</em>, <em>81</em>(11), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07656-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Penetration testing is an effective method for assessing cybersecurity posture. However, as cyber attacks become increasingly sophisticated and network environments grow in complexity, traditional intelligent penetration testing models encounter significant challenges in efficiently identifying optimal strategies and achieving rapid convergence. To address these issues, this paper proposes an automatic penetration testing model based on reinforcement learning, which abstracts the testing process as a Markov Decision Process (MDP) and incorporates a curiosity mechanism to enhance exploration efficiency. The core of this approach lies in training an agent using a reinforcement learning algorithm equipped with a curiosity mechanism, enabling it to automatically explore and select optimal penetration testing strategies based on reward feedback from the environment, and to persist until sensitive privileges are obtained. Experiments conducted in a simulated network environment with 50 hosts and millions of states demonstrate that the proposed model reduces convergence time by approximately 50% compared to the standard Proximal Policy Optimization (PPO) algorithm. By integrating GPU acceleration within a high-performance computing (HPC) framework and employing distributed parallel processing, the model effectively satisfies the real-time and scalability requirements of penetration testing in complex network environments.},
  archive      = {J_SUPERC},
  author       = {Chen, Yang and He, Junjiang and Fang, Wenbo and Yang, Shenwen and Chen, Jiangchuan and Li, Tao and Lan, Xiaolong},
  doi          = {10.1007/s11227-025-07656-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Automatic penetration testing model based on reinforcement learning for complex network environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key exchange based on three-dimensional segre products and their projections. <em>SUPERC</em>, <em>81</em>(11), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07657-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a key exchange protocol in which Alice and Bob use a three-dimensional Segre product embedded in a large projective space by mean of the Veronese embedding. Public keys are given by hyperplanes cutting pairs of Segre products containing a common plane. Alice and Bob consider the residual curve which is projectively equivalent to a smooth plane curve of genus 1, whose j-invariant is the exchanged key. When the dimension of the above projective space increases very much, HPC capabilities are required.},
  archive      = {J_SUPERC},
  author       = {Alzati, Alberto and Tortora, Alfonso},
  doi          = {10.1007/s11227-025-07657-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Key exchange based on three-dimensional segre products and their projections},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying influential spreaders on weighted directed networks based on spreading properties. <em>SUPERC</em>, <em>81</em>(11), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07658-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the influential spreaders in social networks is crucial for maximizing the reach and impact of information dissemination. Many works have been proposed based on undirected and unweighted networks to identify the influential spreaders in the literature. However, many real applications are represented as weighted and directed networks, where the essential characteristics need to be defined for the system. A few works have been proposed based on weighted directed networks, and these measures mainly focused on the concept of finding the central nodes, as reported in the literature. To maximize the spreading propagation in the social network, we have proposed a new “Weighted Cross-bred” method (wcm), which is designed based on the spreading properties of the network. To evaluate the effectiveness of wcm, we have used the Weighted Directed Susceptible-Infected-Recovered (WDSIR) epidemic model as a benchmark simulator, twelve real-world networks, and fourteen well-known existing indexing methods. The results highlight the superior ranking accuracy of wcm, as demonstrated by key performance indicators such as Kendall $$\tau$$ correlation, Precision@r for spreading efficiency, fastest influencer, the effect of various infection probability for seed node-set spreading performance, and average shortest path length $$(L_\mathrm{{s}})$$ across different methods. The experimental findings show that the wcm method consistently outperforms other indexing methods regarding spreading dynamics.},
  archive      = {J_SUPERC},
  author       = {Saha, Nilanjana and Namtirtha, Amrita and Dutta, Animesh},
  doi          = {10.1007/s11227-025-07658-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Identifying influential spreaders on weighted directed networks based on spreading properties},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast generalized surrogate−assisted evolutionary algorithm for solving expensive constrained optimization problems. <em>SUPERC</em>, <em>81</em>(11), 1--47. (<a href='https://doi.org/10.1007/s11227-025-07660-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional evolutionary algorithms (EAs) often require a large number of function evaluations (FEs) to solve expensive constraint optimization problems (ECOPs), leading to high computational costs. To address this challenge, this paper proposes a fast generalized surrogate−assisted evolution algorithm based on a multi-strategy hybrid sparrow search algorithm (FGSAEA-MSHSSA). The proposed algorithm introduces an innovative model management approach that integrates both global and local surrogate models. The proposed algorithm constructs the global surrogate model using an ensemble surrogate method and introduces a variance and distance (VD) criterion to select appropriate individuals for exact evaluation, effectively guiding the evolutionary search process. It also proposes the concept of a population trust region to build local surrogate models, enhancing the exploration capability of FGSAEA-MSHSSA. Additionally, the top feasible mean rule (TFMR) is incorporated to maintain a balance between the feasible and infeasible regions during the search, improving the quality of feasible solutions and significantly accelerating convergence. Experimental results demonstrate that the proposed algorithm outperforms other advanced algorithms on benchmark functions with varying characteristics and spring design problems. It not only significantly reduces computational costs but also greatly enhances optimization performance, with an average improvement of approximately 48.4% compared to other algorithms.},
  archive      = {J_SUPERC},
  author       = {Liu, Genggeng and Su, Xuehui and Zhou, Ruping and Liu, Nengxian and Zhang, Liyuan and Tian, Ye},
  doi          = {10.1007/s11227-025-07660-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {A fast generalized surrogate−assisted evolutionary algorithm for solving expensive constrained optimization problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multilevel integrated supervision self-distillation method. <em>SUPERC</em>, <em>81</em>(11), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07661-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of deep convolutional networks has made them a crucial method for solving various computer vision tasks. In response to the increasing demand for low-error performance in visual applications, numerous techniques have been proposed to enhance the capabilities of deep convolutional networks. As a specialized form of knowledge distillation, self-distillation (SD) eliminates the need for a separate teacher model by incorporating auxiliary branches into the intermediate layers of the network and leveraging its own supervisory signals for training. However, existing SD methods still face challenges, including insufficient utilization of shallow branch information and significant representation differences between deep and shallow branches, which limit the effectiveness of knowledge transfer. To address these issues, this paper proposes a multilevel integrated supervision self-distillation (MLISD) method, which integrates shallow classifiers’ response supervision to the deepest classifier with the feature map supervision of deeper branches toward adjacent shallower branches, thereby enriching the learned knowledge. Additionally, we introduce a parallel channel–spatial adaptive attention module and propose an improved classifier design. Comprehensive experiments conducted with multiple classical deep learning models across diverse public datasets confirm that the proposed MLISD method effectively breaks through the performance limitations of traditional self-distillation approaches. Notably, MLISD-equipped models achieve average accuracy improvements of 2.87% on CIFAR-100, 2.30% on TinyImageNet, 3.49% on CUB-200, and 4.10% on MIT-67, achieving substantial improvements over other cutting-edge self-distillation methods.},
  archive      = {J_SUPERC},
  author       = {Wang, Yuxiang and Lei, Xuemei},
  doi          = {10.1007/s11227-025-07661-5},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {A multilevel integrated supervision self-distillation method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid classical quantum computation for cybersecurity strategies in a layered cybersecurity model. <em>SUPERC</em>, <em>81</em>(11), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07662-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity has become increasingly vital in our highly interconnected digital world. Many key challenges in this field can be modeled as optimization problems, involving elements such as system vulnerabilities, attack budgets, defense costs, and potential attacker gains. Recent advancements in quantum annealing have shown promise in tackling complex optimization tasks across various domains. This paper explores how quantum annealers can be leveraged to address cybersecurity problems from both offensive and defensive perspectives. For each case, a Hamiltonian is constructed in the Quadratic Unconstrained Binary Optimization (QUBO) form—suitable for input into a quantum annealer—and correctness proofs are provided. Along the way, some new QUBO construction techniques are introduced, which may be applicable to other problem areas. The theoretical findings are supported by experimental results obtained using a D-Wave simulator. The article concludes with a discussion on the practical relevance and implementation of the proposed Hamiltonians.},
  archive      = {J_SUPERC},
  author       = {Kritsadakul, Jedsadakorn and Kantabutra, Sanpawat},
  doi          = {10.1007/s11227-025-07662-4},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Hybrid classical quantum computation for cybersecurity strategies in a layered cybersecurity model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying and prioritizing key success factors for scaling DevOps methods in distributed software development environment using analytical hierarchy process. <em>SUPERC</em>, <em>81</em>(11), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07663-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software companies are increasingly adopting distributed software development in conjunction with DevOps practices to improve collaboration, automation, and continuous delivery, ultimately accelerating the delivery of high quality products. However, in distributed and global software development, socio-cultural, geographical, and temporal boundaries hinder the seamless execution of DevOps practices. This study aims to identify and prioritize key success factors for implementing DevOps in such contexts. The research work was structured in three phases. First, a systematic literature review was conducted, resulting in the identification of 12 success factors. These were categorized through expert consultation into four groups based on maturity levels: Foundational DevOps Engineering, Proficient DevOps Engineering, Expert DevOps Engineering, and Full-Stack DevOps Engineering. To gather data for validation of the identified success factors, an online questionnaire survey was carried out in the second phase. Lastly, the factors and their categories were ranked according to their relative significance using the Analytical Hierarchy Process approach. Foundational DevOps Engineering emerged as the most significant category in the results. The most critical individual factors for scaling DevOps include: “executive support for DevOps endeavors”, “maintaining continuous monitoring and evaluation to ensure high-quality production”, “providing efficient training and continuous learning support to improve team members' skills” and “Integrating security into the organization’s culture”. These prioritized factors and categories form a decision-support framework that provides strategic guidance for scaling DevOps practices within the distributed software development setting.},
  archive      = {J_SUPERC},
  author       = {Khan, Abdul Wahid and Khan, Saad Ullah and Alnajim, Abdullah M. and Khan, Faheem and Khan, Rahmatullah},
  doi          = {10.1007/s11227-025-07663-3},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Identifying and prioritizing key success factors for scaling DevOps methods in distributed software development environment using analytical hierarchy process},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-object tracking based on spatial super-resolution and spatiotemporal convolutional self-attention. <em>SUPERC</em>, <em>81</em>(11), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07664-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) is a critical task in computer vision, aiming to track multiple objects in video sequences while accurately identifying and localizing their identities and positions. However, the accuracy of tracking is still affected by factors such as object occlusion and tiny object. In this study, we propose a multi-object tracking method based on spatial super-resolution and spatiotemporal convolutional self-attention. First, to solve the problem of missed detection of small objects, we utilize spatial super-resolution algorithm, extracting more detailed information about object features. Then, to avoid false positive identification and ID switches due to object occlusion, we empower the DETR model by adding spatiotemporal convolutional self-attention layers to leverage the locality information between patches. Furthermore, we design a grid-based object query to the position encoding of the model, which makes up for the lack of explicit physical meanings in DETR. Experimental results on the MOT17 and MOT20 datasets demonstrate significant performance improvements with our proposed method.},
  archive      = {J_SUPERC},
  author       = {Huang, Jinjie and Cui, Jiayu},
  doi          = {10.1007/s11227-025-07664-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Multi-object tracking based on spatial super-resolution and spatiotemporal convolutional self-attention},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT-DGSL: Dynamic transformer using denoising graph structure learning for IoT time series anomaly detection. <em>SUPERC</em>, <em>81</em>(11), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07665-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) devices generate massive volumes of Iot time series data through sensors during continuous operation. The exponential growth in data volume has imposed increasingly stringent requirements on the real-time processing and analysis of this data. Particularly in high-load, high-speed data processing scenarios, the timely detection and handling of anomalies become crucial for maintaining system stability, making efficient anomaly detection a key task for ensuring system reliability. Additionally, many unsupervised deep learning methods often result in high false positive rates. To address these challenges, we propose an unsupervised anomaly detection model: dynamic transformer with denoising graph structure learning (DT-DGSL). DT-DGSL leverages the advantages of the Transformer parallel structure, utilizing the Anomaly Transformer variant and self-attention mechanism to independently learn the spatio-temporal characteristics of sensor data, which enables more accurate reconstruction of the original sequences. We also tackle subtle anomalies in complex datasets and false anomalies from environmental noise by introducing a layer of radial basis function (RBF) neurons and employing window-based dynamic graph structure learning, respectively, to reduce the model’s false positive rate. Experimental results on five public datasets show that DT-DGSL has improved the average F1 score by 20.29% and achieved state-of-the-art results on multiple datasets. Moreover, DT-DGSL demonstrates excellent real-time performance, which is suitable for IoT applications.},
  archive      = {J_SUPERC},
  author       = {You, Peng and Wang, Xinxin and Chen, Peng and Wu, Lei and Chen, Juan and Li, Xi and Zeng, Shengke and Gao, Huangyining},
  doi          = {10.1007/s11227-025-07665-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {DT-DGSL: Dynamic transformer using denoising graph structure learning for IoT time series anomaly detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent audio processing methodology for operational risk reduction in complex industrial process control systems. <em>SUPERC</em>, <em>81</em>(11), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07666-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative audio processing strategy that integrates ambient sound with headset audio to enhance situational awareness in dynamic environments, with potential applications in process control and monitoring systems. Our proposed methodology offers a systematic approach to extracting crucial environmental audio signals and seamlessly integrating them with headset audio content. Through comprehensive simulation studies across three industrial noise scenarios (quiet control room: 50 dBA, production floor: 70 dBA, machinery room: 90 dBA), our method demonstrates superior performance compared to baseline approaches. Specifically, the proposed system achieves significant improvements in signal-to-noise ratio (5–10 dB gain), perceptual evaluation of speech quality (PESQ scores of 3.21 vs. 2.43 for baseline Multi-channel Wiener Filter), short-time objective intelligibility (STOI values of 0.91 vs. 0.78), and signal-to-distortion ratio (16.8 dB vs. 11.3 dB). The system maintains real-time processing capabilities with a real-time factor (RTF) of 0.42 and memory requirements of 127 MB, making it suitable for embedded industrial systems. Validation using real-world industrial recordings from automotive manufacturing facilities confirms practical effectiveness with signal-to-distortion ratio of 7.82 dB and PESQ score of 3.24. The adaptive mixing algorithm and semi-supervised learning techniques enable the system to effectively model and adapt to various acoustic environments, making it suitable for deployment in diverse process control scenarios from petrochemical plants to manufacturing facilities. This research contributes to the field of process control by introducing a novel solution for maintaining operator awareness of critical auditory cues in complex industrial settings, where the ability to perceive and respond to environmental changes is essential for safety and efficiency.},
  archive      = {J_SUPERC},
  author       = {Ma, Gengchen and Xu, Haichao and Chen, Bin and Li, Anji},
  doi          = {10.1007/s11227-025-07666-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Intelligent audio processing methodology for operational risk reduction in complex industrial process control systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing trust of deep learning models with post-quantum digital signatures. <em>SUPERC</em>, <em>81</em>(11), 1--49. (<a href='https://doi.org/10.1007/s11227-025-07669-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance computing (HPC) is crucial for artificial intelligence (AI) and deep learning (DL) but faces challenges related to scalability, data transfer costs, and security risks. Federated Learning (FL) enables collaborative model training without centralized data aggregation. However, FL introduces vulnerabilities, as exchanged models can be intercepted and manipulated, necessitating robust cryptographic protection. With the advent of quantum computing, traditional security mechanisms are at risk, requiring the adoption of Post-Quantum Cryptographic (PQC) algorithms. This study benchmarks three PQC digital signature algorithms: Falcon, SPHINCS+, and ML-DSA. Their execution time, memory usage, and computational efficiency are evaluated in a simulated FL setting. To extend the analysis, different cryptographic hash functions (SHA3-256, SHA3-512, and BLAKE3) are analyzed to assess hashing efficiency under varying computational loads. Both centralized and decentralized FL scenarios are simulated, incorporating PQC-based digital signatures at each phase of the communication pipeline to ensure model integrity and authenticity. The results provide insights into the trade-offs between security and computational overhead, guiding the selection of scalable cryptographic solutions for FL. Falcon and ML-DSA demonstrate minimal impact on computational performance, making them strong candidates for securing FL environments. Future research directions include the direct signing of DL models to enhance security and the integration of widely used FL libraries for more realistic evaluations. These advancements could improve the practical deployment of post-quantum security solutions in FL, ensuring resilience against emerging quantum threats.},
  archive      = {J_SUPERC},
  author       = {Castiglione, Aniello and Esposito, Jacopo Gennaro and Loia, Vincenzo and Nappi, Michele and Pero, Chiara and Polsinelli, Matteo},
  doi          = {10.1007/s11227-025-07669-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--49},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing trust of deep learning models with post-quantum digital signatures},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new multi-wing hyperchaotic system and its application in image encryption. <em>SUPERC</em>, <em>81</em>(11), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07670-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel image encryption scheme based on a multi-wing hyperchaotic system is constructed, and its performance is comprehensively evaluated. By introducing a segmented linear function, the hyperchaotic system with a multi-wing attractor structure is designed, which has a more complex phase space topology compared to traditional single-wing or double-wing chaotic system, can generate higher dimensional pseudo-random sequences with higher initial value sensitivity, and significantly improves the key space and resistance to attacks. The algorithm first utilizes the bit plane decomposition and combination technique to decompose the plaintext image into four planes, and then performs zigzag transform with different vertices on these decomposed planes, followed by bit plane merging of the transform four planes, and forward diffusion and backward diffusion of the merged planes. Experiments show that the novel image encryption algorithm constructed by this multi-wing hyperchaotic system is characterized by a large key space and can effectively resist chosen-plaintext attack and statistical attack. Compared with the existing algorithms, this scheme has significant advantages in terms of security, robustness and efficiency, and is suitable for real-time encryption scenarios. This study provides a new design inspiration for the development of image encryption techniques guided by chaos theory, which increasing the confidentiality, integrity and security of image data and addressing the security threats that may be faced during storage, transmission or sharing.},
  archive      = {J_SUPERC},
  author       = {Ding, Pengfei and Hu, Weiwei and Geng, Penghui and Zhang, Juan and Zhu, Jingge},
  doi          = {10.1007/s11227-025-07670-4},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {A new multi-wing hyperchaotic system and its application in image encryption},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal graph learning driven by multivariate KAN for urban road network traffic prediction. <em>SUPERC</em>, <em>81</em>(11), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07671-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid pace of urbanization, challenges such as traffic congestion and air quality deterioration have become increasingly pronounced, making traffic information forecasting a key component in addressing these challenges within intelligent transportation systems. However, traffic flow exhibits complex dependencies in the spatiotemporal dimensions, and the prediction difficulty is further exacerbated by external events such as traffic accidents. While current models based on neural networks have seen some success, their ability to express nonlinear patterns and provide interpretability remains limited. To this end, this paper presents a traffic information prediction model, Graph Convolutional Multivariate Kolmogorov–Arnold Network, which integrates the multivariate Kolmogorov–Arnold Network (KAN) with the Graph Convolutional Network (GCN). The model first extracts the spatial features of the traffic network through the GCN layer, capturing the topological dependency relationships between roads. Subsequently, it employs three KAN variants—Chebyshev KAN, B-spline KAN, and Taylor KAN—to handle periodicity, smoothness, and nonlinearity in traffic flow, respectively. By dynamically evaluating the characteristics of the traffic data and appropriately assigning weights to each variant, the model adaptively optimizes the capture of different features. The model’s clear mathematical formulation improves the clarity and interpretability of the forecasting process. Experimental results demonstrate that the proposed model outperforms traditional approaches in capturing complex spatiotemporal nonlinear relationships, significantly improving the accuracy and interpretability of traffic flow predictions. This research provides a novel solution for traffic information forecasting in Intelligent Transportation Systems.},
  archive      = {J_SUPERC},
  author       = {Zhang, Ao and Liu, Han and Yang, HaiQiang},
  doi          = {10.1007/s11227-025-07671-3},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Spatiotemporal graph learning driven by multivariate KAN for urban road network traffic prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSF-CSCNet: A supercomputing-ready 3D semantic segmentation network for urban point clouds via multi-scale fusion and context-aware channel modeling. <em>SUPERC</em>, <em>81</em>(11), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07672-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate semantic segmentation of LiDAR point clouds demands substantial computational resources due to massive data volumes and complex feature extraction, particularly in autonomous driving scenarios. To mitigate these computational bottlenecks, this paper proposes MSF-CSCNet, an advanced 3D semantic segmentation framework explicitly optimized for parallel and distributed processing. MSF-CSCNet integrates multi-scale voxel feature fusion and enhanced channel context modeling, enabling efficient utilization of parallel computing environments. The multi-scale spatial fusion module (MSF) effectively addresses spatial density variations through efficient cross-distance feature fusion in cylindrical coordinates, thereby enabling parallel execution. Additionally, the channel context and spatial decomposition module (CSC) dynamically reorganizes feature channels and implements dual-path attention, balancing computational loads across multiple GPUs. Furthermore, the Pinwheel3DConv module, employing asymmetric convolution kernels, significantly enhances segmentation granularity while maintaining computational efficiency. Experimental evaluations conducted on a high-performance computing cluster equipped with NVIDIA RTX 3090 GPUs demonstrate near-linear scalability for MSF-CSCNet across multiple GPUs, achieving end-to-end throughput exceeding seven frames per second. Evaluations on the SemanticKITTI dataset further validate MSF-CSCNet’s superior accuracy (65.81% mIoU, 91.55% Acc, and 71.44% Acc_cls), confirming the method’s capability to effectively handle urban scenes with diverse object densities and distances. These computational results substantiate MSF-CSCNet’s effectiveness and suitability for real-time semantic perception in large-scale autonomous driving applications.},
  archive      = {J_SUPERC},
  author       = {Bai, Yun and Gong, Yuxuan and Wang, Jinlei and Wei, Feng},
  doi          = {10.1007/s11227-025-07672-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {MSF-CSCNet: A supercomputing-ready 3D semantic segmentation network for urban point clouds via multi-scale fusion and context-aware channel modeling},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FuzOptRoute: A fuzzy logic-integrated optimization-based energy-efficient cluster routing framework with edge computing for mobile communication networks. <em>SUPERC</em>, <em>81</em>(11), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07673-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient and reliable routing remains a fundamental challenge in mobile communication networks, particularly due to the dynamic topology, limited energy resources, the increasing integration of high-performance computing (HPC) for real-time analytics, and the rising demand for scalable and adaptive data transmission. This study proposes FuzOptRoute, a novel Fuzzy Logic-Integrated Optimization-Based Cluster Routing Framework that aims to enhance the energy efficiency and communication reliability of mobile communication networks. The proposed framework integrates Fuzzy C-Means (FCM) clustering to intelligently partition network nodes based on multiple parameters such as residual energy, node mobility, and proximity to the base station. FCM enables the formation of dynamic and flexible clusters that adapt to changing network conditions, ensuring balanced energy consumption across the network. To optimize the selection of Cluster Heads (CHs) within the fuzzy-generated clusters, the study introduces the Golden Jackal Optimization (GJO) algorithm—a nature-inspired metaheuristic that balances exploration and exploitation through adaptive population updating and elite solution preservation mechanisms. GJO is employed to identify optimal CHs by maximizing residual energy, minimizing intra-cluster distances, and reducing communication overhead. The framework also incorporates edge and distributed computing to enable localized processing, enhance scalability, and reduce communication latency by delegating computation across multiple nodes. The hybrid integration of FCM and GJO enables the proposed FuzOptRoute framework to maintain efficient cluster formation and routing decisions in real time, thereby prolonging network lifetime and improving data delivery reliability. Simulation results demonstrate that FuzOptRoute significantly outperforms existing clustering-based routing protocols in terms of energy consumption, network lifetime, packet delivery ratio, and latency, particularly under highly dynamic mobility scenarios.},
  archive      = {J_SUPERC},
  author       = {Alotaibi, Jamal},
  doi          = {10.1007/s11227-025-07673-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {FuzOptRoute: A fuzzy logic-integrated optimization-based energy-efficient cluster routing framework with edge computing for mobile communication networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GUITARES: Graph attention network for building knowledge graph-based trust-aware recommender systems. <em>SUPERC</em>, <em>81</em>(11), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07674-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-aware recommender systems are vital for enhancing recommendation precision and user satisfaction while addressing data sparsity and cold start challenges. Traditional approaches often emphasize limited aspects of trust or overlook the complex interactions between users and items. Moreover, knowledge-based methods may struggle with scalability, and artificial intelligence-driven models can miss uncertainties in item information and the multifaceted nature of trust. To address these shortcomings, we propose a hybrid recommendation framework named GUITARES. This framework employs graph attention networks to model enriched user-item interactions alongside trust relationships. GUITARES is structured into three main components: an ontology-based enrichment module that assigns confidence scores to item metadata, a trust prediction module that utilizes demographic similarities, and a graph attention module that integrates trust, metadata, and user ratings. GUITARES scales efficiently to large graphs—validated by systematic experiments—and achieves an RMSE of 0.80 on MovieLens, outperforming state-of-the-art methods, making it ideal for HPC environments handling massive recommendation networks.},
  archive      = {J_SUPERC},
  author       = {Touameur, Ouissem and Harrag, Fouzi and Bellatreche, Ladjel},
  doi          = {10.1007/s11227-025-07674-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {GUITARES: Graph attention network for building knowledge graph-based trust-aware recommender systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMF-net: A mamba-based enhancement network for low-light object detection. <em>SUPERC</em>, <em>81</em>(11), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07675-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in low-light conditions remains challenging. An intuitive approach is to preprocess images using low-light image enhancement methods. However, as these methods are optimized for human perception rather than machine vision, most of them lead to suboptimal detection performance. To address this limitation, we propose a detection-oriented enhancement network that jointly optimizes both tasks, Low-light Mamba Frequency Network (LMF-Net). LMF-Net integrates a multi-scale convolution branch into Mamba, enabling global context modeling and local feature extraction with linear computational complexity. As low-light images contain many informative low and high-frequency components, we introduce a frequency channel attention mechanism to better utilize multi-spectral features. We adopt an end-to-end training strategy by integrating LMF-Net with a detection network, whose parameters remain frozen during training. This ensures improved detection performance in low-light scenes while maintaining robustness in normal lighting. Furthermore, this training strategy allows LMF-Net to be flexibly integrated into existing detection pipelines. Extensive experiments on multiple datasets show that LMF-Net not only outperforms existing methods but also exhibits high computational efficiency.},
  archive      = {J_SUPERC},
  author       = {He, Ao and An, Guanhua and Guo, Jichang},
  doi          = {10.1007/s11227-025-07675-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {LMF-net: A mamba-based enhancement network for low-light object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention and frequency domain enhancement for image dehazing based on transformer. <em>SUPERC</em>, <em>81</em>(11), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07676-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image dehazing is a critical task in computer vision. However, existing methods struggle with handling non-uniform haze distribution, capturing global contextual information, and filtering noise while preserving fine details. To overcome these limitations, we propose a Transformer-based dehazing network enhanced by attention and frequency domain techniques. A dual-path feature encoder is designed, incorporating an Optimized Self-Attention Transformer Block (OSATB) to improve global dependency modeling and a Feature Refinement Extraction Block (FREB) to extract fine texture details using attention mechanisms. Furthermore, a Feature Attention Fusion Block (FAFB) adaptively assigns weights to feature maps, facilitating the integration of global and local information. A Dual-Frequency Enhancement Block (DFEB) further refines pixel-level details and suppresses noise in the frequency domain. Finally, the decoder reconstructs a clear image. To comprehensively evaluate the performance of the proposed method, we conducted a systematic training and evaluation process on multiple large-scale synthetic and real-world hazy image datasets, including RESIDE and other widely used benchmarks. Experimental results demonstrate that the proposed method achieves superior performance on both synthetic and real-world hazy image datasets, effectively addressing the challenges mentioned above.},
  archive      = {J_SUPERC},
  author       = {Wang, Yan and Li, Jiayi and Wang, Huan and Li, Shurong},
  doi          = {10.1007/s11227-025-07676-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Attention and frequency domain enhancement for image dehazing based on transformer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced harmonic fuzzy partition clustering algorithm incorporating a novel membership modification strategy. <em>SUPERC</em>, <em>81</em>(11), 1--51. (<a href='https://doi.org/10.1007/s11227-025-07678-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy partition clustering is a key unsupervised method that has attracted significant research interest. To better reveal the intrinsic relationships among data categories, researchers have recently introduced harmonic fuzzy partition clustering. However, its slow convergence speed limits its effectiveness for large-scale data processing. This paper proposes a modification strategy for harmonic fuzzy membership and develops a rapid harmonic fuzzy partition C-means clustering algorithm. Using the affinity filtering technique, we efficiently identify non-affinity clustering centers while minimizing computational costs. We then adjust the harmonic fuzzy membership degrees, enhancing those for affinity centers and resetting them for non-affinity centers. Our rapid harmonic fuzzy C-means algorithm significantly reduces convergence time by an average of 75% in iterations while maintaining excellent clustering performance and improving computational efficiency. This work advances harmonic fuzzy clustering theory and provides new support for data analysis and processing.},
  archive      = {J_SUPERC},
  author       = {Wu, Chengmao and Wang, Xiaomin},
  doi          = {10.1007/s11227-025-07678-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--51},
  shortjournal = {J. Supercomput.},
  title        = {An enhanced harmonic fuzzy partition clustering algorithm incorporating a novel membership modification strategy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring AI and quantum computing synergies in holographic counterpart frameworks for IoT security and privacy. <em>SUPERC</em>, <em>81</em>(11), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07682-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) ecosystem, expected to surpass 75 billion connected consumer electronics devices by 2025, is revolutionizing industries while simultaneously introducing major security and privacy challenges. This study presents a framework that integrates artificial intelligence (AI), quantum computing (QC), and holographic counterpart modeling to improve IoT security. The traditional security mechanisms are inadequate to the peculiarities of IoT networks, including heterogeneous consumer electronics devices, limited computing capabilities, and more advanced attack vectors. This current study presents a new interdisciplinary approach that will address these issues by combining AI, QC, and holographic counterpart consumer technology applications on an all-purpose framework. The AI layer uses more sophisticated machine learning models, such as long short-term memory networks, and has an anomaly detection accuracy of 90.55%, which is much higher than the traditional models. Additionally, the framework also showed how the false positive rate was reduced to a value of 5%, enhancing reliability. QC enables cryptographic robustness by utilizing quantum key distribution to ensure 100% security in the encryption of data in the prevention of quantum-era malicious hacks. Grover’s algorithm improves encrypted data analysis speed by approximately threefold compared to classical approaches. The holographic counter dimensions come with a rare prediction building block; digital replicas of IoT networks are built in a dynamic manner, thereby cutting down on the possible vulnerabilities by 40% and generic threat resolution by 35%. The framework has been proven scalable and flexible in a variety of IoT setups, as experimental results were demonstrated to support more than 1 million data points and reach 98% correct classification of multiple types of attacks, such as distributed denial-of-service and malware intrusions. The AI-QC-HCF framework enhances IoT security by integrating AI-based adaptive learning, quantum computational techniques, and predictive holographic modeling, thereby supporting a shift from reactive to proactive threat mitigation. This study provides a robust, scalable, and proactive security architecture, addressing critical vulnerabilities in IoT ecosystems while paving the way for integrating advanced computational paradigms to mitigate evolving cyber threats.},
  archive      = {J_SUPERC},
  author       = {Alzahrani, Abdullah I. A.},
  doi          = {10.1007/s11227-025-07682-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Exploring AI and quantum computing synergies in holographic counterpart frameworks for IoT security and privacy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-controlled single-qubit unitary gates based on the quantum fourier transform and deep decomposition. <em>SUPERC</em>, <em>81</em>(11), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07684-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We will present a few new generalizations of the multi-controlled X (MCX) gate that uses the quantum Fourier transform (QFT). Our focus is on implementations that don’t use ancilla qubits. Firstly, we will optimize QFT-MCX and prove that it is equivalent to a stair MCX gate array. This stair-wise structure will allow us to devise a method for adding an arbitrary phase factor to each qubit. The first MCX generalization into multi-controlled unitary gates (MCU) relies on replacing phase gates acting on the target qubit with controlled unitary gates. We will employ alternative single-qubit gate notation to minimize the complexities of these gates and show how to expand the circuit straightforwardly to the multi-controlled multi-target gate. The second generalization relies on the ZYZ-like decomposition. We will show that by extending one QFT-MCX circuit, we implement the two multi-controlled X gates needed for the decomposition. Finally, we will split control wirelines into groups and use iterative ZYZ-like decomposition on QFT-MCU to obtain a “deep decomposed” (DD) MCU which employs a lower number of C-NOTs than the previous two, thus making DD-MCU less prone to decoherence and noise. The supremacy of our implementations over the best-known optimized algorithm will be demonstrated by emulating noisy quantum calculations.},
  archive      = {J_SUPERC},
  author       = {Arsoski, Vladimir V.},
  doi          = {10.1007/s11227-025-07684-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Multi-controlled single-qubit unitary gates based on the quantum fourier transform and deep decomposition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance, portability, productivity, and security in HPC cloud: A systematic literature review. <em>SUPERC</em>, <em>81</em>(11), 1--68. (<a href='https://doi.org/10.1007/s11227-025-07685-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based high-performance computing (HPC) is reshaping the computational landscape by offering scalable, flexible, and cost-effective alternatives to traditional supercomputing infrastructures. Despite its growing influence across scientific and industrial domains, adoption remains limited by persistent challenges in four critical dimensions: performance, portability, productivity, and security. This study presents a systematic literature review (SLR) of peer-reviewed journal publications from 2018 to 2024, aimed at synthesizing recent advancements and identifying unresolved research gaps in cloud-based HPC. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a comprehensive literature search was conducted across the Scopus and Web of Science databases, yielding an initial pool of 77 studies. After rigorous screening and eligibility assessment, 51 high-quality articles were selected for in-depth analysis. The analysis reveals that intelligent workload scheduling, dynamic resource management strategies, and high-speed RDMA-enabled interconnects play a critical role in mitigating performance bottlenecks and enhancing scalability in cloud-based HPC. However, workload portability remains a major challenge due to architectural heterogeneity, proprietary APIs, and vendor lock-in. Recent efforts in multi-cloud orchestration, declarative provisioning, and platform-agnostic standards offer promising pathways to address these issues. Productivity enhancements are being driven by the integration of automated workflow tools, advanced decision-support systems, and user-friendly interfaces, which lower barriers for non-specialist users. In the security domain, advancements such as hardware-based trusted execution environments, robust encryption techniques, and fine-grained access control mechanisms are strengthening the protection of sensitive HPC workloads in shared cloud infrastructures. Despite these advancements, significant gaps persist. Key areas requiring further research include real-time performance tuning through autonomous optimization techniques, privacy-preserving computation frameworks, and the development of sustainable, energy-efficient HPC architectures. Addressing these challenges will require coordinated efforts across academia, industry stakeholders, and cloud service providers. This review offers a comprehensive, thematically organized synthesis of the current state-of-the-art and serves as a foundational resource for advancing secure, portable, and efficient cloud-based HPC.},
  archive      = {J_SUPERC},
  author       = {Kumar, Mandeep and Kaur, Gagandeep and Rana, Prashant Singh},
  doi          = {10.1007/s11227-025-07685-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--68},
  shortjournal = {J. Supercomput.},
  title        = {Performance, portability, productivity, and security in HPC cloud: A systematic literature review},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mink-GraSNet: Computationally efficient 6-DoF grasp detection for large-scale AI-powered robotics. <em>SUPERC</em>, <em>81</em>(11), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07702-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving precise and robust 6-DoF robotic grasping in complex, large-scale cluttered environments presents a significant computational challenge for AI-powered robotics. Processing high-resolution 3D point clouds for real-time grasp detection is often computationally demanding, hindered by methods that struggle with large data volumes and require high latency. To address these limitations and enable efficient, scalable 6-DoF grasp detection, we propose Mink-GraSNet, a novel end-to-end deep learning framework. Mink-GraSNet leverages graspness as a core guiding principle, combining sparse geometric-semantic feature fusion with an adapted efficient sparse convolutional backbone, MinkUNeXt. Crucially, we introduce SACA (Sparse Adaptive Channel Attention), an efficient module specifically designed for sparse tensors to enhance feature discriminability without sacrificing efficiency. This collaborative approach achieves a strong balance between powerful feature representation and high computational efficiency. Experimental results on the large-scale GraspNet-1Billion benchmark demonstrate state-of-the-art grasp detection accuracy. Furthermore, our method exhibits significantly faster inference speeds, showcasing its capability to efficiently handle substantial computational demands and suitability for high-performance robotic applications.},
  archive      = {J_SUPERC},
  author       = {Lyu, Yiyang and Li, Jiazhe and Wang, Aimin and Wang, Weiyi},
  doi          = {10.1007/s11227-025-07702-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {11},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Mink-GraSNet: Computationally efficient 6-DoF grasp detection for large-scale AI-powered robotics},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stage federated learning with group-wise bidirectional guidance. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07449-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed learning framework that enables multiple edge devices to collaboratively train models while preserving data privacy. However, in real-world applications, FL faces various challenges, such as data integrity issues, noisy data, and potential attacks, which can lead to erroneous model training and reduced performance. Previous methods primarily address label noise and attacks by adjusting weights or directly discarding clients that pose threats. However, these approaches often fail when the proportion of malicious clients is high or the noise level is severe. Moreover, simply removing clients contradicts the fundamental principle of FL, which encourages broad device participation. To address these challenges, we propose a novel framework, FedMBG, specifically designed to handle extreme noise and potential attacks in FL. FedMBG consists of two key stages: client selection and group optimization, which classifies and groups clients based on their updates, and inter-group personalization training and model optimization, which leverages information generated by malicious clients to guide other clients in enhancing model robustness, thereby mitigating the impact of noise and attacks. Experimental results demonstrate that FedMBG significantly improves model accuracy and robustness in extreme noise and high-attack environments, outperforming existing FL methods.},
  archive      = {J_SUPERC},
  author       = {Li, Xiaohui and Bian, Taicheng and Yang, Jin and Meng, Dehan and Lu, Yuhang and Jiang, Xi and Liang, Hongtao},
  doi          = {10.1007/s11227-025-07449-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Multi-stage federated learning with group-wise bidirectional guidance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preaftrack: Multi-object tracking based on adaptive feature matching from detection results. <em>SUPERC</em>, <em>81</em>(10), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07466-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most two-stage detection and tracking methods currently adopt IoU distance and appearance features when matching target detection results with trajectory predictions. However, this approach has shortcomings in two main aspects: 1. The selection of feature extraction networks often relies on established methods, such as ReID-related methods, which are typically complex and significantly slow down algorithm processing speed. 2. Feature extraction networks lack consistency when extracting single-frame features, leading to difficulties in matching incomplete objects with previous features when occlusions occur, resulting in incorrect updates of target identities. To address these limitations, we propose a lightweight feature extraction network that integrates current target features with historical data. This network enhances data processing speed while obtaining smooth object features with temporal coherence. To address feature granularity variations across targets, we employ adaptive feature matching approaches tailored to different detection conditions. This strategy maximizes information efficiency while conserving computational resources. An adaptive multifeature extraction method is also proposed to accommodate diverse requirements across different scenarios. The matching strategy developed allows the tracker to serve as a universal and practical solution for various tracking scenarios within a unified framework, eliminating the need for manual parameter tuning. The effectiveness of PreAFTrack is demonstrated through comprehensive evaluations on three major MOT datasets: MOT17, MOT20, and DanceTrack. Code is available at https://github.com/Flowercaty/PreAFTrack .},
  archive      = {J_SUPERC},
  author       = {Zhang, Mandun and Hou, Chenyue and Pang, Yonghui and Shi, Jiale and Zhang, Yiqi and Huang, Xiangsheng},
  doi          = {10.1007/s11227-025-07466-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Preaftrack: Multi-object tracking based on adaptive feature matching from detection results},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saffe: Multimodal model composition with semantic-alignment fusion of frozen encoders. <em>SUPERC</em>, <em>81</em>(10), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07473-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based multimodal models often require expensive, full-model training on task-specific all-modality datasets to achieve high accuracy on targeted downstream tasks. To reduce this significant cost, we introduce SAFFE, a methodology for building accurate, task-specific multimodal models with minimal training, using only standard GPU hardware. SAFFE leverages off-the-shelf, pre-trained, frozen unimodal encoders for each input modality (e.g., text, image, or audio) and connects them through a lightweight, trainable component called the FusionAlign Module (FAM). FAM is a bottleneck mid-fusion neural network, trained on the target dataset to align the outputs of the independently pre-trained unimodal encoders. This approach eliminates the need for end-to-end training while maintaining strong accuracy for the downstream task. As a proof of concept, we validate SAFFE on image retrieval and language understanding tasks. SAFFE-derived models outperform state-of-the-art multimodal systems on datasets such as CIFAR-10, ImageNet-100, and COCO, achieving competitive results with significantly fewer trainable parameters and training time.},
  archive      = {J_SUPERC},
  author       = {Kulasekara, Maithri and Inglés-Romero, Juan F. and Imbernón, Baldomero and Abellán, José L.},
  doi          = {10.1007/s11227-025-07473-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Saffe: Multimodal model composition with semantic-alignment fusion of frozen encoders},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient load balancing in cloud computing using hybrid ant colony optimization and crow search strategies. <em>SUPERC</em>, <em>81</em>(10), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07550-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of cloud services and the increasing reliance on them have made load balancing a significant research challenge. As technological services grow in demand, optimizing their performance becomes essential. This study addresses the load-balancing challenge by mathematically formulating the problem within cloud computing systems, where an objective function is developed to minimize response time, computational cost, and load imbalance, while ensuring constraints such as task allocation to individual virtual machines (VMs) and adherence to resource limits. To solve this problem, we propose a novel hybrid algorithm, ACOCSA, which combines ant colony optimization (ACO) and crow search algorithm (CSA). Our experimental results indicate substantial performance improvements. Specifically, ACOCSA reduces response time by 12% compared to ACO, achieving a reduction from 8.5 to 7.48 s for 400 tasks. Additionally, it demonstrates a 5% improvement over GIJA, with response times of 8.20 s compared to 8.62 s. ACOCSA also completes tasks 33.3% faster than ACO, reducing task completion time from 450 to 300 s for 100 tasks, and 7.8% faster than GIJA, which requires 324 s. The average cost is reduced by 12.5% when compared to CSA, with a cost of 0.11 versus 0.125 for 10 tasks. Furthermore, ACOCSA achieves a 3.5-point increase in fairness index, from 86 to 89.5, across 100 iterations, indicating improved load distribution and balanced VM utilization. These findings demonstrate that ACOCSA outperforms existing algorithms in terms of response time, cost, and fairness of load distribution. Statistical analyses confirm that ACOCSA consistently achieves superior load balancing efficiency, ranking first among other methods, with a top mean rank of 1.00 in the Friedman test ( $${ p}\,\hbox {value}\,<\,0.000047$$ ). Although further empirical validation is needed to explore its energy-saving potential, the results emphasize ACOCSA’s suitability for real-world dynamic cloud environments.},
  archive      = {J_SUPERC},
  author       = {Alsheavi, Amar N. and Alhusaini, Naji and Wang, Xingfu and Farhan, Shaima and Aziz, Samah Abdel and Ahmed, Ibrahim Abdulrab and Khalid, Ahmed and Alwazer, Salwa Mutahar and Saif, Jamil A. M. and Al-Kubati, Ali A. M. and Alsalihi, Adnan K. and Ismail, A. S.},
  doi          = {10.1007/s11227-025-07550-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Efficient load balancing in cloud computing using hybrid ant colony optimization and crow search strategies},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single multi-task deep neural network with a multi-scale feature aggregation mechanism for manipulation relationship reasoning in robotic grasping. <em>SUPERC</em>, <em>81</em>(10), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07553-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In stacked object scenes, effectively perceiving the positional relationships between objects is crucial for enabling robots to grasp safely. To further improve the robot’s ability to understand these positional relationships, this paper proposes a multi-task grasping detection model for stacking object scenes, based on multi-scale feature fusion. We design a multi-scale feature aggregation (MSFA) module to fuse features, enhancing the feature maps’ ability to represent objects of varying sizes. Additionally, we leverage features from multiple views to predict object positional relationships. In particular, the local intersection region feature (IRF) significantly enhances the model’s capability to identify positional relationships between objects while improving computational efficiency. Experimental results on the Visual Manipulation Relationship Dataset (VMRD) demonstrate that our model surpasses current state-of-the-art methods. Furthermore, we conducted grasping experiments in real-world stacking scenarios, which verified the model’s effectiveness and generalization capability.},
  archive      = {J_SUPERC},
  author       = {Dong, Mingshuai and Bai, Yuxuan and Yu, Xiuli},
  doi          = {10.1007/s11227-025-07553-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {A single multi-task deep neural network with a multi-scale feature aggregation mechanism for manipulation relationship reasoning in robotic grasping},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving cloud resource management: An ensemble learning approach for workload prediction. <em>SUPERC</em>, <em>81</em>(10), 1--54. (<a href='https://doi.org/10.1007/s11227-025-07560-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building an effective cloud workload prediction system is challenging due to the complex and dynamic nature of cloud computing environments. Accurate prediction of resource utilization, such as CPU and memory loads, is crucial for efficient resource provisioning and management. High-performance machine learning models are needed for cloud workload prediction, as the workloads can exhibit diverse patterns and changes over time. This study proposes a unique ensemble framework that can effectively predict different aspects of cloud workloads. The proposed approach is based on building an ensemble learning-based models, such as XGBoost and LightGBM, to predict CPU and memory utilization in the cloud computing environment. Specifically, a two-stage model was developed, where the first stage predicts the workload status and the second stage predicts the actual CPU and memory usage based on the predicted status. Hyperparameter tuning is employed to optimize the performance of the ensemble models. The results of the proposed approach demonstrate its effectiveness in cloud workload prediction. For CPU utilization, the XGBoost model achieves an R-squared value of 0.97967, which is 25.78% better than the ARIMA baseline. Similarly, for memory utilization, the LightGBM model achieves an R-squared value of 0.949. These results highlight the superiority of the proposed ensemble framework over traditional approaches, enabling more accurate and reliable cloud resource provisioning and management.},
  archive      = {J_SUPERC},
  author       = {Bawa, Jyoti and Kaur Chahal, Kuljit and Kaur, Kamaljit},
  doi          = {10.1007/s11227-025-07560-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--54},
  shortjournal = {J. Supercomput.},
  title        = {Improving cloud resource management: An ensemble learning approach for workload prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biclustering in bioinformatics using big data and high performance computing applications: Challenges and perspectives, a review. <em>SUPERC</em>, <em>81</em>(10), 1--52. (<a href='https://doi.org/10.1007/s11227-025-07563-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biclustering is a powerful machine learning technique that simultaneously groups rows and columns in matrix-based datasets. Applied to gene expression data in bioinformatics, its use has expanded alongside the rapid growth of high-throughput sequencing technologies, leading to massive and complex biological datasets. This review aims to examine how biclustering methods and their validation strategies are evolving to meet the demands of High Performance Computing (HPC) and Big Data environments. We present a structured classification of existing approaches based on the computational paradigms they employ, including MPI/OpenMP, Apache Hadoop/Spark, and GPU/CUDA. By synthesising these developments, we highlight current trends and outline key research challenges. The knowledge gathered in this work may support researchers in adapting and scaling biclustering algorithms to analyse large-scale biomedical data more efficiently. Our contribution is intended to bridge the gap between algorithmic innovation and computational scalability in the context of bioinformatics and data-intensive applications.},
  archive      = {J_SUPERC},
  author       = {López-Fernández, Aurelio and Gomez-Vela, Francisco A. and Rodriguez-Baena, Domingo S. and Delgado-Chaves, Fernando M. and Gonzalez-Dominguez, Jorge},
  doi          = {10.1007/s11227-025-07563-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--52},
  shortjournal = {J. Supercomput.},
  title        = {Biclustering in bioinformatics using big data and high performance computing applications: Challenges and perspectives, a review},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy improved snake optimizer for library robot path planning problems. <em>SUPERC</em>, <em>81</em>(10), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07570-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study offers a multi-strategy improved snake optimizer (MISO) and applies it to library robot path planning in order to solve the limitations of the conventional snake optimizer, including slow convergence, low solution accuracy, and susceptibility to local optima in complex optimization problems. Firstly, the tent mapping has been used to initialize the population and enhance randomness and diversity, thereby enhancing global optimization capabilities. Secondly, a dynamic inertia weight factor is combined with Lévy flight to optimize the search performance in the exploration phase and balance global search and local exploitation. Thirdly, the centroid opposition-based learning has been used to update individual positions and maintain diversity. The performance of MISO was evaluated using the CEC 2005 benchmark test function set. Results show that MISO significantly outperforms ten comparative algorithms in most cases on the 23 test functions. Ablation experiments show the effectiveness of the three strategies. In the application of library robot path planning, three complex environments were designed to test MISO’s practicality. The results show that MISO’s average path length was reduced significantly compared to comparative algorithms, with a target search accuracy rate of over 97%, significantly superior to comparative algorithms. The paper demonstrates that MISO provides a novel technical solution for efficient and safe path planning of robots in smart libraries, and its multi-strategy fusion concept can offer references for other complex optimization problems.},
  archive      = {J_SUPERC},
  author       = {Xue, Yige},
  doi          = {10.1007/s11227-025-07570-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Multi-strategy improved snake optimizer for library robot path planning problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSA–HAR: Multi-scale segmented attention networks for human activity recognition using sensor signals. <em>SUPERC</em>, <em>81</em>(10), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07576-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks have emerged as a dominant approach in sensor-based human activity recognition (HAR) due to the powerful feature representation capabilities for multimodal time series data, which has become a research hotspot in the field of mobile computing. The attention mechanism is well-known for its potential to enhance activity recognition performance by emphasizing critical temporal sequences and noteworthy sensor modalities. However, existing research primarily focuses on developing deeper or more intricate convolutional attention networks, which inevitably incurs a significant increase in computational complexity. To address these concerns above, we propose a lightweight multi-scale Segmentation Attention called MSA method tailored for sensor-based HAR scenarios. MSA leverages a segmentation structure to extract a channel vector that encapsulates multi-scale information and employs one-dimensional convolution to facilitate cross-channel interaction while substantially reducing model complexity. We evaluate the proposed model on several publicly available HAR datasets, including WISDM, UCI–HAR, PAMAP2, and UniMib–SHAR. The experimental results demonstrate that our method significantly reduces the number of parameters compared to baseline models, while outperforming recently published results under identical configurations. Furthermore, extensive ablation studies are conducted to explore the impact of different group sizes on classification performance. The codes and models will be released at https://github.com/qwm1/decon .},
  archive      = {J_SUPERC},
  author       = {Quan, Weiming and Tang, Yin and Luo, Wei and Zhang, Lei},
  doi          = {10.1007/s11227-025-07576-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {MSA–HAR: Multi-scale segmented attention networks for human activity recognition using sensor signals},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SBEW-YOLOV8: A small object detection algorithm for autonomous driving based on multi-scale feature fusion. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07577-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a critical component of environmental perception in advanced driver assistance systems (ADAS). Despite the rapid development of object detection algorithms, significant challenges remain in practical applications for small objects (such as people, bicycles, and traffic signs). These challenges include occlusion, low resolution, multi-scale targets, and complex dynamic scenes. To address these issues, this paper proposes a novel small object detection algorithm called SBEW-YOLOv8. Firstly, the backbone network incorporates Space-to-Depth Convolution (SPDConv), which is suitable for low-resolution images and small object detection. This technique preserves discriminative feature information and enhances the perception of small objects. Secondly, an efficient multi-scale feature fusion structure, small object bidirectional feature pyramid network (SO-BiFPN), is designed in the neck network to enhance the information exchange between feature layers of different scales. Additionally, efficient multi-scale attention (EMA) is employed to highlight target features and suppress background interference. Finally, the wise intersection over union (WIoU) loss function with adaptive weight adjustment is used to improve the robustness of detection and the regression performance of bounding boxes. This algorithm was tested in various autonomous driving scenarios, including traffic light intersections, rural open roads, curved intersections, and low-light intersections. On the publicly available SODA-D dataset, the average precision for small object detection reached 34.8%, an improvement of 4.6% compared to the baseline model YOLOv8. The results demonstrate that SBEW-YOLOv8 significantly enhances the model’s ability to detect small objects.},
  archive      = {J_SUPERC},
  author       = {Yin, Chunfang and Wang, Zihan and Li, Yicheng and Sun, Kecheng and Wang, Shaohua and Guo, Yuhao},
  doi          = {10.1007/s11227-025-07577-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {SBEW-YOLOV8: A small object detection algorithm for autonomous driving based on multi-scale feature fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating graph robustness through the kirchhoff index and sampling techniques. <em>SUPERC</em>, <em>81</em>(10), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07578-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph robustness is a measure of graph’s ability to maintain connectivity and other graph properties with node or edge failures and is widely used in a variety of complex networks. Supercomputing relies on massive parallel architectures to handle complex network simulations, and distributed-memory systems enhance robustness by isolating node failures. Therefore, estimating graph or complex network robustness is quite important in supercomputing. The Kirchhoff index can be used to evaluate graph robustness, but faces the problem of excessive computational complexity when dealing with large-scale graphs. To improve the efficiency and accuracy of robustness estimation based on Kirchhoff index, in this paper, we propose the Semi-Random Degree-Preferred (SRDP) algorithm, which dynamically adjusts its sampling strategy by combining random sampling with degree-prioritized sampling. Verified by a series of experiments, SRDP shows good performance in classical graphs, random graphs and real-world networks. We also explore the estimation of Kirchhoff index through the downtrend and propose the double sampling method for the robustness evaluation of real-world networks. Experimental results show that SRDP has good applicability to different types and sizes of graphs and networks.},
  archive      = {J_SUPERC},
  author       = {Huang, Xingbin and Chen, Rui and He, Weihua},
  doi          = {10.1007/s11227-025-07578-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Estimating graph robustness through the kirchhoff index and sampling techniques},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy adaptive cultural algorithm for scheduling high-dimensional reentrant hybrid flowshops with incompatible job families. <em>SUPERC</em>, <em>81</em>(10), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07581-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the inherent complexity of scheduling large-scale, high-mix, low-volume orders, this paper formulates a high-dimensional reentrant hybrid flowshop scheduling problem with incompatible job families (HRHFSP-IJF). The proposed model is tailored to satisfy multi-objective engineering requirements from both service and production perspectives. Given the NP-hard nature of HRHFSP-IJF, a multi-strategy adaptive cultural algorithm (MSACA) is developed. This algorithm leverages three strategy pools—multi-heuristic decoding, multi-level group interaction, and success–failure memory in the belief space-to guide population initialization, global search, and local search. First, four decoding strategies are designed to manage priority rules, machine assignments, idle area insertions, and job sequencing for both initialization and iterative updating. Second, interactive individuals are chosen based on non-dominated ranks and Hamming distance, with knowledge transfer facilitating effective cultural interactions. Third, the algorithm employs a dominance-based measure of success/failure and probability learning to adaptively choose variable neighborhood search operators, thereby enhancing the local exploitation of the population. Scheduling experiments on various scales demonstrate that MSACA outperforms several competitive algorithms in terms of convergence, diversity, and dominance, offering a viable solution framework for HRHFSP-IJF.},
  archive      = {J_SUPERC},
  author       = {Wu, Jiawei and Liu, Yong},
  doi          = {10.1007/s11227-025-07581-4},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {A multi-strategy adaptive cultural algorithm for scheduling high-dimensional reentrant hybrid flowshops with incompatible job families},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-based multimodal adaptive fusion for emotion recognition in conversation. <em>SUPERC</em>, <em>81</em>(10), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07584-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in conversation (ERC) aims to identify and understand emotional expressions in conversation, which plays an important role in improving the human–computer interaction experience. How to effectively model both the speaker and conversational context remains a significant challenge in ERC. Existing approaches has primarily focused on graph-based methods to address this issue. Graph neural network (GNN) has shown remarkable effectiveness in capturing relational information within data. However, they typically capture only pairwise relationships, restricting GNN-based methods in handling higher-order semantics and complex multimodal interactions within conversational contexts. In this paper, we propose a hypergraph-based multimodal adaptive fusion method for ERC. We construct three intra-modal hypergraphs for textual modality, visual modality, and acoustic modality in conversational utterances, and introduce contextual hyperedges and speaker self-dependency hyperedges into them. From the two perspectives of conversational context utterances dependence and speaker emotional dependence, the model can more comprehensively understand the emotional information in the conversation. Meanwhile, we construct an inter-modal hypergraph to capture the interactions between different modalities. Additionally, considering the differences in representation capabilities of different modalities, we employ an attention-based gated neural network to fuse the hypergraph information after hypergraph aggregation, in order to reduce redundancy and noise during the cross-modal fusion process. Experimental results on two public datasets verify the superiority of the proposed approach over state-of-the-art approaches.},
  archive      = {J_SUPERC},
  author       = {Xie, Xintong and Ma, Tinghuai and Jia, Li and Rong, Huan},
  doi          = {10.1007/s11227-025-07584-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Hypergraph-based multimodal adaptive fusion for emotion recognition in conversation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep autoencoder-enhanced multi-objective evolutionary algorithm for recommender systems. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07589-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a pivotal role in enhancing user experiences by personalizing content suggestions to individual preferences. However, conventional systems predominantly focus on accuracy, often at the expense of variety and novelty, which are crucial for maintaining user engagement and satisfaction. While widely used, traditional methods like collaborative filtering struggle with challenges such as high dimensionality and data sparsity, limiting their effectiveness. Advances in deep learning have addressed some of these issues, making it a valuable tool for enhancing recommendation techniques. In this paper, we introduce Resc-Auto-MOEA/D, a novel hybrid recommendation model that integrates an autoencoder with a multi-objective evolutionary algorithm (MOEA/D) to optimize recommendations across accuracy, novelty, serendipity, and retention. By decomposing the optimization problem into subproblems and evolving solutions in parallel, our approach achieves a fine-grained balance between personalization and exploration. Experimental evaluations on benchmark datasets demonstrate that Resc-Auto-MOEA/D significantly outperforms existing baselines in both relevance and engagement metrics. The results highlight the model’s ability to adapt to varying user behaviors and data distributions, confirming its effectiveness in generating diverse, surprising, and retention-promoting recommendations. This work contributes a scalable and principled framework for advancing multi-objective personalization in real-world recommendation environments.},
  archive      = {J_SUPERC},
  author       = {Zaizi, Fatima Ezzahra and Qassimi, Sara and Rakrak, Said},
  doi          = {10.1007/s11227-025-07589-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {A deep autoencoder-enhanced multi-objective evolutionary algorithm for recommender systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Star-transformer based semantic enhanced union relation extraction. <em>SUPERC</em>, <em>81</em>(10), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07591-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is a crucial task in natural language processing and knowledge graph construction. However, existing methods often suffer from three major limitations: (1) they overlook the intrinsic semantic associations between subjects and objects; (2) they have limited generalization in long-text scenarios; and (3) their resource consumption grows rapidly with sentence length due to matrix-based tagging strategies. To address the issues, we propose ST-ICRE (star-transformer intrinsic correlation relation extraction), a novel relation extraction model that leverages the intrinsic correlations between subjects and objects. The model effectively captures the associations between the subject and the object by adopting the relay node and satellite node interaction mechanism within the star-transformer structure, thereby improving the sentence’s semantic representation. Moreover, to mitigate the resource consumption of the conventional “filling-the-form” approach, we introduce an entity tagging method with linear-level complexity. The experimental results on both Chinese and English datasets (DuIE2.0, CMeIE, SciERC, FinRED) demonstrate that ST-ICRE outperforms strong baseline models, achieving F1-score improvements of 4.4% on DuIE2.0 and 11.4% on SciERC. Notably, ST-ICRE shows significant performance in handling complex scenarios with overlapping entity relationships.},
  archive      = {J_SUPERC},
  author       = {Hu, Feng and Pei, Wei and Wu, Yirong and Hu, Qin and Wang, Ben and Sun, Shuifa},
  doi          = {10.1007/s11227-025-07591-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Star-transformer based semantic enhanced union relation extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGFT: Hybrid geometric feature transformer for point cloud registration. <em>SUPERC</em>, <em>81</em>(10), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07592-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud registration is a core task in 3D computer vision, aiming to align two point clouds by estimating rigid transformations (rotation and translation). However, existing methods still face challenges in dealing with rotation sensitivity, local feature ambiguity, and mismatches in symmetric regions. This paper presents a novel Hybrid Geometric Feature Transformer (HGFT) that integrates equivariant geometric features with global rotation-invariant features, achieving high-precision and robust point cloud registration. Specifically, HGFT consists of three core modules: 1) an Equivariant Center Point Geometric Attention Mechanism (CGAM), which leverages neighborhood geometric triplets and positional embeddings to extract rotation-sensitive local features; 2) a Geometric Gated Dynamic Fusion Mechanism (GGDF), which adaptively fuses local equivariant features with global Point Pair Features (PPF) rotation-invariant features; and 3) a Symmetry-Aware Attention Mechanism (SAGA), which suppresses mismatches by dynamically penalizing attention weights in symmetric regions. Additionally, a Maximum Clique Transformation Evaluator (MTE) is proposed, which uses geometric consistency constraints to filter high-confidence point correspondences, further enhancing the robustness of transformation estimation. Experimental results indicate that HGFT significantly outperforms existing methods on multiple public datasets, demonstrating particularly strong generalization under noisy conditions, partial overlap, and highly symmetric scenes. It achieves Registration Recall (RR) scores of 95.2% and 78.3% on the 3DMatch and 3DLoMatch benchmarks, respectively.},
  archive      = {J_SUPERC},
  author       = {Lu, Yun-Jun and Xie, Xiao-Yao and Xu, Ming-Qiang and Liu, Song},
  doi          = {10.1007/s11227-025-07592-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {HGFT: Hybrid geometric feature transformer for point cloud registration},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing real-time low-light object detection via multi-scale edge and illumination-guided features in YOLOv8. <em>SUPERC</em>, <em>81</em>(10), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07594-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant impact of low-light environments on target detection performance has become a key issue in computer vision. Limited by factors such as image feature degradation, noise interference and contrast reduction, conventional detectors’ performance degrades dramatically under low-light conditions. Existing solutions usually decouple image enhancement and target detection as independent tasks, yet this paradigm struggles to achieve stable detection in complex low-light environments. Therefore, this paper proposes a feature-aware detection framework integrating multi-scale edge enhancement and light-guided attention mechanisms, built on YOLOv8 with three key modules: the multi-scale edge enhancement module (MEEM) for enhancing edge features in low-contrast scenes, the light-guided attention module (IGAB) for achieving regionally adaptive feature modulation, and the partial convolution module (PConv) for optimizing computational efficiency. Unlike traditional methods using image enhancement as preprocessing, the proposed framework integrates enhancement directly into feature extraction, enabling adaptive learning of low-light scene representations. Experimental results show our method achieves 49.7% mean average precision (mAP) on the ExDark dataset, exceeding YOLOv8 baseline by 6.0%. Additionally, the proposed method demonstrates superior detection robustness across complex low-light scenes at 170.3 FPS, providing efficient and reliable support for visual perception systems in real low-light environments.},
  archive      = {J_SUPERC},
  author       = {Gong, Boao and Zhang, Haoran and Ma, Bohan and Tao, Zhiyong},
  doi          = {10.1007/s11227-025-07594-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing real-time low-light object detection via multi-scale edge and illumination-guided features in YOLOv8},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving load balancing in distributed software-defined networks with a bidirectional long short-term memory-based controller design. <em>SUPERC</em>, <em>81</em>(10), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07595-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networks (SDNs) improve network flexibility and dynamic management by separating the control and data layers. However, the centralized nature of this architecture has generated challenges with load balancing among controllers. Improper load distribution can increase response time, reduce network efficiency, and elevate processing overhead. This study presents a new SDN controller design that improves load balancing in these networks. The suggested controller structure contains four key layers: data gathering, analysis and prediction, decision-making, and execution and control. In this architecture, the analysis and prediction layer uses a bidirectional long short-term memory-based prediction module that can improve future load prediction accuracy through future–past and past–future analyses. Simulation findings in the OMNeT++ environment show that this methodology significantly outperforms network performance compared to earlier methods. An average of 30.9% reduction occurred in response time, and processing overhead was improved by 5.34%. Furthermore, load distribution between controllers was improved by an average of 6.26%. These results show that the proposed strategy is highly effective in improving load balancing and enhancing the efficiency of SDNs.},
  archive      = {J_SUPERC},
  author       = {Shirani, Leila and Movahednejad, Homa and Sharifi, Mahdi and Mahmoudi, Marjan},
  doi          = {10.1007/s11227-025-07595-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Improving load balancing in distributed software-defined networks with a bidirectional long short-term memory-based controller design},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHA: Balanced artificial hummingbird algorithm and its application to space industry. <em>SUPERC</em>, <em>81</em>(10), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07596-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Artificial Hummingbird Algorithm (AHA) is a nature-inspired metaheuristic that mimics the exceptional flight behaviors of hummingbirds. Despite its promise, AHA often suffers from premature convergence and weak exploration. To overcome these issues, we propose the Balanced Artificial Hummingbird Algorithm (BAHA), which incorporates ten well-known chaotic maps into the behavioral switching mechanism of AHA. This integration introduces a dynamic trade-off between exploration and exploitation, enhancing both search efficiency and solution quality. BAHA is rigorously tested on 21 benchmark functions, three engineering design problems, and seven complex space trajectory optimization tasks from the European Space Agency (ESA). Comparative analysis shows that BAHA consistently outperforms or matches ten state-of-the-art algorithms, with the BAHA-v6 variant achieving the highest overall rank in Friedman statistical tests. These results underline the method’s robustness, adaptability, and effectiveness across diverse problem domains. Moreover, BAHA’s population-based and modular design makes it naturally compatible with parallel implementation on high-performance computing (HPC) platforms, especially for large-scale aerospace applications.},
  archive      = {J_SUPERC},
  author       = {Atlı, Zafer and Turkoglu, Bahaeddin},
  doi          = {10.1007/s11227-025-07596-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {BAHA: Balanced artificial hummingbird algorithm and its application to space industry},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attentional fusion-based method for coal-gangue recognition in noisy environment of generalised workface. <em>SUPERC</em>, <em>81</em>(10), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07597-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate coal-gangue identification techniques are essential for intelligent integrated mining and improved coal quality. However, existing methods are susceptible to high dust, noise, and other disturbances, resulting in unstable recognition results that cannot meet the demands of industrial applications. To address these challenges, this paper proposes a coal-gangue recognition method based on the fusion of a multi-scale parallel MCNN-BITCN network with an attention mechanism and the Improved Sparrow Search Algorithm (ISSA). The method combines a bidirectional spatio-temporal convolutional network (BITCN) with a multi-branch convolutional neural network (MCNN) to deeply mine and expand the extracted features. The time-frequency features are then fused through a cross-attention mechanism and fed into a fully connected layer. An improved sparrow search algorithm (ISSA) is used to generate the input weights and biases of the hidden layer nodes. This paper constructs an experimental platform to simulate the impact of coal-gangue on the tail beam of hydraulic support and conducts several comparative experiments. Results show that the MCNN-BITCN model maintains 83.76% accuracy even in high noise environments with a signal-to-noise ratio (SNR) of -5dB. After ISSA optimization, the model’s accuracy improves to 87.69%. These findings highlight the effectiveness and robustness of the proposed ISSA-MCNN-BITCN model under complex noise conditions.},
  archive      = {J_SUPERC},
  author       = {Song, Qingjun and Sun, Shirong and Song, Qinghui and Jiang, Xinrui and Jiang, Haiyan and Lu, Lina},
  doi          = {10.1007/s11227-025-07597-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {An attentional fusion-based method for coal-gangue recognition in noisy environment of generalised workface},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamical analysis and bifurcation exploration in a biological model with neural network forecasting. <em>SUPERC</em>, <em>81</em>(10), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07599-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the dynamics of infectious diseases requires sophisticated modeling approaches that can account for various demographic and epidemiological factors. This study explores a biological disease model incorporating four population classes: susceptible adults, susceptible children, infected adults, and infected children. To analyze the system, we employ equilibrium analysis and bifurcation theory, uncovering both co-dimension-one (Fold, Hopf) and co-dimension-two (Bautin, Fold-Hopf, Bogdanov–Takens, and Cusp) bifurcations, including several degenerate cases. Dynamical tools such as Lyapunov exponents, bifurcation diagrams, Poincaré sections, and phase space reconstruction characterize chaotic and hyper-chaotic behavior. We identify hidden attractors, suggesting multi-stability and complex transitions that may evade traditional stability analysis. Long short-term memory (LSTM) neural networks are implemented to forecast the temporal evolution of the system and demonstrate high predictive accuracy with low error rates. These findings illustrate the power of combining mathematical modeling with machine learning to enhance our understanding of disease spread. The integration of bifurcation theory and LSTM-based forecasting provides a comprehensive framework for anticipating dynamic shifts in epidemiological systems and supports the development of data-driven public health interventions.},
  archive      = {J_SUPERC},
  author       = {Akhtar, Muhammad Waseem and Bashir, Zia and Malik, M. G. Abbas},
  doi          = {10.1007/s11227-025-07599-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {Dynamical analysis and bifurcation exploration in a biological model with neural network forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Activation function design based on schwarz lemma for neural networks. <em>SUPERC</em>, <em>81</em>(10), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07606-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation functions (AFs) in artificial neural networks (ANNs) significantly affect system performance. In this study, a new complex AF obtained using Schwarz lemma is proposed. As a result, three theorems for analytical functions have been proposed by evaluating distinct variants of the boundary Schwarz lemma, and AFs have been generated using these theorems. Obtained AF is an intuitive result of the considered problem. The performance of the proposed AF is extensively evaluated through classification and regression problems on both real and complex-valued datasets and compared with commonly used functions such as sigmoid, tanh, arcsinh, zReLU, swish and gelu. Experimental results show that the proposed function is highly competitive, especially for complex-valued problems. As the network complexity increases, it maintains a stable performance profile and produces stable and reliable results in both training and testing phases. With these features, the proposed function stands out as a powerful and practical alternative, especially for complex neural network applications, based on a theoretical foundation rather than an arbitrary choice. Results from experiments indicate that the proposed function can be used in ANNs successfully.},
  archive      = {J_SUPERC},
  author       = {Örnek, Bülent Nafi and Oral, Canan and Bergil, Erhan and Dirik, Süleyman},
  doi          = {10.1007/s11227-025-07606-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Activation function design based on schwarz lemma for neural networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain-adaptive sentiment analysis method integrating attentional mechanisms and adversarial training. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07608-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-adaptive sentiment analysis utilizes the source domain to annotate the target domain. Using Bidirectional Encoder Representations from Transformers (BERT) directly and its extended models cannot well solve the challenges in feature selection and sample selection bias in the domain faced by the inter-domain transfer model, resulting in poor inference performance. Therefore, this paper proposes a domain-adaptive sentiment analysis method (Incorporating Attention Mechanisms and Adversarial Training, IAMT) that integrates an attention mechanism with adversarial training. Firstly, by incorporating both the dual-axis and multi-head attention, we construct a model capable of capturing local features while addressing cross-domain global dependencies, alleviating the problem of inter-domain feature selection. Secondly, adversarial training is employed to dynamically adjust sample weights in the source domain, mitigating the issue of sample selection bias. Experiments on SemEval and Twitter datasets show the method achieves a 16.31% improvement over the baseline model’s mean macro F1 score and a 0.0156 decrease in maximum mean discrepancy (MMD).},
  archive      = {J_SUPERC},
  author       = {Xu, Fei and Ye, LinXuan},
  doi          = {10.1007/s11227-025-07608-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {A domain-adaptive sentiment analysis method integrating attentional mechanisms and adversarial training},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multivariate filter feature selection and stacking-based ensemble learning algorithm for network intrusion detection. <em>SUPERC</em>, <em>81</em>(10), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07609-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the rapid growth of cyber threats and the increasing vulnerabilities of networked systems, ensuring their security has become one of the fundamental challenges. An intrusion detection system (IDS) plays a crucial role in protecting network data from misuse and suspicious activities by identifying malicious actions based on pre-defined patterns. However, traditional IDS models, which were primarily based on singular algorithms, have not been able to fully meet the expectations and still need further improvements. Many existing approaches have attempted to improve detection accuracy by employing a large number of models. While this has led to high accuracies, it has also increased system complexity and computational cost. Furthermore, high false-positive rates (FPRs) remain a significant issue, reducing the reliability of these models. Additionally, the presence of irrelevant and redundant features in datasets complicates the classification process. To address these challenges, this paper proposes a more efficient approach using the CICIDS2017 dataset. First, essential preprocessing steps, including data balancing and min–max normalization, are applied to improve data quality. Then, the mRMR (minimum redundancy maximum relevance) filter method is used to remove redundant and irrelevant features while selecting the most relevant ones. Finally, a stacking ensemble classification model is implemented, combining k-nearest neighbors (kNNs), decision tree (DT), and neural network (NN) as base learners, with random forest (RF) as the meta-learner, to enhance intrusion detection performance while maintaining a balance between accuracy and computational efficiency. Experimental results demonstrate that the proposed model outperformed singular algorithms by achieving an accuracy of 99.79%, while also reducing the false-positive rate (FPR) to 0.0002, which is significant. By effectively analyzing network traffic data, this approach enhances both detection accuracy and reliability, offering a promising direction for improving IDS.},
  archive      = {J_SUPERC},
  author       = {Hashemi Jouybari, Seyedeh Maryam and Janbaz, Alireza and Esfandiari, Ahmad},
  doi          = {10.1007/s11227-025-07609-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A multivariate filter feature selection and stacking-based ensemble learning algorithm for network intrusion detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing performance and energy efficiency: The method for sustainable deep learning. <em>SUPERC</em>, <em>81</em>(10), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07610-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing sophistication and resource-intensive nature of deep learning algorithms, especially in the realm of computer vision, have raised significant ecological concerns owing to the high energy demands involved in model training. To address this, we propose the efficient adaptive transformation learning with augmentation framework, which is specifically designed to enhance sustainability within deep learning pipelines. The framework incorporates ongoing power consumption tracking throughout the training process to responsively calibrate the strength of data augmentation and to selectively update layers depending on real-time feedback from both energy and model performance. This adaptive mechanism enables a well-regulated compromise between power efficiency, model precision, and training duration. The framework undergoes extensive benchmarking on three diverse datasets–CIFAR-10, ImageNet, and a tailored satellite imagery corpus–utilizing both legacy convolutional models (ResNet, VGG) and contemporary scalable backbones (ViT-B/16, ConvNeXt-T). EATL-A achieves top-tier accuracy scores of 94.5%, 88.8%, and 90.6%, respectively, surpassing current energy-aware benchmarks like PINN-DT, ssProp, and $$\hbox {TinyM}^{2}$$ Net-V3 across both performance and F1-score. It further reduces energy consumption by up to 27% and shortens training time by up to 40% relative to standard transfer learning. Additionally, by translating energy metrics into carbon-equivalent emissions, EATL-A is shown to yield the lowest $$\hbox {CO}_{2}$$ output, up to 4.6 mg less than the next-best alternative on CIFAR-10. These results underscore EATL-A’s scalability, robustness, and environmental relevance, offering a practical and generalizable framework for sustainable AI across both cloud-based and edge computing platforms.},
  archive      = {J_SUPERC},
  author       = {Dwivedi, Pulkit and Islam, Benazir},
  doi          = {10.1007/s11227-025-07610-2},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Balancing performance and energy efficiency: The method for sustainable deep learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient path coverage-based test data generation using an enhanced pelican algorithm. <em>SUPERC</em>, <em>81</em>(10), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07611-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White-box test data generation typically relies on an optimized search through the program input space. Metaheuristic algorithms, such as genetic algorithms, particle swarm optimization, and simulated annealing, are commonly utilized to address this problem. However, it is observed that existing algorithms often fall short in generating diverse test data. Their primary focus is identifying the optimal solution rather than a diverse set of reasonable solutions. This paper aims to address the issue of limited diversity in test data generation by proposing a modified version of the pelican optimization algorithm (POA). The goal is to improve coverage and reduce the fitness evaluations required for generating test data. This study tackles the challenge of minimizing test data volume while achieving high coverage, a significant concern in automatic test data generation. The proposed approach introduces the improved POA to solve the diversity problem in test data generation. The modified algorithm outperforms eight well-known metaheuristic algorithms regarding coverage and the number of fitness evaluations needed. The approach also incorporates techniques to address the challenge of reducing test data volume while maintaining high coverage. Compared to six well-known metaheuristic algorithms, the improved POA demonstrates superior path coverage and efficiency performance. For example, when generating 1000 test cases on benchmark programs such as QuadEq, Gcd, and Bessj, our method achieved up to an 83% increase in path coverage relative to the weakest-performing baseline. This improvement is primarily due to the enhanced diversity of test data, which reduces redundancy and increases the likelihood of covering unique execution paths. The consistent performance of the proposed approach across multiple benchmarks highlights its effectiveness in generating diverse, high-coverage test suites for white-box testing.},
  archive      = {J_SUPERC},
  author       = {Salehi, Mojtaba and Parsa, Saeed and Joudaki, Saba and Kolivand, Hoshang},
  doi          = {10.1007/s11227-025-07611-1},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Efficient path coverage-based test data generation using an enhanced pelican algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-cnn hybrid network for underwater image enhancement. <em>SUPERC</em>, <em>81</em>(10), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07612-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to light attenuation and wavelength-dependent light scattering in underwater environments, underwater images often suffer from color distortion, reduced contrast, and loss of detail, which significantly hinder the performance of high-level computer vision tasks. To address these challenges, we propose a hybrid Transformer-CNN network for underwater image enhancement. First, a Mixed Convolution and Transformer Block (MCTB) is employed in both the encoder and decoder, integrating hierarchical convolutions with self-attention mechanisms to enhance the model’s ability to capture fine-grained details and global contextual information. Secondly, to mitigate feature interference caused by the symmetrical structure of the encoder-decoder architecture, an Enhanced Feature Fusion Module (EFFM) is introduced in the skip connections to refine color and structural information. Finally, the model is trained on the publicly available UIEB-paired dataset and evaluated on multiple underwater image test sets. Quantitative and qualitative results demonstrate that the proposed method achieves superior performance compared to other methods.},
  archive      = {J_SUPERC},
  author       = {Qiao, Jian Hua and Guan, Yu Ting and Zhi, Jin Ning},
  doi          = {10.1007/s11227-025-07612-0},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Transformer-cnn hybrid network for underwater image enhancement},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention-based graph convolutional neural network for multimodal sentiment analysis. <em>SUPERC</em>, <em>81</em>(10), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07613-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis aims to extract aspects and identify their corresponding sentiment polarities from text-image pairs, which is a fine-grained sentiment analysis task. However, the traditional multimodal sentiment analysis method neglects the homogeneity and heterogeneity among the fine-grained modes. To address these limitations, this paper proposes a dual attention-based graph convolutional neural network for multimodal sentiment analysis (DAGCN). Specifically, from a local perspective, we employ two different types of attention mechanism to achieve fine-grained alignment between aspect terms and text-picture pair features, thus facilitating effective intramodal and multimodal information interaction. From a global perspective, we construct a comprehensive graph-structured relational matrix to explore deep-seated text-image correlations and utilize a graph convolutional network to perform feature fusion and node classification, ultimately deriving aspect-level sentiment polarities. Extensive experiments on two multimodal public datasets demonstrate that DAGCN achieves significant performance improvements over existing methods.},
  archive      = {J_SUPERC},
  author       = {Qu, Na and Yu, Long and Tian, Shengwei and Xia, Pusen and Wu, Chaoyue},
  doi          = {10.1007/s11227-025-07613-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Dual attention-based graph convolutional neural network for multimodal sentiment analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum infidelity codistillation for fast and accurate distributed quantum machine learning. <em>SUPERC</em>, <em>81</em>(10), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07614-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to develop a scalable, accurate, and fast-converging method for knowledge transfer in quantum machine learning (QML), which is essential for reducing QML model sizes to fit within a limited number of qubits. Quantum knowledge distillation (QKD) offers a promising approach that transfers knowledge from a pre-trained large teacher model to a smaller model. However, its dependency on the pre-trained large teacher model restricts its applicability to offline training scenarios and cases where a large number of qubits is already available. To address these limitations, we propose quantum infidelity codistillation (QICD), inspired by co-distillation (CD) in classical machine learning and quantum state fidelity in QML. In QICD, following CD, each student learns from the ensemble knowledge of the other students, eliminating the need for a pre-trained teacher. However, the diversity among student models may lead to excessively high KL divergence, used in traditional CD for regularization by measuring knowledge differences, thus hindering training convergence. To resolve this, QICD employs quantum state infidelity as a bounded regularization measure, ensuring stable training. Using the quantum neural tangent kernel framework, we theoretically prove the asymptotic convergence of QICD and demonstrate that the convergence speed increases with the number of students. By numerical simulation on an image classification task, we show that QICD with four students achieves competitive accuracy compared to a baseline QKD using a pre-trained teacher model. QICD also achieves higher accuracy and faster convergence than a baseline quantum codistillation (QCD) that uses the KL divergence, highlighting the effectiveness of quantum infidelity regularization.},
  archive      = {J_SUPERC},
  author       = {Oh, Seungeun and Kim, Jinhyuk and Park, Jihong and Baek, Hankyul and Lee, Hyunsoo and Kim, Joongheon and Kim, Seong-Lyun},
  doi          = {10.1007/s11227-025-07614-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Quantum infidelity codistillation for fast and accurate distributed quantum machine learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pointat: Enhancing point cloud contrastive representation learning via an adaptive truncated loss. <em>SUPERC</em>, <em>81</em>(10), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07615-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual annotation of large-scale point cloud datasets for tasks such as 3D object classification, segmentation, and detection is often laborious due to the irregular structure of point clouds. Self-supervised learning, which operates without human labeling, presents a promising approach to address this challenge. Following the success of contrastive learning in image and video understanding, recent works have investigated self-supervised contrastive learning for point cloud analysis. However, existing contrastive learning approaches face a critical bottleneck caused by the incorporation of false negatives in the InfoNCE loss. This leads to inefficient learning when negative sample pairs are insufficient to differentiate all actual object classes, forcing models to over-separate representations of the same class. To address this limitation, we propose PointAT, a lightweight point cloud contrastive learning framework. Our approach employs a Focused Sampling (FS) module for geometric keypoint identification, enabling discriminative object representation learning. Both coarse-grained point clouds from the FS module and original fine-grained point clouds are processed through parallel streams in a Local Residual Attention module. This dual-stream architecture facilitates comprehensive feature extraction and fusion across multiple scales. Finally, we introduce an Adaptive Truncated Loss (AT) to align multi-scale representations while adaptively managing negative sample separation in the embedding space. We provide theoretical analysis validating our proposed loss function. Experimental results demonstrate that PointAT outperforms previous unsupervised methods across diverse downstream tasks, including 3D object classification on ModelNet40 and ScanObjectNN datasets, and part segmentation on ShapeNet. Comprehensive ablation studies further validate the effectiveness of our approach.},
  archive      = {J_SUPERC},
  author       = {Hong, Yang and Yao, Xinyue and Mo, Jianqing},
  doi          = {10.1007/s11227-025-07615-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Pointat: Enhancing point cloud contrastive representation learning via an adaptive truncated loss},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RHFL: A robust method to defend against poisoning attacks for heterogeneous hierarchical federated learning. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07616-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a decentralized machine learning paradigm designed to address data privacy concerns by exchanging model parameters instead of raw data. Hierarchical federated learning (HFL), a form of FL, enhances communication efficiency through its client-edge-cloud hierarchy. However, HFL is vulnerable to poisoning attacks where malicious clients may corrupt the global model by manipulating local model updates. Moreover, in HFL, data heterogeneity among clients and actions by malicious clients cause their model updates to deviate from benign clients, making it a challenge to identify malicious clients. In this work, we propose a Byzantine-robust method for HFL, named RHFL, which integrates both Jensen–Shannon divergence and performance-weighted aggregation to mitigate the impact of poisoning attacks. Specifically, the model update differences of clients are evaluated by calculating the Jensen–Shannon divergence score between each client and the edge server. Subsequently, malicious clients are detected by conducting an adaptive threshold mechanism that analyzes the statistical characteristics of Jensen–Shannon divergence scores across clients. Finally, a model performance-weighted aggregation rule is developed at the edge server to enhance the robustness of HFL. Due to its high communication and computational demands, particularly in handling large-scale data and real-time updates, RHFL requires high-performance computing environments for efficient operation. Extensive experiments on four benchmark datasets demonstrate that RHFL outperforms current defenses in terms of prediction accuracy.},
  archive      = {J_SUPERC},
  author       = {Zhao, Shihai and Fu, Xiaodong and Liu, Li and Li, Jie and Peng, Wei and Ding, Jiaman},
  doi          = {10.1007/s11227-025-07616-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {RHFL: A robust method to defend against poisoning attacks for heterogeneous hierarchical federated learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-harnet: An efficient hybrid transformer network for human activity recognition. <em>SUPERC</em>, <em>81</em>(10), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07618-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition (HAR) is an emerging research area with a diverse range of applications in surveillance, healthcare, and other fields. However, HAR in surveillance systems presents challenges due to the need for real-time processing of video data in dynamic environments. Capturing both spatial and temporal dependencies in surveillance footage is difficult, especially when dealing with cluttered backgrounds, diverse viewpoints, and partial occlusions. These challenges arise from the computational limitations of many surveillance systems, which make the use of computationally intensive models difficult for efficient and timely activity recognition. To overcome these challenges, we propose a novel and efficient hybrid framework for robust HAR, specifically designed for resource-constrained devices. EfficientNet-B0 up to the block 5 layer with the set of salient contextual features and dimensions of 7x7x1280 is leveraged to extract spatial features from individual frames. By extracting features up to the blocks 5 layers, the model efficiently balances the trade-off between performance and computational cost while still capturing rich spatial representations. In order to understand long-range temporal dependencies, the extracted spatial features vector is then sent to a vision transformer (ViT), which analyzes the sequential frame features in the second stage. This approach enables efficient modeling of temporal relationships across frames. A focal loss function is applied to handle class imbalance, further enhancing the model’s robustness and performance. The proposed framework is evaluated on three challenging HAR datasets-UCF50, YouTube Action, and HMDB51-achieving competitive accuracy and outperforming existing state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Iqbal, Asif and Rauf, Muhammad Arslan and Salim and Mahamud, M. D. Shakib and Khalil, Mian Muhammad Yasir and Qin, Zhen},
  doi          = {10.1007/s11227-025-07618-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {E-harnet: An efficient hybrid transformer network for human activity recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A byzantine-robust federated learning against adversarial–majority attacks. <em>SUPERC</em>, <em>81</em>(10), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07619-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed machine learning framework that enables multiple clients to collaboratively train a global model without sharing local data. However, the process is vulnerable to disruption by malicious clients, who may inject adversarially manipulated models to undermine the aggregation process. While various robust aggregation methods exist, many struggle with detection stability and model robustness under diverse poisoning attacks or adversarial-majority scenarios. To address these limitations, we propose RSDFL, a Robust Similarity-based Dual-gradient Federated Learning model, designed to detect and defend against Byzantine attacks. RSDFL effectively identifies malicious clients even under adversarial-majority conditions and ensures the accuracy and reliability of the global model. The approach incorporates a gradient evaluation method based on class loss changes to determine benign and malicious update directions. Additionally, a bidirectional gradient similarity-based credibility metric is introduced to assess the quality of the clients’ training results, forming the basis for a poisoning detection mechanism and robust global model aggregation algorithm. Compared with the most advanced robust federated learning algorithms currently available, experimental results on the F-MNIST, E-MNIST, PathMNIST, and CIFAR-10 datasets demonstrate that our scheme outperforms state-of-the-art methods in terms of Byzantine client identification accuracy and model performance. The model performance approaches the ideal level observed in non-poisoned scenarios. Particularly in the highly challenging adversarial-majority scenario, our scheme effectively mitigates various poisoning attacks that are difficult for existing algorithms to handle, while also exhibiting superior performance in model convergence speed and stability. These results demonstrate the exceptional robustness of our scheme in complex adversarial environments.},
  archive      = {J_SUPERC},
  author       = {Shi, Yinglong and Hu, Xiaoming and Bai, Shuangjie and Liu, Yan and Lin, Hao},
  doi          = {10.1007/s11227-025-07619-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {A byzantine-robust federated learning against adversarial–majority attacks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid algorithm for multi-objective task scheduling in heterogeneous cloud computing. <em>SUPERC</em>, <em>81</em>(10), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07621-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an increasing complexity of the submitted tasks by users and the diversity of requirements, many computing platforms have begun to incorporate heterogeneous computing resources to meet user demands, which also brings new challenges to computing platform resource management. Task scheduling, as the core link of resource management, its optimization is particularly crucial. Efficient task scheduling strategies can not only significantly enhance the service experience of users, but also improve economic benefits for cloud service providers. In this paper, the grey wolf optimization (GWO) is improved which names as Improved-GWO; then, a novel hybrid algorithm called HIGWOLS is proposed to address the task scheduling problem for heterogeneous virtual machines. HIGWOLS is formed by combining the Improved-GWO with local search algorithm which improves the convergence speed and solution accuracy of traditional GWO. To validate the proposed hybrid method, a series of experiments are performed using different real world datasets with various sizes. The proposed hybrid method is compared with other swarm intelligent algorithms, such as PGSAO, GA-GWO and whale optimization algorithm (WOA). The proposed hybrid algorithm reduces the makespan by 8.9%, 24.6%, and 17.8% compared to PGSAO, GA-GWO and WOA, while improving resource utilization rate by 10.4%, 22.8%, and 27.5%, and reducing degree of load imbalance by 91.8%, 93.6%, and 90.9%, respectively. The experimental results indicate that the HIGWOLS has significant advantages when using HPC2N and NASA iPSC.},
  archive      = {J_SUPERC},
  author       = {Zhang, Youli and Zhang, Hu and Song, Changjian},
  doi          = {10.1007/s11227-025-07621-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A hybrid algorithm for multi-objective task scheduling in heterogeneous cloud computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy and temperature-aware routing approach for congestion control in wireless body area networks. <em>SUPERC</em>, <em>81</em>(10), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07622-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area networks (WBANs) play a critical role in health monitoring but are constrained by rapid energy depletion, node overheating, and network congestion, which degrade quality of service and system reliability. To tackle these challenges, this paper proposes ETC-MOTLBO, an energy-, temperature-, and congestion-aware multi-objective teaching–learning-based optimization framework integrated with software-defined networking (SDN). The approach employs K-means clustering to organize sensor nodes efficiently and uses a centralized SDN controller with a multi-objective fitness function considering residual energy, node temperature, queue length, and intra-cluster distances to optimize cluster head selection and routing paths dynamically. Simulation results demonstrate that, compared to conventional methods, ETC-MOTLBO reduces average energy consumption to as low as 0.66 J, extends network lifetime up to 1990 rounds, maintains a high data delivery rate above 99.98%, and effectively limits end-to-end delay to under 3.82 s even at higher node densities. These improvements confirm that the proposed method significantly enhances energy efficiency, thermal stability, and congestion control, offering a robust and scalable solution for reliable WBAN-SDN communication in healthcare environments.},
  archive      = {J_SUPERC},
  author       = {Mozaffari, Javad and Abdollahi Azgomi, Mohammad and Madadi, Halimeh and Ebrahimi Dishabi, Mohammad Reza},
  doi          = {10.1007/s11227-025-07622-y},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Energy and temperature-aware routing approach for congestion control in wireless body area networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale feature aggregation with hierarchical semantics and uncertainty assessment: Enabling high-accuracy visual retrieval. <em>SUPERC</em>, <em>81</em>(10), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07623-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content retrieval systems facilitate accurate and efficient identification of visually similar images within large-scale databases, serving as a critical component in applications spanning from intelligent monitoring systems to digital media management. While existing deep metric learning approaches predominantly concentrate on developing discriminative feature embeddings to capture visual semantics, they often fail to account for intrinsic uncertainties arising from input noise or inherent semantic ambiguities. This study introduces an Uncertainty-Aware Multi-Scale Feature Aggregation Network (UAMSFANet) that constructs comprehensive image representations through the integration of hierarchical semantic features and probabilistic uncertainty modeling, enabling more reliable similarity computation. The proposed architecture features an innovative Dual Harmonized Focus Attention Module (DHFAM) that establishes cross-dimensional interactions between local spatial patterns and global channel contexts, effectively enhancing discriminative features while suppressing irrelevant information. Extensive experimental validation on standard benchmarks, including CUB-200-2021 and Stanford Cars dataset, confirms the framework’s superior retrieval performance and the synergistic effects of its architectural components. Our project link can be found here .},
  archive      = {J_SUPERC},
  author       = {Cui, JingWen and Yuan, ChunHong and zhang, Dan},
  doi          = {10.1007/s11227-025-07623-x},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Multi-scale feature aggregation with hierarchical semantics and uncertainty assessment: Enabling high-accuracy visual retrieval},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-saving transmission time and power management for D2D connection with a relay node using the same band with a cellular connection. <em>SUPERC</em>, <em>81</em>(10), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07624-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of device-to-device (D2D) communication, utilizing the same spectral resources as cellular networks, is regarded as a pivotal development for the next generation of wireless communication infrastructures. This is especially relevant when relay nodes are introduced to broaden the transmission distance of D2D links. However, the performance bottleneck persists due to the bidirectional interference stemming from both D2D and conventional cellular links, compelling an escalation in transmission power for these connections. Given the paramount importance of energy conservation for both mobile network operators and users, this study tackles the issue of optimizing transmission time selection and power management (TTSPM) in a scenario where a D2D connection with the relay node and a cellular connection coexist on the same sub-channel, aiming to minimize the overall energy expenditure during transmission. First, we formulate the optimization problem as a NP-hard mixed integer nonlinear programming (MINLP) problem. To solve it, we follow the idea of dividing and conquering and investigate four possible resource sharing cases of the two considered links, respectively. For the first three resource-sharing cases, we prove the TTSPM problem can be transformed into convex optimization problems and then present algorithms to obtain the regional optimal solution corresponding to each case. For the fourth resource-sharing case, we develop a simulative game-theory-based approach to tackle the TTSPM problem since it is still a non-convex optimization problem. As virtual non-cooperative players, cellular connections and D2D connection with the relay nodes are viewed as non-cooperative, we establish the presence of Nash equilibrium within the formulated game and develop algorithms to determine the optimal response of each participant, considering the strategy adopted by their counterpart. Numerical analyses reveal that the TTSPM method, by selecting the optimal regional solution from four potential cases of resource allocation, significantly reduces the overall energy required for transmission across the two analyzed links, outperforming the results documented in prior studies.},
  archive      = {J_SUPERC},
  author       = {Jiang, Xian and Zhu, Yiyao and Zhang, Zitian and Chen, Zhenghong and Zhuge, Bin and Dong, Ligang and Wang, Yipin and Sun, Yingqi and Zhang, Jie},
  doi          = {10.1007/s11227-025-07624-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Energy-saving transmission time and power management for D2D connection with a relay node using the same band with a cellular connection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time surface defect detection algorithm for printed circuit boards based on improved YOLOv11n. <em>SUPERC</em>, <em>81</em>(10), 1--47. (<a href='https://doi.org/10.1007/s11227-025-07625-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and accurate defect detection on printed circuit boards (PCBs) is critical to product quality assurance. In this paper, we propose an optimized lightweight target detection model for PCB defect detection, aiming to solve the dual challenges of the difficulty of detecting tiny defects and complex background interference, while meeting the industrial real-time detection requirements. The method uses an uncertainty-aware adaptive training sample selection strategy (UATSS) to improve the training efficiency and detection performance of the model; introduces a detail-enhanced convolution (DEConv) module to improve the feature extraction capability of small defects; proposes a shared lightweight detail-enhanced detection head (SLDECD) to reduce the computational complexity of the model; and uses an improved loss function to improve the training stability. The experimental results show that the model in this paper achieves 97.8% mAP and 99.6% accuracy on the PCB defect dataset, which are 4.0 and 1.9 percentage points higher than the benchmark model, respectively, and at the same time reduces the model size to only 3.8 M, the computation volume from 6.2G FLOPs to 2.7G FLOPs, which is 56.5% less compared to the original model, and the number of frames per second (FPS) reached 144.1. The model has been successfully deployed on the RK3568 platform, realizing the requirements for high-precision real-time detection and embedded device deployment.},
  archive      = {J_SUPERC},
  author       = {Zhou, Zhuguo and Lu, Yujun and Lv, Liye},
  doi          = {10.1007/s11227-025-07625-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {Real-time surface defect detection algorithm for printed circuit boards based on improved YOLOv11n},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced human fall detection via lightweight MDS-OpenPose framework. <em>SUPERC</em>, <em>81</em>(10), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07628-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls among the elderly pose a significant risk of injury and even mortality, underscoring the importance of real-time monitoring systems to mitigate these hazards. Existing posture estimation-based fall detection methods often struggle with high parameter counts, computational complexity, and slow processing speeds. This paper proposes an improved OpenPose algorithm, termed MDS-OpenPose, which addresses these issues. By integrating the lightweight MobileNetV3 network to replace the original VGG feature extraction network, optimizing convolutional layer sizes, and introducing DenseNet dense connections, MDS-OpenPose significantly reduces model complexity while maintaining high accuracy. Fall detection is achieved through a comprehensive method that analyzes vertical distances between the head and feet, trunk tilt angles, and horizontal displacement of the center of mass. Experimental results demonstrate that MDS-OpenPose achieves a substantial improvement in FPS on the COCO dataset while maintaining high precision and recall rates. On the Fall Down dataset, it attains an accuracy of 93.0% and a precision of 92.1%. This achievement demonstrates that supercomputing capabilities can effectively improve the real-time performance and reliability of algorithms in actual fall detection scenarios, highlighting the application value of this research in the field of supercomputing.},
  archive      = {J_SUPERC},
  author       = {Wang, Di and Nan, Gangyang and Xia, Fang},
  doi          = {10.1007/s11227-025-07628-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Enhanced human fall detection via lightweight MDS-OpenPose framework},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid feature selection algorithm based on Mann–Whitney u test and double optimization. <em>SUPERC</em>, <em>81</em>(10), 1--69. (<a href='https://doi.org/10.1007/s11227-025-07629-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the expansion of data size and dimension, single filtering and wrapper feature selection methods are limited in dealing with the problem of data redundancy. Therefore, hybrid feature selection algorithms have attracted much attention. In this paper, a hybrid feature selection algorithm combining the Mann–Whitney U test, improved nutcracker optimization, and a football team training algorithm is proposed. First, S0 is generated via the Mann–Whitney test U and the elite solution strategy, and S1 is obtained via dynamic adjustment. Then, the improved nutcracker optimization algorithm is subsequently used to optimize S1 to obtain S2. Finally, the optimal feature subset is determined by the improved soccer team training algorithm acting on S2. After testing on 22 datasets, the classification accuracy of the proposed algorithm is greater than 90% on most datasets, and the dimension reduction rate is less than 0.5%, which has significant advantages in the feature selection of high-dimensional datasets.},
  archive      = {J_SUPERC},
  author       = {Yang, Xueguang and Zheng, Yuefeng and Gan, Jing and Lu, Yang},
  doi          = {10.1007/s11227-025-07629-5},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--69},
  shortjournal = {J. Supercomput.},
  title        = {A novel hybrid feature selection algorithm based on Mann–Whitney u test and double optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of time series forecasting and spatio-temporal series forecasting in deep learning. <em>SUPERC</em>, <em>81</em>(10), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07632-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting involves identifying patterns and trends in historical time series data to estimate future values, while spatio-temporal forecasting incorporates spatial information to predict future states across both time and space. In recent years, these forecasting tasks have found widespread applications in key domains such as finance, meteorology, energy, transportation, and healthcare. As data volume and model complexity continue to increase, deep learning models have significantly improved predictive accuracy, but also raised the demand for computational resources. In particular, tasks such as large-scale graph modeling, long-range dependency learning, and uncertainty estimation increasingly rely on high-performance computing (HPC), GPU acceleration, and distributed processing. This paper provides a comprehensive review of recent deep learning models for time series and spatio-temporal forecasting. We analyze the characteristics, advantages, and limitations of various models, with a focus on representative approaches based on Transformer architectures and hybrid designs. In addition, we introduce common evaluation metrics, benchmark datasets, and typical application domains. The paper further discusses the computational cost and scalability of these models, especially their adaptability to HPC environments, and offers practical guidelines for model selection tailored to different application scenarios.},
  archive      = {J_SUPERC},
  author       = {Yu, Qianqian and Yang, Guang and Wang, Xiao and Shi, Yaxin and Feng, Ying and Liu, Ang},
  doi          = {10.1007/s11227-025-07632-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {A review of time series forecasting and spatio-temporal series forecasting in deep learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic self-paced undersampling ensemble for imbalanced classification. <em>SUPERC</em>, <em>81</em>(10), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07633-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of large-scale imbalanced data is a challenging task in machine learning. Ensemble methods based on undersampling are considered one of the most effective approaches to address this task. However, most existing undersampling ensemble methods are susceptible to inappropriate undersampling strategies, which may lead to the loss of useful information in the majority class, thereby affecting the model’s generalization ability. To tackle this issue, this paper proposes a novel dynamic self-paced undersampling ensemble (DSUE) method. This method first implements adaptive self-paced undersampling, which selects the most informative majority class samples based on their difficulty distribution to create balanced data subsets for each base classifier. Secondly, a sample weighting strategy is employed to identify critical samples in class-overlapping regions, thereby improving the model’s predictive performance and reducing the impact of noisy data. Finally, a weighted ensemble strategy based on the Gmean scores of base classifiers on the original dataset is introduced, which allocates higher weights to base classifiers that perform better on the original dataset in the final decision-making process. We conducted comparative experiments on 30 small-scale datasets and five large-scale datasets, comparing our method with nine related approaches. The experimental results demonstrate that the proposed DSUE method significantly outperforms the compared methods in evaluation metrics such as F1, Gmean, and AUC, particularly in large-scale imbalanced datasets, showing its superior effectiveness and competitiveness.},
  archive      = {J_SUPERC},
  author       = {Leng, Qiangkui and Lyu, Chunyue and Zhou, Zhuoyu and Meng, Xiangfu and Wang, Changzhong},
  doi          = {10.1007/s11227-025-07633-9},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic self-paced undersampling ensemble for imbalanced classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new multilingual framework for fake reviews detection based on a large language model. <em>SUPERC</em>, <em>81</em>(10), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07636-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Before making a purchase, consumers often look for reviews of the product or service online. These reviews also help businesses since they provide valuable insight into how customers perceive their goods and services. Having trustworthy information was especially important during the COVID-19 pandemic, when people were cooped up at home and had to rely on internet reviews to pass the time. Not only did the quantity of reviews increase during the pandemic, but so did the context and preferences. Reviewers of spam take note of these shifts and work to refine their deceitful methods. For financial gain or competitive advantage, spam reviews often include false, deceptive, or fraudulent statements meant to mislead consumers. Further, dealing with different languages makes fake review identification more complex, especially in the absence of labeled data for model training. Therefore, our study suggests a transformer ensemble model that uses a large language model (LLM) to translate foreign languages into English. We turned to two neural machine translation models-Google Translate and LibreTranslate-to translate two languages: Arabic, Spanish. Next, a set of pre-trained models was used to examine the tone of the reviews. These models included GPT-3, an LLM from OpenAI, bert-base-multilingual-uncased, and Twitter-Roberta-Base. Based on our experimental results, it is evident that a foreign language fake review is achievable through English translation. The suggested ensemble model outperforms both the independent pre-trained models and LLM, and the accuracy and f1-score of fake review detection on translated reviews are 90% and 87.6%, respectively, on the Arabic language. To the best of our knowledge, our proposed framework is the first that use an LLM model for Arabic and Spanish languages.},
  archive      = {J_SUPERC},
  author       = {Mohawesh, Rami and AlQarni, Ahmed Abdallah and Alkhushayni, Suboh M. and Daradkeh, Tariq and Bany Salameh, Haythem},
  doi          = {10.1007/s11227-025-07636-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {A new multilingual framework for fake reviews detection based on a large language model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based network compression framework for lifecycle management of lithium-ion batteries. <em>SUPERC</em>, <em>81</em>(10), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07638-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of the lithium-ion battery (LIB) degradation trajectory is crucial for new energy vehicles. In recent years, bi-directional long short-term memory (Bi-LSTM) networks have achieved good performance in LIB life prediction because they can effectively capture the long-term dependencies of time series data. However, Bi-LSTM has a large number of parameters, high complexity, and low operational efficiency, making it difficult to deploy on an edge device with limited memory and computational power, which greatly restricts its application scenarios in the era of industrial Internet of things. To this end, we propose a knowledge distillation-based network compression framework for degradation trajectory prediction of LIB. In our framework, a high-complexity network is first leveraged to sufficiently extract LIB nonlinear degradation knowledge. Then, a knowledge distillation (KD) technique is integrated to guide the learning of a lightweight heterogeneous network, thereby realizing knowledge transfer between different network structures. The effectiveness of our proposed framework is validated on the Maryland battery dataset. Extensive experimental results indicate that our proposed method outperforms other benchmarks in terms of model complexity and prediction accuracy. Specifically, when the parameter volume of the KD-based lightweight network shrinks by a factor of 155.3, it even achieves comparable performance to the intricate teacher network.},
  archive      = {J_SUPERC},
  author       = {Lu, Shixiang and Yan, Yibo and Zhang, Yansheng and Liu, Yuanhong and Yu, Sheng and Gao, Zhi-Wei},
  doi          = {10.1007/s11227-025-07638-4},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {A knowledge distillation-based network compression framework for lifecycle management of lithium-ion batteries},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kds-radfnet: A distributed thermal infrared and visible image fusion framework based on knowledge distillation and semantic segmentation. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07640-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep neural network-based methods for fusing thermal infrared and visible images often incur knowledge loss, negatively impacting fused image quality. To address this limitation, this paper presents a novel method named KDS-RADFNet, employing knowledge distillation to fuse these modalities. The approach features a specifically designed knowledge distillation network architecture. A teacher network, utilizing a dual-branch structure, separately extracts thermal radiation features from thermal infrared images and gradient texture features from visible images. Complementary knowledge, formed after cross-modal feature alignment, serves as supervisory signals. A student network learns and integrates this information. A distillation loss function facilitates the transfer of the teacher’s feature representations to the student network, establishing a balance between thermal radiation sensitivity and textural-structural fidelity. This process effectively suppresses feature interference during the fusion of multimodal source images. Furthermore, an unsupervised semantic segmentation network is cascaded with the fusion network. Joint supervision using semantic loss and fusion loss guides the training, enhancing the utility of the fused images for downstream high-level vision tasks. Extensive experiments on multiple public datasets demonstrate that the fusion network enhanced by the knowledge distillation method encodes knowledge more effectively, leading to improved fusion performance.},
  archive      = {J_SUPERC},
  author       = {Feng, Siling and Wang, QiaoYun and Lin, Cong and Huang, Mengxing},
  doi          = {10.1007/s11227-025-07640-w},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Kds-radfnet: A distributed thermal infrared and visible image fusion framework based on knowledge distillation and semantic segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid neural network prediction model based on time–frequency domain features and its application to industrial heat exchangers. <em>SUPERC</em>, <em>81</em>(10), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07642-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of outlet temperature and outlet pressure of heat exchangers is critical for production safety in industries such as chemical industry. However, traditional physical modeling requires domain experts to formulate equations and perform time-consuming parameter calibration, while single deep learning models (e.g., standalone CNN or RNN) exhibit limitations in simultaneously extracting both temporal and spatial features. To address these limitations, this study proposes a hybrid neural network model based on convolutional (CNN) + bi-directional gated recurrent unit fused with time-domain features and frequency-domain features, which combines the advantages of each of the Fourier transform, channel attention, and global attention mechanisms and improves the accuracy of the prediction of the data. The performance of this model is verified to be superior to other models by comparing the existing prediction methods with this paper’s method through publicly available datasets. Finally, the proposed model is evaluated by MAE and RMSE evaluation metrics using the operational data of a heat exchanger in a coal coking company as a case study. The results show that the proposed model achieves good accuracy in predicting the assessment metrics of heat exchanger outlet variables, and the reduction of root mean square error and mean absolute error is remarkable, which meets the demand for real-time and accurate safety production prediction in the chemical industry.},
  archive      = {J_SUPERC},
  author       = {Cheng, Nuo and Tang, Anbo and Ye, Shaoli and Wang, Lu and Xie, Nenggang},
  doi          = {10.1007/s11227-025-07642-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {A hybrid neural network prediction model based on time–frequency domain features and its application to industrial heat exchangers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-accuracy tool wear monitoring for micro-milling method based on improved pyramid vision transformer. <em>SUPERC</em>, <em>81</em>(10), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07650-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tool wear is inevitable in micro-milling. The small size of micro-milling tools makes it difficult to detect wear without without using supercomputing and high-precision equipment during downtime, which seriously affects machining quality and efficiency. Therefore, accurate and real-time monitoring of micro-milling tool wear is crucial. In this paper, we propose an improved Pyramid Transformer based on global average pooling (GPVT). To address the problem of high computational complexity of traditional MHSA in processing high-speed cutting images, we design Global Average Pooling with MHSA (GAP-MHSA), significantly reducing computational overhead of model by utilizing normalization and average pooling, which satisfies stringent monitoring efficiency requirements of micro-milling. To enhance model’s ability to analyze wear characteristics of micro-milling tools, KAN linear layer is combined with MLP to make model more interpretable. In addition, considering the multi-scale characteristics of micro-milling cutter wear features, the channel convolutional attention mechanism (CCAM) is designed to integrate advantages of soft attention and hard attention to realize efficient interaction between global and local features, and ensure that the model accurately captures the wear features at different scales. The experimental results show that GPVT is more accurate than other common methods and more efficient than Transformer-based model, which meets the real-time requirements of micro-milling.},
  archive      = {J_SUPERC},
  author       = {Zheng, Gang and Chen, Minshu and Zhou, Qiong},
  doi          = {10.1007/s11227-025-07650-8},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {High-accuracy tool wear monitoring for micro-milling method based on improved pyramid vision transformer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Quantum-resilient security for 6G networks: A comprehensive survey on challenges, solutions, and research opportunities. <em>SUPERC</em>, <em>81</em>(10), 1. (<a href='https://doi.org/10.1007/s11227-025-07651-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Kim, Minji and Park, Jong Hyuk},
  doi          = {10.1007/s11227-025-07651-7},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Quantum-resilient security for 6G networks: A comprehensive survey on challenges, solutions, and research opportunities},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Click-through rate prediction via feature selection and layer-wise residual gated cross-network. <em>SUPERC</em>, <em>81</em>(10), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07652-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommendation scenarios and online advertisements, accurate prediction models are important for the task of click-through rate (CTR) prediction. Current prediction methods usually model higher-order feature interactions to learn complex relationships. However, during training, excessive redundant features will increase model computational complexity. Meanwhile, the process of higher-order feature interactions introduces noisy information and loses original information, thereby affecting the accurate representation of the combined features. To overcome these limitations, a CTR prediction model of fusion feature selection and layer-wise residual gated cross-network (SeLRGCN) is proposed. The SeLRGCN utilizes a feature selection layer to control the information stream in two branches, identifying important features that are jointly recognized by both information streams, which initially reduces the complexity of higher-order interactions. On this basis, a layer-wise residual gated cross-network is designed. The network reinforces feature combinations through considering the guiding role of original combined features to mitigate premature loss of original information. Meanwhile, by designing gating mechanism to filter out ineffective feature interactions, it mitigates the impact of noisy information on the model. SeLRGCN is trained on large-scale real-world datasets such as Criteo, Avazu and MovieLens. The depth of architecture and parametric richness enable stable modeling of sophisticated feature cross-correlations at high orders. Computational results on three public datasets indicate that SeLRGCN model achieves effective improvement in prediction performance.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yuan and Sheng, Tiantian and Fan, Yaqin and Duan, Lunping},
  doi          = {10.1007/s11227-025-07652-6},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Click-through rate prediction via feature selection and layer-wise residual gated cross-network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CVSR: Complex-valued networks for video super-resolution. <em>SUPERC</em>, <em>81</em>(10), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07659-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In video super-resolution (VSR), bidirectional sequences (i.e., forward and backward sequences) inherently describe the temporal flow and provide oriented motion information for high-resolution reconstruction. However, few works consider further modeling of bidirectional features, and they only aggregate these forward features and backward features into a group of ordinary feature maps via concatenation. Therefore, the correlation between the two features in opposite directions remains to be explored. In this paper, we provide a novel viewpoint for VSR, which constructs a higher relationship with respect to the forward features and backward features in the complex number domain. We respectively treat a forward feature and a backward feature as the real component and the imaginary component of a complex number and compute them according to the rules of complex number. This computation allows the bidirectional features to embrace a more coupling relation, so as to excavate high-dimension information used for reconstruction. Specifically to achieve complex VSR framework, we present two transplantable modules, i.e., complex transform and complex attention. The complex transform aims to generally change the bidirectional features to complex features by constructing a complex feature extraction. The complex attention can adaptively rectify the complex features for each complex feature map, so as to project a feature map to a specific frequency. In addition, we analyze the superiority of complex representations compared with real-valued representations. Extensive experiments on representative bidirectional networks (BasicVSR and IconVSR) and their improved form (IBRN) show the effectiveness and robustness of complex VSR framework. Codes are available at https://github.com/ttcluo/CVSR.git .},
  archive      = {J_SUPERC},
  author       = {Luo, Chuan},
  doi          = {10.1007/s11227-025-07659-z},
  journal      = {The Journal of Supercomputing},
  month        = {7},
  number       = {10},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {CVSR: Complex-valued networks for video super-resolution},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new load-balancing approach for cloud computing based on an improved genetic algorithm. <em>SUPERC</em>, <em>81</em>(9), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07368-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing, with its significant potential for remote data storage and processing, has brought new computational advantages for distributed applications. The existence of bottlenecks and congestion in the cloud environment makes traffic management essential in a scalable environment. This paper introduces a complex solution using an optimized genetic algorithm to address scheduling and load-balancing challenges in cloud infrastructure. Additional parameters are integrated into the algorithm to assess resource status before scheduling, effectively preventing server overload or underload by strategically allocating tasks to processing servers. Furthermore, tasks assigned to heavily loaded or dense servers are seamlessly migrated through live migration of virtual machines to alternative servers, enhancing the overall load balance of the cloud infrastructure. The effectiveness of the proposed approach is evaluated through the CloudSim simulator and validated by deploying over a thousand virtual machines in the PlantLab dataset and Azure 2019. Simulation results show a significant improvement in service-level agreement execution compared to comparative methods. Additionally, a reduction in energy consumption has been observed, while the average number of virtual machine migrations shows significant improvement.},
  archive      = {J_SUPERC},
  author       = {Rezapourshahir, Samira and Babaie, Shahram},
  doi          = {10.1007/s11227-025-07368-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A new load-balancing approach for cloud computing based on an improved genetic algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing privacy and security in IoT: A CoAP protocol analysis and improvement approach. <em>SUPERC</em>, <em>81</em>(9), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07401-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern Internet of Things (IoT) environments, the demand for secure and efficient communication protocols is more urgent than ever due to privacy and security challenges. Current solutions often fail to adequately protect user anonymity and location privacy. The Constrained Application Protocol (CoAP), a lightweight communication protocol, is particularly suitable for resource-constrained devices in IoT and sensor networks. This paper provides a detailed analysis of CoAP’s security features using a modular symbolic model and the Tamarin prover. We identify a major flaw: insufficient anonymity, which could allow malicious attackers to track users’ location information. To address this issue, we propose CoAP $$^+$$ , an enhanced version of the protocol that improves both anonymity and overall security. This research not only offers a practical method for analyzing the security of IoT devices but also highlights the importance of addressing anonymity concerns and suggests actionable improvement strategies.},
  archive      = {J_SUPERC},
  author       = {Cai, Guangying and Cai, Liujia and Cui, Xinyue and Lu, Siqi and Wang, Yongjuan and Wang, Xiangyu and Xue, Haoyuan},
  doi          = {10.1007/s11227-025-07401-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing privacy and security in IoT: A CoAP protocol analysis and improvement approach},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study and survey of chain-based routing protocols in wireless sensor networks. <em>SUPERC</em>, <em>81</em>(9), 1--62. (<a href='https://doi.org/10.1007/s11227-025-07412-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain-based routing protocols play a vital role in enabling energy-efficient communication in wireless sensor networks (WSNs). Building upon the foundational principles established by power efficient gathering in sensor information systems (PEGASIS), researchers have proposed several modified versions and novel chain-based routing protocols. This paper surveys the evolution of chain-based routing protocols, classifying them into hybrid and non-hybrid categories. Hybrid protocols combine chain topology with other virtual structures---such as clusters, grids or trees---to enhance overall network performance. Our findings highlight that hybrid chain-based routing protocols achieve up to 30% improvement in energy efficiency and 25% reduction in latency compared to non-hybrid chain-based routing protocols. Each protocol is examined comprehensively in this paper, providing in-depth insights into their design and trade-offs, including the balance between scalability and energy consumption.},
  archive      = {J_SUPERC},
  author       = {Verma, Rahul Kumar and Jain, Shubhra and Kaushik, Abhinesh},
  doi          = {10.1007/s11227-025-07412-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--62},
  shortjournal = {J. Supercomput.},
  title        = {A comparative study and survey of chain-based routing protocols in wireless sensor networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing inference of segmentation on high-resolution images in MLExchange. <em>SUPERC</em>, <em>81</em>(9), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07413-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MLExchange is a machine learning (ML) operations platform providing web user-interfaces (UIs) for data visualization and analysis pipelines at synchrotron facilities. Among these UIs is the segmentation app which helps synchrotron users utilize ML algorithms to automatically segment high-resolution scientific images with minimal manual annotation effort. In this work, we share code optimizations that significantly speed up the segmentation inference workflow of large data in short time. By optimizing the sequence of CPU-GPU data transfers and introducing CPU parallelization to key operations, we improve the per-device, per-image frame computational efficiency and observe close to 3 $$\times$$ speedup over the original segmentation inference workflow run time when utilizing a single GPU. Further adaptations enabling multi-GPU inference yield more than 40 $$\times$$ speedup with 100 GPUs compared to the optimized single GPU inference workflow. This acceleration of the segmentation inference workflow will provide MLExchange users with easy access to segmentation results with little wait time.},
  archive      = {J_SUPERC},
  author       = {Lu, Shizhao and Chavez, Tanny and Koepp, Wiebke and Hao, Guanhua and Zwart, Petrus H. and Hexemer, Alexander},
  doi          = {10.1007/s11227-025-07413-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing inference of segmentation on high-resolution images in MLExchange},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An energy-aware scheduling in DVFS-enabled heterogeneous edge computing environments. <em>SUPERC</em>, <em>81</em>(9), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07432-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is a computational paradigm that addresses the computational and storage needs of end-users. Due to the exponential increase in service demand, edge data centres require continuous performance improvement. Efficient scheduling is a crucial component of edge computing for maximizing capacity, minimizing response time, reducing energy consumption, and optimizing resource utilization. This paper presents an efficient method to minimize the energy overhead of time-constrained applications modelled by directed acyclic graphs in heterogeneous edge computing environments. The technique is divided into two phases. In the first phase, a novel approach for calculating request priorities is designed, and an energy-aware scheduling algorithm based on genetic and ant colony optimization is proposed to obtain an initial scheduling result with reduced energy consumption. In the second phase, considering the slack time among requests and their deadlines, an upward and downward proportionally detection slack algorithm is proposed to further reduce energy overhead using Dynamic Voltage and Frequency Scaling (DVFS) techniques. Simulation results indicate that the proposed method reduces both overall energy consumption and request completion times. On average, the results demonstrate a 0.65 reduction in energy consumption and a 0.20 reduction in completion time compared to randomly constructed Directed Acyclic Graph (DAG) algorithms.},
  archive      = {J_SUPERC},
  author       = {Kazemi, Ferdos and Barzegar, Behnam and Motameni, Homayun and Yadollahzadeh-Tabari, Meisam},
  doi          = {10.1007/s11227-025-07432-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {An energy-aware scheduling in DVFS-enabled heterogeneous edge computing environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributed skewed stream processing system based on scoring high-frequency key perception. <em>SUPERC</em>, <em>81</em>(9), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07465-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The onset of the big data era has ushered in a proliferation of stream-based applications across diverse domains. Nevertheless, the real-world streams are characterized by significant skewness. This attribute skew, in turn, leads to workload imbalances within distributed stream processing systems (DSPSs), resulting in increased response times and diminished throughput in DSPS applications. Building upon this challenge, we present the design and implementation of a distributed skewed stream processing system named SH-Stream, leveraging Scoring High-frequency (SH) key perception. SH-Stream comprises two integral components: the Stream Data Prediction Module and the Efficient Stream Schedule Module. To accurately identify high-frequency keys in streams, we introduce a scoring probabilistic prediction algorithm and establish effective maintenance mechanisms for these high-frequency keys. Load balancing is achieved through the judicious splitting of identified high-frequency keys. We implement and assess this functionality across multiple stream processing platforms, employing large-scale synthetic and real-world datasets for comprehensive evaluation. Our experimental results reveal a notable improvement in throughput, with an impressive 89.9% and 27% enhancement compared to KG and PKG, respectively. Additionally, latency experiences a substantial $$2.7\times$$ improvement, while maintaining skewed control below 0.05%.},
  archive      = {J_SUPERC},
  author       = {Tan, Jiawei and Yang, Li and Guo, Yaolian and Zuo, Zhiwei and Xiao, Xiong},
  doi          = {10.1007/s11227-025-07465-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {A distributed skewed stream processing system based on scoring high-frequency key perception},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-language discriminative fusion network for object tracking. <em>SUPERC</em>, <em>81</em>(9), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07472-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of visual-language(VL) tracking, most existing methods have achieved impressive advancements in multimodal information fusion where the attention mechanism plays a crucial role in VL tasks. However, the way traditional attention mechanisms calculate correlations independently can introduce noise and ambiguity into the attention weights, thus restricting further performance improvements. To address this issue, we propose a multimodal discriminative fusion module. This module innovatively adopts a cross-utilization strategy, combining multimodal discriminative attention (MDA) with multi-head attention, and is committed to exploring the consistency among multimodal relevant vectors. In this way, it enhances effective cross-modal correlations, suppresses incorrect correlations, and thereby realizes the optimization and strengthening of multimodal interactions to achieve the goal of multimodal fusion. In addition, we have proposed a concise, flexible, and efficient VL tracking pipeline named VLDF. This pipeline abandons the complex design of the prediction head and generates the target position through an autoregressive method. This measure not only reduces the model complexity but also enhances the tracking stability. Finally, we have carried out a large number of experiments on benchmark datasets such as TNL2k, LaSOT, LaSOText, and OTB99-Lang. The experimental results fully verify the effectiveness of the proposed method, achieving satisfactory results.},
  archive      = {J_SUPERC},
  author       = {Zhang, Jianwei and Yan, Xinyu and Zhang, Huanlong and Xu, Liusen and Jiang, Bin and Zhong, Bineng},
  doi          = {10.1007/s11227-025-07472-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Vision-language discriminative fusion network for object tracking},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A classifier expansion framework with dual knowledge distillation and dynamic weighting for continual relation extraction. <em>SUPERC</em>, <em>81</em>(9), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07488-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual relation extraction (CRE) aims to learn new relations while avoiding catastrophic forgetting of old ones. Memory-based methods mitigate forgetting by replaying samples stored in a memory buffer, but performance drops significantly without the buffer. This suggests these methods rely heavily on memory replay and neglect the stability of retaining learned knowledge. Repeatedly replaying simple samples may also cause overfitting. To address these issues, we propose a classifier expansion framework based on dual knowledge distillation and dynamic weighting. This method incrementally expands the classifier and uses dual knowledge distillation to retain old knowledge while learning new relations. We design a forgetting weight and an adaptation loss to balance distillation loss. Additionally, we weight classification loss by relation difficulty to prioritize challenging relations and reduce overfitting on simpler ones. Experimental results show that our method effectively reduces forgetting and improves model performance by enhancing stability and mitigating overfitting.},
  archive      = {J_SUPERC},
  author       = {Mao, Aonan and Wu, Di and Jiang, Liting and Song, Shuangyong and Li, Yanbing and Huang, Hao and Slamu, Wushour},
  doi          = {10.1007/s11227-025-07488-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {A classifier expansion framework with dual knowledge distillation and dynamic weighting for continual relation extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-path feature fusion and constrained boundary optimization for open intent detection. <em>SUPERC</em>, <em>81</em>(9), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07499-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open intent detection is a critical task for dialog systems, designed to accurately classify known intents into their respective categories and also detect unknown intents. In this paper, we propose a framework of multi-path feature fusion and constrained boundary optimization for open intent detection (FFBO-OID). First, we finely tune a BERT model using gated weights to integrate hierarchical and global features and operate a joint loss training scheme to enhance the adaptability of the model for class-unbalanced datasets. Second, we introduce constraint factors for both positive and negative samples and learn a more appropriate decision boundary for each known intention to enhance the generalization capability of the model. Finally, the proposed method shows substantial performance improvements and stability across varying proportions of known categories on three benchmark datasets, outperforming other state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Huang, Jinjie and Li, Wenhe},
  doi          = {10.1007/s11227-025-07499-x},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Multi-path feature fusion and constrained boundary optimization for open intent detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing resource allocation in cloud-native applications through proactive autoscaling with the InformerAutoScale model. <em>SUPERC</em>, <em>81</em>(9), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07500-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-native applications are designed to utilize cloud computing resources efficiently. These applications automatically scale resources by managing containerized copies of files and creating containers, which are handled through pods in Kubernetes. However, they face challenges due to the dynamic workload associated with automatic scaling and de-scaling in cloud environments. This makes it difficult to obtain accurate monitoring information, particularly with reactive autoscaling. This research presents a proactive autoscaling approach through the proposed InformerAutoScale model, which predicts resource requirements for long sequences in cloud-native applications to enable accurate pod scaling and descaling. Experimental results demonstrate that the InformerAutoScale approach effectively reduces resource waste and manages issues such as under and over-provisioning. The real-world implementation was carried out using Docker Desktop and Kubernetes, with scale or scaled pods allocated based on application requests. Proactive autoscaling achieved a 90.66% improvement in scaling efficiency compared to reactive methods.},
  archive      = {J_SUPERC},
  author       = {Kumar, Bablu and Verma, Anshul and Verma, Pradeepika and Bennour, Akram},
  doi          = {10.1007/s11227-025-07500-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing resource allocation in cloud-native applications through proactive autoscaling with the InformerAutoScale model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of electrical energy consumption using principal component analysis and independent components analysis. <em>SUPERC</em>, <em>81</em>(9), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07505-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of electricity consumption is crucial for optimizing energy management, reducing operational costs, and ensuring the sustainability of power systems. This study introduces a two-stage framework for short-term electricity consumption prediction by integrating dimensionality reduction techniques—Principal Component Analysis (PCA) and Independent Component Analysis (ICA)—with machine learning models, including Random Forest, Support Vector Regression (SVR), Linear Regression (LR), Artificial Neural Networks (ANN), and Long Short-Term Memory (LSTM) networks. The original 12-dimensional dataset was reduced to two key components using PCA and ICA to eliminate redundancy and noise while preserving essential features. These transformed datasets were then used to train predictive models. Model performance was evaluated using metrics such as the coefficient of determination (R2), Root Mean Square Error (RMSE), and the Willmott Index (WI). The results indicate that PCA generally outperforms ICA across most models. For instance, Random Forest with PCA achieved R2 = 0.79 and RMSE = 44.79, compared to R2 = 0.763 and RMSE = 48.75 using ICA. Likewise, the LSTM model performed significantly better when combined with PCA (R2 = 0.78, WI = 0.83) than with ICA. Paired t test results further support these findings, showing statistically significant improvements in Mean Absolute Error (MAE) for PCA over ICA in ANN and LSTM models (p < 0.05). The findings demonstrate that combining advanced dimensionality reduction—particularly PCA—with powerful machine learning algorithms, especially deep learning models like LSTM, leads to more robust and accurate electricity consumption forecasting. Future work could explore hybrid feature extraction methods and transformer-based architectures to enhance prediction performance across diverse datasets.},
  archive      = {J_SUPERC},
  author       = {Saeedi, Nima and Baharvand, Deniz and Shirini, Kimia and Gharehveran, Sina Samadi},
  doi          = {10.1007/s11227-025-07505-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Prediction of electrical energy consumption using principal component analysis and independent components analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance portability of generated cardiac simulation kernels through automatic dimensioning and load balancing on heterogeneous nodes. <em>SUPERC</em>, <em>81</em>(9), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07510-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrophysiology simulation applications, such as the community-developed openCARP framework for in silico experiments, involve applying a broad range of ionic model kernels with different computational weights and arithmetic intensity characteristics. Efficiently executing these kernels while taking into account variations in kernel execution time and heterogeneous processing unit speeds, is crucial for overall simulation performance. Ensuring that this execution strategy adapts automatically to the underlying hardware architecture is important to ensure performance portability. To address these challenges, this work introduces a method for efficiently distributing ionic model kernels across heterogeneous resources, guided by a resource dimensioning heuristic that adapts to each model’s computational profile. These mechanisms are integrated into openCARP and evaluated on 30 representative ionic models, with a focus on both performance and energy efficiency. We demonstrate that on a node with 8 GPUs, our method achieves a geometric mean speedup of 1.45 compared to using all GPUs, while also improving energy efficiency.},
  archive      = {J_SUPERC},
  author       = {Alba, Vincent and Aumage, Olivier and Barthou, Denis and Counilh, Marie-Christine and Guermouche, Amina},
  doi          = {10.1007/s11227-025-07510-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Performance portability of generated cardiac simulation kernels through automatic dimensioning and load balancing on heterogeneous nodes},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive seasons optimization algorithm for global optimization. <em>SUPERC</em>, <em>81</em>(9), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07511-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seasons optimization (SO) algorithm is an evolutionary-based optimizer designed to solve numerical and engineering optimization tasks. Despite its promising performance, the SO algorithm has two significant drawbacks: slow convergence and the tendency to become trapped in local optima in certain problems. To address these limitations, we proposed an adaptive version of the SO algorithm named the seasons optimization with chaotic reverse learning and opposition-based learning (SOCO) algorithm. The proposed SOCO incorporates two learning strategies: chaotic reverse learning (CRL) and opposition-based learning (OBL). These techniques establish a proper balance between exploration and exploitation, allowing for an efficient search of the solution space and facilitating escapes from local optima, ultimately enhancing the algorithm’s convergence quality. We evaluated the algorithm using three engineering design problems and 20 numerical functions of varying dimensionalities taken from test suites CEC-2015, CEC-2018, and CEC-2022. The simulation results demonstrate that the SOCO algorithm outperformed its counterparts in terms of global search capability and convergence performance.},
  archive      = {J_SUPERC},
  author       = {Asadianfam, Shiva and Emami, Hojjat},
  doi          = {10.1007/s11227-025-07511-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {An adaptive seasons optimization algorithm for global optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multimodal emotion recognition using optimized transformer model with SHAP-based transparency. <em>SUPERC</em>, <em>81</em>(9), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07515-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition is a crucial aspect of human–computer interaction, enabling intelligent systems to understand and respond to human emotions effectively. However, traditional models struggle with cross-modal integration and lack interpretability, making it challenging to accurately classify emotions from speech, text, and facial expressions. This study proposes an optimized transformer-based multimodal emotion recognition framework trained on the MELD (Multimodal EmotionLines Dataset), which provides real-world dialogue-based emotion annotations. Each modality is processed using specialized deep learning models: BERT/RoBERTa for text to extract context-aware sentence embeddings, wav2vec 2.0 for speech to capture intonation, pitch, and tone variations, and ResNet50/VGG16 for facial expressions to identify emotion-relevant visual features. These extracted representations are fused using a transformer-based cross-modal attention mechanism, and the model undergoes hyperparameter optimization to improve accuracy and generalization. To ensure transparency, SHAP (Shapley additive explanations) is incorporated to identify the most influential features contributing to emotion classification across all modalities. Experimental results demonstrate that the proposed approach outperforms traditional deep learning models on MELD, achieving superior accuracy while maintaining explainability. The findings highlight the potential of integrating explainable AI techniques with deep learning to develop reliable and trustworthy emotion recognition systems.},
  archive      = {J_SUPERC},
  author       = {Alyoubi, Adel A. and Alyoubi, Bader A.},
  doi          = {10.1007/s11227-025-07515-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Interpretable multimodal emotion recognition using optimized transformer model with SHAP-based transparency},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv11 optimization for efficient resource utilization. <em>SUPERC</em>, <em>81</em>(9), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07520-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this research is to optimize the eleventh iteration of You Only Look Once (YOLOv11) by developing size-specific modified versions of the architecture. These modifications involve pruning specific layers and reconfiguring the main architecture of YOLOv11. Each proposed version is tailored to detect objects of specific size ranges, from small to large. To ensure proper model selection based on dataset characteristics, we introduced an object classifier program. This program identifies the most suitable modified version for a given dataset. The proposed models were evaluated on various datasets and compared with the original YOLOv11, YOLOv10, and YOLOv8 models. The experimental results highlight significant improvements in computational resource efficiency, with the proposed models maintaining the accuracy of the original YOLOv11. In some cases, the modified versions even outperformed the original model in terms of detection performance. Furthermore, the proposed models demonstrated reduced model sizes—each of the six proposed models showed a notable reduction compared to the original. Additionally, the required GFLOPs were reduced from 6.3 MB (YOLOv11), 5.7 MB (YOLOv10) and 8.1 MB (YOLOv8) to just 3.8 MB for the large model. All proposed models also achieved faster inference times, significantly reducing the time required to detect objects in images. Models weights and the object size classifier can be found in this repository ( https://github.com/AREEG94FAHAD/yolov11 ).},
  archive      = {J_SUPERC},
  author       = {Rasheed, Areeg Fahad and Zarkoosh, Mahdi},
  doi          = {10.1007/s11227-025-07520-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {YOLOv11 optimization for efficient resource utilization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emsd-detr:efficient small object detection for UAV aerial images based on enhanced RT-DETR model. <em>SUPERC</em>, <em>81</em>(9), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07524-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAV aerial image object detection studies are affected by imbalances in large fields of view, changes in scale and viewing angle, object aggregation occlusion, and changes in lighting and weather conditions, resulting in poor performance of small object detection algorithms. In this paper, we propose an Efficient Multi-scale Drone DETR (EMSD-DETR), an object detection model for UAV aerial images that aims to overcome specific challenges. To mitigate the loss of information about small objects due to the increase in the number of layers of the convolutional neural networks, the FRE-Block is proposed. Furthermore, we propose a small object sensitive pyramid for cross-scale feature fusion that effectively fuses local spatial coordinate information with global contextual information to avoid missing details of different feature layers. Finally, the Focaler-Shape-IoU is introduced that incorporates consideration of the shape and scale of the bounding box to expedite convergence and enhance detection precision for difficult samples. Experiments on the VisDrone dataset demonstrate that the EMSD-DETR model improves 1.8%, 2.9%, 2.7%, and 1.2% with regard to precision, recall, mAP $$_{50}$$ , and mAP $$_{50:95}$$ , respectively, while decreasing the number of parameters by 8.2%, as compared to RT-DETR. In addition, generalizability experiments on the TinyPerson and NWPU VHR-10 dataset prove the validity of the EMSD-DETR model.},
  archive      = {J_SUPERC},
  author       = {Zhang, Chaofeng and Yang, Jingmin},
  doi          = {10.1007/s11227-025-07524-z},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Emsd-detr:efficient small object detection for UAV aerial images based on enhanced RT-DETR model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IAgent fault-tolerance approach (iAFTA) based on optimization algorithms in wireless sensor networks. <em>SUPERC</em>, <em>81</em>(9), 1--46. (<a href='https://doi.org/10.1007/s11227-025-07525-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) face persistent challenges in energy efficiency and fault tolerance due to limited node battery life. This paper introduces a novel multi-goal intelligent agent approach (iAFTA) for static WSNs, where intelligent agents (iAgents) proactively monitor cluster head (CH) energy, detect failures, and dynamically elect replacements based on energy and proximity. The process integrates fault tolerance to prevent cascading failures while minimizing energy consumption through adaptive minimum spanning tree (MST) reconfiguration. The proposed iAFTA approach is evaluated across five distinct scenarios using key metrics such as first node dead (FND), half node dead (HND), last node dead (LND), average energy consumption (AEC), and CH replacement rate. In addition, fault-tolerance metrics, including fault detection accuracy, detection time, and energy overhead, are evaluated. Results show that iAFTA achieves 100 % fault detection accuracy, immediate detection and recovery (average detection time of 1.0 round), and low-energy overhead during fault handling, even in large-scale scenarios. Results demonstrate significant improvements over existing protocols like BWOA-V. In Scenarios #1 and #2 (1600 rounds, 200 nodes), iAFTA delayed the FND by 12.1 % (1012.4 vs. 903.9 rounds) and 25.3 % (1096.2 vs. 875.2 rounds), respectively, while maintaining partial functionality beyond round 1600. BWOA-V fully degraded by round 1250.7. In Scenario #3 (100x100m area), all nodes survived under iAFTA, whereas BWOA-V recorded an FND at 1137.1 rounds. Furthermore, iAFTA reduced AEC by 93.3 % at round 500 (0.0138 J vs. 0.2056 J for BWOA-V) and ensured robust fault tolerance with only 11 CH replacements, balancing residual energy among CHs in later rounds. While these results validate iAFTA’s scalability and resilience for large-scale WSN applications, certain limitations were identified during testing under high-stress conditions in Scenarios #4 and #5 (15,000 rounds). In Scenario #4, the LND metric was undefined across all runs due to simulation termination before complete network depletion, limiting the ability to fully assess overall network lifespan but confirming that iAFTA prevents simultaneous energy exhaustion across nodes. In Scenario #5, a high node density of 900 nodes resulted in an average of 4074 CH replacements, reflecting robust energy redistribution but also exposing challenges in achieving balanced energy depletion across all nodes.},
  archive      = {J_SUPERC},
  author       = {Ktari, Mouna and Ktari, Raïda and Khemakhem, Yassine and Hadj Kacem, Ahmed},
  doi          = {10.1007/s11227-025-07525-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--46},
  shortjournal = {J. Supercomput.},
  title        = {IAgent fault-tolerance approach (iAFTA) based on optimization algorithms in wireless sensor networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient NoC-based architecture for convolutional neural networks on multicore systems. <em>SUPERC</em>, <em>81</em>(9), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07526-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been extensively applied in many practical applications such as image classification, speech processing, and object recognition. CNNs are growing deeper to obtain higher accuracies. Moreover, the large amount of data exchange between neurons complicates communication. As a result, it is critical to design high-performance processing hardware to handle CNN workloads. The multicore system based on network-on-chip (NoC) architecture is a promising solution for performing CNN workloads because NoC provides high performance and scalable interconnections for on-chip communications. However, the performance of NoC-based design is greatly impacted by matching the topology to the characteristics of CNN workloads since different CNN applications require varying amounts of connection bandwidth. Therefore, we propose a NoC-based architecture for CNN workloads by using long-distance wire links with respect to performance metrics. The performance of the proposed NoC-based design is evaluated for the two CNN models, LeNet and CDBNet models, in terms of network throughput, average latency, and energy consumption. Additionally, an analysis is conducted on the area overhead related to the proposed design. The experimental findings verified that the suggested NoC-based design is a very competitive design in comparison with the other designs for CNN workloads.},
  archive      = {J_SUPERC},
  author       = {Dehghani, Abbas},
  doi          = {10.1007/s11227-025-07526-x},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {An efficient NoC-based architecture for convolutional neural networks on multicore systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An augmented multi-objective multi-verse optimizer algorithm for solving dynamic economic emission dispatch problems. <em>SUPERC</em>, <em>81</em>(9), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07527-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic economic emissions dispatch (DEED) problem in power systems aims to minimize fuel costs and emissions while meeting load demands and operational constraints. The DEED problem’s high dimensionality and multi-objective nature pose challenges for traditional optimization methods. In contrast to traditional optimization methods, robust optimization algorithms, which are less sensitive to initial conditions, offer better solutions. Therefore, this paper proposes an augmented multi-objective multi-verse optimizer (AMOMVO) algorithm. In the AMOMVO algorithm, we employ a new augmented strategy to adjust the wormhole existence probability parameter, enhancing the algorithm’s exploration capability. Additionally, an augmented strategy for the travelling distance rate balances global exploration in early iterations with local exploitation later, avoiding local optima. Finally, we design a differential mutation search mechanism that significantly improves global search performance. AMOMVO excels in DEED problems with 5, 10, and 15 units.},
  archive      = {J_SUPERC},
  author       = {Tian, Huixian and Song, Yingjie},
  doi          = {10.1007/s11227-025-07527-w},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {An augmented multi-objective multi-verse optimizer algorithm for solving dynamic economic emission dispatch problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuickEn: A data encryption device for high performance storage. <em>SUPERC</em>, <em>81</em>(9), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07532-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of electronic information and mobile Internet, the era of big data has arrived. The massive amount of data are stored in a high-performance storage system using fiber channel storage area networks. Our study of the literature reveals that a significant portion of these data is stored in plain text, which can raise potential security risks, or encrypted by simple devices, which decreases the performance of the storage systems. To solve the problem of plain text data storage and improve throughput performance, we design a high-performance data encryption device using advanced Xilinx field programmable gate array technology. Positioned between a server and a disk array (or storage), the encryption device secures the data written to the disk array. It achieves a data throughput rate of up to 11.21 Gbps by adopting a high-performance hardware platform and using pipeline-based data processing. It also improves the ability of the data encryption device to resist a side-channel attack by designing various SM4 algorithms consisting of different S-boxes.},
  archive      = {J_SUPERC},
  author       = {Zhang, Hongke and Yan, Zheng},
  doi          = {10.1007/s11227-025-07532-z},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {QuickEn: A data encryption device for high performance storage},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing multi-task learning to improve overlapping relation extraction. <em>SUPERC</em>, <em>81</em>(9), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07533-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction (RE) is crucial for advancing information extraction, with overlapping RE being a significant sub-task. This scenario is generally more complex than normal RE. While normal RE involves two entities, overlapping RE involves two or three distinct entities, each with multiple mentions. This increases the relation ambiguity, particularly for single entity overlapping (SEO). To address this issue, we propose a multi-task learning approach, imbibing a syntactic perception task into the RE with two supervisory signals: mention-cross matrix and syntactic binary signal. The former supervises this model to predict an asymmetric product matrix, emphasizing different mentions interactions. The latter utilizes the Steiner minimal tree to identify token-level semantic paths across all mentions in syntactic trees and guides the attention to capture semantic dependencies. These signals collectively optimize the extraction process. The results on four datasets confirm our approach achieves competitive performance, demonstrating the effectiveness of disambiguating SEO scenarios in RE.},
  archive      = {J_SUPERC},
  author       = {Wang, Hailin and Zhang, Song and Zhang, Dan and Ma, Ao},
  doi          = {10.1007/s11227-025-07533-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Harnessing multi-task learning to improve overlapping relation extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A few-shot detection method for new types of network traffic attacks based on meta-learning with cross-attention. <em>SUPERC</em>, <em>81</em>(9), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07534-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the persistent evolution of network attacks, intrusion detection systems need to enhance their identification capabilities for new types of network traffic attacks. However, the advent of new attacks often introduces the challenge of limited samples. We propose a few-shot intrusion detection method to address this challenge. The core of our approach is a cross-attention mechanism based on a meta-learning layer, which highlights the most distinctive regions between the support set and query set samples, thereby improving the model’s detection and recognition capabilities. Additionally, we perform classification using both nearest neighbor and global classifiers. Two loss functions are employed for optimization, ensuring the model is well-suited for specific few-shot learning tasks while maintaining strong generalization capabilities. To mitigate the problem of sparse sample data, we utilize a transductive inference algorithm that enhances the support set by iteratively incorporating more unlabeled query set samples. Experiments conducted on the CICIDS2017 and TUT datasets validate the effectiveness of the proposed method. By using only five samples to detect new attacks on the CICIDS2017 dataset, our method achieves an average recall of 96.28%, surpassing traditional machine learning methods and existing few-shot intrusion detection techniques. When detecting simulated new attacks on the TUT dataset, the average recall rate reached 88.68%. The method provides a practical technical approach for building intrusion detection systems capable of accurately responding to new attacks.},
  archive      = {J_SUPERC},
  author       = {Shi, Kai and Ding, Penghao and Wang, Jinsong},
  doi          = {10.1007/s11227-025-07534-x},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {A few-shot detection method for new types of network traffic attacks based on meta-learning with cross-attention},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved adaptive multi-tasking differential evolutionary algorithm with opposition-based learning. <em>SUPERC</em>, <em>81</em>(9), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07535-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task optimization algorithms are widely recognized for their effectiveness in addressing complex problems. However, they frequently encounter issues such as negative knowledge transfer, reduced convergence efficiency, and the risk of being trapped in local optima throughout the optimization process. To overcome these difficulties, this paper proposes an improved adaptive multi-tasking differential evolutionary algorithm with opposition-based learning (OBLMTDE). The algorithm achieves knowledge balance between tasks by adaptively adjusting the random mating probability, thus accelerating the convergence speed. At the same time, a mutation strategy based on elite selection is introduced, which promotes positive knowledge transfer by selecting excellent individuals engaged in mutation in other tasks. In addition, the algorithm adopts a novel parameter tuning strategy that enhances the global exploration capability and effectively avoids the local optimum trap. To validate the performance of the OBLMTDE algorithm, we conducted experimental comparisons on nine benchmark problems of single-objective multi-task optimization. Our experimental results indicate that OBLMTDE outperforms existing multi-tasking optimization algorithms in most of the tested functions.},
  archive      = {J_SUPERC},
  author       = {Song, Yingjie and Liu, Xidong},
  doi          = {10.1007/s11227-025-07535-w},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {An improved adaptive multi-tasking differential evolutionary algorithm with opposition-based learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UCS-YOLO: A novel approach for multi-scale small target detection in UAVs. <em>SUPERC</em>, <em>81</em>(9), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07536-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift advancement of drone technology has highlighted the essential role of precise object detection in drone images across a variety of use cases, including remote sensing, traffic monitoring, and military reconnaissance. However, existing detection methods often struggle with challenges like small target detection, complex backgrounds, and multi-scale feature fusion. In order to overcome these challenges, we introduce UCS-YOLO, a refined model built upon YOLOv8. The UCS-YOLO framework incorporates several key advancements: (1) an improved ConvFormer module, adapted from the MetaFormer architecture, to augment the C2f module for detailed feature extraction; (2) a new neck architecture integrating CSPCARS with SPDConv modules for efficient fusion of features at multiple scales. The CSPCARS component utilizes channel and spatial attention mechanisms to emphasize key features, while the SPDConv module enhances feature fusion and context awareness across varying scales and environments. Additionally, we propose the ShapeAware IoU loss function, which refines traditional IoU metrics by integrating overlap ratio, center deviation, and shape adaptation, ensuring more accurate small target detection. On the VisDrone2019 dataset, UCS-YOLOv8 achieves a 3.08% improvement in detection accuracy compared to the baseline model. This demonstrates the model’s superior capability in detecting small targets and its effectiveness in handling complex scenes.},
  archive      = {J_SUPERC},
  author       = {Sun, Guang-Ling and Zhang, Fen-Qi and Zhu, Yu-Min and Miao, Fei},
  doi          = {10.1007/s11227-025-07536-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {UCS-YOLO: A novel approach for multi-scale small target detection in UAVs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 3D reconstruction method for driving scenes based on improved neural radiance fields. <em>SUPERC</em>, <em>81</em>(9), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07538-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the limitations of Neural Radiance Fields (NeRF) and its derivatives in dynamic driving scenes by proposing an optimization method based on MARS to improve 3D reconstruction efficiency and stability in complex driving environments. Model parameters are initialized from pre-trained background, global, and object models. To optimize feature extraction and reduce overfitting, mean squared error and regularization terms are introduced. The improved optimizer employs an efficient gradient descent strategy and decouples weight decay from gradient updates. Through iterative backpropagation, model parameters are updated to optimize the loss function, enhancing the model's ability to recognize both static and dynamic objects. The method is evaluated on the KITTI and VKITTI datasets with different splits (Novel View Synthesis (NVS)-75%, NVS-50%, and NVS-25%) and compared with NSG, SUDS, and MARS. The results show a 7.3% improvement in PSNR and a 28.9% reduction in LPIPS, with relatively better performance under low data ratio conditions, enhancing reconstruction quality.},
  archive      = {J_SUPERC},
  author       = {Zhu, Weizhi and Tian, Lianfang and Du, Qiliang and Xie, Juanhong},
  doi          = {10.1007/s11227-025-07538-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {The 3D reconstruction method for driving scenes based on improved neural radiance fields},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABAC policy mining method for heterogeneous access control system. <em>SUPERC</em>, <em>81</em>(9), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07539-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attribute-based access control (ABAC) model has emerged as a more flexible model when addressing complex authorization requirements. However, different information systems may adopt heterogeneous access control systems, and it becomes more and more necessary to migrate them to ABAC access control system. Based on this, we focus on heterogeneous policy migration and propose a universal ABAC policy mining method based on ant colony algorithm. First, we utilize subject-permission tuples from different access control systems as security intent; second, we combine different attributes to make initial policies and transform attribute relationships into attribute constraints with ant colony algorithm optimization to build ABAC policy set; third, we make policy optimization to enhance the policy quality. Experimental results show our superior performance. We improve the policy evaluation metric weighted structure complexity by an average of 34.6% and improve time overhead by 58.3% in complex policy mining situation. Overall, we solve the bottleneck in complex ABAC policy mining situations with improved time overhead and high-quality policy set, providing strong support for heterogeneous policy migration and the promotion of ABAC model in real-world applications.},
  archive      = {J_SUPERC},
  author       = {Siyuan, Shang and Aodi, Liu and Xuehui, Du and Xiaohan, Wang and Ming, Tan},
  doi          = {10.1007/s11227-025-07539-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {ABAC policy mining method for heterogeneous access control system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FPGA-based SqueezeNet transformer with multi-scale attention fusion for real-time respiration rate estimation using PPG signals. <em>SUPERC</em>, <em>81</em>(9), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07543-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory disorders, particularly in patients with conditions such as COVID-19, pose significant health risks. Respiration rate (RR) is a critical vital sign that provides valuable insights into a patient’s health status. Abnormalities in RR often indicate health deterioration, making continuous monitoring an essential early warning system. However, RR monitors are typically limited to patients in the intensive care unit (ICU). Current studies have explored the potential of photoplethysmogram (PPG) signals for noninvasive RR estimation. Although several deep learning (DL) solutions for RR prediction have been developed, challenges remain in achieving high accuracy and real-time deployment. This research proposes a novel lightweight hybrid DL model that integrates SqueezeNet and a transformer with multi-scale attention fusion to enhance feature extraction from PPG signals for effective RR estimation. The model was evaluated using two widely recognized public datasets, Beth Israel Deaconess Medical Center (BIDMC) and CapnoBase. Validation metrics included mean absolute error (MAE), percentage error (E), root mean squared error (RMSE), correlation coefficient (R), standard deviation (2SD), and Pearson correlation coefficient (PCC). Experimental results demonstrate that the proposed approach outperforms four well-established DL-based methods and the most recent models in the literature. For the BIDMC dataset, the proposed model achieved a maximum R and PCC of 0.947 and 0.72, respectively, along with minimal error metrics: MAE of 0.576 breaths per minute (bpm), RMSE of 1.057 bpm, E of 0.04, and 2SD of 1.86 bpm. On the CapnoBase dataset, the model achieved the highest PCC of 0.78 and R of 0.962, with minimal error scores: MAE of 0.465 bpm, RMSE of 0.897 bpm, E of 0.03, and 2SD of 1.73 bpm. An ablation study further validated the significance of each module within the architecture. To enable real-time deployment, the model was implemented on an Intel Arria 10 GX1150 FPGA, optimizing computational efficiency, reducing power consumption, and improving inference speed. This advancement supports broader telemedicine and wearable healthcare applications, with potential for further enhancements through model scaling and multimodal signal integration.},
  archive      = {J_SUPERC},
  author       = {Selvam, Immaculate Joy and Chandran, Srinivasan and Chandrasekaran, Saravanakumar},
  doi          = {10.1007/s11227-025-07543-w},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {FPGA-based SqueezeNet transformer with multi-scale attention fusion for real-time respiration rate estimation using PPG signals},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum-resilient security for 6G networks: A comprehensive survey on challenges, solutions, and research opportunities. <em>SUPERC</em>, <em>81</em>(9), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07544-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information and communication technology, 6G is emerging as a next-generation communication network that enables higher speeds, lower latency, large-scale connectivity, and space and maritime communications. Building on the advancements of 5G, 6G aims to solve various security issues by integrating advanced technologies such as quantum cryptography and blockchain. However, current 6G networks threaten new technologies and existing security threats. For example, security threats like eavesdropping and data interception occur with large-scale device connectivity. In addition, the development of quantum computing, a new technology, may pose a serious threat to existing encryption systems, posing a security threat. In addition, Terahertz (THz) communication, the core technology of 6G communication, may cause various security threats, such as jamming and hijacking attacks. This paper provides a comprehensive survey of threats and solutions to ensure the security and privacy of 6G networks. Current advances in 6G focus on basic security services such as confidentiality, integrity, availability, privacy, and non-repudiation but are ill-prepared for future technical requirements. This paper explores advanced cryptographic techniques, including quantum cryptography, blockchain, and artificial intelligence, to address this gap. This paper investigated a layered security framework that leverages these technologies. Finally, we present open research challenges and future research directions for improving 6G network security. This paper presents a new security perspective to address 6G security issues and provides a technical foundation for securing 6G networks, the next generation.},
  archive      = {J_SUPERC},
  author       = {Kim, Minji and Park, Jong Hyuk},
  doi          = {10.1007/s11227-025-07544-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Quantum-resilient security for 6G networks: A comprehensive survey on challenges, solutions, and research opportunities},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malgta: Large language model-based guided malware tactical analysis. <em>SUPERC</em>, <em>81</em>(9), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07545-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In High-Performance Computing (HPC) environments, a comprehensive understanding of cybersecurity threats and their underlying attack strategies is essential. However, current research predominantly focuses on maliciousness determination, typically emphasizing the code’s operational behaviors rather than the attack strategies employed. The advancements in multimedia computing, particularly Large Language Models (LLMs), have paved the way for innovative solutions to the aforementioned bottleneck. This work proposes MalGTA (Guided Malware Tactical Analysis), an LLM-based system that automates ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge)-aligned malware tactical analysis through Cuckoo Sandbox-driven dynamic profiling. Specifically, we construct a multi-source knowledge base integrated with Retrieval-Augmented Generation (RAG), which mitigates hallucinations in LLMs through context-sensitive threat intelligence retrieval. In addition, we propose a query optimization strategy to address challenges related to input information overload and attention dispersion in LLMs, enabling context-aware data refinement from Cuckoo reports. Finally, this study conducts dynamic analysis on classical VirusShare and Advanced Persistent Threat (APT) samples and constructs an evaluation dataset based on the authoritative malware analysis platform HybridAnalysis. Experimental results show the effectiveness of the method.},
  archive      = {J_SUPERC},
  author       = {Guo, Wenjie and Xue, Jingfeng and Liu, Zeyang and Han, Weijie and Hu, Jingjing},
  doi          = {10.1007/s11227-025-07545-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Malgta: Large language model-based guided malware tactical analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy security level metric of hybrid cryptosystem algorithms. <em>SUPERC</em>, <em>81</em>(9), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07547-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How securely cryptosystems encrypt files is an important question mark in today’s world. This study focused on defining a comprehensive fuzzy security metric for cryptosystems, especially AES (Advanced Encryption Standard)-RSA (Rivest–Shamir–Adleman) hybrid cryptosystem algorithms, using a multi-logic approach with different security parameters. Since every file has a different security level for a cryptosystem, the ANFIS methodology based on the dataset composed of 400 audio files, 400 texts, and 450 image files of different types and sizes as plaintext is applied for an overall evaluation pool for the hybrid algorithm. The proposed system results for the ECB (Electronic Codebook) and PCBC (Propagating cipher-block chaining) modes of the AES algorithm are also examined, and thus the system accuracy is demonstrated. Lastly, a graphical user interface application of the proposed system is developed, and its statistical validation is presented.},
  archive      = {J_SUPERC},
  author       = {Şimşek, Hakan and Öncel, Ömer Faruk},
  doi          = {10.1007/s11227-025-07547-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Fuzzy security level metric of hybrid cryptosystem algorithms},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locally weighted ensemble clustering based on grain distance. <em>SUPERC</em>, <em>81</em>(9), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07548-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of ensemble clustering is to produce more robust, higher quality clustering results by combining several different underlying clusterings. Removing low-quality base clusterings and assigning weights to clusters of different quality can obtain a more accurate ensemble solution. In order to solve this optimization problem, this paper proposes an ensemble strategy of constructing inter-cluster relations after screening the base clusterings. The algorithm consists of three main steps. The first step screens base clustering members by using group consistency measure. The second step evaluates the effectiveness of clusters by using granularity distance knowledge. The third step performs consistency ensemble clustering by two consensus functions. The proposed ensemble clustering algorithm changes the cluster evaluation metrics and removes the need for parameter adjustments during the construction of the metrics. It further compensates for the shortcomings of the single improvement algorithm. In addition, filtering base clustering by the concept of group consistency reduces redundant computation and provides a feasible solution for efficient ensemble clustering in large-scale data scenarios. Experiments on 10 real-world datasets and 2 synthetic datasets verify the accuracy and robustness of the algorithm.},
  archive      = {J_SUPERC},
  author       = {Sun, Yuan and Li, Lahuan and Ma, Binyao},
  doi          = {10.1007/s11227-025-07548-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Locally weighted ensemble clustering based on grain distance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic computational offloading approaches for IoT devices in cloud computing. <em>SUPERC</em>, <em>81</em>(9), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07551-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices (MDs) have become integral to everyday life due to advancements in the Internet of Things (IoT). Offloading complex tasks to cloud environments can leverage the cloud's computational resources to enhance the performance of IoT devices. However, challenges such as high communication costs, network congestion, and the need for low latency make real-time applications like image recognition and video streaming difficult to handle with cloud-only solutions. To address these challenges, we propose a novel computational offloading method specifically designed for IoT environments, which significantly improves efficiency and performance. The proposed approach incorporates a first-order Gauss–Markov and Minimum Mean Square Error estimation technique to optimize small- and large-scale fading estimation. To ensure efficient allocation of cloud resources, we introduce the Dynamic Collaborative Particle Swarm Offloading Optimization technique, which dynamically adjusts resource allocation based on real-time needs. Additionally, the method integrates multi-level blockchain-enabled data transmission to ensure secure and privacy-preserving data transfers. We also present the Lyapunov-Based Cooperative Deep Reinforcement Optimization (LCDRO) algorithm, which aims to minimize energy consumption and enhance decision-making. Furthermore, a mobility-aware Deep Reinforcement Learning technique is employed to optimize resource usage under varying conditions. The performance of the proposed method is demonstrated with qualitative data: The technique achieves a mean square error of 18.7 dB, a latency of 70 ms, energy consumption of 320 J, and a transmission delay of 84 ms for 50 tasks. When compared to existing methods such as DCOS and ADRLO, our approach shows superior efficiency, scalability, and reliability, making it well-suited for large-scale IoT applications. This study contributes to the development of cost-effective, resource-efficient offloading strategies for IoT devices in cloud computing environments.},
  archive      = {J_SUPERC},
  author       = {Albalawi, Nasser},
  doi          = {10.1007/s11227-025-07551-w},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic computational offloading approaches for IoT devices in cloud computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable two-branch network based on an prototype to promote group gene biomarkers discovery. <em>SUPERC</em>, <em>81</em>(9), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07554-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene biomarkers are invaluable for understanding medical mechanisms and targeting drugs. An effective interpretability method is to identify the key factors of gene biomarkers. Many interpretable methods in deep learning are based on layer-wise relevance propagation (LRP) that is particularly effective in MLP-based backbone networks, but it can only extract features for individual samples rather than group samples. While, what we want to get is the biomarkers for a kind of disease group, which can represent a disease mechanism, not those for a certain individual. So, we propose to use prototype of the ith category to denote the group features of the ith disease to find gene biomarkers of the category by LRP algorithm. Whereas LRP algorithm can find features, its accuracy is related to the classification efficiency. The higher classification accuracy is, it can find more accurate features based on LRP. Building on the aforementioned theory, in this paper, we propose a two-branch network architecture. The first branch is MLP architecture and primarily designed for identifying group gene biomarkers based on LRP, while the second branch focuses on enhancing classification efficiency, thereby supporting the first objective. In addition, to improve classification accuracy furtherly, we propose a cosine similarity loss based on two-branch network that can promote the two networks to extract more diverse and fine-grained features. To validate this idea, we construct two variants of the two-branch network: ConvAttMLP and scBERTMLP. Finally, we evaluate the networks and find 20 specificity biomarkers for IgAN disease subtype using our group LRP algorithm.},
  archive      = {J_SUPERC},
  author       = {Zheng, Fang and Zhao, Juanjuan and Gao, Yuanchen and Li, Yafeng and Li, Yaheng and Geng, Yan and Qiang, Yan and Zheng, Yifang},
  doi          = {10.1007/s11227-025-07554-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {An interpretable two-branch network based on an prototype to promote group gene biomarkers discovery},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial progress with quantum algorithms: An in-depth review. <em>SUPERC</em>, <em>81</em>(9), 1--55. (<a href='https://doi.org/10.1007/s11227-025-07555-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing (QC) is anticipated to provide significant computational advantages. It will aid in the solution of numerous difficult and computationally unsolvable issues across a wide range of application areas. The rise of commercial QC has sparked a renewed interest in quantum algorithm (QA) research. To customize effective quantum oracles to meet particular computing requirements, innovative QA is needed to take advantage of parallelism. The current article presents a comprehensive review of QA and its role in Industry 4.0. QA has applications in the fields of cryptography, search and optimization, quantum system simulation, and large-scale linear problem-solving. While previous reviews that focus just on algorithmic theory or specific domains, the current study provides a comprehensive viewpoint by combining a wide conceptual assessment with a scientometric analysis of 1165 QA related articles published between 2014 and 2023, as sourced from the Scopus database. Scientometric analysis shows the Document Co-citation Analysis, Countries Collaboration, and Burst Analysis of the aforementioned documents. The current article sheds light on the utilization of QA across diverse domains and offers valuable insights to enhance its effectiveness in various applications. Moreover, it identifies the top clusters derived from the scientometric study, and it would serve as focal points for future research.},
  archive      = {J_SUPERC},
  author       = {Sood, Sandeep Kumar and Singh, Manmohan and Bhatia, Munish},
  doi          = {10.1007/s11227-025-07555-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--55},
  shortjournal = {J. Supercomput.},
  title        = {Industrial progress with quantum algorithms: An in-depth review},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SQUAD: Software testing for quantum distributed learning software. <em>SUPERC</em>, <em>81</em>(9), 1--10. (<a href='https://doi.org/10.1007/s11227-025-07556-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern neural network research, quantum neural network (QNN) methodologies have been widely adopted due to their inherent quantum advantages. QNN architectures can be partitioned, with each segment distributed across multiple computing machines to preserve privacy-an approach referred to as quantum split learning. Although several novel QNN software testing techniques have been introduced, no methodology currently exists for testing quantum distributed learning software such as quantum split learning. To address this issue, this paper proposes a new software testing method for quantum distributed/split learning, named SQUAD. The proposed SQUAD automatically generates dummy code to complete QNN architectures across separate machines and subsequently performs software testing on all machines. Additionally, a graphical user interface (GUI) for SQUAD is implemented to demonstrate its novelty and feasibility.},
  archive      = {J_SUPERC},
  author       = {Park, Soohyun and Cho, Jae Hyun and Yook, Hyun Jun and Jhun, Ga San and Lee, Youn Kyu and Kim, Joongheon},
  doi          = {10.1007/s11227-025-07556-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--10},
  shortjournal = {J. Supercomput.},
  title        = {SQUAD: Software testing for quantum distributed learning software},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: FDAG-GAN: Frequency-domain attention-guided GAN with feature restoration for underwater image enhancement. <em>SUPERC</em>, <em>81</em>(9), 1. (<a href='https://doi.org/10.1007/s11227-025-07557-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Gu, Hangfan and Wang, Jue and Li, Bo and Li, Jinzhang},
  doi          = {10.1007/s11227-025-07557-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: FDAG-GAN: Frequency-domain attention-guided GAN with feature restoration for underwater image enhancement},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 3-path connectivity of the folded hypercube. <em>SUPERC</em>, <em>81</em>(9), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07558-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be a connected simple graph with vertex set $$V\left( G \right) $$ and edge set $$E\left( G \right) $$ . Let $$\Omega $$ be a subset of $$V\left( G \right) $$ with at least two vertices. A path containing all vertices of $$\Omega $$ is said to be an $$\Omega \text{- } \text {path}$$ of G. Two $$\Omega \text{- }$$ paths $${{P}_{1}}$$ and $${{P}_{2}}$$ of G are internally disjoint if $$E\left( {{P}_{1}} \right) \cap E\left( {{P}_{2}} \right) =\varnothing $$ . For an integer k with $$k\ge 2$$ , the $$k \text{- } \text {path} \text{- } \text {connectivity}$$ $${{\Pi }_{k}}\left( G \right) $$ is defined as $${{\Pi }_{k}}\left( G \right) =\min \left\{ {{\Pi }_{k}}\left( \Omega \right) \left| \, \Omega \subseteq V\left( G \right) \text { and }\left| \, \Omega \right| =k \right. \right\} $$ , where $${{\Pi }_{k}}\left( \Omega \right) $$ represents the maximum number of internally disjoint $$\Omega \text{- } \text {paths}$$ . In this paper, we determine the $$3 \text{- } \text {path} \text{- } \text {connectivity}$$ of the $$n \text{- } \text {dimensional}$$ folded hypercubes $$F{{Q}_{n}}$$ and prove that $$\Pi _3\left( FQ_n \right) =\lfloor \frac{3\left( n+1 \right) -1}{4} \rfloor \text { for }$$ all $$n\geqslant 2.$$},
  archive      = {J_SUPERC},
  author       = {Wang, Yi and Cheng, Dongqin},
  doi          = {10.1007/s11227-025-07558-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {The 3-path connectivity of the folded hypercube},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FIT4HPC?—Accelerating digital transformation by supercomputing opportunities. <em>SUPERC</em>, <em>81</em>(9), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07559-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance computing (HPC) plays a significant role in accelerating digital transformation and industry competitiveness, enabling high-speed data processing and complex simulations through supercomputers, while cloud services make HPC infrastructure affordable and accessible to SMEs. This research examines the potential for cloud HPC adoption in Montenegro, focusing on SME and IT companies as key drivers of digital innovations. Using the HPC4SME Automated Assessment Tool, a multi-criteria decision-making model, and SPSS statistical analyses, the study evaluates company readiness, cloud potential, and HPC performance. Findings indicate that companies are ready for HPC adoption driven by positive business outlook, increasing demand for HPC expertise, high cloud potential, and encouraging development in HPC critical simulations, especially in the IT sector. However, the study’s limitations, including a relatively small market sample, highlight the need for further research into sector-specific trends and structural barriers while emphasising practical drivers and policy insights to advance HPC adoption among SMEs.},
  archive      = {J_SUPERC},
  author       = {Nikolic, Sanja and Filipovic, Luka and Ilijas, Tomi and Vukotic, Milica},
  doi          = {10.1007/s11227-025-07559-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {FIT4HPC?—Accelerating digital transformation by supercomputing opportunities},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAF-DETR: Enhancing UAV image detection with partial attention and dynamic feature integration. <em>SUPERC</em>, <em>81</em>(9), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07561-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With its superior maneuverability and flexibility, the unmanned aerial vehicle (UAV) is able to effortlessly tackle various complex scenarios and challenges. However, due to their small size, limited information, and severe occlusion, the subtle features and semantic information of small objects in UAV images are prone to being lost. This paper proposes partial attention fusion-based detection transformer (PAF-DETR) tailored specifically for enhancing small object detection in UAV images, which employs partial attention fusion module to capture potential small object regions, enhances feature connections through the integration of feature alignment module and CSP-Rep fusion module, and incorporates dynamic upsampling module. First, the extracted features from the backbone are input into attention-driven context-aware encoder and auxiliary branch. Second, within the encoder, attention-based internal scale interaction mechanism is specifically applied to the highest-level feature. Then, a bidirectional fusion strategy is adopted to fuse high-level semantic details with low-level features, while dynamically refining sampling points through dynamic upsampling module. Additionally, it propagates the detailed information from low-level feature to high-level feature. Third, feature alignment module in the auxiliary branch employs dynamic upsampling module to align the features obtained from the backbone’s last three stages, and CSP-Rep fusion module injects them into the corresponding features processed by the encoder. Finally, the decoder and head generate precise category probabilities, and bounding box coordinates as the final detection predictions. The PAF-DETR-50 excels on the VisDrone dataset, achieving a mAP50-95 of 31.3% and a mAP50 of 52%, showcasing its potency in small object detection. Available here is the code: https://github.com/lei12879/PAF-DETR .},
  archive      = {J_SUPERC},
  author       = {Lei, Huan and Ren, Lingfei and Wu, Ze and Yang, Wenyuan},
  doi          = {10.1007/s11227-025-07561-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {PAF-DETR: Enhancing UAV image detection with partial attention and dynamic feature integration},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating the solutions of fractional differential equations with a novel and more efficient iteration procedure. <em>SUPERC</em>, <em>81</em>(9), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07562-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new iterative method to find fixed points of contractive mappings in uniformly convex Banach spaces. The method is proven to be stable and shows faster convergence than existing methods by Thakur, Piri, Ullah, and Harmouchi, as demonstrated through numerical examples and MATLAB plots. A detailed comparison highlights how different parameters affect convergence. We also establish a new result on data dependence using an approximate operator. Finally, the method is applied to solve a Caputo-type fractional differential equation, relevant to real-world problems in viscoelasticity, anomalous diffusion, and electrical circuits.},
  archive      = {J_SUPERC},
  author       = {Alam, Khairul Habib and Rohen, Yumnam and Tomar, Anita},
  doi          = {10.1007/s11227-025-07562-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Approximating the solutions of fractional differential equations with a novel and more efficient iteration procedure},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFMD: Attention fusion-based multiscale decomposition network. <em>SUPERC</em>, <em>81</em>(9), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07565-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting remains a critical task in domains such as energy, power systems, and finance. Although MLP-based models provide lightweight and efficient alternatives to recurrent and attention-based networks, they struggle with capturing temporal dependencies and multiscale dynamics. To address these issues, this paper proposes a novel time-series forecasting framework based on Adaptive Attention Fusion and Multiscale Decomposition (AFMD), built upon a Multi-Layer Perceptron (MLP) architecture. This model innovatively integrates multiscale signal decomposition techniques with a dual-dependency attention mechanism, creating a hierarchical paradigm for temporal feature learning. First, a multi-resolution downsampling strategy is employed to decompose the original time series into subsequences with distinct dynamic characteristics. Next, a parameter-shared sparse gated multi-head attention mechanism is introduced at the subspace level to enable fine-grained modeling of cross-scale temporal patterns. Building on this, a multimodal feature fusion mechanism and dynamic weighted predictor are designed to achieve collaborative optimization of multi-granularity features and probabilistic integration of forecast results through an adaptive gating network. Extensive evaluation on eight real-world datasets demonstrates that the proposed model exhibits outstanding efficiency across various performance metrics, and ablation experiments further validate the effectiveness of the proposed modules.},
  archive      = {J_SUPERC},
  author       = {Yang, Ruidi and Mao, Yuxing and Yan, Hengyu and Wei, Zijie and Li, Jian and Pan, Jianyu},
  doi          = {10.1007/s11227-025-07565-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {AFMD: Attention fusion-based multiscale decomposition network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain-enabled encrypted neural network framework for trust-aware key management and node authentication in industrial internet of things. <em>SUPERC</em>, <em>81</em>(9), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07566-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things (IIoT) introduces complex security challenges in key management due to its distributed architecture and resource-constrained nodes. This paper presents a novel blockchain-enabled key management framework designed to ensure decentralized, tamper-resistant, and scalable security across the IIoT network. The system combines Elliptic Curve Cryptography for easy key creation with smart contracts on a private Ethereum blockchain to allow safe key sharing and management throughout its lifecycle. We also present a way to verify the identity of nodes that takes trust into account, using a Graph Convolutional Network improved with the Ranger optimizer to make it work better and more reliably—something that hasn’t been done before in IIoT security systems. Tests using the X-IIoTID dataset, which includes different types of IIoT traffic during normal and attack situations like spoofing and injection, show that the system reaches 98.9% accuracy in authentication while keeping response times low and processing speeds high. The framework effectively mitigates Sybil and replay attacks, providing a scalable and secure solution that improves both trust and performance in distributed IIoT environments, reinforcing secure industrial data exchange.},
  archive      = {J_SUPERC},
  author       = {Dwivedi, Abhishek and Agarwal, Ratish and Yahya, Mohammad and Alduaiji, Noha and Shukla, Piyush Kumar},
  doi          = {10.1007/s11227-025-07566-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A blockchain-enabled encrypted neural network framework for trust-aware key management and node authentication in industrial internet of things},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WTDL-net: Medical image registration based on wavelet transform and multi-scale deep learning. <em>SUPERC</em>, <em>81</em>(9), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07567-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) medical image registration has drawn substantial research attention. In comparison to traditional approaches, deep learning techniques present significant advantages in terms of speed and accuracy. However, large deformations and complex transformations pose challenges for single-modality image registration. In this study, we propose WTDL-Net, a multi-scale registration network incorporating wavelet transform. First, low-frequency sub-images generated by WT at various resolutions are used as inputs to the multi-scale registration network. Coarse-to-fine registration is achieved by analyzing image information at different resolutions. Second, the high-frequency components derived from the WT are combined to create a high-frequency infographic. This Infographic is applied to constrain multi-level registration, thereby enhancing the optimization of registration details. The proposed approach outperforms existing deep learning-based registration techniques, as shown through comprehensive quantitative and qualitative evaluations on four MR brain scan datasets.},
  archive      = {J_SUPERC},
  author       = {Chu, BoHua and Zhang, BaoJu and Zhang, Bo and Zhang, CuiPing},
  doi          = {10.1007/s11227-025-07567-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {WTDL-net: Medical image registration based on wavelet transform and multi-scale deep learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person retrieval with implicit relation alignment and contrastive learning. <em>SUPERC</em>, <em>81</em>(9), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07568-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person retrieval aims to identify the target person based on a given textual description query. The primary challenge is to learn the mapping of visual and textual modalities into a common latent space. Most existing methods rely on explicit local parts to simulate fine-grained correspondences between modalities, often lacking context information or introducing potential noise. Additionally, visual and textual features are separately extracted using pre-trained unimodal models, resulting in poor matching performance for multimodal data due to insufficient foundational alignment capabilities. To address these issues, we propose an innovative text-to-image person retrieval method, named text-to-image person retrieval with Implicit Relation Alignment and Contrastive Learning, IRACL for short, to combine implicit relationship alignment and contrastive learning. Specifically, the implicit relationship alignment module enhances the matching ability of multimodal data by mining hidden associations between multimodal data. Moreover, the contrastive learning module learns the similarity and dissimilarity between multimodal samples to extract more useful feature representations, thereby enhancing the semantic alignment capability. Our innovative framework demonstrates significant improvements over previous methods on three public datasets, marking notable progress in the task of visual-textual person retrieval.},
  archive      = {J_SUPERC},
  author       = {Shui, Xiangyu and Zhu, Zhenfang and Liu, Yun and Pei, Hongli and Li, Kefeng and Zhang, Huaxiang},
  doi          = {10.1007/s11227-025-07568-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Text-to-image person retrieval with implicit relation alignment and contrastive learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCB routing on unstructured meshes with conflict-based search. <em>SUPERC</em>, <em>81</em>(9), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07569-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In electronic design automation (EDA), routing for printed circuit boards (PCBs) is a critical and challenging task. As component density increases, traditional grid-based routing methods face challenges in both efficiency and success rates. To address this, we propose an enhanced conflict-based search (CBS) algorithm applied to Delaunay grids, termed UGPCB-CBS. We treat the routing problem as a specialized multi-robot path-planning issue, using the CBS algorithm on unstructured grids to improve efficiency and success rates. Our method incorporates map modeling that combines artificial potential field path generation with Delaunay triangulation, effectively handling complex obstacle recognition and avoidance. Tests on open-source datasets show that compared to existing PCB routers, our approach offers advantages and potential in execution speed and routing outcomes. This research extends robot path planning to the EDA domain, providing new perspectives and solutions for PCB routing.},
  archive      = {J_SUPERC},
  author       = {Cao, Jianhao and Cai, Hao and Xu, Ning},
  doi          = {10.1007/s11227-025-07569-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {PCB routing on unstructured meshes with conflict-based search},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSTF: Enhancing long-term forecasting with multi-scale temporal fusion in time series forecasting. <em>SUPERC</em>, <em>81</em>(9), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07572-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term time series forecasting plays a vital role in applications like financial market prediction, energy usage forecasting, and traffic flow analysis. Deep learning models, though widely used in this task, often struggle to capture long-term dependencies and periodic patterns due to the overlapping of variables with different periods. To this end, we propose a multi-scale temporal fusion model named MSTF, which extracts sequential features and periodic patterns across multiple scales using a Time Reverse and Transform block and a Dynamic Combination Reconstruction block. Unlike traditional Transformer-based models, MSTF emphasizes overall temporal continuity rather than individual time point values. Experiments on seven datasets against ten advanced models demonstrate MSTF’s superior performance, faster training time, and reduced model complexity, particularly excelling on high-dimensional datasets.},
  archive      = {J_SUPERC},
  author       = {Zhou, Chengjie and Jiang, Ke and Liu, Yunjiong and Che, Chao and Zhang, Qiang},
  doi          = {10.1007/s11227-025-07572-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {MSTF: Enhancing long-term forecasting with multi-scale temporal fusion in time series forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum chaotic techniques for medical image encryption in next-generation IoMT applications. <em>SUPERC</em>, <em>81</em>(9), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07574-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel Quantum Chaotic Image Encryption (QCIE) framework designed to enhance the security of medical images in Internet of Medical Things (IoMT) applications. The proposed method integrates quantum key generation and chaotic transformations to achieve high encryption strength while maintaining computational efficiency. A two-step process is employed: first, a quantum-generated key ensures unpredictability and resistance to quantum attacks; second, pixel scrambling using the 2D Logistic-Sine Coupled Map (2D-LSCM) enhances confusion and diffusion. Experimental results demonstrate the framework’s robustness, with an entropy of 7.9992, NPCR of 99.63%, and UACI of 33.53%, confirming strong resistance to statistical and differential attacks. Additionally, the method achieves fast encryption/decryption times (e.g., 1.18 s for 425 × 425 images), making it suitable for real-time IoMT applications. Comparative analysis with state-of-the-art techniques shows superior performance in correlation reduction and computational efficiency. The framework ensures lossless decryption, preserving diagnostic quality, and addresses the limitations of existing methods by balancing security, speed, and adaptability for resource-constrained IoMT devices.},
  archive      = {J_SUPERC},
  author       = {Guitouni, Zied and Zayani, Hafedh Mahmoud},
  doi          = {10.1007/s11227-025-07574-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Quantum chaotic techniques for medical image encryption in next-generation IoMT applications},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing temporal knowledge graph completion with counterfactual insights. <em>SUPERC</em>, <em>81</em>(9), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07579-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity and temporal nature of real-world data, temporal knowledge graph completion has emerged as a research hotspot. This paper introduces a novel approach named temporal counterfactual augmentation (TCA) to address the challenges of temporal knowledge graph (TKG) completion, particularly the issues of temporal dynamics and data scarcity. Specifically, our TCA method leverages counterfactual augmentation to model the temporal community structure and its impact on entity relationships, thereby significantly enhancing the model’s ability to predict missing temporal links. By constructing “what-if” scenarios, our method provides a deeper understanding of TKGs, resulting in improved predictive performance and a more nuanced representation of temporal changes. Extensive experimental evaluations validate the effectiveness of our TCA approach, demonstrating its robustness to data sparsity and noise, as well as its clear superiority in TKG completion tasks.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yue and Ma, Guodong and Sun, Li and Xu, Di and Pang, Shengnan and Yang, Fuqiang},
  doi          = {10.1007/s11227-025-07579-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing temporal knowledge graph completion with counterfactual insights},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum-driven security evolution in IoT: AI-powered cryptography and anomaly detection. <em>SUPERC</em>, <em>81</em>(9), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07582-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of the Internet of Things (IoT) has introduced significant cybersecurity and computational challenges that exceed the capabilities of traditional security mechanisms. This study presents a quantum–classical hybrid security model that enhances anomaly detection, encryption, and predictive maintenance in IoT networks. By integrating quantum key distribution (QKD), post-quantum cryptography (PQC), and quantum machine learning (QML), the proposed approach strengthens threat detection and ensures secure communication. Experimental validation using noisy intermediate-scale quantum (NISQ) devices and IBM quantum simulators demonstrates a 98.7% anomaly detection accuracy, an 80% reduction in latency, and a 3.9% false-positive rate, significantly outperforming traditional AI-based intrusion detection models. The quantum federated learning (QFL) framework further enhances decentralised AI accuracy by 14.5%, while QKD improves encryption resilience by increasing the secure key rate by 500%. The model’s ability to reduce training time by 50% and enhance energy efficiency by 225% makes it scalable for real-time IoT deployments. The proposed security model has wide-ranging implications for industries reliant on IoT networks, such as healthcare, smart cities, and industrial automation, where real-time anomaly detection and secure communication are critical. Organisations deploying IoT infrastructure can leverage quantum-enhanced security to mitigate evolving cyber threats, reduce operational risks, and ensure compliance with future post-quantum cryptographic standards. This research establishes a quantum-secured IoT ecosystem, reinforcing post-quantum encryption and real-time quantum security analytics to mitigate evolving cyber threats. Future directions will explore quantum homomorphic encryption (QHE), zero-trust security architectures (ZTSA), and adaptive quantum AI models, ensuring the practical deployment of quantum-enhanced cybersecurity solutions. The findings highlight quantum methodologies as a scalable, computationally efficient, and high-accuracy approach to securing next-generation IoT environments.},
  archive      = {J_SUPERC},
  author       = {Mujlid, Hana Mohammed and Alshahrani, Reem},
  doi          = {10.1007/s11227-025-07582-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Quantum-driven security evolution in IoT: AI-powered cryptography and anomaly detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCE-net: Single-image deraining with adaptive normalization and multi-scale feature integration. <em>SUPERC</em>, <em>81</em>(9), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07603-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing single-image deraining methods still struggle with the complex effects of raindrops on transparent surfaces like glass, camera lenses, and other optical components. This paper proposes a novel single-image deraining algorithm using a multistage recursive network to effectively separate the raindrop layer from the background layer on transparent surfaces. The proposed network includes multiple basic layers, each incorporating a revised layer normalization module to standardize multi-scale features across different data distributions, enhancing generalization and adaptability to real-world scenarios. GCE-Net includes an adaptive feature fusion module (SK Fusion) to integrate features from different levels and suppress redundancy, while the multilayer perceptron module enhances nonlinear feature representation. A gating mechanism is introduced to enhance flexibility, and combined with a recursive structure, it captures dependencies among deep features, significantly improving deraining performance. We trained the model on the Raindrop dataset and tested it on both the Raindrop and SPA-Data datasets. The raindrop dataset targets raindrops on transparent surfaces with diverse shapes and complex scenes. GCE-Net shows excellent performance in PSNR (34.14) and SSIM (0.969) metrics, effectively restoring background information while minimizing raindrop impact on image quality. The proposed algorithm provides an efficient and robust baseline for image deraining on transparent surfaces, demonstrating potential for practical applications in real-time video surveillance systems and large-scale image processing pipelines that require HPC infrastructure to handle high-throughput data streams. Leveraging depthwise separable convolutions, the model achieves a runtime of 4.389 ms on high-end GPUs, balancing deraining quality (PSNR 34.14) with real-time efficiency, making it suitable for supercomputing-accelerated edge-cloud collaborative frameworks.},
  archive      = {J_SUPERC},
  author       = {Jin, Tianchun and Zhang, Jindong and Qin, Guihe and Mingzhou, Ma},
  doi          = {10.1007/s11227-025-07603-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {9},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {GCE-net: Single-image deraining with adaptive normalization and multi-scale feature integration},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel particle swarm optimization with individual-based adaptive learning strategy for numerical optimization. <em>SUPERC</em>, <em>81</em>(8), 1--67. (<a href='https://doi.org/10.1007/s11227-025-07352-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, aiming at further strengthening the capability of particle swarm optimization (PSO) algorithm to deal with the search dilemmas, that is, premature convergence and stagnation, a novel variant of PSO is proposed by devising an individual-based adaptive learning strategy. In this new strategy, to ensure the search efficiency of particle and ameliorate the robustness and adaptivity of algorithm for various search environments and stages well, the search status of every particle is first measured by its update situation, and two special pools of velocity updating formulas are accordingly designed for different search requirements characterized by fitness and/or diversity. Also, Q-learning technique is then employed to dynamically choose the suitable formula among the corresponding pool for each particle to find its new position. Therefore, this strategy can adaptively assign the proper search formula for different particles. Moreover, in order to maintain the vitality of population during the whole search process, a population restart mechanism based on random opposition learning is further introduced, where the stagnant particles are greedily replaced with the randomly ones generated by the personal historical best positions. Resultantly, the proposed algorithm can effectively improve the performance of the algorithm. Finally, a series of ablation and comparison experiments are conducted on the IEEE CEC2017 benchmark functions, and the numerical results demonstrate the effectiveness and superiority of the proposed strategy and algorithm.},
  archive      = {J_SUPERC},
  author       = {Liu, Peiwen and Tian, Mengnan and Wang, Xinduan},
  doi          = {10.1007/s11227-025-07352-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--67},
  shortjournal = {J. Supercomput.},
  title        = {A novel particle swarm optimization with individual-based adaptive learning strategy for numerical optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient program optimization through knowledge-enhanced LoRA fine-tuning of large language models. <em>SUPERC</em>, <em>81</em>(8), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07378-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source code optimization enables developers to enhance programs at the human–computer interaction level, thereby improving development efficiency and product quality. With the rise of large language models (LLMs), fine-tuning and prompting have become mainstream solutions for this task. However, both approaches present challenges: fine-tuning is resource-intensive due to the exponential growth in the scale of LLMs, whereas prompting, although resource-efficient, struggles to generate high-quality optimized programs. In this paper, we present CodeOPT, a LoRA-driven approach for fine-tuning LLMs to optimize C/C++ code. Instead of fine-tuning all LLM parameters, CodeOPT leverages LoRA to fine-tune only an optimization adapter, significantly reducing the number of trainable parameters. Additionally, we incorporate prior optimization knowledge during fine-tuning and introduce optimization-based instruction fine-tuning, enabling LLMs to effectively learn from external knowledge sources to improve program optimization. To evaluate the effectiveness of CodeOPT, we benchmarked it against several baselines on challenging programming tasks from different code completion platforms. Experimental results demonstrate that CodeOPT outperforms all baselines, including the state of the art, while keeping modifications to the original program minimal.},
  archive      = {J_SUPERC},
  author       = {Xu, Caixu and Guo, Hui and Cen, Caicun and Chen, Minglang and Tao, Xiongjie and He, Jie},
  doi          = {10.1007/s11227-025-07378-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Efficient program optimization through knowledge-enhanced LoRA fine-tuning of large language models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leech growth algorithm: A new meta-heuristic algorithm. <em>SUPERC</em>, <em>81</em>(8), 1--92. (<a href='https://doi.org/10.1007/s11227-025-07387-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new nature-inspired meta-heuristic algorithm, the Leech Growth Algorithm (LGA), is proposed and thoroughly tested to provide an alternative optimization method for solving practical engineering problems. LGA is inspired by the developmental processes of leeches in nature, including random movements, foraging, nesting, and mating behavior. A unique maturation factor is introduced to simulate the developmental process of leeches, while the maturation factor is also used to balance exploration and exploitation. In the exploration phase of LGA, leeches randomize movement and foraging; in the exploitation phase, leeches nesting, and mating. At the same time, the maturation factor of the leeches causes LGA to shift from exploration to exploitation. In addition, theoretical analysis and experiments have led to the conclusion that the maturation factor can be used as a flexible and practical new threshold conversion mechanism for meta-heuristic algorithms. LGA is experimentally and analytically compared with other excellence optimizers through experimental and analytical comparisons on 41 benchmark functions as well as 4 engineering problems and 1 scheduling problem. The results show that LGA outperforms the tested competitors in solving benchmark functions and engineering problems in general, validating the utility of the proposed optimizer in solving challenging real-world problems.},
  archive      = {J_SUPERC},
  author       = {Wu, Jin and Su, Zhengdong and Luo, Wenxuan},
  doi          = {10.1007/s11227-025-07387-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--92},
  shortjournal = {J. Supercomput.},
  title        = {Leech growth algorithm: A new meta-heuristic algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deterministic approach to modelling the dynamics of vulnerabilities, cyberattacks, and security hardening using Lotka–Volterra equations. <em>SUPERC</em>, <em>81</em>(8), 1--47. (<a href='https://doi.org/10.1007/s11227-025-07393-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving cybersecurity landscape, comprehending the dynamic interactions among system vulnerabilities, cyberattacks, and security hardening measures is essential for building resilient systems. Cyber-ecosystems exhibit inherent complexity, characterized by nonlinear feedback loops, adaptive adversaries, and evolving defences. This study proposes a deterministic mathematical framework, grounded in the Lotka–Volterra equations, to model these dynamics, conceptualizing vulnerabilities as "prey", cyberattacks as "predators", and security hardening as a regulatory "third species" that suppresses both vulnerabilities and attacks. By adapting this ecological model, the study captures the competitive and symbiotic relationships driving cybersecurity environments, incorporating parameters such as vulnerability discovery rates, attack sophistication, and the efficacy of security measures. The Systemic Behavioural Analysis section investigates emergent behaviours, including phase transitions between stable and chaotic states, hysteresis effects in response to parameter changes, and bifurcations that arise from delayed hardening efforts. These qualitative insights are juxtaposed with the quantitative findings from the Deterministic Analysis, which employs Jacobian matrices, eigenvalue stability criteria, and Lyapunov exponents to identify equilibrium points and classify system trajectories. Key regimes—such as the Optimum Ecosystem (balanced coexistence), Extinction Status (collapse of vulnerabilities/attacks), and Enhancement Status (runaway growth of threats)—are rigorously mapped through phase-space curves and validated via Runge–Kutta discretization. A critical contribution of this work lies in reconciling systemic behavioural predictions with deterministic results. For instance, the Systemic Analysis hypothesizes that delayed security interventions could destabilize the system, a claim quantitatively confirmed by Lyapunov stability metrics showing sensitivity to hardening response times. Similarly, phase-space plots corroborate the Systemic Analysis’s prediction of oscillatory dynamics under high attack rates. This synergy between qualitative and quantitative methods strengthens the model’s predictive power.},
  archive      = {J_SUPERC},
  author       = {Atıcı, Sinan and Tuna, Gurkan},
  doi          = {10.1007/s11227-025-07393-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {A deterministic approach to modelling the dynamics of vulnerabilities, cyberattacks, and security hardening using Lotka–Volterra equations},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MixeRF: Neural radiance fields with multi-dimensional feature mixing capability. <em>SUPERC</em>, <em>81</em>(8), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07441-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural radiance fields (NeRFs) revolutionized 3D reconstruction by learning continuous scene representations from sparse 2D images, yet face two limitations: (i) inadequate modeling of channel–space interactions by MLP-based architectures and (ii) ineffective use of collective supervision information between distant pixels in the optimization process. To address these challenges, we propose mixed feature radiance field (MixeRF), which combines multi-resolution hash encoding with a multi-dimensional feature interaction network. The hierarchical hash table improves the training efficiency, while the cross-feature mechanism enhances the channel–space interdependence for fine scene detail recovery. We further design distribution-aligned normal distribution residual loss based on distributional alignment to perform global pixel supervision by predicting the minimization of the distributional distance between residuals and Gaussian noise. To balance optimization stability with reconstruction quality, we introduce a smooth approximation technique for differentiable loss function fine-tuning. Experiments on mixed indoor/outdoor datasets demonstrate consistent performance gains: +2.13 dB higher PSNR than Nerfacto on the Lego dataset and 2.2 dB higher PSNR than Instant-NGP on the Fern dataset. The smooth approximation technique incurs merely 1.15 dB average cross-dataset PSNR degradation (range: 0.06–0.96 dB) while preserving optimization stability.},
  archive      = {J_SUPERC},
  author       = {Chai, Jinhao and Shen, Jingfang},
  doi          = {10.1007/s11227-025-07441-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {MixeRF: Neural radiance fields with multi-dimensional feature mixing capability},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPU optimizations to accelerate an image enhancement algorithm. <em>SUPERC</em>, <em>81</em>(8), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07447-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of images captured in challenging environmental conditions, such as nighttime or low illumination, is often compromised. Low-light images captured in non-uniform illumination environments contain a compressed dynamic range that can be improved to expose more detail and information. Many enhancement algorithms exist for low-light or dark images, but some are computationally intensive, making them difficult to use in real-time scenarios. Unsharp masking is a popular algorithm that enhances details and edges in images. For example, an algorithm incorporates local and global enhancements, including color space conversions from RGB to HSV and back, unsharp masking, and histogram equalization. However, runtime profiling revealed that unsharp masking is computationally expensive, taking up to 75% of the runtime. To address this issue, the unsharp masking steps were implemented on GPU hardware using a straightforward method, with each thread computing a single output to leverage its parallelization power. Subsequently, we analyzed the runtime and identified optimal optimization combinations that leverage shared memory, registers, and changing thread workloads to enhance communication efficiency within the GPU. For a filter size $$5\times 5$$ , our experimental results showed a speedup of up to $$16.36\times$$ at the kernel level and $$3.5\times$$ at the application level using GPU optimization techniques compared to the CPU platform.},
  archive      = {J_SUPERC},
  author       = {Daemdoost, Amin and Shahbahrami, Asadollah and Noorpoor, Hesam and Esmi, Nima and Hassanpour, Reza},
  doi          = {10.1007/s11227-025-07447-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {GPU optimizations to accelerate an image enhancement algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-branch semantic segmentation method for autonomous driving. <em>SUPERC</em>, <em>81</em>(8), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07453-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation provides technical support for automatic road sensing, and widely used in autonomous driving. However, when faced complex road scenes, existing segmentation methods still have problems such as insufficient learning of contextual information, inability to accurately segment multi-scale targets, and inaccurate segmentation of edge regions. To address these problems, we developed a multi-branch semantic segmentation method with CNN and Transformer (MBFormer). First, an exponentially weighted strip-window fusion pooling method in the CNN feature extraction stage was used to enhance the contextually important feature representation, enhance the long-distance dependencies, and expand the sensory field through a long and narrow kernel aggregation method. Then, cross-resolution multi-scale attention was used in the transformer feature extraction stage to fuse high and low resolution information to fully capture multi-scale information and enhance the segmentation capability of multi-scale targets. Finally, to solve the problem of inaccurate target edge segmentation, a branch based on boundary prediction was designed, and a boundary-aware module was used to establish the mapping relationship between pixels at different locations to fully capture the boundary information. Experiments were conducted on the Cityscapes and ACDC road datasets, and the mIoU of MBFormer achieved nearly 2% improvement compared to current mainstream segmentation models.},
  archive      = {J_SUPERC},
  author       = {Zhao, Huaqi and Lu, Zhengguang and Zhang, Songnan and Peng, Xiang and Li, Guojing},
  doi          = {10.1007/s11227-025-07453-x},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {A multi-branch semantic segmentation method for autonomous driving},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node-disjoint paths in k-ary n-cube with optimal maximum path length. <em>SUPERC</em>, <em>81</em>(8), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07454-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-ary n-cube( $$Q_n^k$$ ) serves as a fundamental topology for interconnection networks in high-performance computing architectures. It has the advantages of high regularity, high fault tolerance, high bandwidth, low latency, and small network diameter. Disjoint paths can strengthen network robustness, efficiency, and reliability by offering multiple independent transmission options, and have received widespread attention. Recently, Lv et al. (J Parallel Distrib Comput 183:104761) proposed a method to construct 2n disjoint paths in $$Q_n^k$$ . However, the maximum path length, which is $$(n-1) \lfloor k/2 \rfloor + k - 1$$ , is not optimal. Since path length directly impacts the latency and efficiency of data transmission, in this paper, we further explore the algorithm. We aim to ensure that the maximum length of disjoint paths between any two nodes in $$Q_n^k$$ is at most $$n \lfloor k/2 \rfloor + 1$$ . This length is optimal, given that the diameter of the network is $$n \lfloor k/2 \rfloor$$ . Additionally, through simulation experiments, we compare the average path length and find that our algorithm outperforms the algorithm proposed by Lv et al. (J Parallel Distrib Comput 183:104761). We further apply the constructed disjoint paths to enhance fault-tolerant routing and data transmission.},
  archive      = {J_SUPERC},
  author       = {Xu, Yuanhang and Wang, Yan and Fan, Jianxi and Cheng, Baolei and He, Qi},
  doi          = {10.1007/s11227-025-07454-w},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Node-disjoint paths in k-ary n-cube with optimal maximum path length},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHAED-net: A lightweight multiscale hybrid attention encoder-decoder network for the efficient segmentation of industrial forging images. <em>SUPERC</em>, <em>81</em>(8), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07456-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient segmentation of the boundaries, shapes, and sizes of forgings is crucial for intelligent forging perception. Current image segmentation techniques frequently face challenges in achieving an effective balance between speed and accuracy. Moreover, these techniques often fail to adapt well to the complex working conditions and diverse scales of forgings. In this study, a lightweight multiscale hybrid attention encoder-decoder network (MHAED-Net) is designed for the efficient segmentation of industrial forging images. MHAED-Net is characterized by only 0.076 M parameters and 0.087 Giga Floating-point Operations Per Second. The model employs a novel multiscale hybrid attention block (MHAB) that integrates the convolution normalization activation block and the ShuffleNetV2 block to create an encoder-decoder network. The proposed MHAB integrates CNN-based and Transformer-based attention through a multi-branch fusion approach. It employs dilated convolutions for multi-scale feature learning and incorporates a Lightweight Transformer to capture long-range dependencies. MHAED-Net achieves a mean Intersection over Union of 94.82% and Dice Similarity Coefficient of 97.34% in the segmenting the FORSeg dataset. Extensive experimental results demonstrate that MHAED-Net achieves state-of-the-art performance under complex conditions and multi-scale scenarios, highlighting its significant potential for industrial applications.},
  archive      = {J_SUPERC},
  author       = {Wan, Miao and Lin, Y. C. and Li, Shu-Xin and Wu, Gui-Cheng and Zeng, Ning-Fu and Zhang, Song and Chen, Ming-Song and Li, Chao and Zhan, Xiao-Dong and Qiu, Yu-Liang},
  doi          = {10.1007/s11227-025-07456-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {MHAED-net: A lightweight multiscale hybrid attention encoder-decoder network for the efficient segmentation of industrial forging images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization-based noise filtering among user-centric tweets to improve predictions in recommendation system. <em>SUPERC</em>, <em>81</em>(8), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07457-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the exponential growth of social media platforms, user-generated content has emerged as a valuable resource for enhancing recommendation systems. However, the pervasive noise in user-centric tweets, stemming from irrelevant, ambiguous, or misleading information, continues to degrade the performance and reliability of such systems. To address this challenge, this paper proposes nuclear physics optimization algorithm (NPO) as the core contribution for effective noise filtering in tweet-based recommendation systems. The methodology begins with preprocessing the raw tweet data and extracting features that accurately reflect user preferences and interests. Central to our approach, the NPO algorithm is designed to dynamically adjust its parameters to identify and eliminate noisy tweets based on semantic similarity and domain relevance. By adaptively optimizing the filtering process, the NPO effectively tailors itself to the characteristics of the tweet dataset, leading to enhanced accuracy and reliability in movie recommendation outcomes. Experimental evaluations conducted on a real-world tweet dataset associated with the MovieLens dataset validate the superiority of the proposed approach. Notably, when integrated with a recurrent neural network (RNN) classifier, the system achieved impressive performance metrics, including an accuracy of 0.94, precision of 0.93, recall of 0.91, F1-score of 0.92, and a mean average precision (MAP) of 0.92. Comparative analyses against conventional baseline models highlight significant improvements in prediction accuracy and recommendation quality.},
  archive      = {J_SUPERC},
  author       = {Jain, Kirti and Jindal, Rajni},
  doi          = {10.1007/s11227-025-07457-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Optimization-based noise filtering among user-centric tweets to improve predictions in recommendation system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combinatorial test case prioritization method based on the quadratic network with wide multi-layer kernels. <em>SUPERC</em>, <em>81</em>(8), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07459-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing strength of combinatorial testing poses a significant challenge in managing the growing number of test cases within time and resource constraints. Prioritizing test cases in combinatorial testing aims to identify an optimal sequence for early fault detection. While the wide-kernel convolutional neural network (WCNN) has shown promise in this area, further improvements are necessary for more reliable results. This study introduces a novel prioritization approach for combinatorial testing utilizing the Wide-kernel Quadratic Convolutional Neural Network (WQCNN). Wide kernels are utilized to capture distant fault features by having a large receptive field. Quadratic neurons in neural networks facilitate nonlinear feature extraction, enhancing feature representation. An attention mechanism integrated into the quadratic convolutional neural network aims to model dependencies among distant parameters more effectively. Additionally, incorporating residual connections not only boosts the performance and generalization of deep neural networks but also improves gradient propagation efficiency. The model presented in this paper has undergone experimental validation, with results indicating that it significantly improves prioritization effectiveness and accelerates fault detection.},
  archive      = {J_SUPERC},
  author       = {Sheng, Yunlong and Zhuang, Xuye and Yin, Jiancheng and Zhang, Bowen and Yang, Siting},
  doi          = {10.1007/s11227-025-07459-5},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A combinatorial test case prioritization method based on the quadratic network with wide multi-layer kernels},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optical microscope algorithm with precise focusing strategy and migration strategy with application in 3D path planning. <em>SUPERC</em>, <em>81</em>(8), 1--75. (<a href='https://doi.org/10.1007/s11227-025-07460-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical microscope algorithm (OMA) has garnered significant attention due to its clear mechanism and effectiveness in solving various optimization problems. However, the approach demonstrates vulnerabilities to premature convergence and local solution attraction, particularly in complex, high-dimensional problem spaces. Therefore, this paper proposes OMA with a precise focusing strategy and migration strategy (PMOMA). Firstly, a multi-fusion strategy will be proposed to enhance the initial population quality. Secondly, an introduction of the precise focusing strategy enhances the exploration ability of the algorithm and accelerates convergence speed. Finally, introducing a migration strategy prevents the algorithm from falling into local optima, resulting in improved solution accuracy. To evaluate PMOMA’s performance, we compare it with 9 other algorithms in CEC 2017 benchmark functions, Virtual Library of Simulation Experiments, and NLtoolbox. Additionally, PMOMA was implemented for solving engineering applications and 3D path planning to further validate its effectiveness. Overall, PMOMA demonstrated superiority in both numerical benchmarks and practical experiments.},
  archive      = {J_SUPERC},
  author       = {Dai, Enhui and He, Zhenxue and Zhao, Xiaojun and Zhang, Xiaodan and Wang, Yijin and Wang, Xiang},
  doi          = {10.1007/s11227-025-07460-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--75},
  shortjournal = {J. Supercomput.},
  title        = {An optical microscope algorithm with precise focusing strategy and migration strategy with application in 3D path planning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A research landscape on formal verification of UML dynamic modeling. <em>SUPERC</em>, <em>81</em>(8), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07464-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formal verification of UML dynamic modeling is the key to ensuring the reliability of model-driven engineering (MDE) in complex systems. However, due to the lack of formal semantics in UML itself, the existing methods are still fragmented. This systematic literature review (SLR) analyzes 73 formal association studies of dynamic modeling through search, screening, and statistics, and discusses the progress, challenges, and applications of these studies in different models. The discussion in this paper addresses three important aspects: the dynamic modeling verification process with formalization and inference as the main stages, the role of metamodels in model formal verification, and verification methods combined with automated (or semiautomated) tools. In addition, this paper summarizes the technical shortcomings such as the complexity of model transformation and the bottleneck of tool performance. It proposes future research directions to solve the challenges of complex dynamic modeling.},
  archive      = {J_SUPERC},
  author       = {Wu, Runfang and Du, Ye and Tang, Yu},
  doi          = {10.1007/s11227-025-07464-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {A research landscape on formal verification of UML dynamic modeling},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Divergence measure of spherical fuzzy sets and their applications in MAGDM based on TOPSIS method. <em>SUPERC</em>, <em>81</em>(8), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07468-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spherical fuzzy set is a generalization of various fuzzy structures, including fuzzy sets, intuitionistic fuzzy sets, Pythagorean fuzzy sets, and picture fuzzy sets. The notion of the spherical fuzzy chi-square divergence measure was defined by the intuitionistic fuzzy chi-square divergence measure. In this paper, the concept of the chi-square divergence measure for spherical fuzzy sets is defined and some operational properties related to the definition are proposed. In addition, comparative analysis is conducted through simulation experiments and numerical examples with common distance measures and similarity measures. Based on this, a multiple-attribute group decision-making (MAGDM) method based on the TOPSIS method is proposed. Finally, the feasibility and reliability of the method are verified through an example of evaluating a food distribution center.},
  archive      = {J_SUPERC},
  author       = {Xu, Changlin and Yang, Rong and Shen, Juhong},
  doi          = {10.1007/s11227-025-07468-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Divergence measure of spherical fuzzy sets and their applications in MAGDM based on TOPSIS method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving non-cyclic dynamic multi-objective optimization problems via GRU prediction and multi-information hybrid exploration. <em>SUPERC</em>, <em>81</em>(8), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07471-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In non-cyclic dynamic multi-objective optimization problems, the non-cyclic nature of environmental changes may cause the Pareto optimal front (PF) to be different from historical times. In addition, changes may also occur on the Pareto optimal solutions set (PS). However, predictions based solely on a single space show lower accuracy due to insufficient information. Therefore, solving non-cyclic dynamic multi-objective optimization problems via gate recurrent unit (GRU) prediction and multi-information hybrid exploration (GPMHE) is designed to overcome the above challenges. In the objective space, the GRU-based prediction strategy (GP) captures patterns of population change, predicts its distribution in new environments, and subsequently maps the results to the decision space; The multi-information hybrid exploration strategy (MHE) takes the feature individual as the representative individual, adaptively guides the population evolution direction in the decision space, thereby enhancing the algorithm’s adaptability. Compared with five advanced algorithms on the non-cyclic dynamic benchmark test set (NCD), the proposed algorithm GPMHE has shown robust adaptation to dynamic environmental changes.},
  archive      = {J_SUPERC},
  author       = {Sun, Hao and Bai, Xiaochuang and Wang, Cong and Yang, He and Hu, Ziyu},
  doi          = {10.1007/s11227-025-07471-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Solving non-cyclic dynamic multi-objective optimization problems via GRU prediction and multi-information hybrid exploration},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFGIC-net: Diffusion feature-guided information complementary network for infrared and visible light fusion. <em>SUPERC</em>, <em>81</em>(8), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07476-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of preserving detailed information, such as target edges and textures, in multimodal image fusion, particularly for infrared and visible images. We propose the Diffusion Feature Guidance Network based on Information Complementarity (DFGIC-Net), which leverages diffusion features for enhanced multimodal fusion. The network consists of two main components: first, a strategy to generate diffusion features that balance multimodal information and enhance edge details, and second, a wavelet transform-based approach to decompose image features into high- and low-frequency components, which are then optimized through an Information Complement Enhancement Module (ICEM). This module bridges the semantic gap between modalities, ensuring comprehensive fusion of frequency and spatial domain information. Our Fusion-Guide Head combines these features with a learnable boundary enhancement strategy to produce fused images with sharp boundaries and high fidelity. Extensive experiments show that DFGIC-Net outperforms state-of-the-art fusion methods in multiple metrics and retains superior performance in downstream tasks, providing strong support for advanced visual applications. Our code will be available at https://github.com/ccnokk/DFGIC.},
  archive      = {J_SUPERC},
  author       = {Cui, Yekai and Duan, Peng and Li, Jinjiang},
  doi          = {10.1007/s11227-025-07476-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {DFGIC-net: Diffusion feature-guided information complementary network for infrared and visible light fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial training with borderline samples. <em>SUPERC</em>, <em>81</em>(8), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07477-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have achieved tremendous success in image classification tasks. However, CNNs are vulnerable to adversarial attacks, such as applying imperceptible perturbations on the legitimate images. To address the security threats posed by these adversarial attacks, many defense techniques have been proposed. Adversarial training has been shown to be effective in enhancing CNNs robustness against adversarial samples. However, the trade-off between robustness and classification accuracy in adversarial training cannot be overlooked. In this paper, we propose a novel approach to adversarial training that simultaneously trains the model using both real images and minimally perturbed borderline adversaries. These borderline adversaries were generated during the training process, using the shortest successful perturbations for each individual training sample at specific training states. Instead of training with a fixed $$\epsilon$$ that applies uniform perturbations to all training samples, this shortest successful perturbation is adaptive to the network’s training state and is automatically determined. The rationale behind this approach is that the decision boundary will be less distorted by these additional adversaries, which helps maintain the classification accuracy while improving adversarial robustness. Preliminary experiments conducted on Cholec80 dataset for surgical tool recognition showed that this method achieved 2–7% improvement in both adversarial robustness and accuracy compared to other adversarial training methods, while also reducing overlap in the classification regions after adversarial training.},
  archive      = {J_SUPERC},
  author       = {Ding, Ning and Möller, Knut},
  doi          = {10.1007/s11227-025-07477-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Adversarial training with borderline samples},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedSSU: Flexible and efficient decentralized unlearning for federated learning. <em>SUPERC</em>, <em>81</em>(8), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07478-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated unlearning (FU) is crucial for enforcing “the right to be forgotten” in federated learning (FL) by removing a participant’s data influence from the global model. Despite growing demand, existing FU methods are predominantly server-driven, leading to high computational costs and limited user control over data revocation. We propose FedSSU, a decentralized FU framework that enables efficient client-side unlearning. By leveraging saliency maps and similarity constraints, FedSSU precisely removes selected data subsets while reducing reliance on centralized computation. Additionally, we introduce FedSSU-Class, a lightweight extension for class-level unlearning, minimizing storage and communication overhead. Experiments on benchmark datasets show that FedSSU accelerates unlearning by up to 70–90 $$\times$$ compared to full retraining while preserving model utility and achieving comparable effectiveness. These results establish FedSSU as a scalable and practical solution for privacy-preserving unlearning in FL systems.},
  archive      = {J_SUPERC},
  author       = {Leng, Yuhe and Xu, Lei and Liu, Jianghua and Zhang, Xiaojun and Mei, Lin and Qu, Youyang and Xu, Chungen},
  doi          = {10.1007/s11227-025-07478-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {FedSSU: Flexible and efficient decentralized unlearning for federated learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FastMS-CDA: Speeding up adversarial sample generation with multistage diffusion model. <em>SUPERC</em>, <em>81</em>(8), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07480-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing prevalence of deep learning, the risk of adversarial attacks has become increasingly prominent. Among the many key challenges, the efficiency of adversarial sample generation remains an urgent problem, as most traditional attack methods suffer from high computational costs and long generation times. To address this limitation, we propose a novel adversarial attack framework based on a multistage diffusion model-FastMS-CDA. Unlike traditional diffusion attacks that uniformly inject perturbations across the entire denoising trajectory, FastMS-CDA divides the denoising process into multiple sub-stages, allowing perturbations to be injected at each stage. This design not only accelerates the sampling process, but also enhances the success rate of adversarial attacks. Furthermore, we have designed an evaluation metric aimed at dynamically balancing attack success rate and generation time, enabling flexible optimization for specific application needs, making FastMS-CDA both efficient and practical. Extensive experiments conducted on CIFAR-10, MNIST, SVHN, and ImageNet demonstrate the effectiveness of our method. On the MNIST dataset, FastMS-CDA generates each image in just 0.5 milliseconds while maintaining a high attack success rate, outperforming several state-of-the-art baseline methods in both effectiveness and efficiency.},
  archive      = {J_SUPERC},
  author       = {Zhu, Linying and Wang, Shanshan and Chen, Zhenxiang and Zhang, Yi},
  doi          = {10.1007/s11227-025-07480-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {FastMS-CDA: Speeding up adversarial sample generation with multistage diffusion model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resampling and weighted ensemble method for dynamic imbalance data stream classification. <em>SUPERC</em>, <em>81</em>(8), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07482-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance inevitably occurs in dynamic data stream scenarios and can pose tremendous challenges for data stream mining. To address these challenges, an adaptive resampling and weighted ensemble method (ARWE) is proposed in this paper. First, the dynamic subdivision Poisson resampling (DSPR) module in ARWE is developed to address the class imbalance problem in the data stream. DSPR combines local information from minority class samples with the imbalance rate to design a sample-weighting scheme that can enhance the visibility of minority class samples, particularly those at the boundaries. This approach ensures that the model pays more attention to minority class boundary samples. Second, to address drift, the detection mechanism is designed with a drift warning stage that extends the search for marginal samples when a drift warning occurs and recalculates the weights to cope with simultaneous changes in the data distribution and imbalance rate. Finally, the ensemble update and decision-making are achieved through a co-constructed weighting scheme that utilizes Hellinger distance and accuracy. To compare the proposed method with eight state-of-the-art methods, simulation experiments are conducted on 17 data streams with concept drift and class imbalance. The results demonstrate the superiority of the proposed model in handling dynamically unbalanced data streams.},
  archive      = {J_SUPERC},
  author       = {Zhang, Tuyi and Liu, Sanmin and Huang, Subin and Zhang, Ping and Chen, Xinquan and Zhu, Jian and Yu, Wentao},
  doi          = {10.1007/s11227-025-07482-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive resampling and weighted ensemble method for dynamic imbalance data stream classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view temporal graph neural network for numerous miniature cascade popularity prediction. <em>SUPERC</em>, <em>81</em>(8), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07484-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cascade popularity prediction is a fundamental technique for information propagation analysis in many social applications such as Twitter, Facebook, Weibo, etc. Recent investigations show that the majority of information propagation (> 61%) is contributed from numerous miniature cascades (cascade size < 25). However, existing prediction methods are usually size-sensitive and have the basis for predicting large-size cascades. This causes seriously incorrect predictions for numerous miniature cascade predictions. This is because miniature cascade suffers a feature starvation problem while large-size cascade has much more passing features. In this paper, we propose a novel cascade feature augmentation method, named CasMV, which introduces additional mutual information from a multi-view of the cascade. In detail, the first view is the cascade graph at the observing time. The second view is the cascade graph during the passing process. The last view is the user graph across the different cascades. After, a temporal fusion network is proposed to fuse the cascade features from the above views. At last, the fused cascade features are used to predict the future propagation size of each cascade. Experiments on real-world social graphs show that the proposed method achieves new state-of-the-art records under the scenario where miniature cascades dominate the data, obtaining approximately 5% improvements compared to peer methods. Moreover, the proposed method achieves competitive results in the general data environment compared to the SOTA methods. The source code of the work is available at https://github.com/subetter/CasMV.git .},
  archive      = {J_SUPERC},
  author       = {Wu, Yasu and Fu, Changlong and He, Zhenli and Huang, Wei and Xie, Cheng},
  doi          = {10.1007/s11227-025-07484-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Multi-view temporal graph neural network for numerous miniature cascade popularity prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UST-SU: A U-shaped video prediction network based on partial autoregression. <em>SUPERC</em>, <em>81</em>(8), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07486-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively managing temporal dependencies and capturing accurate spatial features are dual challenges in video prediction. Autoregressive models typically use shallow recursive networks with limited time-step horizons, while non-autoregressive models may overlook inherent temporal dependencies. To tackle these challenges, we introduce UST-SU, a U-shaped spatiotemporal simple unit network. UST-SU utilizes a multilayer interactive sampling architecture to extract challenging spatial features for shallow autoregressive networks. The fusion of multi-dimensional spatial features during image reconstruction preserves crucial region-specific information. Our spatiotemporal simple unit (ST-SU), focusing on encoding global spatiotemporal information, achieves a balance in subsequent memory flows. By discarding redundant information and incorporating early-stage details, ST-SU efficiently handles spatiotemporal sequence tasks, making it a suitable core unit for integration. Additionally, we propose a partial autoregressive strategy to broaden the temporal receptive field, preserving temporal dependencies discarded by non-autoregressive models. Across diverse video prediction benchmarks, UST-SU consistently outperforms previous state-of-the-art models.},
  archive      = {J_SUPERC},
  author       = {Cui, Zhaojun and Tian, Wei and Luo, Fan and Liu, Qi and Jiang, Shengqin},
  doi          = {10.1007/s11227-025-07486-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {UST-SU: A U-shaped video prediction network based on partial autoregression},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UCP: A unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment. <em>SUPERC</em>, <em>81</em>(8), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07487-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained large language models (LLMs) have been widely applied to natural language-based code generation. However, because code generation tasks are highly sensitive to structured information and exhibit diverse logical forms, directly adapting methods optimized for natural language tasks to code generation often proves less effective for open-source models. Conventional fine-tuning is generally limited to single, specific scenarios, while the standard Chain-of-Thought (CoT) approach differs from code in both expression and logical structure. Consequently, existing methods lack code-specific optimization strategies for downstream tasks. To address these issues, this paper leverages the unique logical interpretation and structured information of programming languages, specifically, pseudocode reflecting abstract syntax features, to construct a unified code generation framework called UCP, which integrates multi-task learning and enhanced alignment. The goal is to improve the code generation capabilities of open-source LLMs. By designing tasks that generate code from pseudocode, we build a multi-task dataset to jointly fine-tune LLMs and apply reinforcement learning(RL), optimizing a multi-task loss function to balance data distribution and task difficulty. We also establish consistent learning objectives at each stage through task-aligned training. Furthermore, focusing on code completion, we construct a multi-granularity code completion dataset—encompassing function-level, line-level, and token-level completions—for use in the RL phase. At the inference stage, we adopt a cyclic self-filling inference mechanism aligned with the completion task. We also design fill-in-the-blank tasks during pre-training to ensure alignment between the training and inference stages. The Qwen2.5-Coder-7B-Instruct model was post-trained using our proposed UCP, resulting in a HumanEval pass@1 metric improvement from 84.15 to 87.80% and a LiveCodeBench pass@1 metric increase from 25.4 to 27.2%, both surpassing other mainstream open-source models with similar parameter scales. By exposing intermediate pseudocode, UCP enhances interpretability and can benefit AI-powered IDEs (e.g., Cursor), improving developer trust and real-world usability.},
  archive      = {J_SUPERC},
  author       = {Wen, Yongjun and Cui, Zhihao and Liu, Yihao and Zhang, Zhao and Zhou, Jiake and Tang, Lijun},
  doi          = {10.1007/s11227-025-07487-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {UCP: A unified framework for code generation with pseudocode-based multi-task learning and reinforcement alignment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motif-based community detection in multiplex networks with edge deletion optimization. <em>SUPERC</em>, <em>81</em>(8), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07489-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex network analysis offers a powerful framework for exploring complex systems by capturing multiple modes of interaction or relationship types among entities. This study focuses on community detection within multiplex networks, aiming to uncover tightly connected groups of nodes that reflect the network’s multidimensional structure. Traditional network models primarily depend on pairwise connections, often neglecting higher-order structures that involve interactions among more than two nodes. Consequently, relying on a single structural perspective fails to fully capture the global characteristics of complex networks. To overcome this limitation, we propose a novel approach that integrates both low-order and high-order connections across all network layers into a unified proximity matrix. Specifically, we linearly combine the adjacency matrices, Jaccard similarity matrices, and motif-based adjacency matrices from each layer to construct a comprehensive similarity representation. This integration allows our method to capture both local and global structural features effectively. To further enhance community cohesion and detection accuracy, we introduce an edge pruning strategy that removes low-similarity connections, thereby reducing noise and redundancy. Finally, we apply Spectral Clustering (SPC) to the refined proximity matrix to identify communities. Experimental results on both synthetic and real-world datasets demonstrate that our method significantly outperforms existing approaches in terms of accuracy and robustness in community detection.},
  archive      = {J_SUPERC},
  author       = {Yang, Han and Hu, Siwei and Tang, Fengqin and Zhao, XueJing},
  doi          = {10.1007/s11227-025-07489-z},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Motif-based community detection in multiplex networks with edge deletion optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BPTCN: A low-latency branch prediction model based on temporal convolutional networks. <em>SUPERC</em>, <em>81</em>(8), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07490-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Branch prediction has remained one of the critical technologies in high-performance processors over the past three decades. However, recently proposed offline methods cooperating with TAGE-SC-L predictors (The state-of-the-art online branch predictor) exhibit deficiencies in both prediction accuracy and the dimensionality of input features. Therefore, we present BPTCN, a low-latency branch prediction model based on temporal convolutional networks (TCN) designed for practical on-chip implementation. BPTCN models branch prediction tasks through temporal convolutional networks and incorporates both global and local branch histories during training, enabling effective prediction of long history-dependent branches and Hard-to-Predict (H2P) branches that are sensitive to local history patterns. At runtime, BPTCN predicts a few H2P branches, while TAGE-SC-L predicts the remaining branches. Experimental results demonstrate that compared to the unlimited predictor MTAGE-SC (An impractical large-scale baseline), our method achieves an average reduction in Mispredictions Per Kilo Instructions (MPKI) of 4.4% (Under specific workloads, the maximum reduction reaches 10.0%, i.e., up to 10.0%.) on Spec2017 Integer benchmarks. When compared with state-of-the-art offline method BranchNet under equivalent storage overhead, it further reduces MPKI by 2.1% (and up to 6.1%). In the practical, resource-constrained variant Mini-BPTCN, compared to the 64KB TAGE-SC-L, this approach reduces the average MPKI of SPEC2017 by 9.9% (and up to 18.9%), with consistent but smaller improvements observed on SPEC2006 Integer workloads (an average of 5.1%, up to 18.9%), validating the architecture’s generalization capability. Even when compared to BranchNet with similar storage overhead, Mini-BPTCN achieves more than a 2.6% MPKI reduction on both SPEC2017 and SPEC2006 (with a maximum of 16.0%).},
  archive      = {J_SUPERC},
  author       = {Cai, Ye and Zhong, Jinghui and Chen, Guoliang and Liao, Hao},
  doi          = {10.1007/s11227-025-07490-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {BPTCN: A low-latency branch prediction model based on temporal convolutional networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAFFNet: A multi-modal adaptive feature fusion net for signal modulation recognition. <em>SUPERC</em>, <em>81</em>(8), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07492-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation recognition (AMR) is a fundamental process between signal detection and demodulation. Despite recent advances in deep learning-based AMR, existing methods often fail to maintain robustness in severe noise scenarios. To address this, we propose MAFFNet, a noise-robust multi-modal architecture that synergistically processes raw in-phase/quadrature (IQ) signals and derived amplitude/phase (AP) information through a dual-branch vision transformer-LSTM framework. Specifically, the modified vision transformer (ViT) branch employs localized attention mechanisms to reduce computational complexity, while the LSTM branch incorporates phase-difference attention to model temporal dependencies in AP information. Additionally, a learnable feature fusion module with element-wise weights dynamically combines multi-domain features, complemented by an orthogonal constraint loss that reduces inter-branch redundancy. Extensive experiments on the RML2018.01 benchmark show that the proposed MAFFNet achieves 82.53 $$\%$$ accuracy between 0–10 SNRs, outperforming other methods by 5.46–11.25%.},
  archive      = {J_SUPERC},
  author       = {Jiang, Yuncong and Jia, Weifei and Yu, Quanlin},
  doi          = {10.1007/s11227-025-07492-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {MAFFNet: A multi-modal adaptive feature fusion net for signal modulation recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv7-tiny-based lightweight and efficient algorithm for photovoltaic cell crack detection. <em>SUPERC</em>, <em>81</em>(8), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07493-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic cell crack detection is critical for maintaining the efficiency and reliability of solar energy systems. However, existing detection algorithms often struggle with the trade-off between model size and accuracy, particularly in identifying complex crack patterns in photovoltaic cells. To address this challenge, we propose PSD-YOLO, a novel detection algorithm designed to optimize both performance and efficiency. The algorithm integrates the lightweight convolution module PSDConv into YOLOv7-tiny, replacing the DW convolution in Ghost Spatial Convolution (GSConv), thereby enhancing the detection capability for diverse crack types while retaining adaptability. Additionally, the loss function is enhanced by adopting the Efficient IoU (EIoU) in place of the original CIoU, which contributes to faster convergence and improved bounding box regression accuracy. Experimental results demonstrate that PSD-YOLO reduces parameters and computational cost by 18.3% and 16.7%, respectively, compared to YOLOv7-tiny, resulting in a more lightweight and resource-efficient model. However, this improvement in compactness comes with a trade-off in inference speed, which has been noted in our experimental results.},
  archive      = {J_SUPERC},
  author       = {Tiwari, Satyarth and Sharma, Sanjay Kumar},
  doi          = {10.1007/s11227-025-07493-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {YOLOv7-tiny-based lightweight and efficient algorithm for photovoltaic cell crack detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid and parallel GAN architecture with non-IID noise input. <em>SUPERC</em>, <em>81</em>(8), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07495-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a hybrid generative adversarial network (GAN) by combining the classical and quantum approaches with input noise samples drawn from the dependent and nonidentical distribution learned from the training data. Leveraging quantum computing our approach is built on styleGAN for image generation. Present day generative models are still dependent on classical computation method for adversarial learning. They also use independent and identically distributed (IID) noise without considering the data statistics. In this work, we use a hybrid approach by combining quantum computing with the classical way of learning. Unlike StyleGAN, our work is implemented by training intermediate independent generative adversarial networks (GANs) in parallel where we make use of the available training images. The trained parameters initialize the combined architecture to refine the parameters in the final training. A variational quantum circuit (VQC) is embedded in the generators during the training process. The use of parallel setup as well as combining the quantum method with classical significantly reduce the training time. The non-IID samples as input which are generated using the training data statistics enhance the accuracy as well as contribute to training time reduction. The efficacy of the proposed method is tested on Flickr-Faces High-Quality (FFHQ) dataset and Celeba High-Quality (CelebaHQ) dataset. We have conducted experiments with both variants of GANs, namely the classical generator and the hybrid generator, referred to as the proposed classical approach and the proposed quantum approach. A hybrid generator, also referred to as a quantum generator, combines a quantum circuit with a classical GAN. An ablation study is also performed to check performance of VQC by changing the rotation gates and type of entanglements. We compare our results with the classical styleGAN with IID noise as well as other state of the art methods qualitatively as well as using the quantitative metrics such as Fréchet inception distance (FID), density, and coverage. Experiments show that the proposed method reduces the computational complexity as well as generates better quality images. The proposed method of non-IID, hybrid and parallel GAN improves the FID score up to 75 $$\%$$ .},
  archive      = {J_SUPERC},
  author       = {Gohel, Prashant and Joshi, Manjunath},
  doi          = {10.1007/s11227-025-07495-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Hybrid and parallel GAN architecture with non-IID noise input},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AF-YOLOv8: A lightweight algorithm suitable for helmet and vest detection. <em>SUPERC</em>, <em>81</em>(8), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07496-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personal protective equipment (PPE) is pivotal in safeguarding operators in industrial and construction environments against many external physical hazards. However, prevailing PPE detection techniques frequently encounter difficulties in achieving an optimal equilibrium between detection speed and accuracy. We present the innovative Adaptive Focus YOLOv8 (AF-YOLOv8) model to address this issue, which significantly advances detection precision and speed. Firstly, we propose the dual-focused diffusion pyramid network (DFDPN), a novel architecture that masterfully captures intricate information across multiple feature scales through focusing and diffusion mechanisms. Secondly, we put forth a parameter-shared convolutional detection head (PSCDH), an efficient design that dramatically curtails the parameters required. Furthermore, we integrate the RVB_EMA module into the C2F, optimizing the model by reducing parameters while intensifying its focus on PPE characteristics. The experiments have demonstrated that AF-YOLOv8 achieves an mAP of 91.2% on the test set, representing a 1.4% improvement over the YOLOv8. Furthermore, there are 33.6%, 22%, and 34.9% reductions in parameters, GFLOPs, and model size, respectively. In addition, AF-YOLOv8 demonstrated generalization performance in experiments on the Visdrone2019 dataset.},
  archive      = {J_SUPERC},
  author       = {Chen, Xi and Wang, Guohui},
  doi          = {10.1007/s11227-025-07496-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {AF-YOLOv8: A lightweight algorithm suitable for helmet and vest detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TMATrack: Token merging for autoregressive visual object tracking. <em>SUPERC</em>, <em>81</em>(8), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07498-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking methods often suffer from complex head network structures that require multiple loss functions, making the training process challenging. Moreover, these methods rely solely on initial templates or simple online update mechanisms, which fail to effectively handle changes in target appearance and position over time. The complete input of search region images into the network also introduces substantial redundant background information, leading to significant interference during the feature extraction stage. To address these issues, we propose a method, i.e., TMATrack, which adopts a transformer-based architecture and utilizes an autoregressive generation approach, eliminating the need for complex head networks and redundant loss functions. Firstly, we design a vision transformer with a token merging module as the backbone network for feature extraction. This module merges similar regions in the background, thereby reducing background noise. Secondly, we employ the decoder part of the Transformer, incorporating historical trajectory information and visual features, to generate target coordinates in an autoregressive manner. Additionally, we utilize an online template update mechanism to capture changes in target appearance and introduce a dual-template masking mechanism to prevent low-quality template updates from degrading the target features. Extensive experimental results demonstrate that our proposed TMATrack achieves competitive performance on several tracking benchmarks. Specifically, it achieves 72.6% AUC on OTB100 benchmark and 84.7% AUC on TrackingNet benchmark, both of which represent state-of-the-art results at comparable resolutions and model sizes.},
  archive      = {J_SUPERC},
  author       = {Chen, Jinguang and Yao, Hongxiao and Ma, Lili},
  doi          = {10.1007/s11227-025-07498-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {TMATrack: Token merging for autoregressive visual object tracking},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical simulation and multi-objective optimization of braking wear of multi-piston brake pads. <em>SUPERC</em>, <em>81</em>(8), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07501-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article combines Archard wear algorithm with Abaqus finite element software for wear simulation and verifies the accuracy of the algorithm through experiments, with an error of 1.6%. This method was used to conduct an in-depth analysis of the wear of the three-piston caliper brake pads, in order to explore their braking performance. On this basis, sensitivity analysis was conducted on the three-piston layout structure using Taguchi method, and a genetic algorithm optimized neural network surrogate model (GA-BP) was constructed. The non-dominated sorting genetic algorithm II (NAGA-II) was introduced for multi-objective optimization to obtain the Pareto curve. The research results show that the contact pressure distribution of the three pistons is uniform, and the maximum values of contact stress and pressure are concentrated at the groove. Observing the Pareto surface, it can be seen that there is a contradiction between wear quality and contact area. While reducing wear, the overall contact area between the front and rear parts of the brake pad shows a downward trend; by using multi-objective optimization methods, the wear amount of brake pads was reduced from 2778.3 to 2731.91 mg, and the contact area was increased from 2533 to 2779.3 mm2. The multi-objective optimization method used in this article has shortened the cycle and cost of optimizing calipers, which has a positive significance for the design of calipers.},
  archive      = {J_SUPERC},
  author       = {Tang, Zhenhua and Yin, Haiyan and Zhao, Jinmiao and Ding, Chao},
  doi          = {10.1007/s11227-025-07501-6},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Numerical simulation and multi-objective optimization of braking wear of multi-piston brake pads},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of machine learning and deep learning approaches for anomaly detection in high-performance computing systems. <em>SUPERC</em>, <em>81</em>(8), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07503-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is crucial in high-performance computing (HPC) systems for maintaining effective, efficient, and secure operations. This survey focuses on the current status of the application of machine learning and deep learning in HPC systems for detecting various types of anomalies, including performance anomalies, operational anomalies, and security anomalies. The study takes a thorough look at the current approaches using diversified machine learning and deep learning techniques, the significance and challenges that anomaly detection in HPC systems brings, as well as the factors that should be considered in determining the performance of the systems according to the research conducted. Additionally, it explores tools and frameworks created using these techniques, specifically tailored for HPC systems. Nevertheless, it also reveals the issues with existing models, and based on them, further research is suggested. Hence, the discoveries unveiled in this study will be helpful for researchers and professionals specializing in anomaly detection within HPC systems.},
  archive      = {J_SUPERC},
  author       = {Ki, Cibin and Sivakumar, Ramah and Mulerikkal, Jaison and A, Binu and Gupta, Manish and Jan, Tony},
  doi          = {10.1007/s11227-025-07503-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {A comprehensive survey of machine learning and deep learning approaches for anomaly detection in high-performance computing systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-document summarization through subsection-aware pre-training objectives. <em>SUPERC</em>, <em>81</em>(8), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07504-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training language models are increasingly being utilized for multi-document summarization (MDS) tasks. However, pre-training typically necessitates large-scale, domain-specific data. Most MDS pre-training models process multiple documents as a single document, while ignoring the subsection relationship information among different documents. In this paper, we focus on pre-training objectives for MDS, which assume key information appears across multiple documents that point to the same topic. We segment each document into several subsections based on text structure features. Then, we compare the subsections of different documents, extract key sentences from these subsections using text similarity, and generate a proxy summary. Experimental results on Multi-News and WikiSum demonstrate that our proposed model outperforms compared MDS models in terms of ROUGE scores and maintains strong performance even with limited data samples.},
  archive      = {J_SUPERC},
  author       = {Wang, Xianchuan and Lu, Ben and Ming, Wenkai and Wang, Xianchao},
  doi          = {10.1007/s11227-025-07504-3},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Multi-document summarization through subsection-aware pre-training objectives},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFF-DSTnet: Fabric anomaly detection based on adaptive feature fusion dual-student–teacher network. <em>SUPERC</em>, <em>81</em>(8), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07506-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the textile industry, the ability to effectively detect multiple types of fabric anomalies remains a core challenge. Traditional student–teacher networks are constrained by their fixed receptive fields, making it difficult to effectively detect large-area texture anomalies, especially color anomalies. To overcome this bottleneck, this paper proposes a dual-student–teacher network architecture, with the patch description network and masked autoencoder selected as the backbones of the two student networks. Our research demonstrates that the masking strategy of the masked autoencoder enables the model to fully utilize contextual information from the visible region, allowing it to exhibit excellent complementarity with the patch description network in fabric anomaly detection tasks. Secondly, this paper introduces a focus pixel fusion strategy that adaptively adjusts the fusion weights and fusion ranges of feature maps based on the anomaly types, achieving refined information integration between different student networks. Finally, we propose the PNFE image preprocessing method, which mitigates the impact of overfitting on the network by adding Perlin noise to fabrics to generate random shadows and applying random fisheye effects, improving training performance without increasing the number of training images. Compared with other methods from recent years, the experimental results of AFF-DSTnet validate its superiority in relevant metrics.},
  archive      = {J_SUPERC},
  author       = {Chen, Haowen and Liu, Hao and Liang, Jiuzhen and Zhuang, Junjie and Wang, Ruyu},
  doi          = {10.1007/s11227-025-07506-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {AFF-DSTnet: Fabric anomaly detection based on adaptive feature fusion dual-student–teacher network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computation-efficient quantum convolutional neural networks for autonomous driving applications. <em>SUPERC</em>, <em>81</em>(8), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07507-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a computation-efficient quantum convolutional neural network (CE-QCNN) architecture designed for autonomous driving applications. A key contribution of this work lies in the formulation of a tri-value qubit encoding (TQE) scheme, which compactly embeds three-channel RGB image data into single-qubit states via a sequence of quantum rotations. This strategy enables significant qubit resource reduction while preserving the representational richness of multi-channel visual inputs. The encoded quantum states are subsequently processed through parameterized quantum circuits for convolutional feature extraction, forming the core of the proposed CE-QCNN framework. To further improve learning stability and early-stage performance, a knowledge distillation (KD) strategy is employed, transferring supervision from a pretrained classical CNN model to the quantum network. The proposed model is evaluated on the KITTI dataset, a standard benchmark for autonomous driving, where it demonstrates both competitive detection accuracy and reduced computational complexity. These results substantiate the scalability and practical applicability of CE-QCNNs for future quantum-enhanced perception systems in real-time autonomous driving scenarios.},
  archive      = {J_SUPERC},
  author       = {Roh, Emily Jimin and Im, Chaemoon and Jeong, Wonjun and Park, Soohyun},
  doi          = {10.1007/s11227-025-07507-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Computation-efficient quantum convolutional neural networks for autonomous driving applications},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-user multi-exit DNN inference partitioning and task scheduling strategy. <em>SUPERC</em>, <em>81</em>(8), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07508-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge intelligence, combining artificial intelligence with edge computing, is a promising emerging technology. However, its efficient operation inevitably faces the challenge of handling massive data. To address this challenge, multi-exit models and partitioning models have been developed. Notably, existing research on multi-exit deep neural networks (DNN) inference partitioning models predominantly focuses on optimizing the model itself, with less attention to the task scheduling complexity in multi-user scenarios. In view of this, this paper delves into the issues of DNN inference partitioning and task scheduling within a multi-user environment, proposing a multi-user multi-exit DNN inference partitioning and task scheduling strategy. This strategy takes into account factors such as task urgency and deadlines, optimizing DNN exit and partition points while enabling rational task scheduling to maximize task completion rates and inference accuracy. We design a double greedy algorithm-based inference task scheduling mechanism that efficiently schedules inference tasks for multiple users on edge servers, achieving optimal utilization of system resources. Additionally, we introduce the multi-agent proximal policy optimization method to further optimize the performance of multi-exit and partition models. Simulation experiments, compared to other mainstream scheduling algorithms, demonstrate that the proposed algorithm effectively improves task completion rates.},
  archive      = {J_SUPERC},
  author       = {Tian, Xianzhong and Li, Yucheng and Mao, Xuhua and Zhang, Luoming and Lin, Ziyi},
  doi          = {10.1007/s11227-025-07508-z},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Multi-user multi-exit DNN inference partitioning and task scheduling strategy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feasibility analysis and opposition white shark optimizer for optimizing modified EfficientNetV2 model for road crack classification. <em>SUPERC</em>, <em>81</em>(8), 1--60. (<a href='https://doi.org/10.1007/s11227-025-07509-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pavement cracks start as obvious cracks in the surface layer and progress to deeper layers, affecting the overall structure. Therefore, detecting asphalt pavement cracks is a critical and time-consuming task. This study establishes an intelligent approach for automatic asphalt pavement crack classification, based on the integration of Opposition-based Learning (OBL), White Shark Optimizer (WSO), and Convolution Neural Networks (CNNs). This involves creating a Modified variant of the pre-trained CNN EfficientNetV2 (MEfficientNetV2) model. The proposed method was combined with Principal Component Analysis (PCA) to ensure efficient feature selection and dimensionality reduction. A set of pre-processing steps was applied to further improve the quality of images and remove any noise or artifacts. Extensive experiments were managed to train and validate the proposed asphalt pavement crack classification method on low-contrast natural images with several class labels. These images were gathered from many publicly available asphalt crack datasets to assess the adaptability and specificity of the proposed method. The proposed pavement crack classification method surpasses existing methods with a precision of 96.9317%, a recall of 98.6358%, a specificity of 98.9377%, an accuracy of 98.8368%, and an F1-score, representing the harmonic average of a classification model’s recall and precision, of 98.6358%. Thus, the proposed method is a viable substitute to assist transportation agencies in routine pavement inspection tasks.},
  archive      = {J_SUPERC},
  author       = {Al-Shalabi, Mohammed and Mahdi, Mohammed A. and Braik, Malik and Al-Betar, Mohammed Azmi and Ahamad, Shahanawaj and Saad, Sawsan A.},
  doi          = {10.1007/s11227-025-07509-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--60},
  shortjournal = {J. Supercomput.},
  title        = {Feasibility analysis and opposition white shark optimizer for optimizing modified EfficientNetV2 model for road crack classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of energy-efficient control in rail transit systems under event impact. <em>SUPERC</em>, <em>81</em>(8), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07513-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an integral component of urban public transportation systems, urban rail transit significantly alleviates urban road traffic pressure and holds a pivotal position in the development strategies of urban public transportation. This paper aims to investigate the energy-saving optimization control problem of trains under the influence of events. Firstly, we consider train operation time, train dynamics, and train energy consumption and then establish an energy-saving control optimization model for rail transit that takes into account the influence of events. Secondly, we devise a deep reinforcement learning-based method for optimizing train energy-saving control, which incorporates the impact of events. Finally, we validate our proposed method using real-world urban rail transit data in a subway simulation environment, comparing it with other deep reinforcement learning methods. The results indicate that the proposed approach effectively reduces energy consumption for rail transit trains when facing both unforeseen and regular events, across different subway systems.},
  archive      = {J_SUPERC},
  author       = {Ma, Changxi and Zhao, Mingxi and Wang, Tao},
  doi          = {10.1007/s11227-025-07513-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Optimization of energy-efficient control in rail transit systems under event impact},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Likelihood and pivotal inference for kumaraswamy parameters under progressive type-II censoring. <em>SUPERC</em>, <em>81</em>(8), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07514-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate parameter inference for the Kumaraswamy distribution based on progressively type-II censored data. Our approach involves employing the method of maximum likelihood to derive point estimates for the model parameters. We establish the existence and uniqueness of these maximum likelihood estimators. Additionally, we present pivotal quantities that enable the construction of exact confidence intervals and joint confidence regions for the model parameters. To assess the performance of our proposed estimation techniques, we conduct comprehensive simulation studies. In conclusion, we apply the introduced estimation methods to analyze and discuss the results obtained from three real datasets, providing practical insights into their performance. These exact joint confidence regions can be directly utilized to construct confidence bounds for various reliability indices and quality control measures, enhancing their applicability in industrial settings.},
  archive      = {J_SUPERC},
  author       = {Wu, Shuo-Jye and Tseng, Yao-Ting and Kuş, Coşkun},
  doi          = {10.1007/s11227-025-07514-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Likelihood and pivotal inference for kumaraswamy parameters under progressive type-II censoring},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven federated learning: A systematic literature review on approaches, challenges, and prospects. <em>SUPERC</em>, <em>81</em>(8), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07516-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables collaborative model training across distributed clients while preserving data privacy. Recent studies have focused on enhancing FL performance by transferring knowledge, which includes feature representations, fine-grained model parameters, and network architectures. From the aspects of methods, challenges, and prospects, this paper presents a detailed review of knowledge-driven FL, classifying existing methods into four categories: federated learning based on knowledge distillation (FL-KD), federated learning based on knowledge transfer (FL-KT), federated learning based on knowledge sharing (FL-KS), and other innovative approaches. We analyze the techniques used for knowledge management and discuss key challenges in this field. Additionally, we explore strategies in knowledge-driven FL, including FL-KD, FL-KT, FL-KS, and emerging approaches. We also summarize the commonly used datasets, evaluation metrics, and baselines in this area. Finally, we highlight current challenges and future directions, offering insights into potential advancements in knowledge-driven FL.},
  archive      = {J_SUPERC},
  author       = {Lin, Xiaogang and Zhao, Xiaoli and Yin, Zilong and Pan, Hao and Jing, Panzhao and Li, Weishan and Wang, Kangwei and Shu, Yincan},
  doi          = {10.1007/s11227-025-07516-z},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Knowledge-driven federated learning: A systematic literature review on approaches, challenges, and prospects},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-archive niche with two-stage directed differential evolution for multimodal multi-objective optimization. <em>SUPERC</em>, <em>81</em>(8), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07517-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Multi-Objective Optimization Problems (MMOPs) refer to situations where there are multiple equivalent Pareto sets corresponding to the same Pareto front. The complexity of solving MMOPs lies in locating multiple equivalent PSs within the decision space while maintaining diversity and convergence in both the decision and objective spaces. To better address this issue, a dual-archive niche approach using two-stage directed differential evolution is proposed, named MMOHCDE_DDM. Firstly, the algorithm leverages the concept of dual archives and introduces affinity propagation clustering for niche differential evolution, automatically generating multiple stable niches. Subsequently, it combines with a competitive particle swarm optimizer to address two solution spaces with different evolutionary requirements. Secondly, by generating multiple subpopulations through affinity propagation clustering, the algorithm employs two distinct mutation strategies to update populations in parallel. This approach enables more effective exploration within niches, effectively enhancing the diversity of both the decision and objective spaces. Furthermore, while the above strategies effectively enhance diversity, they may lead to a loss of convergence. To mitigate this issue and improve convergence, a two-stage directed differential operator is proposed. Introducing a directed differential operator in the later stages of the search provides directed exploration of regions with higher optimality, thereby enhancing convergence. The proposed approach enhances the diversity of both the decision and objective spaces while ensuring convergence in the objective space. The algorithm is compared with various state-of-the-art MMO algorithms on 22 MMO test problems. Experimental results demonstrate that the proposed algorithm outperforms multiple state-of-the-art MMO algorithms in the majority of MMO test problems.},
  archive      = {J_SUPERC},
  author       = {Chen, Yilin and Gao, Bo and Lu, Tao and Wu, Yiqi and Liao, Xiangyun and Wang, Qiong},
  doi          = {10.1007/s11227-025-07517-y},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {A dual-archive niche with two-stage directed differential evolution for multimodal multi-objective optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space models and depth separable convolution for high-precision hybrid wafer defect detection. <em>SUPERC</em>, <em>81</em>(8), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07521-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wafer defect detection is pivotal in the semiconductor manufacturing process, directly influencing production efficiency and product quality. With the increase in integration and design complexity of semiconductor wafers, the variety and number of defects have also risen. Given the inefficiencies of manual inspection, recent advancements in state-space models (SSM), exemplified by Mamba, have demonstrated proficiency in modeling long-range dependencies while maintaining linear computational complexity. Inspired by this, we propose a dual-path fusion network(DPFNet), a VisionMamba-based approach tailored for image classification and wafer defect detection. DPFNet integrates state-space modeling with depthwise separable convolution (DSC) techniques, effectively capturing global sequence information and local detailed features. Utilizing PatchEmbedding, the input image is segmented into chunks, with the SSM module modeling dependencies between these sequences. Concurrently, the convolutional branch, incorporating DSC and channel attention modules, focuses on local feature extraction. Through a gating mechanism, these dual feature representations are adaptively fused, enabling a step-by-step extraction and processing of features from low to high levels via multilayer DPFBlocks. Our extensive experiments on the MixedWM38 dataset demonstrate DPFNet’s outstanding performance, achieving accuracy, precision, recall, and F1-score of 98.84%, 98.70%, 98.69%, and 98.69%, respectively. Compared to existing deep learning models, DPFNet exhibits superior accuracy and robustness, particularly in complex hybrid defect scenarios.},
  archive      = {J_SUPERC},
  author       = {Zhang, Haibin and Lang, Tingting and Wang, Cheng and Liu, Wei and Tang, Shaosheng and Ji, Yanjun},
  doi          = {10.1007/s11227-025-07521-2},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {State-space models and depth separable convolution for high-precision hybrid wafer defect detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-asynchronous federated learning method integrating personalization and staleness awareness for traffic flow prediction in dynamic internet of vehicles. <em>SUPERC</em>, <em>81</em>(8), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07523-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely collection and analysis of large-scale vehicle travel data are crucial for traffic flow prediction. However, centralized data processing poses significant privacy risks, while federated learning within dynamic Internet of Vehicles (IoV) faces challenges such as device heterogeneity, non-independent and identically distributed (non-IID) data and stochastic communication latency issues. To address these issues, we propose a semi-asynchronous federated learning method, FedSAP. Firstly, FedSAP constructs a global model by aggregating model parameters from any minority of clients. This approach mitigates the negative impacts of unstable and unreliable communication in the IoV on model training. Secondly, a dynamic asynchronous aggregation strategy is implemented at the server side. This strategy dynamically adjusts global model aggregation weights based on the staleness of local models and differences in gradient directions between local and global models, addressing performance degradation caused by staleness. Additionally, at the vehicle terminal, FedSAP introduces a parameter decoupling technique. By dynamically adjusting the personalization coefficient, the global model’s adaptability to local sensing data is accelerated, reducing the negative impact of data heterogeneity on its performance. Experiments on public traffic flow datasets demonstrate that FedSAP outperforms baseline methods on two common traffic flow prediction models, achieving approximately a 50% increase in convergence efficiency and a 9% reduction in prediction error. The results substantiate the superiority and adaptability of the proposed method in dynamic vehicular networking environments.},
  archive      = {J_SUPERC},
  author       = {Zhao, Peng and Liao, Zhuhua and Zhao, Yijiang and Xu, Jianbo and Yi, Aiping},
  doi          = {10.1007/s11227-025-07523-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {A semi-asynchronous federated learning method integrating personalization and staleness awareness for traffic flow prediction in dynamic internet of vehicles},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MEDU-net: Channel-based full-resolution contour refinement feedback for patch-aware gland image segmentation. <em>SUPERC</em>, <em>81</em>(8), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07529-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphological diversity and edge ambiguity pose challenges for accurate gland segmentation in medical imaging. We propose the MEDU-Net channel: Full-resolution and contour refinement feedback patch-aware U-Net, a novel network integrating three key components to improve segmentation accuracy. First, the full-resolution multilevel fusion module mitigates information loss in the encoder-decoder structure by full-resolution fusion of deep channels, thereby achieving multi-scale feature preservation. Second, the contour refinement perception module adopts multibranch adaptive contour perception to feature refine complex gland edge delineation. Third, the feature feedback patch awareness module in skip connections expands the awareness sensitivity and supervises the feature reshaping process through feature patches and feedback. After evaluation on GlaS and CRAG datasets, MEDU-Net surpasses the state-of-the-art methods in terms of Dice coefficient and segmentation accuracy, and performs well in handling the complexity of glandular structures. This study provides an effective solution for clinical histopathology image segmentation.},
  archive      = {J_SUPERC},
  author       = {Li, Yuan and Wang, Jue and Li, Bo and Li, Jinzhang},
  doi          = {10.1007/s11227-025-07529-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {MEDU-net: Channel-based full-resolution contour refinement feedback for patch-aware gland image segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fabdb: A low-latency fault-tolerant architecture based on dynamic bypass for network-on-chip. <em>SUPERC</em>, <em>81</em>(8), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07530-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the further reduction in transistor size, the probability of component failures in Network-on-Chip increases significantly, and routers, as the main components of NoC, may lead to network communication interruption in case of failure. Most existing fault-tolerant schemes are designed based on rerouting strategies, which can create network hotspots, while increasing the number of faulty routers may lead to packet loss. Previous fault-tolerant schemes based on bypass routing can alleviate these problems, but bypass routing is restricted to faulty routers and is susceptible to network traffic distribution, resulting in high packet delays. In this paper, we propose a fault-tolerant router architecture based on dynamic bypass, where the use of bypasses is no longer restricted to faulty routers. For a healthy router, packets that pass through the bypass channel do not interfere with normal internal channel transmission, which improves packet transmission efficiency. Based on this architecture, we propose two dynamic bypass fault-tolerant schemes, FABDB and FABDB++, and FABDB++ offers more flexible bypass usage conditions compared to FABDB. The experimental results show that our proposed fault-tolerant scheme reduces the delay by 36.2% and improves the throughput by 24.3% on average compared with the existing schemes. The reliability is above 99% in the presence of 8 faulty routers in an 8x8 mesh. The proposed scheme achieves low dynamic power overhead and hardware resource overhead while maintaining high reliability.},
  archive      = {J_SUPERC},
  author       = {Ouyang, Yiming and Ji, Zhuoxuan and Li, Jianhua and Liang, Huaguo},
  doi          = {10.1007/s11227-025-07530-1},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Fabdb: A low-latency fault-tolerant architecture based on dynamic bypass for network-on-chip},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-objective cuckoo search with migration operator for benchmark optimization and IoT task scheduling in cloud-fog computing. <em>SUPERC</em>, <em>81</em>(8), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07531-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective cuckoo search (MOCS) algorithm is an effective metaheuristic for solving complex optimization problems. Like many optimization algorithms, MOCS faces challenges with premature convergence and maintaining diversity in the solution space. To address this issue, we propose an upgraded MOCS algorithm that includes a migration operator that is activated upon early convergence detection. Migration operator aims to improve exploration and exploitation by reintroducing diversity when the algorithm stagnates. The proposed algorithm, termed MG-MOCS, is evaluated using standard benchmark functions, including IMOP and ZDT problems. MG-MOCS shows significant improvements in spacing and hypervolume metrics. Statistical tests such as the Friedman test confirm the superior performance of MG-MOCS compared to other state-of-the-art algorithms like NSGA-II, NSGA-III, SPEA2, MOGWO and MSKEA. Furthermore, MG-MOCS is applied to a real-world IoT task scheduling problem in a cloud-Fog computing environment, where it efficiently balances workload distribution across Cloud and Fog resources. Results demonstrate that the migration operator enhances MOCS’s ability to avoid local optima, resulting in better optimization performance.},
  archive      = {J_SUPERC},
  author       = {BahraniPour, Fatemeh and Farshi, Mohammad and Ebrahimi Mood, Sepehr},
  doi          = {10.1007/s11227-025-07531-0},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Enhanced multi-objective cuckoo search with migration operator for benchmark optimization and IoT task scheduling in cloud-fog computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic frame-based weight estimation and joint position-scale model for underwater object tracking. <em>SUPERC</em>, <em>81</em>(8), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07537-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex underwater environment and the scattering and absorption effects in water, underwater images often suffer from low visibility and weak texture features, posing significant challenges for object feature extraction and tracking. To address these issues, we propose a novel underwater object tracking method based on dynamic frame selection and a joint position-scale estimation model. Our approach initially employs a dichotomy method to select the most correlated frame with the current frame, using inter-frame information to estimate the weights of convolutional features for effective feature fusion. Subsequently, a tracking model with joint position-scale estimation is constructed, where the fused object features are input to estimate the object’s position and scale accurately in complex underwater environments. Additionally, a confidence evaluation metric based on average peak correlation energy is integrated into the model update strategy to halt updates during object occlusion or disappearance, enhancing tracking stability and preventing error accumulation. Experimental results on the UTB180 dataset and actual underwater environments demonstrate that our algorithm achieves improved tracking precision and success rates compared to state-of-the-art methods, particularly in scenarios with scale variations, occlusions, and low visibility.},
  archive      = {J_SUPERC},
  author       = {Xu, Haiyan and Ren, Jing and Xie, Yingjuan and Huo, Guanying},
  doi          = {10.1007/s11227-025-07537-8},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic frame-based weight estimation and joint position-scale model for underwater object tracking},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECDOAGM: An elephant collective defense optimization algorithm with a gray model for managing distributed massive data streams in IoT architectures. <em>SUPERC</em>, <em>81</em>(8), 1--51. (<a href='https://doi.org/10.1007/s11227-025-07546-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) refers to the connection of everyday things to the Internet, enabling them to collect, transmit, and share data. This interconnected network of countless devices transforms existing frameworks, enabling them to interact intelligently with each other and their environment. Today, decentralized systems of smart devices are emerging as a new paradigm in the IoT, due to reasons such as interoperability and limitations in massive data processing within centralized systems. In these distributed systems, IoT components provide data resources for applications, and also offer distributed computing services and communication storage. This enables the creation of a distributed data stream. Numerous distributed computing technologies, along with hardware virtualization, service-oriented architecture, and automated computing, have fueled the development of cloud computing. Researchers have developed and analyzed new algorithms and techniques in the field of distributed computing on the IoT network. However, these often show disadvantages in guaranteeing Quality of Service (QoS) parameters. To address these drawbacks, we propose a novel solution using a combination of an evolutionary algorithm based on the collective defense of elephants and a gray model, named ECDOAGM. This method provides the possibility of distributed processing in the IoT architecture while optimally distributing network load. Evaluation results from the IoT DDoS Honeypot Dataset (IoT-DH) demonstrate that the proposed method is more efficient than other approaches. The proposed approach outperforms the methods of Yosuf et al., Fawzy et al., and Wang et al. by 1.18%, 1.86%, and 0.86% in accuracy for managing distributed data streams, respectively. It also demonstrates faster processing times by 10.12 s, 1.3 s, and 0.9 s compared to the same methods, respectively. Consequently, the proposed approach offers superior QoS.},
  archive      = {J_SUPERC},
  author       = {Ajirlou, Mohammad Farrokhzadeh and Jalilvand, Abbas and Khalilian, Madjid},
  doi          = {10.1007/s11227-025-07546-7},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--51},
  shortjournal = {J. Supercomput.},
  title        = {ECDOAGM: An elephant collective defense optimization algorithm with a gray model for managing distributed massive data streams in IoT architectures},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time image dehazing algorithm based on adaptive routing. <em>SUPERC</em>, <em>81</em>(8), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07549-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most image dehazing algorithms in practical applications suffer from weak input adaptability due to their neglect of input image types (hazy or haze-free), and they often enhance dehazing performance by deepening network layers, resulting in large parameter counts that make real-time processing difficult. To address these issues, we propose a real-time image dehazing algorithm based on adaptive routing. Firstly, we design an adaptive routing module based on multi-scale feature extraction to determine the processing path of the input image. Then, based on the traditional feature attention (FA) module, a lightweight de-redundant feature attention (DRFA) module is constructed for dehazing processing. Finally, the residual network with the PixelShuffle upsampling module is utilized for efficient image recovery. The experimental results demonstrate that our algorithm achieves high PSNR and SSIM scores on several datasets, and we reach an average PSNR and SSIM of 26.75 dB and 0.832 on the mixed dataset of clear and hazy images, respectively. These results outperform other comparative algorithms, indicating the robustness and practicality of our approach. Not only that, our algorithm has a computational cost of 8.93G FLOPs and a dehazing time of only 4.81 ms during the 256 × 256-pixel image dehazing efficiency test, which meets the requirements of real-time processing for video surveillance in outdoor scenes.},
  archive      = {J_SUPERC},
  author       = {Meng, Kun and Yang, Shengjie and Liu, Zhen and Li, Sheng and Wang, Min and Liao, Haibin and Yuan, Li},
  doi          = {10.1007/s11227-025-07549-4},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {A real-time image dehazing algorithm based on adaptive routing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital forensic analysis for vehicle infotainment systems based on packet fingerprinting. <em>SUPERC</em>, <em>81</em>(8), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07552-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing number of in-vehicle computing systems and rapid development of technologies, such as autonomous driving technology, various IoT technologies are being incorporated into vehicles. In these scenarios, a vehicle is typically connected to a smartphone or various sensors to exchange information based on wireless communication. While this is convenient for the driver, from a security standpoint, it means exposing the vehicle to a new cyberattack surface, including wireless communication attacks such as Bluetooth and Wi-Fi replay attacks, unauthorized network intrusion, and password interception. Therefore, active research on security inspection and improvement for wireless communication in vehicular environments is required. Some studies in this regard have raised security issues, but little digital forensic research has been conducted on the issues raised. Against this background, we conducted a case study based on packet fingerprinting to improve the level of security in wireless communication in a vehicular environment (i.e., in-vehicle wireless communications). Packet fingerprinting was applied to 11 in-vehicle infotainment systems. Consequently, devices and services in use were identified from wireless network packets. Images of internal storage data were acquired from three in-vehicle infotainment systems, and a file system-based analysis was performed on the images to derive digital forensic artifacts related to the packets stored in the vehicle systems. Further analysis was conducted by combining the derived artifacts with the packet fingerprinting results. Our findings contribute to evaluating and improving the security level of wireless communication in various in-vehicle infotainment system environments. In addition, various identification information and digital forensic artifacts derived from these in-vehicle infotainment systems can contribute to digital forensic investigations in vehicular wireless communications.},
  archive      = {J_SUPERC},
  author       = {Shin, Yeonghun and Yu, Geon and Shon, Taeshik},
  doi          = {10.1007/s11227-025-07552-9},
  journal      = {The Journal of Supercomputing},
  month        = {6},
  number       = {8},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Digital forensic analysis for vehicle infotainment systems based on packet fingerprinting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MeghMesa: A multilevel elasticity for streaming applications in cloud. <em>SUPERC</em>, <em>81</em>(7), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07232-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing offers various services to its users, ranging from infrastructure, and system development environments, to software as a service over the Internet. A cloud service provider should deliver its services swiftly to real-time applications, which demand fluctuating computational processing. Real-time stream computations are perennial, receiving processing requests unpredictably and requiring a fair amount of resources for their processing in a constrained timeframe. Such a dynamic nature of applications leads to resource elasticity at runtime. In a cloud resource hierarchy, multiple resources with different processing capabilities and costs exist. To optimally utilize them and ensure the uninterrupted availability of resources to the real-time processing requirements, it is required to scale the resources at each processing layer efficiently. This work proposed the multilevel elasticity framework in a cloud environment for processing real-time streaming applications and collectively optimizing the elasticity concern of multilevel resources while attaining service level agreements and quality of service parameters.},
  archive      = {J_SUPERC},
  author       = {Thakkar, Riddhi and Bhavsar, Madhuri},
  doi          = {10.1007/s11227-025-07232-8},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {MeghMesa: A multilevel elasticity for streaming applications in cloud},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual introspective distillation for unbiased scene graph generation. <em>SUPERC</em>, <em>81</em>(7), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07246-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing scene graph generation methods primarily focus on addressing the long-tail problem in the labeling. However, most debiasing approaches struggle with a trade-off between head and tail class performance compared to biased-trained models. In this paper, we propose a balanced fusion strategy to leverage the strengths of both model types. From the perspective of causality, we proposed a mutual supervision intervention (MSI) method, which consists of a batch-level intervention and a model-level alignment part. This method is integrated into the existing Introd framework to address the bias in the fusion process of scene graph generation models. We propose a new metric called DP@100 to compare the output of the student model and the teacher model, providing an evaluation of the fusion performance under this distillation framework. The results of experiments performed on the Visual Genome dataset show the effectiveness of the proposed MSI method.},
  archive      = {J_SUPERC},
  author       = {Sun, Bo and Hao, Zhuo and Yu, Lejun and He, Jun},
  doi          = {10.1007/s11227-025-07246-2},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Mutual introspective distillation for unbiased scene graph generation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cellular goore game with multiple learning automata in each cell and its applications. <em>SUPERC</em>, <em>81</em>(7), 1--47. (<a href='https://doi.org/10.1007/s11227-025-07249-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a model known as cellular goore game (CGG) has been introduced, which represents a hybrid approach combining principles from Cellular Automata theory, Learning Automata from reinforcement learning, and Goore Game from game theory. While this model has garnered attention, it has been noted that each cell in the traditional CGG model is equipped with only a single learning automaton, which may not be suitable for certain real-world scenarios. In this study, we aim to enhance the traditional CGG model by introducing multiple learners within each cell, resulting in the proposed model termed CGG-MLA (Cellular Goore Game with Multiple Learning Automatons). We apply this extended model to address the overlapping community detection problem in multilayer social networks, leveraging its optimization capabilities. Additionally, we investigate the temporal behavior of the CGG-MLA using a solution based on ordinary differential equations (ODEs) and conduct a thorough performance analysis to validate its effectiveness. Our experimental results demonstrate that the CGG-MLA-based approach surpasses alternative algorithms, including Pure-Chance-CGG, GenLouv, mInfomap, PMM, CLACD, and MLCD, in terms of metrics such as normalized mutual information (NMI), modularity, MinMaxCut and Coverage, thus highlighting its efficacy in overlapping community detection within multilayer social networks.},
  archive      = {J_SUPERC},
  author       = {Khomami, Mohammad Mehdi Daliri and Saghiri, Ali Mohammad and Meybodi, Mohammad Reza},
  doi          = {10.1007/s11227-025-07249-z},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {Cellular goore game with multiple learning automata in each cell and its applications},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating zero-touch automation and optimization of beyond 5G services: Deep learning and intent-based networking fusion. <em>SUPERC</em>, <em>81</em>(7), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07260-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of 5G induced complex circumstances for operators to manage the network operations. The traditional manual configuration approaches to configure networks are inadequate to handle the vastly distributed infrastructure, diverse services with flexible requirements, and dynamic changes. To this end, intent-based networking (IBN) paves the way toward automatic handling of network service orchestration. It governs the network operations using the high-level, human-understandable, simplified interpretation of requirements. Administrators only determine what is required and don’t require configuring how to achieve the goals. In addition to the abstraction of hectic configuration requirements, it follows two-way intelligence-driven closed-loop operations to handle dynamic changes and assurance of services automatically. This work empowers automated 5G service orchestration with guaranteed quality of service (QoS) on vastly distributed multi-domain infrastructure through IBN and deep learning. It implements the long-short term memory (LSTM) model for virtual network function, achieving 0.1213 RMSE for resource prediction and management. It explored the RouteNet model with 0.025 RMSE for service path and routing control to optimize the key performance indicators. This results in machine learning (ML)-driven optimized resource scaling and the best path routing.},
  archive      = {J_SUPERC},
  author       = {Khan, Talha Ahmed and Abbas, Khizar and Afaq, Muhammad and Song, Wang-Cheol},
  doi          = {10.1007/s11227-025-07260-4},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Accelerating zero-touch automation and optimization of beyond 5G services: Deep learning and intent-based networking fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical perspective to the juggling sequence rotation performance pattern from system memory locality reference viewpoint. <em>SUPERC</em>, <em>81</em>(7), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07261-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any software/algorithm meant to run on computer systems is desirable to be optimal and efficient, in terms of system resource usage—whether embedded systems that demand minimal memory usage, real-time systems that must meet deadlines or any other computer system without special restrictions. However, some software/algorithms executions fail to exhibit these properties—wholly or partially. Meanwhile, these attributes can be requirements in some systems. Juggling sequence rotation is one of such algorithms that fail to show efficiency. Its average performance is poor within offsets chosen from around the square root of the sequence size. Yet, it is optimal in element assignments and performs well with offsets selected from within the first few cycle gaps and some around the middle of the sequence size. This inconsistency has attracted some research attention to unveil the cause of the pattern in order to advance performance of the algorithm and related cache behaviour. The attempt has identified hidden properties of the algorithm, by definitions and formulating equations and laying experimental framework for improving performance of the algorithm. This research is poised to advance the ongoing study to include validating some of the property concepts, represented in definitions and equations, of the algorithm. Formal proof methods were adopted for the validation. The results are formulation of 2 lemmas and 5 theorems with proofs. The most important proof is seqrotcircum (“SEQuence ROTation CIRCUMference”), defined in previous study (Erho et al. in: Proceedings of the 2023 IEEE 15th International Conference on Computer Research and Development (ICCRD), IEEE, China, pp 70–78, 2023). The seqrotcircum concept along with base cycle gap, core in the ongoing study, is key to redesigning the juggling rotation algorithm and to catch up with cache memory behaviour. The results of this study may be useful not only to many computing systems, including embedded and real-time systems, but also for future studies.},
  archive      = {J_SUPERC},
  author       = {Erho, Joseph Agaroghenefuoma and Japheth, Bunakiye Richard and Kenekayoro, Patrick Tarilayefa and Consul, Juliana Iworikumo},
  doi          = {10.1007/s11227-025-07261-3},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Theoretical perspective to the juggling sequence rotation performance pattern from system memory locality reference viewpoint},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QEKLR: Quantum-enhanced kernel logistic regression for classification. <em>SUPERC</em>, <em>81</em>(7), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07266-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is fundamental in machine learning (ML) applications such as medical diagnosis, financial analysis, and image recognition. Quantum machine learning shows promise in enhancing feature representation and computational efficiency. However, challenges like the noisy intermediate-scale quantum hardware limitations, lack of interpretability, and barren plateau issue in parameterized quantum circuits hinder its practical adoption. To address these issues, this work proposes a novel hybrid approach called quantum-enhanced kernel logistic regression (QEKLR) for classification tasks, which combines quantum computation with classical logistic regression (LR) model for improved classification performance. In our QEKLR model, classical data (CD) are first transformed to quantum states (QS) using shallow-depth ZZFeatureMap, and then, fidelity kernel is employed to compute the dot product between feature vectors, resulting in a trained quantum kernel. Subsequently to predict new instances, the quantum kernel is integrated into a classical LR model. We evaluated the proposed model’s effectiveness using four datasets: synthetic, Iris, Statlog Heart Disease (HD), and Ecoli datasets achieving accuracy rates of 100%, 100%, 94.87%, and 71%, respectively. In addition, experimental results reveal that the proposed QEKLR model surpasses classical ML models, achieving the MCC 0.88 and AUC-ROC 0.98 for the Statlog HD dataset demonstrating strong classification capability. However, on the Ecoli dataset, the model’s performance was comparable to existing ML models, indicating balanced performance across datasets while maintaining robust classification ability and effective class distinctions.},
  archive      = {J_SUPERC},
  author       = {Misra, Shreshtha and Rani, Poonam},
  doi          = {10.1007/s11227-025-07266-y},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {QEKLR: Quantum-enhanced kernel logistic regression for classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel fault-tolerant technique for star graph-based interconnection networks. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07272-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interconnection network is a fundamental technique for realizing high-performance computing and massive data communication. Fault tolerance of high-performance computing systems is a critical issue in ensuring network reliability, and connectivity is one of the most significant indicators for assessing fault tolerance of the system. However, the existing conditional connectivity measures cannot reveal the fault tolerance of a network well enough to balance the size of each component and the number of components of the remaining network in the presence of failing units. In this work, we introduce a novel connectivity measure for star graph, h-extra r-component connectivity, denoted by $$\text{ECC}_{r}^{h}(\text{{Star}}_{n})$$ , for the reliability of n-dimension star network $$\text{{Star}}_{n}$$ by taking into account of the size and number of disconnected components in a faulty network. Then, we determine the 1-extra 3-component connectivity and 1-extra 4-component connectivity of $$\text{{Star}}_{n}(n\ge 5)$$ to be $$\text{ECC}_{3}^{1}(\text{{Star}}_{n})=4n-10$$ and $$\text{ECC}_{4}^{1}(\text{{Star}}_{n})=6n-18$$ , respectively. Furthermore, we design an algorithm based on random iterations to obtain edge minimal cuts (RIEMC), aiming at solving the problem of the 1-extra r-component connectivity of G. Simulation results demonstrate that 1-extra r-component connectivity can accurately and effectively reflect fault tolerance and reliability of $$\text{{Star}}_{n}$$ than the state-of-the-art connectivity measures.},
  archive      = {J_SUPERC},
  author       = {Liu, Wenfei and Liu, Jiafei and Chang, Jou-Ming and Wu, Jingli and Wang, Qi},
  doi          = {10.1007/s11227-025-07272-0},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {A novel fault-tolerant technique for star graph-based interconnection networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-adaptive transfer network for visual–textual cross-domain sentiment classification. <em>SUPERC</em>, <em>81</em>(7), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07273-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sentiment analysis aims to address the problem of insufficient labeled data by transferring invariant knowledge across domains. Existing studies focus on unimodal domain transfer, but modal differences hinder the transfer of domain information and limit the acquisition of domain-invariant knowledge in multimodal data. Therefore, we propose a domain-adaptive transfer network (DATN) for multimodal cross-domain sentiment analysis. The joint representation is acquired through a bidirectional visual–textual interactive fusion network, and adversarial discriminative domain adaptation is employed to learn the marginal domain shared knowledge in the joint representation. The performance of multimodal domain adaptive modules aligns with conditional distributions. Extensive experiments on public and self-constructed datasets demonstrate the effectiveness of the model and show that self-constructed datasets have the potential to serve as a new benchmark. Compared with the best-performing method, the model’s accuracy on public datasets increased by 3.6% and 8.2%, respectively, and on self-built datasets by 9.2% and 3.3%, respectively.},
  archive      = {J_SUPERC},
  author       = {Wang, Yuan and Tohti, Turdi and Han, Dongfang and Zuo, Zicheng and Liang, Yi and Liao, Yuanyuan and Yang, Qingwen and Hamdulla, Askar},
  doi          = {10.1007/s11227-025-07273-z},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Domain-adaptive transfer network for visual–textual cross-domain sentiment classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-EDGE: An object detection algorithm for traffic scenarios. <em>SUPERC</em>, <em>81</em>(7), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07275-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic scene detection plays a crucial role in autonomous driving, with object detection being a fundamental task within this domain. However, deploying large models to in-vehicle platforms and achieving real-time detection in complex traffic scenarios is challenging. To address this issue, we propose an improved version of the YOLOv8 algorithm, named YOLO-EDGE. First, GhostConv is introduced in the backbone to replace several standard convolutions, thereby reducing model parameters. Second, a novel C2FEMA module is proposed, which maintains the lightweight advantages and captures richer gradient flow information while improving algorithm accuracy. Lastly, the neck of the original YOLOv8 network is improved by transforming the PAN-FPN structure into a more lightweight SlimNECK structure, which enhances feature information and further improves feature extraction capabilities. Experimental results on the PASCAL VOC dataset show that YOLO-EDGE reduces the model size by 7%, achieving a final size of only 20.9M compared to the baseline YOLOv8s. The number of parameters decreases by 7.6%, while the mean average precision (mAP@0.5) increases by 2.2% and the mAP@0.5:0.95 improves by 3.2%. These results demonstrate the effectiveness of YOLO-EDGE. Furthermore, YOLO-EDGE achieves a mean average precision (mAP@0.5) of 64.9% on the multi-object detection dataset UA-DETRAC, further demonstrating the algorithm’s versatility.},
  archive      = {J_SUPERC},
  author       = {Li, Yanshun and Zheng, Quanfeng and Xu, Shuobo and Wang, Peng and Wang, Yuhai and Song, Ze and Guo, Mengwei},
  doi          = {10.1007/s11227-025-07275-x},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {YOLO-EDGE: An object detection algorithm for traffic scenarios},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-objective scheduling for heterogeneous computing platforms using hybrid MOEAD with SA and TS-guided initialization strategies. <em>SUPERC</em>, <em>81</em>(7), 1--62. (<a href='https://doi.org/10.1007/s11227-025-07278-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid growth in data and computational demands has driven the widespread adoption of heterogeneous computing systems that combine different processing units, such as CPUs, GPUs, and FPGAs. Efficient scheduling of tasks in these systems is essential to optimize resource utilization, reduce power consumption, and meet performance requirements. However, the complexities of managing multiple tasks, diverse machine architectures, and conflicting objectives make scheduling in these environments an NP-hard problem. This study reformulates the traditional scheduling model as a multi-objective optimization problem focusing on minimizing makespan and maximizing parallelization across heterogeneous systems. Multi-Objective Evolutionary Algorithms based on Decomposition (MOEA/D) have effectively solved these complex scheduling challenges. MOEA/D offers a flexible and powerful approach for handling multi-objective scheduling tasks in a heterogeneous computing environment. This paper explores how MOEA/D can be combined with other metaheuristics to further improve task scheduling and balance competing performance objectives. The effectiveness of the approach is demonstrated through 28 validation scenarios. The algorithm’s performance is evaluated using four scientific workflows: structured as (FFT and Montage) and unstructured as (Molecular-A and Molecular-B). Performance evaluation is performed using appropriate metrics, specifically hypervolume and inverted generational distance plus, to assess the quality of the solutions. Experimental results demonstrate that the GRASP-MOEA/D hybrid approach outperforms all competitors in structured workflows, achieving the best schedule by minimizing makespan and maximizing resource utilization within a reasonable runtime. For unstructured workflows, GSA-MOEA/D achieves the best performance in 75% of cases, while SA-MOEA/D is the best in 37.5% of cases. However, GSA-MOEA/D and SA-MOEA/D face significant computational overhead as workflow size increases. In particular, GRASP-MOEA/D is the second-best performer in most unstructured workflow scenarios, making it a strong alternative to effectively solve these scheduling challenges.},
  archive      = {J_SUPERC},
  author       = {Saad, Abla and Abdel-Raouf, Osama and Hadhoud, Mohy and Kafafy, Ahmed},
  doi          = {10.1007/s11227-025-07278-8},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--62},
  shortjournal = {J. Supercomput.},
  title        = {Enhanced multi-objective scheduling for heterogeneous computing platforms using hybrid MOEAD with SA and TS-guided initialization strategies},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lynxsight: Change-point detection through different distance-based common spatial patterns. <em>SUPERC</em>, <em>81</em>(7), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07282-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting changes or shifts in data over time is known as change-point detection. This phenomenon is crucial for identifying the deterioration of industrial components and preventing costly breakdowns or failures. There are several supervised and unsupervised approaches used in change-point detection, which involve evaluating the difference between the sampling distributions of two-time windows. The accurate detection of change-points is a critical challenge addressed by Industry 4.0 and can enable timely action to avoid costly failures in industrial elements. This paper discusses the use of distance-based common spatial patterns (DB-CSPs) as an offline change-point detection technique in multivariate time series data. DB-CSP is a supervised approach that projects the data into a subspace to identify the most relevant features that differentiate between two-time windows. Afterward, a classification algorithm is used to effectively detect changes in the data. We demonstrate the adequacy of LynxSight using public datasets and apply the new approach to a real industrial use case, achieving better results than some state-of-the-art techniques.},
  archive      = {J_SUPERC},
  author       = {Florez, Arantzazu and Rodríguez-Moreno, Itsaso and Florez-Tapia, Ane M. and Artetxe, Arkaitz and Sierra, Basilio},
  doi          = {10.1007/s11227-025-07282-y},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Lynxsight: Change-point detection through different distance-based common spatial patterns},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the generalized fibonacci quaternions and the linear difference equations with periodic coefficients. <em>SUPERC</em>, <em>81</em>(7), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07283-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present two main objectives. Firstly, we introduce a novel generalization of the generalized Fibonacci quaternion sequences, providing an explicit analytic Binet formula that significantly extends previous formulations in the literature. This advancement offers a powerful mathematical tool for analyzing and computing quaternion sequences efficiently. Secondly, we explore quaternion sequences associated with real sequences that serve as solutions of a linear difference equation of order r, whose coefficients exhibit periodicity with period $$p\ge 2$$ . We derive comprehensive results that not only extend existing work but also unify previously disparate approaches under a common mathematical framework. Our formulation elegantly handles all cases of root multiplicities and provides a systematic approach to analyzing these complex quaternion sequences. Furthermore, we highlight the special case $$r=2$$ and $$p=2$$ , offering illustrative numerical examples that demonstrate the practical utility of our theoretical framework. Our results provide mathematicians and applied scientists with new computational tools for working with quaternion sequences in settings where periodic coefficients arise naturally.},
  archive      = {J_SUPERC},
  author       = {Ben Taher, R. and Lassri, M.},
  doi          = {10.1007/s11227-025-07283-x},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {On the generalized fibonacci quaternions and the linear difference equations with periodic coefficients},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid numerical method with high accuracy to solve a time-space diffusion model in terms of the caputo and riesz fractional derivatives. <em>SUPERC</em>, <em>81</em>(7), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07287-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes an efficient hybrid numerical approach that combines high accuracy with low computational cost to approximate solutions of the time-space diffusion model governed by the Caputo and Riesz fractional derivatives. Addressing the fractional time derivative in the Caputo sense, we employ a combination of quadratic and linear interpolations, achieving an accuracy of $$\mathscr {O}\big \{\big (\Delta t\big )^{2-\gamma }\big )\big \}$$ . For the spatial discretisation of the Riesz space-fractional operator, we utilise a compact finite difference scheme with fourth-order accuracy. The stability and convergence properties of the proposed numerical method are rigorously analysed and verified. Finally, we provide with several numerical examples, supplemented by graphical and tabular illustrations, to demonstrate the accuracy, efficiency, and robustness of the proposed approach.},
  archive      = {J_SUPERC},
  author       = {Derakhshan, Mohammad Hossein and Ordokhani, Yadollah and Kumar, Pushpendra and Gómez-Aguilar, J. F.},
  doi          = {10.1007/s11227-025-07287-7},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A hybrid numerical method with high accuracy to solve a time-space diffusion model in terms of the caputo and riesz fractional derivatives},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STGEN: Spatio-temporal generalized aggregation networks for traffic accident prediction. <em>SUPERC</em>, <em>81</em>(7), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07288-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents frequently lead to severe injuries and substantial economic losses, making timely and accurate predictions crucial for improving public safety and reducing financial impacts. However, traditional traffic accident prediction methods lack robust spatial feature modeling, which makes it difficult to effectively respond to complex road conditions and the evaluation of accident probability. Therefore, we propose a two-stream network architecture called STGEN, which integrates focused temporal self-attention with spatial feature transfer. Firstly, a novel road design model is proposed to address the challenges of evaluating complex road conditions based on historical data. This model replaces the traditional grid-based path coverage method by incorporating detailed spatial features, such as road geometry, and consolidating road network information that extends beyond multi-hop neighborhoods. Secondly, the concept of time entropy is introduced and the attention mechanism is used to encode time to further improve the model’s ability to predict traffic accidents in the time dimension. Simultaneously, to enhance the representation of geographic spatial features, a weighted vector graph based on cosine similarity is proposed, which is integrated with a graph structure to strengthen spatio-temporal associations and accurately capture complex spatio-temporal dependencies. Comprehensive simulations conducted on real-world datasets demonstrate the effectiveness and scalability of STGEN.},
  archive      = {J_SUPERC},
  author       = {Li, Xiguang and Zhu, Yuhan and Sun, Yunhe and Guan, Yunchong and Hawbani, Ammar and Muthanna, Ammar and Zhao, Liang},
  doi          = {10.1007/s11227-025-07288-6},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {STGEN: Spatio-temporal generalized aggregation networks for traffic accident prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation of the damped geophysical KdV equation using the explicit exponential time differencing method. <em>SUPERC</em>, <em>81</em>(7), 1--12. (<a href='https://doi.org/10.1007/s11227-025-07289-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tsunami waves, which are strong waves, occur in oceans as a result of an earthquake or volcanic eruptions. Tsunamis propagation are described by the geophysical Korteweg–de Vries (geoKdV) equation. To investigate tsunami attenuation, an experimental study examined the impact of coastal vegetation on tsunami waves. The findings indicated that coastal vegetation effectively contributes to the damping of tsunami wave height. However, the dynamics of the interaction between these waves can be mathematically governed by adding an extra term in the geoKdV equation that is the damping term. The damped geoKdV (dgeoKdV) equation is classified as a non-integrable equation, indicating the absence of an exact analytical solution. Consequently, the main goal of this article is to seek a numerical approximation solution for the dgeoKdV equation. For this purpose, we choose one of the powerful numerical methods for solving initial value problems, that is the explicit exponential time differencing method (ETD method). The method utilizes the exact solution of the geoKdV equation as an initial condition to approximate the solution of the dgeoKdV equation. The numerical simulations conducted show the effect of the interaction between the waves and found that the damping term has an effective impact on the amplitude of the tsunami waves. As the values of the damping term increase, the amplitude of the tsunami waves decreases, causing the width of the waves to be flatten. This impact is opposed to the effect of the Coriolis phenomena. Actually, increasing the values of the Coriolis parameter leads to a decrease in the tsunami wave amplitude.},
  archive      = {J_SUPERC},
  author       = {Ashi, H. A. and Aljahdaly, Noufe H.},
  doi          = {10.1007/s11227-025-07289-5},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--12},
  shortjournal = {J. Supercomput.},
  title        = {Investigation of the damped geophysical KdV equation using the explicit exponential time differencing method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABIDS-VEM: Leveraging an equilibrium optimizer and data ramification in association with ensemble learning for anomaly-based intrusion detection system. <em>SUPERC</em>, <em>81</em>(7), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07292-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of the Internet of Things (IoT) and Industrial Internet of Things (IIoT) within the Industry 4.0 paradigm leverages software-defined networking, multi-cloud architectures, and edge/fog computing to enhance industrial processes. However, this digital transformation introduces significant cybersecurity and privacy vulnerabilities within the complex, data-intensive IoT/IIoT ecosystems. To mitigate these risks, this research proposes a novel Anomaly-based Intrusion Detection System using Voting-based Ensemble Model (ABIDS-VEM) in Industry 4.0 environments. The VEM architecture synergistically combines multiple machine learning algorithms and gradient boosting frameworks, including CatBoost (CB), XGBoost (XGB), LightGBM (LGBM), Logistic Regression (LR), and Random Forest (RF), to enhance the precision and computational efficiency of intrusion detection systems (IDS) in IoT/IIoT contexts. The proposed framework incorporates a data ramification process, in which the data is divided into multiple parts, feature selection process which is optimized through the Equilibrium Optimizer (EO) algorithm, and outlier detection utilizing the Isolation Forest (IF) method. Comprehensive empirical evaluations were conducted using three benchmark datasets: XIIoTID, NSL-KDD, and UNSW-NB15, to validate the efficacy of the proposed system. The model achieves high accuracy across datasets: 98.1476% for XIIoT-ID, an impressive accuracy of 98.9671% for NSL-KDD, and 94.1327% for UNSW-NB15 dataset. These experimental results demonstrate the potential of this approach to significantly enhance the resilience of critical industrial systems and data against evolving cyber threats, thereby supporting the continued evolution of Industry 4.0 technologies and bolstering the security posture of IoT/IIoT ecosystems. This research contributes to the ongoing efforts to secure the rapidly expanding digital industrial landscape, offering a robust solution for detecting and mitigating sophisticated cyberattacks in the increasingly interconnected and data-driven industrial environments of the future.},
  archive      = {J_SUPERC},
  author       = {Verma, Priyanka and O’Shea, Donna and Newe, Thomas and Mehta, Nakul and Bharot, Nitesh and Breslin, John G.},
  doi          = {10.1007/s11227-025-07292-w},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {ABIDS-VEM: Leveraging an equilibrium optimizer and data ramification in association with ensemble learning for anomaly-based intrusion detection system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective scheduling of heterogeneous parallel systems using the VITS algorithm. <em>SUPERC</em>, <em>81</em>(7), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07293-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous systems are widely used to implement a wide range of critical services. Resource management is a key challenge in parallel systems and becomes more complicated when system resources are heterogeneous. The issue of resource heterogeneity from different aspects simultaneously has not received much attention in the literature. This study addresses this issue and investigates multi-objective scheduling in heterogeneous parallel environments regarding processing speed and cost. The main objectives are increasing the system's throughput by completing more tasks, improving the system's profitability, and reducing the total completion time and runtime. Proper task allocation and scheduling on heterogeneous resources are effective in achieving goals. This paper introduces a vector allocation and scheduling approach improved by an extended tabu search-based strategy. In the proposed methodology, abbreviated as the VITS, a vector approach is first used to allocate and schedule tasks on heterogeneous resources. Then, the vector is improved using an extended tabu search-based strategy to obtain better results for the objectives. The proposed methodology utilizes several efficient genetic algorithm mutation methods to produce better and high-quality solutions. The proposed algorithm was simulated and evaluated on several benchmark files of different sizes, containing a minimum of 100 tasks and 10 heterogeneous resources and a maximum of 500 tasks and 80 heterogeneous resources. The simulation results are compared with other selected algorithms, including a vector allocation method improved by genetic (VIGA) and simulated annealing (VISA) algorithms. The evaluation of the results verifies the superiority of the proposed algorithm. Comparing the results on the various test files demonstrates that the proposed VITS compared to VIGA and VISA have respectively an average percentage improvement of 6.9 and 7.7 in task completion rate, 3.8 and 5.3 in profitability, 4 and 2.9 in total task completion time, and 66 and 500 in the algorithm's runtime.},
  archive      = {J_SUPERC},
  author       = {Bakhoda, Saeedeh and Abdollahi Azgomi, Mohammad and Ebrahimi Dishabi, Mohammad Reza},
  doi          = {10.1007/s11227-025-07293-9},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Multi-objective scheduling of heterogeneous parallel systems using the VITS algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of resource-aware parallel and distributed computing: A review. <em>SUPERC</em>, <em>81</em>(7), 1--80. (<a href='https://doi.org/10.1007/s11227-025-07295-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a review of state-of-the-art solutions concerning the optimization of computing in the field of parallel and distributed systems. Firstly, we contribute by identifying resources and quality metrics in this context including servers, network interconnects, storage systems, computational devices as well as execution time/performance, energy, security, and error vulnerability, respectively. We subsequently identify commonly used problem formulations and algorithms for integer linear programming, greedy algorithms, dynamic programming, genetic algorithms, particle swarm optimization, ant colony optimization, game theory, and reinforcement learning. Afterward, we characterize frequently considered optimization problems by stating these terms in domains such as data centers, cloud, fog, blockchain, high performance, and volunteer computing. Based on the extensive analysis, we identify how particular resources and corresponding quality metrics are considered in these domains and which problem formulations are used for which system types, either parallel or distributed environments. This allows us to formulate open research problems and challenges in this field and analyze research interest in problem formulations/domains in recent years.},
  archive      = {J_SUPERC},
  author       = {Czarnul, Paweł and Antal, Marcel and Baniata, Hamza and Griebler, Dalvan and Kertesz, Attila and Kessler, Christoph W. and Kouloumpris, Andreas and Kovačić, Salko and Markus, Andras and Michael, Maria K. and Nikolaou, Panagiota and Öz, Isil and Prodan, Radu and Rakić, Gordana},
  doi          = {10.1007/s11227-025-07295-7},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--80},
  shortjournal = {J. Supercomput.},
  title        = {Optimization of resource-aware parallel and distributed computing: A review},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VFCkM: A federated clustering framework based on k-means algorithm for vertically partitioned data with shared attributes. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07296-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning (ML) requires the aggregation of training data on a central server, which introduces various constraints. Federated learning (FL) emerges as a promising solution for real-world applications where direct aggregation of data is not feasible. It addresses ML challenges by facilitating collaborative learning of a shared model among different clients without the need to exchange their local data with a central server. This decentralized training approach ensures the privacy of clients’ data. Vertical FL (VFL) has gained significance as a crucial learning framework for training models on vertically distributed data. This study proposes an efficient clustering framework for VFL based on k-means with shared attributes among clients (VFCkM). Unlike previous research in vertical federated clustering, where the assumption is that all clients possess identical samples but varied attributes, our approach introduces a new clustering framework incorporating shared attributes among the clients’ data. VFCkM has been comprehensively evaluated against recent existing studies using eight real-world datasets under varying cluster configurations. VFCkM minimizes the average runtime across all real datasets by 85.8, 48.0, and 57.4% comparing to FSDPC, FFCM, and HFDPC, respectively.},
  archive      = {J_SUPERC},
  author       = {Alfawaz, Oruba and El-Moursy, Ali A. and Saad, Mohamed and Khedr, Ahmed M.},
  doi          = {10.1007/s11227-025-07296-6},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {VFCkM: A federated clustering framework based on k-means algorithm for vertically partitioned data with shared attributes},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tiny-ParsBERT: An optimized hybrid model for efficient sentiment analysis in persian texts. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07297-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis in Persian texts poses a persistent challenge in the field of natural language processing (NLP) due to the unique linguistic features and structural complexities of the language. Existing methods for sentiment analysis often demand substantial computational resources because of their reliance on complex models with numerous parameters. Despite this, these methods frequently fail to achieve satisfactory levels of accuracy and generalization. Additionally, their performance deteriorates when confronted with unconventional or noisy data, limiting their efficiency in real-world applications. This research proposes a novel transformer-based model tailored for sentiment analysis in Persian texts. By reducing the number of model layers and employing adversarial training techniques, the proposed approach significantly enhances performance. The reduction in model parameters not only improves computational efficiency but also achieves superior accuracy and F1-score compared to existing approaches. Experimental evaluations reveal that the proposed model attains an accuracy of 96.84 and an F1-score of 96.83 on the “Taghche” dataset, and an accuracy of 90.72 and an F1-score of 90.69 on the “Snappfood” dataset. These results highlight the model’s clear advantage in developing lightweight, faster, and more effective sentiment analysis systems for practical and wide-ranging applications.},
  archive      = {J_SUPERC},
  author       = {Nooraee, Mohsen and Ghaffari, Hamidreza and Zarisfi Kermani, Fateme},
  doi          = {10.1007/s11227-025-07297-5},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Tiny-ParsBERT: An optimized hybrid model for efficient sentiment analysis in persian texts},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobile crowd sensing based spectrum monitoring with privacy protection and malicious behavior detection using hyperledger fabric and identity mixer. <em>SUPERC</em>, <em>81</em>(7), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07300-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowd Sensing (MCS)-based spectrum monitoring emerges to check the status of the spectrum for dynamic spectrum access. For privacy-preserving purposes, spectrum sensing reports may be sent anonymously. However, anonymous submission of reports increases the probability of fake reports by malicious participants. Also, it is necessary to assign a fair reward to encourage the honest participants, which needs to take into account participant’s reputation. In this research, a method is presented for MCS-based spectrum monitoring which uses Hyperledger Fabric and Identity Mixer (Idemix). This framework overcomes security challenges such as providing anonymity of the participants, identifying malicious participants, detecting intentional and unintentional incorrect reports, and providing a secure protocol to reward participants. An intuitive evaluation of the security features of the proposed method confirms that the proposed method withstands key threats, such as de-anonymization, participant misbehavior, privacy-compromising collusion among system entities, and reputation manipulation attack. Also, numerical evaluations show that the proposed method is superior compared to the similar centralized method in terms of delay when the number of participants is sufficiently large. Specifically, it achieves an average improvement of approximately 39% in scenarios involving 1000 to 2000 participants, and more than a twofold reduction in delay for the case with 2000 participants. Notably, this enhancement comes without a substantial increase in signaling overhead, which remains only slightly more than double that of the centralized method. Moreover, simulations show that the proposed method can successfully distinguish malicious participants from the honest ones in most scenarios.},
  archive      = {J_SUPERC},
  author       = {Yaqoubi, Zahra and Ghahfarokhi, Behrouz Shahgholi and Seifhashemi, Faegheh and Mahdavi, Mojtaba},
  doi          = {10.1007/s11227-025-07300-z},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {Mobile crowd sensing based spectrum monitoring with privacy protection and malicious behavior detection using hyperledger fabric and identity mixer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing aspect-level sentiment analysis through the integration of local context interdependencies and syntactic quality compensation. <em>SUPERC</em>, <em>81</em>(7), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07301-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification (ASC) predicts sentiment polarities for specific aspect terms in written text. Although incorporating syntax information significantly enhances ASC, two primary issues remain overlooked. First, many models focus on identifying aspect-related local contexts by analyzing the syntactical relationship between aspect terms and context words. However, they neglect the interdependencies between various contexts, limiting the comprehensiveness and depth of aspect-related sentiment representations. Second, variations in sentence syntax quality pose challenges to dynamic adaptation. To address these issues, we initially decompose syntax trees into two sub-trees, facilitating the precise identification of aspect-related local contexts and the differentiation of their roles. We introduce the fusion network with syntax-based learning and semantics-based assistance (FN-SLSA). This model exploits a wider range of syntax information to learn aspect-related representations. Based on these representations, it further constructs a syntax-based sentiment representation. This representation is enriched with deeper and more comprehensive semantics derived from the interdependencies between these representations. Additionally, the model learns a semantics-based sentiment representation that complements the syntax-based sentiment representation and adapts to variations in syntax tree quality. Experimental results on four benchmark datasets demonstrate that the FN-SLSA model outperforms a range of state-of-the-art models. Moreover, the ablation experiments and case study verify the effectiveness of important components in this model.},
  archive      = {J_SUPERC},
  author       = {Zhou, Jinfeng and Zeng, Xiaoqin and Zou, Yang and Zhu, Haoran},
  doi          = {10.1007/s11227-025-07301-y},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing aspect-level sentiment analysis through the integration of local context interdependencies and syntactic quality compensation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontological approach towards discovering and recommending COVID-19 therapeutics, risk factors, and drug interactions. <em>SUPERC</em>, <em>81</em>(7), 1--59. (<a href='https://doi.org/10.1007/s11227-025-07302-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s data-driven world, integrating diverse healthcare data sources into a unified framework is essential. The COVID-19 pandemic has underscored the critical need for extracting meaningful insights from fragmented clinical data, particularly in areas such as treatment efficacy, risk factor identification, and drug interactions. To address these challenges, we propose the COVID-19 Drug and Risk Ontology (COViDRO)-a formally developed OWL-DL ontology designed to model and integrate COVID-19 treatment options aligned with the “PRADiCT” framework (Patient Risk factors, Adverse effects, Drug interaction, Clinical findings, and Treatment procedure). We hypothesize that this ontology will assist healthcare professionals in discovering and recommending COVID-19 therapeutics tailored to individual patients by considering risk factors, underlying health conditions, ongoing medications, potential drug interactions, and adverse effects. To validate its reliability and effectiveness, COViDRO underwent a multi-tier evaluation process: (1) Quality-based assessment using the Ontology Pitfall Scanner (OOPS!) to detect and resolve modeling errors, benchmarking COViDRO against related ontologies based on structural, functional, and usability dimensions; (2) Structural and logical validation using OntoDebug for structural integrity checks and the Pellet reasoner for logical consistency verification; (3) Quantitative evaluation using the OntoMetrics framework to assess ontology metrics such as attribute richness, relation richness, and knowledge base complexity, comparing with related ontologies; and (4) Query-based evaluation using SPARQL to assess the ontology’s reasoning and retrieval capacity. The evaluation results confirm that COViDRO effectively organizes 135 classes, 32 object properties, and 15 data properties, enabling structured clinical reasoning. SPARQL queries successfully demonstrate its ability to retrieve patient-specific therapeutic recommendations, assess risk factors, and generate drug interaction alerts, validating its practical utility in healthcare settings. As a formal, DL-enabled ontology, COViDRO can contribute to automated inference of treatment options, thereby enhancing decision support systems and knowledge-based applications. Its structured and extensible approach makes it a valuable resource not only for COVID-19 but also for future pandemics and infectious disease management, reinforcing its significance in healthcare informatics.},
  archive      = {J_SUPERC},
  author       = {Bain, Debanjali and Dutta, Biswanath},
  doi          = {10.1007/s11227-025-07302-x},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--59},
  shortjournal = {J. Supercomput.},
  title        = {Ontological approach towards discovering and recommending COVID-19 therapeutics, risk factors, and drug interactions},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing keyphrase extraction with dependency relation-aware attention graph convolutional networks. <em>SUPERC</em>, <em>81</em>(7), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07303-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyphrase extraction is a significant challenge in natural language processing with diverse applications. However, existing state-of-the-art methods model documents using convolutional neural networks, focusing solely on local feature subsequences to capture local relationships between adjacent elements. This disregards the importance of the overall structure of the document, directly impacting the quality of generated keyphrases. To address this challenge, we propose an end-to-end framework for keyphrase extraction that explores the integration of dependency-awareness, self-attention, and graph convolutional networks for latent representation learning. Additionally, we construct a label selection filter to optimize keyphrase prediction results based on global representations by integrating selection vectors, thereby enhancing the accuracy of keyphrases. Competitive experimental results on public datasets validate the effectiveness of the proposed method over state-of-the-art methods. The experimental results show an average improvement of about 1.9% and 7.8% in $$F_1$$ @5 and $${F_1}$$ @10 scores, respectively, on the four major public datasets.},
  archive      = {J_SUPERC},
  author       = {Dong, Yuyu and Liu, Fang’ai and Zhuang, Xuqiang and Bai, Ran and Gao, Xuejian},
  doi          = {10.1007/s11227-025-07303-w},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing keyphrase extraction with dependency relation-aware attention graph convolutional networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGFormer: A multi-information-based GRU-transformer network for pedestrian trajectory prediction. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07304-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction plays a crucial role in enabling fully autonomous driving in urban environments, this paper proposes a GRU-Transformer network with multi-information integration (MGFormer) to predict pedestrian trajectories from a driving perspective. Firstly, MGFormer integrates pose and optical flow information with observed trajectory information. It uses skeleton sequence reorganization and local optical flow division techniques to reduce information distortion caused by occlusion. Subsequently, a cross-information fusion attention mechanism based on information evaluation is introduced. This mechanism comprehensively considers the importance of various information sources and the relevance of different features within each information source. Finally, MGFormer utilizes an innovative trajectory decoding network that combines GRU and Transformer models to enhance the effectiveness of decoding and predicting fused features. On the JAAD and PIE datasets, this method outperforms other approaches in predicting the displacement error within a 1.5 second, while also significantly reducing inference time compared to the latest model.},
  archive      = {J_SUPERC},
  author       = {Liu, Quankai and Sang, Haifeng and Wang, Jinyu and Chen, Wangxing},
  doi          = {10.1007/s11227-025-07304-9},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {MGFormer: A multi-information-based GRU-transformer network for pedestrian trajectory prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An alternative proposed single error detection algorithm for the single parity check algorithm. <em>SUPERC</em>, <em>81</em>(7), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07305-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, our objective is to propose an alternative algorithm to the single parity check algorithm that exhibits improved capabilities. To achieve this, we introduce a function for symmetrizing binary codes with an error resilience capability. Additionally, we present the symmetry check algorithm for error detection and provide a theoretical proof that the error detection bits of the symmetry check algorithm not only identify errors but also enable the recovery of a portion of the original binary code bits. The symmetry check algorithm has the ability to recover a portion of the data in any channel, regardless of the level of noise present, in proportion to the introduced noise. By implementing the symmetry check algorithm on a group of $$512 \times 512$$ grayscale images with a $$20\%$$ error probability, we observed a $$25\%$$ increase in the peak signal-to-noise ratio. This feature is not present in the single parity check algorithm. One of our key achievements is that in the event of data loss in the original image, the symmetry check algorithm can detect it using the symmetry bits and recover the lost image as a black and white image, while still performing error control.},
  archive      = {J_SUPERC},
  author       = {Gharehbagheri, Parviz and Javadi, Hamid Haj Seyyed and Rad, Nader Jafari and Bakhshi, Hamidreza},
  doi          = {10.1007/s11227-025-07305-8},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {An alternative proposed single error detection algorithm for the single parity check algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TMTC: Trusted multi-modal transformer classification framework for video frame deletion detection. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07307-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of information technology, video data have become a primary source of information on the internet, shaping public perception. However, maliciously tampered videos pose a serious threat to social trust, highlighting the necessity for video authentication. This study focuses on the detection of video frame deletion manipulation. Although existing frame deletion forensic methods have achieved remarkable progress, most rely solely on visual data, limiting their performances in complex scenarios. To address this limitation, we propose a novel framework, TMTC (Trustworthy Multimodal Transformer Classification), which integrates both audio and visual features for improved detection performance. Specifically, the framework leverages an enhanced ResNet to extract audio features and a three-dimensional convolutional neural network (3DCNN) to capture visual features. The multimodal fusion method, which is based on uncertainty, may yield conflicts in confidence levels during the feature fusion process. To facilitate effective multimodal fusion, we propose a cross-modal feature mediation (CFM) module that addresses modality-specific confidence bias and resolves inter-modal discrepancies, including temporal misalignment and feature inconsistency. Finally, a Dempster-Shafer evidence theory module is utilized for robust classification. Experimental results show that TMTC achieves a 1.48% accuracy improvement on non-degraded datasets and a 5.43% improvement on noisy datasets, compared to the best-performing method among the state-of-the-art frame deletion detection techniques evaluated.},
  archive      = {J_SUPERC},
  author       = {Feng, Chunhui and Zhong, Yongxiang and Huang, Yigong and Liu, Xiaolong},
  doi          = {10.1007/s11227-025-07307-6},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {TMTC: Trusted multi-modal transformer classification framework for video frame deletion detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive context learning for two-stage human-object interaction detection. <em>SUPERC</em>, <em>81</em>(7), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07308-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-object interaction (HOI) detection aims to localize humans and objects and infer their interactions in an image. Specifically, transformer-based two-stage methods exhibit outstanding training and performance advantages. However, these methods often utilize object features lacking fine-grained context for HOI classification, neglecting pose and orientation information, and suffering from insufficient relation context for HOI triplets’ relational reasoning. In this paper, we propose a two-stage transformer-based model to address these issues. Firstly, we introduce a novel explicit query construction method for the decoder, leveraging spatial and content priors from the object detector along with human pose information to initialize these queries. This enables the decoder to effectively identify the type of interaction. Additionally, we improve the cross-attention in the decoding process to better reintroduce image features and propose parallel branch decoders to separately perform interaction classification and optimize instance detection. Between the two decoders, we employ a novel attentive fusion module to generate and propagate the relation context, assisting the model in relational reasoning. Extensive experiments conducted on two widely used public benchmarks demonstrate the effectiveness of our approach. The results show that our model surpasses other methods and achieves state-of-the-art performance.},
  archive      = {J_SUPERC},
  author       = {Xia, Limin and Xiao, Qiyue},
  doi          = {10.1007/s11227-025-07308-5},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Comprehensive context learning for two-stage human-object interaction detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AAMB: A cross-domain identity authentication scheme based on multilayered blockchains in IoMT. <em>SUPERC</em>, <em>81</em>(7), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07309-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet of medical things (IoMT) integrates various sensors, smart devices, and fully utilizes medical data to provide high-quality medical services through the Internet of Things (IoT). Smart medical devices can be cross-domain shared in IoMT to provide health monitoring, disease diagnosis, rehabilitation training, etc. In IoMT, conventional authentication schemes struggle to meet cross-domain medical service sharing requirements due to resource constraints (computational/communication), confidentiality challenges, and strict latency demands. To address these issues, we propose a cross-domain authentication scheme based on dynamic accumulators and two-layer blockchains. First, a blockchain-based collaborative authentication framework is designed to realize secure and reliable intradomain and cross-domain authentication. Second, certificateless cryptography and dynamic accumulators are combined to guarantee both the confidentiality and efficiency of cross-domain authentication. Furthermore, we analyze the potential security threats that threaten the system’s stability and formally demonstrate the security of the proposed scheme using Burrows–Abadi–Needham logic. The formal and informal security analyses indicate that the proposed scheme is secure and can resist against known security threats. Finally, we evaluate the performance of the proposed authentication protocols in terms of computational and communication overhead. The corresponding performance analysis shows that compared with related protocols, it can reduce the computational and communication costs by more than 42.3% and 21.4%, respectively.},
  archive      = {J_SUPERC},
  author       = {Zhang, Zheqing and Li, Hongzhi and Li, Dun and Li, Kuan-Ching},
  doi          = {10.1007/s11227-025-07309-4},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {AAMB: A cross-domain identity authentication scheme based on multilayered blockchains in IoMT},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse correction-optimized vertical federated unlearning. <em>SUPERC</em>, <em>81</em>(7), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07310-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertical federated learning (VFL) is a distributed machine learning technique that enables collaborative training between an active party with labeled features and passive parties with unlabeled features. While VFL ensures data privacy and improves model performance, it lacks an effective and efficient mechanism for users to selectively withdraw their contributions from model updates. In this paper, we propose an inverse correction optimization (ICO) vertical federated unlearning scheme, which allows users to selectively remove their data contributions, whether it involves all or only a subset of their data. Specifically, we frame the unlearning problem as an optimization challenge and develop gradient ascent and gradient correction algorithms tailored to the unique training framework of vertical federated learning. Our approach significantly accelerates the retraining speed of the unlearning model while maintaining the model’s effectiveness. Furthermore, we introduce backdoor attacks during training to evaluate the unlearning effectiveness. Experimental results across various tasks and datasets show that ICO achieves a prediction accuracy that differs by only 3.31% from retraining, with an attack performance differing by just 0.49%. While delivering comparable unlearning performance, ICO also accelerates the unlearning optimization process.},
  archive      = {J_SUPERC},
  author       = {Li, Lang and Hu, Li and Mo, Kanghua and Ding, Ziyu and Wu, Yaqi and Yan, Hongyang and Li, Jin},
  doi          = {10.1007/s11227-025-07310-x},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Inverse correction-optimized vertical federated unlearning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An audio–visual multimodal adaptive balanced learning method based on gradient modulation. <em>SUPERC</em>, <em>81</em>(7), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07311-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenge encountered in audio–visual multimodal learning where heterogeneous learning rates result in one modality dominating the learning process and suppressing other modalities, thus weakening the multimodal collaborative decision-making process, a multimodal adaptive balanced learning method based on gradient modulation (AGM-CR) is proposed. This method introduces modulation coefficients to dynamically adjust the learning rates of different modalities based on gradient variations. A gradient balancing strategy is further employed by incorporating the gradient losses of individual modalities into the total loss as a regularization term to mitigate gradient disparities and balance the learning process. Experimental results show that AGM-CR improves classification accuracy by 3.1% and 1.3% on the CREMA-D and RAVDESS datasets, respectively, and reduces gradient fluctuations over multiple iterations, thereby enhancing training stability and accelerating convergence. Moreover, AGM-CR is a plug-and-play approach, offering greater flexibility and generalizability than the existing balancing methods do.},
  archive      = {J_SUPERC},
  author       = {Ao, Wenxiu and Wang, Zhongmei and Liu, Jianhua and Peng, Shenao and Zheng, Liang},
  doi          = {10.1007/s11227-025-07311-w},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {An audio–visual multimodal adaptive balanced learning method based on gradient modulation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An implicit tubular-aware network for coronary artery segmentation. <em>SUPERC</em>, <em>81</em>(7), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07312-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of coronary arteries is crucial for the diagnosis and monitoring of cardiovascular diseases. To effectively segment coronary arteries and leverage their inherent properties, we propose tubular-aware network (TANet), a network specifically designed for coronary artery segmentation. TANet is designed to leverage the inherent properties of coronary arteries: their macro-level single-connectivity as a tree structure, and the tubular shape of both thick and thin vessels. TANet incorporates a position information propagation (PIP) mechanism, aiming to selectively propagate positional information. In conjunction with a single-connectivity selection (SCS) module, it selects the vascular region from multiple large, vessel-like areas, thereby reducing the impact of substantial non-vascular elements. Finally, a tubular alignment (TA) module employs multi-thickness features fusion to thickness-aligned vascular features, attempting to maintain vascular morphological accuracy while accommodating richer vascular morphology, which further guides the model’s final output. Experimental results on three public, de-identified datasets demonstrate that TANet outperforms most existing methods in improving segmentation accuracy.},
  archive      = {J_SUPERC},
  author       = {Chen, Jialong and Tong, Jijun and Liu, Yicheng and Xia, Shudong},
  doi          = {10.1007/s11227-025-07312-9},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {An implicit tubular-aware network for coronary artery segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal information cooperative interaction network for video salient object detection. <em>SUPERC</em>, <em>81</em>(7), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07314-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video salient object detection is all about identifying the most salient object from a video sequence and segmenting the exact region of that object. Most video salient object detection methods have low performance and low efficiency, and there is much room for improvement. We found that some existing methods consider the advantages of spatial and temporal modalities, but do not fully explore the complementarity between different modalities, which may lead to poor performance of the model when dealing with complex scenes. To cope with the above problems, this paper proposes a novel end-to-end spatiotemporal information cooperative interaction network (SICINet) for salient object detection in video. The network consists of three key modules: cross-modal feature supplementation (CFS), cross-guidance enhancement (CGE), and refinement-adaptive fusion (RAF). Specifically, we propose the CFS module to enable spatiotemporal features to complement each other to facilitate discriminative feature learning, and to learn cross-modal feedback features to ensure the comprehensiveness of salient information in the subsequent fusion stage. In addition, considering that spatiotemporal information can be mutually constrained, we designed the CIE module to use the rough prediction maps of spatiotemporal modalities to bootstrap each other’s multilevel features to filter the unimodal redundant information. Finally, we introduce the RAF module to refine the input features using spatial attention and achieve adaptive weighting fusion by learning the channel weights. Experimental evaluations on four publicly available datasets show that our proposed method is robust under various challenging scenarios (e.g., multiple objects, dynamic foregrounds) and performs more favorably than current state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Wang, Jun and Sun, Chenhao and Wang, Haoyu and Yang, Yang and Ren, Xing and Li, Xiaoli},
  doi          = {10.1007/s11227-025-07314-7},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Spatiotemporal information cooperative interaction network for video salient object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). N-lock: A transaction-released shard reconfiguration protocol with zero-knowledge proof. <em>SUPERC</em>, <em>81</em>(7), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07317-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain has been a significant driver of changes in how cryptocurrencies are conceptualized despite being well-known for the scalability problems, such systems face in terms of the time and cost that it takes to carry out a transaction. While sharding enhances blockchain scalability, cross-shard transactions significantly compromise its effectiveness. Shard reconfiguration can reduce the generation of cross-shard transactions in traditional sharding systems, where the transactions related to the accounts are locked or semi-locked during the reconfiguration process, lengthening the transaction confirmation latency, thus jeopardizing the performance of blockchain sharding. To this end, we propose a transaction-released shard reconfiguration protocol, N-Lock. First, we unlock the account-related transactions (including payer transactions and payee transactions) during reconfiguration, refreshing the account state in the target shard when the reconfiguration is complete. A description of waiting transactions and possible atomicity problems within the proposed method is added to ensure system security. Moreover, to address the latency problem generated by a large number of message validations and queries during the account migration process, a non-interactive zero-knowledge proof to avoid query operations is introduced. Experimental evaluations demonstrate that N-Lock has better transaction processing capability than existing shard reconfiguration methods. With eight shards, 32 nodes, and 300,000 transactions, the proposed work’s throughput is 17% higher than other existing methods, with the message verification latency reduced by 79%.},
  archive      = {J_SUPERC},
  author       = {Xu, Nengxiang and Chen, Yuxiang and Liang, Wei and He, Dacheng and Li, Kuanching and Ling, Nam},
  doi          = {10.1007/s11227-025-07317-4},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {N-lock: A transaction-released shard reconfiguration protocol with zero-knowledge proof},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven fuzzy logic control method for improved USV path planning. <em>SUPERC</em>, <em>81</em>(7), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07318-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parameters of the path planning algorithm for unmanned surface vehicles (USVs) usually rely on manual settings, which makes it difficult for the algorithm to achieve the optimal solution when considering multiple factors in path planning. This paper proposes a data-driven method to improve the USV path planning algorithm in response to the problem of unreasonable control caused by manual experience parameter settings in traditional algorithms. Firstly, a dataset is constructed by extracting corresponding parameters from traditional fuzzy logic control algorithms. Then, using two existing fuzzy controllers as samples, a fuzzy neural network is designed. Finally, using this dataset, a new fuzzy logic controller is generated through a fuzzy neural network. Compared with traditional fuzzy logic controllers, data-driven controllers exhibit a more reasonable distribution of variable parameters, thus verifying the superiority of neural network-based controllers. Numerical simulations show that the proposed method improves both the path length and the navigation time, while ensuring safety in complex environments.},
  archive      = {J_SUPERC},
  author       = {Wang, Feng and Wang, Chenglong and Wang, Yuanhui and Chemori, Ahmed and Zhang, Xiaoyue and Zhang, Kun and Zhang, Yuxuan},
  doi          = {10.1007/s11227-025-07318-3},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Data-driven fuzzy logic control method for improved USV path planning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the application of quantum technologies to industrial and real-world use cases. <em>SUPERC</em>, <em>81</em>(7), 1--6. (<a href='https://doi.org/10.1007/s11227-025-07320-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in quantum computing are leading to an era of practical utility, enabling the tackling of increasingly complex problems. The goal of this era is to leverage quantum computing to solve real-world problems in fields such as machine learning, optimization, and material simulation, using revolutionary quantum methods and machines. All this progress has been achieved even while being immersed in the noisy intermediate-scale quantum era, characterized by the current devices’ inability to process medium-scale complex problems efficiently. Consequently, there has been a surge of interest in quantum algorithms in various fields. Multiple factors have played a role in this extraordinary development, with three being particularly noteworthy: (i) the development of larger devices with enhanced interconnections between their constituent qubits, (ii) the development of specialized frameworks, and (iii) the existence of well-known or ready-to-use hybrid schemes that simplify the method development process. In this context, this manuscript presents and overviews some recent contributions within this paradigm, showcasing the potential of quantum computing to emerge as a significant research catalyst in the fields of machine learning and optimization in the coming years.},
  archive      = {J_SUPERC},
  author       = {Osaba, Eneko and Villar-Rodriguez, Esther and Oregi, Izaskun},
  doi          = {10.1007/s11227-025-07320-9},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--6},
  shortjournal = {J. Supercomput.},
  title        = {Exploring the application of quantum technologies to industrial and real-world use cases},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instruction selection optimization for VLIW architecture based on classification node merging. <em>SUPERC</em>, <em>81</em>(7), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07323-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional instruction selection methods fail to fully exploit the very long instruction word (VLIW) architecture’s efficient scalar instructions. We propose an optimized instruction selection method based on classification node merging. This method abstracts scalar intermediate instructions into nodes and divides them into associated and similar ones according to operational semantics. Combined with the VLIW architecture’s instruction set features and guided by the instruction cost model, the nodes are merged and optimized to select efficient instructions. We design an instruction generation framework that swiftly converts the low level virtual machine intermediate representation into the instruction sequence of the target architecture. The experimental results show that, compared with the instruction sequence generated by M7002-cc, the instruction sequence generated with the solution proposed in this paper exhibits an average execution performance that is up to 54% higher on the FT-M7002 hardware platform.},
  archive      = {J_SUPERC},
  author       = {Liu, Fangjun and Zhang, Huifu and Hu, Yonghua and Xie, Anxing and Cao, Wei and Mo, Shangfeng},
  doi          = {10.1007/s11227-025-07323-6},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Instruction selection optimization for VLIW architecture based on classification node merging},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An oversampling method based on the weighting of minority class clusters. <em>SUPERC</em>, <em>81</em>(7), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07325-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversampling algorithms improve imbalanced dataset classification by increasing the quantity of the minority class to reduce the domination of the majority class. The existing oversampling methods only focus on solving the imbalance problem between classes, often ignoring the imbalance problem within the class, and even producing noise or unnecessary samples. The weighted minority cluster oversampling algorithm (WMCOA) was proposed to solve this problem. This method can avoid the generation of new noise samples, and effectively solve the problem of intra-class and inter-class imbalance, so as to make the data set samples achieve a better-balanced proportion. In the experiments of 20 imbalanced data sets, support vector machine, K-nearest neighbor, and random forest were used as classifiers. The experimental results show that compared with several commonly used imbalanced data processing algorithms, the proposed algorithm can effectively improve the performance of imbalanced data. The WMCOA algorithm has achieved better results in F-measure, G-mean, and AUC evaluation indicators.},
  archive      = {J_SUPERC},
  author       = {He, Yunbin and Li, Chenglong and Guo, Fuwei},
  doi          = {10.1007/s11227-025-07325-4},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {An oversampling method based on the weighting of minority class clusters},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MapsTSF: Efficient traffic prediction via hybrid mamba 2-transformer spatiotemporal modeling and cross adaptive periodic sparse forecasting. <em>SUPERC</em>, <em>81</em>(7), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07328-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is a critical yet challenging task due to the complex spatiotemporal dependencies in road networks. We propose MapsTSF, a novel framework that enhances traffic forecasting by integrating three innovative components. Spatial path embedding uses multiple traversal algorithms to capture dynamic spatial flow patterns across road networks. The hybrid Mamba2-transformer model combines Mamba2’s selective state-space modeling with transformer’s global attention to effectively capture intricate spatiotemporal dependencies. Additionally, the cross adaptive periodic sparse forecasting mechanism decouples periodic and trend features, reducing computational overhead while preserving high accuracy. Experiments on real-world datasets demonstrate that MapsTSF outperforms baseline methods by an average of 18.80% in MAE, 15.69% in RMSE, and 19.80% in MAPE. With its scalable and efficient design, MapsTSF is well-suited for real-time traffic management in smart cities and navigation applications, providing precise and reliable forecasts for large-scale, dynamic road networks.},
  archive      = {J_SUPERC},
  author       = {Wang, Bing and Cai, Chaoqi and Zhang, Xingpeng and Zhao, Chunlan and Zhang, Chi and Zhang, Youming},
  doi          = {10.1007/s11227-025-07328-1},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {MapsTSF: Efficient traffic prediction via hybrid mamba 2-transformer spatiotemporal modeling and cross adaptive periodic sparse forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized machine learning for real-time, non-invasive blood pressure monitoring. <em>SUPERC</em>, <em>81</em>(7), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07330-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous, non-invasive blood pressure (BP) monitoring is essential for managing cardiovascular health; yet, traditional cuff-based systems are unsuitable for real-time use. This study presents a hybrid machine learning framework that fuses photoplethysmography and electrocardiography signals with optimized feature selection to achieve accurate and efficient BP estimation. By leveraging complementary signal characteristics, key physiological features such as pulse transit time and pulse arrival time are extracted to improve predictive performance. A Random Forest model tailored for physiological data yields state-of-the-art accuracy, with a mean absolute error of 1.602 mmHg for diastolic and 2.082 mmHg for systolic BP, exceeding clinical standards. The model maintains high accuracy while reducing feature dimensionality by 80%, supporting real-time deployment on wearable devices. This AI-driven approach addresses sensor variability and computational constraints, offering a practical solution for continuous, cuffless BP monitoring in personalized and digital healthcare.},
  archive      = {J_SUPERC},
  author       = {Eldakhly, Nabil M.},
  doi          = {10.1007/s11227-025-07330-7},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Optimized machine learning for real-time, non-invasive blood pressure monitoring},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QENN: Breast cancer prediction using quantum-enhanced neural network. <em>SUPERC</em>, <em>81</em>(7), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07331-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer continues to be a major worldwide health issue, requiring advanced predictive models for better healthcare outcomes and early detection. This research presents the novel quantum-enhanced neural network (QENN), a hybrid classical-quantum approach that integrates a classical neural network with a quantum feature map and a parameterized quantum circuit to enhance breast cancer classification performance. The QENN model is applied to both the wisconsin (diagnostic) breast cancer dataset (WBCD) and the SEER breast cancer dataset (SBCD). For the WBCD, QENN was able to deliver high-performance comparable to classical machine learning models and state-of-the-art research work, thus demonstrating the capability to extract complex patterns in biomedical datasets. For the SBCD, a dataset with class imbalance and high number of categorical features, QENN performed reasonably compared to classical machine learning models, after application of several preprocessing steps. However, it demonstrated a comparably high AUC-ROC score, which has been proven to be one of the most reliable metrics for imbalanced datasets. The study demonstrates the potential of QENN in biomedical applications, showing strong performance on balanced and well-processed datasets while maintaining comparable effectiveness on datasets with moderate class imbalance and high cardinality categorical features by leveraging quantum principles for distinct data representation and class separability.},
  archive      = {J_SUPERC},
  author       = {Dixit, Vimal and Rajkumar, Krishnan},
  doi          = {10.1007/s11227-025-07331-6},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {QENN: Breast cancer prediction using quantum-enhanced neural network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PB-UOKM: A policy-based updatable oblivious key management scheme for secure and practical data sharing in remote storage. <em>SUPERC</em>, <em>81</em>(7), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07332-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of big data and cloud computing has led to a significant increase in data storage, computation, and sharing on cloud servers. While offering substantial benefits, this shift also introduces critical security challenges, particularly regarding the protection of sensitive information from cyber threats and unauthorized access. This paper addresses these challenges by introducing PB-UOKM, a policy-based updatable oblivious key management scheme, which facilitates secure and practical data sharing in cloud storage environments. PB-UOKM effectively alleviates the burden of key management for users by storing private keys securely in a key management server (KMS) and ciphertexts in a storage server (STS). When a user sends a data access request, the KMS and the STS return the encrypted private keys and the corresponding ciphertext, respectively. The scheme also supports time-bounded secrecy through key and ciphertext updates, ensuring privacy during key rotation. The contributions of this paper include a comprehensive review of updatable oblivious key management, the integration of key insulation with updatable oblivious key management to create PB-UOKM, the instantiation of the scheme with concrete algorithms and correctness proofs, and an evaluation of its security and efficacy through theoretical analysis and simulation results. PB-UOKM is positioned as a robust solution for secure data storage in cloud computing scenarios, addressing the need for granular access control and privacy preservation.},
  archive      = {J_SUPERC},
  author       = {Hong, Hanshu and Sun, Yibo and Sun, Zhixin},
  doi          = {10.1007/s11227-025-07332-5},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {PB-UOKM: A policy-based updatable oblivious key management scheme for secure and practical data sharing in remote storage},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel conditional discrimination index approach for feature selection in partially labeled hybrid data. <em>SUPERC</em>, <em>81</em>(7), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07333-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, most of the data obtained are hybrid data. Fully labeling such hybrid data is often time-consuming, labor intensive, and costly, while focusing solely on labeled samples may lead to the loss of critical information due to the limited number of labeled data. Research on feature selection using partially labeled data offers significant advantages, such as reducing dependency on labeled data and improving learning efficiency and performance. To address this issue, a semi-supervised feature selection method capable of handling partially labeled data is proposed based on the conditional discrimination index. First, by analyzing the characteristics of hybrid data, the distances between objects in the feature space are constructed, leading to the information granules with respect to feature subsets. Subsequently, in the label space, the missing labels are filled with the set composed of all existing labels, forming new partially labeled hybrid data. Considering the label distances between objects, a new tolerance relation is established to derive decision classes. Based on the information granules and decision classes, the significance of feature subsets is characterized using the discrimination index method. Then, a feature selection algorithm is designed depending on the significance. Experiments conducted on twelve real-world partially labeled hybrid datasets demonstrate that the proposed algorithm outperforms several existing feature selection algorithms in terms of classification accuracy and F1 score. Additionally, to validate the robustness of the algorithm, varying degrees of perturbations are introduced and tested on six of these datasets. The experimental results show that the algorithm still exhibits high stability, proving its applicability and reliability in complex and noisy environments. Statistical analyses further validate these findings. Finally, to further validate the practicality of the algorithm, it is deployed on an actual production line in a factory for fault detection, and significant results are achieved in the experimental tests.},
  archive      = {J_SUPERC},
  author       = {He, Jiali and Abisado, Mideth B.},
  doi          = {10.1007/s11227-025-07333-4},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {A novel conditional discrimination index approach for feature selection in partially labeled hybrid data},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential-trigonometric optimization algorithm with multi-strategy fusion for UAV three-dimensional path planning. <em>SUPERC</em>, <em>81</em>(7), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07335-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of Unmanned Aerial Vehicle (UAV) technology, trajectory planning has emerged as a critical area of research. A three-dimensional path planning method for UAV based on an improved Exponential-trigonometric Optimization Algorithm (IETO) is proposed. The approach constructs a multi-objective optimization function that evaluates path quality by considering key factors such as path length, flight altitude, and turning angle. The IETO algorithm integrates interval-constrained logistic chaotic mapping, an improved dynamic reverse learning strategy, and an adaptive artificial bee colony (ABC) escape mechanism into the Exponential-trigonometric Optimization (ETO) framework, which effectively mitigates premature convergence to local optima. Through benchmark tests using the CEC2017 test set and simulations in high-threat environments demonstrate that the IETO algorithm exhibits superior robustness. Compared to established algorithms such as GWO and GJO, IETO achieves superior performance in most function evaluations. Notably, it excels in solving complex functions, maintaining a balanced approach between exploration and exploitation. In mountainous terrain, IETO generates the smoothest paths with the lowest costs, rapidly converging to the optimal solution. These results highlight the algorithm’s effectiveness and its potential for practical UAV path planning applications.},
  archive      = {J_SUPERC},
  author       = {Xu, Tao and Chen, Chaoyue and Meng, Fanfan and Ma, Dongdong},
  doi          = {10.1007/s11227-025-07335-2},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Exponential-trigonometric optimization algorithm with multi-strategy fusion for UAV three-dimensional path planning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HIFNet: Wavelet transform-enhanced UAV object detection in complex conditions. <em>SUPERC</em>, <em>81</em>(7), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07338-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With deep learning advancements, UAV object detection has great potential in various fields. However, in complex conditions, such as nighttime or fog, small object details are easily obscured by the background, leading to feature loss. To address this, we propose a network based on Wavelet Transform (WT), called the Hierarchical Interactive Fusion Network (HIFNet). First, Wavelet Spatial Frequency Awareness (WSFA) is created to enhance the representation of small objects in complex backgrounds. WT captures edge textures using high-frequency components, while the attention mechanism focuses on target areas. WSFA combines these, using attention weights from high-frequency features to specifically enhance small object expression. Second, Hierarchical Interactive fusion feature pyramid network uses hierarchical interactive fusion technology. Cross-layer fusion enhances shallow and deep features in the backbone, while cross-stage fusion combines shallow details with deep semantics. Then, element-wise addition is used for deep interaction, preserving small details during feature sampling. Finally, the adaptive mixed (A-mixed) loss combines IoU and normalized Wasserstein distance (NWD) losses. It emphasizes small objects by adjusting NWD based on object area and dynamically balances the losses for optimization. Experimental results show HIFNet’s exceptional performance on three datasets, achieving $$\text {mAP}_{50-95}$$ scores of 35.5%, 57.1%, and 55.9%, respectively.},
  archive      = {J_SUPERC},
  author       = {Shang, Lei and Lei, Huan and Wu, Ze and Yang, Wenyuan},
  doi          = {10.1007/s11227-025-07338-z},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {HIFNet: Wavelet transform-enhanced UAV object detection in complex conditions},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPF-unet: A CNN-swin transformer fusion network for 3D brain tumor segmentation in MRI images. <em>SUPERC</em>, <em>81</em>(7), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07339-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) brain tumor segmentation is a crucial task in medical imaging analysis, with significant implications for precision medicine, disease monitoring, and pathology research. However, the complex structural heterogeneity and scale variations of brain tumors in MRI data pose challenges for accurate 3D segmentation. To address these limitations, we propose DPF-Unet, a dual-path U-shaped network designed to synergize the complementary strengths of convolutional neural networks (CNNs) and Transformers for robust tumor segmentation. The CNN path captures fine-grained local details, while the Swin Transformer path models long-range global dependencies, enabling comprehensive feature learning. To unify these dual-path features, we introduce an attentional feature aggregation module that dynamically fuses channel-wise and spatial information across local and global contexts. Furthermore, we develop a multi-level feature fusion module to enrich hierarchical encoder outputs, enhancing segmentation robustness to extreme tumor scale variations. We conducted comprehensive performance evaluations and cross-domain generalization tests on DPF-Unet on the BraTS 2020, BraTS 2021, and BraTS-Africa datasets. The experimental results show that the model exhibits competitive performance on all three datasets, especially on the BraTS 2021 validation set, with Dice Scores of the ET, TC, and WT reaching 84.88 $$\%$$ , 89.44 $$\%$$ , and 91.74 $$\%$$ , respectively. Our experiments validate that DPF-Unet successfully bridges CNN and Transformer paradigms, outperforming existing methods in accuracy and generalization.},
  archive      = {J_SUPERC},
  author       = {Li, Xinxin and Lan, Zhenping and Sun, Yanguo and Sun, Yuheng and Guo, Yuepeng and Wang, Yuru and Yuan, Aixia},
  doi          = {10.1007/s11227-025-07339-y},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {DPF-unet: A CNN-swin transformer fusion network for 3D brain tumor segmentation in MRI images},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cs-pbft: A comprehensive scoring-based practical byzantine fault tolerance consensus algorithm. <em>SUPERC</em>, <em>81</em>(7), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07342-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical Byzantine Fault Tolerance (PBFT) is one of the most important consensus algorithms in distributed systems, which can effectively respond to the threat of malicious nodes. However, PBFT still has shortcomings in terms of arbitrary selection of primary nodes, high communication overhead, and lack of reward and punishment mechanisms. To address this problem, in this paper, we propose a comprehensive scoring-based Practical Byzantine Fault Tolerance consensus algorithm, called CS-PBFT. The algorithm introduces a comprehensive scoring mechanism to evaluate the node’s reliability and overall capability, which is composed of two key metrics: node honor and recommendation scores. Based on this mechanism, the algorithm selects the primary node, slave node, and alternate node to ensure an efficient and secure consensus process. Additionally, the algorithm optimizes the communication process in the Commit and Reply phases of the PBFT consensus protocol, reducing communication latency and improving consensus efficiency. Experimental results show that the improved PBFT algorithm not only improves consensus efficiency but also reduces communication overhead, strengthens fault tolerance against malicious nodes, and demonstrates better scalability.},
  archive      = {J_SUPERC},
  author       = {Liang, Bo and Yuan, Fujiang and Deng, Jiaru and Wu, Qi and Gao, Jie},
  doi          = {10.1007/s11227-025-07342-3},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Cs-pbft: A comprehensive scoring-based practical byzantine fault tolerance consensus algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-aware dynamic scene tracking and reconstruction for mobile robots leveraging visual SLAM. <em>SUPERC</em>, <em>81</em>(7), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07343-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots operating in dynamic environments often encounter challenges due to interference from moving objects, compromising the performance of their SLAM systems. To address this issue, we propose a depth camera based semantic-aware visual SLAM approach for mobile robots, aimed at dynamic scene tracking and reconstruction. By leveraging a lightweight Yolact++ network, we segment and detect objects in the scene, eliminate dynamic features through prior knowledge and epipolar constraints, and utilize high-confidence static features for robot’s pose estimation. Subsequently, the overall similarity between images is evaluated based on the similarity of the matched semantic object regions between images to select high-quality candidate keyframes, effectively enhancing the precision of loop closure detection. Furthermore, we employ Delta Generalized Labeled Multi-Bernoulli (Delta-GLMB) filtering to track the masks of prior dynamic objects provided by Yolact++. A global semantic octree map is then constructed, integrating both the semantic knowledge of the static scene and the tracking information of dynamic targets, which in turn realizes the tracking & reconstruction of the dynamic scene. This allows mobile robots to mimic human behavior and cognitive abilities, not merely to construct a map of unknown environments more efficiently, but also to track the state of moving targets in the field-of-view(FoV) in real-time, enabling self-localization and navigation functions. Experimental results demonstrate the effectiveness of our approach in improving the robustness, accuracy, and adaptability of mobile robots in dynamic environments.},
  archive      = {J_SUPERC},
  author       = {Liu, Tianwei and Luo, Jingwen},
  doi          = {10.1007/s11227-025-07343-2},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Semantic-aware dynamic scene tracking and reconstruction for mobile robots leveraging visual SLAM},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Change detection of remote sensing building images based on dual-domain strip attention DML-UNet network. <em>SUPERC</em>, <em>81</em>(7), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07344-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of building change detection (CD) lies in its contribution to understanding urban development and human activities. Convolutional neural networks have emerged as the predominant approach for CD, yet existing architectures still exhibit limitations in feature extraction and detection accuracy, with most state-of-the-art (SOTA) methods containing millions of parameters. To address this, we propose a dual-domain mixed lightweight U-Net (DML-UNet) for improved building CD in remote sensing imagery. Specifically, our method employs: (1) An optimized EfficientNet-B4 backbone using only its first three module slices for efficient feature extraction, achieving parameter reduction while enhancing performance; (2) A novel dual-domain mixed attention block (DMAB) that processes features through spatial/frequency-domain striping and cross-temporal feature mixing to boost representational capacity with lower computational costs; (3) Upsampling operations combined with a pixel to pixel classifier for precise change identification. Extensive experiments on LEVIR-CD and WHU-CD datasets demonstrate that DML-UNet achieves F1-scores of 91.21% and 91.81%, respectively, with merely 0.31M parameters, outperforming SOTA DSTAMNet by 1.4% and 1.78%, validating its superiority over existing CD methods.},
  archive      = {J_SUPERC},
  author       = {Zhan, MengJun and Xie, XiaoYao and Wang, Heng and Guo, ZhongYuan},
  doi          = {10.1007/s11227-025-07344-1},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Change detection of remote sensing building images based on dual-domain strip attention DML-UNet network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting cyberattacks in smart grids using VGG-16 and whale-fisher mantis optimization algorithm (WOA-FMO). <em>SUPERC</em>, <em>81</em>(7), 1--49. (<a href='https://doi.org/10.1007/s11227-025-07345-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing integration of cyber-physical systems (CPSs) and information and communication technologies (ICT) within the Smart Grid (SG) framework has led to significant advancements in energy systems. However, this integration introduces vulnerabilities, particularly cyberattacks like distributed denial of service (DDoS) attacks. This research presents a new approach to detecting cyberattacks in SG by combining deep learning (DL) techniques with the whale optimization (WOA) and fisher mantis optimization (FMO) algorithm, which forms the WOA-FMO hybrid algorithm. The system utilizes convolutional neural networks (CNN) for feature extraction and long-short-term memory (LSTM) networks to classify network traffic into normal and abnormal categories. The WOA-FMO algorithm optimizes the feature selection process, reducing dimensionality and improving model accuracy, thereby enhancing detection efficiency. Experimental evaluations on the PhishTank, UCI, and Tan datasets demonstrate that the proposed approach outperforms traditional approaches in terms of sensitivity, specificity, accuracy, and precision. A comparison of five optimization algorithms—GOA, ABC, BWO, GWO, and WOA-FMO—reveals that the WOA-FMO hybrid achieves the highest sensitivity (98.86%), accuracy (98.57%), and precision (98.30%), as well as strong specificity (98.28%). These results underscore the effectiveness of WOA-FMO in optimizing feature selection and improving classification performance, offering a robust solution for enhancing the resilience of IoT-based SGs against advanced cyberattacks.},
  archive      = {J_SUPERC},
  author       = {Masaud, Mohamed Ahmed Ali and Avcı, Selçuk Alparslan and Rahebi, Javad},
  doi          = {10.1007/s11227-025-07345-0},
  journal      = {The Journal of Supercomputing},
  month        = {5},
  number       = {7},
  pages        = {1--49},
  shortjournal = {J. Supercomput.},
  title        = {Detecting cyberattacks in smart grids using VGG-16 and whale-fisher mantis optimization algorithm (WOA-FMO)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proposed method of acquiring train data for early-modern japanese printed character recognizers. <em>SUPERC</em>, <em>81</em>(6), 1--28. (<a href='https://doi.org/10.1007/s11227-024-06866-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National Diet Library maintains a digital archive of approximately 400,000 historical texts from the Meiji to early Showa periods (1868–1935), representing a significant corpus of Japanese cultural heritage. While these materials are digitally preserved as high-resolution images, the lack of machine-readable text severely constrains their accessibility and scholarly utility. This limitation particularly impacts early-modern Japanese printed texts, where conventional optical character recognition systems achieve only 60–75% accuracy due to the unique characteristics of historical typography. Current approaches to digitizing these materials face significant challenges: manual transcription is prohibitively expensive for large-scale application, while automated methods struggle with the irregular features of early-modern printed characters, including non-standardized character forms, ink bleeding, and letterpress artifacts. Furthermore, the scarcity of available character samples, particularly for less frequent characters, hinders the development of robust recognition systems. This study presents a novel methodology for enhancing early-modern Japanese character recognition through a two-fold approach: (1) utilizing CycleGAN-generated synthetic characters to augment limited historical samples and (2) developing an optimal mixing strategy between original, generated, and modern characters. Our approach achieves recognition rates of up to 97.81%, significantly outperforming conventional methods while addressing the critical challenge of data scarcity in historical character recognition. Experimental validation demonstrated that our proposed method achieved substantial improvements in recognition accuracy: incorporating generated characters increased recognition rates from 93.43 to 97.81% (p < 0.001) when sufficient original characters were available, and maintained robust performance (94.90%) even with limited historical samples. The model achieved AUC scores consistently above 0.999 across all experiments, demonstrating high reliability in character discrimination regardless of the data composition.},
  archive      = {J_SUPERC},
  author       = {Koiso, Norie and Takemoto, Yuki and Ishikawa, Yu and Takata, Masami},
  doi          = {10.1007/s11227-024-06866-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Proposed method of acquiring train data for early-modern japanese printed character recognizers},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing performance portability for a SYCL implementation of the 2D shallow water equations. <em>SUPERC</em>, <em>81</em>(6), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07063-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SYCL is an open standard for targeting heterogeneous hardware from C++. In this work, we evaluate a SYCL implementation for a discontinuous Galerkin discretization of the 2D shallow water equations targeting CPUs, GPUs, and also FPGAs. The discretization uses polynomial orders zero to two on unstructured triangular meshes. Separating memory accesses from the numerical code allow us to optimize data accesses for the target architecture. A performance analysis shows good portability across x86 and ARM CPUs, GPUs from different vendors, and even two variants of Intel Stratix 10 FPGAs. Measuring the energy to solution shows that GPUs yield an up to 10x higher energy efficiency in terms of degrees of freedom per joule compared to CPUs. With custom designed caches, FPGAs offer a meaningful complement to the other architectures with particularly good computational performance on smaller meshes. FPGAs with High Bandwidth Memory are less affected by bandwidth issues and have similar energy efficiency as latest generation CPUs.},
  archive      = {J_SUPERC},
  author       = {Büttner, Markus and Alt, Christoph and Kenter, Tobias and Köstler, Harald and Plessl, Christian and Aizinger, Vadym},
  doi          = {10.1007/s11227-025-07063-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Analyzing performance portability for a SYCL implementation of the 2D shallow water equations},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective task scheduling algorithm for load balancing in cloud computing based on improved harris hawks optimization. <em>SUPERC</em>, <em>81</em>(6), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07091-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, task scheduling and virtual machine (VM) allocation have emerged as the most significant challenges in resource management in cloud computing environments, which is some kind of optimization problem. The main objective of task scheduling and virtual machine allocation problems is to reduce task length and completion time while boosting resource utilization. Several task scheduling algorithms use heuristic and meta-heuristic techniques to solve this optimization problem. Among these well-known techniques is the Harris hawks optimization (HHO) algorithm. However, most of these approaches failed to consider limitations of HHO, which will have an impact on the task scheduling process. To solve the task scheduling problem in cloud computing (CC), this paper proposes an adaptive task scheduling algorithm that enhances the HHO approach. Rather than selecting a random solution, the suggested approach selects the best-fit solution, whose characteristics are carried over to the next solution in the HHO exploration phase. Furthermore, the modified HHO avoids the local optima solution of HHO by employing a mutation process involved in exploitation phase of HHO. The simulation results demonstrate that the proposed algorithm outperforms the current approaches in terms of standard division for load balancing, makespan, scheduling length, throughput, and resource utilization.},
  archive      = {J_SUPERC},
  author       = {Emara, Farouk A. and Gad-Elrab, Ahmed A. A. and Sobhi, Ahmed and Alsharkawy, Almohammady S. and Embabi, Mahmoud E. and El-Baky, M. A. Abd},
  doi          = {10.1007/s11227-025-07091-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Multi-objective task scheduling algorithm for load balancing in cloud computing based on improved harris hawks optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social recommendation based on contrastive learning of hypergraph convolution. <em>SUPERC</em>, <em>81</em>(6), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07143-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems often use social relationships to improve recommendation quality in the face of sparse data. However, in reality, user interactions can be very complex, user relationships may be high-order, and the contribution of each neighbor may be different. Therefore, traditional social relationship methods cannot fully explore user interactions. Additionally, data sparsity can lead to poor model robustness, making it susceptible to noisy data. To address these issues, this paper proposes a multi-channel hypergraph convolutional network model based on contrastive learning, aiming to enhance social recommendation through high-order user relationships and contrastive learning. The model includes an embedding layer, a propagation layer, and a contrastive learning layer. For user embedding, each channel of the propagation layer learns high-order embedding information through hypergraph convolution. For item embedding, the neighbor-aware attention coefficient is used to mine the implicit correlations of items. In addition, the contrastive learning layer adds randomly uniform noise to the embedding to perform graph augmentation at the representation level, using contrastive learning to obtain more uniformly distributed embedding representations for score prediction. Experimental results on two real datasets, Douban and Yelp, show that the proposed model improves Predict, Recall and NDCG by 1.42 $$-$$ 2.11%, 1.30 $$-$$ 2.30% and 1.89 $$-$$ 2.74%, respectively.},
  archive      = {J_SUPERC},
  author       = {Xue, Peng and Gao, Qian and Fan, Jun},
  doi          = {10.1007/s11227-025-07143-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Social recommendation based on contrastive learning of hypergraph convolution},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSI-MFS: Lightweight multi-objective feature selection for enhanced multi-label classification. <em>SUPERC</em>, <em>81</em>(6), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07163-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of multi-label (ML) data has witnessed a significant increase in numerous fields as big data technology continues to expand. However, these datasets often contain a high degree of redundancy and irrelevant attributes, which can negatively impact the efficiency and predictive performance of machine learning models. To address these challenges, this paper introduces PSI-MFS, a novel lightweight multi-objective feature selection (MLFS) approach that efficiently optimizes feature selection criteria while maintaining computational efficiency. Despite the availability of several MLFS approaches, many existing methods struggle to achieve optimal balance between computational efficiency and selection quality. PSI-MFS overcomes this by simultaneously optimizing three conflicting feature selection (FS) objectives: minimizing feature–feature redundancy ( $$\downarrow $$ ), maximizing feature–label relevancy ( $$\uparrow $$ ), and maximizing feature–label interaction ( $$\uparrow $$ ), using a preference selection index (PSI)-based optimization strategy. PSI-MFS provides a trade-off between feature correlation and classification performance while significantly reducing memory consumption and execution time. The time complexity of PSI-MFS is low, and experimental assessments on ten benchmark datasets demonstrate its superior or competitive performance compared to 11 state-of-the-art (SOTA) FS methods. The effectiveness of PSI-MFS is further validated through statistical analysis using Friedman’s test, which confirms its significant performance improvements. Notably, PSI-MFS achieves faster execution times and outperforms existing methods in 80% of cases, making it a robust and scalable solution for ML feature selection.},
  archive      = {J_SUPERC},
  author       = {Verma, Gurudatta and Sahu, Tirath Prasad},
  doi          = {10.1007/s11227-025-07163-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {PSI-MFS: Lightweight multi-objective feature selection for enhanced multi-label classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDPA: A part-of-speech-driven prompt and attention method for aspect sentiment triplet extraction. <em>SUPERC</em>, <em>81</em>(6), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07188-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triplet Extraction (ASTE) is pivotal for nuanced sentiment analysis, demanding precise identification of aspect terms, opinion terms, and their associated sentiment polarities. Existing methods often rely on additional networks, such as graph neural networks, to exploit semantic and syntactic knowledge from reviews. However, these approaches tend to increase model complexity while neglecting the intrinsic relationship between target terms and their part-of-speech attributes. To address these limitations, we propose a novel Part-of-speech-Driven Prompt and Attention (PDPA) framework for ASTE. Our approach integrates part-of-speech information into both a lightweight soft prompt mechanism and an attention network, significantly enhancing model efficiency and performance. Specifically, the soft prompt embedding, initialized with rich term features, guides a pre-trained language model to generate task-specific knowledge from a part-of-speech perspective, effectively bridging the gap between task requirements and feature representations. Furthermore, the attention network strengthens term representations and their interactions within a 2D table by incorporating part-of-speech information during the update process. Additionally, we introduce a boundary tag mapping strategy for triplet decoding, which transforms asymmetric regions into symmetric regions based on diagonals, thereby fully leveraging bidirectional interactions between entities that are often overlooked by conventional region-based detection methods. Extensive experiments on public benchmark datasets demonstrate that our PDPA framework achieves state-of-the-art performance, showcasing its effectiveness and efficiency in ASTE tasks.},
  archive      = {J_SUPERC},
  author       = {Wang, Guangchao and Li, Zhaojun and Liu, Cong and Wang, Rongyan and Guo, Changyou},
  doi          = {10.1007/s11227-025-07188-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {PDPA: A part-of-speech-driven prompt and attention method for aspect sentiment triplet extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel metaheuristic algorithm using structured population and virtual particles. <em>SUPERC</em>, <em>81</em>(6), 1--90. (<a href='https://doi.org/10.1007/s11227-025-07194-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional metaheuristic algorithms frequently rely on unstructured and fixed populations, neglecting the solution memory and treating candidate solutions in their traditional form. These limitations can result in inefficiencies in the search process, such as revisiting low-quality regions and reducing the exploration flexibility. This paper introduces the Structured population algorithm (SPA) as a novel metaheuristic algorithm that addresses these challenges by integrating a structured population, a solution list, and virtual particles to enhance the search process. SPA commences by initializing a set of virtual particles that represent positions in the search space but do not directly correspond to solutions. Each virtual particle generates a subset of solutions within a defined neighborhood and these solutions are grouped according to their originating particles. The algorithm operates iteratively by selecting the top three solutions from each group to form a local triangle and calculating the pivot points as the centroids of these triangles. Subsequently, the top three pivot points of all local triangles were identified to construct a global triangle. Using this information, a global centroid is derived to guide the movement of virtual particles, with the worst-performing particle moving in the opposite direction to enhance exploration. Updated particles generate new solutions in their neighborhoods, iteratively refining the population until convergence. The performance of the algorithm was validated using shifted test functions designed to assess center-biased tendencies, demonstrating competitive results with superior solution quality, faster convergence, and effective handling of the center-biased limitations.},
  archive      = {J_SUPERC},
  author       = {Cuevas, Erik and González-Sánchez, Oscar A. and Delgado-Castañeda, Noé and Zaldívar, Daniel and Rodríguez-Vazquez, Alma},
  doi          = {10.1007/s11227-025-07194-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--90},
  shortjournal = {J. Supercomput.},
  title        = {A novel metaheuristic algorithm using structured population and virtual particles},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RBC-MSS: Asynchronous broadcasting protocol based on multi-secret sharing. <em>SUPERC</em>, <em>81</em>(6), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07211-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Byzantine fault-tolerant (BFT) protocols enable ordered transactions among untrusted participants. Asynchronous BFT protocols are the most robust BFT protocols, but their high latency limits practical application. This latency is primarily due to the communication overhead of the reliable broadcast (RBC) protocol. To solve the high latency problem of asynchronous broadcast protocols, we first propose a novel multi-secret sharing scheme that enhances the efficiency of ciphertext segmentation and reconstruction. Besides, our core part, using our proposed multi-secret sharing scheme as a basis, constructs a new broadcast protocol, RBC-MSS, which reduces the message complexity generated by the RBC protocol to $$O(N^2)$$ . Subsequent experiments show that the latency of this algorithm is reduced by 57.41% compared to the RBC protocol and 46.31% compared to the provable broadcast (PB) protocol. When integrated with the consensus process, the throughput of the algorithm is improved by 20.11% and 12.97% compared to the Dumbo and sDumbo protocols, respectively. Furthermore, it also provides greater resistance to data leakage attacks. The protocol offers both lower communication latency and stronger security.},
  archive      = {J_SUPERC},
  author       = {Bai, Fenhua and Xu, Hongye and Shen, Tao and Zeng, Kai and Zhang, Xiaohui and Zhang, Chi},
  doi          = {10.1007/s11227-025-07211-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {RBC-MSS: Asynchronous broadcasting protocol based on multi-secret sharing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning- and deep learning-based anomaly detection in firewalls: A survey. <em>SUPERC</em>, <em>81</em>(6), 1--60. (<a href='https://doi.org/10.1007/s11227-025-07212-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of data mining has brought increasing attention to firewall anomaly detection. Firewalls serve as a frontline defense by monitoring and controlling network traffic based on predefined rules. However, managing these rules can be complex and prone to errors, leading to vulnerabilities and security risks. To address this challenge, advanced anomaly detection techniques leveraging both Machine Learning (ML) and Deep Learning (DL) have been developed specifically for firewalls. In this study, we investigate innovative ML and DL-based approaches to enhance firewall anomaly detection. We present various methodologies, analyze their effectiveness, and provide a comparative evaluation of their performance. Our findings demonstrate the strong potential of ML and DL-based models in strengthening firewall defenses. Notably, a hybrid log-based model incorporating K-means, Gaussian Mixture Model (GMM), and Bayesian GMM (BGMM) exhibited significant improvements in recall and accuracy. Furthermore, the use of GMM for positive log pruning highlights the effectiveness of unsupervised learning in refining anomaly detection within firewall log data. Our study identifies key challenges and proposes advanced AI techniques to enhance firewall anomaly detection, emphasizing the need for ongoing research and collaboration.},
  archive      = {J_SUPERC},
  author       = {Dhrir, Hanen and Charfeddine, Maha and Tarhouni, Nesrine and Kammoun, Habib M.},
  doi          = {10.1007/s11227-025-07212-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--60},
  shortjournal = {J. Supercomput.},
  title        = {Machine learning- and deep learning-based anomaly detection in firewalls: A survey},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified temporal link prediction framework based on nonnegative matrix factorization and graph regularization. <em>SUPERC</em>, <em>81</em>(6), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07217-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex real-world systems, evolving over time, can be modeled as dynamic networks. Numerous studies have focused on utilizing information about the entities and relationships within networks. Temporal link prediction, a challenging yet critical task for dynamic networks, aims to forecast the appearance and disappearance of links in future snapshots based on the network structure observed in previous snapshots. However, existing works have not fully utilized information from historical networks, such as evolving structures and community data. Additionally, nonnegative matrix factorization (NMF) techniques are unable to automatically extract nonlinear spatial and temporal features from dynamic networks. In this paper, we introduce a unified temporal link prediction framework, EDeepEye, which leverages NMF and graph regularization to predict temporal links. Based on this framework, we propose three novel methods: SDeepEye, GDeepEye, and QDeepEye, which incorporate prior information, weighted matrices, and modularity matrices, respectively. Additionally, we provide effective multiplicative updating rules for the factors of the methods, which learn latent features from the temporal topological structure. Three evaluation metrics, i.e., area under the receiver operator characteristic curve, Precision and root mean squared error, are applied to verify the superiority of the proposed methods. The results of empirical study show that our proposed methods outperform the baseline methods on eight real-world networks and 16 synthetic networks.},
  archive      = {J_SUPERC},
  author       = {Li, Min and Zhou, Shuming and Wang, Dajin and Chen, Gaolin},
  doi          = {10.1007/s11227-025-07217-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {A unified temporal link prediction framework based on nonnegative matrix factorization and graph regularization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-feature fusion supervoxel clustering segmentation method based on energy function. <em>SUPERC</em>, <em>81</em>(6), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07220-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervoxels serve as a more natural and compact representation of 3D point clouds, allowing segmentation operations to be performed on regions rather than scattered points. Most current supervoxel segmentation methods rely on random sampling of representative seed points to generate supervoxels with fixed resolution. However, when seed points fall on the object boundary, erroneous growth of supervoxels may occur, leading to over-segmentation or under-segmentation issues. Additionally, the fixed resolution cannot adapt to different scenes. To address the issues in the concave-convex segmentation algorithm for supervoxels, this paper proposes a multi-feature fusion segmentation method based on an energy function. First, ideal seed points are selected based on the mean curvature of the local neighborhood. Then, an energy function incorporating normal and color information is employed to generate supervoxels and exchange boundary points. Finally, an entropy function based on the dimensional feature information of the local neighborhood is constructed to assist in computing the normal vectors of the supervoxels. The experimental results show that the generated supervoxels align more closely with object boundaries and exhibit high robustness across different scenes. Among the three test datasets, the segmentation method proposed in this paper outperforms other region-growing methods in terms of precision, recall, and mean intersection over union.},
  archive      = {J_SUPERC},
  author       = {Meng, Chao and Du, Yuhong and Yang, Leicheng and Dong, Guangyu},
  doi          = {10.1007/s11227-025-07220-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A multi-feature fusion supervoxel clustering segmentation method based on energy function},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal multiobjective optimization algorithm with fine-grained special crowding distance and dual-space selection mechanism. <em>SUPERC</em>, <em>81</em>(6), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07221-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many multimodal multiobjective optimization algorithms strive to solve multimodal multiobjective optimization problems (MMOPs), which have multiple equivalent Pareto optimal solution sets (PSs) in the decision space, and these PSs correspond to the same Pareto front in the objective space. Although these algorithms have the advantage of enhanced search capabilities, there are still various challenges in addressing MMOPs, such as incomplete Pareto optimal sets and unevenly distributed Pareto optimal sets. To address these problems, this paper presents a multimodal multiobjective optimization algorithm with a fine-grained special crowding distance and a dual-space selection mechanism. In the proposed algorithm, a fine-grained special crowding distance (FSCD) is used to measure the comprehensive crowding distances of individuals in the decision and objective spaces. Next, an FSCD-based reproduction strategy is employed to select an exemplar and generate high-quality offspring. Finally, environmental selection based on dual spaces is proposed to improve the convergence of the population without decreasing its diversity. To verify the effectiveness of the proposed algorithm, a series of experiments are carried out on CEC2019 benchmark problems and a path planning optimization problem. The experimental results indicate that the proposed algorithm outperforms its peer competitors.},
  archive      = {J_SUPERC},
  author       = {Li, Wei and Ping, Zeming and Wang, Lei},
  doi          = {10.1007/s11227-025-07221-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {Multimodal multiobjective optimization algorithm with fine-grained special crowding distance and dual-space selection mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to balance the verification burden: A multi-hierarchical aggregate signature for drone swarms. <em>SUPERC</em>, <em>81</em>(6), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07222-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drone and drone swarm have come to the fore in recent regional conflicts, also bringing their associated security concerns, including authentication, into sharp focus. The aggregate signature offers a solution to authenticate the entire drone swarm. However, the verification process for each signature in the aggregation algorithm places a heavy burden on the master drone, and the aggregation time is even hundreds of times longer than the signing time. This accelerates battery depletion and reduces the flight endurance of the entire drone swarm due to the bucket effect. To balance the verification burden between the master drone and the other drones in the swarm, in this paper, we propose a multi-hierarchical aggregate signature scheme for drone swarms, utilizing a complete tree structure. Each node in the tree represents a drone, and each drone at a non-leaf node is responsible for verifying and aggregating the signatures from its child nodes, continuing this process up to the root node (the master drone). Therefore, it can further balance the verification workload and reduce aggregation time through parallel processing. Additionally, we introduce a tracing algorithm to identify invalid or malicious drones when verification fails. Our security proof shows unforgeability and traceability, while performance simulations reveal that aggregation time is now only dozens of times the signing time, and the aggregator’s communication cost has decreased from approximately 50 times that of the signer to about 4 times, albeit with the trade-off of increased communication frequencies.},
  archive      = {J_SUPERC},
  author       = {Meng, Lei and Xu, Yueqiang and Gao, Feiran and Lin, Fuhong},
  doi          = {10.1007/s11227-025-07222-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {How to balance the verification burden: A multi-hierarchical aggregate signature for drone swarms},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the transferability of adversarial examples via the high-level interpretable features for object detection. <em>SUPERC</em>, <em>81</em>(6), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07225-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress in deep learning technology has positioned object detection models as crucial tools for solving complex computer vision problems, particularly in fields such as autonomous driving, intelligent surveillance, and medical diagnosis. However, the vulnerability of these models to adversarial attacks presents significant risks to their safety in application. In particular, during real-world deployment, models often function as black boxes, and transferable adversarial attacks have drawn increasing attention due to their tangible threats to practical applications. Among these, feature-level adversarial attacks have emerged as a new branch in this field, enhancing the transferability of adversarial examples by interfering with the model's intermediate features. To address the issue of gradient saturation during backpropagation in existing methods, this study proposes a High-level Interpretable Features Attack method. This method, through Diversity-Enhanced Integrated Gradients, assesses the key features that different models rely on in common, providing more reliable guidance for generating adversarial examples. Additionally, we introduce random transformations such as motion blur and salt-and-pepper noise, which not only enrich the diversity of input samples but also strengthen integral gradient features that are generally effective across different models, thereby reducing the dependency of adversarial examples on specific model architectures. Through a series of extensive experiments, we demonstrate that the proposed method can effectively attack various object detection models, including Faster R-CNN, SSD, RetinaNet, YOLOv5, and YOLOv8, significantly enhancing the cross-model transferability of adversarial examples. Our method achieves an attack success rate of up to 90% on the YOLOv8 model. These results not only underscore the effectiveness of the attack strategy but also highlight its universality and practicality in real-world applications.},
  archive      = {J_SUPERC},
  author       = {Ding, Zhiyi and Sun, Lei and Mao, Xiuqing and Dai, Leyu and Ding, Ruiyang},
  doi          = {10.1007/s11227-025-07225-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Improving the transferability of adversarial examples via the high-level interpretable features for object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research and application of smart insole assisted gait recognition technology. <em>SUPERC</em>, <em>81</em>(6), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07226-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a nascent biometric technology, gait recognition has demonstrated considerable potential for application across various fields, including security monitoring, medical diagnosis, and human–computer interaction. Wearable devices offer significant advantages in gait recognition, including real-time tracking, high portability, and independence from specific environments. They can continuously collect gait data in various settings, including daily life and complex scenes. Although existing studies have made some progress in gait recognition, there are still challenges regarding the generalization ability of the models and the lack of recognition accuracy. In this study, a lightweight and wireless smart insole based on flexible materials and integrated with pressure and inertial sensors is developed. The monitoring system is constructed using a combination of ensemble empirical mode decomposition (EEMD), convolutional neural network (CNN), and long short-term memory network (LSTM). The initial stage of the process involved data preprocessing, which included data cleaning, the exclusion of nonspecific actions, feature extraction, and the organization of the data. Secondly, EEMD extracted the crucial intrinsic mode functions (IMFs) encompassing essential gait characteristics. The principal IMF was then extracted from the power spectrogram to train the CNN-LSTM model. To address the overfitting issue in the classification model, the max-pooling and dropout techniques are adopted. Subsequently, the model was trained and evaluated to construct a multidimensional evaluation system. This study included twenty healthy subjects. Their gait data were collected in six real-life scenarios while wearing insoles, and the performance of CNN, CNN-LSTM, and K-nearest neighbor (KNN) models was compared using leave-one-subject-out cross-validation. The results show that the proposed CNN-LSTM model exceeds a high level of 96% for a variety of evaluation metrics for the recognition of gait patterns and phases, with a Matthews correlation coefficient of 0.96 and root-mean-square errors of 0.15 and 0.17, which show significant superiority compared to other methods.},
  archive      = {J_SUPERC},
  author       = {Yuan, Yan and Xu, Jinwei and Wei, Fansen and Mu, Jingsong and Chen, Pin and Wang, Yong},
  doi          = {10.1007/s11227-025-07226-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Research and application of smart insole assisted gait recognition technology},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-based edge service offloading in cloud–edge–terminal environment. <em>SUPERC</em>, <em>81</em>(6), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07228-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of mobile edge computing enables edge devices to efficiently utilize resources through optimized scheduling, providing robust computational support for diverse service requests. However, mobile intelligent terminals have limited computational resources and often rely on edge servers for task processing. Each edge server, in turn, has finite resources, necessitating task offloading to other servers when resource demand exceeds availability. This process aims to improve the efficiency of the response of the service. However, edge devices tend to prioritize their own performance, often neglecting load balancing across servers. To address this issue, this paper proposes a deep reinforcement learning-based method for offloading edge services in mobile edge environments. The method considers both the offloading demands of mobile terminals and the service reception capacities of edge servers to achieve efficient offloading, load balancing, and reduced communication delay. Initially, offloading demands and the reception capabilities of idle edge servers are mathematically modeled. The offloading scenario is then framed as an optimization problem involving multiple objectives and subject to various constraints. Finally, deep reinforcement learning is applied to construct a Markov decision process for iterative optimization, resulting in low-delay and balanced offloading solutions. The experimental results show that, compared with the baseline methods such as Random, Top-K, K-means, PSO, and Q-learning, the method proposed in this paper has achieved improvements of 30.85%, 17.42%, 12.69%, 22.32%, and 11.64% respectively in terms of the load standard deviation. This successfully verifies the effectiveness of the method proposed in this paper.},
  archive      = {J_SUPERC},
  author       = {Cao, Buqing and Yi, Yating and Zeng, Zilong and Ye, Hongfan and Tang, Bing},
  doi          = {10.1007/s11227-025-07228-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A deep Q-network-based edge service offloading in cloud–edge–terminal environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDPNet: Deep forgery detection by leveraging multi-scale self-forgery images generating. <em>SUPERC</em>, <em>81</em>(6), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07229-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of deep learning-based generation models, the problem of facial forgery has become increasingly prevalent. Therefore, deep forgery detection has become a major research focus, attracting widespread attention from scholars. However, the complex and diverse technologies employed in facial forgery and generation bring tremendous challenges for the generalization of detection models. For this, we propose a new forgery feature extraction network, FDPNet, with the goal of training a model that can effectively extract forgery traces from various media types and accurately predict the forgery regions to distinguish between genuine and fake content. To improve the model’s accuracy, this work also proposes an adversarial data augmentation technique, AMSM. This method aims to improve the detection model’s generalization ability by diversifying the types of forgery and strengthening self-supervised tasks that are sensitive to specific forgery configurations. Experimental results show that our model’s performance on the dataset was improved by 0.09%. The model’s generalization ability was significantly enhanced in cross-dataset testing, with improvements of 0.66%, 0.43%, and 1.15%. These innovations significantly enhance the accuracy and generalization of forgery detection.},
  archive      = {J_SUPERC},
  author       = {Li, Boyang and Zhao, Huihuang and Li, Leyi},
  doi          = {10.1007/s11227-025-07229-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {FDPNet: Deep forgery detection by leveraging multi-scale self-forgery images generating},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scientometric analysis of reviews on the internet of things. <em>SUPERC</em>, <em>81</em>(6), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07230-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm is redefining our lives, allowing us to make “smart” decisions. This boom has also gained popularity in academic research, one of the core goals being to make IoT research more accessible to students and early researchers, while making sure that experienced researchers keep up with the changes happening in the research area. A large number of review papers are available covering surveys related to IoT vision enabling technologies, applications, key features, and future directions. Nevertheless, there is a lack of analysis of these reviews. This study provides a scientometric analysis of already available reviews in the field of IoT to identify upcoming research needs and bring simplicity to literature research. In total, 964 review articles in the field of IoT written in English and published in peer-reviewed journals and conferences from 2010 to April 2023 have been finalized from the Google Scholar database. Three broad categories of analysis have been performed on the 964 relevant collected literature, namely (a) statistical; (b) machine learning-based; and (c) evaluative analysis. An important differentiating feature of the current study is the use of machine learning for data exploration, thereby providing better interpretation. We find that the trend to review the field of IoT has increased in the last five years with only one article in 2010. This article identifies and quantifies the knowledge gaps to inform the community, industry, and government authorities about research directions for IoT. Furthermore, this scientometric analysis serves as a foundational resource for IoT researchers in identifying relevant and important survey papers that target their research fields in IoT.},
  archive      = {J_SUPERC},
  author       = {Jain, Sarika and Sukul, Priyanka and Groppe, Jinghua and Warnke, Benjamin and Harde, Pooja and Jangid, Ritik and Rehan, Waqas and Cotrado, Yuri and Fischer, Stefan and Groppe, Sven},
  doi          = {10.1007/s11227-025-07230-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A scientometric analysis of reviews on the internet of things},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mayfly algorithm with elementary functions and mathematical spirals for task scheduling in cloud computing system. <em>SUPERC</em>, <em>81</em>(6), 1--46. (<a href='https://doi.org/10.1007/s11227-025-07231-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an Internet-based computing model, cloud computing realizes the elastic scaling and efficient utilization of resources by centralizing computing resources (such as servers, storage and networks) to form resource pools and provide services to users on-demand. Task scheduling directly affects the operational efficiency, load balancing and energy consumption of the entire system. In order to improve the execution efficiency of task scheduling in cloud computing system, a Cycloid spiral X mayfly algorithm (CXMA) based on improved dance damping ratio and dance mode was proposed. Firstly, the elementary function is used to improve the dance damping ratio, which effectively improves the convergence stability of the algorithm and better balances the ability of global exploration and local development, so that the algorithm can locate the optimal solution more accurately while maintaining high search diversity. On the basis of improving the dance damping ratio, the basic mathematical function is used to improve the dance mode of the mayfly, and the search efficiency and solution accuracy of MA are significantly improved by optimizing the search behavior of the individual mayfly so as to improve the robustness and adaptability of MA. Through simulation experiments, the total cost, time cost, load cost and price cost of the system under large-scale and small-scale tasks are tested. Comparing the proposed CXMA with other swarm intelligence optimization algorithms, the experimental results show that the proposed CXMA has significant advantages in searching for the optimal task scheduling strategy. In terms of total cost, CXMA is 6.7% lower than ACO, 0.7% lower than CDO, 3.7% lower than WOA, 4.0% lower than BOA, 2.6% lower than AOA, 1.6% lower than SOA and 3.0% lower than RSO.},
  archive      = {J_SUPERC},
  author       = {Sui, Xiao-Fei and Zhang, Si-Wen and Wang, Jie-Sheng and Zhang, Shi-Hui and Zhang, Yun-Hao and Bai, Xue-Lian},
  doi          = {10.1007/s11227-025-07231-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--46},
  shortjournal = {J. Supercomput.},
  title        = {Mayfly algorithm with elementary functions and mathematical spirals for task scheduling in cloud computing system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2multisense: A novel approach to fuzzy fusion in multisensor data to improve saving energy in WBSN. <em>SUPERC</em>, <em>81</em>(6), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07233-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body sensor networks (WBSNs) are vital for healthcare applications but face challenges due to limited energy resources and continuous data transmission. This study proposes F $$^2$$ multisense, a novel fuzzy data fusion method to optimize energy consumption at two levels: adaptive emergency detection at the node level and dynamic sampling rate adjustment at the coordinator level. At the first level, data transmission is optimized using adaptive local emergency detection and the NEWS system. At the second level, coordinator level, optimization is achieved through a fuzzy system that adaptively determines the sampling rate. Furthermore, the number of sensors aligns with the number of vital signs in the NEWS system, and the samples examined are numerous, demonstrating the completeness of the method. In addition, the dual-layer design of the system supports real-time adaptation and scalability, ensuring robust performance in dynamically changing environments and large-scale deployments. This approach integrates fuzzy logic with the NEWS system, ensuring reliable health assessments without compromising timeliness or accuracy. To evaluate the method, simulations were performed based on real sensor data from the MIMIC-II database. The results demonstrate a 40% reduction in data transmission and a 64% decrease in energy consumption compared to state-of-the-art methods, allowing efficient and precise patient monitoring.},
  archive      = {J_SUPERC},
  author       = {Shankani, Rana and Khalifavi, Maedeh and Shirmohammadi, Zahra and Nikoofard, Amirhossein},
  doi          = {10.1007/s11227-025-07233-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {F2multisense: A novel approach to fuzzy fusion in multisensor data to improve saving energy in WBSN},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved discrete harris hawks optimization algorithm for the no-wait job shop problem to minimize total weighted tardiness. <em>SUPERC</em>, <em>81</em>(6), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07234-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of the well-known job shop problem through introducing no-wait constraints, the no-wait job shop problem (NWJSP) is one of the most difficult combinatorial problems. In this study, we consider the NWJSP with the objective of minimizing total weighted tardiness and develop a mixed integer linear programming model (MILP) to formulate the problem. Furthermore, we propose an improved discrete Harris Hawks optimization (IDHHO) algorithm to efficiently explore the solution space. Firstly, to enhance solution quality during the initialization phase, we develop an improved apparent tardiness cost (IATC) rule and integrate it with the Nawaz–Enscore–Ham (NEH) heuristic, thereby constructing a new heuristic called IATC_PNEH. Secondly, six discrete operators are used to update the population during the iterative search phase. Finally, an insertion-based perturbation strategy is introduced to prevent falling into local optima. The computational results and statistical analyses based on benchmark sets show that the IATC_PNEH heuristic outperforms some other heuristics in most cases, and the proposed IDHHO algorithm is competitive to several other high-performing algorithms. Besides, optimal solutions for all small-size instances are obtained by implementing the Cplex solver on the MILP model.},
  archive      = {J_SUPERC},
  author       = {Yin, Jie and Zhang, Shuning and Liu, Li and Deng, Guanlong},
  doi          = {10.1007/s11227-025-07234-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {An improved discrete harris hawks optimization algorithm for the no-wait job shop problem to minimize total weighted tardiness},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application I/O behavior analysis on leadership cluster system. <em>SUPERC</em>, <em>81</em>(6), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07235-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A parallel file system is essential for executing large workloads via large-scale computing resources such as national leadership computers; however, a primary cause of performance degradation arises from I/O operation. In the scientific workloads, there is often a significant variance in I/O performance, and the information needed to determine the characteristics of the tasks is limited at the time of job submission. These characteristics make it very difficult to analyze and predict I/O performance. Nevertheless, accurate analysis of the I/O behavior of applications based on multidimensional logs greatly aids in overcoming these challenges. In this paper, we examine in detail the relationship between applications and I/O behavior on the basis of multiple logs from jobs executed on the national leadership computer Nurion, which is operated by the Korea Institute of Science and Technology Information (KISTI). Moreover, we analyze which key features best reflect the characteristics of the applications and propose methods to identify applications on the basis of this analysis. In practice, the proposed classification method can eliminate the tedious tasks of users having to manually input the types of applications. In addition, it is useful for administrators to restrict the types and number of concurrently running applications for various reasons. To verify this potential, our experimental results include the accuracy of applying four algorithms widely used in multiclass classification on the basis of key features detected through feature analysis, along with a confusion matrix.},
  archive      = {J_SUPERC},
  author       = {Park, Ju-Won and Hong, Taeyoung},
  doi          = {10.1007/s11227-025-07235-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Application I/O behavior analysis on leadership cluster system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating ChatGPT’s strengths and limitations for data race detection in parallel programming via prompt engineering. <em>SUPERC</em>, <em>81</em>(6), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07237-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models have significantly advanced software engineering, enabling tasks like code comprehension and fault detection. However, their ability to detect complex bugs, such as data races in parallel programming, remains uncertain. Fault detection in parallel programming (Pthreads) requires a deep understanding of thread-based logic, as data races occur when threads access shared data concurrently without proper synchronization. This paper explores ChatGPT’s potential in Pthreads fault detection by addressing three questions: (1) Can ChatGPT effectively debug parallel programming threads? (2) How can dialogue assist with the detection of faults? (3) How can prompt engineering help to improve ChatGPT’s fault detection performance?. We examine advanced prompt engineering techniques, such as Zero-Shot, Few-Shot, Chain-of-Thought, and Retrieval-Augmented Generation prompts. Additionally, we introduce three hybrid prompting techniques to enhance performance, including Chain-of-Thought with Few-Shot Prompting, Retrieval-Augmented Generation with Few-Shot Prompting, and Prompt Chaining with Few-Shot Prompting, while evaluating ChatGPT’s strengths and limitations for data race detection.},
  archive      = {J_SUPERC},
  author       = {Alsofyani, May and Wang, Liqiang},
  doi          = {10.1007/s11227-025-07237-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Evaluating ChatGPT’s strengths and limitations for data race detection in parallel programming via prompt engineering},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-point and length-representation-based model for nested named entity recognition. <em>SUPERC</em>, <em>81</em>(6), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07240-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is one of the core tasks in natural language processing (NLP), yet accurately extracting nested entities remains a formidable challenge. This study proposes a novel span-based method for nested entity recognition, termed SPLR, which incorporates two knowledge embedding strategies—Prior Knowledge Function (PKF) and Token Length Lexical Corpus (TLLC)—to accurately locate entities of varying lengths. Experimental results show that SPLR-PKF achieves F1 scores of 84.2, 86.5, and 79.6 on ACE2004, ACE2005, and GENIA, with nested levels 1–2 scoring 83.2 and 82.0, respectively. In contrast, SPLR-TLLC attains F1 scores of 84.1, 87.5, and 88.4 on the same datasets and 88.9, 87.5, and 70.6 for nested levels 1–3. Moreover, in NST (i.e., for entities with nested relationships of the same category) NER tasks, the SPLR-TLLC model improves performance by 39.5% compared to previous models.},
  archive      = {J_SUPERC},
  author       = {Lu, Hangqing and Yan, Quan and Wang, Li},
  doi          = {10.1007/s11227-025-07240-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {A single-point and length-representation-based model for nested named entity recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The ensemble of self-information-based feature selection for heterogeneous data via k-nearest neighborhood rough set model. <em>SUPERC</em>, <em>81</em>(6), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07244-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kernel step of feature selection using rough set theory is to establish feature evaluation function to assess the classification ability of feature subset. Dependency in rough set theory is a feature evaluation function. However, this function considers only the classification information contained in the lower approximation of the decision while ignoring the upper approximation.k-nearest-neighbor rule (KNN-rule) is an important classification technique. By combining neighborhood rough set model with KNN-rule, KNN-neighborhood rough set model can be obtained. This model has a strong ability to approximate decision. This paper studies feature selection for heterogeneous data based on the ensemble of self-information and KNN-neighborhood rough set model. First, KNN-neighborhood rough set model for heterogeneous data is established. Using this model, decision self-information for four types of heterogeneous data is constructed. By applying linear fusion approach, the ensemble operator of self-information is derived, which can be used as feature evaluation function. This ensemble operator integrates multiple self-information measures, comprehensively considering both the upper and lower approximations of the decision boundary. Moreover, this ensemble operator balances the contributions of different self-information measures in evaluating feature subsets, accurately determines feature importance, effectively avoids feature redundancy, and significantly enhances classification accuracy and efficiency. It provides a novel pathway for the efficient processing and precise analysis of heterogeneous data. Next, a feature selection algorithm for heterogeneous data is designed based on this ensemble operator. Finally, a series of numerical experiments conducted on real-world datasets is used to evaluate the designed algorithm. The experimental results demonstrated that this algorithm offers statistically significant advantages over six other feature selection algorithms. Statistical analysis shows that SI-FFS achieves superior performance across four classifiers compared to the other six algorithms, with an average improvement of 15.95% in F1 score.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yong Cai and Lin, Yonghua and Rizon, Mohamed and Chiong, Meng Choung and Chu, Yih Bing},
  doi          = {10.1007/s11227-025-07244-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {The ensemble of self-information-based feature selection for heterogeneous data via k-nearest neighborhood rough set model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective federated XGBoost learning for multi-class classification in non-IID environments. <em>SUPERC</em>, <em>81</em>(6), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07245-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a decentralized approach that enables machine learning models to be trained on local data across distributed clients, offering an alternative to centralized learning by protecting data privacy. Tree-based ensemble methods, such as Random Forest and XGBoost, have demonstrated high performance in various tasks, but their application in federated learning environments especially with Non-IID (Non-Independent and Identically Distributed) data presents challenges in model accuracy and complexity. This paper proposes a federated learning method based on vector-valued XGBoost, specifically designed to address multi-class classification problems in Non-IID data environments. Our method divides the tree-building process into two phases: tree growth and global weight adjustment. These phases are combined to form four types of federated XGBoost models, allowing flexible adjustments in performance and model complexity. Through experiments conducted in federated learning environments, we demonstrate that our proposed method achieves high accuracy while reducing model complexity in Non-IID data settings.},
  archive      = {J_SUPERC},
  author       = {Kang, Sung Won and Park, Cheong Hee},
  doi          = {10.1007/s11227-025-07245-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Effective federated XGBoost learning for multi-class classification in non-IID environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing cost and resource variability for big data task scheduling in heterogeneous cloud environments. <em>SUPERC</em>, <em>81</em>(6), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07248-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data consists of large and complex datasets that exist on a very large scale and complexity which challenge methods of data management, processing, and analysis. Given the ever-increasing demands from users and companies, and considering the massive nature of big data, there is a critical need for powerful scheduling algorithms. Previous studies typically treat tasks and cloud components equivalently without taking costs into account. In contrast, the current paper formulates the scheduling issue as an integer linear programming challenge for scheduling big data tasks in heterogeneous cloud environments, optimizing costs and resource use via server diversity, dynamic pricing, and a novel scheme change rescheduling mechanism. This method makes the created model more relevant to real-life situations, and linear models like simplex and searching state-space trees are used to find a solution. The evaluation findings, when comparing the suggested method to earlier approaches, demonstrate a decrease in costs and an improvement in the uptake of the proposed methodology.},
  archive      = {J_SUPERC},
  author       = {Ayyadi, Armin and Jahani, Arezoo},
  doi          = {10.1007/s11227-025-07248-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Addressing cost and resource variability for big data task scheduling in heterogeneous cloud environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban city data delivery optimization in VNDN using a route-based caching approach with content-type awareness in intelligent transportation system. <em>SUPERC</em>, <em>81</em>(6), 1--38. (<a href='https://doi.org/10.1007/s11227-025-07250-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to enhance the performance of vehicular named data networking (VNDN) in dynamic environments by improving cache hit efficiency and minimizing network response delays. The study proposes a content type-aware routing strategy and an integrated content pre-caching strategy based on content popularity prediction to address the challenges of redundant caching and inefficient content delivery in VNDN. A twofold approach is adopted. First, a content type-aware routing strategy is developed to select optimal forwarding paths based on message attributes and destination node information. Second, the unsupervised learning model Latent Dirichlet Allocation is utilized to predict automotive users’ content request preferences dynamically. The topological relationships among devices in the Internet of Vehicles and the predicted user preferences are integrated to estimate content popularity accurately. This information is used to implement a pre-caching strategy (R-pre-cache) that reduces redundant caching and optimizes cache utilization. Simulation experiments demonstrate that the proposed R-pre-cache strategy significantly outperforms existing caching strategies. Key performance improvements include a higher content delivery ratio, reduced latency, minimized retrieval time, and enhanced cache hit ratios. Additionally, the strategy exhibits excellent scalability and durability, making it suitable for dynamic vehicular environments. The proposed content type-aware routing and pre-caching strategies offer a robust solution for improving VNDN performance in dynamic and unpredictable environments. By leveraging content popularity prediction and efficient caching mechanisms, the study provides a scalable and durable framework for enhancing vehicular network communication, making it a viable architecture for diverse content applications in the Internet of Vehicles.},
  archive      = {J_SUPERC},
  author       = {Javeed, Muhammad Awais and Li, Dawei and Ashraf, Muhammad Awais},
  doi          = {10.1007/s11227-025-07250-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Urban city data delivery optimization in VNDN using a route-based caching approach with content-type awareness in intelligent transportation system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale detection of underwater objects using attention mechanisms and normalized wasserstein distance loss. <em>SUPERC</em>, <em>81</em>(6), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07251-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater imaging faces challenges such as light attenuation, scattering, and water turbidity, which degrade image quality and hinder accurate organism recognition. The detecting underwater objects dataset, with resolutions from 586 × 482 to 3840 × 2160 pixels, highlights significant object scale variation, including a high proportion of small objects (27.38%). This study introduces the underwater attention-parallel residual bi-fusion feature pyramid network model, which improves detection accuracy for small- and medium-sized objects in complex underwater environments. The proposed model incorporates a spatial pyramid pooling module with attention mechanisms to enhance multi-scale feature representation and integrates the normalized Wasserstein distance into the loss function for better detection flexibility. Experimental results demonstrate that the model outperforms state-of-the-art methods, achieving a mean average precision at intersection over union threshold of 0.5 of 88.8% and a mean average precision at intersection over union threshold range of 0.5–0.95 of 68.3%, representing a 2.5–9% improvement over baseline models. Furthermore, the model achieved a precision of 85.5%, recall of 82.9%, and an F1-score of 0.8417. These results highlight the model’s robustness and effectiveness, offering significant contributions to underwater biodiversity studies, environmental assessments, and marine ecosystem management. By addressing scale variability and achieving high accuracy even for rare species such as scallops, the proposed model supports practical applications in underwater monitoring and conservation.},
  archive      = {J_SUPERC},
  author       = {Tsai, Yu-Shiuan and Tsai, Chia-Tung and Huang, Jian-Hong},
  doi          = {10.1007/s11227-025-07251-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Multi-scale detection of underwater objects using attention mechanisms and normalized wasserstein distance loss},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task learning framework using tri-encoder with caption prompt for multimodal aspect-based sentiment analysis. <em>SUPERC</em>, <em>81</em>(6), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07252-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis (MABSA) is an advanced technology to identify all aspect terms together with their respective sentiment mentioned in the multimodal data. Most existing MABSA methods encounter two main challenges: (1) The representations used in MABSA are directly encoded by the general pre-trained models, which are insensitive to identifying aspect-level sentiment. (2) Latent visual semantic information is underutilized when representing the key aspects and their sentimental polarities. To address the mentioned challenges, we propose an optimized multi-task learning framework using a tri-encoder with caption prompt (TECP), including MABSA and two auxiliary unimodal tasks to jointly learn the aspect-aware and sentiment-aware multimodal representation. In TECP, the merged-attention fusion network is designed to obtain multimodal features, which enhances the intra-modal and cross-modal semantic interactions. Within the tri-encoder, the caption encoder is designed to further generate visual caption feature as important clue to enrich the multimodal semantic and sentimental information. Moreover, within the caption encoder, the dependency weight attention network is proposed to focus on the aspect-level feature in the caption sentence. We conduct elaborate experiments and evaluate the performance of TECP with respect to Precision, Recall, and F1-score. Our TECP achieves SOTA results on two benchmark Twitter datasets in comparison with previous baseline models.},
  archive      = {J_SUPERC},
  author       = {Cai, Yuanyuan and Tong, Fei and Zhang, Qingchuan and Xiong, Haitao},
  doi          = {10.1007/s11227-025-07252-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Multi-task learning framework using tri-encoder with caption prompt for multimodal aspect-based sentiment analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized intrusion detection system for resource-constrained IoMT environments: Enhancing security through efficient feature selection and classification. <em>SUPERC</em>, <em>81</em>(6), 1--54. (<a href='https://doi.org/10.1007/s11227-025-07253-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a resource-efficient IDS tailored for the IoMT, primarily emphasizing IoMT-enhanced security in medical networks. Characteristically resource-constrained and inherently vulnerable to various cyber threats, IoMT devices are typically ordinary. Inherent IoMT IDS pays off with the necessity for a critical trade-off between detection accuracy and computational efficiency. For this reason, the two-step feature selection stage is proposed to bring this challenge down. Firstly, the system decreases the dimensionality by operating the MI filtering on the dataset and keeps only the most informative features. It further refines this using ensemble-based ranking methods, such as Random Forest, AdaBoost, XGBoost, and LightGBM, to ensure the optimum feature selection for the task. Random Forest was adopted for the final classification because it is generally robust, efficient at handling high-dimensional data, and usually performs well. The proposed system has been tested with intensive usage using three well-acknowledged benchmark datasets, namely WUSTL-EHMS-2020, NSL-KDD, and CIC-IoMT2024. It showed considerable accuracy, precision, recall, and F1-score gains, particularly for DDoS and DoS attack types. The proposed technique significantly reduces execution time and memory usage. This, in turn, makes the approach much more suitable for real-time implementation. At the same time, the gains to be had in computational resource savings make this an attractive approach for resource-constrained hardware environments. This work proposes an effective and efficient IDS for IoMT security.},
  archive      = {J_SUPERC},
  author       = {Salehpour, Arash and Balafar, Mohammad Ali and Souri, Alireza},
  doi          = {10.1007/s11227-025-07253-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--54},
  shortjournal = {J. Supercomput.},
  title        = {An optimized intrusion detection system for resource-constrained IoMT environments: Enhancing security through efficient feature selection and classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale feature enhanced detection of foreign object intrusions on railways. <em>SUPERC</em>, <em>81</em>(6), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07254-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective detection of foreign object intrusions on railways is essential for ensuring railway safety. A complex and variable railway environment leads to high miss and false alarm rates, particularly in detecting small-scale foreign objects. To address this challenge, we propose a railway foreign intrusion detection method based on multi-scale feature enhancement. Central to our method is the Dimension-aware Diffusion Fusion network, which enhances the capture and utilization of multi-scale feature information through diffusion and fusion in the intermediate layers of the backbone network. Additionally, we integrate the Variable Size and Stride module into the backbone network, enabling adaptive multi-scale feature extraction, which is crucial for detecting objects of varying sizes. Furthermore, we employ the High–Low (HiLo) attention mechanism, which significantly enhances feature representation by focusing on both high and low-frequency information, thereby improving the network’s ability to discern subtle object details amidst complex backgrounds. Moreover, we introduce the EMA slide loss, a flexible loss function capable of dynamically adjusting parameters for multi-scale detection tasks. The proposed method was tested on the Railway Foreign Intrusion (RFI) dataset and the public CityPersons dataset. Specifically, on the RFI dataset, our method achieves mAP@50 of 81.4% and mAP@50–95 of 59.4%. Additionally, on the CityPersons dataset, we achieve mAP@50 of 68.6% and mAP@50–95 of 42.8%. Experimental results demonstrate that our method outperforms comparative detectors in detection performance, highlighting its potential to significantly enhance railway safety and operational efficiency.},
  archive      = {J_SUPERC},
  author       = {Gao, Jialin and Zhu, Liqiang and Guo, Baoqing and Wang, Yao},
  doi          = {10.1007/s11227-025-07254-2},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Multi-scale feature enhanced detection of foreign object intrusions on railways},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical evaluation of ensemble learning and hybrid CNN-LSTM for IoT threat detection on heterogeneous datasets. <em>SUPERC</em>, <em>81</em>(6), 1--52. (<a href='https://doi.org/10.1007/s11227-025-07255-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has experienced exponential growth, with a vast number of interconnected devices infiltrating daily life and industries. As this ecosystem expands, IoT security becomes increasingly vital due to the rising sophistication of cyber threats like malware, DDoS attacks, and data breaches, which endanger the confidentiality, integrity, and availability of IoT-based systems. Challenges in IoT security are rooted in the diverse nature of devices, limited resources at IoT endpoints, and the complex, dynamic network environment. This research aims to address the need for highly accurate and efficient IoT threat detection. We conduct an in-depth comparison between ensemble machine learning classifiers and advanced hybrid neural network models, using data from three key datasets: IoT-23, N-BaIoT, and CICIDS2017. Through rigorous experimentation, our refined techniques yield remarkable results. The proposed models achieved 95% accuracy on the IoT-23 dataset, along with notable area under the curve (AUC) scores. For the N-BaIoT and CICIDS2017 datasets, an impressive 99.99% accuracy was attained, highlighting the models’ adaptability to different threat scenarios. This research contributes to IoT security by comprehensively evaluating state-of-the-art threat detection methods, providing valuable insights for researchers and practitioners, and suggesting directions for future research in optimizing model selection and data processing techniques.},
  archive      = {J_SUPERC},
  author       = {Nazir, Ahsan and He, Jingsha and Zhu, Nafei and Wajahat, Ahsan and Ullah, Fahim and Qureshi, Sirajuddin and Pathan, Muhammad Salman},
  doi          = {10.1007/s11227-025-07255-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--52},
  shortjournal = {J. Supercomput.},
  title        = {Empirical evaluation of ensemble learning and hybrid CNN-LSTM for IoT threat detection on heterogeneous datasets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous attention YOLO model for traffic sign detection. <em>SUPERC</em>, <em>81</em>(6), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07256-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection plays a pivotal role in enhancing the safety and efficiency of autonomous driving systems. Nevertheless, accurately detecting small, occluded, and visually complex traffic signs remains a significant challenge in real-world environments. To address these issues, this article proposes a Heterogeneous Attention YOLO model (HA-YOLO), a novel framework built upon the YOLOv8 model, designed to improve detection robustness under challenging conditions. The proposed approach incorporates High-level Screening-feature Pyramid Networks (HSFPN) for adaptive multiscale feature fusion, thereby reducing the loss of fine-grained details crucial for small or partially obscured signs. The proposed model also integrates Spatial and Channel Synergistic Attention (SCSA) and Triplet Attention are embedded into the C2f module, forming the C2f-Synergistic Attention (CSA) and C2f-Triplet Attention (CTA) submodules. These attention mechanisms enable the network to focus on salient spatial and semantic information, alleviating false positives and missed detections in complex scenarios. Under the tested conditions, experimental evaluations on TT-100K, CCTSDB, and GTSDB datasets demonstrate that HA-YOLO outperforms the baseline YOLOv8m by 5.1%, 0.6% and 15.9% in mAP@50, respectively, validating its effectiveness in real-world traffic sign detection tasks. The code of the proposed method will be publicly available at https://github.com/dengy1207/HAYOLO .},
  archive      = {J_SUPERC},
  author       = {Deng, Yan and Huang, Lidong and Gan, Xinsu and Lu, Youfang and Shi, Shunxiang},
  doi          = {10.1007/s11227-025-07256-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {A heterogeneous attention YOLO model for traffic sign detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved snake optimization algorithm based on hybrid strategy. <em>SUPERC</em>, <em>81</em>(6), 1--41. (<a href='https://doi.org/10.1007/s11227-025-07258-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Snake Optimization algorithm (SO) is an efficient meta-heuristic algorithm. However, it still has insufficient convergence speed and accuracy when tackling complex problems. To address these shortcomings, this paper proposes an improved Snake Optimization algorithm based on Hybrid Strategy (HSO). During the population initialization phase, the study employs a good point set initialization method, resulting in a more uniform distribution of the initial population. Second, a nonlinear balance factor is introduced to better balance exploration and exploitation. Furthermore, the differential evolution strategy and Lévy flight strategy are introduced to enhance the algorithm’s capability to escape local optima. To evaluate the effectiveness of the proposed strategies, this study conducted an ablation comparison experiment based on the CEC2022 benchmark functions and compared the HSO algorithm with several meta-heuristic algorithms. The results of the experiment were then statistically analyzed using the Friedman test and Wilcoxon signed-rank test. Finally, three engineering design problems were employed to assess the application value of HSO in practical problems. The findings demonstrate that HSO achieves significant improvements in optimization capability compared to SO, and outperforms the comparison algorithms.},
  archive      = {J_SUPERC},
  author       = {Yang, Yahao and Liu, Yu and Yan, Pengguo and Wang, Yukun and Zhao, Zhenlong},
  doi          = {10.1007/s11227-025-07258-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--41},
  shortjournal = {J. Supercomput.},
  title        = {An improved snake optimization algorithm based on hybrid strategy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive network construction for single-cell clustering. <em>SUPERC</em>, <em>81</em>(6), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07263-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell clustering on single-cell RNA sequencing (scRNA-seq) data enables precise and detailed discrimination of cell populations and their tissue functions, garnering significant interest. A category of outstanding methods performs node clustering on cell networks constructed from preprocessed or dimensionally reduced data, capturing the complex relationships between cells to accomplish the cell clustering task. However, these methods typically employ a k nearest neighbors (KNN) approach to construct the cell network, using the same number k of highly similar cells for each cell. This approach overlooks the distribution characteristics of the similarity values, which can degrade subsequent clustering performance. In this paper, we analyze the similarity distribution of cells and propose determining the k value for each cell based on its similarity distribution. Consequently, we develop an adaptive network construction algorithm that selects a varying number of highly similar cells for each cell, with the number automatically determined according to the cell’s similarity distribution. Our experiments on several datasets demonstrate that this proposed adaptive network construction algorithm outperforms the KNN-based approach and enhances clustering performance.},
  archive      = {J_SUPERC},
  author       = {Yang, Tianyu and Hu, Yanmei and Wu, Yihang and Zhang, Yingxi and Duo, Bin and Tang, Xiaochuan and Li, Xiangtao},
  doi          = {10.1007/s11227-025-07263-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {An adaptive network construction for single-cell clustering},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethink reynolds’ rules: Flock-inspired network for vehicle trajectory prediction. <em>SUPERC</em>, <em>81</em>(6), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07265-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction plays a pivotal role in the field of intelligent vehicles. However, due to the ignorance of future sequential and social correlations of vehicle trajectories, existing works usually suffer from serious inaccurate prediction, such as critical kinematic infeasibility and severe potential collision risks. To address the above challenges, this paper proposes an efficient flock-inspired network (FN)-based vehicle trajectory prediction algorithm. Specifically, first of all, by means of establishing the sequential correlations of vehicle trajectories, a feasible global velocity matching (GVM) scheme is proposed to enhance prediction efficiency. In addition, we design a viable radial basis attention (RBA) module to extract the active flock centering behaviors for improving the social compatibility of trajectory prediction. Moreover, in order to further reduce the potential risk of traffic collisions, we construct an available Hypothetical Rollout Predictor (HRP) to represent the passive avoidance behaviors among future trajectories. Finally, the extensive experimental results on four typical benchmark datasets (NGSIM, highD, INTERACTION, and Argoverse datasets) firmly demonstrate the effectiveness of our proposed algorithm compared with other state-of-the-art approaches.},
  archive      = {J_SUPERC},
  author       = {Xue, Qifan and Yang, Feng and Li, Shengyi and Li, Xuanpeng and Li, Guangyu and Zhang, Weigong},
  doi          = {10.1007/s11227-025-07265-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Rethink reynolds’ rules: Flock-inspired network for vehicle trajectory prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling evasive malware behavior: Toward generating a multi-sources benchmark dataset and evasive malware behavior profiling using network traffic and memory analysis. <em>SUPERC</em>, <em>81</em>(6), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07267-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ongoing issue of malware significantly undermines network security. Despite the proliferation of detection techniques, traditional detection methods often struggle to distinguish malware activities accurately. Consequently, there is a growing recognition of the need to leverage artificial intelligence (AI) techniques to enhance malware detection capabilities. However, AI-based approaches heavily depend on data to understand and differentiate various network behaviors. Nonetheless, nowadays, single-source datasets are inadequate to detect all types of malware, as malware can display malicious activity across multiple sources. To address this gap, in this paper, we introduce BCCC-Mal-NetMem-2025, a novel multi-source malware dataset merging memory and network data sources along with a benign user and entity behavioral profiler (BUEBP) to generate background benign data and a new memory data analyzer named VolMemLyzer-V2 to analyze and extract memory features. Our approach addresses shortcomings in current dataset creation and evaluation practices by synthesizing two data sources, aiming to establish a new standard for dataset integrity. Methodologically, we execute 2,000 malware samples across eight families, capturing memory and network data and extracting features for comprehensive analysis. This effort culminates in developing a sophisticated multilayer malware detection system leveraging network and memory data. The proposed model consistently outperforms alternatives in all scenarios through comprehensive evaluation and can identify unknown malicious activities.},
  archive      = {J_SUPERC},
  author       = {Habibi Lashkari, Arash and Shafi, MohammadMoein and Li, Yongkun and Singh, Abhay Pratap and Barkworth, Ashley},
  doi          = {10.1007/s11227-025-07267-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Unveiling evasive malware behavior: Toward generating a multi-sources benchmark dataset and evasive malware behavior profiling using network traffic and memory analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A trust-driven optimization model for reliable authorization in hadoop environment. <em>SUPERC</em>, <em>81</em>(6), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07268-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authorization is a fundamental service in the Hadoop environment. It ensures data and protocol security while granting access exclusively to authorized users, allowing them to perform operations such as data storage, processing, and file transfer in a controlled manner. However, maintaining effective authorization remains challenging due to vulnerabilities in the Hadoop ecosystem and potential abnormal user behavior. Various authorization protocols have been developed based on different assumptions about the Hadoop environment, each aiming to ensure reliable and efficient access control through distinct techniques. While these techniques have their strengths and limitations, authorization can be further enhanced by integrating additional security mechanisms. In this work, we propose a trust-based authorization model to assist the NameNode in making access control decisions, particularly when handling uncertain or untrusted authenticated users. This model addresses two key questions: (1) should the authenticated user be authorized to perform the requested operation? (2) how should the request be executed? Our approach leverages machine learning alongside existing security tools, such as monitoring systems and intrusion detection mechanisms, to identify intrusions or unauthorized operations. By continuously analyzing incoming requests and monitoring the Hadoop environment, our method enhances security while maintaining operational efficiency. Additionally, we integrate elephant herding optimization to enable a distributed and adaptive access control mechanism, optimizing user satisfaction, minimizing security risks, and reducing resource consumption. The proposed model is evaluated against a generic authorization framework based on role-based access control and attribute-based access control using different performance metrics. Experimental results demonstrate the effectiveness of our approach in detecting unauthorized access. Furthermore, the machine learning-based intrusion detection method is assessed using widely recognized datasets, considering key metrics such as accuracy, recall, precision, F1-score, specificity, AUC-ROC, and execution time. The results illustrate that the applied ML techniques are effective and can achieve optimal performance.},
  archive      = {J_SUPERC},
  author       = {Battat, Nadia and Makhoul, Abdallah},
  doi          = {10.1007/s11227-025-07268-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {A trust-driven optimization model for reliable authorization in hadoop environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed finite-time adaptive fuzzy-based fault-tolerant control of robotic manipulators using dynamic scaling factor. <em>SUPERC</em>, <em>81</em>(6), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07270-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulators play a critical role in modern automation; however, their efficacy can be significantly restricted by actuator faults, which present challenges to both stability and reliability. Current control strategies, including finite-time and fixed-time methods, encounter difficulties in achieving precise system state convergence within a designated timeframe. Furthermore, their structure relies on fractional power terms, which complicate the implementation process. To address these challenges, this paper proposes a novel prescribed-time control strategy that guarantees system stability within a predetermined time, regardless of initial conditions. The key innovation lies in the integration of a dynamic time-varying scaling factor into a sliding mode controller, acting as an infinite gain to enforce strict prescribed-time convergence. Additionally, a fuzzy logic system is integrated to adaptively approximate actuator faults, thereby enhancing the robustness of the system while reducing computational complexity. The boundedness of the system states is proved through the Lyapunov stability theory. Moreover, the simulation result illustrates the performance of the proposed approach in the presence of actuator faults.},
  archive      = {J_SUPERC},
  author       = {Serajgah, Saman Amini and Ahmadi, Ali-Akbar},
  doi          = {10.1007/s11227-025-07270-2},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Prescribed finite-time adaptive fuzzy-based fault-tolerant control of robotic manipulators using dynamic scaling factor},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network intrusion detection based on feature fusion of attack dimension. <em>SUPERC</em>, <em>81</em>(6), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07271-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic anomaly detection involves the rapid identification of intrusions within a network through the detection, analysis, and classification of network traffic data. The variety of cyberattacks encompasses diverse attack principles. Employing an indiscriminate feature selection strategy may lead to the neglect of key features highly correlated with specific attack types. This oversight could diminish the recognition rate for that category, thereby impacting the overall performance of the detection model. To address this issue, this paper proposes a network traffic anomaly detection model based on the fusion of attack-dimensional features. Firstly, construct binary classification datasets independently for each attack class and perform individual feature selection to extract positively correlated features for each class. The features are then fused by employing a combination methods. Subsequently, based on the fused sub-datasets, base classifiers are trained. Finally, an ensemble learning approach is introduced to integrate the predictions of individual classifiers, enhancing the robustness of the model. The proposed approach, validated on NSL-KDD and UNSW-NB15 benchmark datasets, outperforms the latest methods in the field by achieving a $$2\%$$ and $$7\%$$ increase in precision on weighted averages.},
  archive      = {J_SUPERC},
  author       = {Sun, Xiaolong and Gu, Zhengyao and Zhang, Hao and Gu, Jason and Liu, Yanhua and Dong, Chen and Ye, Junwei},
  doi          = {10.1007/s11227-025-07271-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Network intrusion detection based on feature fusion of attack dimension},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive two-stage task offloading based on meta reinforcement learning for mobile edge computing. <em>SUPERC</em>, <em>81</em>(6), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07274-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing (MEC), the limited resources of individual edge servers and the uneven workload can significantly impact the system performance and user quality of experience (QoE), necessitating greater consideration for edge-edge and edge-cloud collaboration. However, existing collaborative task offloading strategies still fall short in performance and lack adaptability to dynamic environments. To address these challenges, this paper proposes a meta-reinforcement learning-based two-stage task offloading algorithm, named MRL-TSO, for decentralized task offloading in a generic MEC framework that integrates edge-edge and edge-cloud cooperation. MRL-TSO is the first to leverage MRL to address collaborative task offloading for edge-edge and edge-cloud at the edge layer and innovatively divides the offloading decision into two stages: in the first stage, a trained decision model is used to make preliminary decisions based on local information; in the second stage, the initial decision is combined with the status of edge servers to filter out unavailable resources, thereby improving the reliability of the decision. Experimental results indicate that, compared to the state-of-the-art work, MRL-TSO increases the task success rate by at least 1.43% and reduces latency by 9.69%. Especially in the case of edge server failures, it improves the task success rate by at least 45.60% compared to the competitive algorithms, demonstrating better environmental adaptability and robustness.},
  archive      = {J_SUPERC},
  author       = {Li, Wenjuan and Yang, Genyuan and Wang, Ben and Zhang, Qifei and Hu, Keyong and Pan, Chengjie and Ni, Qiwen},
  doi          = {10.1007/s11227-025-07274-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive two-stage task offloading based on meta reinforcement learning for mobile edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic environmental protection edge computing: A monitoring algorithm and system of truck black smoke emission in complex scene. <em>SUPERC</em>, <em>81</em>(6), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07276-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illegal emission of black smoke from trucks is the focus and difficulty of road traffic environmental protection law enforcement. In order to solve the problem of insufficient accuracy and speed of black smoke detection in complex environments, we propose a lightweight real-time black smoke detection model EC-RTDETR based on edge intelligence. EC-RTDETR is deployed on intelligent hardware. It realizes real-time detection of illegal emission of black smoke from trucks in complex traffic environments. Firstly, a multi-scale feature extraction module is designed in backbone by using different types of convolutional modules to reduce information loss during feature extraction and memory access during inference. Secondly, we introduce an improved multipath coordinate attention mechanism. It enhances the model feature fusion by utilizing the information of spatial and channel dimensions. Finally, minimum point distance intersection over union is used to replace complete IoU to optimize the model loss function, which reduced the redundancy of the predicted bounding box. The mean average precision achieves 94.6%. It is improved by 2.8% compared with RTDETR. We have deployed the model at the detection points in Xuchang City, Henan Province. The results show that EC-RTDETR meets the requirement of real-time detection. The results are also transmitted to the cloud directly. This facilitates the rapid enforcement by the environmental protection department.},
  archive      = {J_SUPERC},
  author       = {Yang, Kang and Zhang, Lili and Han, Yucheng and Zhang, Ke and Li, Jing and Wei, Wei and Tan, Hongxin and Yu, Pei},
  doi          = {10.1007/s11227-025-07276-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Traffic environmental protection edge computing: A monitoring algorithm and system of truck black smoke emission in complex scene},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnosis of sacroiliitis using MR images with a simplified custom deep learning model. <em>SUPERC</em>, <em>81</em>(6), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07280-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axial spondyloarthritis (SpA) is an inflammatory disease that causes back pain by affecting the axial skeleton, and the sacroiliac (SI) joints are mostly involved. An early diagnosis is required to prevent structural damage. Magnetic resonance imaging (MRI) is the primary tool for the diagnosis of axial spondyloarthritis; however, the occurrence of noninflammatory degenerative changes might prevent the accurate diagnosis even for experts. Deep learning (DL) aims to assist radiologists in detecting and diagnosing sacroiliitis by providing distinct and effective feature extraction along MR sequences. This retrospective study considers a primary dataset with 50 clinical sacroiliitis and 50 control group patients and aims to diagnose sacroiliitis using 4 MRI sequences. For this purpose, a simplified convolutional neural network model is developed, and comprehensive comparative experiments and analyses are performed. Three pre-trained DL models are considered in a comparative study using a transfer learning approach. Image-based, sequence-based, and patient-based experiments are conducted to evaluate general diagnostic abilities, analyze further clinical implementations, and determine the most informative and challenging MRI sequences. The results showed that the proposed model has the ability to detect sacroiliitis with 0.951 and 0.977 accuracy in patient and image-based experiments, respectively. The deep learning models obtained promising results for future clinical implementation to assist radiologists in detecting sacroiliitis. It is also analyzed that the STIR coronal images are the most challenging, while T1 axial sequences are the most informative sequences for sacroiliitis diagnosis.},
  archive      = {J_SUPERC},
  author       = {Uzelaltinbulat, Selin and Kucukciloglu, Yasemin and Ilhan, Ahmet and Mirzaei, Omid and Sekeroglu, Boran},
  doi          = {10.1007/s11227-025-07280-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Diagnosis of sacroiliitis using MR images with a simplified custom deep learning model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the impact of high-performance computing on digital transformation: Benefits, challenges, and size-dependent differences. <em>SUPERC</em>, <em>81</em>(6), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07281-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance computing (HPC) plays a crucial role in accelerating digital transformation, yet there is a lack of studies that systematically characterize its impact across different company sizes. This study addresses this gap by analyzing a cross-sectoral panel of 294 Portuguese companies, comprising 103 large enterprises and 191 small- and medium-sized enterprises (SMEs). It was applied descriptive analysis and statistical hypothesis testing methods. Two key research questions guide this investigation. The first explores the primary benefits and challenges associated with HPC adoption, while the second examines whether these factors vary between large companies and SMEs. The findings indicate that the benefits and challenges of the HPC are heterogeneously perceived by large companies and SMEs. It identified significant differences in the perceived benefits and challenges of HPC, particularly concerning cost savings, decision-making, cost and skills management, lack of awareness, and workforce skills gap. These findings contribute to a deeper understanding of how HPC supports digitalization processes, highlighting sector-specific and size-dependent differences in its perceived value and implementation barriers. This study provides valuable insights for businesses, policymakers, and researchers seeking to optimize HPC strategies for digital transformation.},
  archive      = {J_SUPERC},
  author       = {Almeida, Fernando and Okon, Edet},
  doi          = {10.1007/s11227-025-07281-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Assessing the impact of high-performance computing on digital transformation: Benefits, challenges, and size-dependent differences},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision and LiDAR multi-modal fusion beam prediction method for millimeter-wave communication system. <em>SUPERC</em>, <em>81</em>(6), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07284-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future vehicle-connected communication systems increasingly rely on millimeter-wave (mmWave) and terahertz (THz) communication technologies to establish reliable connections. While high-frequency band communications offer the advantages of high data rates and low latency, the beams are susceptible to interference from obstacles, which leads to signal attenuation and multipath effects, affecting the reliability of traditional unimodal beam prediction. Therefore, the use of multi-modal sensor data such as Vision and LiDAR is crucial. However, the adoption of these techniques often results in a higher beam training overhead. To solve this problem, we propose a new multi-modal deep learning framework that utilizes a Multi-modal Group Attention Transformer (MGA-Transformer) for sensor-assisted beam prediction. Specifically, our method first preprocesses the collected visual and LiDAR data, utilizes a Grouped-query Attention mechanism for multi-scale feature fusion, and utilizes time mixing to enhance the temporal correlation of multi-modal data. Finally, the fused multi-modal features are fed into the Multilayer Perceptron (MLP) network to achieve fast and accurate beam prediction. In four different communication scenarios, our proposed scheme shows an overall prediction accuracy of 91.4%, a 10% improvement in the Top-1 accuracy compared with single-mode beam prediction. Because the sensor data are significantly affected by the environment, the performance of the multi-modal model is degraded when there is only a single-mode input. We adopted the Moe architecture to provide an independent processing unit for each mode and verified that the multi-modal model can effectively handle situations when there is only image data input. The solution effectively reduces the beam training overhead while achieving a reasoning speed of 43.47 FPS, providing highly reliable and low-latency communication support in highly mobile environments.},
  archive      = {J_SUPERC},
  author       = {Luo, Wenyu and Hou, Changxing and Shao, Xia and Yan, Tianze and Xuan, Annan},
  doi          = {10.1007/s11227-025-07284-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Vision and LiDAR multi-modal fusion beam prediction method for millimeter-wave communication system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey analyzing encryption schemes for IoT security measures. <em>SUPERC</em>, <em>81</em>(6), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07285-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers focus on protecting users’ data in storage platforms such as cloud, edge, and fog due to the widespread deployment of Internet of Things environments and devices and high-speed networks. This includes safeguarding data collected from various sources like social media, healthcare, education, business, and defense against unauthorized use. To achieve this goal, it is essential to discuss different cryptographic encryption techniques and algorithms, especially those relevant to securing data obtained from IoT environments. In this paper, different cryptographic schemes are discussed, focusing on attribute-based encryption, searchable-based encryption, identity-based encryption, proxy re-encryption, functional encryption scheme, and predicate encryption schemes. Computations on the raw data obtained from IoT devices can be performed at the edge or cloud using homomorphic encryption, which has also been discussed. Lightweight cryptography is designed for low-power-consuming IoT devices. Here, different cryptographic schemes are compared using distinct parameters.},
  archive      = {J_SUPERC},
  author       = {Dhiman, Shalini and Nayak, Sumitra and Mahato, Ganesh Kumar and Chakraborty, Swarnendu Kumar},
  doi          = {10.1007/s11227-025-07285-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {A survey analyzing encryption schemes for IoT security measures},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A provably secure certificateless online/offline signature scheme for internet of things. <em>SUPERC</em>, <em>81</em>(6), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07294-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things (IoT), it is necessary to guarantee the integrity, authentication and nonrepudiation of messages. Considering the high security and efficiency requirements of the data transmission for the IoT, the online/offline signature scheme is a wonderful choice. However, most of the existing online/offline signature schemes are based on "hash-sign-switch" paradigm, and they exist key exposure as well as high storage overhead problems. Therefore, this paper designs a provably secure certificateless online/offline signature scheme for IoT (psCL-OOS). By incorporating the double-trapdoor chameleon hash to the scheme, the key exposure-free is perfectly achieved. Moreover, based on the discrete logarithm problem, we prove the security of the scheme in the random oracle model. The results show that our scheme can resist both type I and type II adversary attacks, and is strongly unforgeable against adaptively chosen message attacks. Finally, performance analysis shows that the psCL-OOS scheme is superior to other compared schemes on computational complexity and communication overhead.},
  archive      = {J_SUPERC},
  author       = {Chen, Yulei and Guo, Dongwei and Chen, Jianhua},
  doi          = {10.1007/s11227-025-07294-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {A provably secure certificateless online/offline signature scheme for internet of things},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modelling approach for estimating energy consumption of NoSQL-based storage systems. <em>SUPERC</em>, <em>81</em>(6), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07298-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale data storage systems, NoSQL database management systems are commonly adopted for their capacity to provide better performance and availability. A key feature is the support for eventual consistency. Distinct consistency levels can be adopted, such that a designer may adjust the respective influence on performance and availability according to system requirements. Some research proposes techniques to estimate the impact of eventual consistency on performance and availability, but energy consumption is usually not taken into account. This paper presents a modeling approach based on stochastic Petri nets for estimating energy consumption of NoSQL-based systems utilizing quorum technique. The conceived model jointly considers performance and availability as well as the influence of consistency level, replication factor, and read and write operations. The proposed approach provides an additional design tool to evaluate system settings before the final implementation. Experimental results demonstrate replication factor and consistency level may impact energy usage more than 10%.},
  archive      = {J_SUPERC},
  author       = {Souza, Fillipe and Tavares, Eduardo and Araújo, Carlos},
  doi          = {10.1007/s11227-025-07298-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {A modelling approach for estimating energy consumption of NoSQL-based storage systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic feature space construction for unsupervised few-shot image classification. <em>SUPERC</em>, <em>81</em>(6), 1--45. (<a href='https://doi.org/10.1007/s11227-025-07315-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised few-shot learning faces challenges such as "sampling bias" and "class collision," which make it difficult to extract effective features from limited samples and map them into a separable feature space, thus weakening the model’s generalization ability. To address this issue, this paper proposes a novel unsupervised few-shot learning method—Enhanced Contrastive Self-supervised Learning (ECSL). ECSL includes a multi-task training framework, a General Feature Enhancement (GFE) module, a Projection Distance Metric Algorithm (PDMA), and an Adjustable Loss function (AL). The method aims to enhance the model’s understanding of samples through complex task collaboration, enabling it to extract more generalized semantic information and thereby establish an effective mapping from samples to a separable feature space. Experimental results show that ECSL outperforms existing methods such as PsCo and CPNWCP on the miniImageNet and tieredImageNet datasets. In the 5-way 1-shot task, ECSL improves classification accuracy by 2.10% and 2.11%, respectively, compared to CPNWCP, and in the 5-way 5-shot task, it improves by 0.66% and 1.55%. These results show significant competitiveness among unsupervised few-shot learning methods, particularly in the miniImageNet 5-way 1-shot experiment, where ECSL even exceeds traditional supervised methods.},
  archive      = {J_SUPERC},
  author       = {Wang, Zhicheng and Wang, Longge and Yu, Junyang and Li, Han and Wang, Tingyu and Wu, Jinhu},
  doi          = {10.1007/s11227-025-07315-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {6},
  pages        = {1--45},
  shortjournal = {J. Supercomput.},
  title        = {Semantic feature space construction for unsupervised few-shot image classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive differential evolution with knowledge inheritance for single-objective human-powered aircraft design. <em>SUPERC</em>, <em>81</em>(5), 1--35. (<a href='https://doi.org/10.1007/s11227-024-06859-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel and efficient optimizer derived from differential evolution (DE): Competitive differential evolution with knowledge inheritance (CDEKI). CDEKI is developed by introducing the competitive mechanism and incorporates a novel DE/winner-to-best/1 mutation strategy and a hybrid local search operation. Moreover, we emphasize the significance of a commonly neglected component in DE: the repair operation. We propose a novel repair operation with knowledge inheritance to accelerate optimization convergence, particularly when the generated offspring exceeds the search domain. Through comprehensive numerical experiments conducted on the CEC2020 benchmark functions, competing against sixteen state-of-the-art optimizers and advanced DE variants, our proposed CDEKI demonstrates significant superiority. Additionally, the ablation experiments are conducted to independently investigate the performance of the proposed strategies. Furthermore, we extend the application of CDEKI to real-world human-powered aircraft design tasks, showcasing its extraordinary performance in practical scenarios. As an effective and efficient optimizer, CDEKI presents a compelling alternative evolutionary approach for addressing real-world applications across diverse domains. The source code of CDEKI is available in https://github.com/RuiZhong961230/CDEKI .},
  archive      = {J_SUPERC},
  author       = {Zhong, Rui and Cao, Yang and Zhang, Enzhi and Munetomo, Masaharu},
  doi          = {10.1007/s11227-024-06859-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Competitive differential evolution with knowledge inheritance for single-objective human-powered aircraft design},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preliminary evaluation of SHAVER: Sharing vector registers with an accelerator. <em>SUPERC</em>, <em>81</em>(5), 1--22. (<a href='https://doi.org/10.1007/s11227-024-06863-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, demand for data-parallel processing has been growing, and this parallelism often appears in artificial intelligence processes. One method to accelerate these processes is using domain-specific architecture (DSA). A common data transfer method on DSA is DMA (direct memory access). There are several studies on DMA-based accelerators. However, few studies focus on data transfer methods. In this paper, a vector register-sharing mechanism has been proposed as a new data transfer method. Our proposed mechanism is named “SHAVER." In this mechanism, a part of vector registers is directly shared with an accelerator. An open-source RISC-V vector co-processor is used to evaluate the mechanism’s potential. It has been implemented on an FPGA and a simulator for the evaluations. The results indicate the possibility of the proposal mechanism to achieve a maximum of 8.38% speedup over DMA transfer.},
  archive      = {J_SUPERC},
  author       = {Tanaka, Tomoaki and Kato, Michiya and Osana, Yasunori and Miyoshi, Takefumi and Tada, Jubee and Tanaka, Kiyofumi and Nakajo, Hironori},
  doi          = {10.1007/s11227-024-06863-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Preliminary evaluation of SHAVER: Sharing vector registers with an accelerator},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similar music recommendation method using spotify API. <em>SUPERC</em>, <em>81</em>(5), 1--17. (<a href='https://doi.org/10.1007/s11227-024-06864-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we proposed a similar music–recommendation method based on the baseline method. A similar music recommendation method using the Spotify API was proposed as a music retrieval method. The baseline method computes the Euclidean distance between the audio features obtained from the Spotify API. In this method, the normalization of the obtained audio features and validation of the features used were insufficient. Therefore, in this study, to confirm the effectiveness of music recommendation methods, a questionnaire is used as comparative data. From the results of the questionnaire, a ranking of each music is determined. To recommend music that is closer to the ranking, we propose a method to improve the baseline method. The proposed method is adopted normalization, audio feature selection, and similarity computations based on cosine similarity. It was verified through experiments that the method of normalizing appropriate features by adopting the min–max method and computing similarity using the Euclidean distance was effective.},
  archive      = {J_SUPERC},
  author       = {Takata, Masami and Chiyonobu, Miho},
  doi          = {10.1007/s11227-024-06864-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Similar music recommendation method using spotify API},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation environment for reconfigurable virtual accelerators using a field programmable gate array development environment. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06865-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, studies on artificial intelligence and high-performance computing have accelerated computations using field programmable gate arrays (FPGAs). High-level synthesis (HLS) is beneficial for implementing algorithms from these fields onto FPGAs as circuits. However, because the circuits generated by HLS are generally larger than those designed with hardware description language, using FPGAs in practice presents challenges regarding resource restrictions. To address these issues, we proposed a reconfigurable virtual accelerator (ReVA) that allows the sharing of resources across multiple FPGAs and enables the implementation of large-scale circuits. In this study, we proposed and implemented a ReVA Simulator. Furthermore, we estimated the execution time when utilizing ReVA and performed evaluations. The evaluation results demonstrate that the ReVA Simulator achieves a fast Fourier transform reduced by 36% compared to execution in C.},
  archive      = {J_SUPERC},
  author       = {Kawai, Shunya and Maeda, Eriko and Yaguchi, Kazuki and Osana, Yasunori and Miyoshi, Takefumi and Nakajo, Hironori},
  doi          = {10.1007/s11227-024-06865-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Simulation environment for reconfigurable virtual accelerators using a field programmable gate array development environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-speed computation method for condition numbers in the range restricted general minimum residual method. <em>SUPERC</em>, <em>81</em>(5), 1--19. (<a href='https://doi.org/10.1007/s11227-024-06868-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a method for fast computation of the stopping condition of the range restricted general minimum residual (RRGMRES) method. The RRGMRES method is iterative, causing the matrix size to increase with the number of iterations. The stopping criterion for the iterations is based on the condition number. The condition number was expressed as the ratio of the largest singular value to the smallest singular value. In the RRGMRES method, the computation of the condition number of the upper triangular matrix is a bottleneck. Conventional methods compute the smallest and largest singular values required for the condition number in each iteration. Conversely, the proposed method leverages the increasing matrix size with each iteration and utilizes the results from the previous iteration. In the proposed method, the smallest singular value can be obtained with high speed and accuracy using the inverse iteration method, and the largest singular value can be converted into a problem of computing the smallest singular value: using the inverse matrix. However, the matrix in this study may contain clusters of singular values around the largest singular value. Therefore, the largest singular values had to be separated from the clusters by using the Cholesky LR method. The accuracy of RRGMRES using the proposed method was nearly equal to that of the conventional method. By comparing the experimental results with those obtained using conventional methods, the proposed method was 10 times faster than the conventional method.},
  archive      = {J_SUPERC},
  author       = {Chiyonobu, Miho and Takata, Masami and Kimura, Kinji and Nakamura, Yoshimasa},
  doi          = {10.1007/s11227-024-06868-2},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {High-speed computation method for condition numbers in the range restricted general minimum residual method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved spherical search algorithm with memory-based dynamic population for optimization. <em>SUPERC</em>, <em>81</em>(5), 1--71. (<a href='https://doi.org/10.1007/s11227-025-07095-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spherical search algorithm (SS) generates novel solutions by partitioning the population and utilizing a spherical search space. However, the fixed size of sub-populations leads to an accelerated convergence rate in SS, which often results in being trapped into local optima. This paper presents an advanced SS enhanced with a memory-based dynamic population scheduling system (SSDS). Building on the foundational SS framework, SSDS innovates with a dynamic population approach, utilizing a sub-population ratio record sequence to leverage historical data, and multiplexing historical population proportions reasonable improve the exploration behavior. As a result, SSDS dynamically balances exploration and exploitation throughout the search process. Preliminary results indicate that SSDS surpasses contemporary nine algorithms in IEEE congress on evolutionary computation (CEC) benchmark tests and exhibits promising application in 22 complex real-world problems. A closer analysis of the search performance and population diversity further highlights the effectiveness of the proposed SSDS.},
  archive      = {J_SUPERC},
  author       = {Liu, Sicheng and Tao, Sichen and Wang, Kaiyu and Lei, Zhenyu and Gao, Shangce},
  doi          = {10.1007/s11227-025-07095-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--71},
  shortjournal = {J. Supercomput.},
  title        = {Improved spherical search algorithm with memory-based dynamic population for optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T-sanitation: Contrastive masked auto-encoder-based few-shot learning for malicious traffic detection. <em>SUPERC</em>, <em>81</em>(5), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07104-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems (IDSs) are a crucial component of network security, offering real-time monitoring, detection, and alerting. However, existing endeavors in establishing IDSs depend on the availability of a significant amount of supervised traffic. When malicious sample data are scarce, the model is prone to overfitting and shows poor generalization, especially in new attack patterns and out-of-domain scenarios. In this paper, we propose T-Sanitation, a novel contrastive masked auto-encoder-based malicious traffic detection in few-shot learning. Specifically, we first construct a generic representation of network traffic by analyzing session traffic based on transport-layer protocols. Then, T-Sanitation introduces two pre-training tasks: contrastive learning and mask patch reconstruction to enable the model to form a universal and difference analysis capability in unbiased representations from traffic with varying lengths and patterns. To validate the model’s effectiveness, we inherit the pre-trained encoder appended with a classifier for fine-tuning on supervised few-shot traffic. Additionally, we introduce focal loss and weight balance strategies to enhance the detection performance. Extensive experiments on the CIC-IDS2018, USTC-TFC2016, and ISCX-VPN2016-Service datasets demonstrate that T-Sanitation achieves an average detection accuracy of 99.07% using only 5 training samples per class for fine-tuning. It achieves an inference efficiency of over 1250 samples/s, with a model parameter size of 71.43 million. Compared with state-of-the-art few-shot learning methods, T-Sanitation achieves the highest performance in terms of accuracy, precision, recall, and F1 score. Moreover, it matches the performance gains of advanced methods that fine-tune using the full-training dataset.},
  archive      = {J_SUPERC},
  author       = {Sun, Jianwen and Zhang, Bin and Li, Hongyu and Yuan, Lu and Chang, Heyu},
  doi          = {10.1007/s11227-025-07104-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {T-sanitation: Contrastive masked auto-encoder-based few-shot learning for malicious traffic detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The mapping trick: Leveraging RoboSoccer obstacle avoidance and navigation for advanced task scheduling solutions in foggy IoE ecosystems. <em>SUPERC</em>, <em>81</em>(5), 1--100. (<a href='https://doi.org/10.1007/s11227-025-07147-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel approach to addressing the task scheduling problem in fog-based Internet of Everything (IoE) environments, drawing inspiration from RoboSoccer’s obstacle avoidance and navigation techniques. This methodology exploits RoboSoccer’s dynamic adaptability, advanced problem-solving capabilities, and established simulation environments to improve task scheduling efficiency in IoE systems. By integrating feature engineering and reinforcement learning, the task scheduling challenge is reformulated within the RoboSoccer domain, enabling the application of advanced control and decision-making strategies. The core objective of this study is to evaluate the effectiveness of this mapping on the performance of various algorithms, with a focus on five key metrics: Makespan (MS), Resource Utilization Ratio (RUR), Average Task Completion Time (ATCT), Resource Allocation Accuracy (RAA), and in Processing Speed (PS). One of the key benefits of this method is its ability to quickly adapt to changes in dynamic environments, making it a suitable solution for real-world IoE applications, reducing complexity in agent interactions, and improving algorithm reusability through knowledge transfer. Furthermore, RoboSoccer’s diverse simulators ensure scalability, making the method applicable across a wide range of task scheduling scenarios. Experimental results show total average improvements of 19.56% in MS, 6.68% in RUR, 4.87% in ATCT, 0.61% in RAA, and 0.29% in PS, thus demonstrating the effectiveness of the proposed RoboSoccer Mapping Trick in advanced recurrent RL algorithms. This groundbreaking methodology not only redefines RoboSoccer’s potential in optimizing task scheduling in resource-constrained IoE environments but also sets the stage for revolutionary advancements in problem-solving techniques across diverse domains.},
  archive      = {J_SUPERC},
  author       = {Azarkasb, Seyed Omid and Khasteh, Seyed Hossein},
  doi          = {10.1007/s11227-025-07147-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--100},
  shortjournal = {J. Supercomput.},
  title        = {The mapping trick: Leveraging RoboSoccer obstacle avoidance and navigation for advanced task scheduling solutions in foggy IoE ecosystems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep recognition of partial differential equations based on reinforcement learning and genetic algorithm. <em>SUPERC</em>, <em>81</em>(5), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07162-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting basic behavioral patterns or control equations from data has significant prospects for enhancing our understanding and utilization of physical systems in science and engineering. However, traditional methods for extracting these control equations often require a pre-obtained library containing candidate function terms, which is typically large and complex. Additionally, the collected data often contains noise, limiting the effectiveness of equation learning. To address this challenge, this paper proposes a reinforcement learning and genetic algorithm-based knowledge-guided dual-layer optimization structure algorithm (RLKGGA) for equation discovery, which combines reinforcement learning and genetic algorithms to identify partial differential equations (PDEs) thoroughly. Specifically, the Savitzky–Golay filter preprocesses the data, while the long short-term memory (LSTM) proxy generates a predetermined traversal sequence of the binary tree, facilitating the derivation of each PDE expression. Subsequently, under the guidance of an adaptive selection strategy, the obtained individuals are updated using a genetic algorithm to ensure the algorithm’s efficiency. Furthermore, a knowledge-guided double-layer optimization structure is proposed to aid in discovering complex partial differential equations. Manual constraints are utilized to eliminate unreasonable equations. Additionally, the LSTM is optimized through reinforcement learning, with a reward function designed to allocate rewards to each expression. Finally, the effectiveness of the method was experimentally verified, indicating that RLKGGA can proficiently identify control equations in various systems, including PDEs with complex forms and high-order derivatives. It also demonstrates robust performance in handling noisy data.},
  archive      = {J_SUPERC},
  author       = {Du, Jinyang and Liu, Renyun and Cheng, Du and Li, Qingliang and Yu, Fanhua},
  doi          = {10.1007/s11227-025-07162-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Deep recognition of partial differential equations based on reinforcement learning and genetic algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing speech emotion recognition: A deep learning approach with self-attention and acoustic features. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07166-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER), which involves detecting and classifying emotions from speech signals, plays a crucial role in human–computer interaction. However, challenges such as variability in emotional expression and limited labeled data have hindered progress in this area. To address these issues, we propose a novel deep learning framework that combines multiple acoustic features, including MFCCs, Mel-spectrograms, and temporal-frequency domain features. Our model leverages three parallel CNN-LSTM branches for sequential feature extraction, followed by a self-attention mechanism to integrate the extracted representations. A final LSTM layer, along with dense layers, refines the classification process. This innovative fusion of features and attention mechanisms significantly enhances emotion recognition performance. Experimental evaluations demonstrate the effectiveness of our approach in improving classification accuracy.},
  archive      = {J_SUPERC},
  author       = {Aghajani, Khadijeh and Zohrevandi, Mahbanou},
  doi          = {10.1007/s11227-025-07166-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing speech emotion recognition: A deep learning approach with self-attention and acoustic features},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FootprintNet: A siamese network method for biometric identification using footprints. <em>SUPERC</em>, <em>81</em>(5), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07170-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric technologies are fast becoming a requirement in security systems today, providing solutions where traditional means alone would not be adequate. This paper proposes FootprintNet, a Siamese network that utilizes pre-trained convolutional neural networks, specifically EfficientNet, MobileNet, and ShuffleNet, to improve the robustness and accuracy of footprint recognition. By learning the ability to identify fine distinctions between images of footprints, FootprintNet offers great biometric identification potential. Detailed analysis of the Biometric 220 × 6 Human Footprint dataset shows a true positive rate over 99% under various thresholds and a precision rate of 100% during training. Most importantly, this system is also applicable to newborn and infant identification, making it especially significant in medical settings, including hospitals and birthing clinics. Furthermore, the model sizes range from 7.8 MB (ShuffleNet) to 24.5 MB (EfficientNet), which makes FootprintNet deployable on low-computational-power devices—a highly desirable trait for mobile or high-security applications.},
  archive      = {J_SUPERC},
  author       = {İbrahimoğlu, Nadir and Osmani, Amjad and Ghaffari, Ali and Günay, Faruk Baturalp and Çavdar, Tuğrul and Yıldız, Furkan},
  doi          = {10.1007/s11227-025-07170-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {FootprintNet: A siamese network method for biometric identification using footprints},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-fast: A lightweight object detection model for edge devices. <em>SUPERC</em>, <em>81</em>(5), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07172-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight convolutional neural networks have created new opportunities for object recognition, enabling high-performance algorithms to operate on resource-constrained devices while preserving strong representational and generalization capabilities. This paper introduces a lightweight YOLO-Fast object detection model. By replacing the backbone feature extraction network, redundant computations are minimized, thereby optimizing inference speed. An attention module is incorporated to enhance detection accuracy and feature fusion capability. The experimental findings based on the publicly accessible VisDrone dataset indicate that the proposed model has a 1.03% improvement in mAP over the baseline model. Through sparse training and channel pruning, the model’s inference speed is further optimized, while the number of network parameters is reduced. Moreover, knowledge distillation restores the network’s accuracy to pre-pruning levels. The model’s computational load is reduced by 35.5%, with a processing time of 12 ms per image on the embedded Atlas 200I development board. The code is available at: https://github.com/ZJ-Song-Lab/YOLO-Fast .},
  archive      = {J_SUPERC},
  author       = {Song, Zijing and Zhang, Xiaoyu and Tan, Panlong},
  doi          = {10.1007/s11227-025-07172-3},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {YOLO-fast: A lightweight object detection model for edge devices},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLDE: A competitive learning-driven differential evolution optimization for the influence maximization problem in social networks. <em>SUPERC</em>, <em>81</em>(5), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07175-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence maximization problem focuses on identifying a small subset of influential users in social networks that can ignite maximum influence spread. The existing meta-heuristic evolutionary optimizations for the problem struggle with the threat of premature convergence into local optima easily and lack flexibility. It highlights the need for solutions with high influence spread while showing satisfactory time efficiency in large-scale networks. To address such challenges, a competitive learning-driven differential evolution (CLDE) optimization is proposed. The algorithm constructs an evolutionary population by employing a random partitioning mechanism that divides it into an excellent subpopulation and a common subpopulation. The global exploration and local exploitation operations are adopted for each subpopulation to improve the solution diversity and performance. Furthermore, an adaptive probabilistic updating-driven local search strategy is incorporated to better accommodate the topological structure of networks and enhance the robustness of the algorithm. Extensive experiments conducted on six real social networks and three different types of synthetic networks demonstrate that the proposed CLDE achieves an average improvement of 6% in influence spread compared to the state-of-the-art baselines, as well as competitive results to the well-known greedy-based cost-efficient lazy forward algorithm.},
  archive      = {J_SUPERC},
  author       = {Chai, Baoqiang and Zhang, Ruisheng and Li, Xinyue and Tang, Jianxin},
  doi          = {10.1007/s11227-025-07175-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {CLDE: A competitive learning-driven differential evolution optimization for the influence maximization problem in social networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel implementation of OCB using VAES and GPUs. <em>SUPERC</em>, <em>81</em>(5), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07179-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authenticated encryption schemes currently offer one of the greatest advantages in data encryption. Evaluating their capabilities and the various versions they come in is essential. The Offset Codebook is an authenticated encryption scheme with multiple versions, depending on the masking generation function (MGF) used, yielding different outcomes depending on the context. However, some MGFs can achieve more optimal performance than others, particularly in extensive parallelism, where most MGFs exhibit weaknesses due to their dependence on the previous block. This study compares two primary MGF versions: gray code (OCB3) and AES rounds (RAOCB). OCB3 is considered the most efficient and fast way to process OCB; however, it has limitations regarding parallel data processing. OCBRA is the latest version and, despite its reduced domain, boasts the distinct advantage of no block-to-block dependence. The main objective of this comparison is to determine whether OCBRA is faster than OCB3, considering factors such as message size, where parallelism can be leveraged. We conducted experiments using messages of various sizes categorized as small, medium, and large. All versions were implemented using 512-bit vector instructions (AVX-512 and VAES), and some tests were performed using GPU acceleration. The results obtained were as follows: OCB3 achieved 0.24 cycles per byte, while OCBRA achieved 0.19 cycles per byte. Overall, OCBRA demonstrated superiority across all tested message sizes.},
  archive      = {J_SUPERC},
  author       = {Pérez-Sarmiento, Luis A. and Mancillas-López, Cuauhtemoc},
  doi          = {10.1007/s11227-025-07179-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Parallel implementation of OCB using VAES and GPUs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint optimization for 6G beyond diagonal IRS-assisted multi-carrier NOMA vehicle-to-infrastructure communication. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07181-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent reconfigurable surface (IRS) is regarded as a highly promising technology for facilitating and enhancing the performance of future wireless communication networks. This is due to its capacity to effectively modify wireless channels in desired destinations with low-cost design and energy consumption. A significant amount of research has been dedicated to exploring the use of conventional IRS, where each phase response element is only connected to its own ground load with no connection to the other phase response elements. However, the simple design of conventional IRS limits its capacity to adjust passive beamforming. This study focuses on the implementation of beyond diagonal IRS (BD-IRS) in multi-carrier non-orthogonal multiple access (NOMA) vehicular communication, surpassing the use of diagonal phase shift matrices. Specifically, we propose a new optimization approach that aims to maximize the achievable spectral efficiency of a multi-carrier NOMA vehicular communication with BD-IRS assistance. This is achieved by optimizing the transmission power of RSU and the phase response of the BD-IRS. We utilize block coordinate descent and successive convex approximation methods to convert the original optimization problem into a series of subproblems. For the power allocation problem at RSU, we adopt Dinkelbach’s and first-order Tayler approximation while exploiting unitary constraint transformation for the phase response problem at BD-IRS and then use the CVX toolbox for the solution. The numerical findings clearly illustrate the advantages of the proposed optimization framework and implementing BD-IRS in multi-carrier NOMA vehicular communications networks in comparison to the conventional IRS architecture.},
  archive      = {J_SUPERC},
  author       = {Ahmed, Manzoor and Khan, Wali Ullah and Alamgeer, Mohammad and Alabdulkreem, Eatedal and Ebad, Shouki A. and Al-Sharafi, Ali M. and Dutta, Ashit Kumar and Khurshaid, Tahir},
  doi          = {10.1007/s11227-025-07181-2},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Joint optimization for 6G beyond diagonal IRS-assisted multi-carrier NOMA vehicle-to-infrastructure communication},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent device to device handover management techniques for 5G/6G and beyond. <em>SUPERC</em>, <em>81</em>(5), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07182-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As mobile networks grow to 5G, 6G, and beyond, uniform Handover Management (HOM) becomes important to ensure continuous connectivity and an improved user experience. This research investigates the complexities of HOM in next-generation (NZ) networks, concentrating on the problems and solutions for a smooth transition between various network types and standards. Device-to-Device (D2D) requires a fast, intelligent, and reliable handover (HO) decision system to deliver seamless mobility and ongoing service. With the exponential growth of Internet of Things (IoT) devices, D2D communication, augmented reality (AR), virtual reality (VR), and other technologies, efficiently managing the handover process which is critical to ensuring low latency, high data rates, and huge connectivity. The study investigates advanced methods such as machine learning (ML), long short-term memory (LSTM) model, and deep learning (DL) for improving handover management and reducing service disruptions. This paper is in accordance with sustainable development goals (SDGs), Goal 9: specifically, industry, innovation, and infrastructure, by linking the generations inside the network using creative HO techniques. Through improving digital infrastructure, encouraging innovation, and guaranteeing fair access to high-quality, reliable, and robust communication networks, the results seek to advance sustainable manufacturing. This in-depth examination of handover management for 5G, 6G, and beyond offers a thorough study that researchers, policymakers, and network operators working toward a sustainable digital future will find invaluable.},
  archive      = {J_SUPERC},
  author       = {Topazal, S M and Islam, Shayla and Kolandaisamy, Raenu A./L. and Hasan, Mohammad Kamrul and Ismail, Ahmad Fadzil and Sabrina Suhaimi, Nur Hanis and Abbas, Huda Saleh and Khan, Muhammad Attique and Alezabi, Kamal Ali},
  doi          = {10.1007/s11227-025-07182-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Intelligent device to device handover management techniques for 5G/6G and beyond},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain-based framework with cryptographic tags for healthcare security. <em>SUPERC</em>, <em>81</em>(5), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07183-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access control in healthcare is essential for ensuring secure and privacy-preserving data management, yet traditional centralized approaches are vulnerable to security breaches and inefficiencies. Blockchain-based access control offers a decentralized and transparent alternative; however, existing solutions suffer from high execution time, excessive gas consumption, and limited scalability. To address these limitations, this work proposes a Tag-Based Access Control (TBAC) framework using blockchain, where a tag score is dynamically computed for entities based on predefined attributes, and access is granted accordingly. This method enhances granularity and flexibility in access control while maintaining the immutability and security of blockchain. Experimental results demonstrate that the proposed system reduces execution time by 20.9%, lowers gas consumption by 13.8%, and improves scalability by 25%, making it a highly efficient solution for secure healthcare data management. The security analysis demonstrates the resilience of TBAC in healthcare 4.0 against various Sybil attacks, 51 % attacks, and Denial of Service (DoS) attacks through the proposed tag score.},
  archive      = {J_SUPERC},
  author       = {Kumar, Ashish and Chatterjee, Kakali},
  doi          = {10.1007/s11227-025-07183-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {A blockchain-based framework with cryptographic tags for healthcare security},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVGwfa: A multi-level parallel sequence-to-graph alignment algorithm. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07184-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pangenome graph represents the genomes of multiple individuals, offering a comprehensive reference and overcoming allele bias from linear reference genomes. Sequence-to-graph alignment, crucial for pangenome tasks, aligns sequences to a graph to find the best matches. However, existing algorithms struggle with large-scale sequences. In this paper, we propose PVGwfa, a multi-level parallel sequence-to-graph alignment algorithm. We first employ MPI and Pthread for multi-process and multi-thread parallelization. Next, we introduce a hybrid load balancing strategy for better performance. Additionally, we vectorize the core of PVGwfa using SIMD instructions to accelerate sequence alignment. Experiments on real and simulated datasets show that PVGwfa reduces computation time from nearly an hour to a few minutes. For large datasets, PVGwfa achieved speedups ranging from 1.98 $$\times$$ to 100.44 $$\times$$ as the number of processes increased from 2 to 128, while maintaining consistent alignment results. The PVGwfa tool and source code are publicly available at https://github.com/nudt-bioinfo/PVGwfa.git .},
  archive      = {J_SUPERC},
  author       = {Peng, Chenchen and Xia, Zeyu and Tang, Shengbo and Guo, Yifei and Yang, Canqun and Tang, Tao and Cui, Yingbo},
  doi          = {10.1007/s11227-025-07184-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {PVGwfa: A multi-level parallel sequence-to-graph alignment algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart contract generation model based on code annotation and AST-LSTM tuning. <em>SUPERC</em>, <em>81</em>(5), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07186-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of smart contracts in many fields, the number, types, and complexity of smart contracts are showing a rapidly increasing trend. However, the development of smart contracts has its own unique programming language and security requirements, which are difficult for conventional software personnel to adapt quickly, and how to realize the efficient development of smart contracts according to the application requirements is an important issue that needs to be solved for its further development. The author proposes a smart contract generation method based on abstract syntax tree (AST) long short-term memory (LSTM) characterization and code annotation tuning large language model, which adopts the AST-LSTM model combining abstract syntax tree and tree-long short-term memory(Tree-LSTM) to vectorize the code as well as Sentence-BERT to vectorize the annotations and carry out a weighted analysis, and constructs a smart contract clustering analysis model to achieve accurate clustering of functionally similar smart contracts. Then, the AST-LSTM+Transformer model is used to detect defects in the clustered code and correlate the related annotation information to construct a diverse prompt feature prompt statement dataset. Finally, the Llama2-7B model is used as the basis for demand-specific smart contract generation with the help of Lora and P-Tuning v2 fine-tuning techniques. In this paper, we conducted comparative experiments with existing methods with the help of BLEU, an auxiliary tool for the quality assessment of bilingual translation, and Mythril, VaaS, and other code security detection tools. The results of the experiment show that the average value of BLEU of the code generated by this paper’s method is improved by about 25%, and the code security is improved by about 9%, which will greatly promote the rapid development and exploitation of smart contracts with high-security requirements.},
  archive      = {J_SUPERC},
  author       = {Yong, Chen and Defeng, Hu and Chao, Xu and Nannan, Chen and Jianbo, Liu},
  doi          = {10.1007/s11227-025-07186-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Smart contract generation model based on code annotation and AST-LSTM tuning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved YOLO-based method with lightweight c3 modules for object detection in resource-constrained environments. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07187-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of deep learning algorithms, object detectors have achieved impressive performance in practical applications. An efficient detection framework is essential for performing detection tasks on devices with limited computational resources. However, current detection algorithms often face challenges due to their complexity, including numerous parameters and significant computational demands. To overcome these challenges, this paper introduces a streamlined and effective detection method. The integration of the FasterNet Block into the Cross-Stage Partial Network (C3) of the backbone reduces computational and storage demands. Additionally, by introducing cross-scale feature fusion in the neck network, the computational load and parameter requirements during inference are further decreased. Meanwhile, the dynamic head with multi-scale processing and Shape-IoU enhances detection accuracy and robustness, achieving a balance between lightweight design and performance. Compared to the original YOLOv5 models, the proposed lightweight method reduces the number of parameters by 29.4 to 43.0 $$\%$$ and compresses the size of the model by 31.6 to 42.7 $$\%$$ while maintaining a high mAP@0.5. Furthermore, the designed models achieve a faster inference speed since the computations could be reduced by more than 30 $$\%$$ . In robustness experiments under varying lighting conditions, the proposed model demonstrates stable detection performance even in challenging lighting scenarios, showing its reliability in real-world applications. In conclusion, our research offers considerable improvements in model accuracy, parameter efficiency, and size compared to the mainstream object detection algorithms.},
  archive      = {J_SUPERC},
  author       = {Song, Jian and Xie, Jie and Wang, Qingwang and Shen, Tao},
  doi          = {10.1007/s11227-025-07187-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {An improved YOLO-based method with lightweight c3 modules for object detection in resource-constrained environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel optimization of monte carlo neutron transport method based on sunway bluelight II supercomputer. <em>SUPERC</em>, <em>81</em>(5), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07190-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance computing is crucial for complex nuclear energy simulations, and the Monte Carlo method is one of the most precise methods among them. Based on the Sunway Bluelight II supercomputer, the general heterogeneous two-level parallel optimization method is proposed for the open-source Monte Carlo neutron transport code (OpenMC). Thread-level parallel optimization includes direct parallel optimization, computational data optimization and load balancing optimization. In process-level optimization, a communication optimization method suitable for Sunway chip hardware architecture is proposed. Subsequently, comprehensive tests are conducted on two different test models, B&W 1484 Core 1 and BEAVRS, using different data scales. Results demonstrate significant performance improvements: the optimized code achieves sustained floating-point performance up to 5.34 TFLOPS. Within a single-core group, neutron transport simulations of the B&W 1484 Core 1 model and the BEAVRS model achieve speedups of 25.12 and 20.29 times, respectively. Particularly, when the two-level parallel optimization program is expanded to 2048 processes (2048 MPE + 131,072 CPE), the strong scalability of the B&W 1484 Core 1 model reaches 82.68%. When executing the BEAVRS benchmark problem, the weak scalability is nearly linear. Moreover, when using 2048 processes to execute computational tasks of the same scale, the two-level parallel optimization program of the Sunway Bluelight II supercomputer takes a similar amount of time as the standard MPI + OpenMP parallel program of the Shanhe supercomputer. Our work not only improves the efficiency of neutron transport simulations, but also provides reference value for other parallel optimization research on the Sunway supercomputer.},
  archive      = {J_SUPERC},
  author       = {Zhang, Zhongliang and Liu, Tao and Wang, Chengzhi and Guo, Ying and Pan, Jingshan and Zhao, Dawei and Wu, Xiaoming and Yang, Meihong},
  doi          = {10.1007/s11227-025-07190-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Parallel optimization of monte carlo neutron transport method based on sunway bluelight II supercomputer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DYR-SLAM: Enhanced dynamic visual SLAM with YOLOv8 and RTAB-map. <em>SUPERC</em>, <em>81</em>(5), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07191-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes Dynamic YOLOv8-RTAB-Map SLAM (DYR-SLAM), an enhanced dynamic visual SLAM algorithm that leverages YOLOv8 and RTAB-Map to address the challenges of inaccurate mask coverage and small pixel region omission in existing deep learning-based visual SLAM systems. DYR-SLAM employs YOLOv8 to obtain semantic information and an initial mask, which is subsequently corrected using multi-frame depth information to ensure mask coverage consistency with dynamic objects. By integrating multi-frame point cloud and depth information in RTAB-Map, the mask accuracy is optimized, retaining more static information, while eliminating dynamic objects. Furthermore, an acceleration constraint model predicts dynamic object trajectories to ensure robustness in complex motion and occlusion scenarios. Adaptive culling weights and multi-frame consistency detection improve point cloud culling accuracy when RTAB-Map is combined with YOLOv8. Evaluated on the TUM RGB-D dataset, DYR-SLAM demonstrates higher localization accuracy and better dense point cloud mapping in dynamic scenes compared to advanced SLAM systems like RTAB-MAP, DS-SLAM, and DynaSLAM.},
  archive      = {J_SUPERC},
  author       = {Li, Cun and Jiang, Shuhai and Zhou, Kangqian},
  doi          = {10.1007/s11227-025-07191-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {DYR-SLAM: Enhanced dynamic visual SLAM with YOLOv8 and RTAB-map},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative task allocation for heterogeneous UAV coalitions with resource requirements based on multi-genotype genetic algorithm. <em>SUPERC</em>, <em>81</em>(5), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07193-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the task allocation problem for heterogeneous unmanned aerial vehicle (UAV) coalitions in coordinated attacks against dynamic targets. The primary objectives are to minimize task completion time and maximize coalition effectiveness. To create a more realistic mission scenario, multiple constraints, such as resource requirement and task time, are considered. First, a novel UAV coalition model based on resource requirement constraints is proposed, and the coalition optimization problem is formulated as a non-convex mixed integer quadratic programming model to rationally allocate resources, reduce task time, and enhance UAV cooperation. Then, a multi-genotype genetic algorithm (MGGA) with customized crossover and mutation operators is proposed. It ensures that the aforementioned constraints are satisfied, and efficient task allocation is achieved. This algorithm features a specialized coding strategy to prevent the occurrence of a chromosome deadlock condition caused by sub-coalition coupling, in which several UAVs become stuck in an infinite waiting state. Simulation results demonstrate that the MGGA effectively optimizes task allocation for heterogeneous UAV coalitions while maintaining overall coalition performance. Monte Carlo experiments confirm the superior performance of our approach compared to conventional methods.},
  archive      = {J_SUPERC},
  author       = {Zhang, Xiaoyong and Yue, Wei},
  doi          = {10.1007/s11227-025-07193-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Collaborative task allocation for heterogeneous UAV coalitions with resource requirements based on multi-genotype genetic algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VBATS: An adaptive strategy for grouped GEMM on GPUs. <em>SUPERC</em>, <em>81</em>(5), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07195-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General matrix multiplication (GEMM) is a crucial operation in various fields, such as deep learning, scientific computing, and image processing. In many real-world applications, particularly in deep learning, matrices are often too small and have a variety of matrix sizes to make full use of GPUs. To address this issue, the vbatch method and grouped GEMM have been proposed in previous studies and libraries, both designed to process a set of small, independent GEMMs using a single CUDA kernel. However, the strategy selection in vbatch GEMM is typically rudimentary, and grouped GEMM lacks support for configurable tile sizes, limiting its flexibility. In this work, we discuss the limitations of previous work related to the vbatch method and propose a framework named VBATS, an adaptive vbatch tiling and splitting algorithm for grouped GEMM. VBATS introduces a unified tile method to reduce redundant thread blocks, along with a two-stage strategy selection algorithm that includes a tiling stage and a splitting stage to accelerate vbatch GEMM on GPUs. The experimental results based on synthetic grouped GEMM on an NVIDIA A100 GPU demonstrate that VBATS achieves an average performance gain of approximately 2.01x over cuBLAS grouped GEMM (up to 8.96x). We also performed experiments on various GPU architectures, demonstrating that our proposed method achieves consistent performance improvements across different platforms. Furthermore, using Google-Net as a real-world case study, VBATS can achieve a speed up of 2.72x.},
  archive      = {J_SUPERC},
  author       = {Shang, Jiandong and Wen, Zhuxin and Hua, Haobo and Guo, Hengliang and Wu, Gang and Fan, Wenlong and Guo, Yang and Qin, Guangsheng},
  doi          = {10.1007/s11227-025-07195-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {VBATS: An adaptive strategy for grouped GEMM on GPUs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep-reinforcement-learning-based strategy selection approach for fault-tolerant offloading of delay-sensitive tasks in vehicular edge-cloud computing. <em>SUPERC</em>, <em>81</em>(5), 1--37. (<a href='https://doi.org/10.1007/s11227-025-07196-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the high resource demands of delay-sensitive tasks in vehicular networks, task offloading techniques have become prevalent in Mobile Edge-Cloud Computing (MECC) systems to reduce task completion times. Numerous studies have explored and addressed the task offloading problem in dynamic and unpredictable MECC environments using various Deep Reinforcement Learning (DRL) approaches. However, the critical issue of fault-tolerant (FT) task offloading in vehicular networks has not been comprehensively addressed. Failures of offloaded tasks to MECC nodes can significantly impact the quality of service in vehicular networks and potentially lead to catastrophic outcomes in critical vehicular tasks. To address this challenge, this paper proposes a DRL-based FT task offloading method for MECC environments to minimize the average response time and latency of all tasks under faulty conditions. An analytical model of the optimization problem is developed, followed by a Deep Deterministic Policy Gradient (DDPG) algorithm to determine the optimal deployment and recovery patterns for delay-sensitive tasks. The actor-critic architecture of DDPG, where the actor determines the task execution plans (including primary/backup nodes and the optimal recovery strategy) based on the current state, and the critic evaluates the decision, allows DDPG to adapt more smoothly to dynamic, continuous environments like vehicular networks, where the system’s state, available resources, and failure rates are constantly changing. Our results show that by implementing diverse failure recovery strategies in high failure environments, our proposed method can reduce the total task completion time and the number of failures by an average of 29% and 78%, respectively, compared to baseline methods. Furthermore, the method’s adaptability to changes in available computational resources and varying failure rates is clearly demonstrated.},
  archive      = {J_SUPERC},
  author       = {Babaiyan, Vahide and Bushehrian, Omid},
  doi          = {10.1007/s11227-025-07196-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {A deep-reinforcement-learning-based strategy selection approach for fault-tolerant offloading of delay-sensitive tasks in vehicular edge-cloud computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hilbert similarity convex for efficient EEG feature selections. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07199-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work describes a novel feature selection approach for detecting epileptic seizures in an EEG dataset that is based on a Hilbert similarity measurement of a convex set. Because the medical dataset has a high dimensionality, feature selection is vital for identifying diseases early and protecting human health. Moreover, high-dimensional data affect the prediction accuracy of machine learning algorithms and increase the system's complexity, making the results inefficient. Therefore, 1: This research presents a feature selection model mainly based on 2: Hilbert mathematical similarity measurement for computing similarity and related features based on high harmony inside the same feature. Using the proposed model, 3: The similarity between signals is computed and optimal, and 4: High similarity features are selected, while 5: Ineffective features are removed. Using the EEG data from Bonn University, we assessed the performance of the system. In addition, we assessed the proposed model based on recall, precision, and accuracy, which was compared to other earlier methods. Research findings confirmed that it was effective at extracting optimum features from EEG data. The proposed model obtained 100% accuracy within 10% of the feature selection.},
  archive      = {J_SUPERC},
  author       = {Baawi, Salwa Shakir and Hakem, Ekram and Al-Hamzawi, Abdulkareem A. and Al-Shammary, Dhiah and Ibaida, Ayman and Mahdi, Ahmed M.},
  doi          = {10.1007/s11227-025-07199-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Hilbert similarity convex for efficient EEG feature selections},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-frequency dual-domain attention for acoustic echo cancellation. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07200-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing acoustic echo cancellation (AEC) technologies primarily focus on time-domain analysis, aiming to eliminate echo by modeling the long-range correlations of speech signals. However, these methods are limited in their ability to capture the dynamic variations in the frequency components of speech signals, thereby overlooking the significance of frequency-domain information. This paper proposes an energy distribution analysis method based on time-frequency (T-F) representation to address this issue. Introducing a dual-domain attention module (DDAM), which independently computes the local importance weights in both the frequency and time domains and multiplies these weights with the input features, accurately captures the most important time-frequency features of speech signals. In addition, the dual-domain feature enhancement block (DDFEB), which combines DDAM and convolutional layers, further enhances the multilevel representation of input features and integrates them into the encoder–decoder framework, effectively improving the representation of the time-frequency features. Experimental results show that the proposed method improves the perceptual evaluation of speech quality (PESQ) by 17.65% compared to the existing F-T-LSTM method and achieves a short-time objective intelligibility (STOI) score of 0.93. Furthermore, the proposed method increases the mean opinion score (MOS) by 0.33 compared to the existing DTLN-aec method, demonstrating its superiority in enhancing the user experience.},
  archive      = {J_SUPERC},
  author       = {Huang, Yibo and Qin, Weidong and Li, Zhiyong and Zhang, Qiuyu},
  doi          = {10.1007/s11227-025-07200-2},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Time-frequency dual-domain attention for acoustic echo cancellation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stream information complementarity network for RGB-D camouflaged object detection. <em>SUPERC</em>, <em>81</em>(5), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07201-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflage object detection (COD) aims to identify objects hidden in natural scenes. Due to the imperceptible differences between disguised objects and their surrounding environment, accurately detecting disgusted objects is extremely challenging. To overcome this challenge, introducing depth map has become an important breakthrough in that it can provide valuable spatial clues for COD tasks. In this paper, we propose a multi-stream information complementarity network (MICNet) for camouflage object detection, comprehensively exploiting complementary useful information from depth and RGB images to boost the accuracy of detection. The MICNet adopts an encoding-fusion-decoding structure and utilizes a two-stream pyramid visual transformer as backbone to extract multi-level features from input images. In advance, coarse depth map is generated by a frozen depth estimation model for the given RGB image. We first propose a cross-modal attention enhancement module that adaptively integrates RGB features and depth features based on attention mechanisms. Then, we introduce a simple and effective positioning guidance generation module, which generates coarse positioning maps to provide localization guidance for subsequent decoding processes. Finally, we design a multi-stream information aggregation unit, which takes richer intermediate information into account to preserve spatial detail of targets. Extensive experimental results on four COD datasets indicate that our network achieves superior performance in four common metrics compared to 14 state-of-the-art COD methods, while also performing well in salient object detection tasks.},
  archive      = {J_SUPERC},
  author       = {Ying, Chenghao and Zhou, Zhiping and Li, Kewei and Zhang, Zhaozhong and Yang, Qingshuang},
  doi          = {10.1007/s11227-025-07201-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Multi-stream information complementarity network for RGB-D camouflaged object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation via causal-contrastive learning. <em>SUPERC</em>, <em>81</em>(5), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07202-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to reduce the domain differences between source and target domains by mapping their data to a shared feature space, thereby learning domain-invariant features. The aim of this study is to address the challenges faced by contrastive learning-based UDA methods when dealing with domain discrepancies, particularly the spurious correlations introduced by confounding factors caused by data augmentation. In recent years, contrastive learning has gained attention for its powerful representation learning capabilities, as it can pull similar samples from the source and target domains closer together while separating different classes of negative samples. This process helps alleviate domain differences and enhances the model’s generalization ability. However, mainstream UDA methods based on contrastive learning often introduce confounding factors due to the randomness of data augmentation, leading the model to learn incorrect spurious associations, especially when the target domain contains counterfactual data from the source domain. As the amount of counterfactual data increases, this bias and accuracy loss can significantly exacerbate and are difficult to eliminate through non-causal methods. To address this, this paper proposes causal invariance contrastive adaptation (CICA), a causal-contrastive learning-based unsupervised domain adaptation model for image classification. The model inputs labeled source domain samples and unlabeled target domain samples into a feature generator after data augmentation, and quantifies the degree of confusion between the generated features based on a backdoor criterion. We effectively separate domain-invariant features from spurious features using adversarial training, thereby reducing the interference of confounding factors on the domain adaptation task. Our experiments conducted on four domain adaptation image classification benchmark datasets and one counterfactual dataset show that the model achieves a significant improvement in average classification accuracy compared to state-of-the-art methods on the benchmark datasets, while still maintaining advanced performance on the counterfactual dataset.},
  archive      = {J_SUPERC},
  author       = {Wei, Xing and Jiang, Wenhao and Yang, Fan and Zhao, Chong and Lu, Yang and Zhang, Benhong and Bi, Xiang},
  doi          = {10.1007/s11227-025-07202-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Unsupervised domain adaptation via causal-contrastive learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A common and efficient algorithm for discovering high utility co-location patterns and their concise representation from massive spatial data. <em>SUPERC</em>, <em>81</em>(5), 1--40. (<a href='https://doi.org/10.1007/s11227-025-07203-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From spatial data sets, identifying groups of spatial features whose utility participation index (UPI) values are larger than a user-specified utility threshold is called high utility co-location pattern (HUCP) mining that can reveal valuable information and has been applied in many fields. Since UPI does not hold the downward closure property, almost current mining HUCP algorithms design some pruning strategies to remove unnecessary candidates in advance to improve mining performance. However, these algorithms are still powerless when dealing with large and dense data. Moreover, to avoid missing interesting HUCPs, the utility threshold should be set as small as possible. Unfortunately, this setting leads to many HUCPs generated that disturb users’ understanding and requires expensive execution resources. To address these, first, a top-down HUCP mining framework is proposed. Neighboring instances are divided into maximal cliques (MCs), and then, these MCs are organized in a compact hash table structure. The longest keys in the structure correspond to the longest candidates, and the mining process starts with these candidates and performs in a top-down search style. Second, a concise representation, $$\epsilon$$ -closed HUCPs, is proposed that can effectively compress similar patterns. Finally, comprehensive experiments on diverse data show that the proposed method is effective and efficient.},
  archive      = {J_SUPERC},
  author       = {Bui, Thiloan and Tran, Vanha and Do, Thaigiang and Le, Hoangan and Ngo, Truongminh},
  doi          = {10.1007/s11227-025-07203-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {A common and efficient algorithm for discovering high utility co-location patterns and their concise representation from massive spatial data},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference and training acceleration of deep learning partial differential equation solver. <em>SUPERC</em>, <em>81</em>(5), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07204-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution of partial differential equations plays a crucial role in research across many scientific fields. Physics-informed DeepONet (PI-DeepONet) is an advanced deep learning model for solving partial differential equations. This paper focuses on PI-DeepONet and performs multilevel optimization to improve its inference and training speeds. We have customized the single-precision matrix multiplication (SGEMM, C = alpha * $$A \cdot B$$ + beta * bias) kernels, within the commonly used model size range of PI-DeepONet, our customized SGEMM kernels achieves 1.1–1.5 times the acceleration compared to the best single-precision matrix multiplication in cuBLAS. Additionally, we designed fusion kernels (integrating multiple computations into one GPU kernel to improve computational efficiency) specifically for the unique structure of the modified MLP used in PI-DeepONet, resulting in 1.7–2.3 times acceleration in the model’s end-to-end inference (includes data transfer from memory to global memory) speed, with GPU computation time being reduced by 3.0–5.7 times. Finally, we employed data parallelism (divide data into multiple subsets and process them in parallel on multiple GPUs) for distributed training of the model and used communication masking strategies, maintaining scalability at 83–85%.},
  archive      = {J_SUPERC},
  author       = {Wang, Xun and Zhu, Xianxi and Meng, Xiangyu and Zhu, Zeyang and Zhang, Siyu and Song, Tao},
  doi          = {10.1007/s11227-025-07204-y},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Inference and training acceleration of deep learning partial differential equation solver},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-CE: An underwater low-visibility environment target detection algorithm based on YOLO11. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07205-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In challenging underwater environments with limited visibility due to poor lighting and murky water, the ability to detect and identify targets is essential for various marine operations. We present an improved YOLO11 network, called YOLO-CE, to increase the accuracy of underwater target recognition under such circumstances. First, we propose a new convolutional module (CRAConv) that integrates coordinate attention (CA) and receptive field attention (RFA) into the backbone network. Secondly, we propose an edge spatial fusion module (ESFM) and integrate it into C3k2 to naturally form C3k2-ESFM, which learns different image features more deeply. Then, content-guided attention (CGA) is embedded into the feature pyramid network (FPN) to constrain the consistency of feature fusion across the backbone and neck. To improve the precision and stability of target localization, we do not use the traditional CIoU but Wise-IoU v3. On the UTDAC2020 and URPC2021 datasets, the YOLO-CE algorithm achieves mAP50 scores of 85% and 82.7%, respectively. Our approach performs excellently in enhancing small targets and general detection precision compared to mainstream object detection algorithms. The source code of our YOLO-CE will be made available at https://github.com/lanfafa/YOLO-CE .},
  archive      = {J_SUPERC},
  author       = {Chen, Ruolan and Zhou, Huibo and Xie, Hui and Wang, Bingyang},
  doi          = {10.1007/s11227-025-07205-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {YOLO-CE: An underwater low-visibility environment target detection algorithm based on YOLO11},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive scheduling framework of streaming applications based on performance-to-cost ratio in heterogeneous cloud environment. <em>SUPERC</em>, <em>81</em>(5), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07207-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapidly growing demand for real-time processing of large amounts of stream data, the global deployment of cloud infrastructure for stream processing has brought tremendous economic benefits to cloud service providers, yet large-scale stream processing continues to increase resource cost consumption. In stream processing, the trade-off between performance and cost for workflows scheduling at lower resource cost remains to be explored. In this paper, a deployment method of streaming applications is proposed to maximize the performance-to-cost ratio in Storm, and a communication traffic optimization method for inter-node communication based on graph partitioning is proposed to reduce resource cost. First, we propose a cost-efficient model based on performance-to-cost ratio and a Storm-based performance-to-cost ratio maximization deployment algorithm PC-Storm. The PC-Storm first detects and collects task node information in the heterogeneous cluster. Then, it calculates the performance-to-cost ratio of the nodes and builds a performance-to-cost ratio table. Finally, the Storm task threads are assigned to nodes with the high performance-to-cost ratio. In addition, a maxSubtopology algorithm is also proposed to optimize the communication traffic between Storm nodes based on graph partitioning. The maxSubtopology algorithm assigns the tasks with heavy communication traffic to the same node under the premise of satisfying the performance constraint. Compared with the existing algorithms, the PC-Storm improves the resource performance-to-cost ratio by 40.92%, and the maxSubtopology algorithm reduces the communication cost by 42.8%. The proposed method can maximize performance-to-cost ratio and reduce the communication cost effectively for deployment of streaming applications.},
  archive      = {J_SUPERC},
  author       = {Li, Hongjian and Tan, Gangfan and Wang, Chenzi and Gao, Yuan and Zhou, Tao and Duan, Xiaolin},
  doi          = {10.1007/s11227-025-07207-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Adaptive scheduling framework of streaming applications based on performance-to-cost ratio in heterogeneous cloud environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnable semantic completion and distance-induced graph matching for domain adaptive object detection. <em>SUPERC</em>, <em>81</em>(5), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07208-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive object detection aims to transfer an object detection model trained on a source domain to a target domain without annotated data. The typical work in recent years has performed pixel-level adaptation based on graphs by completing domain mismatch semantics. They alleviated the problem of decreased performance of object detection models caused by domain shift to some extent. However, significant distribution differences between domains were neglected when generating the illusory nodes. Moreover, they assigned inappropriate weights between class nodes when constructing the graph, resulting in suboptimal adaptation. We propose a framework for learnable semantic completion and distance-induced graph matching to resolve the above problems. Specifically, we design a missing classes illusory nodes generation module based on deep neural networks. This module leverages node information storage centers to store node representations of existing classes. Based on stored nodes, deep neural networks are utilized to generate illusory nodes for missing classes. This can complete the domain data of missing classes and optimize the domain adaptation training process. In addition, this module employs a replicating–perturbation–sampling strategy to address the issue of supply–requirement inconsistency of nodes within deep neural networks. Furthermore, we propose a distance-induced sampling node graph structure construction module. By utilizing Euclidean distance between nodes and applying a Gaussian kernel, we construct a more accurate and realistic sampling node graph structure. This can better perceive the connections between classes, achieving fine-grained adaptation guided by graph matching. Extensive experiments conducted on three different domain adaptation scenarios validate that our approach outperforms existing methods significantly.},
  archive      = {J_SUPERC},
  author       = {Xu, Zhijie and Qiu, Yuanyuan and Zhang, Jianqin},
  doi          = {10.1007/s11227-025-07208-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Learnable semantic completion and distance-induced graph matching for domain adaptive object detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved qARM algorithm for frequent itemsets search in large-scale data sets. <em>SUPERC</em>, <em>81</em>(5), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07209-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum algorithm for association rules mining (qARM) has a significant limitation: the need for artificial setting of the quantum oracle of data when mining frequent itemsets. This becomes extremely time-consuming when dealing with large-scale data. To overcome this limitation, this study proposes an improved method based on the $$C^{n} -X$$ gate and the extended Grover algorithm (less than oracle). We abandon the original quantum phase estimation algorithm in the process of calculating the support degree and instead use a combined gate based on the $$C^{n} -X$$ gate. This is because its linear time complexity is more efficient than the polynomial time complexity of the quantum estimation algorithm. Furthermore, we modify the extended Grover algorithm to screen the support degree. Our method is validated using IBM’s Qiskit tool for simulation experiments. We test on data sets with sizes of $$2\times 2$$ and $$4\times 4$$ , and fragments 29-32 items of data for the dataset Market Basket Optimization. The results demonstrate that, with our method, when dealing with large-scale data sets, there is no longer a need to prepare quantum oracle for all data in advance. In the valid data, its search accuracy can reach above 90 $$\%$$ at the highest. This suggests that our improved method enhances the efficiency and accuracy of quantum association rules mining.},
  archive      = {J_SUPERC},
  author       = {Qi, Han and Wang, Liyuan and Fu, Dianshuo and Gani, Abdullah and Gong, Changqing},
  doi          = {10.1007/s11227-025-07209-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {Improved qARM algorithm for frequent itemsets search in large-scale data sets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key technologies for task processing in ternary optical computer. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07210-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a key technology for task processing in ternary optical computer (TOC)—the operation-data file (SZG file). Firstly, we analyze and summarize the data processing advantages of ternary optical computer. Then, we propose the design principles of SZG file and provide a detailed explanation of the significant role played by SZG file in the task processing process. Furthermore, we will discuss how to construct a collaborative task processing mechanism based on SZG file, focusing on the format of SZG file and the task classification strategy based on SZG file. Finally, we will conduct experimental testing on the ternary optical computer platform using a specific example. Tasks can be executed correctly in parallel on ternary optical computer, successfully coordinating the differences in task processing characteristics between electronic computers and ternary optical computer. These will establish a bridge for collaborative work between electronic computers and ternary optical computers, while also providing new ideas for other emerging computing systems in terms of task processing methods.},
  archive      = {J_SUPERC},
  author       = {Li, Shuang and Yang, Wen and Li, Luqun and Li, Wenjing and Li, Dazhi and Wang, Zhehe},
  doi          = {10.1007/s11227-025-07210-0},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Key technologies for task processing in ternary optical computer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ellipse detection and positioning in complex vision measurement environments. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07213-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ellipses are often widely used as a visual positioning marker. Occluded ellipses in complex backgrounds are difficult to detect and locate accurately. Traditional ellipse detection methods are prone to missed detection and large edge positioning deviations. This greatly affects the accuracy of subsequent algorithms. A single-stage anchor-free ellipse detector is proposed in this paper, which achieves fast and high-precision detection and positioning of ellipses in complex occluded environments. According to the special shape of the ellipse, the attention mechanism is introduced to help the model more accurately locate the area containing the ellipse and pay more attention to useful channel information. Secondly, dynamic upsampling and variable convolution are used to design the decoder of the model to improve the positioning accuracy of the ellipse. Gauss–Wasserstein is used for IoU loss, and the center point deviation loss is modified to optimize the ellipse regression accuracy. Combined with real measurement applications, this paper builds an ellipsoidal sphere dataset for large-scale spatial camera calibration. Experiments on self-built datasets and public datasets show that the performance of the proposed method is better than the state-of-the-art model.},
  archive      = {J_SUPERC},
  author       = {Song, Jin and Zeng, Bowei and Ma, Jun},
  doi          = {10.1007/s11227-025-07213-x},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Ellipse detection and positioning in complex vision measurement environments},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCLMD: Dynamic clustering and label mapping distribution for constructing in-context learning demonstrations. <em>SUPERC</em>, <em>81</em>(5), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07214-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-Context Learning refers to the ability of large language models to understand and generate appropriate responses based on the provided demonstration without requiring explicit retraining, which is closely related to the quality of the demonstration. Existing methods typically use traditional selection algorithm for demonstration construction, which fails to fully exploit the In-Context Learning ability of large language models. This paper adopts Dynamic Clustering and Label Mapping Distribution (DCLMD) to enhance the In-Context Learning ability of large language models. Our approach first dynamically selects relevant samples based on the distribution of the target sample in the sample space and introduces a hierarchical clustering filtering method to achieve diversified sample selection within different semantic clusters. Next, we design a ranking selection method based on loss functions to evaluate the demonstration’s ability to learn correct mapping relationships in label spaces, and the final demonstration is selected through a ranking strategy. Experimental results on seven different datasets across various tasks, such as natural language inference, show that our method improves the accuracy of two large language models by up to 3.2% and 8.9%, respectively.},
  archive      = {J_SUPERC},
  author       = {Du, Yongping and Zhang, Qi and Fu, Shuyi and Hou, Ying and Han, Honggui},
  doi          = {10.1007/s11227-025-07214-w},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {DCLMD: Dynamic clustering and label mapping distribution for constructing in-context learning demonstrations},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topic mining and forecasting on patent map for GPU technology. <em>SUPERC</em>, <em>81</em>(5), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07215-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, applications in fields of commercial computing, scientific computing and artificial intelligence have been booming. Compared with traditional computing platforms, GPUs have advantages for data centers such as high concurrent processing capacity and high bandwidth transmission efficiency. It can significantly improve system performance and has received widespread attention. However, GPUs also face unprecedented challenges in high-performance computing, architectural innovation, energy efficiency and thermal optimization. To accelerate the process of GPU performance improvement, it is very important to carry out patent analysis, evolution path research and development trend prediction of GPU technology. Firstly, this paper provides an in-depth analysis of the development status of GPU technology based on patent maps. Secondly, the BERTopic model is used to cluster the patent technology topics to obtain four technology topics in the field of GPU technology. Finally, Logistic model is used to analyze and predict the technology life cycle of the identified technology themes. The results show that from 2005 to 2023, the number of GPU patent applications generally shows an upward trend, experiencing three stages of slow growth, rapid growth and relatively stable fluctuation. The scope of GPU technology applications covers a wide range of fields from high-end gaming and professional graphic design to artificial intelligence and cloud computing. The four technology themes obtained through BERTopic model clustering analysis are: graphics processing and GPU foundation, CPU and GPU collaborative computing, GPU hardware design and optimization, and GPU comprehensive application and cross-fertilization. The initial three themes were analyzed and predicted in terms of the technology life cycle. It is anticipated that within the forthcoming years, these themes will attain maturity or decline, correspondingly, and technological innovation activities will persist.},
  archive      = {J_SUPERC},
  author       = {Hou, Ke and Wu, Mengying and Wu, Wenjun and Huang, Linhao},
  doi          = {10.1007/s11227-025-07215-9},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Topic mining and forecasting on patent map for GPU technology},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An elastic reconfiguration strategy for operators in distributed stream computing systems. <em>SUPERC</em>, <em>81</em>(5), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07216-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low latency and high throughput are crucial for distributed stream computing systems. Existing operator reconfiguration strategies often have poor performance under resource-limited and latency-constraint scenarios. The challenge lies in the elasticity of operator parallelism and reconfiguration of operators that balances performance constraints and performance improvement. To address these issues, we propose Er-Stream, an elastic reconfiguration strategy for various application scenarios. This paper discusses the Er-Stream from the following aspects: (1) We model task topology as a queuing network to evaluate system latency, and construct a communication cost model to formalize the reconfiguration problem; (2) we proposed an elastic strategy for operator parallelism to rationally utilize the available resources and reduce the processing latency of topology; (3) we proposed a reconfiguration strategy for operators to reduce the communication cost, and set thresholds added to control its trigger frequency; (4) we design and implement Er-Stream and integrated it into Apache Storm. We evaluate key metrics such as latency, throughput, resource usage, and CPU utilization in a real-world distributed stream computing environment. Results demonstrate significant improvements achieved by Er-Stream. In comparison with Storm’s existing strategies, it reduces average system latency by up to 30%, increases average system throughput by 1.89 times, lowers average resource usage by 26.6%, and increases CPU utilization by 19.8%.},
  archive      = {J_SUPERC},
  author       = {Sun, Dawei and Fan, Yinuo and Guan, Chengjun and Rong, Jia and Gao, Shang and Buyya, Rajkumar},
  doi          = {10.1007/s11227-025-07216-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {An elastic reconfiguration strategy for operators in distributed stream computing systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cluster-based solution for service function chain allocation in large-scale infrastructure. <em>SUPERC</em>, <em>81</em>(5), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07218-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changes in telecommunication services demand the development of a new infrastructure to attend new network applications’ requirements. The traditional approach to network functions running over dedicated equipment can no longer handle all the dynamics of these new services. The network function virtualization (NFV) paradigm decouples a function from the underlying dedicated hardware thus making networks more flexible and agile. A set of virtual network functions (VNFs) can be deployed as virtual machines or containers across common servers, and orchestrated to compose a service function chain (SFC). Despite the many benefits of NFV, it raises several challenges. SFC placement is a complex task, since it requires taking into consideration the characteristics of VNFs, the SFC requirements, and the state of network infrastructure. This poses a challenge for large-scale networks. Information regarding network resources are stored in a large database, and retrieving such data in order to perform SFC placement according to some strategy can be a problem. Limited memory capacity and the presence of a large number of disk operations can compromise the performance of SFC placement algorithms and make it unfeasible. In addition, the amount of memory available to run the allocation algorithm may not be sufficient to load the large amount of information that describe the network resources (occasionally in the hundreds of gigabytes). We address this problem by using a cluster-based solution that stores and retrieves data for large-scale infrastructures in order to perform SFC placement. The results demonstrate that the use of clusters in the preprocessing step can drastically reduce the size of the resulting database, as well as the execution time to select candidate nodes for a scalable SFC allocation.},
  archive      = {J_SUPERC},
  author       = {de Freitas Bezerra, Diego and da Silva Rocha, Elisson and Santos, Guto Leoni and Moreira, André Luis Cavalcanti and Kelner, Judith and Sadok, Djamel F. H. and Gonçalves, Glauco Estácio and Marquezini, Maria Valéria and Endo, Patricia Takako},
  doi          = {10.1007/s11227-025-07218-6},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {A cluster-based solution for service function chain allocation in large-scale infrastructure},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automatic software test-generation method to discover the faults using fusion of machine learning and horse herd algorithm. <em>SUPERC</em>, <em>81</em>(5), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07219-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the time-consuming and expensive phases in software development is software testing, which is used to improve the quality of software systems. Therefore, Software test automation is a helpful technique that can alleviate testing time. Several techniques based on evolutionary and heuristic algorithms have been put forth to produce maximum coverage test sets. The primary shortcomings of earlier methods are inconsistent outcomes, insufficient branch coverage, and low fault-detection rates. Increasing branch coverage rate, defect detection rate, success rate, and stability are the primary goals of this research. A time- and cost-effective method has been suggested in this research to produce test data automatically by utilizing machine learning and horse herd optimization algorithms. In the first stage of the proposed method, the suggested machine learning classification model identifies the non-error-propagating instructions of the input program using machine learning algorithms. In the second stage, a test generator was suggested to cover only the program's fault-propagating instructions. The main characteristics of produced test data are avoiding the coverage of non-error-propagating instructions, maximizing the coverage of error-propagating instructions, maximizing success rate, and the fault discovery capability. Several experiments have been performed using nine standard benchmark programs. In the first stage, the suggested instruction classifier provides 90% accuracy and 82% precision. In the second stage, according to the results, the produced test data by the suggested method cover 99.93% of the error-prone instructions. The average success percentage with this method was 98.93%. The suggested method identifies roughly 89.40% of the injected faults by mutation testing tools.},
  archive      = {J_SUPERC},
  author       = {Arasteh, Bahman and Arasteh, Keyvan and Ghaffari, Ali},
  doi          = {10.1007/s11227-025-07219-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {An automatic software test-generation method to discover the faults using fusion of machine learning and horse herd algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dhcm: A dynamic hierarchy coordination mechanism for memory optimization. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07224-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern processors rely on advanced memory management techniques such as predicting and prefetching to bridge the processor–memory gap. However, current mechanisms are primarily designed for a specific memory hierarchy level or access pattern, resulting in inefficiencies for diverse workloads with mixed memory access patterns. To address this challenge, this paper proposes DHCM, a Dynamic Hierarchy Coordination Mechanism that intelligently schedules prediction hierarchies and dynamically optimizes memory access processes to enhance system performance. DHCM integrates a hierarchy coordination mechanism driven by a State Trigger. This mechanism dynamically leverages system feedback to prioritize and coordinate memory operations, enabling the simultaneous management of both off-chip load requests and on-chip cache accesses. Through extensive evaluations on the ChampSim simulator, DHCM demonstrates its adaptability and efficiency with an average IPC improvement of 34.08% and 24.09% on single-core and multi-core systems, respectively. Additionally, DHCM contributes a 64.17% miss coverage and 89.33% DRAM-loads reduction.},
  archive      = {J_SUPERC},
  author       = {Fang, Juan and Li, Jingjing and Teng, Ziyi},
  doi          = {10.1007/s11227-025-07224-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Dhcm: A dynamic hierarchy coordination mechanism for memory optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated data stream analysis framework for internet of vehicles based on online ensemble learning and two-dimensional fractal dimension. <em>SUPERC</em>, <em>81</em>(5), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07227-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the 5th-generation mobile network (5G) technology and intelligent connected vehicles, the amount of data generated by the Internet of Vehicles (IoV) continues to increase. Due to the dynamic environment of IoV, data streams face the concept drift problem, where changes in data distribution over time lead to changes in the relationship between input features and target variables. This results in a decline in the performance of machine learning models, as models trained on outdated data fail to capture evolving patterns. To solve this problem, we propose an automated data stream analysis framework based on online ensemble learning and two-dimensional fractal dimension, which includes three pipelines: automated data preprocessing, drift-based automated feature engineering (DA-FE), and a novel two-stage online adaptation method that automatically integrates model and detects drifts through proposed the window-based confidence averaging ensemble method and the optimized sliding window based on the two-dimensional fractal dimension method. The proposed framework is a complete automated data stream analysis framework that enables automatic, high-performance, and efficient data stream analysis for IoV. On four public network datasets and one IoV simulation dataset, the performance and efficiency of the proposed framework are evaluated based on various metrics such as accuracy, precision, recall, F1-score, inference time, and throughput. Experimental results show that the proposed framework is superior to the most state-of-the-art data stream analysis methods.},
  archive      = {J_SUPERC},
  author       = {Wang, Yingqing and Liang, Yanhua and Huang, Yue and Qin, Guihe},
  doi          = {10.1007/s11227-025-07227-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {An automated data stream analysis framework for internet of vehicles based on online ensemble learning and two-dimensional fractal dimension},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDos prevention in IoT networks by analyzing source-side inter-bot traffic using deep learning techniques. <em>SUPERC</em>, <em>81</em>(5), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07236-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth in IoT networks, both in usage and the number of devices, considerable challenges appear in the field. The majority of the past research is focused on analyzing traffic on the destination (victim’s) side which has some major drawbacks. That is, they are only passive defenses after the attack and do not use the outbound statistical features of attacks. Therefore, it is hard to trace back to the attacker with these approaches. In this paper, we focused on analyzing the inner botnet traffic from the attacker’s source network which allows us to detect and prevent Distributed Denial of Service (DDoS) attacks more efficiently. The novelty of the work is the prevention of DDoS attacks by detecting the initial phase of the attack before it harms the victim. We use attention-based deep learning models to better analyze the sequence of traffic exchange among bots (within the source network). This results in stopping the attack from the origin before it begins. We compared our method with some previous machine learning models on the BOT-IoT dataset which is real data gathered by the University of New South Wales (UNSW) research center. The results show that using the attention mechanism will increase the F1-score significantly to 99.5%.},
  archive      = {J_SUPERC},
  author       = {Malekzadeh, Saba and Yousefi, Saleh and Tajbakhsh, Mir Saman},
  doi          = {10.1007/s11227-025-07236-4},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {DDos prevention in IoT networks by analyzing source-side inter-bot traffic using deep learning techniques},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dcsca-net: A dual-branch network with enhanced cross-fusion and spatial-channel attention for precise medical image segmentation. <em>SUPERC</em>, <em>81</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07239-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, two-branch networks combining CNNs and transformers have advanced medical image segmentation by leveraging CNNs for local feature extraction and transformers for global context modeling. However, challenges remain in feature fusion and computational efficiency. In this paper, we propose a dual-branch network with enhanced cross-fusion and spatial-channel attention. The dual-stream cross-fusion (DCF) module facilitates interaction between CNN and transformer features, while the cross-scale feature fusion (CS) module in the decoder enhances contextual understanding. To further optimize performance, an attention enhancement (SCAM) module is introduced between the DCF output and the CS input to enable deeper fusion of local and global information. The DCF module is also augmented with multi-layer factorial attention for multi-level feature interaction and fusion. Additionally, a dynamic loss mechanism with adaptive weight adjustment improves training stability and generalization in the presence of class imbalance. Experiments demonstrate a significant improvement in segmentation accuracy, underscoring the effectiveness of multi-level fusion and attention enhancement in medical image analysis.},
  archive      = {J_SUPERC},
  author       = {Wang, Nianhao and Wang, Han},
  doi          = {10.1007/s11227-025-07239-1},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Dcsca-net: A dual-branch network with enhanced cross-fusion and spatial-channel attention for precise medical image segmentation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The evolution of high-performance computing: How AI and quantum computing are reshaping supercomputing. <em>SUPERC</em>, <em>81</em>(5), 1--3. (<a href='https://doi.org/10.1007/s11227-025-07241-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Ranilla-Cortina, Sandra and Alonso-Jordá, Pedro and Vigo-Aguiar, Jesús and Ranilla, José},
  doi          = {10.1007/s11227-025-07241-7},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--3},
  shortjournal = {J. Supercomput.},
  title        = {The evolution of high-performance computing: How AI and quantum computing are reshaping supercomputing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASOD-YOLOX: A study on small object detection in aerial images based on YOLOX. <em>SUPERC</em>, <em>81</em>(5), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07243-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In UAV aerial imagery, small objects often occupy minimal pixel regions and are prone to being obscured by noisy backgrounds, posing significant detection challenges. Existing methods primarily rely on multi-scale information fusion to address these issues, yet their overall detection accuracy for small objects remains limited. To tackle this, we propose ASOD-YOLOX, an aerial small object detection algorithm based on YOLOX, which integrates advancements in multi-scale fusion, contextual information, and attention mechanisms to enhance feature representation and discrimination. Specifically, the backbone network incorporates the CrissCross Attention module to improve multi-scale feature representation, while the Bidirectional Adaptive Layered Weight Fusion Network (BALWF-Net) employs bidirectional information flow and a Dynamic Adaptive Feature Fusion (DASF) module to adaptively adjust fusion weights, addressing information loss in traditional unidirectional flows. Additionally, the Multi-Scale Self-Attention Network (MSA-NET) leverages dilated convolutions and self-attention mechanisms to enrich contextual information, enhance the separation of targets from the background, and reduce false positives, leading to improved small object detection performance. Results obtained from experiments using VisDrone-2021, UAVDT, and MS COCO datasets indicate that the $$\text {AP}_{S}$$ values of ASOD-YOLOX are 31.1%, 27.2%, and 23.1%, respectively. These findings surpass existing advanced methods, demonstrating their capability in detecting small targets within aerial images.},
  archive      = {J_SUPERC},
  author       = {Zhang, Hongying and Liu, Wentao and Chen, Enyao},
  doi          = {10.1007/s11227-025-07243-5},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {ASOD-YOLOX: A study on small object detection in aerial images based on YOLOX},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Publisher correction: Thermal image edge detection for AI-powered medical research imaging. <em>SUPERC</em>, <em>81</em>(5), 1. (<a href='https://doi.org/10.1007/s11227-025-07257-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Hoorfar, Hamid and Puche, Adam C. and Merchenthaler, Istvan},
  doi          = {10.1007/s11227-025-07257-z},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Publisher correction: Thermal image edge detection for AI-powered medical research imaging},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Dynamic cloud model based on decision field theory. <em>SUPERC</em>, <em>81</em>(5), 1. (<a href='https://doi.org/10.1007/s11227-025-07286-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Anjali and Gupta, Anjana},
  doi          = {10.1007/s11227-025-07286-8},
  journal      = {The Journal of Supercomputing},
  month        = {4},
  number       = {5},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Dynamic cloud model based on decision field theory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLS: A novel hybrid security framework utilizing the wiedemann algorithm and chaotic mapping for MQTT. <em>SUPERC</em>, <em>81</em>(4), 1--34. (<a href='https://doi.org/10.1007/s11227-024-06858-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the Internet of Things (IoT) influences cloud computing security policies. Various methods have been developed to protect against hackers, with advanced techniques often favored due to their ability to enhance the robustness of algorithms. Each cloud platform includes a security broker (SB) section that plays a vital role in data balancing and management while supporting Message Queuing Telemetry Transport (MQTT) protocols. This article presents a multilayered security (MLS) approach that integrates a phased encryption method, combining the Wiedemann algorithm and chaotic mapping to enhance data security. Initial results show enhancements in three key areas: security, efficiency, and availability, achieved through a weighted and prioritized strategy. Furthermore, the article discusses the customer satisfaction index and techniques for attack mitigation. The results indicate a 60.67% increase in the customer satisfaction index and a 61.41% reduction in total assigned penalty costs.},
  archive      = {J_SUPERC},
  author       = {Rezaei, Azita and Broumandnia, Ali and Mirabedini, Seyed Javad},
  doi          = {10.1007/s11227-024-06858-4},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {MLS: A novel hybrid security framework utilizing the wiedemann algorithm and chaotic mapping for MQTT},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach to botnet attacks in the fog computing layer and apache spark for smart cities. <em>SUPERC</em>, <em>81</em>(4), 1--30. (<a href='https://doi.org/10.1007/s11227-024-06915-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has seen significant growth in recent years, impacting various sectors such as smart cities, healthcare, and transportation. However, IoT networks face significant security challenges, particularly from botnets that perform DDoS attacks. Traditional centralized intrusion detection systems struggle with the large traffic volumes in IoT environments. This study proposes a decentralized approach using a fog computing layer with a reptile group intelligence algorithm to reduce network traffic size, followed by analysis in the cloud layer using Apache Spark architecture. Key network traffic features are selected using a chameleon optimization algorithm and a principal component reduction method. Multi-layer artificial neural networks are employed for traffic analysis in the fog layer. Experiments on the NSL-KDD dataset indicate that the proposed method achieves up to 99.65% accuracy in intrusion detection. Additionally, the model outperforms other deep and combined learning methods, such as Bi-LSTM, CNN-BiLSTM, SVM-RBF, and SAE-SVM-RBF, in attack detection. Implementation of decision tree, random forest, and support vector machine algorithms in the cloud layer also demonstrates high accuracy rates of 96.27%, 98.34%, and 96.12%, respectively.},
  archive      = {J_SUPERC},
  author       = {Al Dawi, Abdelaziz and Tezel, Necmi Serkan and Rahebi, Javad and Akbas, Ayhan},
  doi          = {10.1007/s11227-024-06915-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {An approach to botnet attacks in the fog computing layer and apache spark for smart cities},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSVDetector: A heterogeneous semantic graph-based method for smart contract vulnerability detection. <em>SUPERC</em>, <em>81</em>(4), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06951-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of blockchain technology, smart contracts have found widespread application across various domains. However, their security vulnerabilities have increasingly attracted attention. To overcome the limitations present in current detection methods, particularly in terms of semantic representation and structural comprehension, this paper proposes Heterogeneous Semantic Vulnerability Detector (HSVDetector), a novel vulnerability detection method for smart contracts based on a Heterogeneous Semantic Graph (HSG). We construct a Variable Dependency Graph (VDG) derived from the Abstract Syntax Tree (AST) of smart contracts to capture both data flow and control flow dependencies between variables. Additionally, we generate the HSG to provide a comprehensive representation of both semantic and structural aspects of the code. To efficiently learn the features of HSG, we design the HGAT-SC model, which employs a graph attention mechanism to analyze the characteristics of heterogeneous nodes and edges. We evaluate HSVDetector on four types of vulnerabilities: timestamp dependency, reentrancy attacks, delegatecall, and integer overflow/underflow. Experimental results indicate that HSVDetector achieves detection accuracies of 93.12%, 91.15%, 95%, and 89.89% for each respective vulnerability, significantly outperforming existing methods. HSVDetector offers an innovative and effective approach for enhancing the security of smart contracts.},
  archive      = {J_SUPERC},
  author       = {Zhu, Heming and Li, Hao and Lu, Gehao},
  doi          = {10.1007/s11227-025-06951-2},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {HSVDetector: A heterogeneous semantic graph-based method for smart contract vulnerability detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-dependent generalization bounds for parameterized quantum models under noise. <em>SUPERC</em>, <em>81</em>(4), 1--28. (<a href='https://doi.org/10.1007/s11227-025-06966-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning offers a transformative approach to solving complex problems, but the inherent noise hinders its practical implementation in near-term quantum devices. This obstacle makes it challenging to understand the generalization capabilities of quantum circuit models. Designing robust quantum machine learning models under noise requires a principled understanding of complexity and generalization, extending beyond classical capacity measures. This study investigates the generalization properties of parameterized quantum machine learning models under the influence of noise. We present a data-dependent generalization bound grounded in the quantum Fisher information matrix. We leverage statistical learning theory to relate the parameter space volumes and training sizes to estimate the generalization capability of the trained model. By integrating local parameter neighborhoods and effective dimensions defined through quantum Fisher information matrix eigenvalues, we provide a structured characterization of complexity in quantum models. We analyze the tightness of the bound and discuss the trade-off between model expressiveness and generalization performance.},
  archive      = {J_SUPERC},
  author       = {Khanal, Bikram and Rivas, Pablo},
  doi          = {10.1007/s11227-025-06966-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Data-dependent generalization bounds for parameterized quantum models under noise},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-enhanced graph convolutional networks for aspect-based financial sentiment analysis. <em>SUPERC</em>, <em>81</em>(4), 1--19. (<a href='https://doi.org/10.1007/s11227-025-06972-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based financial sentiment analysis (ABFSA) is a challenging task at the intersection of finance and natural language processing, which aims to infer the trend of a specific entity (e.g., a company or stock) by identifying the sentiment reflected in financial-related texts, while there are a great deal of outstanding works dealing with aspect-level sentiment analysis task. However, there remains a deficiency in research explicitly targeting the ABFSA. In particular, due to the expressive differences between texts in the financial domain and social media texts, existing models lose sentiment details when mining the semantics of finance-related texts. To tackle this issue, the paper conducts a thorough analysis of the expressive features of financial texts and proposes a dual-enhanced GCN network (DEGCN) for financial sentiment analysis. DEGCN is composed of two main components: The Sentic-enhanced GCN focuses on fine-grained sentiment connections between words to overcome the loss of sentiment details caused by unified modeling, and the Domain-enhanced GCN is designed based on the characteristics of financial texts, dividing each sentence into finer categories for classification, thereby significantly reducing noise introduced by domain quantification inconsistencies. Extensive experiments and ablation studies on two public benchmark datasets demonstrate that the proposed model achieves significant improvements over previous baselines.},
  archive      = {J_SUPERC},
  author       = {Yao, Ruiyang},
  doi          = {10.1007/s11227-025-06972-x},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Dual-enhanced graph convolutional networks for aspect-based financial sentiment analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic cloud model based on decision field theory. <em>SUPERC</em>, <em>81</em>(4), 1--51. (<a href='https://doi.org/10.1007/s11227-025-06989-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world applications are characterized by uncertainties, with randomness and fuzziness being the significant challenges inherent in human cognition. The Cloud Model (CM) synthesizes these uncertainties, enabling the transformation between qualitative and quantitative instantiations. Integrating CM with Decision Field Theory (DFT) is essential for managing the complexities of dynamic and probabilistic decision-making. Our research introduces a novel Dynamic Cloud Model based on Decision Field Theory (DCM-DFT). It incorporates an innovative methodology for creating dynamic clouds by capturing initial uncertainty using cloud descriptors. We built a custom time series model to compute attention weights for forecasted periods, effectively managing the full spectrum of uncertainty fluctuations in a decision maker’s dynamic mental state. We demonstrate DCM-DFT’s practical implementation using the Lifestyle and Wellbeing real-time dataset, showcasing fluctuations in decision ranking of alternatives over time. A comparative study exhibits DCM-DFT’s enhanced performance over traditional approaches, significantly improving decision-making preferences in dynamic and uncertain environments.},
  archive      = {J_SUPERC},
  author       = {Anjali and Gupta, Anjana},
  doi          = {10.1007/s11227-025-06989-2},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--51},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic cloud model based on decision field theory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double salted HMAC signature with blockchain for faster and secure video integrity verification. <em>SUPERC</em>, <em>81</em>(4), 1--26. (<a href='https://doi.org/10.1007/s11227-025-06996-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital technology advancements have increased the use of video surveillance for ongoing observation, aiding in forensic investigations and crime prevention. Recent developments in video editing and manipulation software, however, make it simple to alter footage without leaving obvious traces. Therefore, before being used as evidence, video data need to have its integrity verified. In this paper, a novel and lightweight method for ensuring the integrity of video data is presented. Blockchain, Hash-based message authentication code using BLAKE2b hash function, and Twisted Edwards Curve to generate signatures and Diffie-Hellman algorithm using Curve25519 for exchange key are used in the proposed method. The file location for the video segment, the double salted HMAC signature, and the transient public key needed to validate the signature are all included in each block in the chain. The double salted HMAC signature is the combined signature of salted HMAC value of the video segment and salted HMAC value of previous block. Recomputing the salted HMAC values allows for the validation of this signature at the time of verification. According to experimental data, the proposed method is faster and more secure than state-of-the-art methods. With negligible additional storage requirements, our method can detect every kind of forgery on any video file, by an authorized user. Additionally, our security analysis demonstrates that our method is resistant to side-channel, differential, preimage, and key substitution attacks, among other forms of assaults. The proposed lightweight video integrity verification method is more appropriate for usage in devices with limited resources.},
  archive      = {J_SUPERC},
  author       = {Lawrence, Linju and Shreelekshmi, R.},
  doi          = {10.1007/s11227-025-06996-3},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Double salted HMAC signature with blockchain for faster and secure video integrity verification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on the recent random walk-based methods for embedding graphs. <em>SUPERC</em>, <em>81</em>(4), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07019-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning, deep learning and NLP methods on graphs are vastly present in different fields and have important roles in various domains from self-driving cars to friend recommendations on social media platforms. However, to apply these methods on graphs, the data usually need to be in an acceptable size and format. In fact, graphs normally have high dimensions, and therefore we need to transform them to a low-dimensional vector space. Embedding is a low-dimensional space into which one can translate high-dimensional vectors in a way that intrinsic features of the input data are preserved. In this review, we first explain the importance of graphs and the embedding methods applied to them. Next, we will review some of the random walk-based embedding methods as well as their strengths and weaknesses that have been developed recently. Later, we will address research directions for future research.},
  archive      = {J_SUPERC},
  author       = {Bozorgi, Elika and Alqaaidi, Sakher Khalil and Shams, Afsaneh and Arabnia, Hamid Reza and Kochut, Krzysztof},
  doi          = {10.1007/s11227-025-07019-x},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {A survey on the recent random walk-based methods for embedding graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable training of trustworthy and energy-efficient predictive graph foundation models for atomistic materials modeling: A case study with HydraGNN. <em>SUPERC</em>, <em>81</em>(4), 1--48. (<a href='https://doi.org/10.1007/s11227-025-07029-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present our work on developing and training scalable, trustworthy, and energy-efficient predictive graph foundation models (GFMs) using HydraGNN, a multi-headed graph convolutional neural network architecture. HydraGNN expands the boundaries of graph neural network (GNN) computations in both training scale and data diversity. It abstracts over message passing algorithms, allowing both reproduction of and comparison across algorithmic innovations that define nearest-neighbor convolution in GNNs. This work discusses a series of optimizations that have allowed scaling up the GFMs training to tens of thousands of GPUs on datasets consisting of hundreds of millions of graphs. Our GFMs use multitask learning (MTL) to simultaneously learn graph-level and node-level properties of atomistic structures, such as energy and atomic forces. Using over 154 million atomistic structures for training, we illustrate the performance of our approach along with the lessons learned on two state-of-the-art US Department of Energy (US-DOE) supercomputers, namely the Perlmutter petascale system at the National Energy Research Scientific Computing Center and the Frontier exascale system at Oak Ridge Leadership Computing Facility. The HydraGNN architecture enables the GFM to achieve near-linear strong scaling performance using more than 2000 GPUs on Perlmutter and 16,000 GPUs on Frontier.},
  archive      = {J_SUPERC},
  author       = {Lupo Pasini, Massimiliano and Choi, Jong Youl and Mehta, Kshitij and Zhang, Pei and Rogers, David and Bae, Jonghyun and Ibrahim, Khaled Z. and Aji, Ashwin M. and Schulz, Karl W. and Polo, Jordà and Balaprakash, Prasanna},
  doi          = {10.1007/s11227-025-07029-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--48},
  shortjournal = {J. Supercomput.},
  title        = {Scalable training of trustworthy and energy-efficient predictive graph foundation models for atomistic materials modeling: A case study with HydraGNN},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DQN-MSRA: An online SFC deployment method based on multistep reinforcement learning. <em>SUPERC</em>, <em>81</em>(4), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07042-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with enhancements in software-defined network (SDN) technology and network function virtualization technology, the IETF has proposed replacing conventional dedicated hardware-based network services with virtualized service function chains (SFCs). However, in dynamically changing network environments, performing online SFC deployment while satisfying network capacity constraints is already a challenging task. Providing fast and efficient online services for randomly arriving requests while also ensuring service quality is even more difficult. In this regard, we incorporate the SDN characteristic and propose a univariate modeling approach that can accommodate both network function placement and dynamic routing. This pattern not only avoid exploiting invalid paths during the training procedure, but also effectively reduces the number of variables in the complete SFC placement, as well as the size of the action space. More importantly, we apply the idea of multistep reinforcement learning (RL) to SFC placement with dependencies for the first time and propose a novel SFC-suitable placement method named DQN-MSRA. Compared with the conventional one-step RL process that focuses on the impact of the current step reward on a given action, DQN-MSRA reduces the impact of the immediate reward and pays more attention to the long-term ones, making it more applicable to online SFC placement. We verify the effectiveness of DQN-MSRA from multiple perspectives and experimentally analyze the association between the aggregation window size and service chain length. In addition, our approach has a higher acceptance rate, better deployment stability, and higher adaptability than recent novel deployment methods.},
  archive      = {J_SUPERC},
  author       = {Zhang, Zhibo and Wang, Huiqiang and Li, Rongqiang and Lv, Hongwu and He, Dongmiao},
  doi          = {10.1007/s11227-025-07042-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {DQN-MSRA: An online SFC deployment method based on multistep reinforcement learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale machine learning with synchronous parallel adaptive stochastic variance reduction gradient descent for high-dimensional blindness detection on spark. <em>SUPERC</em>, <em>81</em>(4), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07046-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parallelization of optimization algorithms is of paramount importance in large-scale machine learning. In this paper, we explore the implementation of Adaptive learning rate Stochastic Gradient Descent (A-SGD) in a synchronized and parallelized manner. Additionally, we incorporate a Variance Reduction (VR) strategy to enhance the rate of convergence. Our approach addresses the complexity associated with high-dimensional datasets, particularly within the context of Logistic Regression (LR) and Support Vector Machine (SVM). Initially, we utilize the Histogram of Oriented Gradients (HOG) to extract high-dimensional sparse features from a dataset designed for Blindness Detection. Subsequently, we employ LR and SVM as our classifiers of choice. Finally, we apply the Synchronous A-SGD (SA-SGD) and Synchronous Adaptive Stochastic Variance Reduction (SA-SVRG) to the solutions of these classifiers. Our experimental results indicate that the performance of SA-SGD and SA-SVRG is notably superior when executed on a cluster as opposed to a single node.},
  archive      = {J_SUPERC},
  author       = {Qin, Chuandong and Zhang, Yiqing and Cao, Yu},
  doi          = {10.1007/s11227-025-07046-8},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Large-scale machine learning with synchronous parallel adaptive stochastic variance reduction gradient descent for high-dimensional blindness detection on spark},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal image edge detection for AI-powered medical research imaging. <em>SUPERC</em>, <em>81</em>(4), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07050-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared thermal imaging has emerged as a tool in medical research and diagnostics, offering a potential high throughput AI-powered method to analyze skin temperature patterns and find physiological conditions. This study focused on the research application of digital thermal imaging to detect hot flush events in primates. A convolutional neural network (CNN) was employed to define facial boundaries and measure facial temperatures. To enhance boundary detection, edge detection methods were applied as a preprocessing step, with their outputs serving as inputs to the CNN model. These methods were evaluated and compared on the relevant dataset, and six of them contributed to improved performance metrics. Among these, the Sobel and Scharr methods achieved the highest test accuracy on unseen images (99.91%), while Scharr and Canny showed the lowest test loss values (0.29%). Furthermore, the Sobel and Scharr methods showed improvements in performance, achieving IoU score increases of 2.01% and 1.87%, respectively, over the baseline U-Net model without preprocessing, which is important for meeting the project's goal of improving the accuracy of facial skin temperature measurements. By integrating these edge detection techniques, the accuracy of facial temperature measurements was enhanced, enabling the precise identification of hot flush events. This research underscores the value of combining advanced image processing methods with deep learning models for enhancing the analysis of thermal images in biomedical applications.},
  archive      = {J_SUPERC},
  author       = {Hoorfar, Hamid and Puche, Adam C. and Merchenthaler, Istvan},
  doi          = {10.1007/s11227-025-07050-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Thermal image edge detection for AI-powered medical research imaging},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APPBoost: An adaptive parameter pair boosting algorithm for enhanced robustness against noise and imbalance. <em>SUPERC</em>, <em>81</em>(4), 1--36. (<a href='https://doi.org/10.1007/s11227-025-07053-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AdaBoost is a widely-used boosting algorithm known for its effectiveness in improving model accuracy by iteratively adjusting sample weights to focus on misclassified examples. However, its performance deteriorates in the presence of noisy and imbalanced data. To address these challenges, we propose Adaptive Parameter Pair Boosting (APPBoost) to dynamically adjust sample weights by introducing two parameters during the boosting process. APPBoost employs a new loss function with the parameter pair $$(\theta , \epsilon )$$ , and utilizes an updated weight adjustment mechanism to optimize the classification process in each iteration. This approach mitigates the impact of noisy and misclassified samples, leading to improved generalization and robustness. Theoretical analysis demonstrates that APPBoost effectively bounds the training error and is a special case of the Forward Stagewise Additive Model. Experimental results on both simulated and real-world datasets show that APPBoost outperforms traditional AdaBoost and its variants, particularly in scenarios with high noise levels and class imbalance. In a case study on cardiovascular disease diagnosis, coupled with RFE-RF feature selection, APPBoost achieves superior accuracy, precision, and AUC compared to conventional machine learning and deep learning methods, as well as a 3.2% improvement over AWABoost and a 7.8% improvement over AdaBoost. Additionally, SHAP analysis provides interpretability by quantifying feature contributions, offering insights into the decision-making process of APPBoost.},
  archive      = {J_SUPERC},
  author       = {Wang, Ziheng and Shao, Zixuan and Wang, Baowei and Cheng, Xu},
  doi          = {10.1007/s11227-025-07053-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {APPBoost: An adaptive parameter pair boosting algorithm for enhanced robustness against noise and imbalance},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable two-stage model for real-time wetland bird recognition. <em>SUPERC</em>, <em>81</em>(4), 1--17. (<a href='https://doi.org/10.1007/s11227-025-07061-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional efficient lightweight image classification algorithms generally demonstrate low accuracy in real-time wetland bird recognition tasks due to the environmental complexity and the high similarity among bird species. Moreover, a bird recognition server needs to perform computation-intensive tasks of multi-process parallel inferences, requiring a low inference latency of the bird recognition algorithm. Traditional high-accuracy fine-grained methods cannot meet the demands due to their high computational complexity. In this study, we introduce a scalable two-stage model for real-time wetland bird recognition, which incorporates an object detector and a fine-grained image recognition technique, bilinear pooling, to encode fine-grained features. Additionally, we design a lightweight architecture and propose a bilinear scalable module in the bilinear pooling to trade-off between latency and accuracy. The experimental results show that the proposed method achieves 77.6% and 97.6% accuracy on the CUB and WPB datasets, respectively, which are much higher than MobileNetV3 and ShuffleNetV2, with a low inference latency of only 79.5 ms on CPU. Furthermore, parallel inference experiments in practical environments demonstrate that the proposed method achieves an inference speed of 15.3 FPS, with 12 parallel video streams.},
  archive      = {J_SUPERC},
  author       = {Xia, Wenyuan and Zhou, Qing and Wu, Dayu and Wang, Siyuan and Zhou, Mengshuang},
  doi          = {10.1007/s11227-025-07061-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {A scalable two-stage model for real-time wetland bird recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic communication based on bi-level routing attention in IoT environment. <em>SUPERC</em>, <em>81</em>(4), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07062-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional communication methods rely on meticulously designed system modules to ensure accurate bit-level transmission. However, with the growing complexity and volume of data, these approaches are reaching the Shannon limit. Semantic communication (SC) emerges as a promising solution that emphasizes meaning rather than bit-level precision. Despite its potential, SC still faces challenges in efficiently extracting and preserving relevant features, especially in resource-constrained environments. This article proposes a SC method that utilizes bi-level routing attention (BRA), named BRASC. By capturing both region-to-region and token-to-token attention mechanisms, BRA captures broad meaning as well as specific details, retaining key semantic information while eliminating less relevant data, thereby enhancing feature representation and improving transmission accuracy. Experimental results demonstrate that BRASC consistently outperforms Original Images Direct Classification (OIDC), Deep Learning (ResNet18), and Baseline methods in image classification accuracy on the STL-10 dataset. BRASC shows superior performance across varying signal-to-noise ratios (SNR), maintaining high accuracy and stability, particularly excelling in low SNR conditions. This robustness across diverse channel conditions confirms BRASC’s effectiveness and adaptability for semantic communication in challenging communication scenarios.},
  archive      = {J_SUPERC},
  author       = {Yan, Xiao and Xiumei, Fan and Yau, Kok-Lim Alvin and Zhixin, Xie and Rui, Men},
  doi          = {10.1007/s11227-025-07062-8},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Semantic communication based on bi-level routing attention in IoT environment},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mfe-net: A multiscale feature enhanced network for mesoscale convective systems identification. <em>SUPERC</em>, <em>81</em>(4), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07065-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of Mesoscale convective systems (MCSs) is important for disaster prevention and management. Traditional MCSs identification methods are based on temperature and area thresholds. These methods are highly accurate for MCSs identification, but consume large computational resources. Deep learning models have made significant progress in the field of object identification. However, existing deep learning models do not take into account the characteristics of excessive differences in MCSs area coverage and uneven spatial distribution. Direct application of these models to this task may lead to the problems of missed identification of small MCSs and ambiguous identification of MCSS boundaries. In this paper, we construct a MCSs recognition dataset and propose a Multiscale Feature Enhancement Network (MFE-Net) for identifying MCSs. This model consists of two main modules: Feature Alignment Distribution Module (FADM) and Asymmetric Feature Recovery Module (AFRM). The FADM, which is used to aggregate multiscale information during the downsampling phase, aims to improve the perception of small-scale MCSs and prevent them from being lost during the downsampling process of the model. AFRM is designed to extract and preserve spatial edge features of MCSs from different spatial dimensions and accurately identify the edges of MCSs. The experimental results show that our MFE-Net achieves excellent performance both quantitatively and qualitatively.},
  archive      = {J_SUPERC},
  author       = {Li, Peng and Huang, Zhanao and Li, Yan and Kou, Yi and Li, Xiaojie},
  doi          = {10.1007/s11227-025-07065-5},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {Mfe-net: A multiscale feature enhanced network for mesoscale convective systems identification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quality-of-service provision for BXIv3-based interconnection networks. <em>SUPERC</em>, <em>81</em>(4), 1--34. (<a href='https://doi.org/10.1007/s11227-025-07069-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supercomputers (SCs) enable advanced research for a variety of scientific fields, and data centers (DCs) power our day-to-day services. These two massive systems work at scales, in terms of storage and computing power, which are not comparable to our everyday devices. As such, they require state-of-the-art technology to constantly evolve and meet our increasing demand. The interconnection network is the backbone of these systems, since it must provide efficient communication among the nodes that compose the whole system, otherwise becoming the entire system bottleneck. As multiple applications and services may use subsets of the system at the same time, interconnection networks must prevent excessive degradation for latency-sensitive applications. To this end, differentiated services are used to provide fair network access that considers bandwidth and latency requirements for each application. In this paper, we extend the switch architecture of next-generation BXI networks (hereafter called BXIv3) to incorporate arbitration tables so these networks can provide quality of service (QoS) to applications and services running on both SCs and DCs. Our proposal has been implemented in a network simulator, which models the behavior of a BXIv3 network. We have used several traffic patterns and arbitration table configurations to conduct a set of simulation experiments for the evaluation of our solution. The obtained results show that our proposal achieves accurate bandwidth allocation with differentiated latencies. Moreover, a study of memory requirements shows that our solution is quite feasible for hardware implementation.},
  archive      = {J_SUPERC},
  author       = {de la Rosa, Miguel Sánchez and Gomez-Lopez, Gabriel and Andújar, Francisco J. and Escudero-Sahuquillo, Jesús and Sánchez, José L. and Alfaro-Cortés, Francisco J. and Lagadec, Pierre-Axel},
  doi          = {10.1007/s11227-025-07069-1},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Quality-of-service provision for BXIv3-based interconnection networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital signature scheme based on general chebyshev polynomial. <em>SUPERC</em>, <em>81</em>(4), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07074-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the operational efficiency and lower computational costs of public key cryptography based on the Chebyshev polynomial compared to elliptic curve cryptography (ECC), the digital signature schemes based on the Chebyshev polynomial have not been widely applied. The primary obstacle includes its short period characteristic and coefficient fixation issue, which makes cryptosystems vulnerable to exhaustive attacks. To enhance the resistance of cryptosystems to the exhaustive attack, the general Chebyshev polynomial (GCP) is developed in this paper. It still possesses the semigroup property that public key cryptosystems rely on and provides an optional parameter that improves its complexity and pluralism. A novel digital signature scheme with reduced design complexity and enhanced security based on GCP is proposed. Theoretical analyses and experimental results show that this digital signature scheme offers more advantages in terms of both security and efficiency than existing schemes.},
  archive      = {J_SUPERC},
  author       = {Li, Shouliang and Min, Rudong and Zhang, Jilong and Han, Jiale and Shen, Yulin and Yang, Zhen and Yang, Yi},
  doi          = {10.1007/s11227-025-07074-4},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {A digital signature scheme based on general chebyshev polynomial},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sim-ConvFormer: A lightweight fault diagnosis framework incorporating SimAM and external attention. <em>SUPERC</em>, <em>81</em>(4), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07075-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things and artificial intelligence technologies, the massive data generated by mechanical equipment has driven the fault diagnosis technology into the “big data” era. The analysis, diagnosis, and prediction of these data have become crucial for ensuring the smooth and safe operation of mechanical equipment. In recent years, traditional convolutional neural networks (CNNs) and Transformer-based models have been widely used in industrial fault diagnosis. This paper proposes a new lightweight fault diagnosis framework, Sim-ConvFormer, to address the issues of high model complexity and stringent hardware requirements. The Sim-ConvFormer framework integrates SimAM and External Attention. SimAM (A Simple, Parameter-Free Attention Module for Convolutional Neural Networks) enhances the model’s sensitivity to fine-grained signal variations, capturing locally significant features at different scales. Unlike self-attention, External Attention enhances generalization by computing the affinity between input features and two external memory modules shared across the dataset, thereby capturing global contextual information. The synergy of these technologies not only preserves their individual advantages but also enhances the model’s robustness and accuracy in handling various faults. Experiments on three different mechanical systems demonstrate Sim-ConvFormer’s superior fault diagnosis performance, particularly in terms of model lightness and diagnostic robustness compared to existing Transformer-based methods and CNN-based methods. These results indicate that Sim-ConvFormer is an effective fault diagnosis framework suitable for deployment in resource-constrained industrial environments.},
  archive      = {J_SUPERC},
  author       = {Gao, Jianbang and Guo, Yuxiao and Gao, Guowang},
  doi          = {10.1007/s11227-025-07075-3},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Sim-ConvFormer: A lightweight fault diagnosis framework incorporating SimAM and external attention},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of SSD simulators and emulators. <em>SUPERC</em>, <em>81</em>(4), 1--43. (<a href='https://doi.org/10.1007/s11227-025-07078-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing demand of supercomputing and hyperscale data centers for high-performance and reliable storage systems, solid-state drives (SSDs) have emerged as a dominant technology. Unlike traditional hard disk drives, SSDs utilize flash memory to achieve significantly faster data access and higher bandwidth. These advantages translate to improved system responsiveness, faster boot times, and enhanced application performance across various compute and data-intensive workloads. However, the intricate architecture and dynamic nature of modern SSDs pose significant challenges for designers. Hardware advancements, such as the adoption of 3D NAND flash memory and complex controller algorithms, necessitate rigorous testing and optimization before real-world deployment. This is where SSD simulators and emulators become indispensable tools in the development cycle. This survey delves into the critical role of SSD simulators and emulators, highlighting their contributions to accelerated innovation, performance optimization, predictive analysis, and future-proofing capabilities. Through a comprehensive evaluation of these tools, this work aims to provide valuable insights for researchers and developers, ultimately leading to the continued advancement of efficient, reliable, and future-proof SSD solutions.},
  archive      = {J_SUPERC},
  author       = {Gheibi-Fetrat, Atiyeh and Serajeh Hassani, Fatemeh and Mohammadi-Lak, Masoud and Mirzaei, Amir and Akbarzadeh, Negar and Kheyrati-Fard, Mahmoud Reza and Hosseini, Mohammad and Javadi Nezhad, Ahmad and Tavakkol, Arash and Lee, Jeong A. and Sarbazi-Azad, Hamid},
  doi          = {10.1007/s11227-025-07078-0},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--43},
  shortjournal = {J. Supercomput.},
  title        = {A survey of SSD simulators and emulators},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGB-YOLOv5: Straw granulator blockage monitoring system. <em>SUPERC</em>, <em>81</em>(4), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07079-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The straw granulator serves as a critical device for processing straw biomass resources, with channel blockages being a frequent challenge during straw particle production. Channel blockages significantly compromise production efficiency and damage equipment safety, potentially leading to severe mechanical damage. This study presents the SGB-YOLOv5 straw granulator blockage monitoring system, engineered to accurately identify the stacked states of strip-like materials amidst dynamic multi-object interference. By counting straw particles, the system monitors the blockage state of the granulator and triggers an emergency stop upon reaching the blockage alarm threshold. Leveraging a robust datasets, the SGB-YOLOv5 monitoring algorithm extracts visual feature maps via a feature extraction network, which are subsequently analyzed. Post-training evaluations revealed that SGB-YOLOv5 attained a MAP value of 97.5%, with a per-instance decision time of 0.011 s, outperforming other advanced network models and satisfying accuracy standards for practical deployment. Finally, a comprehensive blockage monitoring system for straw granulators was tested to determine the confidence thresholds, ensuring accurate detection within a range of 0.47–0.84. Furthermore, a production test was conducted based on this, validating its effectiveness and accuracy, to some extent, it estimated the production output of the straw granulator. The findings confirm that the blockage monitoring system effectively detects and issues alerts for the pellet blockage states in straw granulators.},
  archive      = {J_SUPERC},
  author       = {Tong, Haoyang and Gao, Dongyang and Wang, Zhixu and Feng, Longlong and Li, Yue and Bai, Xuewei},
  doi          = {10.1007/s11227-025-07079-z},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {SGB-YOLOv5: Straw granulator blockage monitoring system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KSIPF: An effective noise filtering oversampling method based on k-means and iterative-partitioning filter. <em>SUPERC</em>, <em>81</em>(4), 1--35. (<a href='https://doi.org/10.1007/s11227-025-07081-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Synthetic Minority Oversampling TEchnique (SMOTE) is known as the benchmark method to solve class imbalance learning. Since SMOTE was proposed, many variants of it have emerged, which are classified into two types: pre-processing and post-processing. However, most of the pre-processing methods do not filter the noisy samples; at the same time, the post-processing methods do not give attention to the focus area data. In this paper, we present an oversampling method based on kmeans-SMOTE and Iterative Partition Filter (KSIPF), which overcomes the shortcomings of the above methods. Firstly, KSIPF uses k-means to cluster the data and selects the clusters to oversample, and then, IPF is used to remove the noise samples from the data. Then, KSIPF is compared with the SMOTE and its variants on 30 synthetic imbalanced data sets and 20 real-world imbalanced data sets, and the balanced data sets are used to train SVM and AdaBoost classifiers to determine whether it is effective. Finally, the experiment results demonstrate that KSIPF performs better than the comparisons, including area under the curve, F1-measure, and the statistical test.},
  archive      = {J_SUPERC},
  author       = {Sun, Pengfei and Wang, Zhiping and Jia, Liyan and Wang, Xiaoxi},
  doi          = {10.1007/s11227-025-07081-5},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {KSIPF: An effective noise filtering oversampling method based on k-means and iterative-partitioning filter},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous parallel algorithm for the cartesian discrete ordinates for multizone heterogeneous system. <em>SUPERC</em>, <em>81</em>(4), 1--33. (<a href='https://doi.org/10.1007/s11227-025-07087-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in computing technology have revolutionized the efficiency and cost-effectiveness of realistic reactor core simulations. The discrete ordinates ( $$S_N$$ ) method is a widely adopted approach for numerically solving the Boltzmann transport equation (BTE), which describes neutron distribution in nuclear reactors. Recently, the MT-3000, a novel multizone heterogeneous architecture designed for high-performance computing, has been developed, offering a peak double-precision performance of 11.6 TFLOPS at 1.2 GHz. In this study, we propose an efficient four-level heterogeneous $$S_N$$ parallel algorithm for structured hexahedral grids on the MT-3000 system. The algorithm incorporates a two-level KBA strategy with an optimized communication scheme among the MT-3000’s acceleration cores and employs a software caching technique to reduce memory access latency. Numerical experiments reveal that our algorithm achieves 1.68 TFLOPS on a single MT-3000 chip, representing 14.5% of its peak performance. The heterogeneous parallel algorithm demonstrates strong scaling efficiency, consistently exceeding 50% across 4 to 256 MT-3000 systems. Furthermore, we develop a performance model that closely aligns with the experimental results.},
  archive      = {J_SUPERC},
  author       = {Li, Runhua and Wang, Qinglin and Liu, Jie},
  doi          = {10.1007/s11227-025-07087-z},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {A heterogeneous parallel algorithm for the cartesian discrete ordinates for multizone heterogeneous system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced data analytics approach to a cognitive cyber-physical system for the identification and mitigation of cyber threats in the medical internet of things (MIoT). <em>SUPERC</em>, <em>81</em>(4), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07093-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of connected devices into the Medical Internet of Things (MIoT) has improved healthcare delivery but also brings vulnerabilities to cyber threats to patient safety and the integrity of critical medical systems. Today’s security threats are no longer simple and traditional security mechanisms are no longer sufficient. The contribution of this research is an advanced data analysis approach based on a cognitive cyber-physical system to detect and prevent cyber-attacks in MIoT environments. In this paper, we introduce a framework that combines the whale optimization algorithm (WOA) with deep learning models such as gated recurrent units (GRU) and a dense neural network (DNN) for anomaly detection in cyber-attacks. Using a set of wearable health devices and medical imaging equipment, the system is trained to detect threats with unprecedented accuracy. The performance of the model is improved with Hyperparameter optimization using WOA. Experimental results show that the proposed GRU-DNN-WOA framework achieves a detection accuracy of 98.2%, precision of 97.1%, recall of 98.0%, and F1-score of 97.5% on the MedBIoT dataset. On the IoT-23 dataset, it achieves an accuracy of 96.8%, precision of 95.7%, recall of 96.6%, and F1-score of 96.1%, outperforming prior cybersecurity techniques. The results confirm the framework's robustness, scalability, and real-time applicability for securing the MIoT systems.},
  archive      = {J_SUPERC},
  author       = {Tang, Yayuan and Mishra, Suchi and Alduaiji, Noha and Shukla, Piyush Kumar and Yahya, Mohammad and Pang, Tao},
  doi          = {10.1007/s11227-025-07093-1},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {An advanced data analytics approach to a cognitive cyber-physical system for the identification and mitigation of cyber threats in the medical internet of things (MIoT)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M2SSCENet: A multi-branch multi-scale network with spatial-spectral cross-enhancement for hyperspectral and LiDAR data classification. <em>SUPERC</em>, <em>81</em>(4), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07096-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of hyperspectral image (HSI) and light detection and ranging (LiDAR) data offers a powerful approach for land cover classification; however, challenges remain in effectively integrating their complementary information. Existing methods often overlook the importance of spatial information and fail to fully exploit the synergy between HSI and LiDAR data. To address these limitations, this paper proposes M2SSCENet, a multi-branch multi-scale joint learning and spatial-spectral cross-enhancement network. M2SSCENet employs a three-branch architecture to extract HSI spectral features, HSI spatial features, and LiDAR features, respectively. For cross-modal fusion, the network proposes two novel modules: the cross-modality bilateral attention feature fusion module enhances the interaction between HSI spectral features and LiDAR features, while the spatial attention-guided cross-modality fusion module dynamically adjusts spatial attention to capture key elevation information. Additionally, a pixel distance-based proximal feature selection module is proposed to enhance spatial feature representation by emphasizing neighboring pixels with higher contributions. Experimental results on the Trento and Houston2013 datasets demonstrate the superiority of M2SSCENet, achieving OA of 98.44% and 94.33%, respectively. Compared with suboptimal methods on each dataset, M2SSCENet improves classification accuracy by 0.27% on the Trento dataset and by 2.03% on the Houston2013 dataset. Notably, for categories with similar spectral distributions but significant elevation differences, such as “Highway” and “Parking Lot 1,” the proposed method achieves accuracy improvements of 2.18% and 4.75%, respectively. These results highlight the effectiveness of M2SSCENet in leveraging the complementary strengths of HSI and LiDAR data for improved land cover classification.},
  archive      = {J_SUPERC},
  author       = {Yu, Changhong and Zhang, Mingxuan},
  doi          = {10.1007/s11227-025-07096-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {M2SSCENet: A multi-branch multi-scale network with spatial-spectral cross-enhancement for hyperspectral and LiDAR data classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning techniques for enhanced security and privacy in 6G terrestrial–nonterrestrial network architecture. <em>SUPERC</em>, <em>81</em>(4), 1--39. (<a href='https://doi.org/10.1007/s11227-025-07097-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seamless integration of terrestrial networks (TNs) and non-terrestrial networks (NTNs) is a cornerstone in achieving the vision of ubiquitous connectivity in 6G systems. This native integration of TN and NTN components enables global coverage, ultrareliable low-latency communications, and massive device connectivity, but it also presents significant challenges. These challenges include ensuring robust security in distributed architectures, safeguarding privacy during cross-domain data handling, and managing complex interference scenarios in shared and adjacent spectrum environments. Artificial intelligence (AI) serves as a transformative enabler in overcoming these challenges, providing advanced capabilities for real-time threat detection, adaptive authentication, privacy-preserving mechanisms, and dynamic spectrum management. By leveraging advanced techniques such as bidirectional long short-term memory (BiLSTM) networks, multi-agent reinforcement learning (MARL), and federated learning (FL), the proposed solutions enable robust anomaly detection, dynamic spectrum allocation, and scalable privacy-preserving model training. These techniques collectively improve key performance metrics, including a 30% enhancement in signal-to-interference-plus-noise ratio (SINR), over 90% spectrum efficiency, and a privacy budget of $$\epsilon < 1$$ , while reducing latency to below 50 ms. This paper explores the vulnerabilities inherent to TN–NTN architectures, identifies limitations of traditional approaches, and examines cutting-edge AI-driven solutions tailored for integrated TN–NTN systems. Key contributions include insights into AI’s role in addressing security, privacy, and interference challenges, and the development of decentralized intelligence frameworks for scalable and efficient network operations.},
  archive      = {J_SUPERC},
  author       = {Khalid, Maira and Ali, Jehad and Mohsin, Ahmed Raza and Roh, Byeong-hee and Alenazi, Mohammed J. F.},
  doi          = {10.1007/s11227-025-07097-x},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Deep learning techniques for enhanced security and privacy in 6G terrestrial–nonterrestrial network architecture},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing resilience communication in B5G: Optimal deployment of tethered networked flying platforms for disaster recovery. <em>SUPERC</em>, <em>81</em>(4), 1--14. (<a href='https://doi.org/10.1007/s11227-025-07098-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication networks have to be resilient for quick reaction and recovery activities to be possible during catastrophes. Tethered Networked Flying Platforms (TNFPs) offer a viable way to lessen the effects of communication infrastructure failures in Beyond 5 G (B5G) networks. In this research, the best way to deploy TNFPs in disaster situations when conventional ground-based stations are jeopardized, including earthquakes and floods, is examined. In order to improve coverage and dependability, TNFPs, which include low-altitude platforms (LAPs), medium-altitude platforms (MAPs), and high altitude platforms (HAPs), operate at different altitudes. Optimizing power consumption, transmission distances, and coverage probability through adjustment of tether length and elevation angle are important deployment parameters. The simulation results show how efficient performance parameters, including line-of-sight probability, affect total coverage probability, Bit Error Rate (BER), and Signal-to-Noise Ratio (SNR). The results highlight TNFPs’ ability to guarantee robust communication networks in B5G environments.},
  archive      = {J_SUPERC},
  author       = {Saif, Abdu and Shah, Nor Shahida Mohd and Al-Moliki, Yahya M. and Jiang, Weiwei and Alsamhi, Saeed Hamood},
  doi          = {10.1007/s11227-025-07098-w},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--14},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing resilience communication in B5G: Optimal deployment of tethered networked flying platforms for disaster recovery},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Median filtering forensics using spatial and frequency domain residuals. <em>SUPERC</em>, <em>81</em>(4), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07099-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most important topics in image forensics, median filtering detection has developed rapidly in recent years. However, the robustness to JPEG compression is still challenging, especially for small image blocks and low quality compression. We find that when an image is undergone successively median filtering and JPEG compression operations, the median filtering residual (MFR) between the sequential two versions tends to converge. However, the convergence rate for the median filtered image is pretty faster than that for the original one. Based on this, in this paper, we present a JPEG image median filtering forensic method using both spatial and frequency domain residuals. To measure the convergence rate, the nonzero coefficients together with autoregressive coefficients of multiple MFRs are extracted in the spatial domain. Furthermore, a calibration strategy based on image sharpening is proposed in the frequency domain for capturing the convergence difference of MFRs between unaltered and median filtered images. Finally, the complementary features extracted in the two domains are concatenated for the detection task. Experimental results demonstrate the proposed approach is able to accurately detect median filtering and outperforms some state-of-the-art methods, especially in the scenario of small image blocks.},
  archive      = {J_SUPERC},
  author       = {Niu, Yakun and Chen, Xiangru and Yin, Hongjian},
  doi          = {10.1007/s11227-025-07099-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Median filtering forensics using spatial and frequency domain residuals},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure and substructure connectivity of folded divide-and-swap cube. <em>SUPERC</em>, <em>81</em>(4), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07100-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$ {\mathcal {H}} $$ be a connected subgraph of a graph G. The $${\mathcal {H}}$$ -structure connectivity of G, denoted by $$ \kappa (G;{\mathcal {H}}) $$ , is the minimum cardinality of a set of connected subgraphs in G, whose removal either disconnects G or reduces it to a trivial graph, where each element in the set is isomorphic to $$ {\mathcal {H}} $$ . The $${\mathcal {H}}$$ -substructure connectivity of G, denoted by $$ \kappa ^s(G;{\mathcal {H}}) $$ , is the minimum cardinality of a set of connected subgraphs in G, whose removal either disconnects G or reduces it to a trivial graph, where each element in the set is isomorphic to a connected subgraph of $$ {\mathcal {H}} $$ . In this paper, we investigate the $$ {\mathcal {H}} $$ -structure connectivity and $$ {\mathcal {H}} $$ -substructure connectivity of folded divide-and-swap cube $$ FDSC_n $$ for $$ {\mathcal {H}}\in \{K_1, K_{1,1}, K_{1,m} \text (2\le m \le d+2) \} $$ where $$ n=2^d $$ . We show that $$\kappa (FDSC_n;K_1)=\kappa ^s(FDSC_n;K_1)=d+2$$ , $$\kappa (FDSC_n;K_{1,1})=\kappa ^s(FDSC_n;K_{1,1})=d+1 $$ for $$ d\ge 3 $$ and $$\kappa (FDSC_n;K_{1,m})=\kappa ^s(FDSC_n;K_{1,m})=\lfloor \frac{d}{2}\rfloor +1$$ for $$d\ge 1 $$ and $$ 2\le m \le d+1$$ . Moreover, we show that $$\kappa ^s(FDSC_n;K_{1,d+2})=\lfloor \frac{d}{2}\rfloor +1$$ for $$d\ge 1 $$ and we provide a bound for $$\kappa (FDSC_n;K_{1,d+2})$$ when $$d\ge 3 $$ .},
  archive      = {J_SUPERC},
  author       = {Türkmen, Muhammed and Çiftçi, Canan and Boruzanlı Ekinci, Gülnaz},
  doi          = {10.1007/s11227-025-07100-5},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Structure and substructure connectivity of folded divide-and-swap cube},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative approach to classify meniscus tears by reducing vision transformers features with elasticnet approach. <em>SUPERC</em>, <em>81</em>(4), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07103-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meniscal tears, a prevalent orthopedic condition caused by abrupt knee movements, excessive load, or injury, require an accurate diagnosis for effective treatment. This study investigates the vision transformer (ViT) models' efficacy in automated classification of meniscus pathologies. It also explores how feature reduction using the ElasticNet method can improve classification accuracy and computational efficiency. The study utilized MRI scans from a dataset comprising 5000 images collected from clinical cases. Initially, classification was performed using EfficientNet and SqueezeNet architectures. Subsequently, feature extraction was conducted using ViT models, generating a feature set of 1000 dimensions. ElasticNet was employed to reduce features before reclassification using support vector machines (SVM). Model performance was evaluated based on accuracy, precision, sensitivity, and specificity. The ViT_base_32 model achieved a classification accuracy of 99.9% with a processing time of 1.2 s. Feature reduction via ElasticNet significantly enhanced classification performance while maintaining high precision, sensitivity, and specificity. These improvements demonstrate the effectiveness of combining ViT models with ElasticNet to diagnose meniscal tears. The findings highlight the potential of vision transformer models, in conjunction with ElasticNet, to provide rapid and highly accurate diagnostic assistance for meniscal injuries. This methodology shows promise for application to other medical diagnostic domains, offering valuable advancements in healthcare technology.},
  archive      = {J_SUPERC},
  author       = {Genç, Hasan and Koç, Canan and Yüzgeç Özdemir, Esra and Özyurt, Fatih},
  doi          = {10.1007/s11227-025-07103-2},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {An innovative approach to classify meniscus tears by reducing vision transformers features with elasticnet approach},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy golden jackal optimization for engineering design. <em>SUPERC</em>, <em>81</em>(4), 1--60. (<a href='https://doi.org/10.1007/s11227-025-07106-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Golden Jackal Optimization algorithm (GJO) is a Swarm Intelligence (SI) algorithm utilized for tackling arduous problems in undefined search spaces. In order to address the issues of slow convergence and difficulty in evading local optima encountered by GJO, the Multi-Strategy Golden Jackal Optimization (MSGJO) algorithm is proposed. Three strategies were implemented to enhance the original GJO. Firstly, the utilization of a Good Point Set, as opposed to random numbers, improves the quality of the initial population. Secondly, the introduction of a Quasi-Opposition-Based Learning strategy facilitates the balancing of algorithmic exploration and exploitation capabilities, leading to enhanced convergence efficiency. Lastly, the maintenance of population diversity during the iterative process is achieved through the adoption of the Cauchy mutation and chaotic circle perturbation strategies. A comparative analysis was conducted on 23 benchmark functions using fourteen SI algorithms. Additionally, MSGJO was applied to the CEC2019 competition suite, successfully solving two distinct engineering design problems. The results demonstrate that MSGJO exhibits significant superiority not only in solving problems involving global optimal solutions but also in addressing challenging constrained problems. The code for this study will be available at https://github.com/ProfYangPaperCode/MSGJO-code .},
  archive      = {J_SUPERC},
  author       = {Yang, Wenbiao and Lai, Tingfeng and Fang, Yuhui},
  doi          = {10.1007/s11227-025-07106-z},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--60},
  shortjournal = {J. Supercomput.},
  title        = {Multi-strategy golden jackal optimization for engineering design},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning inference optimisation for IoT: Conv2D-ReLU-BN layer fusion and quantisation. <em>SUPERC</em>, <em>81</em>(4), 1--20. (<a href='https://doi.org/10.1007/s11227-025-07107-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of deep learning models on resource-constrained devices requires the development of new optimisation techniques to effectively exploit the computational and storage capacities of these devices. Thus, the primary objective of this research is to introduce an innovative and efficient approach for fusing convolution (or fully connected), ReLU, and batch normalisation neural network layers into a unified, single-layer structure, alongside a quantisation method for this new fused layer. This approach has been evaluated using the Arduino BLE Sense ARM Cortex-M4 and the Arduino Portenta H7 Lite ARM Cortex-M4 and M7 processors, known for their widespread adoption in various Internet of Things devices. Depending on the microcontroller unit and compilation flag used, the fused layers can reduce the overall execution time by up to 1.53 $$\times$$ , and on individual layers it can reach a speedup of 2.95 $$\times$$ .},
  archive      = {J_SUPERC},
  author       = {Mestre, Jose I. and Barrachina, Sergio and Quezada, Darwin and Dolz, Manuel F.},
  doi          = {10.1007/s11227-025-07107-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Deep learning inference optimisation for IoT: Conv2D-ReLU-BN layer fusion and quantisation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sql injection detection algorithm based on bi-LSTM and integrated feature selection. <em>SUPERC</em>, <em>81</em>(4), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07109-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SQL injection attacks represent a significant web security threat. However, due to their diversity and variability, existing detection methods often suffer from high false alarm rates and low accuracy. To address these challenges, this paper proposes an efficient and lightweight SQL injection detection model, SQLLS, based on a bidirectional long short-term memory network. Initially, the term frequency-inverse document frequency algorithm is employed to convert SQL statements into numerical feature vectors, enabling the extraction of key information and enhancing the model’s ability to characterize the input data. Subsequently, an integrated feature selection method, GFC, is presented, which combines multiple techniques to improve both the accuracy and robustness of feature selection. Specifically, gradient boosting regression trees are used to evaluate the importance of each feature, identifying those most significant for classification; Fisher score filters out features that can effectively distinguish between SQL injections and non-injections based on statistical significance; and the chi-square test further evaluates the relevance of the features with respect to the target label, ensuring that the selected features are highly correlated with SQL injection detection. After feature selection, a mixed precision training technique is utilized to reduce memory consumption and enhance training efficiency. To reduce the complexity of the bidirectional long short-term memory model and improve its computational efficiency, this paper introduces a pruning technique that minimizes computational overhead by removing unimportant weight connections, thereby improving the model’s operational efficiency. Experimental results demonstrate that the SQLLS model achieves an accuracy of 100%, a low false alarm rate of 0.154%, and significantly shorter running times compared to existing models.},
  archive      = {J_SUPERC},
  author       = {Qin, Qiurong and Li, Yueqin and Mi, Yajie and Shen, Jinhui and Wu, Kexin and Wang, Zhenzhao},
  doi          = {10.1007/s11227-025-07109-w},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Sql injection detection algorithm based on bi-LSTM and integrated feature selection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A progressive interaction model for multimodal sarcasm detection. <em>SUPERC</em>, <em>81</em>(4), 1--28. (<a href='https://doi.org/10.1007/s11227-025-07110-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection aims to determine whether conflicting semantics arise in different modalities. Existing research, primarily relying on direct interaction between image and text, limits model performance in sarcasm detection due to the difficulty in cross-modal alignment and information integration caused by semantic differences between the modalities. In this paper, we propose a progressive interaction approach. First, unlike the traditional direct interaction approach, the pre-interaction approach is adopted by bridging the image and text through attributes to reduce the semantic difference between them. Then, contrastive learning is employed to align image and text features for better synchronization of image-text semantics. Finally, sarcasm cues are captured through the interaction between image and text for detecting sarcasm. In the pre-interaction phase, we design different components for image and text respectively for their interaction with attributes. Experiments demonstrate the excellent performance of our method on a multimodal sarcasm detection task.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yulei and Zhu, Guangli and Ding, Yuanyuan and Wei, Zhongliang and Chen, Lei and Li, Kuan-Ching},
  doi          = {10.1007/s11227-025-07110-3},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {A progressive interaction model for multimodal sarcasm detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward more secure constructions of flexible multi-client functional encryption schemes. <em>SUPERC</em>, <em>81</em>(4), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07112-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A flexible multi-client functional encryption scheme for set intersection (FMCFE-SI) [Rafiee, J. Supercomput 2023] is a cryptographic primitive that enables an evaluator to learn the intersection from any arbitrary subsets of a fixed client set, without need to learn the plaintext set of each individual client. In [Rafiee, J. Supercomput 2023], several security notions for FMCFE-SI, as well as the relations between them, are proposed. Constructing an FMCFE-SI with indistinguishability security against adaptive adversary (aIND) has remained as a challenging problem so far. In this paper, we propose a new FMCFE-SI construction to achieve this security notion in the random oracle model. We prove the security of our FMCFE-SI construction under Decisional Diffie–Hellman assumption in G1 (DDH1) in the bilinear groups. Our FMCFE-SI construction, compared to other existing constructions, does not increase the computational and storage overheads despite satisfying the stronger security notion.},
  archive      = {J_SUPERC},
  author       = {Rafiee, Mojtaba},
  doi          = {10.1007/s11227-025-07112-1},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Toward more secure constructions of flexible multi-client functional encryption schemes},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective and efficient conditional contrast for data-free knowledge distillation with low memory. <em>SUPERC</em>, <em>81</em>(4), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07115-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-free knowledge distillation has recently gained significant attention in the field of model compression, as it enables knowledge transfer from a trained teacher model to a smaller student model without requiring original training data. Current methods often utilize generative adversarial networks (GANs) to synthesize fake samples, but this approach introduces two main issues. First, mode collapse leads to instances lacking diversity for downstream tasks. Second, inefficient instance synthesis makes existing methods too time-consuming and thus difficult to adapt to large-scale datasets. Finally, the increased memory footprint makes deployment difficult. In this paper, we propose a novel paradigm called conditional contrast for data-free knowledge distillation (CC-DFKD), which integrates conditional generative adversarial network (CGAN) and contrastive learning. CGAN synthesizes class-specific diverse images to address the diversity challenge, while contrastive learning enriches the student model’s feature representations to tackle the reality challenge. Additionally, compared with the recent work, simplification of the distillation loss reduces instance generation time and memory usage during operation, achieving significant speed improvements (half an hour to nine hours reduction) and lower GPU memory usage (2000–5000 MB reduction). Empirical results across multiple datasets validate CC-DFKD’s effectiveness and efficiency under low-memory conditions. Code is available at: https://github.com/jcynxu/CC-DFKD .},
  archive      = {J_SUPERC},
  author       = {Jiang, Chenyang and Li, Zhendong and Yang, Jun and Wu, Yiqiang and Li, Shuai},
  doi          = {10.1007/s11227-025-07115-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Effective and efficient conditional contrast for data-free knowledge distillation with low memory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDT-IDS: Graph-based decision tree intrusion detection system for controller area network. <em>SUPERC</em>, <em>81</em>(4), 1--30. (<a href='https://doi.org/10.1007/s11227-025-07116-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of automotive technology, the security of in-vehicle networks (IVN) has received increasing attention. The controller area network (CAN), widely used for in-vehicle communication, faces significant security risks due to its inherent vulnerabilities. These risks can lead to attacks, data leakage, and abnormal functioning of vehicle systems. Currently, the mainstream security approach is the intrusion detection system (IDS). Graph-based IDSs have been widely studied for their ability to represent the relationships between CAN messages through nodes and edges, providing an intuitive and structured analysis that enables effective detection of various types of attacks. However, existing graph-based methods rely on basic features, such as the number of nodes, edges, and the maximum degree, which are insufficient for capturing the complex characteristics of spoofing and replay attacks, resulting in suboptimal detection accuracy. To address this, we propose a graph-based decision tree IDS, named GDT-IDS, specifically tailored to the characteristics of spoofing and replay attacks. By analyzing these attack types, we introduce three novel graph-based features—time difference, betweenness centrality, and graph density—that significantly enhance detection accuracy. Moreover, our method can perform multi-class classification, effectively handling mixed attack scenarios. The use of a decision tree model ensures the process remains lightweight and interpretable, making it suitable for resource-constrained systems like vehicles.},
  archive      = {J_SUPERC},
  author       = {Ye, Pengdong and Liang, Yanhua and Bie, Yutao and Qin, Guihe and Song, Jiaru and Wang, Yingqing and Liu, Wanning},
  doi          = {10.1007/s11227-025-07116-x},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {GDT-IDS: Graph-based decision tree intrusion detection system for controller area network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Storage access optimization for efficient GPU-centric information retrieval. <em>SUPERC</em>, <em>81</em>(4), 1--18. (<a href='https://doi.org/10.1007/s11227-025-07118-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of AI/ML workloads has outpaced the capabilities of CPU-centric architectures to deliver the required data throughput and compute efficiency. This paper introduces a GPU-centric architecture leveraging GPUDirect Storage (GDS) to transfer data directly from SSDs to GPU memory, bypassing CPU bottlenecks and enabling high-throughput data paths. We propose Embedding from Storage Pipelined Network (ESPN) and its extension, ESPN-LIVE, which employ optimizations like data prefetching and on-demand embedding generation to align storage latency with GPU throughput. Experiments show ESPN reduces query latency by up to $$3.9\times$$ , cuts memory usage by up to $$16\times$$ , and improves throughput by up to 68%. ESPN-LIVE eliminates the need to store multi-vector embeddings by dynamically computing document representations, reducing storage costs by up to $$16\times$$ , and making it particularly effective for single-query systems. These results highlight the potential of SSD-GPU integration for scalable, high-performance AI/ML workloads in information retrieval and LLM applications.},
  archive      = {J_SUPERC},
  author       = {Shrestha, Susav and Gautam, Aayush and Reddy, Narasimha},
  doi          = {10.1007/s11227-025-07118-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {Storage access optimization for efficient GPU-centric information retrieval},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmentation and debiasing for signers in signer-independent sign language translation. <em>SUPERC</em>, <em>81</em>(4), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07119-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language translation (SLT) aims to convert sign language videos into corresponding text, bridging the communication gap between the deaf and hearing communities. A practical SLT system must generalize well to unseen signers. This requirement necessitates that the SLT system maintains good performance in a signer-independent setting, where the model encounters signers who were not present in the training data. However, existing sign language datasets often lack diversity in signers and exhibit biases toward signers, which leads to suboptimal generalization capabilities of current SLT models. Moreover, current signer-independent SLT methods heavily rely on the multiple signer identity labels in the dataset. To address this issue, we propose a method that does not require signer identity labels: DADS (data augmentation and debiasing for signer) for signer-independent sign language translation. Firstly, we propose signers-oriented data augmentation, which consists of two components: the data augmentation based on adversarial training (DAAT) and data augmentation based on diffusion model (DADM). DAAT uses model gradients to create adversarial examples, while DADM employs diverse prompts to produce high-quality, signer-diverse sign language data. By combining these two data augmentation methods, we alleviate the scarcity of sign language data and significantly enhance the diversity of signers in the dataset. Secondly, we introduce signer-oriented debiasing (SD). Specifically, we use a signer-biased classifier to capture the biases present in the dataset and a signer-debiased classifier to learn debiased features. This process helps to comprehensively eliminate the model’s bias toward signers, thereby improving its generalization and robustness in signer-independent scenarios. Our experimental results demonstrate that DADS enhances the performance of models in signer-independent setting and also shows excellent performance under more challenging common corruption setting.},
  archive      = {J_SUPERC},
  author       = {Fu, Honghao and Chen, Yidong},
  doi          = {10.1007/s11227-025-07119-8},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Data augmentation and debiasing for signers in signer-independent sign language translation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCNet-YOLO: A symmetric convolution network for multi-scenario ship detection based on YOLOv7. <em>SUPERC</em>, <em>81</em>(4), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07120-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) can work under all-weather and all-day conditions, and it has been widely applied in maritime fields. However, existing algorithms based on SAR still have limitations in ship detection due to the complex scenarios and small-sized targets. In order to solve those problems, a Symmetric Convolution Network based on YOLOv7 (SCNet-YOLO) was proposed for SAR ship target detection. Firstly, we have designed a Symmetric Convolutional structure (SConv), it is highly effective in enhancing the capability of feature extraction for small targets. Secondly, we add the dynamic head to fuse the attention mechanism and better capture the ship targets of various sizes. Finally, the WIoU is used as the loss function to capture the border information while avoiding overfitting. The experiment results show that the SCNet-YOLO proposed in this paper achieves a precision of 93.5% and mAP50:95 of 68.1% on the HRSID, and achieves a precision of 96.1% and mAP50:95 of 71.7% on the SSDD, and it is superior to other state-of-the-art SAR ship detection methods in the overall performance.},
  archive      = {J_SUPERC},
  author       = {Zhou, Weina and Yang, Yuqi and Zhao, Ming and Hu, Wenhua},
  doi          = {10.1007/s11227-025-07120-1},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {SCNet-YOLO: A symmetric convolution network for multi-scenario ship detection based on YOLOv7},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI model auditing scheme towards cloud-edge high-performance computing. <em>SUPERC</em>, <em>81</em>(4), 1--19. (<a href='https://doi.org/10.1007/s11227-025-07121-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance Computing (HPC) uses high-performance computers or computer clusters to handle complex computational tasks. Moreover, the cloud-edge architecture is well-suited for this computing model. In many HPC scenarios, specific AI models are trained on HPC and then distributed to edge servers closer to users, providing low-latency and high-efficiency intelligent services. However, ensuring the integrity of models presents a significant challenge, as even minor changes to model parameters can have substantial negative impacts on real-world applications. For example, a single erroneous instruction in intelligent transportation could lead to a traffic accident. To address this, periodic auditing of AI models stored on edge servers is necessary. We propose the AI Model Auditing scheme (AIMA), which leverages the characteristic that multiple edge servers locally store the model. A distributed and collaborative model integrity verification method is designed, eliminating the need for HPC to expend significant computational resources on generating homomorphic verification tags, which constitute the primary computational overhead in existing data auditing schemes. Additionally, we developed a consensus protocol tailored for AI model auditing based on Practical Byzantine Fault Tolerance (PBFT). By constructing a blockchain to record audit results, HPC can obtain tamper-proof model audit records. Furthermore, we introduce update strategies for AI models and edge server groups, enhancing the practicality of the proposed scheme. Finally, we analyze the security features of the scheme and validate its efficiency in a simulated cloud-edge HPC environment. Experimental results demonstrate that AIMA incurs lower computational overhead than the compared schemes during both the audit preparation and execution phases, while the computational and storage costs introduced by consensus remain entirely acceptable.},
  archive      = {J_SUPERC},
  author       = {Li, Yi and Zheng, Wenying and Ji, Sai},
  doi          = {10.1007/s11227-025-07121-0},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {AI model auditing scheme towards cloud-edge high-performance computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing network intrusion detection by employing mondrian forests to achieve multiple attack classification. <em>SUPERC</em>, <em>81</em>(4), 1--24. (<a href='https://doi.org/10.1007/s11227-025-07123-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online intrusion detection, a classification model able to identify different types of attacks is valuable as it can help users respond instantly and adequately against unexpected adversaries. This paper presents a new active learning mechanism to secure effective multiple attack classification for online intrusion detection. The new mechanism is built over our previous lifelong sampling (LS) mechanism which uses its random forest (RF) operation to pursue favorable binary classification in online environments. The new mechanism advances the LS-RF framework by using the Mondrian forest (MF)—an innate lifelong learning procedure able to avoid cumulative training data without additional effort—to develop a desired multiple classification architecture. We choose MF to realize online multiple classification mainly because it can train a model to identify different attack types in the online process and can hence fortify classification and detection to help users act promptly against sudden maliciousness. Experimental results show that, by effective model training, our Multi-Classification mechanism performs desirable classification and detection—in terms of precision, accuracy and F1-scores—at moderate time cost (which is feasible and negligible when compared with the significant performance gain).},
  archive      = {J_SUPERC},
  author       = {Chuang, Po-Jen and Huang, Pang-Yu},
  doi          = {10.1007/s11227-025-07123-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing network intrusion detection by employing mondrian forests to achieve multiple attack classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis on component reliability of (n, k)-star networks. <em>SUPERC</em>, <em>81</em>(4), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07128-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability of interconnection networks has been a significant attention for parallel distributed computing. In the design of interconnection networks, one of the most fundamental concerns is the topological reliability, which can be usually characterized by the functional subsystem of the underlying network topology. Typically, the largest connected component in a faulty network is referred as the functional subsystem without severe performance degradation, which greatly reflects the communication ability and efficiency of interprocessors in the surviving network. The paper first characterizes all possibilities of small components when deleting at most $$n+4k-10$$ vertices from the (n, k)-star network for $$n \ge 8$$ , $$k \ge 4$$ , $$n-k \ge 4$$ . Then, we present a minimum neighborhood search algorithm to find the minimum number of neighbors of small components in terms of interconnection rules of (n, k)-star networks. Finally, we implement simulation experiments and analyze its performance under different iterations. These findings contribute to the construction of highly reliable interconnection network systems.},
  archive      = {J_SUPERC},
  author       = {Wang, Zhihang and Liu, Jiafei and Lee, Chia-Wei and Wu, Jingli and Li, Gaoshi},
  doi          = {10.1007/s11227-025-07128-7},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {An analysis on component reliability of (n, k)-star networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tp-yolov8: A lightweight and accurate model for traffic accident recognition. <em>SUPERC</em>, <em>81</em>(4), 1--31. (<a href='https://doi.org/10.1007/s11227-025-07129-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accident detection is an important part of road safety, impacting the lives of those involved and others on the road. Using surveillance cameras on traffic poles to detect accidents poses unique challenges, such as incomplete dataset categories, small-sized detection objects, and the need for lightweight models. Current traffic accident recognition algorithms, while effective in detection, often require extensive resources, making deployment on edge devices difficult. This paper proposes a more accurate and lightweight traffic accident recognition model based on YOLOv8, optimized for traffic pole monitoring and deployment on edge devices. To improve small object detection, we made improvements to the neck. We modified the neck by adding a detection layer for small-sized objects using large-scale feature maps, along with a dedicated small object detection head (SODL-SODH). Additionally, we design a lightweight cross-scale feature fusion module (LCSFFM) to optimize the PAN-FPN structure, reducing model parameters and computational complexity while enhancing small-target detection. In the downsampling layer, we incorporate the squeeze-excited aggregate spatial attention module (SEASAM) into the C2F module to help the network focus on essential image information, with minimal impact on model parameters and computational complexity. To address dataset limitations, we built the traffic accident-type (TAT) dataset for training and evaluation, and validated it against other advanced methods. Experimental results show that our model outperforms the baseline on the TAT dataset, improving the mAP0.5 by 1% and reducing parameters by 25.9%. On the BDD-IW dataset, our TP-YOLOv8s outperforms other methods in terms of accuracy. Compared with the best other methods, it improves the mAP0.5 index by 1.4% and reduces the number of parameters by 84.1%.},
  archive      = {J_SUPERC},
  author       = {Ning, Zhaole and Zhang, Tianze and Li, Xin and Wu, Aiying and Shi, Gang},
  doi          = {10.1007/s11227-025-07129-6},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Tp-yolov8: A lightweight and accurate model for traffic accident recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AccPRET: A proposal of a multicore architecture with reconfigurable accelerators and time predictability. <em>SUPERC</em>, <em>81</em>(4), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07131-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multicore processors become the standard for performance scaling, challenges related to predictability and repeatability arise, particularly in real-time and cyber-physical systems. Precision-Timed (PRET) architectures address this by enforcing deterministic execution, but current designs primarily exploit thread-level parallelism (TLP) while underutilizing instruction-level parallelism (ILP). This limitation can lead to suboptimal performance in workloads with limited TLP. To address this, we propose AccPRET, a novel quad-core architecture that integrates a coarse-grained reconfigurable array (CGRA) with a PRET processor, enabling the simultaneous exploitation of TLP and ILP while maintaining real-time guarantees. Our FPGA-based evaluation demonstrates that AccPRET achieves speedups of up to 6.69 × over VLIW architectures and 6.33 × over out-of-order architectures, with a 36.76 × improvement in multicore execution over single-threaded execution. Furthermore, AccPRET delivers these performance gains while consuming 4% less area than an out-of-order processor and only 2.2x the area of a VLIW processor. These results highlight the viability of integrating reconfigurable computing into deterministic architectures, offering a promising approach to bridging high performance and predictable execution. Future research will explore energy-efficient scheduling, hybrid memory hierarchies, scalable interconnects, and compiler/toolchain support to further enhance AccPRET’s capabilities in real-time and embedded computing domains.},
  archive      = {J_SUPERC},
  author       = {Siqueira, Hadley and Kreutz, Marcio},
  doi          = {10.1007/s11227-025-07131-y},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {AccPRET: A proposal of a multicore architecture with reconfigurable accelerators and time predictability},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controllable face soft-biometric privacy enhancement based on attribute disentanglement. <em>SUPERC</em>, <em>81</em>(4), 1--29. (<a href='https://doi.org/10.1007/s11227-025-07134-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though the widespread application of face recognition systems facilitates user authentication and identification, it may result in potential changes in user privacy concerns. This is mainly because untrustworthy service providers utilize advanced deep learning models to automatically extract users’ soft-biometric attributes without user consent, thereby posing significant privacy threats. Existing attribute privacy protection methods can obscure multi-attribute while preserving identity information, but they fail to adjust the level of privacy protection, so they have limited flexibility in various scenarios. To solve this problem, this paper proposes an attribute disentanglement network (ADNet) to generate perturbed images using attribute codes from the attribute disentanglement module (ADM), thereby obfuscating arbitrary classifiers while preserving identity recognition. Specifically, the designed ADM can separate attribute-related and attribute-unrelated codes from attribute codes, realizing privacy protection during the transformation of attribute-related code and preserving unrelated information. Moreover, a control factor $$\alpha$$ is used to adjust the degree of transformation, and its value can be adjusted to meet various requirements. Extensive experimental results indicate that ADNet provides controllability for multi-attribute privacy protection while maintaining identity recognition utility. It meets the demands of different protection scenarios and outperforms previous soft-biometric privacy protection strategies.},
  archive      = {J_SUPERC},
  author       = {Huang, Weidi and Yao, Zhiqiang and Jin, Biao and Chen, Zheyu and Wang, Yue},
  doi          = {10.1007/s11227-025-07134-9},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Controllable face soft-biometric privacy enhancement based on attribute disentanglement},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vision-based inspection system for pharmaceutical production line. <em>SUPERC</em>, <em>81</em>(4), 1--23. (<a href='https://doi.org/10.1007/s11227-025-07135-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection in filled vials is significant for the pharmaceutical safety. Due to the weak features and different scales of defects, it leads to missed and false inspection. In this paper, we firstly design a data acquisition solution and create the custom datasets VialG1_DET, VialG2_DET, VialG3_DET. Secondly, we design a multi-workstation inspection system combining traditional image processing algorithms and deep learning object detection algorithms to detect defects of surface and contents in vials. We propose Defect Detection of Surface and Contents in Vials (DDSCNet) by designing Quadra Fusion and Attention (QUFUAtt) module which enhances the capability of feature fusion in network, introducing the self-attention and convolution (ACmix) which focuses on the defective areas, and Linear Deformable Convolution which extracts the weak features of defects. Our experiments show that the proposed DDSCNet achieves 76.7% mean Average Precision (mAP@0.5) on the VialG1_DET, 65.9% mAP@0.5 on the VialG2_DET, along with 86.9% mAP@0.5 on the VialG3_DET with low computational complexity of 9.3GFLOPS, and outperforms YOLOv11 by 3.5% mAP@0.5.},
  archive      = {J_SUPERC},
  author       = {Xu, Haixia and Xu, Yuting and Hu, Kaiyu},
  doi          = {10.1007/s11227-025-07135-8},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {A vision-based inspection system for pharmaceutical production line},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static gesture recognition based on thermal imaging sensors. <em>SUPERC</em>, <em>81</em>(4), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07140-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The applicability of gesture recognition technology in a variety of scenarios within the field of human–computer interaction has been demonstrated due to the flexibility and non-contact nature of the technology. In particular, thermal imaging technology is not limited by lighting conditions, which is effectively reduces risk by capturing only thermal radiation rather than detailed visual features. In this study, a low-resolution 32 × 24 pixels end-to-end embedded infrared thermal image camera gesture recognition system is developed. A thermal image gesture dataset of 4500 images is constructed to train and evaluate the system. This study investigates the effects of incorporating the spatial transformer network (STN) attention mechanism on improving gesture recognition accuracy. Thus, a new method combines lightweight convolutional neural networks and STN is proposed. Additionally, the proposed method achieves a recognition accuracy of 98.5% and inference time of only 59 ms per frame on embedded devices when tested on a self-made infrared thermal image sign language gesture dataset, outperforming mainstream lightweight models.},
  archive      = {J_SUPERC},
  author       = {Zhang, Zhi-Yuan and Ren, Hao and Li, Hao and Yuan, Kang-Hui and Zhu, Chu-Feng},
  doi          = {10.1007/s11227-025-07140-x},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Static gesture recognition based on thermal imaging sensors},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on mitigating popularity bias in federal recommendation based on users’ behavior. <em>SUPERC</em>, <em>81</em>(4), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07144-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the enhancement of user privacy awareness and government regulations on privacy protection, the combination of personalized recommendation technology and privacy protection technology has become a trend. Although federated recommendation technology effectively addresses the issue of user privacy leakage, our research has found the phenomenon of popularity bias in federated recommendation, where popular products are prioritized for recommendation. This phenomenon results in unfair competition among products and affects e-commerce platform development. It is imperative to address the issue of popularity bias in recommendations. In this paper, we study the issue of popularity bias in recommendation systems under the federated learning framework. First, we quantitatively analyze the popularity bias in federated recommendation models, demonstrating the presence of strong popularity bias in their recommendation results. Secondly, drawing upon psychological theories and considering the impact of social groups and exposure effects on user behavior, we explore the behavioral influences contributing to popularity bias and design a debiasing method suitable for federated recommendations. Finally, we propose a strategy for mitigating popularity bias within the federated recommendation framework, which can simultaneously address both privacy protection and popularity bias, tackling these two significant issues. We validate the effectiveness of our debiasing method on two publicly available datasets, achieving data security while reducing popularity bias and improving recommendation accuracy.},
  archive      = {J_SUPERC},
  author       = {Li, Peng and Zhu, Xinru and Li, Xiaoshan and Huo, Baofeng},
  doi          = {10.1007/s11227-025-07144-7},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Research on mitigating popularity bias in federal recommendation based on users’ behavior},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An additive feature fusion attention based on YOLO network for aircraft skin damage detection. <em>SUPERC</em>, <em>81</em>(4), 1--27. (<a href='https://doi.org/10.1007/s11227-025-07148-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft skin damage detection is crucial for ensuring flight safety. This article presents an enhanced object detection algorithm tailored for scenarios with low image complexity. Initially, considering the low image complexity inherent in aircraft skin damage data, an additive feature fusion attention mechanism is proposed to enhance the YOLOv7 neck feature fusion approach, aiming at diminishing the computational and parametric loads of the model. Secondly, the Inner-CIoU loss function is enhanced and the dynamic Inner-CIoU loss function is introduced to substitute the original CIoU loss function in YOLOv7. Subsequently, to validate the proposed method, an Aircraft Skin Damage Dataset encompassing five types of damage, with image backgrounds solely comprising the aircraft skin, is generated. Lastly, experimental results demonstrate that the proposed additive feature fusion attention mechanism, tailored for scenarios like Aircraft Skin Damage Dataset with low image complexity, significantly reduces the model parameters without compromising model accuracy. Compared to the YOLOv7, the proposed method improves the detection accuracy by 1.6% and reduces the number of parameters by 19.4%; the enhanced YOLOv7 model is compared with mainstream object detection models to illustrate the superiority of the improved algorithm. The Pascal VOC2007 Database and Aluminum Profile Surface Detection Database are selected as control groups, which are used to further validate the correctness of the proposed theory, namely the additive feature fusion attention mechanism.},
  archive      = {J_SUPERC},
  author       = {Wu, Jun and Zhang, Yajing and Shan, Tengfei and Xing, Zhiwei and Chen, Jiusheng and Guo, Runxia},
  doi          = {10.1007/s11227-025-07148-3},
  journal      = {The Journal of Supercomputing},
  month        = {3},
  number       = {4},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {An additive feature fusion attention based on YOLO network for aircraft skin damage detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying influential nodes in complex networks by adjusted feature contributions and neighborhood impact. <em>SUPERC</em>, <em>81</em>(3), 1--39. (<a href='https://doi.org/10.1007/s11227-024-06645-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the spreading ability of nodes is considered a fundamental issue in network science, with numerous applications in controlling system failure, rumors spreading, and product advertising. Many methods have been proposed to identify influential nodes, which, despite their advantages, suffer from high time complexity, low accuracy, and low resolution. This paper presents a feature based on K-Shell and the degree applied to the node and its neighbors. It adjusts the contribution of various features. The number of selected neighbors and the influence of each neighbor are chosen according to the structural features of the graph. The actual spreading ability of the node is measured with the Susceptible-Infected-Recovered (SIR) model, and the evaluations include accuracy, precision, resolution, correlation, Kolmogorov–Smirnov Test, and time complexity. Assessing 14 real-world and 20 artificial networks compared to 12 recent methods, such as the HGSM (Hybrid Global Structure Model), indicates that the proposed method performs best in various aspects.},
  archive      = {J_SUPERC},
  author       = {Esfandiari, Shima and Fakhrahmad, Seyed Mostafa},
  doi          = {10.1007/s11227-024-06645-1},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--39},
  shortjournal = {J. Supercomput.},
  title        = {Identifying influential nodes in complex networks by adjusted feature contributions and neighborhood impact},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online real-time energy consumption optimization with resistance to server switch jitter for server clusters. <em>SUPERC</em>, <em>81</em>(3), 1--28. (<a href='https://doi.org/10.1007/s11227-024-06827-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adjusting the deployment of each server in a server cluster in real-time and online based on a changing load has important considerations. In response to the deficiencies in the existing research on server switch jitter and real-time optimization, this paper proposes a periodic energy consumption optimization strategy based on mixed integer programming (MIP) for server clusters. During an optimization period, the strategy allows the CPU of the server to switch between adjacent frequencies to optimize cluster energy consumption at a granular level. First, we describe cluster energy optimization as a basic MIP model, with a reasonable definition of the decision variables and the modeling of the server load and power. Then, we include the server switch overhead in the objective function of the model, considering the joint optimization of multiple periods. Finally, we design an efficient solution scheme based on Gurobi and create two solution adjustment schemes that can reduce CPU frequency switching. The test results reveal that the proposed strategy can effectively suppress server switch jitter and can be carried out in real-time. The extra power cost of reducing CPU frequency switching is also evaluated and analyzed in the testing section.},
  archive      = {J_SUPERC},
  author       = {Xiong, Zhi and Tan, Linhui and Xu, Jianlong and Cai, Lingru},
  doi          = {10.1007/s11227-024-06827-x},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Online real-time energy consumption optimization with resistance to server switch jitter for server clusters},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VPSNet: 3D object detection with voxel purification and fully sparse convolutional networks. <em>SUPERC</em>, <em>81</em>(3), 1--17. (<a href='https://doi.org/10.1007/s11227-024-06890-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional object detection presents a significant challenge in the realm of 3D scene understanding. In the context of autonomous driving via LiDAR, fully sparse detection models that are based on sparse convolution are increasingly being adopted as a prevalent trend. However, these methods ignore the redundant background voxel information in the scene. To fill this gap, this paper presents a fully sparse 3D object detection model based on voxel feature refinement (VPSNet), which aims to select valuable voxels and reduce background voxels, thereby reducing computational consumption. In addition, a novel dilation sparse convolutional backbone network architecture is designed to enhance the model’s receptive field, thereby capturing richer voxel information. This paper presents numerous experiments conducting using the KITTI 3D object detection dataset and nuScenes dataset to prove the effectiveness of the model. Notably, the model achieves a 2.2% improvement in the mean average precision (mAP) on the nuScenes dataset compared to the SOTA models.},
  archive      = {J_SUPERC},
  author       = {Wen, Jia and Zhang, Qi and Zhang, Guanghao},
  doi          = {10.1007/s11227-024-06890-4},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {VPSNet: 3D object detection with voxel purification and fully sparse convolutional networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergent data-driven workflows for open radiation calculations: An exportable methodology to any field. <em>SUPERC</em>, <em>81</em>(3), 1--26. (<a href='https://doi.org/10.1007/s11227-024-06894-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast growth worldwide of linkable scientific datasets supposes significant challenges in their management and reuse. Large experiments, such as the Latin American Giant Observatory, generate volumes of data that can benefit other kinds of studies. In this sense, there is a modular ecosystem of external radiation tools that should harvest and supply datasets without being part of the main pipeline. Workflows for personal dose estimation, muongraphy in volcanology or mining, or aircraft dose calculations are built with different privacy policies and exploitation licenses. Every numerical method has its own requirements and only parts could make use of the Collaboration’s resources, which implies the convergence with other computing infrastructures. Our work focuses on developing an agnostic methodology to address these challenges while promoting open science. Leveraging the encapsulation of software in nested containers, where the inner layers accomplish specific standardization slices and calculations, the wrapper compiles metadata and data generated and publishes them. All this allows researchers to build a data-driven computer continuum that complies with the findable, accessible, interoperable, and reusable principles. The approach has been successfully tested in the computer-demanding field of radiation-matter interaction with humans, showing the orchestration with the regular pipeline for diverse applications. Moreover, it has been integrated into public or federated cloud environments as well as into local clusters and personal computers to ensure the portability and scalability of the simulations. We postulate that this successful use case can be customized to any other field.},
  archive      = {J_SUPERC},
  author       = {Núñez-Chongo, Osiris and Asorey, Hernán and Rubio-Montero, Antonio Juan and Suárez-Durán, Mauricio and Mayo-García, Rafael and Carretero, Manuel},
  doi          = {10.1007/s11227-024-06894-0},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Convergent data-driven workflows for open radiation calculations: An exportable methodology to any field},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of energy-efficient and high-speed hybrid decimal adder. <em>SUPERC</em>, <em>81</em>(3), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06897-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decimal computations have attracted a lot of attentions in computer science in recent years due to the increasing significance of decimal-based financial and commercial applications. Addition, a fundamental arithmetic operator, is crucial for performing more complex functions like multiplication and division. Thus, designing an efficient decimal addition method is essential for improving the overall performance of decimal systems. In response, this paper introduces a new hybrid decimal adder. The proposed adder integrates the Carry Skip adder with the Carry Select adder to improve delay, power consumption and area metrics. Simulations and comparisons with recent state-of-the-art Binary Coded Decimal adders highlight the advantages of our design in terms of Power-Delay Product (PDP) and Area-Delay Product (ADP). The proposed adder achieves a 62.25% reduction in PDP and a 48% reduction in ADP. Experiments and simulations were carried out using VHDL and ModelSim SE 10.6f on 90 nm CMOS technology.},
  archive      = {J_SUPERC},
  author       = {Mashayekhi, Negin and Jaberipur, Ghassem and Reshadinezhad, Mohammad Reza and Moghimi, Shekoofeh},
  doi          = {10.1007/s11227-024-06897-x},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Design of energy-efficient and high-speed hybrid decimal adder},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy enhanced dandelion optimizer based on elliptic approximation strategy and adaptive fitness-distance-similarity balance for solar photovoltaic parameter estimation. <em>SUPERC</em>, <em>81</em>(3), 1--74. (<a href='https://doi.org/10.1007/s11227-024-06899-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dandelion optimizer (DO) is an advanced swarm intelligence algorithm, but still exhibits certain limitations. This paper proposes an enhanced DO named EFDO. Firstly, a hybrid piecewise logistic-circle map is proposed to generate a uniform and high-quality initial population with superior ergodicity and diversity. Secondly, based on elliptic curves, we propose a novel approximation strategy for the first time, and integrate it into the DO, which improves the solution accuracy, and effectively assists the algorithm in avoiding entrapment in local optima. Thirdly, we innovatively incorporate a new similarity metric operator into the original fitness-distance balance method, creating a novel selection strategy named adaptive fitness-distance-similarity balance. This new strategy can effectively explore potential excellent solutions, increase the diversity and prevent premature convergence. EFDO achieves better performance compared against twelve algorithms on the CEC2017 benchmark functions and six engineering problems. Finally, EFDO is applied to parameter estimation of photovoltaic models, underscoring its application capability.},
  archive      = {J_SUPERC},
  author       = {Liu, Tianbao and Feng, Zhe},
  doi          = {10.1007/s11227-024-06899-9},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--74},
  shortjournal = {J. Supercomput.},
  title        = {Multi-strategy enhanced dandelion optimizer based on elliptic approximation strategy and adaptive fitness-distance-similarity balance for solar photovoltaic parameter estimation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P2PPO: Parallel residual network and prioritized experience replay enhanced PPO for task offloading and resource allocation in SatEC. <em>SUPERC</em>, <em>81</em>(3), 1--27. (<a href='https://doi.org/10.1007/s11227-024-06900-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite edge computing (SatEC) has received much attention from the academic community due to its extensive coverage capabilities and latency-reducing properties. Optimizing computing offloading and resource allocation presents a significant challenge for SatEC. For the dynamic changes in the satellite network environment and large-scale application scenarios, the existing deep reinforcement learning (DRL) algorithms may be delayed in policy updates, difficult to converge, and unstable. Therefore, we first model the task scheduling of satellite edge computing to consider both delay and energy cost minimization. Then, a proximal policy optimization (PPO) method based on parallel residual network (PRN) and priority experience replay (PER) is proposed to learn the optimal offloading strategy and resource allocation. We refer to this algorithm as the P2PPO algorithm. Simulation results show that the P2PPO algorithm improves the offloading performance of the system and the convergence speed of the model, ensuring that the delay and energy consumption of the system are minimized in the case of limited resources, and its performance is better than other five baseline algorithms.},
  archive      = {J_SUPERC},
  author       = {Zhong, Jie and Chen, Juan and Wu, Zongling and Chen, Peng and Tian, Di and Li, Xi},
  doi          = {10.1007/s11227-024-06900-5},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {P2PPO: Parallel residual network and prioritized experience replay enhanced PPO for task offloading and resource allocation in SatEC},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral radius and k-factor-critical graphs. <em>SUPERC</em>, <em>81</em>(3), 1--13. (<a href='https://doi.org/10.1007/s11227-024-06902-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a nonnegative integer k, a graph G is said to be k-factor-critical if $$G-Q$$ admits a perfect matching for any $$Q\subseteq V(G)$$ with $$|Q|=k$$ . In this article, we prove spectral radius conditions for the existence of k-factor-critical graphs. Our result generalizes one previous result on perfect matchings of graphs. Furthermore, we claim that the bounds on spectral radius in Theorem 3.1 are sharp.},
  archive      = {J_SUPERC},
  author       = {Zhou, Sizhong and Sun, Zhiren and Zhang, Yuli},
  doi          = {10.1007/s11227-024-06902-3},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--13},
  shortjournal = {J. Supercomput.},
  title        = {Spectral radius and k-factor-critical graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing SIKE for blockchain-based IoT ecosystems with resource constraints. <em>SUPERC</em>, <em>81</em>(3), 1--44. (<a href='https://doi.org/10.1007/s11227-024-06906-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology offers a robust framework for integration with the Internet of Things (IoT), enhancing interoperability, security, privacy, and scalability in modern technological ecosystems. However, traditional cryptographic protocols used in blockchain systems are increasingly vulnerable to quantum attacks due to advancements in quantum computing. In response, the National Institute of Standards and Technology (NIST) has prioritized research in post-quantum cryptography, presenting challenges and opportunities for developing blockchain-based applications tailored to IoT devices. Among the post-quantum cryptographic schemes evaluated in NIST's third standardization round, the Supersingular Isogeny Key Encapsulation (SIKE) protocol stands out for its relatively small public and private key sizes. Despite this advantage, SIKE faces challenges related to high latency, necessitating efficient implementations to make it viable for real-world applications. This research focuses on optimizing the cryptographic foundations of blockchain networks to securely and efficiently integrate resource-constrained IoT ecosystems. By enhancing the SIKE protocol, which exhibits strong resistance to brute-force and whitewashing attacks, the study achieves significant performance improvements. Our FPGA-based implementation on the VIRTEX-6 XC6VLX760 demonstrates reduced latency, achieving a key generation time of 24 ms, encapsulation time of 72 ms, and decapsulation time of 73 ms for SIKEp434. These results highlight the feasibility of deploying SIKE-optimized blockchain networks in IoT environments with stringent resource constraints.},
  archive      = {J_SUPERC},
  author       = {Ismail, Nabil A. and Khadra, Shaimaa Abu and Attiya, Gamal M. and Abdulrahman, Salah Eldin S. E.},
  doi          = {10.1007/s11227-024-06906-z},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Optimizing SIKE for blockchain-based IoT ecosystems with resource constraints},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint computation offloading and resource allocation in multi-cell MEC networks. <em>SUPERC</em>, <em>81</em>(3), 1--52. (<a href='https://doi.org/10.1007/s11227-025-06921-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A widely studied typical mobile edge computing (MEC) system consists of a cloud server, several edge servers, and some user equipment. Each MEC system is also referred to as a cell. In a multi-cell network, there are several different cells, and the cloud servers in different cells can be connected. In this paper, we consider the problem of offloading computing tasks crossing cells in a multi-cell network to improve the user’s quality of experience (QoE). We first investigate a cross-cell task binary computation offloading and resource allocation model for optimizing QoE and formulate this optimization problem as a mixed-integer nonlinear programming (MINLP). Then, for the offline case, we design an efficient exact algorithm (DGOSS) that can find the optimal computation offloading and resource allocation. For the online case, we devise an online algorithm (DTE-DOL) with a sub-linear bounded regret under dynamic computing task generation, dynamic server quota, and uncertain server-side information assumptions. The online algorithm adopts the multi-user Multi-Armed Bandit technique and distributed auction technique. Finally, we compare the performance of the proposed algorithms on different instances with previously existing algorithms. Experimental results show that for the offline case, the DGOSS algorithm can improve the QoE by approximately 5% with about 37.75% less running time, while for the online case, the DTE-DOL algorithm can significantly improve the QoE by around 18.75% with almost the same running time.},
  archive      = {J_SUPERC},
  author       = {Xiao, Qimu and Xiao, Mingyu},
  doi          = {10.1007/s11227-025-06921-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--52},
  shortjournal = {J. Supercomput.},
  title        = {Joint computation offloading and resource allocation in multi-cell MEC networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized dynamic load balancing for virtual machines in cloud computing: A blockchain-enabled system with state channel optimization. <em>SUPERC</em>, <em>81</em>(3), 1--30. (<a href='https://doi.org/10.1007/s11227-025-06922-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an innovative load balancing algorithm that utilizes blockchain-enabled cloud computing environments. The proposed scheme leverages blockchain technology's decentralized architecture to dynamically and efficiently distribute workloads across virtual machines (VMs). This approach optimizes resource utilization and enhances the performance of cloud services. By integrating smart contracts and employing a meticulous VM selection process, our method effectively addresses the challenges associated with traditional load balancing techniques, which often struggle to adapt to dynamic, heterogeneous workloads. Furthermore, our algorithm promotes transparency and security in task allocation and execution, capitalizing on blockchain's inherent features of immutability and consensus. The effectiveness of the proposed scheme is demonstrated through rigorous simulation using the CloudSim toolkit, showcasing significant improvements over existing methods in terms of makespan, execution time, resource utilization, and throughput. These results underline the potential of our proposed solution to revolutionize cloud computing infrastructure management, making it more adaptable, efficient, and resilient to varying computing demands.},
  archive      = {J_SUPERC},
  author       = {Roselin, J. and Insulata, Israelin J.},
  doi          = {10.1007/s11227-025-06922-7},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Decentralized dynamic load balancing for virtual machines in cloud computing: A blockchain-enabled system with state channel optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Siamsdt: A self-adaptive dynamic template siamese network for airborne visual tracking of MAVs on heterogeneous FPGA-SoC. <em>SUPERC</em>, <em>81</em>(3), 1--25. (<a href='https://doi.org/10.1007/s11227-025-06928-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airborne visual tracking is pivotal in enhancing the autonomy and intelligence of micro aerial vehicles (MAVs). However, MAVs frequently encounter challenges such as viewpoint changes and interference from similar objects in practice. Additionally, due to their small size and lightweight characteristics, MAVs have limited onboard computational resources, significantly constraining algorithm complexity and impacting tracking performance. To address these issues, we propose a robust and lightweight tracking model, self-adaptive dynamic template Siamese network (SiamSDT). Leveraging two key designs: temporal attention mechanism and Self-adaptive Template Fusion module, SiamSDT is capable of adapting to the appearance variations during the tracking process. Specifically, temporal attention mechanism integrates historical information in a sequential manner, retaining pertinent information while reducing storage and computational complexity. Additionally, the Self-adaptive Template Fusion module dynamically adjusts the fusion ratio of each template through a similarity matrix, further enhancing the model’s adaptability and anti-interference capability. Furthermore, we propose a solution tailored for heterogeneous ZYNQ platforms to deal with the issue of limited onboard resources, and an FPGA-based accelerator is designed to accelerate the inference process through pipeline, data reuse, ping-pong operation and array partition. The performance of SiamSDT was evaluated on OTB and UAV123 dataset. On the UAV123 dataset, SiamSDT achieves a 4.8% increase in precision and a 1.2% increase in success rate compared to the baseline algorithm without any increase in parameters. The hardware simulation experiments demonstrate that our deployment scheme can significantly reduce inference latency with an acceptable decrease in tracking performance.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yuxin and Wen, Jiazheng and Wu, Ran and Liu, Huanyu and Li, Junbao},
  doi          = {10.1007/s11227-025-06928-1},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Siamsdt: A self-adaptive dynamic template siamese network for airborne visual tracking of MAVs on heterogeneous FPGA-SoC},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved dwarf mongoose optimization algorithm based on hybrid strategy for global optimization and engineering problems. <em>SUPERC</em>, <em>81</em>(3), 1--61. (<a href='https://doi.org/10.1007/s11227-025-06931-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dwarf Mongoose Optimization algorithm is a metaheuristic approach designed to solve single-objective optimization problems. However, DMO has certain limitations, including slow convergence rates and a tendency to get stuck in local optima, particularly when applied to multimodal and combinatorial problems. This paper introduces an enhanced version of the DMO, referred to as HDMO, which is based on a hybrid strategy. Firstly, a sine chaotic mapping function is integrated to enhance the diversity of the initial population. Secondly, the study aims to improve the algorithm’s performance through the integration of nonlinear control, adaptive parameter tuning, hybrid mutation strategies, and refined exploration–exploitation mechanisms. To evaluate the performance of the proposed HDMO, we conducted tests on the CEC2017, CEC2020, and CEC2022 benchmark problems, as well as 19 engineering design problems from the CEC2020 real-world optimization suite. The HDMO algorithm was compared with various algorithms, including (1) highly cited algorithms such as PSO, GWO, WOA and SSA; (2) recently proposed advanced algorithms, namely, BOA, GBO, HHO, SMA and STOA; and (3) high-performance algorithms like LSHADE and LSHADE_SPACMA. Experimental results demonstrate that, compared to other algorithms, HDMO exhibits superior convergence speed and accuracy. Wilcoxon rank-sum test statistics confirm the significant performance improvement of HDMO, highlight its potential in practical engineering optimization and design problems.},
  archive      = {J_SUPERC},
  author       = {He, Fuchun and Fu, Chunming and He, Youwei and Huo, Shaoyong and Tang, Jiachang and Long, Xiangyun},
  doi          = {10.1007/s11227-025-06931-6},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--61},
  shortjournal = {J. Supercomput.},
  title        = {Improved dwarf mongoose optimization algorithm based on hybrid strategy for global optimization and engineering problems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network security situation assessment based on BKA and cross dual-channel. <em>SUPERC</em>, <em>81</em>(3), 1--37. (<a href='https://doi.org/10.1007/s11227-025-06932-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network security situation assessment (NSSA) has become increasingly critical due to the growing frequency and sophistication of network attacks. NSSA involves analyzing network threats and security incidents to support network administrators in decision-making and the implementation of protective strategies. To address the challenges of low assessment accuracy in current NSSA methods, we propose a novel model that integrates an enhanced black-winged kite algorithm (BKA) with a cross dual-channel framework. First, we develop a cross dual-channel architecture that combines a convolutional neural network with a bidirectional long short-term memory network. This structure effectively integrates temporal and spatial features; while, an attention mechanism highlights key information, thereby improving the accuracy of traffic classification. Second, the improved BKA is employed to optimize network parameters, further enhancing the model’s overall performance. Finally, the situation value is derived from the classification results and mapped to corresponding network security situation levels, completing the NSSA process. Experimental results on the NSL-KDD dataset demonstrate that the proposed model achieves notable improvements, with an accuracy of 83.66%, a recall of 80.04%, and an F1-score of 83.13%. Moreover, the proposed assessment method offers a more robust and comprehensive evaluation of the network’s overall security status, highlighting its potential for practical application.},
  archive      = {J_SUPERC},
  author       = {Zhang, Shengcai and Fu, Zhiying and An, Dezhi and Yi, Huiju},
  doi          = {10.1007/s11227-025-06932-5},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Network security situation assessment based on BKA and cross dual-channel},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A random flight–follow leader and reinforcement learning approach for flexible job shop scheduling problem. <em>SUPERC</em>, <em>81</em>(3), 1--44. (<a href='https://doi.org/10.1007/s11227-025-06935-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid search algorithm that integrates random flight, follow leader policy, and reinforcement learning, aiming to efficiently solve the flexible job shop scheduling problems. The algorithm adopts a two-stage encoding policy and a random-key-based encoding conversion mechanism, effectively establishing a mapping relationship between individual positions and the flexible job shop scheduling problem solutions. By introducing a reinforcement learning mechanism, the flexible job shop scheduling problem is transformed into a Markov decision process. Furthermore, a carefully designed system of state space, action space, and reward is utilized to achieve precise and efficient exploration of the local search space. This algorithm framework combines the extensive exploration capabilities of global search with the fine optimization capabilities of local search, significantly enhancing solution efficiency and algorithm performance. Empirical analysis demonstrates that the results on multiple authoritative benchmark datasets outperform current state-of-the-art algorithms, verifying the algorithm's outstanding performance and broad applicability in solving the flexible job shop scheduling problems.},
  archive      = {J_SUPERC},
  author       = {Shao, Changshun and Yu, Zhenglin and Ding, Hongchang and Cao, Guohua and Duan, Jingsong and Zhou, Bin},
  doi          = {10.1007/s11227-025-06935-2},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {A random flight–follow leader and reinforcement learning approach for flexible job shop scheduling problem},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and mitigation of TCP-based DDoS attacks in cloud environments using a self-attention and intersample attention transformer model. <em>SUPERC</em>, <em>81</em>(3), 1--42. (<a href='https://doi.org/10.1007/s11227-025-06940-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {TCP-based Distributed Denial of Service (DDoS) attacks pose a significant danger to cloud infrastructures because they can imitate genuine traffic patterns, making them difficult to detect using standard approaches. This study introduces the Self-Attention and Intersample Attention Transformer (SAINT) model, a unique deep learning architecture that incorporates Sparse Logistic Regression to address these issues. The SAINT framework uses dual attention mechanisms-self-attention for capturing complicated intraflow dependencies and intersample attention for assessing interflow relationships-to provide enhanced detection of malicious traffic. SAINT, unlike existing methodologies, prioritizes scalability, interpretability, and computational efficiency, distinguishing it from traditional models such as CNNs, RNNs, and ensemble techniques. The model’s efficacy was evaluated using the BCCC-cPacket-Cloud-DDoS-2024 dataset, which included 700,000 traffic flows across 17 advanced attack scenarios, with state-of-the-art metrics: 95% precision, 95% recall, 96% F1 score, and 97% accuracy. Furthermore, studies on the CICDDoS2019 dataset confirmed SAINT’s resilience and flexibility to a variety of network conditions. SAINT addresses real-world issues in cloud-based DDoS detection, such as temporal and spatial traffic complexities, to provide a viable, high performance solution for protecting current cloud infrastructures. This work establishes the groundwork for scalable, adaptable, and efficient cloud-native security frameworks, paving the path for enhanced countermeasures to changing cyber threats.},
  archive      = {J_SUPERC},
  author       = {Kirubavathi, G. and Sumathi, I. R. and Mahalakshmi, J. and Srivastava, Durgesh},
  doi          = {10.1007/s11227-025-06940-5},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Detection and mitigation of TCP-based DDoS attacks in cloud environments using a self-attention and intersample attention transformer model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Capsule feature selector for software defect prediction. <em>SUPERC</em>, <em>81</em>(3), 1--38. (<a href='https://doi.org/10.1007/s11227-025-06949-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of predictive models in software defect prediction is vulnerable to redundant features. Feature selection methods prove effective in reducing the spatial dimensionality of features. However, traditional approaches in feature selection encounter challenges in efficiently delivering the optimal subset of features. We introduce a capsule feature selector (CFS) for software defect prediction, drawing inspiration from capsule networks. Initially, our method outlines four essential computational processes within the capsule feature selector: capsule structure, sorting rules, search rules, and transfer rules. Subsequently, we uniformly place the binary capsule operator into the capsule basic units, employing search rules to refine the search process. Sorting rules are applied to select the optimal binary capsule operator for each individual capsule basic unit. Lastly, the optimal binary capsule operator from each capsule basic unit is transmitted to the capsule region for fitness value comparison via the transfer rules. This process facilitates the selection of the optimal subset of features. Comparative experiments conducted on 15 publicly available software defect datasets demonstrate that CFS outperforms the other eight advanced feature selection algorithms. This indicates that CFS exhibits superior performance. The experimental findings are further substantiated through nonparametric statistical analysis.},
  archive      = {J_SUPERC},
  author       = {Tang, Yu and Dai, Qi and Du, Ye and Zheng, Tian-shuai and Li, Mei-hong},
  doi          = {10.1007/s11227-025-06949-w},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Capsule feature selector for software defect prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-guided graph attention auto-encoder. <em>SUPERC</em>, <em>81</em>(3), 1--22. (<a href='https://doi.org/10.1007/s11227-025-06953-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute graph clustering is an important tool to analyze and understand complex networks. In recent years, graph attention auto-encoder has been applied to attribute graph clustering as a learning method for unsupervised feature representation. However, the graph attention auto-encoder only learns the feature representation of the nodes, and needs to use traditional clustering algorithms such as k-means and spectral clustering to achieve the final clustering of nodes. During the optimization process, the clustering loss cannot be fed back to the auto-encoder and the extracted features are not necessarily suitable for downstream clustering tasks because the auto-encoder model for feature learning and the clustering model are mutually independent. To overcome this problem, we propose a cluster-guided graph attention auto-encoder (CGATAE), which introduces a cluster-guided pairwise feature relationship preservation-based non-negative matrix factorization model (FR-NMF) into the graph attention auto-encoder. The model CGATAE obtains the final clustering results while learning the cluster-oriented node feature representation. Experiments on five public attribute graph datasets verify the effectiveness of the CGATAE model, and its clustering quality is significantly better than the original graph attention auto-encoder model.},
  archive      = {J_SUPERC},
  author       = {Zheng, Zhiwen and Chen, Xiaoyun and Huang, Musheng},
  doi          = {10.1007/s11227-025-06953-0},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Cluster-guided graph attention auto-encoder},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perceptual QP optimization for VVC with dual hybrid neural networks. <em>SUPERC</em>, <em>81</em>(3), 1--21. (<a href='https://doi.org/10.1007/s11227-025-06954-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a dual hybrid neural network model combining convolutional neural networks (CNNs) and artificial neural networks (ANNs) to optimize the quantization parameter (QP) for both $$64\times 64$$ and $$32\times 32$$ blocks in the versatile video coding (VVC) standard, enhancing video quality and compression efficiency. The model employs CNNs for spatial feature extraction and ANNs for structured data handling, addressing the limitations of current heuristic and just noticeable distortion (JND)-based methods. A dataset of luminance channel image blocks, encoded with various QP values, is generated and preprocessed, and the dual hybrid network structure is designed with convolutional and dense layers. The QP optimization is applied at two levels: the $$64\times 64$$ model provides a global QP offset, while the $$32\times 32$$ model refines the QP for further partitioned blocks. Performance evaluations using model error metrics like mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), as well as perceptual metrics like weighted PSNR (WPSNR), MS-SSIM, PSNR-HVS-M, and VMAF, demonstrate the model’s effectiveness. While our approach performs competitively with state-of-the-art algorithms, it significantly outperforms in VMAF, the most advanced and widely adopted perceptual quality metric. Furthermore, the dual-model approach yields better results at lower resolutions, whereas the single-model approach is more effective at higher resolutions. These results highlight the adaptability of the proposed models, offering improvements in both compression efficiency and perceptual quality, making them highly suitable for practical applications in modern video coding.},
  archive      = {J_SUPERC},
  author       = {Ruiz Atencia, Javier and López Granado, Otoniel Mario and Pérez Malumbres, Manuel and Martínez-Rach, Miguel Onofre},
  doi          = {10.1007/s11227-025-06954-z},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Perceptual QP optimization for VVC with dual hybrid neural networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing strategies in mobile crowdsensing: An enhanced MAPPO approach using a behavior network. <em>SUPERC</em>, <em>81</em>(3), 1--28. (<a href='https://doi.org/10.1007/s11227-025-06957-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing involves assigning multiple tasks around points of interest to mobile users (MUs) for execution. Developing an optimal task allocation strategy is crucial for the entire system, as it directly impacts the benefits of stakeholders. Leveraging recent advancements in multi-agent reinforcement learning (MARL), which have demonstrated unique advantages in simulating complex interactions among multiple agents, we propose a pricing strategy based on an improved behavior network and multi-agent proximal policy optimization (MAPPO) algorithm. Specifically, we formulate the problem as a multi-leader multi-follower Stackelberg game, and then apply MAPPO, a MARL technique which employs centralized training and decentralized execution, to solve this game. To better capture complex sequential input information and achieve superior behavior strategies, we integrate an attention mechanism with a gated recurrent unit (GRU) network into the actor network, forming a MARL algorithm with an improved behavior network, termed GRU-and-Attention-based MAPPO (GA-MAPPO). Simulation results demonstrate that the proposed GA-MAPPO algorithm is effective compared with baseline approaches. It can learn an optimal pricing strategy that maximizes the benefits of Task Initiators (TIs) and guides TIs in pricing MUs effectively.},
  archive      = {J_SUPERC},
  author       = {Zhao, Shengsheng and Yu, Yantao and Huang, Tiancong and Liu, Guojin and Wu, Yucheng},
  doi          = {10.1007/s11227-025-06957-w},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Pricing strategies in mobile crowdsensing: An enhanced MAPPO approach using a behavior network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFVE: Visual information enhancement metaphor detection with multimodal splitting fusion. <em>SUPERC</em>, <em>81</em>(3), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06958-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaphors are ubiquitous in natural language, and metaphor detection, as an important prerequisite for metaphor understanding, is widely used in natural language processing tasks such as sentiment analysis, sarcasm interpretation, and text comprehension. Current metaphor detection methods rely mainly on text and identify metaphorical language through language analysis. However, these methods usually focus too much on text content, ignore the importance of visual metaphors, and lack effective multimodal metaphor feature integration methods. This paper proposes a metaphor detection model with visual information enhancement based on multimodal split fusion. Specifically, we first use a multidimensional attention enhancement module to process image information. This module optimizes the recognition and processing of key features by sequentially integrating channel and spatial attention mechanisms, thereby improving the performance of the model in visual tasks. To achieve two-way interaction of multimodal metaphor features, we design a multimodal split-fusion module. This module enhances the model’s metaphor detection ability by dividing each modal data into feature blocks of equal size and aggregating and weighting these blocks. Extensive experimental results on the public multimodal metaphor dataset METMeme and the sarcasm dataset Sarcasm verify the effectiveness of our model.},
  archive      = {J_SUPERC},
  author       = {Yang, Qimeng and Meng, Hao and Yan, Yuanbo and Guo, Shisong and Wei, Qixing},
  doi          = {10.1007/s11227-025-06958-9},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {SFVE: Visual information enhancement metaphor detection with multimodal splitting fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early rumor detection method based on stage sampling and triple-relationship graph. <em>SUPERC</em>, <em>81</em>(3), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06959-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem that the influence of rumor propagation stages is ignored in traditional rumor detection methods, an early rumor detection method based on stage sampling and triple-relationship graph is proposed. Firstly, the sampling probability density function is defined, and the stage sampling method based on normal distribution is proposed to obtain the comment sets with respect to the early stage, middle stage, and late stage of an event. Secondly, both the comment posting time and information propagation directions are considered, and the triple-relationship graph that integrates diffusion relationship, aggregation relationship, and sibling relationship for each stage is constructed. Moreover, the advantage of heterogeneous graph attention network (HAN) in exploring graph structural features is leveraged to obtain the node representations. Finally, to improve the interpretability and to capture the mutual influence between nodes efficiently, a graph-level vector computation method based on compressed self-attention mechanism and soft attention mechanism is proposed. Experimental results on two public datasets show that the proposed method consistently outperforms existing typical methods, with Fw improvements of approximately 2.1% and 3.7% on the CED and Weibo datasets, respectively, validating its effectiveness on early rumor detection. Furthermore, attention weight visualization experiments explicitly highlight the contributions of comments at different stages, significantly enhancing the interpretability of our approach.},
  archive      = {J_SUPERC},
  author       = {Wang, Youwei and Feng, Lizhou and Zhang, Yan},
  doi          = {10.1007/s11227-025-06959-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Early rumor detection method based on stage sampling and triple-relationship graph},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-robot collaborative 3D path planning based on game theory and particle swarm optimization hybrid method. <em>SUPERC</em>, <em>81</em>(3), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06960-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-robot path planning in 3D environment is a complex and challenging task that needs to consider not only the high quality and safety of the paths, but also the coordination between robots. Aiming at this problem, a collaborative 3D path planning scheme using game theory and particle swarm optimization hybrid method (GTPHM) is presented in paper. Firstly, a cost function is formulated to transform path planning into an optimization problem, for which the multi-robot space motion equation is designed to satisfy the dynamic constraints. Then, a game theory-based multi-robot path planning framework is established, using collision costs and multi-objective heuristic functions as game gains to maintain the game-theoretic interaction between robots. In the improved particle swarm optimization algorithm (PSO), the particle space position transformation method designed according to the three-dimensional space vector, used as a strategy update mechanism based on game theory. For collisions avoidance between robots, each robot adjusts its cooperative strategy based on the behavior of the other robots. Each robot chooses the optimal cooperative strategy, and then gradually approaches the Nash equilibrium. Comparative experimental results show that GTPHM can effectively guide multi-robot to plan a safe and collision-free path from the starting point to the target point in mountain and city complex 3D environment.},
  archive      = {J_SUPERC},
  author       = {Qiu, Hong and Yu, Wentao and Zhang, Gan and Xia, Xuan and Yao, Kun},
  doi          = {10.1007/s11227-025-06960-1},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {Multi-robot collaborative 3D path planning based on game theory and particle swarm optimization hybrid method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PESA: Error sensitivity analysis tool for floating-point computational programs. <em>SUPERC</em>, <em>81</em>(3), 1--24. (<a href='https://doi.org/10.1007/s11227-025-06962-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floating-point programs are currently extensively applied across various domains of scientific computing. Within such computational programs, there is a propensity to utilize high-precision floating-point variables to ensure the accuracy of the results. However, this practice concurrently leads to a decline in program performance. To address this issue, researchers have aimed to reduce the precision requirements of variables in programs without significant impact on results. Current mixed-precision tools utilize differential derivation to compute variable sensitivity, but this method is cumbersome and can cause memory crashes in intensive computational programs. This paper presents program error sensitivity analysis (PESA), an error sensitivity analysis tool based on variance decomposition, optimized for floating-point programs using LLVM. PESA uses the Sobol method to perform error sensitivity analysis and provides the user with the magnitude of error sensitivity for each variable in the program. Experimental results show that PESA produces error analysis results consistent with other tools and outperforms other sensitivity analysis tools overall by testing six benchmark files and small applications.},
  archive      = {J_SUPERC},
  author       = {Cui, Mengqi and Xu, Jinchen and Zhou, Yuchang and Yang, Hongru and Ji, Liguang and Zhou, Bei},
  doi          = {10.1007/s11227-025-06962-z},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {PESA: Error sensitivity analysis tool for floating-point computational programs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M-C&M-BL: A novel classification model for brain tumor classification: Multi-CNN and multi-BiLSTM. <em>SUPERC</em>, <em>81</em>(3), 1--25. (<a href='https://doi.org/10.1007/s11227-025-06964-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the central organ for human cognition and behavior, the human brain is critical to daily functioning. Brain tumors disrupt normal activities and require accurate diagnosis and intervention. In this study, an approach is presented that allows the detection of tumors in the brain. The main motivation of the study is to determine whether there is a tumor in the brain with high performance. For this purpose, the proposed method was tested using the open-source Br35H brain magnetic resonance imaging (MRI) dataset. The proposed model, M-C&M-BL, integrates a Convolutional Neural Network (CNN) for image feature extraction with a Bidirectional Long Short-Term Memory (BiLSTM) Network for sequential data processing. Metrics such as Accuracy (Acc), F1 Score (F1), Precision (Pre), Recall (Rec), Specificity (Spe), and Matthews Correlation Coefficient (MCC) were used for performance evaluation. The proposed model achieved 99.33% Acc and 99.35% F1, outperforming CNN-based models such as BMRI-Net (98.69% Acc, 98.33% F1) and AlexNet (98.79% Acc, 98.82% F1). It also demonstrated competitive performance against MobileNetv2, which achieved a slightly higher Acc of 99.67%. This approach has significant potential for integration into clinical decision support systems, web and mobile diagnostic platforms, and hospital picture archiving and communication systems (PACS). These tools can aid in early diagnosis, improve diagnostic accuracy, and reduce evaluation time. However, challenges such as ensuring privacy, achieving generalizability across diverse datasets, and addressing infrastructure constraints must be addressed for seamless deployment. This study highlights the feasibility and potential of combining deep learning architectures to advance AI-driven tools in healthcare, ultimately improving clinical workflows and patient outcomes.},
  archive      = {J_SUPERC},
  author       = {Başarslan, Muhammet Sinan},
  doi          = {10.1007/s11227-025-06964-x},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {M-C&M-BL: A novel classification model for brain tumor classification: Multi-CNN and multi-BiLSTM},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cloud-based AIoT intelligent infrastructure for firefighting pump fault diagnosis-based hybrid CNN-GRU deep learning technique. <em>SUPERC</em>, <em>81</em>(3), 1--28. (<a href='https://doi.org/10.1007/s11227-025-06965-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firefighting pumps provide vital roles in maintaining the pressure of fluid power in the firefighting system and are broadly utilized in the majority of residential, commercial, or industrial buildings. However, the reliance on periodic inspections to ensure their availability during emergency scenarios poses challenges such as high maintenance costs and the need for expert knowledge. This study addresses these challenges by proposing a cloud-based AIoT intelligent infrastructure for diagnosing faults and identifying potential hidden failure conditions in firefighting pumps. The framework integrates IoT devices with different sensors installed on pumps to accumulate real-time data under normal and failure conditions. A hybrid convolutional neural network-gate recurrent unit (CNN-GRU) deep learning model is constructed to analyze this data, leveraging hyperparameter optimization to enhance performance. Through the hyperparameter process, a hybrid CNN-GRU algorithm is constructed for analyzing and validating with other traditional approaches, including the recurrent unit (RNN), long short-term memory (LSTM), GRU, CNN, and CNN-RNN methods. The experiments demonstrate that the AIoT framework-based CNN-GRU algorithm could accurately provide intelligent fault diagnosis of firefighting pumps and effectively decrease the operation and maintenance cost of firefighting pump manufacturing companies in Taiwan. This innovative approach offers a practical solution for firefighting pump manufacturers and has broader implications for smart maintenance systems in critical infrastructure.},
  archive      = {J_SUPERC},
  author       = {Nguyen, Da-Thao and Nguyen, Thanh-Phuong and Cho, Ming-Yuan},
  doi          = {10.1007/s11227-025-06965-w},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Cloud-based AIoT intelligent infrastructure for firefighting pump fault diagnosis-based hybrid CNN-GRU deep learning technique},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling QSPR for pyelonephritis drugs: A topological indices approach using MATLAB. <em>SUPERC</em>, <em>81</em>(3), 1--26. (<a href='https://doi.org/10.1007/s11227-025-06967-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph theory serves as a powerful mathematical framework for modeling complex systems, including the chemical structures of pharmaceutical compounds. This study employs degree-based topological indices to analyze the chemical structures of 12 commonly prescribed antibiotics for treating kidney infections. These indices represent numerical values derived from a graph, allowing for the prediction of the physicochemical properties of compounds without the need for laboratory experiments. A computer-based technique and algorithm were employed to streamline calculations and data analysis. The degree-based topological indices were calculated using the MATLAB program. A comparison of their topological indices was conducted to predict the physicochemical characteristics of the selected drugs. Additionally, SPSS software was utilized to develop Quantitative Structure–Property Relationship (QSPR) models, which analyze the correlation between topological indicators and the drugs' physicochemical properties. Various regression models were applied to evaluate the effectiveness of the drugs. Effective predictors were identified, and optimal equations were established based on the highest correlation coefficients and Fisher's test. The study found that the power equation is the most effective method for estimating molar refraction (MR) and polarizability (P) using the Randic ( $${R}_{-1/2}$$ ) index. Conversely, the cubic equation proved the most reliable technique for estimating (MR) and (P) using the second modified Zagreb ( $${}^{m}{M}_{2}$$ ) and atomic bond connectivity (ABC) indices. The findings highlight the potential of using degree-based topological indices in predicting the physicochemical characteristics of drugs. Identifying effective predictors and optimal equations contributes to understanding the relationship between chemical structure and properties, paving the way for further research in drug design and development.},
  archive      = {J_SUPERC},
  author       = {Hasani, Mehri and Ghods, Masoud and Mondal, Sourav and Siddiqui, Muhammad Kamran and Cheema, Imran Zulfiqar},
  doi          = {10.1007/s11227-025-06967-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Modeling QSPR for pyelonephritis drugs: A topological indices approach using MATLAB},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VolRec: 4D real-time volumetric reconstruction of OCT data. <em>SUPERC</em>, <em>81</em>(3), 1--22. (<a href='https://doi.org/10.1007/s11227-025-06969-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the design, analysis and development of VolRec, a volumetric 4D reconstruction system for OCT (optical coherence tomography) data. VolRec is able to obtain and process more than 25 high-resolution OCT data volumes per second. This way, VolRec allows OCT systems to perform real-time measurements that could help doctors and physicians in many different cases, e.g., during surgical interventions or during exams to restless patients, such as kids. Moreover, VolRec allows to adapt to telemedicine techniques such as telesurgery or image-guided medical robots. To achieve real-time performance, it is necessary to address the limitations of current OCT systems, which are restricted by both the acquisition and processing of massive amounts of data. To overcome those limitations, this work proposes an approach based on a 4D reconstruction. Our proposal allows to generate high-resolution volumes from acquired low-resolution ones. Hence, increasing the acquisition speed while reducing the acquisition resolution without sacrificing image quality. To this end, we use parallel programming mechanisms such as OpenMP (for CPUs) and CUDA to exploit the computing capabilities of modern GPUs. Our real-time volumetric reconstruction algorithm efficiently achieves a very high performance, reaching a processing rate of 18 GigaVoxels/s and about 72 $$\times$$ speedup over a parallel CPU-based algorithm using a GPU, by efficiently exploiting the vast amount of data-level parallelism inherent to OCT data volumes.},
  archive      = {J_SUPERC},
  author       = {Vicente-Jaén, Arturo and Mompeán, Juan and Aragón, Juan L. and Artal, Pablo},
  doi          = {10.1007/s11227-025-06969-6},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {VolRec: 4D real-time volumetric reconstruction of OCT data},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluation of isogeny-based digital signature algorithms: Introducing FIBS—fast isogeny-based digital signature*. <em>SUPERC</em>, <em>81</em>(3), 1--24. (<a href='https://doi.org/10.1007/s11227-025-06970-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing a digital signature scheme is considerably more challenging to accomplish than a key exchange in isogeny-based cryptography. Except for SQISign, other isogeny-based digital signature algorithms are considered impractical primarily due to performance reasons. However, an even more significant concern lies in security issues. Recently, various quantum and non-quantum attacks, including Castryck and Decru’s brilliant method, have been proposed to break isogeny-based cryptosystems. Therefore, there is a need for a diverse isogeny-based digital signature scheme that is robust enough to withstand emerging attacks. This paper presents FIBS: fast isogeny-based digital signature based on the isogeny-based hash function. We combine the CGL hash function and SPHINCS+—a hash-based digital signature algorithm. Targeting NIST security level 1, our implementation in C with CGL hash function instantiated with 256-bit prime takes 38.08 s for key generation, 896.39 s for signing, and 172.37 s for verification. To provide a comprehensive evaluation, we compared FIBS with other isogeny-based digital signatures and selected digital signatures from the NIST PQC standardization project, analyzing performance and memory usage using Valgrind. The results demonstrate that FIBS offers “moderately fast and efficient" performance within the isogeny-based digital signatures while maintaining simplicity and implementation ease. This position's FIBS as a promising alternative for applications where other isogeny-based schemes may fall short.},
  archive      = {J_SUPERC},
  author       = {Kim, Suhri and Lee, Youngdo and Yoon, Kisoon},
  doi          = {10.1007/s11227-025-06970-z},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Performance evaluation of isogeny-based digital signature algorithms: Introducing FIBS—fast isogeny-based digital signature*},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pallet localization algorithm based on improved human pose estimation with transfer learning. <em>SUPERC</em>, <em>81</em>(3), 1--33. (<a href='https://doi.org/10.1007/s11227-025-06973-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning target detection algorithms face significant accuracy limitations in automated warehousing systems, especially in pallet stacking and occlusion scenarios. Based on this, we propose an innovative transfer learning approach that achieves efficient multi-scale feature extraction and fusion through the improved YOLOv8s-pose architecture and BDEM (boundary detail extraction module)-enhanced FFDPN (feature focus diffusion pyramid). Combined BA Wing loss (boundary-aware Wing loss) and APT-TAL (adaptive power transformation task-aligned labelling) strategy improves detection accuracy at 12 keypoints of pallet E-section. The system achieved 94.4% detection accuracy and 93.2% keypoint positioning accuracy at a processing speed of 104.2 FPS (frames per second). Finally, the LMedS (least median of squares)-based position optimisation solution further improves reliability by controlling the pallet inclination and distance measurement errors to within 4.0° and 29 mm, providing a practical solution for automated logistics systems.},
  archive      = {J_SUPERC},
  author       = {Zhou, Zhuguo and Lu, Yujun and Lv, Liye},
  doi          = {10.1007/s11227-025-06973-w},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Pallet localization algorithm based on improved human pose estimation with transfer learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A text-based framework for carbon price forecasting via multivariate temporal graph neural network. <em>SUPERC</em>, <em>81</em>(3), 1--34. (<a href='https://doi.org/10.1007/s11227-025-06974-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon prices is essential for both policymakers and market participants. However, the inherent volatility of carbon prices, driven by numerous external factors, poses significant predictive challenges. This study proposes a carbon price forecasting framework based on graph neural network, which effectively harnesses online news headline data. First, external information from online news headlines is integrated into the carbon price forecasting model. Second, to address the temporal variability of news impact, a method for textual information extraction that accounts for time-related changes is proposed. Specifically, thematic information is distilled from news across different periods using a dynamic topic model (DTM), and sentiment information is conducted using SnowNLP, which is enhanced with an accumulative decay factor. Subsequently, due to the complex relationship between carbon price and textual information, a multivariate temporal graph neural network (MtemGNN) is constructed to automatically learn the correlation between features, thus improving predictive performance. Finally, using Shenzhen, Guangzhou, and Fujian carbon markets as case studies, the experimental results demonstrate that extracting thematic and sentiment information using the proposed textual information extraction method can enhance carbon price forecasting effectiveness. Furthermore, the proposed MtemGNN exhibits higher forecasting precision compared to other baseline models.},
  archive      = {J_SUPERC},
  author       = {Zhang, Dabin and Yu, Zehui and Zeng, Zhimei and Zhang, Boting and Lin, Ruibin and Hu, Huanling},
  doi          = {10.1007/s11227-025-06974-9},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {A text-based framework for carbon price forecasting via multivariate temporal graph neural network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive benchmark of machine learning-based algorithms for medium-term electric vehicle charging demand prediction. <em>SUPERC</em>, <em>81</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11227-025-06975-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current difficulties faced by evolutionary smart grids, as well as the widespread electric vehicles (EVs) into the modernised electric power system, highlight the crucial balance between electricity generation and consumption. Focusing on renewable energy sources instead of fossil fuels can provide an enduring environment for future generations by mitigating the impacts of global warming. At this time, the popularity of EVs has been ascending day by day due to the fact that they have several advantages such as being environmentally friendly and having better mileage performance in city driving over conventional vehicles. Despite the merits of the EVs, there are also a few disadvantages consisting of the integration of the EVs into the existing infrastructure and their expensiveness by means of initial investment cost. In addition to those, machine learning (ML)-based techniques are usually employed in the EVs for battery management systems, drive performance, and passenger safety. This paper aims to implement an EV monthly charging demand prediction by using a novel technique based on an ensemble of Pearson correlation (PC) and analysis of variance (ANOVA) along with statistical and ML-based algorithms including seasonal auto-regressive integrated moving average with exogenous variables (SARIMAX), convolutional neural networks (CNNs), extreme gradient boosting (XGBoost) decision trees, gated recurrent unit (GRU) networks, long short-term memory (LSTM) networks, bidirectional LSTM (Bi-LSTM) and GRU (Bi-GRU) networks for the Eastern Mediterranean Region of Türkiye. The performance and error metrics, including determination coefficient (R $$^2$$ ), mean absolute percentage error (MAPE), mean absolute error (MAE), and mean absolute scaled error (MASE), are evaluated in a benchmarking manner. According to the obtained results, in Scenario 1, a hybrid of PC and XGBoost decision trees model achieved an R $$^2$$ of 96.21%, MAPE of 5.52%, MAE of 6.5, and MASE of 0.195 with a training time of 2.08 s and a testing time of 0.016 s. In Scenario 2, a combination of ANOVA and XGBoost decision trees model demonstrated an R $$^2$$ of 96.83%, a MAPE of 5.29%, a MAE of 6.0, and a MASE of 0.180 with a training time of 1.62 s and a testing time of 0.012 s. These findings highlight the superior accuracy and computational efficiency of the XGBoost models for both scenarios compared to others and reveal XGBoost's suitability for EV charging demand prediction.},
  archive      = {J_SUPERC},
  author       = {Tolun, Ömer Can and Zor, Kasım and Tutsoy, Onder},
  doi          = {10.1007/s11227-025-06975-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {A comprehensive benchmark of machine learning-based algorithms for medium-term electric vehicle charging demand prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Energy efficiency and performance analysis of a legacy atomic scale materials modeling simulator (VASP). <em>SUPERC</em>, <em>81</em>(3), 1--2. (<a href='https://doi.org/10.1007/s11227-025-06976-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Nieves-Pérez, Isidoro and Muñoz, Alfonso and Almeida, Francisco and Blanco, Vicente},
  doi          = {10.1007/s11227-025-06976-7},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--2},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Energy efficiency and performance analysis of a legacy atomic scale materials modeling simulator (VASP)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GBADroid: An android malware detection method based on multi-view feature fusion. <em>SUPERC</em>, <em>81</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11227-025-06977-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of mobile internet, the open Android operating system has become the most widely used mobile platform globally, leading to a surge in malware that poses serious threats to user device security. Current Android malware detection methods mainly rely on a single feature set, making it difficult to comprehensively represent the characteristics of Android applications. To address this limitation, this paper proposes an Android malware detection method called GBADroid. GBADroid comprehensively characterizes Android software by considering multi-view features. Specifically, it first matches against a list of dangerous permissions to identify potential risks and then employs an information gain algorithm and a Bidirectional Gated Recurrent Unit (BiGRU) to extract opcode features. It also constructs a function call graph (FCG) to extract graph features using Graph Sample and Aggregate (GraphSAGE) algorithm. Experimental results show that GBADroid achieves a detection accuracy of 98.73%, demonstrating superior performance compared to existing methods.},
  archive      = {J_SUPERC},
  author       = {Meng, Yi and Luktarhan, Nurbol and Yang, Xiaotong and Zhao, Guodong},
  doi          = {10.1007/s11227-025-06977-6},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {GBADroid: An android malware detection method based on multi-view feature fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The VAE-FastGA anomaly detection model based on subspace and weakly correlated ultra-high-dimensional data. <em>SUPERC</em>, <em>81</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11227-025-06988-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of technology has led to a continuous increase in data dimensions, and the detection of high-dimensional data growing from tens of dimensions to millions of dimensions. As a result, the negative impact of the dimensional curse on anomaly detection has become increasingly remarkable. Although subspace research has been quite extensive, it has been difficult to extend to ultra-high-dimensional (UHD) datasets. To address this issue, this paper proposes the VAE-FastGA subspace search model, which is based on the idea of feature selection and aims to efficiently screen out anomalous subspaces from weakly correlated UHD data. The model integrates variational autoencoder (VAE) networks with accelerated genetic algorithms (FastGA), using VAE reconstruction to guide the search process of the genetic algorithm. An acceleration mechanism is designed to increase search efficiency by discarding invalid attributes during genetic operations and iteratively preserving anomalous subspaces. To mitigate the effects of sample sparsity, a probabilistic statistical model is introduced to optimize the anomalous subspaces. Finally, the idea of hyperdimensional spheres is integrated to improve the detection of marginal anomalies. The experimental sections organize precision experiments based on the KDD-CUP’99, MNIST, and UCSD datasets, perform subspace evaluations based on the MNIST dataset, and conduct scalability research based on incrementally generated datasets. The results show that the proposed algorithm exhibits higher AUC values, better subspace quality, and improved time efficiency in ultra-high dimensions.},
  archive      = {J_SUPERC},
  author       = {Wan, Junhang and Chen, Yanping and Gao, Cong},
  doi          = {10.1007/s11227-025-06988-3},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {The VAE-FastGA anomaly detection model based on subspace and weakly correlated ultra-high-dimensional data},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UAV aerial photography target detection based on improved YOLOv9. <em>SUPERC</em>, <em>81</em>(3), 1--23. (<a href='https://doi.org/10.1007/s11227-025-06991-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In UAV aerial photography, the existence of small-size targets, dense distribution and occlusion phenomenon often leads to frequent missed and false detection in the detection process, which has a significant impact on the detection accuracy of the model. To solve this problem, this paper proposes an improved YOLOv9s model, BF-YOLOv9s. First, the application of the BiFormer attention mechanism serves to enhance the model’s concentration on small targets, thereby facilitating the retention of more refined and detailed features. Second, according to the lightweight demand of UAV aerial photography, the RepNCSPELAN4_Ghost module is proposed, which integrates GhostConv into the backbone network RepNCSPELAN4, significantly reducing the computing load and optimizing the use of computing and memory resources. Finally, the BiFPN feature pyramid network is introduced to promote the fusion and exchange of cross-layer information and improve the detection effect. By selecting the Focal WIOU loss function, model convergence is accelerated, the loss is reduced and training efficiency is improved. The experimental results show that BF-YOLOv9s achieves a mAP50 of 41.3% on the VisDrone2019 dataset, outperforming the original YOLOv9s by 5.6%, while also reducing the parameter count by 8.3%.},
  archive      = {J_SUPERC},
  author       = {Zhang, Heng and Peng, Yang and Liu, Yan li},
  doi          = {10.1007/s11227-025-06991-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {UAV aerial photography target detection based on improved YOLOv9},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph affine transformer with a symmetric adaptation strategy for text classification. <em>SUPERC</em>, <em>81</em>(3), 1--22. (<a href='https://doi.org/10.1007/s11227-025-06992-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a foundational natural language processing task. Many models have transformed text data into innovative graph structures and employed graph neural networks (GNNs) to learn representations for classification. However, graphs constructed based on artificial rules may contain redundant connections, which can introduce noise. Additionally, graph neural network-based (GNN-based) models are ineffective in learning word order. To cope with these difficulties, we propose graph affine Transformer with a symmetric adaptation strategy (GATSAS) for text classification. After graph construction, a symmetric gated graph neural network is crafted to detect edge attributes and remove trivial connections. In the graph learning step, graph affine Transformer encodes word positions and updates word representations with multi-head graph affine attention. Then, the readout module fuses word features to achieve text representation. The experimental results show that GATSAS has an average accuracy of 0.11 $$-$$ 2.37% higher than the GNN-based benchmark models.},
  archive      = {J_SUPERC},
  author       = {Ma, Minyi and Gong, Hongfang and Ding, Yingjing},
  doi          = {10.1007/s11227-025-06992-7},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Graph affine transformer with a symmetric adaptation strategy for text classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient quantized GEMV implementation for large language models inference with matrix core. <em>SUPERC</em>, <em>81</em>(3), 1--31. (<a href='https://doi.org/10.1007/s11227-025-06993-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impressive advantages of Large Language Models (LLMs) have sparked much attention in deploying and utilizing these models on devices. However, the excessive parameters in LLMs lead to a significant memory footprint and computing burden during the inference process, severely restricting the potential uses of LLMs. As an effective model compression method, quantized compression can lower the threshold for deployment and inference of LLMs. In this way, quantized GEneral Matrix–Vector multiplication (GEMV) is the primary runtime component in the inference process. In practice, the dequantization process and low computational density limit the performance of quantized GEMV. This paper proposes an efficient quantized GEMV implementation consisting of the vectorized pre-fetch scheme, an efficient kernel design based on Matrix Core, and the optimization of atomicAdd to accelerate the LLMs’ inference. Finally, various comparison experiments were performed on MI210. Experiment results show the proposed method performs better than previous approaches in multiple shape quantized GEMV and end-to-end inference on LLMs.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yu and Lu, Lu and Zhao, Rong and Guo, Yijie and Yang, Zhanyu},
  doi          = {10.1007/s11227-025-06993-6},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {An efficient quantized GEMV implementation for large language models inference with matrix core},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outsourcing collaboration analysis of multiparty privacy data using the improved yannakakis. <em>SUPERC</em>, <em>81</em>(3), 1--27. (<a href='https://doi.org/10.1007/s11227-025-06994-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many organizations are producing or collecting private data in fields such as medical research and government regulation. Due to current privacy protection, laws and regulations, commercial competition, and other issues, these institutions cannot directly share their data. Collaborative analysis of private data from multiple institutions will benefit each institution and create profits together. Therefore, we propose a Yannakakis-based multiparty outsourcing collaboration analysis scheme. It enables organizations to collaboratively analyze private data from multiple organizations according to their needs while ensuring that private data are not leaked to each other. Our scheme is based on the improved Yannakakis algorithm to build a series of query components, such as Semi-join, Join, Order-by, etc. We also optimized the join operation. By confusing the input tuples and protecting their authenticity through annotations, the join operation can be directly joined through the hash value without disclosing the join results. Through this series of configurations, we can execute a query with $$ O(\textrm{IN}+\textrm{OUT}) $$ runtime and communication, where $$ \textrm{IN} $$ is the total number of tuples in the input relationship, and $$ \textrm{OUT} $$ is the output size. We have carried out a series of comparative experiments, and the results show that our system is 1.3X–7.4X faster than the baseline.},
  archive      = {J_SUPERC},
  author       = {Chen, Zigang and Zhang, Zhenjiang and Leng, Tao and Zhu, Haihua and Liu, Yuhong},
  doi          = {10.1007/s11227-025-06994-5},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Outsourcing collaboration analysis of multiparty privacy data using the improved yannakakis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERBFT: Improved asynchronous BFT with erasure code and verifiable random function. <em>SUPERC</em>, <em>81</em>(3), 1--29. (<a href='https://doi.org/10.1007/s11227-025-06995-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The asynchronous Byzantine-fault tolerance (BFT) protocols are widely adopted in mission-critical tasks. However, existing asynchronous consensus algorithms, such as Honey Badger BFT (HBBFT) and DumboBFT, still suffer from bandwidth waste, excessive producer election rounds, and low consensus efficiency. Therefore, exploring optimized solutions for current asynchronous consensus algorithms is imperative to enhance efficiency. This work proposes an improved asynchronous BFT with erasure code and verifiable random function (ERBFT). By incorporating an erasure code scheme, ERBFT optimizes the provable broadcast protocol to decrease unnecessary bandwidth wastage and message complexity. Based on the node’s performance during the broadcast phase, a comprehensive node activity evaluation mechanism has been devised to calculate the node’s activity level. When integrated with verifiable random function, this activity level facilitates the efficient selection of a producer from among the active nodes. This integration enhances the efficiency of reaching consensus and effectively diminishes the frequency of producer elections. Finally, the theoretical and experimental analysis shows that ERBFT has notably higher throughput and significantly lower latency than HBBFT, Dumbo2, and sDumbo. Specifically, when $$n=100$$ , compared to HBBFT, the throughput of ERBFT has increased by 137.4%, and the latency has decreased by 58.4%.},
  archive      = {J_SUPERC},
  author       = {Lan, Yu and Huang, Hui and Huang, Zhenjie and Chen, Qunshan and Wu, Shuaike},
  doi          = {10.1007/s11227-025-06995-4},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {ERBFT: Improved asynchronous BFT with erasure code and verifiable random function},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RL-EAR: Reinforcement learning-based energy-aware routing for software-defined wireless sensor network. <em>SUPERC</em>, <em>81</em>(3), 1--22. (<a href='https://doi.org/10.1007/s11227-025-06998-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient energy utilization in wireless sensor networks is paramount for the success of Internet of things (IoT) applications. Traditional energy-saving routing protocols typically compute isolated routes, which may only partially optimize energy consumption globally. Software-defined wireless sensor networking (SDWSN) is emerging as a crucial architecture for enabling IoT, leveraging software-defined network principles to facilitate routing operations. However, existing routing algorithms often need more capability to identify the most optimized paths. In this paper, we propose a reinforcement learning-based energy-aware routing (RL-EAR) algorithm to optimize the routing paths of SDWSN. Our method utilizes a reward function considering factors such as remaining energy, hop count, and congestion to optimize routes from any node to the controller node, aiming to enhance network lifetime. The SDWSN controller, acting as the agent, receives rewards based on its actions and refines routes over time through interactions with the data plane. The simulation results of the RL-EAR algorithm demonstrate its prominence over existing routing algorithms. Metrics such as network lifetime, packet delivery ratio, and the number of dead nodes over time are utilized to evaluate the effectiveness of our proposed algorithm. As a result, RL-EAR increases network lifetime by 42% compared to existing routing algorithms.},
  archive      = {J_SUPERC},
  author       = {Narwaria, Abhishek and Kumari, Varsha and Mazumdar, Arka Prokash},
  doi          = {10.1007/s11227-025-06998-1},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {RL-EAR: Reinforcement learning-based energy-aware routing for software-defined wireless sensor network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADH-YOLO: A small object detection based on improved YOLOv8 for airport scene images in hazy weather. <em>SUPERC</em>, <em>81</em>(3), 1--20. (<a href='https://doi.org/10.1007/s11227-025-06999-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately obtaining airport objects is crucial to ensuring airport safety and improving airport efficiency. The previous research has found that airport scene images have so many small objects. The presence of hazy reduces visibility and affects the ability to obtain information about objects in airport scene images. To address the challenges, this article proposes a small object detection based on improved YOLOv8 for airport scene images in hazy weather (ADH-YOLO). Firstly, this article constructs HASS1, HASS2, and HRSOD hazy datasets based on the HAZERD method. We find that YOLOv8 which is anchor-free detection shows significant performance improvement after using anchor boxes in hazy datasets. Then, to adapt to hazy environments, we design a decoupled detection head with the attention module (DDAH) and add a coordinate attention (CA) module to the backbone network. A small object detection layer is added to the original structure to further improve the performance of small object detection. Finally, this article uses partial convolution (PConv) to balance detection performance and computational resource consumption to reconstruct the backbone and neck C2F modules. We propose two lite versions of ADH-YOLO (LADH-YOLOn and LADH-YOLOa) compared with the original YOLOv8x, in which Params decreased by 22.1% and 49.6%, with higher mAP values. The proposed method improves mAP by 10.5% and 31.2% on the HASS1 and HASS2. Generalization experiments show that the proposed method achieves 96.1% mAP optimal detection results compared to classical detection methods on the HRSOD. The source code is available at https://github.com/rookie257/HAD-YOLO .},
  archive      = {J_SUPERC},
  author       = {Zhou, Wentao and Cai, Chengtao and Srigrarom, Sutthiphong and Wang, Pengfei and Cui, Zijian and Li, Chenming},
  doi          = {10.1007/s11227-025-06999-0},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {ADH-YOLO: A small object detection based on improved YOLOv8 for airport scene images in hazy weather},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine medical image registration with landmarks and deformable networks. <em>SUPERC</em>, <em>81</em>(3), 1--21. (<a href='https://doi.org/10.1007/s11227-025-07000-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image registration is a critical task in medical image processing. However, most deep learning-based registration methods primarily rely on a single network to directly predict the deformation field, which can result in challenges when accurately matching certain complex imaging regions. Moreover, the pervasive issue of insufficient training data in medical image registration further limits improvements in model performance. To address these challenges, we propose a novel coarse-to-fine image registration architecture (CFIR) consisting of a landmark-based registration network (LRN) and a deformable registration network (DRN). LRN first extracts and aligns contours and key anatomical regions from the images, achieving coarse registration. Subsequently, DRN refines the alignment by concentrating on finer details that were not adequately addressed during the coarse registration stage, ensuring precise alignment of local features between the images to be registered. During the training process, we employ segmentation and recombination to augment the training data. The performance of CFIR is rigorously evaluated on brain MRI and abdominal CT registration tasks, demonstrating superior registration accuracy compared to several existing CNN-based and Transformer-based methods. Our method provides a new paradigm for medical image registration.},
  archive      = {J_SUPERC},
  author       = {Cao, Zhipeng and Yao, Nianmin and Meng, Linqi and Fang, Jingyi and Zhao, Jian},
  doi          = {10.1007/s11227-025-07000-8},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Coarse-to-fine medical image registration with landmarks and deformable networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRCD: A regional-contention-driven arbitration policy for CPU–GPU heterogeneous systems. <em>SUPERC</em>, <em>81</em>(3), 1--25. (<a href='https://doi.org/10.1007/s11227-025-07001-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In CPU–GPU heterogeneous systems, there exists intense resource contention between CPUs and GPUs. Traditional resource arbitration policies fail to account for the heterogeneity of cores, leading to inefficient network resource utilization for the CPU, which negatively impacts its performance. In heterogeneous networks, the degree of resource contention varies across different regions. This paper first uses reinforcement learning to analyze the message feature weights relied upon for resource arbitration in different network regions. To achieve more efficient resource allocation, a regional-contention-driven arbitration policy is proposed. The simulation results show that, compared to traditional arbitration policy, the overall network latency is reduced by 7.99%, and CPU performance is improved by 11.42%. Furthermore, a dynamic regional-contention-driven arbitration policy is proposed, which further reduces the overall network latency by 10.47% and increases CPU performance by 16.79% compared to traditional arbitration policy.},
  archive      = {J_SUPERC},
  author       = {Fang, Juan and Cheng, Haoyu and Wang, Yuening and Zhai, Ran},
  doi          = {10.1007/s11227-025-07001-7},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {DRCD: A regional-contention-driven arbitration policy for CPU–GPU heterogeneous systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDRNet: A channel grouping based time-slice dilated residual network for long-term time-series forecasting. <em>SUPERC</em>, <em>81</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07011-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately capturing inter-series and intra-series variations is crucial for multivariate long-term time-series forecasting. Existing channel-independent and channel-mixing approaches struggle with complex inter-series relationships, while RNN-based models face challenges in capturing long-term intra-series dependencies. Additionally, current decomposition methods struggle with complex trends in the series, further hindering intra-series modeling. To address these, we propose GDRNet, which consists of four components: the channel grouping block (CGB), the channel group multi-mixer block (CGMB), the time-slice dilated residual GRU (SDRGRU), and the multi-trend decomposition block (MTDB). CGB groups channels with similar distributions for inter-series learning, while CGMB captures complex dependencies between series across various granularities and perspectives. SDRGRU expands the receptive field and incorporates residual learning to capture long-term intra-series dependencies, while MTDB enhances trend-seasonal decomposition, further facilitating precise intra-series modeling. GDRNet achieving 9.12% and 22.30% improvements in multivariate and univariate forecasting tasks, respectively, showcases its effectiveness in time-series forecasting.},
  archive      = {J_SUPERC},
  author       = {Bao, Qingda and Miao, Shengfa and Tian, Yulin and Jin, Xin and Wang, Puming and Jiang, Qian and Yao, Shaowen and Hu, Da and Wang, Ruoshu},
  doi          = {10.1007/s11227-025-07011-5},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {GDRNet: A channel grouping based time-slice dilated residual network for long-term time-series forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSIM: Self-supervised learning method based on spatially selected shifts and irregular image masking. <em>SUPERC</em>, <em>81</em>(3), 1--22. (<a href='https://doi.org/10.1007/s11227-025-07013-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning has gained popularity for reducing the cost of large-scale dataset labeling while improving model generalization and representation. Among self-supervised learning techniques, masked learning is a prominent approach. However, current masking methods typically use regular small block masking after data augmentation, which is not truly random and can degrade the local correlation between image chunks. This paper proposes a novel self-supervised learning method based on spatially selected shifts and irregular image masks (SSIM). The method generates irregular images by threshold binarization, randomly masks the input image, and then performs spatially selective shifting and aggregated input position information operations. This approach not only avoids fixed mask shapes but also preserves and enhances the local correlation between image chunks. We benchmark our method using the DINO model, applying irregular random masking and spatial selective shifting. Experiments on the Imagenet10 dataset show improvements in linear and k-NN accuracy by 7.6% and 5.7%, respectively. The results demonstrate that SSIM outperforms existing self-supervised learning methods using masks. The code of this paper has been open source. https://github.com/wangzy2024/SSIM},
  archive      = {J_SUPERC},
  author       = {Shao, Yunxue and Wang, Zhiyang and Wang, Lingfeng},
  doi          = {10.1007/s11227-025-07013-3},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {SSIM: Self-supervised learning method based on spatially selected shifts and irregular image masking},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive focal distance tabu search approach for the minimum 2-connected dominating set problem. <em>SUPERC</em>, <em>81</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11227-025-07014-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum connected dominating set problem has garnered significant attention due to its wide applications in mobile ad hoc networks and sensor grids. As its variant, the minimum 2-connected dominating set (M-2CDS) problem plays a crucial role in fault-tolerant network design, with its importance increasingly prominent. To address the M-2CDS problem, this paper proposes an adaptive focal distance tabu search algorithm (AFD-TS). The algorithm employs a swap-based neighborhood structure paired with an efficient neighborhood evaluation method, enhanced by adaptive tabu strategies. It also incorporates several adaptive techniques, such as innovative diversification mechanisms, traceback strategies, and reverse approaches, all organized within a unique solution pool structure. To improve the efficiency, the algorithm applies two different optimization strategies and a fast maintenance for the set of cut vertices. Experiments were conducted on 37 public benchmark datasets. Results indicate that AFD-TS significantly reduced the running time in 12 instances while maintaining comparable performance in 15 ones. To verify the algorithm’s solving capability in large-scale complex scenarios, tests were further conducted on 34 newly generated instances. Experimental results demonstrate that the AFD-TS algorithm achieved leading performance across all new instances, fully proving its superiority in handling complex problems. Furthermore, this study conducted an analysis of the key components of the AFD-TS algorithm, comprehensively assessing the contribution of each module to the overall effectiveness of the algorithm, providing important basis for further optimization and improvement.},
  archive      = {J_SUPERC},
  author       = {Luo, Mao and Liu, Xianhong and Wu, Xinyun and Xiong, Caiquan and Ke, Yuanzhi},
  doi          = {10.1007/s11227-025-07014-2},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {An adaptive focal distance tabu search approach for the minimum 2-connected dominating set problem},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum-resistant blockchain and performance analysis. <em>SUPERC</em>, <em>81</em>(3), 1--42. (<a href='https://doi.org/10.1007/s11227-025-07018-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology enables secure information and value exchange in untrusted environments by integrating cryptographic techniques such as public–private key cryptography, hash algorithms, and consensus mechanisms. It is poised to become a foundational technology for the future Internet of Value. However, the security of current mainstream blockchains relies on asymmetric encryption algorithms that are vulnerable to quantum attacks, as their security depends on the computational difficulty of solving number-theoretic problems like integer factorization and discrete logarithms in classical computing models. This paper investigates quantum-resistant blockchain technologies to address these vulnerabilities. First, it analyzes the susceptibility of existing blockchain systems to quantum attacks at multiple levels, including signature algorithms, TLS layer data exchange, consensus mechanisms, and privacy protection. Second, it provides a comprehensive comparison of promising quantum-resistant signature and key encapsulation algorithms, evaluating their characteristics and performance in terms of resource utilization, key size, and other critical metrics. Building on this analysis, the paper proposes a general framework for measuring performance indicators of quantum-resistant blockchains and suggests optimization methods to enhance system performance, focusing on aspects such as block size and consensus mechanisms. Additionally, a multidimensional comparative analysis of existing quantum-resistant blockchain solutions is presented. This work highlights the challenges in achieving quantum resistance for blockchain systems and offers valuable insights and guidance for researchers designing quantum-resistant blockchain solutions and optimizing their performance.},
  archive      = {J_SUPERC},
  author       = {Wu, Faguo and Zhou, Bo and Song, Jiale and Xie, Lijia},
  doi          = {10.1007/s11227-025-07018-y},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Quantum-resistant blockchain and performance analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Train track fastener defect detection algorithm based on MGSF-YOLO. <em>SUPERC</em>, <em>81</em>(3), 1--44. (<a href='https://doi.org/10.1007/s11227-025-07024-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of train track fasteners is an important task to ensure the safe, reliable, and long-term stable operation of the railway system. Under the high stress and dynamic loads during train operation, track fasteners play a crucial role in maintaining the alignment and structural integrity of the tracks. However, traditional manual inspection methods are time-consuming, labor-intensive, and error-prone, while existing defect-detection algorithms often have the problem of low accuracy. To address these challenges, an improved YOLOv8n algorithm named MGSF-YOLO for high-precision detection of train track fastener defects is proposed. Firstly, an attention mechanism MSAM that combines MSCA and CBAM is proposed. MSAM adaptively adjusts the feature dimensions of different channels and the attention intensity at spatial positions through convolution kernels of various scales. This allows the model to focus on key features and regions and simultaneously enhances information extraction by exploiting the correlations between channels, thereby improving the model’s detection performance. Secondly, GSConv is used to replace Conv. This not only reduces the number of model parameters and computational cost but also improves the model’s detection accuracy. Then, an SPPFPool module that integrates average pooling and max pooling is proposed. This module aggregates the edge, background, and contextual information of the entire image, alleviates the impact of image scale changes, enhances the model’s adaptability to inputs of different sizes, effectively reduces false positives and false negatives, and improves the detection accuracy. Finally, the FocalerIoU loss function is introduced to replace the original CIoU loss function, which improves the regression accuracy and accelerates the model’s convergence speed. Experimental results show that compared with YOLOv8n, MGSF-YOLO has achieved performance improvements. The number of model parameters has decreased by 12.2%, and the computational amount has been reduced by 6.1%. Without sacrificing the detection speed, the mean average precision (mAP) has also increased by 2.6%. On the coco128 dataset, the publicly available NEU-DET dataset, and the real-world fastener dataset collected from the Roboflow website, the mAP of MGSF-YOLO has increased by 1.6%, 2.4%, and 3.6%, respectively, compared to YOLOv8n. Compared with other models, MGSF-YOLO reaches the highest mAP value, fully demonstrating its superior generalization ability and detection accuracy. It provides a reliable solution for the detection of railway fastener defects.},
  archive      = {J_SUPERC},
  author       = {Ma, Siwei and Li, Ronghua and Hu, Henan},
  doi          = {10.1007/s11227-025-07024-0},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {Train track fastener defect detection algorithm based on MGSF-YOLO},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective plug-and-play lightweight modules for YOLO series models. <em>SUPERC</em>, <em>81</em>(3), 1--26. (<a href='https://doi.org/10.1007/s11227-025-07026-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in lightweight models based on the YOLO architecture has been a notable trend in recent years. However, most of these models are designed for specific application scenarios, often requiring researchers to redesign lightweight models for different scenarios, thereby increasing development costs. To address this challenge, this paper proposes an efficient lightweight strategy that can be integrated into existing YOLO models, eliminating the need for network architecture redesign. Specifically, the strategy comprises three modules: the lightweight feature extraction module (LFEM), the multi-feature shared convolution module (MSCH), and the feature segmentation and sparse optimization module (LDown). The LFEM module enhances the efficiency of feature extraction in the backbone network by generating potentially redundant feature maps employing standard convolution. The MSCH module reduces the number of parameters in the detection head using shared convolutional layers. The LDown module utilizes feature segmentation for downsampling operations and incorporates the NAM attention mechanism to leverage sparse feature information. To validate the effectiveness of this strategy, we applied it to various YOLO models, including YOLOv5, YOLOv6, YOLOv8, YOLOv10, YOLO-lite, SPDConv, YOLO-Drone, Hyper-YOLO, RCS-YOLO, and ASF-YOLO. We conducted experiments on the DOTA, Pascal VOC2012, and TZ-Plane datasets. The experimental results demonstrate that our proposed lightweight strategy effectively adapts to different models across various target detection scenarios. Moreover, it achieves a substantial reduction in computational complexity while maintaining detection performance. The source code will be made available at https://github.com/lixiaobai-star/EPLM-YOLO .},
  archive      = {J_SUPERC},
  author       = {Dang, Lanxue and Li, Zan and Li, Shilong and Qiao, Baojun and Zhou, Liming},
  doi          = {10.1007/s11227-025-07026-y},
  journal      = {The Journal of Supercomputing},
  month        = {2},
  number       = {3},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Effective plug-and-play lightweight modules for YOLO series models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized harmonic fuzzy partition C-means clustering. <em>SUPERC</em>, <em>81</em>(2), 1--46. (<a href='https://doi.org/10.1007/s11227-024-06723-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defects of fuzzy clustering based on Ruspini partitioning in revealing the relationship between categories, a new generalized harmonic fuzzy partition C-means clustering algorithm is proposed in this paper. Firstly, based on the existing concept of Zadeh’s fuzzy set, the new concept of generalized harmonic fuzzy set is introduced and some basic operations of generalized harmonic fuzzy sets are given. Secondly, the axiomatic definitions and specific expressions of fuzzy entropy and similarity for generalized harmonic sets applied to pattern analysis and machine intelligence are provided. Again, the corresponding harmonic fuzzy partition for cluster analysis are further defined. Fourthly, based on the concept of harmonic fuzzy partition, we propose a novel generalized harmonic fuzzy partition C-means clustering algorithm. Finally, the competitiveness and advantages of the proposed algorithm are verified by comparing with existing representative fuzzy clustering algorithms.},
  archive      = {J_SUPERC},
  author       = {Wu, Chengmao and Zhou, Siyu},
  doi          = {10.1007/s11227-024-06723-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--46},
  shortjournal = {J. Supercomput.},
  title        = {Generalized harmonic fuzzy partition C-means clustering},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AISBench: An performance benchmark for AI server systems. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06778-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) server systems, including AI servers and AI server clusters, are widely utilized in AI applications. The performance of an AI server system determines the performance of the performance an AI application, which has garnered significant attentions and investments from industries and users. However, performance is influenced not only by the AI computing accelerating chips but also by the other configurations of an AI server system, such as architecture, memory, bus, central processing unit (CPU), interconnect equipment, software, etc. As these components are often provided by different vendors, the myriad combinations thereof present challenges in assessing performance in an architecture-neural, reproducible, fairness-enhanced, and performance bottleneck identification-oriented manner. In response to this need, this paper introduces AISBench, a performance benchmark for AI server systems. AISBench comprises standardized rules and a test toolkit that has been agreed upon by over 20 AI server system and server component manufacturers. Compared to other AI performance benchmarks, AISBench provides a more comprehensive metrics system that enables performance benchmarking as well as identification of performance bottlenecks for optimization. Experimental data indicate that our benchmark testing approach offers sufficient comprehensiveness, effectiveness, and stability.},
  archive      = {J_SUPERC},
  author       = {Dong, Jian and Bao, Wei and Cao, Xiaoqi and Xu, Yang and Yang, Yuze and Li, Binbin and Zhang, Qi and Ye, Heng},
  doi          = {10.1007/s11227-024-06778-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {AISBench: An performance benchmark for AI server systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An energy consumption prediction approach in smart cities by CNN-LSTM network improved with game theory and namib beetle optimization (NBO) algorithm. <em>SUPERC</em>, <em>81</em>(2), 1--51. (<a href='https://doi.org/10.1007/s11227-024-06811-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges of the Internet of Things and smart cities is energy consumption and energy theft. An accurate approach to predicting energy consumption and detecting energy theft in smart cities increases efficiency and energy efficiency. Forecasting energy consumption makes energy production based on the needs of consumers, and detecting energy theft makes energy consumption forecasting models more accurate. In this manuscript, in the first step, the data set is balanced using the generative adversarial network based on game theory and the synthetic minority oversampling based on sample density method. In the second step, the basic features of the samples are selected with the Namib beetle optimization (NBO) algorithm to reduce the input of the CNN-LSTM model. In the third step, the hyperparameters of the CNN-LSTM model are optimized to reduce the prediction and classification error rate with the NBO algorithm. In the Benin Electricity Company dataset, the proposed method has fewer errors in predicting energy consumption than the LSTM, GRU, ARIMA-LSTM, and ARIMA-GRU methods. On the Individual Household Electric-Power Consumption dataset, the proposed method provides lower energy consumption prediction errors than convolutional neural network (CNN), long short-term memory (LSTM), and CNN-LSTM. The NBO algorithm optimizer CNN-LSTM hyperparameters more accurately than Coati optimization algorithm, jellyfish search optimization, Harris hawks optimization (HHO), and African vultures optimization algorithm. Experiments on the State Grid Corporation of China dataset showed that the proposed method's accuracy, sensitivity, and precision in predicting energy theft are 98.93, 98.32, and 96.78%. The proposed method is more accurate than CNN, DeepCNN, CNN-LSTM, and the gated recurrent unit (GRU) method.},
  archive      = {J_SUPERC},
  author       = {Chahardoli, Meysam and Osati Eraghi, Nafiseh and Nazari, Sara},
  doi          = {10.1007/s11227-024-06811-5},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--51},
  shortjournal = {J. Supercomput.},
  title        = {An energy consumption prediction approach in smart cities by CNN-LSTM network improved with game theory and namib beetle optimization (NBO) algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-objective evolutionary algorithm based on dynamic mating and strengthened fitness selection mechanism. <em>SUPERC</em>, <em>81</em>(2), 1--77. (<a href='https://doi.org/10.1007/s11227-024-06821-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms have demonstrated their superiority in dealing with many-objective optimization problems. However, their performance in handling many objective optimization problems can be significantly affected due to the sensitivity on the curvature of Pareto front. This paper proposes the dynamic mating selection strategy and strengthened fitness selection mechanism to solve many objective optimization problems (MaOEA-DMSF). In MaOEA-DMSF, a dynamic mating selection strategy is proposed to select appropriate mating population, which can generate high-quality offspring with a higher probability. In addition, a strengthened fitness selection mechanism is proposed to improve convergence without deterioration in population diversity. To verify the effectiveness of the proposed MaOEA-DMSF, a series of experiments are carried out against eight state-of-the-art many-objective optimization algorithms on three widely used benchmark test suites. Experimental results demonstrate that the proposed MaOEA-DMSF has higher competitiveness compared with peer competitors.},
  archive      = {J_SUPERC},
  author       = {Li, Wei and Tang, Wenhao and Wang, Lei},
  doi          = {10.1007/s11227-024-06821-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--77},
  shortjournal = {J. Supercomput.},
  title        = {Many-objective evolutionary algorithm based on dynamic mating and strengthened fitness selection mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on trust-rating mechanism for WSN node sensors using evolutionary game theory. <em>SUPERC</em>, <em>81</em>(2), 1--35. (<a href='https://doi.org/10.1007/s11227-024-06824-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the critical security challenge posed by Sybil attacks in wireless sensor networks (WSNs), where a single node impersonates multiple identities to disrupt network operations. We propose a novel trust-rating mechanism based on evolutionary game theory, which incorporates incentives to foster cooperation and deter malicious behavior. By adjusting parameters such as P, $$\omega _{T}$$ , $$\varphi$$ , and $$\alpha$$ , network operators can guide the evolution of strategies toward desirable outcomes, including complete collaboration $$x_{2} = 1$$ . The stability of $$x_{2}$$ ensures robust defense against Sybil attacks, while $$x_{3}^{*}$$ identifies conditions under which partial collaboration may persist. Rigorous mathematical analysis and proofs support the mechanism’s foundation, showing that under favorable conditions (Theorem 2), collaboration strategies dominate, ensuring communication stability within the WSN. The derivation of evolutionarily stable strategies (ESS) demonstrates that system dynamics favor cooperation, which is validated through OMNET++ simulations. The results confirm the mechanism’s effectiveness in achieving ESS and enhancing WSN security, achieving a high true detection rate (TDR) of 99.8% and a low false detection rate (FDR) of 0.8%, outperforming existing Sybil detection methods.},
  archive      = {J_SUPERC},
  author       = {Navaei Tourani, Azadeh and Haj Seyyed Javadi, Hamid and Navidi, Hamidreza and Sharifi, Arash},
  doi          = {10.1007/s11227-024-06824-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {A study on trust-rating mechanism for WSN node sensors using evolutionary game theory},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dhcache: A dual-hash cache for optimizing the read performance in key-value store. <em>SUPERC</em>, <em>81</em>(2), 1--26. (<a href='https://doi.org/10.1007/s11227-024-06828-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key-value (KV) stores are widely utilized in data-intensive applications to obtain exceptional storage performance. However, its caching mechanism often suffers read and write pauses. Especially when accessing old data periodically, it results in cache hit ratios and system throughput decline. To address the performance degradation issue, we propose an innovative dual-hash caching mechanism called DHCache. Firstly, we introduce a dual-hash structure in DHCache. It alleviates read and write pauses by reducing the frequency of rehash operations on the hash table. Secondly, we employ a Most Recently Used (MRU) cache replacement policy on DHCache to retain old data. This enhances the cache hit ratios and throughput when periodically accessing old data. DHCache is deployed within LevelDB, demonstrating significant performance advantages. Experimental results indicate that DHCache improves throughput by 11.89–21.92% in various read workloads compared to traditional LRUCache. Significantly, read performance improvement does not come at the cost of write performance degradation.},
  archive      = {J_SUPERC},
  author       = {Lu, Jinkang and Lv, Meng and Li, Peixuan and Yuan, Zhu and Xie, Ping},
  doi          = {10.1007/s11227-024-06828-w},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Dhcache: A dual-hash cache for optimizing the read performance in key-value store},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Classification of EEG event-related potentials based on channel attention mechanism. <em>SUPERC</em>, <em>81</em>(2), 1--2. (<a href='https://doi.org/10.1007/s11227-024-06830-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Tang, Yiou and Ma, Yan and Xiao, Chunling and Wu, Min and Zeng, Guoyuan},
  doi          = {10.1007/s11227-024-06830-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--2},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Classification of EEG event-related potentials based on channel attention mechanism},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel solution of the controller and backup controller placement problem for improving reliability in IoT-based data monitoring systems. <em>SUPERC</em>, <em>81</em>(2), 1--32. (<a href='https://doi.org/10.1007/s11227-024-06846-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of the Internet of Things (IoT) is expanding, particularly in health and life application such as earthquake monitoring. Additionally, due to lower energy consumption, the use of long-range wide area network (LoRaWAN) is on the rise. However, in LoRaWAN architectures, challenges arise in terms of reliability. This is because LoRaWAN functions based on the ALOHA and faces channel selection and spreading factors (SF), as well as distortion, noise, and interference. This paper proposes an architecture for monitoring earthquake. To improve reliability, the first approach introduces an optimal controller placement, while the second provides an optimal backup controller placement algorithm. An error control process based on the Kalman filter is added to the system. Simulation results demonstrate these strategies reduces energy consumption by up to 40%. In the error control, propagation delay decreases by 60%, and in the controller placement, delay decreases by 40%. The packet delivery rate before corrections is 49.42%, while the average rate for the controller placement is 67.34% and for error control is 68.84%.},
  archive      = {J_SUPERC},
  author       = {Zangeneh, Iman and Bidgoli, Amir Massoud and Dolati, Ardeshir},
  doi          = {10.1007/s11227-024-06846-8},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Novel solution of the controller and backup controller placement problem for improving reliability in IoT-based data monitoring systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEVYEFO-WTMTOA: The hybrid of the multi-tracker optimization algorithm and the electromagnetic field optimization. <em>SUPERC</em>, <em>81</em>(2), 1--54. (<a href='https://doi.org/10.1007/s11227-024-06856-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of engineering optimization often faces significant challenges in efficiently exploring complex solution spaces to identify optimal configurations, frequently struggling with local optima and premature convergence. These issues are especially pronounced in traditional optimization algorithms when applied to high-dimensional or intricate engineering problems. This paper introduces the LEVYEFO-WTMTOA algorithm, an innovative hybrid that combines the modified multi-tracker optimization algorithm (MTOA) with the electromagnetic field optimization (EFO) approach. This integration effectively addresses the limitations of previous methods, such as stagnation in local optima and suboptimal search strategies. The evaluations using the CEC2018 benchmark suite demonstrate that the LEVYEFO-WTMTOA algorithm significantly outperforms existing algorithms, reducing the mean error by an average of 20%. Specifically, the presented algorithm achieved a maximum cost improvement of 31.03% in spring design and 32.15% in welded beam design. These results confirm the LEVYEFO-WTMTOA’s superior capability in handling complex optimization tasks, offering a powerful tool for algorithmic design in engineering applications and setting a new benchmark for performance in the field.},
  archive      = {J_SUPERC},
  author       = {Safi-Esfahani, Faramarz and Mohammadhoseini, Leili and Larian, Habib and Mirjalili, Seyedali},
  doi          = {10.1007/s11227-024-06856-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--54},
  shortjournal = {J. Supercomput.},
  title        = {LEVYEFO-WTMTOA: The hybrid of the multi-tracker optimization algorithm and the electromagnetic field optimization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: A hybrid machine learning approach for feature selection in designing intrusion detection systems (IDS) model for distributed computing networks. <em>SUPERC</em>, <em>81</em>(2), 1--3. (<a href='https://doi.org/10.1007/s11227-024-06869-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Pourardebil Khah, Yashar and Hosseini Shirvani, Mirsaeid and Motameni, Homayun},
  doi          = {10.1007/s11227-024-06869-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--3},
  shortjournal = {J. Supercomput.},
  title        = {Correction: A hybrid machine learning approach for feature selection in designing intrusion detection systems (IDS) model for distributed computing networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic sharding model and performance optimization method for consortium blockchain. <em>SUPERC</em>, <em>81</em>(2), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06870-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consortium blockchain has been widely used in finance, e-government due to the characteristics of controllability, supervision, and operability. However, traditional consortium blockchains have bottlenecks in throughput. To solve the bottlenecks, the paper proposes a Dynamic Sharding Model and Performance Optimization Method for Consortium Blockchain (DSPO-CB), which offers a new shard architecture and dynamically optimizes the architecture through the Deep Q-Network (DQN). Firstly, the model reduces redundancy and improves space utilization by classifying the nodes ensuring security. Secondly, the model proposes the shard structure through a dynamic clustering method based on the node status to reduce the proportion of cross-shard transactions. Finally, the DQN is used to dynamically optimize the sharding and consensus architecture. Experiments show that DSPO-CB improves the throughput by 33% and saves up to 78% storage space compared with the existing consortium blockchain.},
  archive      = {J_SUPERC},
  author       = {Wang, Yan and Gong, Zheng and Jia, Dayu and Tan, Aiping and Liu, Minchao},
  doi          = {10.1007/s11227-024-06870-8},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic sharding model and performance optimization method for consortium blockchain},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: A smart vista-lite system for anomaly detection and motion prediction for video surveillance in vibrant urban settings. <em>SUPERC</em>, <em>81</em>(2), 1. (<a href='https://doi.org/10.1007/s11227-024-06877-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Alasiry, Areej and Qayyum, Mohammed},
  doi          = {10.1007/s11227-024-06877-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: A smart vista-lite system for anomaly detection and motion prediction for video surveillance in vibrant urban settings},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Availability assessment of SDN-ICN service for multi-access edge computing. <em>SUPERC</em>, <em>81</em>(2), 1--32. (<a href='https://doi.org/10.1007/s11227-024-06879-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic on mobile and wireless networks has seen exponential growth in the last decade. With the advent of the fifth-generation (5 G) cellular technology, there is a strict requirement to ensure system availability, capacity, and reliability to provide operation services that work through wireless network mechanisms. Multi-access edge computing (MEC) is an appropriate approach for wireless access networks as such a technology. It provides support at the edge, encompassing the Mist, Fog, and Cloudlet paradigms. Additionally, software-defined networking (SDN) can enhance network performance and promote flexibility to support computation offloading and network slices. Therefore, stochastic models are important for designing MEC systems because they enable distinct arrangements to assess availability before implementing the real system. Thus, this paper presents a hierarchical modeling approach based on continuous-time Markov chains (CTMC), stochastic Petri nets (SPN), and reliability block diagrams (RBD) to assess the availability of an MEC system that adopts SDN for information-centric networks (ICN) context. Case studies demonstrate the practical feasibility of the proposed approach, in which results indicate system downtime can be reduced up to 97.52% using the conceived models to assess distinct redundancy techniques.},
  archive      = {J_SUPERC},
  author       = {Nascimento, Erick and Lins, Luan and Tavares, Eduardo and Pereira, Paulo and Dantas, Jamilson and Kosta, Sokol and Maciel, Paulo},
  doi          = {10.1007/s11227-024-06879-z},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Availability assessment of SDN-ICN service for multi-access edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging fog computing and software-defined networking for a novel velocity-aware routing protocol with election and handover thresholds in VANETs. <em>SUPERC</em>, <em>81</em>(2), 1--37. (<a href='https://doi.org/10.1007/s11227-024-06883-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular ad hoc networks (VANETs) facilitate real-time communication between vehicles and infrastructure, but ensuring efficient and reliable communication is a challenge due to the high mobility and dynamic nature of the network. To address these challenges, we propose an intelligent routing protocol that introduces a novel clustering algorithm for selecting cluster heads (CHs). The algorithm uses a weight function that considers vehicle speed, inter-vehicle distance, and lifetime within a cluster. This selection method enhances route stability, reduces long-range communication, and significantly lowers control overhead. Moreover, we developed a new architecture for cluster management in VANETs by redefining both the election and handover processes. In this new design, we establish distinct areas and threshold distances for each stage. The election area is where the current CH crosses the election threshold distance and initiates the election process for a new CH. Once the election is completed and a new CH is selected, the handover area comes into effect. This area marks the transition point where the responsibilities of the current CH are transferred to the newly elected CH. This modification enhances cluster management, improves communication reliability, and reduces control overhead during the transition phases. Additionally, our approach integrates advanced technologies such as fog computing for enhanced location awareness and software-defined networking (SDN) for increased programmability and scalability. A dual-phase strategy is employed, with SDN handling primary packet routing and AODV serving as a fallback mechanism in case of SDN failure, ensuring robust communication under varying network conditions. We evaluated our protocol using the NS3 simulator, comparing it with five existing VANET routing protocols, that are, IDVR, VDLA, IRTIV, GPCR, and ICDRP, on key performance metrics such as throughput and end-to-end (E2E) delay. We also compared it with CBDRP, BRAVE, MoZo, CORA, and ICDRP protocols on control overhead. The results show significant improvements in network performance, and particularly, throughput increases by 22,451.8%, 176,296.2%, 191,450.2%, 255,222.7%, and 69.6%, while E2E delay decreases by 87.35%, 90.16%, 92.79%, 97.61%, and 48.50% compared to IDVR, VDLA, IRTIV, GPCR, and ICDRP, respectively. Furthermore, Hello message overhead is reduced by 99.37%, 98.68%, 97.31%, 84.36%, and 11.24%, compared to CBDRP, BRAVE, MoZo, CORA, and ICDRP, respectively, while overall control overhead improves by 29.21% compared to ICDRP. Finally, our protocol achieves a 99% SDN packet delivery ratio and an E2E delay of less than 0.15 s, demonstrating superior performance across key metrics.},
  archive      = {J_SUPERC},
  author       = {Darabkh, Khalid A. and Al-Mistarihi, Mamoun F. and Odat, Bayan Abdallah},
  doi          = {10.1007/s11227-024-06883-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--37},
  shortjournal = {J. Supercomput.},
  title        = {Leveraging fog computing and software-defined networking for a novel velocity-aware routing protocol with election and handover thresholds in VANETs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFFCNN: Multi-scale fractional fourier transform convolutional neural network for multivariate time series forecasting. <em>SUPERC</em>, <em>81</em>(2), 1--31. (<a href='https://doi.org/10.1007/s11227-024-06888-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series Forecasting (MTSF) is challenging due to the difficulty of extracting complex periodic patterns from temporal data. Currently, many Transformer-based models and MLP-based models achieve success by using Fourier transform (FT) to extract periodic information from time series data. However, Transformer models perform well but use many resources. MLP models are lightweight but too simple to capture complex features. Recent studies show that CNN-based models offer a better balance between efficiency and performance, but they struggle to capture both coarse and fine-grained temporal features. In addition, the single perspective of FT limits its ability to represent complex periodic features. To address these issues, we propose the Multi-Scale Fractional Fourier Transform Convolutional Neural Network (MFFCNN) for MTSF. The fractional Fourier transform (FrFT) is an extension of the FT. It extracts periodic features from different angles by adjusting the rotation. MFFCNN uses these multi-scale features to generate adaptive patches for different datasets. Then, 2D convolution is applied to model relationships within and between patches, capturing both inter- and intra-series features from a multi-scale perspective. Results on ten benchmark datasets show that MFFCNN outperforms seven state-of-the-art models. Our code is stored in https://github.com/immortalityC?tab=repositories.},
  archive      = {J_SUPERC},
  author       = {Chen, Wuqi and Ye, Junjie and Zhao, Chunna and Huang, Yaqun},
  doi          = {10.1007/s11227-024-06888-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {MFFCNN: Multi-scale fractional fourier transform convolutional neural network for multivariate time series forecasting},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring data flow design and vectorization with oneAPI for streaming applications on CPU+GPU. <em>SUPERC</em>, <em>81</em>(2), 1--30. (<a href='https://doi.org/10.1007/s11227-024-06891-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, oneAPI has emerged as a competitive framework to optimize streaming applications on heterogeneous CPU+GPU architectures, since it provides portability and performance thanks to the SYCL programming language and efficient parallel libraries as oneTBB. However, this approach opens up a wealth of implementations alternatives in this type of applications: from how to design the data flow to how to exploit data parallelism. Choosing the best alternative is not trivial, so in this paper we analyze them and contribute with an analytical model based on queue theory that helps in the on-line selection of the alternative that maximizes the throughput and the occupancy of the CPU and GPU compute units. We explore the design space offered by: a) different APIs to define the data flow (parallel_pipeline and Flow Graph from oneTBB, and SYCL events from SYCL); b) alternative kernel implementations to express data parallelism (SYCL, AVX and std::simd); and c) the mapping of the kernels into the available computing resources (CPU cores and GPU). The results show that the std::simd library can be 1.54x faster, 3% more energy efficient, and requires 7.36x less programming effort than AVX, and that implementations that enable asynchronous offloading of tasks to the devices as those based on SYCL events and Flow Graph APIs outperform the other APIs, being up to 1.10x faster and up to 1.18x more energy efficient.},
  archive      = {J_SUPERC},
  author       = {Campos, Cristian and Asenjo, Rafael and Navarro, Angeles},
  doi          = {10.1007/s11227-024-06891-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Exploring data flow design and vectorization with oneAPI for streaming applications on CPU+GPU},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review of intermediate representations for quantum computing. <em>SUPERC</em>, <em>81</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11227-024-06892-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intermediate representations (IRs) are fundamental to classical and quantum computing, bridging high-level quantum programming languages and the hardware-specific instructions required for execution. This paper reviews the development of quantum IRs, focusing on their evolution and the need for abstraction layers that facilitate portability and optimization. Monolithic quantum IRs, such as QIR (Lubinski et al. in Front Phys 10:940293, 2022. https://doi.org/10.3389/fphy.2022.940293), QSSA (Peduri et al. in Proceedings of the 31st ACM SIGPLAN international conference on compiler construction. CC 2022. Association for Computing Machinery, New York, 2022), or Q-MLIR (McCaskey and Nguyen in Proceedings-2021 IEEE International Conference on Quantum Computing and Engineering, QCE, 2021), their effectiveness in handling abstractions, and their hybrid support between quantum-classical operations are evaluated. However, a key limitation is their inability to address qubit locality, an essential feature for distributed quantum computing (DQC). To overcome this, InQuIR (Nishio and Wakizaka in InQuIR: Intermediate Representation for Interconnected Quantum Computers, 2023. https://arxiv.org/abs/2302.00267) was introduced as an IR specifically designed for distributed systems, providing explicit control over qubit locality and inter-node communication. While effective in managing qubit distribution, InQuIR’s dependence on manual manipulation of communication protocols increases complexity for developers. NetQIR (Vázquez-Pérez et al. in NetQIR: An Extension of QIR for Distributed Quantum Computing, 2024. https://arxiv.org/abs/2408.03712), an extension of QIR for DQC, emerges as a solution to achieve the abstraction of quantum communications protocols. This review emphasizes the need for further advancements in IRs for distributed quantum systems, which will play a crucial role in the scalability and usability of future quantum networks.},
  archive      = {J_SUPERC},
  author       = {Cardama, F. Javier and Vázquez-Pérez, Jorge and Piñeiro, César and Pichel, Juan C. and Pena, Tomás F. and Gómez, Andrés},
  doi          = {10.1007/s11227-024-06892-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Review of intermediate representations for quantum computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Singularity to deploy HPC applications: A study case with WRF. <em>SUPERC</em>, <em>81</em>(2), 1--22. (<a href='https://doi.org/10.1007/s11227-024-06893-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study evaluates the performance and portability of the Weather Research and Forecasting model in high-performance computing environments, comparing traditional baremetal deployments with containerized executions using Singularity. Experiments were conducted on the TeideHPC system, focusing on execution time, the impact of different compilers (Intel vs. GCC), and parallelization strategies (MPI and OpenMP). The results indicate that while Singularity introduces a performance overhead of 11 to 15%, it offers significant advantages in portability and reproducibility. Additionally, the study highlights the importance of compiler choice and the influence of container image size on startup times, emphasizing the need for careful optimization in containerized HPC workflows.},
  archive      = {J_SUPERC},
  author       = {Tondreau, Pierre-Simon Callist Yannick and Perez, Juan C. and Díaz, Juan P. and Blanco Pérez, Vicente and Felipe, Jonatan},
  doi          = {10.1007/s11227-024-06893-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {Singularity to deploy HPC applications: A study case with WRF},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improve accuracy in CNNs while using approximate computing methods. <em>SUPERC</em>, <em>81</em>(2), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06901-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks have been one of the science’s most influential and essential branches in the past decades. Neural networks have found applications in various fields including medical and pharmaceutical services, voice and speech recognition, computer vision, natural language processing, and video and image processing. Neural networks have many layers and consume much energy. Approximate computing is a promising way to reduce energy consumption in applications that can tolerate a degree of accuracy reduction. This paper proposes an effective method to prevent accuracy reduction after using approximate computing methods in the CNNs. The method exploits the k-means clustering algorithm to label pixels in the first convolutional layer. Then, using one of the existing pruning methods, different pruning amounts have been applied to all layers. The experimental results on three CNNs and four different datasets show that the accuracy of the proposed method has significantly improved (by 17%) compared to the baseline network.},
  archive      = {J_SUPERC},
  author       = {Rafieinejad, Mohammadreza and Marvasti, Mohammadreza Binesh and Asghari, Seyyed Amir and Shahbakhti, Kimiya},
  doi          = {10.1007/s11227-024-06901-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Improve accuracy in CNNs while using approximate computing methods},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using deep learning on microscopic images for white blood cell detection and segmentation to assist in leukemia diagnosis. <em>SUPERC</em>, <em>81</em>(2), 1--42. (<a href='https://doi.org/10.1007/s11227-024-06903-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and accurate diagnosis of leukemia is essential to increase the chances of successful treatment. However, manual analysis of bone marrow cells is a time-consuming process prone to errors. With advancements in health technologies, automating the detection of leukemic cells has become indispensable to accelerating and improving diagnostic accuracy. This study proposes the Y-YOLOv10 model, which combines Principal Component Analysis (PCA) to reduce the dimensionality of images and the YOLOv10 model for real-time detection, distinguishing 12 types of white blood cells. To enhance the diversity and robustness of training, six public datasets were combined, resulting in a comprehensive and representative dataset. Additionally, seven advanced data augmentation techniques were applied, including rotation, zoom, blurring, noise addition, contrast adjustment, horizontal and vertical flips, and cropping. These techniques were used alongside the original data, generating realistic variations and improving the model’s ability to handle real-world laboratory scenarios. Furthermore, H.264 compression artifacts were introduced during training to simulate conditions of reduced image quality, making the Y-YOLOv10 robust to variations in acquisition quality. The Y-YOLOv10 achieved average performances of 96.85% accuracy, 95.21% recall, and 96.76% F1-score, outperforming methods such as YOLOv8 and ResNet50. Additionally, H.264 compression allowed for a 30–40% reduction in data size while maintaining high performance and faster processing times. This study highlights the potential of lightweight deep learning models to improve leukemia classification, reduce the workload of specialists, and ensure a robust and adaptable system for various application conditions.},
  archive      = {J_SUPERC},
  author       = {Ferreira, Fernando Rodrigues Trindade and do Couto, Loena Marins},
  doi          = {10.1007/s11227-024-06903-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {Using deep learning on microscopic images for white blood cell detection and segmentation to assist in leukemia diagnosis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent energy pairing scheduler (InEPS) for heterogeneous HPC clusters. <em>SUPERC</em>, <em>81</em>(2), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06907-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, energy consumption has become a limiting factor in the evolution of high-performance computing (HPC) clusters in terms of environmental concern and maintenance cost. The computing power of these clusters is increasing, together with the demands of the workloads they execute. A key component in HPC systems is the workload manager, whose operation has a substantial impact on the performance and energy consumption of the clusters. Recent research has employed machine learning techniques to optimise the operation of this component. However, these attempts have focused on homogeneous clusters where all the cores are pooled together and considered equal, disregarding the fact that they are contained in nodes and that they can have different performances. This work presents an intelligent job scheduler based on deep reinforcement learning that focuses on reducing energy consumption of heterogeneous HPC clusters. To this aim it leverages information provided by the users as well as the power consumption specifications of the compute resources of the cluster. The scheduler is evaluated against a set of heuristic algorithms showing that it has potential to give similar results, even in the face of the extra complexity of the heterogeneous cluster.},
  archive      = {J_SUPERC},
  author       = {López, Marta and Stafford, Esteban and Bosque, Jose Luis},
  doi          = {10.1007/s11227-024-06907-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Intelligent energy pairing scheduler (InEPS) for heterogeneous HPC clusters},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced mechanism for malicious URL detection using deep learning and DistilBERT-based feature extraction. <em>SUPERC</em>, <em>81</em>(2), 1--35. (<a href='https://doi.org/10.1007/s11227-024-06908-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s digital age, the rapid increase in online activities has heightened web users’ privacy risks, making them more susceptible to various cyber-attacks. Among these, phishing is one of the most widespread threats in cybersecurity. Phishing employs deceitful tactics to lure individuals and organizations into visiting malicious URLs and disclosing sensitive information, such as passwords, credit card details, and personal data. These attacks are carefully crafted to mislead users into believing they are interacting with legitimate websites or online services, to steal account information for malicious purposes. To address the limitations of traditional phishing detection methods—such as their inability to detect zero-day attacks, high rates of false positives and negatives, and the need for frequent updates to list-based approaches (e.g., blacklists and whitelists)—this paper presents an advanced approach for identifying malicious URLs by integrating transformer learning and deep learning techniques. Specifically, Distilled Bidirectional Encoder Representations from Transformers (DistilBERT) extracts features from URLs and captures relevant textual information. A hybrid deep learning model combining convolutional neural network (CNN) and long short-term memory (LSTM) layers is then applied to classify the dataset into malicious and legitimate URLs. The novelty of this method lies in combining DistilBERT with a hybrid deep learning model (CNN-LSTM) to detect malicious URLs. The proposed approach was evaluated on two large public datasets to test its effectiveness under various conditions. Experimental results demonstrate that it performs exceptionally well, achieving the highest accuracy of 98.19%, and outperforming some comparable methods in the literature on similar datasets. This proves that the integration of DistilBERT and the hybrid CNN-LSTM model is successful in detecting malicious URLs. DistilBERT optimizes the feature extraction process, while the CNN-LSTM model leverages the strengths of both models and mitigates the limitations of each, resulting in a more comprehensive approach to classification.},
  archive      = {J_SUPERC},
  author       = {Zaimi, Rania and Safi Eljil, Khouloud and Hafidi, Mohamed and Lamia, Mahnane and Nait-Abdesselam, Farid},
  doi          = {10.1007/s11227-024-06908-x},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {An enhanced mechanism for malicious URL detection using deep learning and DistilBERT-based feature extraction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing open-world object detection with AIGC-generated datasets and elastic weight consolidation. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06910-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel approach to enhancing open-world object detection (OWOD) models by combining artificial intelligence generated content and elastic weight consolidation (EWC). To address the issue of low category richness and mitigate catastrophic forgetting, we first utilize stable diffusion with low-rank adaptation (LoRA) fine-tuning to generate customized detection target datasets. These datasets are then employed to train an improved open-world region-based efficient model, incorporating an EWC module to constrain parameter changes during learning new tasks. Experimental results demonstrate that our approach achieves a mean average precision of 84.7% on the generated datasets, significantly improving category richness while mitigating forgetting of previously learned categories. The proposed method effectively balances learning new categories and retaining memory of old ones, advancing the frontiers of OWOD research.},
  archive      = {J_SUPERC},
  author       = {Xue, Wenjin and Xu, Guowei and Yang, Nan and Liu, Jian},
  doi          = {10.1007/s11227-024-06910-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Enhancing open-world object detection with AIGC-generated datasets and elastic weight consolidation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy rule-based intelligent cardiovascular disease prediction using complex event processing. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06911-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease (CVDs) is a rapidly rising global concern due to unhealthy diets, lack of physical activity, and other factors. According to the World Health Organization (WHO), primary risk factors include elevated blood pressure, glucose, blood lipids, and obesity. Recent research has focused on accurate and timely disease prediction to reduce risk and fatalities, often relying on predictive models trained on large datasets, which require intensive training. An intelligent system for CVDs patients could greatly assist in making informed decisions by effectively analyzing health parameters. CEP has emerged as a valuable method for solving real-time challenges by aggregating patterns of interest and their causes and effects on end users. In this work, a fuzzy rule-based system is proposed for monitoring clinical data to provide real-time decision support. A fuzzy rule based on clinical and WHO standards ensures accurate predictions. The integrated approach uses Apache Kafka and Spark for data streaming, and the Siddhi CEP Engine for event processing. Additionally, numerous cardiovascular disease-related parameters are passed through CEP Engine to ensure fast and reliable prediction decisions. To validate the effectiveness of the approach, simulation is done with real-time, unseen data to predict cardiovascular disease. Using synthetic data (1000 samples), and categorized it into "Very Low Risk, Low Risk, Medium Risk, High Risk, and Very High Risk." Validation results showed that 20% of samples were categorized as very low risk, 15–45% as low risk, 35–65% as medium risk, 55–85% as high risk, and 75% as very high risk.},
  archive      = {J_SUPERC},
  author       = {Kumar, Shashi Shekhar and Chandra, Ritesh and Harsh, Anurag and Agarwal, Sonali},
  doi          = {10.1007/s11227-024-06911-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Fuzzy rule-based intelligent cardiovascular disease prediction using complex event processing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward privacy-preserving verifiable DSSE for attribute-based cloud computing system. <em>SUPERC</em>, <em>81</em>(2), 1--25. (<a href='https://doi.org/10.1007/s11227-024-06912-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic symmetric searchable encryption (DSSE) allows clients to perform keyword searches and updates on encrypted databases outsourced to cloud servers. Ensuring forward privacy is a crucial security property for DSSE schemes to protect data privacy. However, existing forward-private DSSE schemes face significant limitations: they either rely on an honest-but-curious server, assuming it always returns correct search results without providing verification functionality, or they lack support for fine-grained attribute-based searches and access control. As a result, these schemes cannot be directly applied to attribute-based databases. In this paper, we propose the first verifiable forward-private DSSE scheme suitable for attribute-based databases. Specifically, we construct a secure index based on attribute elements to realize fine-grained searches on attribute-value type databases while ensuring the forward privacy of the scheme. We also design a novel verification tag using symmetric homomorphic encryption to verify the correctness of search results. In addition, our scheme achieves access control functionality to ensure that different users can only access authorized files. Experimental evaluations show that our scheme has advantage in the update, search and verification processes. And the security analysis proves our scheme is secure.},
  archive      = {J_SUPERC},
  author       = {Peng, Tianqi and Gong, Bei and Sun, Pengxuan},
  doi          = {10.1007/s11227-024-06912-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Toward privacy-preserving verifiable DSSE for attribute-based cloud computing system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rock block fall prediction prototype by structural control applied to slopes using quantum machine learning (QML). <em>SUPERC</em>, <em>81</em>(2), 1--30. (<a href='https://doi.org/10.1007/s11227-024-06913-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural and man-made rock collapses are complex phenomena and cause serious dangers in many countries around the world. As a result, millions of dollars’ worth of public and private property are damaged. It is then crucial to investigate the stability of the slopes to prevent these rockfall disasters. This study presents a new approach to evaluate the probability of rock block falls on slopes, focusing on the management of geological structures that influence the stability and safety of mining operations. Because the need to support slopes is currently expensive, and in practice, their assessment is often subjective, because in some cases, the simulated failure mechanisms are not met in the field due to the existence of additional factors that are not introduced in the simulation, which motivates the search for an accurate and efficient tool that includes more variables and offers greater safety. For this reason, we propose to evaluate the stability of slopes with the help of conventional machine learning (ML) models and innovative quantum machine learning (QML) algorithms in order to ensure their structural stability. Our objective is to evaluate the various existing ML metrics with test data taken from a mine for different types of quantum embedding and to discuss their reliability. The model finds acceptable successes in the total calculation of true positives (TP) and true negatives (TN), which indicates the degree of accuracy in the positive and negative predictions made by our proposal. In this way, it is contrasted that the incorporation of QML algorithms into the application represents an innovation in the evaluation of the stability of rocky slopes, allowing to obtain a good reliability in the evaluation of the stability of the slopes.},
  archive      = {J_SUPERC},
  author       = {Cisneros Eufracio, Alfredo and Perez Alvarado, Roberth Saenz and Rosales Huamani, Jimmy Aurelio and Villanueva, Uwe Rojas and Castillo Sequera, Jose Luis and Gomez Pulido, Jose Manuel},
  doi          = {10.1007/s11227-024-06913-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Rock block fall prediction prototype by structural control applied to slopes using quantum machine learning (QML)},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lagrange stability of quaternion-valued memristive neural networks on time scales: Linear optimization method. <em>SUPERC</em>, <em>81</em>(2), 1--20. (<a href='https://doi.org/10.1007/s11227-024-06914-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the issue of Lagrange stability of quaternion-valued memristive neural networks. First, by scale-limited Halanay inequality, new Lagrange stability algebraic conditions are obtained. Considering that the memristive connections are switching between two different parameters, thus, the memristive model is equivalent to a robust system by introducing some new matrices, we then use the generalized matrix measure to solve the time scales matrix norm issues, and all the derived scale-limited sufficient criteria not only apply to continuous-time system and their discrete-time analogs, but also satisfy the system with uncertain terms. Eventually, illustrations are addressed to reflect the solvability and practicability of the strategy.},
  archive      = {J_SUPERC},
  author       = {Li, Ruoxia and Si, Linli and Cao, Jinde},
  doi          = {10.1007/s11227-024-06914-z},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Lagrange stability of quaternion-valued memristive neural networks on time scales: Linear optimization method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust graph neural networks based on feature fusion. <em>SUPERC</em>, <em>81</em>(2), 1--20. (<a href='https://doi.org/10.1007/s11227-025-06917-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving landscape of graph neural networks (GNNs), this work is focused on dealing with the inherent challenges posed by noise and adversarial interferences in network-structured data. We propose an innovative GNN model with feature fusion (FFGNN) designed to enhance the resilience and reliability of GNNs in the face of practical scenarios. FFGNN introduces a denoising module to enhance robustness and suppress excessive feature smoothing, while incorporating an attention mechanism to improve model performance. Experimental validation on benchmark datasets, including Cora, CiteSeer and PubMed, demonstrates the superiority of our algorithm framework in various scenarios. We evaluated the performance of FFGNN under different conditions, such as feature noise, adversarial attacks, and clean data, showing that the complementary denoising and attention modules significantly enhance the model’s robustness and accuracy compared to other baseline models. This work represents a paradigm shift in GNN design, offering a novel approach to graph signal denoising and ensuring stable performance across diverse applications.},
  archive      = {J_SUPERC},
  author       = {Jin, Yan and Shi, Haoyu and Meng, Huaiye},
  doi          = {10.1007/s11227-025-06917-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {Robust graph neural networks based on feature fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking the power of optimized data balancing ratios: A new frontier in tackling imbalanced datasets. <em>SUPERC</em>, <em>81</em>(2), 1--62. (<a href='https://doi.org/10.1007/s11227-025-06919-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data balancing methods eliminate the problem of imbalanced class distributions, which often lead to the majority class being well-learned while the minority class remains underrepresented, negatively affecting classification performance. This study applies data balancing to the healthcare domain, a critical field where classification success directly impacts human life. The primary aim is to introduce novel balancing methods while addressing the previously overlooked problem of optimizing data balancing ratios. Six healthcare datasets were used: Wisconsin Diagnostic Breast Cancer (WDBC), Wisconsin Prognostic Breast Cancer (WPBC), Z-Alizadeh Sani, Kidney, Diabetes, and Stroke, all characterized by significant diseases and imbalanced class distributions. Six balancing methods were tested, including synthetic minority oversampling technique (SMOTE), adaptive synthetic sampling (ADASYN), support vector machine-SMOTE (SVM-SMOTE), Borderline-SMOTE, cubic interpolation, and quadratic interpolation, with interpolation-based methods being adapted to this domain for the first time. The critical factor in data balancing is identifying the optimal ratio that maximizes classification performance. In this study, particle swarm optimization (PSO), whale optimization algorithm (WOA), and Optuna optimization methods were used to optimize balancing ratios via a custom-designed fitness function that simultaneously optimizes classification accuracy and resource consumption. Classification was conducted for three scenarios: full balance, optimized balance, and imbalance, using support vector machine (SVM), random forest (RF), and ensemble learning (EL) classifiers, allowing for extensive analysis. Each combination of balancing methods, classifiers, and optimization techniques was separately analyzed using metrics such as accuracy, precision, recall, F1-score, time, central processing unit (CPU) usage, and memory usage. As a result, the combination that optimally balances classification accuracy and resource consumption was determined for each dataset, providing both comprehensive analysis and insights into the impact of balancing ratio optimization on diagnostic success in health care.},
  archive      = {J_SUPERC},
  author       = {Aymaz, Samet},
  doi          = {10.1007/s11227-025-06919-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--62},
  shortjournal = {J. Supercomput.},
  title        = {Unlocking the power of optimized data balancing ratios: A new frontier in tackling imbalanced datasets},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MEKF: Long-tailed visual recognition via multiple experts with knowledge fusion. <em>SUPERC</em>, <em>81</em>(2), 1--18. (<a href='https://doi.org/10.1007/s11227-025-06920-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of data in real-world applications often shows a long-tailed shape, making long-tailed recognition challenging as traditional models bias toward majority categories. Multi-expert ensemble methods have shown promise but often suffer from insufficient expert diversity and high model variance. To address these issues, we propose multiple experts with knowledge fusion (MEKF), which includes diversified fusion experts and dual-view self-distillation. MEKF enhances expert diversity by fusing features of different depths and introduces distribution diversity loss with distribution weights. Dual-view self-distillation reduces model variance by extracting semantic information from weakly augmented data predictions. Experiments on CIFAR100-LT, ImageNet-LT, and Places-LT benchmarks validate MEKF’s effectiveness, showing excellent performance.},
  archive      = {J_SUPERC},
  author       = {Zhang, Qian and Ji, Chenghao and Shao, Mingwen and Liang, Hong},
  doi          = {10.1007/s11227-025-06920-9},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {MEKF: Long-tailed visual recognition via multiple experts with knowledge fusion},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAQT: Multi-scale attention and query-optimized transformer for end-to-end pose estimation. <em>SUPERC</em>, <em>81</em>(2), 1--20. (<a href='https://doi.org/10.1007/s11227-025-06923-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are rapidly turning their focus to human pose estimation as a crucial area of computer vision. In light of the shortcomings of existing Transformer-based pose estimate methods when handling localized features, this work presents MAQT, an enhanced end-to-end method aimed at precise multi-human body pose estimation. To improve the localization of keypoints that are sensitive to scale changes, MAQT offers an Asym-Fusion block. Additionally, we design a new query strategy to optimize the initial selection of queries with Uncertainty-minimal Query Selection. Two self-attention mechanisms are used in the decoding phase for understanding and recording spatial and semantic connections between keypoints. In this paper, the MAQT method is validated on the MS COCO and CrowdPose datasets, and favorable experimental results are obtained.},
  archive      = {J_SUPERC},
  author       = {Liang, Hong and Wang, Cuiping and Shao, Mingwen and Zhang, Qian},
  doi          = {10.1007/s11227-025-06923-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--20},
  shortjournal = {J. Supercomput.},
  title        = {MAQT: Multi-scale attention and query-optimized transformer for end-to-end pose estimation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AlzONet: A deep learning optimized framework for multiclass alzheimer’s disease diagnosis using MRI brain imaging. <em>SUPERC</em>, <em>81</em>(2), 1--40. (<a href='https://doi.org/10.1007/s11227-025-06924-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD), characterized by progressive neurological degeneration and cognitive decline, necessitates early detection for effective intervention before symptom onset. Deep learning (DL) methodologies have emerged as promising tools for predicting and classifying AD. In this context, Convolutional Neural Networks (CNNs) exhibit proficiency in discerning specific AD features, enabling accurate diagnosis. To this end, this study proposes an effective deep learning optimized CNN model, namely, AlzONet, tailored to address the intricate challenges of Alzheimer’s patient brain classification. To explore the generalization of the AlzONet model through three gradient optimization algorithms: Adam, SGD, and RMSProp, this study focuses on how each algorithm impacts the model’s ability to minimize the loss function during training and how well it generalizes to new, unseen data. The Kaggle AD dataset, which includes normal, mild, very mild, and moderate stages, assesses the model’s performance. K fold cross-validation is applied to evaluate the model’s efficacy and generalization capability reliably. In contrast, a transfer learning-based comparison was conducted with five pre-trained models (VGG-16, DenseNet-121, ResNet-50, Inception-V3, and Xception). The results reveal that AlzONet trained with Adam achieves exceptional accuracy of 98.1% with a learning rate of 0.0001, while SGD and RMSProp yield 97.3% and 96.6% with a learning rate of 0.001 during training. In the testing phase, the optimized AlzONet model with Adam surpasses expectations with 96.5% accuracy, 96.7% F1-score, and 99.7% AUC.},
  archive      = {J_SUPERC},
  author       = {Alahmed, Hiba A. and Al-Suhail, Ghaida A.},
  doi          = {10.1007/s11227-025-06924-5},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {AlzONet: A deep learning optimized framework for multiclass alzheimer’s disease diagnosis using MRI brain imaging},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-time-scale with clockwork recurrent neural network modeling for sequential recommendation. <em>SUPERC</em>, <em>81</em>(2), 1--31. (<a href='https://doi.org/10.1007/s11227-025-06925-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation (SR) methods improve accuracy by considering the temporal sequence of user-item interactions rather than treating interaction histories as static sets. In this paper, we address the problem of implicit representation learning for multi-time-scale user interests by proposing a novel method based on user behavior sequence modeling—multi-time-scale with clockwork recurrent neural network modeling for sequential recommendation (MTSC). Specifically, firstly, we group the neurons of the hidden layer of the recurrent neural network (RNN) based on the clockwork RNN (CW-RNN) method according to the different degrees of dynamic changes of user interests. Secondly, we design different update frequencies to extract user interest features at multiple time scales. Finally, we model the dependency of user interest features at different time scales through scale-dimensional convolution to generate a unified representation of user interest features at multiple time scales, which can be used to predict the items of interest to users. To validate its effectiveness, we conducted extensive experiments on three public datasets, and the results demonstrate that the MTSC model achieves state-of-the-art performance across all baselines. More precisely, on the Steam dataset, the Precision@10 metric of the MTSC model improved by 4.73% compared to the best baseline model, robustly validating the effectiveness and superiority of the proposed method.},
  archive      = {J_SUPERC},
  author       = {Huang, Nana and Ding, Hongwei and Hu, Ruimin and Jiao, Pengfei and Zhao, Zhidong and Yang, Bin and Zheng, Qi},
  doi          = {10.1007/s11227-025-06925-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Multi-time-scale with clockwork recurrent neural network modeling for sequential recommendation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LogCTBL: A hybrid deep learning model for log-based anomaly detection. <em>SUPERC</em>, <em>81</em>(2), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06926-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System logs are used to record the operational status of a system and significant events, and by performing anomaly detection on these logs, system faults can be rapidly and accurately identified. However, existing anomaly detection methods encounter difficulties with features that exhibit complex relationships, thereby limiting detection accuracy. Furthermore, the majority of methods depend on supervised learning, which hinders the detection of abnormal logs in large, unlabeled datasets. To address these limitations, this paper proposes a novel semi-supervised log anomaly detection model, termed LogCTBL (CNN-TCN-Bi-LSTM). Firstly, the model parses raw logs using the Drain3 tool. Secondly, it applies BERT for semantic embedding, thereby addressing the issue of log statement discreteness. Thirdly, the model further employs the HDBSCAN (hierarchical density-based spatial clustering of applications with noise) algorithm to estimate dummy tags for unlabeled data in the training set, thereby addressing the challenge of insufficient labeled data. Finally, the hybrid model is then applied to anomaly detection, and the efficacy of the proposed method is evaluated on the BGL and Thunderbird datasets. The findings demonstrate that the proposed method surpasses alternative approaches, attaining F1 scores of 99.87% and 99.78% in the two datasets, respectively.},
  archive      = {J_SUPERC},
  author       = {Huang, Hong and Luo, Wengang and Wang, Yunfei and Zhou, Yinghang and Huang, Weitao},
  doi          = {10.1007/s11227-025-06926-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {LogCTBL: A hybrid deep learning model for log-based anomaly detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient video transformer network with token discard and keyframe enhancement for action recognition. <em>SUPERC</em>, <em>81</em>(2), 1--22. (<a href='https://doi.org/10.1007/s11227-025-06927-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing video transformers divide the video frames into a long sequence of tokens and perform self-attention computation among all tokens. However, the tokens corresponding to background information have little effect, and complete utilization of these tokens would generate a lot of computational redundancy. Based on this observation, we design an efficient video transformer named TDKE, which adaptively discards unimportant tokens and solely utilizes important tokens during the inference process. Specifically, the backbone of the TDKE is a 12-layer video transformer, which can be divided into two main parts. The first part, named the Scanner module, is composed of the first two transformer layers. The second part, named the Delicacy module, is composed of the remaining ten transformer layers. The Scanner module quickly discards unimportant tokens of each frame and selects a keyframe. Among them, the importance of each token is measured by pre-calculated attention maps, and the frame with the highest importance score is defined as the keyframe. The Delicacy module uses a weight enhancement technology to the keyframe and further discards redundant tokens based on our enhanced attention maps. We evaluate TDKE on two action recognition datasets, Kinetics-400 and SSv2. The results confirm that TDKE is efficient. For example, TDKE achieved a Top-1 accuracy of 77.8% on the Kinetics-400 dataset using only 306 GFLOPs.},
  archive      = {J_SUPERC},
  author       = {Zhang, Qian and Yang, Zuosui and Shao, Mingwen and Liang, Hong},
  doi          = {10.1007/s11227-025-06927-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--22},
  shortjournal = {J. Supercomput.},
  title        = {An efficient video transformer network with token discard and keyframe enhancement for action recognition},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A small defect detection technique for industrial product surfaces based on the EA-YOLO model. <em>SUPERC</em>, <em>81</em>(2), 1--26. (<a href='https://doi.org/10.1007/s11227-025-06929-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in industrial products is vital for ensuring product quality. Ensuring real-time performance, while improving the detection accuracy of low-pixel-resolution small defects against background interference poses a significant challenge. To address this, the EA-YOLO model, based on Yolov8, is proposed. It includes three main improvements: replacing C2f (Faster Implementation of CSP Bottleneck with 2 convolutions) with a specially designed C2FN (Faster Implementation of CSP FastNet Block with 2 convolutions Network) in the backbone module to reduce parameters and GFLOPs, while enhancing speed; introducing the Environmental Awareness Dynamic Network (EADN) to prevent the loss of defect information in extreme positions; and using the improved Dynamic Adaptive Fusion Detector (DAF-Detect) for predictions. Case studies with the NEU-DET and PCB-DET datasets show that EA-YOLO achieves a mAP of 81.1 and 97.8%, respectively, improving by 4.3 and 4.1% compared to the baseline model, with reduced parameters, GFLOPs, and increased FPS, demonstrating good robustness and generalization ability.},
  archive      = {J_SUPERC},
  author       = {Li, Biao and Wang, Bing and Hu, Xiong and Zhai, Jianhui and Ji, Changping},
  doi          = {10.1007/s11227-025-06929-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {A small defect detection technique for industrial product surfaces based on the EA-YOLO model},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilinear diffusion graph convolutional network model for social recommendation. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-025-06930-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces a bilinear diffusion graph convolutional network (BiDGCN) to address the pervasive issue of data sparsity in collaborative filtering recommendation systems. By integrating user social interactions with graph convolutional networks, the BiDGCN captures both user–neighbor and neighbor–neighbor interactions through diffusion and bilinear aggregation mechanisms. This dual aggregation approach dynamically models social influence, significantly enhancing user representation and recommendation accuracy. Experimental evaluations on the Yelp and Flickr datasets demonstrate the efficacy of the model, achieving a 5% higher hit rate and a 6% improvement in normalized discounted cumulative gain compared to state-of-the-art models. The BiDGCN provides a robust solution for social recommendation tasks, overcoming data sparsity while delivering superior predictive performance.},
  archive      = {J_SUPERC},
  author       = {Prasad, Chandrabhushan and Saritha, Sri Khetwat and Jain, Sweta},
  doi          = {10.1007/s11227-025-06930-7},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Bilinear diffusion graph convolutional network model for social recommendation},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level navigation network: Advancing fine-grained visual classification. <em>SUPERC</em>, <em>81</em>(2), 1--19. (<a href='https://doi.org/10.1007/s11227-025-06933-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification (FGVC) is defined as the finer division of sub-categories within basic categories. The task is both valuable and challenging. Its difficulty primarily arises from its intrinsic slight inter-class variations and substantial intra-class differences. The crucial solution to FGVC lies in identifying local regions with subtle yet discriminative features and effectively representing them. Nevertheless, with the increasing prevalence of deep convolutional neural networks, researchers have primarily prioritized the use of high-level, abstract, semantic features to achieve FGVC, consequently overlooking low-level, detailed information, resulting in poor feature representation capabilities. Thus, we put forward the multi-level navigation network, denoted as MLNN, to enhance feature representation by incorporating both high-level semantics and low-level details. Specifically, MLNN is composed of (1) the feature refinement and attention enhancement module, which enables the network to learn detailed feature representations and further enhance features with attention mechanisms, and (2) the triplet-enhanced multi-level fusion module, which integrates the features of different levels, leading to a more comprehensive feature representation. Experimental outcomes reveal that our approach attains state-of-the-art performance on three widely-accepted benchmark datasets.},
  archive      = {J_SUPERC},
  author       = {Liang, Hong and Li, Xian and Shao, Mingwen and Zhang, Qian},
  doi          = {10.1007/s11227-025-06933-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {Multi-level navigation network: Advancing fine-grained visual classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defocus deblur method of multi-scale depth-of-field cross-stage fusion image based on defocus map forecast. <em>SUPERC</em>, <em>81</em>(2), 1--25. (<a href='https://doi.org/10.1007/s11227-025-06934-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defocus blur often arises in images captured with wide apertures and shallow depth of field, presenting significant challenges due to its spatial variability and difficulty in estimation. Existing methods for defocus and deblurring typically address overall blur but struggle with varying blur effects across different depths of field. To tackle this issue, we propose a novel approach that estimates defocus maps and performs multi-scale defocus deblurring through cross-stage fusion of multi-scale depth-of-field images. Our method, inspired by optimizing the pupil mask in monocular ranging, utilizes all-pixel dual-core focus sensing technology to estimate defocus blur for each pixel. We independently solve for the blur kernels of left and right parallax images, establishing a connection between depth of field and defocus in the form of a defocus map. This approach enables the recovery of fully focused images through multi-scale depth-of-field cross-stage fusion. By leveraging global information features from dual-pixel image sensing, our method significantly improves the handling of defocus blurring across different depth-of-field scales and outperforms recent defocus and deblurring methods in both quantitative and qualitative assessments.},
  archive      = {J_SUPERC},
  author       = {Li, Pei and Bai, Tong and Pan, Xiaoying and Zuo, Chengyu},
  doi          = {10.1007/s11227-025-06934-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Defocus deblur method of multi-scale depth-of-field cross-stage fusion image based on defocus map forecast},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobile recognition system for multinational currencies based on CA-DSC-RepVGG algorithm. <em>SUPERC</em>, <em>81</em>(2), 1--27. (<a href='https://doi.org/10.1007/s11227-025-06936-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) continue to present challenges in the form of redundant network architectures, high computational intensity, and difficulties in deployment on an expanding array of embedded devices for the practical task of multi-country currency image recognition. This paper proposes a new lightweight multinational banknote recognition model, designated CA-DSC-RepVGG. The backbone network employs the RepVGG-A0 network, and a lightweight CA coordinate attention mechanism is introduced after the residual structure of the backbone network. This enhances the feature extraction capability by emphasizing the information representation. Concurrently, the conventional convolution in the residual structure is enhanced through the utilization of depth-separable convolution. Subsequently, the CA-DSC-RepVGG model is deployed to the rk3568 embedded device. A series of comparative experiments were conducted on three contemporary banknote image datasets: Australian Dollar, Euro, and US Dollar. The experimental results demonstrate that CA-DSC-RepVGG enhances accuracy by 1.05% and reduces the number of parameters by 78.4% in comparison with the pre-improvement period. Following deployment on rk3568 for testing purposes, the average accuracy value was found to be 99.79%. The single image inference process took approximately 9.83 ms, while the detection speed was approximately 101.73 f/s. These results demonstrate that the system meets the requirements for real-time and embedded device deployment of multi-country banknote algorithms in industrial applications.},
  archive      = {J_SUPERC},
  author       = {Yang, Xiaonan and Zhao, Zuoxi and Yuan, Kai and Xiao, Can and Luo, YangFan},
  doi          = {10.1007/s11227-025-06936-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Mobile recognition system for multinational currencies based on CA-DSC-RepVGG algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved jaya algorithm for energy-efficient distributed heterogeneous permutation flow shop scheduling. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-025-06938-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing studies on distributed permutation flow shop scheduling assume identical shops, overlooking the impact of heterogeneous shops. This paper addresses the energy-efficient distributed heterogeneous permutation flow shop scheduling problem, which accounts for variations in energy consumption when jobs are processed on different machines in heterogeneous factories. Several research gaps are stated following: (1) Previous studies predominantly use the NEH algorithm and its variants, which require substantial computational resources, while a single random initialization strategy fail to generate a high-quality population. (2) The classical Jaya algorithm relies on a single learning target, which may lead the population to converge prematurely to local optima. (3) Confidence-based operator selection models are influenced by historical performance and cannot dynamically adjust operator weights based on recent performance. (4) The previous works lack of effective energy-saving strategies. To address these issues, we propose a competitive multilevel Jaya algorithm with SPA-based multi-directional local search (CMJA-SPALS). Key innovations of CMJA-SPALS as follows: (1) A hybrid initialization strategy that generates a high-quality initial population with good diversity and convergence using fewer evaluations. (2) The multilevel competition mechanism uses non-dominated sorting to divide the population into multiple levels. Individuals within the same level are randomly paired for competition to determine diversified learning targets, significantly enhancing population diversity and reducing the risk of converging to local optima. (3) Individuals apply specific search operators based on its optimization bias, while the surprisingly popular algorithm (SPA) dynamically adjusts the selection probabilities of operators, improving local search success rates and accelerating convergence. (4) A critical path-based energy-saving strategy designed to reduce machine idle time by adjusting the processing speed of non-critical jobs, effectively lowering total energy consumption. The proposed method’s performance is evaluated using three multi-objective metrics: HV, GD, and Spread. The effects of parameter settings are investigated, and extensive numerical experiments are conducted. Comparative results and statistical analyses demonstrate that CMJA-SPALS outperforms NSGA-II, SD-Jaya, MOEA/D, and KMOEA/D across multiple test instances of varying scales, confirming its effectiveness and robustness.},
  archive      = {J_SUPERC},
  author       = {Zhang, Qiwen and Zhen, Tian},
  doi          = {10.1007/s11227-025-06938-z},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Improved jaya algorithm for energy-efficient distributed heterogeneous permutation flow shop scheduling},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CPCS: A perception sharing scheme of vehicle-road cooperation based on cybertwin. <em>SUPERC</em>, <em>81</em>(2), 1--30. (<a href='https://doi.org/10.1007/s11227-025-06939-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-road cooperative perception plays an important role in intelligent transportation systems. By receiving cooperative perception messages (CPM) shared from the roadside infrastructure, the vehicle can acquire richer real-time information about road conditions and traffic flow. However, existing CPM sharing strategies face challenges when dealing with complex traffic scenarios, including data exchange frequency leading to channel congestion, and indiscriminate data sharing resulting in redundant or incomplete information. In this regard, this paper proposes a cybertwin-based cooperative perception sharing scheme (CPCS). Leveraging the perceptual information collected by cybertwin, we design a road individual intention relevance criterion (RIRC) to quantify the traffic safety relationship among road individuals and propose a high-value content selection learning algorithm based on deep deterministic policy gradient and velocity entropy. By calculating the relevance between individual road users, the infrastructure selectively shares road information with vehicles, thus improving the timeliness and effectiveness of CPM. Furthermore, considering the diversity of vehicle perception demands and the fluctuation of real-time channel busy ratio, we design a CPM adaptive transmission frequency control and bandwidth allocation algorithm under multi-vehicle requests to avoid channel congestion and resource wastage. Compared to traditional sharing schemes, the CPM quality of service is improved by 2.45 times, and the object redundancy is reduced by 75.4%.},
  archive      = {J_SUPERC},
  author       = {Liu, Jianhang and Xia, Chunxing and Cui, Xuerong and Wu, Haibo},
  doi          = {10.1007/s11227-025-06939-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {CPCS: A perception sharing scheme of vehicle-road cooperation based on cybertwin},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cloud-WAVECAP: Ground-based cloud types detection with an efficient wavelet-capsule approach. <em>SUPERC</em>, <em>81</em>(2), 1--29. (<a href='https://doi.org/10.1007/s11227-025-06941-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud detection plays a significant role in various practices, such as weather forecasting, climate studies, etc. This paper presents an integrated approach called cloud-WAVECAP for ground-based cloud detection using a combination of wavelet and capsule networks. The proposed approach utilizes the wavelet’s multiscale analysis capability to detect significant cloud features at different resolutions. Meanwhile, the inherent capability of dynamic routing by the capsule network increases the model’s ability to capture hierarchical structures and spatial relationships within the clouds. The cloud-WAVECAP model applies two-level wavelet decomposition, followed by convolutional layers and the capsule network. This architecture integrates preprocessing, wavelet layers, and capsule layers to capture both low- and high-level features for accurate cloud classification. It excels in identifying different cloud types, which is vital for meteorological analysis. Cloud-WAVECAP is assessed using several metrics and outperforms Inception V3, VGGNet, Resnet50, EfficientNet-B7, achieving 98.42% precision, 98.48% recall, and 99.12% accuracy. Additionally, the model’s efficiency, measured by Floating Point Operations (FLOPs), is competitive, resulting in 1.5426 GIGA FLOPS compared to other methods.},
  archive      = {J_SUPERC},
  author       = {Mishra, Sanjukta and Kar, Samarjit and Guhathakurta, Parag Kumar},
  doi          = {10.1007/s11227-025-06941-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Cloud-WAVECAP: Ground-based cloud types detection with an efficient wavelet-capsule approach},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLDDoS: A distributed denial of service attack detection method using multi-level sketch. <em>SUPERC</em>, <em>81</em>(2), 1--36. (<a href='https://doi.org/10.1007/s11227-025-06942-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Denial of Service (DDoS) attacks pose a severe threat to network stability, and detecting them remains a significant challenge. Solutions based on programmable data planes and sketches have become a research hotspot. However, existing works, which are based on generic sketches, focus solely on the use of statistical results for large traffic flows, neglecting the inherent information within the large traffic itself. This could lead to additional costs for administrators in obtaining information about large traffic flows. To address this, we have designed a Multi-Level Sketch on the data plane to record detailed information of large flows and statistical information of small flows. In the control plane, we use the collected information to calculate the normalized entropy of the source IP addresses of network traffic, implementing an adaptive threshold detection scheme, a state control mechanism, and a traffic marking mechanism based on information from large flows. We validated the differences between Multi-Level Sketch and state-of-the-art methods on the public datasets CAIDA Anonymized Internet Traces 2019 and CAIDA DDoS 2007 using the same space size. The experimental results show that the average relative error difference between Multi-Level Sketch and Elastic Sketch is between 0.0383 and 2.82. In terms of information entropy estimation, the relative error of Multi-Level Sketch is 2.27 to 2.99 times lower than that of Elastic Sketch. In terms of true positive rate, false positive rate, and detection accuracy in DDoS attack detection, our method outperforms state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Xiao, Junbi and Sun, Ruifeng and Liu, Jianhang},
  doi          = {10.1007/s11227-025-06942-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {MLDDoS: A distributed denial of service attack detection method using multi-level sketch},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic target detection based on context enhancement and feature purification. <em>SUPERC</em>, <em>81</em>(2), 1--18. (<a href='https://doi.org/10.1007/s11227-025-06944-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiscale feature fusion strategy has made substantial strides in object detection; however, it may result in feature loss or boundary distortion for larger objects when optimized for small object detection. In order to capture additional contextual information, this paper suggests a novel feature pyramid composite network structure that improves object feature extraction by incorporating residual feature extraction. In order to mitigate feature loss during the fusion process, a unified module is implemented to collect and combine global data. Furthermore, in order to optimize inter-layer information flow and mitigate interference from conflicting information, feature refinement is implemented in both channel and spatial dimensions. This method enhances the detection performance of small objects and maintains the critical features of larger objects. Experimental results indicate that this method surpasses other object detection models in terms of detection precision and achieves a 2.3% higher detection accuracy on the KITTI dataset than YOLOv9.},
  archive      = {J_SUPERC},
  author       = {Liu, Tao and Lin, Chenyoukang and Hu, Yunteng and Cao, Ruyi and Zhang, Wendong},
  doi          = {10.1007/s11227-025-06944-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--18},
  shortjournal = {J. Supercomput.},
  title        = {Traffic target detection based on context enhancement and feature purification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt4LJP: Prompt learning for legal judgment prediction. <em>SUPERC</em>, <em>81</em>(2), 1--24. (<a href='https://doi.org/10.1007/s11227-025-06945-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of legal judgment prediction (LJP) involves predicting court decisions based on the facts of the case, including identifying the applicable law article, the charge, and the term of penalty. While neural methods have made significant strides in this area, they often fail to fully harness the rich semantic potential of language models (LMs). Prompt learning is a novel paradigm in natural language processing (NLP) that reformulates downstream tasks into cloze-style or prefix-style prediction challenges by utilizing specialized prompt templates. This paradigm shows significant potential across various NLP domains, including short text classification. However, the dynamic word lengths of LJP labels present a challenge to the general prompt templates designed for single-word [MASK] tokens commonly used in many NLP tasks. To address this gap, we introduce the Prompt4LJP framework, a new method based on the prompt learning paradigm for the complex LJP task. Our framework employs a dual-slot prompt template in conjunction with a correlation scoring mechanism to maximize the utility of LMs without requiring additional resources or complex tokenization schemes. Specifically, the dual-slot template consists of two distinct slots: one dedicated to factual descriptions and the other to labels. This approach effectively tackles the challenge of dynamic word lengths in LJP labels, reformulating the LJP classification task as an evaluation of the applicability of each label. By incorporating a correlation scoring mechanism, we can identify the final result label. The experimental results show that our Prompt4LJP method, whether using discrete or continuous templates, outperforms baseline methods, particularly in charges and terms of penalty prediction. Compared to the best baseline model EPM, Prompt4LJP shows F1-score improvements of 2.25% and 4.76% (charge prediction and term of penalty prediction) with discrete templates, and 3.24% and 4.05% with the continuous template, demonstrating prompt4LJP ability to leverage pretrained knowledge and adapt flexibly to specific tasks. The source code can be obtained from https://github.com/huangqiongyannn/Prompt4LJP .},
  archive      = {J_SUPERC},
  author       = {Huang, Qiongyan and Xia, Yuhan and Long, Yunfei and Fang, Hui and Liang, Ruiwei and Guan, Yin and Xu, Ge},
  doi          = {10.1007/s11227-025-06945-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Prompt4LJP: Prompt learning for legal judgment prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating cyberphysical risks in IoT-enabled smart transport infrastructure. <em>SUPERC</em>, <em>81</em>(2), 1--29. (<a href='https://doi.org/10.1007/s11227-025-06948-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to mitigate cyberphysical risks in an IoT-enabled intelligent transport infrastructure. Self-driving cars (SDCs) are becoming increasingly integral to smart cities, offering significant advantages such as reducing the burden on human drivers, optimizing resource utilization, and contributing to cleaner air through reduced emissions. To address potential cybersecurity challenges, this research presents a novel machine learning (ML)-based intrusion detection system (IDS) targeting an SDC cyberphysical system (CPS) that effectively identifies and mitigates attacks on the associated physical components of SDCs. A key feature of the SDC-CPS architecture is integrating a controller area network into the SDC-related simulator. By leveraging IoT/sensing devices, comprehensive data samples were collected from the SDC-CPS architecture for analysis. Furthermore, the study introduces a krill herd search-driven fine-tuned tree method for data processing, achieving impressive results, including 98.3% precision, 97.8% recall, 98.3% F1-score, and 98.4% accuracy. The findings highlight that the proposed solution outperforms existing IDS models, establishing it as a reliable and efficient approach for enhancing the security of intelligent transport systems.},
  archive      = {J_SUPERC},
  author       = {Alkhudhayr, Hanadi and Ardah, Hanin},
  doi          = {10.1007/s11227-025-06948-x},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Mitigating cyberphysical risks in IoT-enabled smart transport infrastructure},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ldstd: Low-altitude drone aerial small target detector. <em>SUPERC</em>, <em>81</em>(2), 1--28. (<a href='https://doi.org/10.1007/s11227-025-06950-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high imaging resolution, presence of multiple targets in close proximity, complex backgrounds and severe overlaps in UAV images present a significant challenge for the detection of small targets in such images. The issue of achieving faster and more accurate detection has been a significant concern. In order to adequately address these issues, this article proposes the implementation of a Low-Altitude Drone Aerial Small Target Detector algorithm (LDSTD) based on YOLOv8. This paper proposes a bidirectional growth fusion network (BGFN) to address the issue of the network’s difficulty in discriminating targets in complex backgrounds. The proposed BGFN effectively enhances the classification and localisation ability in complex backgrounds by effectively using deep and shallow features to enhance target suppression and background estimation. On this basis, the addition of a high-resolution detection head and the removal of a low-resolution detection head serve to enhance the detection ability of small targets, while simultaneously reducing the number of parameters. Furthermore, this paper presents the design of a Spatial-Channel Enhancement Module (SCEM), which enhances the feature information of the target during feature extraction, filters the superfluous interference information and addresses the issue of the loss of information pertaining to small targets in the sampling process. This paper proposes a novel lightweight multi-scale feature extraction module (LMSC) and its integration with YOLOv8’s C2f, resulting in a new structure, C2f-LMSC. This structure enhances the extraction of features from scalable receptive fields at higher levels of the network while simultaneously reducing the computational burden through the introduction of a lightweight convolutional module. The experiments demonstrate that the LDSTD algorithm presented in this paper exhibits substantial enhancements in both the publicly accessible datasets VisDrone2019 and NWPU VHR-10. For the VisDrone2019 dataset, the algorithm attains a mAP50 of 38.1% in the test set, signifying a 4.1% increase compared to YOLOv8s. Additionally, it achieves a mAP0.5–0.95 of 21.8%, marking an 2.8% rise over YOLOv8s.},
  archive      = {J_SUPERC},
  author       = {Sun, Yuheng and Lan, Zhenping and Sun, Yanguo and Guo, Yuepeng and Li, Xinxin and Wang, Yuru and Li, Bo},
  doi          = {10.1007/s11227-025-06950-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--28},
  shortjournal = {J. Supercomput.},
  title        = {Ldstd: Low-altitude drone aerial small target detector},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inqasm: InQuIR compiler to NetQASM. <em>SUPERC</em>, <em>81</em>(2), 1--29. (<a href='https://doi.org/10.1007/s11227-025-06955-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing is a rapidly evolving field, with almost every aspect open to change or improvement. This includes moving from using a single quantum processing unit to interconnecting multiple quantum processing units (or several of them), establishing a new paradigm called distributed quantum computing and increasing the overall computing capability. Some research is already underway in this area to prepare the ground for an eventual architecture with these characteristics. This is the case of InQuIR (Nishio and Wakizaka in arXiv:2302.00267 2023) and NetQASM (Dahlberg et al in QST 7:035023 2022), two languages developed for distributed quantum computing. This paper presents the development of the InQASM compiler with the aim of translating code from the InQuIR language to NetQASM, establishing a compilation stack for the new distributed paradigm. An example of this compilation and a simulation of the compiled code are shown to showcase it.},
  archive      = {J_SUPERC},
  author       = {Vázquez-Pérez, Jorge and Cardama, F. Javier and Piñeiro, César and Pichel, Juan C. and Pena, Tomás F. and Gómez, Andrés},
  doi          = {10.1007/s11227-025-06955-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Inqasm: InQuIR compiler to NetQASM},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Research on site selection of emergency material reserve based on set pair analysis and TOPSIS integration method: A case study of hebei province, china. <em>SUPERC</em>, <em>81</em>(2), 1. (<a href='https://doi.org/10.1007/s11227-025-06971-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SUPERC},
  author       = {Kong, Dekun and Yang, Wenguang},
  doi          = {10.1007/s11227-025-06971-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {J. Supercomput.},
  title        = {Correction: Research on site selection of emergency material reserve based on set pair analysis and TOPSIS integration method: A case study of hebei province, china},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRIORITI: Scoring and categorization-based threat prioritization. <em>SUPERC</em>, <em>81</em>(1), 1--44. (<a href='https://doi.org/10.1007/s11227-024-06465-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The threat alert fatigue or alert overload problem has become critical in recent years. In practice, the volume of threat alerts is higher than the volume of alerts that SOC analysts can investigate. In this paper, we propose “Threat Inspection and Prioritization (PRIORITI),” a threat inspection mechanism that derives threat intelligence from the threat alert for prioritizing investigation. PRIORITI works in three phases, the first phase computes MITRE techniques, which act as a base layer for threat scoring and categorization. The second phase of PRIORITI maps the threat technique to CAPEC attack patterns and derives the scoring metrics. We further propose a novel threat scoring mechanism based on the derived metrics for threat score computation. The third phase of PRIORITI maps each MITRE technique to a single category from Microsoft’s STRIDE framework. Finally, threat score and category are used to prioritize the threat alerts. We evaluated PRIORITI on 7.6 million alerts from the DARPA dataset. It maps these alerts to 21 unique MITRE techniques and computes the threat scores and categories. From the aforementioned results, PRIORITI prioritizes 1.27% (i.e., 96703 out of 7.6 million) of captured alerts as critical by processing an average of 1 million alerts within $$\approx$$ 20 s. In addition, PRIORITI provides additional insights to the SOC analysts to investigate the threat alerts, which improves the time taken to respond to threats after detection. Through this effort, PRIORITI improves the productivity of the SOC analysts and provides a significant contribution to handle the “threat alert fatigue.”},
  archive      = {J_SUPERC},
  author       = {Patil, Rajendra and Muneeswaran, Sivaanandh and Sachidananda, Vinay and Hongyi, Peng and Gurusamy, Mohan},
  doi          = {10.1007/s11227-024-06465-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--44},
  shortjournal = {J. Supercomput.},
  title        = {PRIORITI: Scoring and categorization-based threat prioritization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of fake web pages and phishing attacks with rabbit optimization algorithm. <em>SUPERC</em>, <em>81</em>(1), 1--32. (<a href='https://doi.org/10.1007/s11227-024-06658-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing attacks are a type of deception-based attack in which the thief directs Internet users to fake sites. Fake sites look very similar to real sites, so users easily trust them and reveal their valuable information, such as usernames and passwords. A practical way to detect phishing attacks is to use machine learning techniques. In order to reduce the detection error of phishing attacks, a two-step approach is presented in this paper. The first stage selects the essential features using the rabbit optimization algorithm. This feature selection technique identifies the most relevant features for the detection of phishing attacks and is delivered to three classifications, MLP, RF, and XGBoost, to decrease the detection error of phishing attacks in embedded learning with voting. The tests performed in the MATLAB environment are performed on two datasets: UCI and Tan. Experiments show that the proposed method in the UCI dataset has accuracy, sensitivity, and precision of 97.82%, 97.51%, and 97.62%, respectively. If the Tan dataset is used, then the accuracy, sensitivity (recall), and precision of the proposed method in detecting phishing attacks are 97.91%, 97.88%, and 97.52%, respectively. The results show the proposed method’s superior performance in detecting phishing attacks. The proposed approach to detecting phishing is more accurate than the RF, MLP, XGBoost, BiLSTM, and RNN methods.},
  archive      = {J_SUPERC},
  author       = {Shahba, Leyla and Heidary-Sharifabad, Ahmad and Mollahoseini Ardakani, Mohammadreza},
  doi          = {10.1007/s11227-024-06658-w},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Detection of fake web pages and phishing attacks with rabbit optimization algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on various security protocols of edge computing. <em>SUPERC</em>, <em>81</em>(1), 1--77. (<a href='https://doi.org/10.1007/s11227-024-06678-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing has emerged as a transformative data processing method by decentralizing computations and bringing them toward the data source, significantly reducing latency and enhancing response times. However, this shift introduces unique security challenges, especially within the detection and prevention of cyberattacks. This paper gives a comprehensive evaluation of the edge security landscape in peripheral computing, with specialized expertise in identifying and mitigating various types of attacks. We explore the challenges associated with detecting and preventing attacks in edge computing environments, acknowledging the limitations of existing approaches. One of the very interesting novelties that we include in this survey article is, that we designed a Web application that runs on an edge network and simulates SQL injection attacks-a common threat in edge computing. Through this simulation, we examined every one of the cleanup strategies used to discover and prevent such attacks using input sanitization techniques, ensuring that the malicious SQL code turned neutralized. Our studies contribute to deeper know-how of the security landscape in edge computing by providing meaningful insights into the effectiveness of multiple prevention strategies.},
  archive      = {J_SUPERC},
  author       = {Bhattacharya, Tathagata and Peddi, Adithya Vardhan and Ponaganti, Srikanth and Veeramalla, Sai Teja},
  doi          = {10.1007/s11227-024-06678-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--77},
  shortjournal = {J. Supercomput.},
  title        = {A survey on various security protocols of edge computing},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new hardware architecture of high-performance real-time texture classification system based on FPGA. <em>SUPERC</em>, <em>81</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06705-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visual system is essential as a critical source for intelligent robots to acquire external information. Nevertheless, the real-time performance of existing approaches remains inadequate. To address this, a new high-performance target classification system based on FPGA has been developed as part of the visual system. This system optimizes the hardware architecture of the target classification algorithm, incorporating a novel method aimed at boosting parallelism to improve real-time performance. The system is implemented on the Xilinx Zynq-7045 FPGA. Experimental results demonstrate that, for a grayscale image with a resolution of 128 $$\times$$ 128, the feature extraction time is merely 85.64 µs, achieving a speed three orders of magnitude greater than that of the MATLAB platform. Additionally, the resource consumption of this design is lower than that of existing hardware architectures.},
  archive      = {J_SUPERC},
  author       = {Zhang, Yanjun and Guo, Xin and Guo, Hongchen and Zhang, Yichen},
  doi          = {10.1007/s11227-024-06705-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {A new hardware architecture of high-performance real-time texture classification system based on FPGA},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GFIDF:gradual fusion intent detection framework. <em>SUPERC</em>, <em>81</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06708-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal intent detection integrates various types of information to identify user intent, which is crucial for developing dialog systems that function effectively in complex, real-world environments. Current methods show potential for improving the exploration of connections between patterns and extracting key semantic features from nontextual data. Many researchers opt to fuse data at a single level. In this paper, the gradual fusion intent detection framework (GFIDF), which consists of two main modules, is proposed. The first module, the conical multilayer convolutional attention (CMCA) module, uses a conical multilayer convolutional architecture. This architecture allows the module to capture both local and global contextual information, refining feature representations. The CMCA module is designed to eliminate noise and enhance feature quality by leveraging adaptive convolutional operations. These operations produce a clearer characterization of multimodal data that facilitates alignment and fusion in subsequent processing stages. The second module, the multimodal split and recombination attention (MSRA) module, matches and integrates augmented features from the CMCA module with textual information. This module segments multimodal features into distinct blocks to focus attention on individual segments. By utilizing a block-level attention mechanism, the MSRA module captures interdependencies between modalities, aiding in the understanding of user intent. Four performance metrics are employed for evaluation: accuracy (ACC), F1 score, precision (P), and recall (R). Compared with the baseline model, all the metrics show improvements ranging from 1% to 3%. Experiments validate the CMCA module’s noise reduction effects when processing video and audio modalities. Additionally, the results demonstrate the effectiveness of the MSRA module in fusing the three modal features.},
  archive      = {J_SUPERC},
  author       = {Yang, Qimeng and Liu, Yi and Lu, Lanlan and Liu, Lei},
  doi          = {10.1007/s11227-024-06708-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {GFIDF:gradual fusion intent detection framework},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MECG: Modality-enhanced convolutional graph for unbalanced multimodal representations. <em>SUPERC</em>, <em>81</em>(1), 1--19. (<a href='https://doi.org/10.1007/s11227-024-06729-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal sentiment analysis tasks, it is very challenging to model the relationships between different modalities and fuse them. The problem in this area is the unbalance of sentiment representation and distribution across the different modalities, resulting in a fusion process that deviates from the multimodal sentiment-semantic space. We propose a novel fusion framework, MECG, based on graph convolutional neural networks, which provides an efficient approach for fusing unaligned multimodal sequences. With the help of text modalities, we first use the multimodal enhancement module to enhance visual and acoustic modalities to obtain more discriminative modalities, thus assisting the subsequent aggregation process. In addition, we construct text-driven multimodal feature graphs for modality fusion, which can effectively deal with the unbalanced issue among modalities in the graph convolution aggregation process. Finally, we integrate the fused information extracted by MECG into the verbal representation, thus dynamically transforming the original word representations toward the most accurate multimodal sentiment-semantic space. Our model proves its effectiveness and superiority on two publicly available datasets: CMU-MOSI and CMU-MOSEI.},
  archive      = {J_SUPERC},
  author       = {Tang, Jiajia and Ni, Binbin and Yang, Yutao and Ding, Yu and Kong, Wanzeng},
  doi          = {10.1007/s11227-024-06729-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--19},
  shortjournal = {J. Supercomput.},
  title        = {MECG: Modality-enhanced convolutional graph for unbalanced multimodal representations},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved binary linear programming models for finding maximum edge bi-clique in bipartite graphs. <em>SUPERC</em>, <em>81</em>(1), 1--26. (<a href='https://doi.org/10.1007/s11227-024-06733-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of finding the largest cluster in an undirected simple bipartite graph with the maximum number of edges is known as Maximum Edge Bi-clique (MEB) problem. MEB has many applications in several fields like bioinformatics, social networks and data mining. Since the problem has been proved to be NP-complete, the Binary Linear Programming (BLP) is an interesting alternative for solving it. In this paper, a new BLP model is proposed which has fewer variables than previous models which finds a bi-clique with the given size, if exist. First, by identifying and removing redundant constraints from previous models, the BLP model becomes more compact, which in some cases allows it to find larger bi-cliques, improving the overall solution quality. Then, a more efficient quaternary search method is proposed to find the MEB. Afterward, a theorem is proved which helps to reduce the search space of the quaternary search and as a result to reduce the number of calls to the BLP model. Then another theorem is proved which helps to propose 3 models which we call it 3-Binary Linear Programming (3-BLP) procedure. 3-BLP is especially efficient for bipartite graphs in which the difference between the maximum degrees of nodes in two sides of the bipartite graph is large. The experimental results show the superiority of the proposed approaches in terms of speed and accuracy compared to the state of the art.},
  archive      = {J_SUPERC},
  author       = {Ghadiri, Mohammad Javad and Bagherian, Mehri},
  doi          = {10.1007/s11227-024-06733-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {Improved binary linear programming models for finding maximum edge bi-clique in bipartite graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RIOKV: Reducing iterator overhead for efficient short-range query in LSM-tree-based key-value stores. <em>SUPERC</em>, <em>81</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06735-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-range queries frequently occur in real-world scenarios. Traditional LSM-Tree-based key-value storage systems handle range query requests using an iterator mechanism. However, the data required for short-range queries typically comes from only a few iterators, and the construction of unnecessary iterators in the iterator mechanism degrades range query performance. To address this issue, we propose a MemTable Retention mechanism for Level 0 and an Iterator Reduction mechanism for other levels in LSM-Tree. The former retains the Immutable MemTable, which should have been persisted to Level 0, in memory to reduce the read overhead from Level 0 during short-range queries. The latter reduces the overhead of creating unnecessary iterators through the Level Filter Table. We developed a prototype system, RIOKV, based on LevelDB. Experimental results show that, under workloads with intensive short-range queries, RIOKV’s throughput is approximately 1.18 $$-$$ 1.58 times that of LevelDB, 1.01 $$-$$ 1.24 times that of RemixDB, and 1.06 $$-$$ 1.46 times that of RocksDB. In workloads with mixed range queries and writes, RIOKV’s throughput is about 1.11 $$-$$ 3.50 times that of LevelDB, 0.94 $$-$$ 1.16 times that of RemixDB, and 1.28 $$-$$ 3.24 times that of RocksDB.},
  archive      = {J_SUPERC},
  author       = {Lin, Xinwei and Pan, Yubiao and Feng, Wenjuan and Zhang, Huizhen and Lin, Mingwei},
  doi          = {10.1007/s11227-024-06735-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {RIOKV: Reducing iterator overhead for efficient short-range query in LSM-tree-based key-value stores},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum neural network-assisted learning for small medical datasets: A case study in emphysema detection. <em>SUPERC</em>, <em>81</em>(1), 1--32. (<a href='https://doi.org/10.1007/s11227-024-06740-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancement in AI and deep learning has transformed medical image diagnosis; however, approaches to disease diagnosis, such as the detection of emphysema, one of the severest forms of COPD, stand to benefit from these technologies more. The main problem with the detection of emphysema from CT scans is the lack of very large, annotated datasets to train deep learning models. Classic models, like CNNs, are usually underfitting to small datasets and hence have very poor diagnostic accuracy. To address this challenge, we consider an integrated hybrid quantum–classical neural network model by combining the quantum variational circuits with CNNs. This new approach uses the power of quantum computing to identify subtle patterns in small datasets and could solve one of the key problems of deep learning. The model is pre-trained on large chest X-ray datasets and fine-tuned on a smaller emphysema dataset, which allows it to generalize more when data is limited. The experimental results confirm that the proposed approach is effective; namely, the quantum-assisted model reaches an accuracy of 0.5690 and F1-score of 0.5990, outperforming the traditional CNN models. This work points to the novelty of quantum computing in diagnosis with limited amounts of data, a very important challenge in this area of medical AI. Given that our research will conform to the limitation and work on small datasets, this work opens a new frontier in medical image analysis and shows ways in which QNN can substantially outperform traditional methods in detecting subtle markers of diseases; this indeed contributes to the growing body of knowledge in quantum-enhanced AI and opens up new frontiers toward some potential applications in the field of diagnosis of rare diseases and health diagnostics.},
  archive      = {J_SUPERC},
  author       = {Oviesi, Safura and Tarokh, Mohamad Jafar and Momeni, Mohamad kazem},
  doi          = {10.1007/s11227-024-06740-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {Quantum neural network-assisted learning for small medical datasets: A case study in emphysema detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human activity recognition by body-worn sensor data using bi-directional generative adversarial networks and frequency analysis techniques. <em>SUPERC</em>, <em>81</em>(1), 1--34. (<a href='https://doi.org/10.1007/s11227-024-06743-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing datasets used for human activity recognition (HAR) usually suffer from limitations in terms of size variation and distribution of activity classes, which can impair the generalizability and robustness of the trained model, especially in the case of activity classes with minority data. This paper proposes an architecture utilizing bi-directional generative adversarial networks (Bi-GANs) beside fast Fourier transform, which stacks the 1-D accelerometer signals as m frequency bins × frames × 3 orientations and produces an RGB-based features pattern. The extracted patterns allow the 2D-CNN-based Bi-GAN architecture to learn the accelerometer signals' cross-axis relationships, which served as input for training a deep learning model for activity recognition equipped with a fuzzy inference dense layer. Also, we have used Hidden Markov Models (HMMs) for post-processing the classifier's output, which integrates the window-level decision in more extended periods, obtaining a significant performance improvement. The proposed method examined and conducted on MobiAct, Up-Fall, Opportunity, and WISDM datasets with different rates of augmentation, reaching to the 99.7%, 99.96%, 86.8%, and 99.12% rate of accuracy, respectively.},
  archive      = {J_SUPERC},
  author       = {Kia, Zohre and Yadollahzaeh-Tabari, Meisam and Motameni, Homayun},
  doi          = {10.1007/s11227-024-06743-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Human activity recognition by body-worn sensor data using bi-directional generative adversarial networks and frequency analysis techniques},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond classical approaches: Redefining the landscape of high-accurate movie recommendation using QNN. <em>SUPERC</em>, <em>81</em>(1), 1--30. (<a href='https://doi.org/10.1007/s11227-024-06746-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are crucial in delivering personalized content and enhancing user satisfaction. This paper investigates the performance of various machine learning algorithms, classical neural networks (CNNs), and quantum neural networks (QNNs) for movie recommendations using the MovieLens-1 M dataset. Traditional approaches like random forest, K-means, and support vector machines (SVM) are evaluated against the newly proposed QNN models. Two distinct QNN architectures are introduced, leveraging the principles of quantum computing, such as superposition and entanglement, to enhance recommendation accuracy. The study demonstrates that the simple QNN architecture significantly outperforms traditional machine learning models and CNNs, reducing prediction errors by 6% in terms of Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The complex QNN model, while accurate, requires more computational resources compared to its simpler counterpart. This research highlights the transformative potential of quantum computing in recommender systems, offering unprecedented accuracy and personalization. Future research will focus on scalability, practical implementation of QNNs, and exploring their application across diverse domains.},
  archive      = {J_SUPERC},
  author       = {Sinha, Bam Bahadur and Sinha, Ramnish and Priye, Vishnu},
  doi          = {10.1007/s11227-024-06746-x},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Beyond classical approaches: Redefining the landscape of high-accurate movie recommendation using QNN},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational message passing with mutual information maximization for inductive link prediction. <em>SUPERC</em>, <em>81</em>(1), 1--34. (<a href='https://doi.org/10.1007/s11227-024-06749-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive link prediction (ILP) in knowledge graphs (KG) is gaining significant attention, focusing on predicting missing triples involving unseen entities during training. While subgraph-based methods are prevalent, they often encounter two primary limitations: (i) a tendency to concentrate on fully-inductive setting with unseen-unseen entities, neglecting the challenge of a more realistic truly-inductive setting involving both unseen entities and unseen relations, and (ii) a constraint in handling local subgraphs, overlooking the global structural information of the KG. To address these challenges, we propose RPMI, a novel model utilizing a relational message passing network with mutual information maximization tailored for the truly-inductive setting. Specifically, RPMI extracts enclosing and one-hop disclosing subgraphs around target triples, incorporates topological patterns between relations to transform entity graphs into relational graphs for subgraph reasoning, and introduces techniques like injecting KG’s ontological schema and relation-aware neighborhood attention. Moreover, to enhance the global modeling of topological patterns between relations, we maximize subgraph-graph interaction information. Extensive experiments on various inductive benchmark datasets demonstrate RPMI’s substantial performance improvement over existing methods in both fully and truly-inductive link predictions.},
  archive      = {J_SUPERC},
  author       = {Liang, Xinyu and Si, Guannan and Li, Jianxin and Tian, Pengxin and An, Zhaoliang and Zhou, Fengyu},
  doi          = {10.1007/s11227-024-06749-8},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {Relational message passing with mutual information maximization for inductive link prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel source project and optimized training data selection approach for cross-project fault prediction. <em>SUPERC</em>, <em>81</em>(1), 1--47. (<a href='https://doi.org/10.1007/s11227-024-06750-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software fault prediction (SFP) is a great tool for limiting the software testing resources allocation and enhancing the software reliability. In reality, collecting adequate historical training data for a new developing project might be a challenging task, in such cases cross-project fault prediction (CPFP) is useful. Prior studies have demonstrated transfer learning and training data selection models for CPFP. However, existing models are unstable to the source projects that are used to train the prediction model. In addition, imbalanced projects and irrelevant features are issues to review in CPFP. To address the limitations in existing CPFP models, we propose a novel optimized source data selection model for CPFP through Wilcoxon signed-rank test-based source project selection (WPS) and an optimized training data construction (optimizedTC) technique called WPSTC. We evaluate WPSTC with 31 datasets and seven performance measures and compare it with existing fault prediction models over five conventional and one ensemble machine learning model. On average, WPSTC outperforms CPFP models and can solve existing models’ sensitivity towards selected source projects and solve the imbalance and curse of dimensionality issues of CPFP models.},
  archive      = {J_SUPERC},
  author       = {Manchala, Pravali and Bisi, Manjubala},
  doi          = {10.1007/s11227-024-06750-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {A novel source project and optimized training data selection approach for cross-project fault prediction},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CovMedCare: Confluence of internet of things, blockchain and machine learning for remote monitoring system of pandemic patients. <em>SUPERC</em>, <em>81</em>(1), 1--36. (<a href='https://doi.org/10.1007/s11227-024-06751-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the increasing number of global communicable diseases such as COVID-19, remote monitoring systems have become necessary in the healthcare industry. The paucity of a competent and secure remote patient monitoring system and a lack of an appropriate platform to disseminate the information about the patient’s condition to the concerned relatives and doctors was felt during the recent pandemic. Moreover, during COVID-19, a sudden deterioration in the patient’s condition was observed in the hospital. Motivated by these issues, we have proposed a secure and robust decentralized patient monitoring model called CovMedCare for monitoring COVID-19 inpatients utilizing the confluence of Machine Learning, the Internet of Things and Blockchain technologies. In the proposed model, sensor data from WBAN is integrated with the patient’s previous health records to predict the patient’s deteriorating health condition over a blockchain network for timely decisions with minimum delay. The accuracy of the proposed model is assessed on a dataset with five medical sensor attributes and fifteen previous health records attributes collected from a hospital with 40,000 samples. The extensive experimental results exhibit that the proposed system performs better than the existing ones and achieves an accuracy of 99% in identifying the patient whose health condition is deteriorating.},
  archive      = {J_SUPERC},
  author       = {Krishna, Charu and Kumar, Divya and Kushwaha, Dharmender Singh},
  doi          = {10.1007/s11227-024-06751-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--36},
  shortjournal = {J. Supercomput.},
  title        = {CovMedCare: Confluence of internet of things, blockchain and machine learning for remote monitoring system of pandemic patients},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConvBiFuseNet: A parallel fusion model with routing attention for MRI brain tumor classification. <em>SUPERC</em>, <em>81</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06758-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although convolutional neural networks (CNNs) have made significant progress in medical image processing, the standard CNN model still has some drawbacks. Firstly, local feature extraction in CNN networks lacks targeted adaptive attention, potentially resulting in ineffective feature information being emphasized. Secondly, the model fails to effectively capture dependencies among long-range features, leading to suboptimal discriminative feature representations for each semantic category. To address these limitations, this paper proposes the ConvBraNet model with adaptive attention capability, introducing a Bi-level Routing Attention (BRA) and Global Response Normalization (GRN). BRA enhances the interdependence of channel mappings by employing an adaptive attention mechanism with routing, allowing irrelevant feature information to be ignored. Ultimately, we integrated ConvBraNet with Biformer, naming the resulting model ConvBiFuseNet. This fusion model combines ConvBraNet’s excellent local feature extraction performance with Biformer’s ability to capture global feature context information, utilizing a parallel integrated staged interaction learning approach. This approach effectively integrates local information with corresponding global dependencies. The proposed model’s performance is evaluated on three different brain tumor datasets for classifying brain tumor MRI 2D slice images. Notably, on the 2D T1-weighted CE-MRI dataset, the model achieves an accuracy of 98.36%, a recall of 98.53%, a specificity of 99.24%, and an F1-Score of 98.15%. Furthermore, the model’s generalization ability is verified on other datasets, yielding satisfactory results. Comparison and ablation experiments confirm the importance of the attention mechanism model with routing and the effectiveness of the proposed fusion model architecture.},
  archive      = {J_SUPERC},
  author       = {Liu, Shiguo and Wei, Dejian and Zhang, Junzhong and Ji, Xurui and Cao, Hui},
  doi          = {10.1007/s11227-024-06758-7},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {ConvBiFuseNet: A parallel fusion model with routing attention for MRI brain tumor classification},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deepat: A real-time deep learning based model for aircraft tracking system. <em>SUPERC</em>, <em>81</em>(1), 1--31. (<a href='https://doi.org/10.1007/s11227-024-06759-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time aircraft tracking is a critical component of aircraft flight testing. The data flowing from the aircraft to the ground control center must be real-time and uninterrupted. However, ground control systems often can cause disconnection with the aircraft, leading to tracking challenges. This study first presents a brief survey of real-time aircraft tracking systems (ATS) and then proposes DeepAT, a deep learning-based ATS for real-time three-dimensional prediction of the aircraft’s next location. The proposed DeepAT model provides uninterrupted real-time data tracking by employing an encoder-decoder GRU model to predict the next location of the aircraft. Thus, in case of any disconnection, the tracking of the aircraft is ensured. DeepAT model is evaluated using real flight test sensor data collected through a telemetry system. Experimental evaluations are performed for two structurally different aircraft models, one being a highly maneuverable fixed-wing aerobatic/training aircraft and the other a tactical unmanned aerial vehicle. The efficiency and superiority of the proposed method are demonstrated by comparing it with state-of-the-art methods. The results show that DeepAT outperforms existing methods by providing more accurate predictions of the next location of the aircraft.},
  archive      = {J_SUPERC},
  author       = {Çakıcı, Muhammed Emir and Okay, Feyza Yıldırım and Özdemir, Suat},
  doi          = {10.1007/s11227-024-06759-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--31},
  shortjournal = {J. Supercomput.},
  title        = {Deepat: A real-time deep learning based model for aircraft tracking system},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pattern synthesis of linear antenna-array for high gain and low sidelobe level based on sand cat swarm optimization algorithm. <em>SUPERC</em>, <em>81</em>(1), 1--21. (<a href='https://doi.org/10.1007/s11227-024-06763-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel optimization method based on the sand cat swarm optimization (SCSO) algorithm for the pattern synthesis of linear antenna-array (LAA), aiming to obtain the high gain and low sidelobe level (SLL). The innovation of the proposed method consists in efficiently regulating the radiation characteristics of the LAA by optimizing the geometric and electrical parameters including the phase, amplitude, rotation and position based on the SCSO algorithm to achieve the desired radiation performances. The full-wave method of moments (MoM) is adopted to rigorously consider the mutual coupling effect among the array elements to guarantee the design accuracy. To demonstrate the feasibility and effectiveness of the SCSO algorithm, the proposed method is compared with three typical algorithms, including the Genetic Algorithm (GA), the Gray Wolf (GWO) algorithm, and the Particle Swarm Optimization (PSO). The results show that the SCSO algorithm demonstrates superior convergence capabilities while maintaining the high gain and low SLL, highlighting the potential as a robust method for the LAA.},
  archive      = {J_SUPERC},
  author       = {Mou, Jianhui and Wang, Jian and Wang, Yangwei and Xiang, Ming and Zhang, Lihua},
  doi          = {10.1007/s11227-024-06763-w},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Pattern synthesis of linear antenna-array for high gain and low sidelobe level based on sand cat swarm optimization algorithm},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep deterministic policy gradients with a self-adaptive reward mechanism for image retrieval. <em>SUPERC</em>, <em>81</em>(1), 1--35. (<a href='https://doi.org/10.1007/s11227-024-06764-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional image retrieval methods often face challenges in adapting to varying user preferences and dynamic datasets. To address these limitations, this research introduces a novel image retrieval framework utilizing deep deterministic policy gradients (DDPG) augmented with a self-adaptive reward mechanism (SARM). The DDPG-SARM framework dynamically adjusts rewards based on user feedback and retrieval context, enhancing the learning efficiency and retrieval accuracy of the agent. Key innovations include dynamic reward adjustment based on user feedback, context-aware reward structuring that considers the specific characteristics of each retrieval task, and an adaptive learning rate strategy to ensure robust and efficient model convergence. Extensive experimentation with the three distinct datasets demonstrates that the proposed framework significantly outperforms traditional methods, achieving the highest retrieval accuracy having 3.38%, 5.26%, and 0.21% improvement overall as compared to the mainstream models over DermaMNIST, PneumoniaMNIST, and OrganMNIST datasets, respectively. The findings contribute to the advancement of reinforcement learning applications in image retrieval, providing a user-centric solution adaptable to various dynamic environments. The proposed method also offers a promising direction for future developments in intelligent image retrieval systems.},
  archive      = {J_SUPERC},
  author       = {Ahmad, Farooq and Zhang, Xinfeng and Tang, Zifang and Sabah, Fahad and Azam, Muhammad and Sarwar, Raheem},
  doi          = {10.1007/s11227-024-06764-9},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--35},
  shortjournal = {J. Supercomput.},
  title        = {Deep deterministic policy gradients with a self-adaptive reward mechanism for image retrieval},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization method of c2 system architecture based on ALCARO. <em>SUPERC</em>, <em>81</em>(1), 1--33. (<a href='https://doi.org/10.1007/s11227-024-06768-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the lack of combat mission-driven and guided optimization methods in existing command and control (C2) system architectures, this paper proposes an optimization method for C2 system architecture based on an improved artificial rabbit optimization (ARO) algorithm, specifically the adaptive inertia weight, Levy flight, and chaotic opposite-based learning in artificial rabbit optimization (ALCARO). This method introduces a collaborative connection degree for C2 system architectures, quantitatively describing the degree of collaboration between combat units and same-level C2 units, and establishes a mathematical model for the optimization problem of C2 system architecture. The ALCARO algorithm innovatively incorporates adaptive inertia weight, Levy flight, and piecewise chaotic mapping-based opposite learning strategies to enhance the algorithm's convergence speed, effectively avoiding premature convergence to local optima and demonstrating robust performance. Simulation results show that this method can effectively enhance the connectivity among collaborative combat units in a mission-oriented manner and possesses excellent invulnerability.},
  archive      = {J_SUPERC},
  author       = {Wang, Jian-wei and Zhang, Qing and Pan, Cheng-sheng},
  doi          = {10.1007/s11227-024-06768-5},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--33},
  shortjournal = {J. Supercomput.},
  title        = {Optimization method of c2 system architecture based on ALCARO},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic position weighting aspect-focused graph convolutional network for aspect-based sentiment analysis. <em>SUPERC</em>, <em>81</em>(1), 1--25. (<a href='https://doi.org/10.1007/s11227-024-06783-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that analyzes the affective attitudes of specific aspects of a review. Recent studies have focused on using graph convolutional networks and attention mechanisms for ABSA; however, most of the existing works fail to flexibly consider the internal distance relationships between aspects and contexts when constructing dependency graphs, and their models do not pay sufficient attention to the aspects in the feature extraction process after performing graph convolution. In this paper, we propose a dynamic position weighting aspect-focused graph convolutional network (DPWAFGCN-BERT) to address the above problems. Specifically, we combine the relative distance and dependency distance measures to weight the original dependency graph and utilize dynamic coefficients to control the influence strengths of different distance types to achieve enhanced aspect sentiment feature aggregation. Furthermore, after implementing graph convolution, we design an aspect-focused attention fusion module, which includes both a retrieval-based multihead attention mechanism and an aspect-oriented multihead attention mechanism, to learn contextual sentiment features based on aspects from different feature subspaces. We conduct experiments on four public datasets, and the experimental results demonstrate the excellent performance of our proposed model.},
  archive      = {J_SUPERC},
  author       = {Yu, Bengong and Cao, Chengwei and Yang, Ying},
  doi          = {10.1007/s11227-024-06783-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Dynamic position weighting aspect-focused graph convolutional network for aspect-based sentiment analysis},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel construction of edge-independent spanning trees in complete josephus cubes. <em>SUPERC</em>, <em>81</em>(1), 1--30. (<a href='https://doi.org/10.1007/s11227-024-06784-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The n-dimensional complete Josephus cube $$CJC_n$$ is the edge-augmented Josephus cube suitable for massively parallel processing systems. Compared with the Josephus cube, $$CJC_n$$ has better fault tolerance performance while maintaining high scalability. A set of k ( $$k\ge 2$$ ) spanning trees rooted at the same vertex r in graph G is called edge-independent trees (EISTs for short) when the k paths from $$v\in V(G)\setminus \{r\}$$ to r have no common edges. EISTs are crucial in distributing information, ensuring fault-tolerant broadcasting, reliable data transmission, and IP fast rerouting. This paper studies the existence and construction of $$n+2$$ EISTs rooted at an arbitrary vertex in $$CJC_n$$ . We present a parallel Algorithm CJC_EIST for constructing $$n+2$$ EISTs, enabling each vertex to determine its parent in each spanning tree instantaneously. Using $$2^n$$ processors ( $$|V(CJC_n)=2^n|$$ ), our algorithm achieves parallel execution with O(n) time complexity. As $$CJC_n$$ is $$(n+2)$$ -edge-connected, the number of resulting EISTs constructed by Algorithm CJC_EIST is optimal. Finally, we provide the corresponding theoretical proof of the algorithm and perform simulation experiments using the resulting spanning trees.},
  archive      = {J_SUPERC},
  author       = {He, Qi and Wang, Yan and Fan, Jianxi and Cheng, Baolei},
  doi          = {10.1007/s11227-024-06784-5},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Supercomput.},
  title        = {Parallel construction of edge-independent spanning trees in complete josephus cubes},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cellular goore game-based algorithm for finding the shortest path in stochastic multi-layer graphs. <em>SUPERC</em>, <em>81</em>(1), 1--50. (<a href='https://doi.org/10.1007/s11227-024-06786-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem in stochastic graphs has been extensively studied, with numerous algorithms proposed using various learning automata models. However, the dynamic nature, diverse individual characteristics, and inherent uncertainties of social interactions necessitate the adoption of stochastic multi-layer social network modeling. This approach provides deeper insights into the complex relationships within social networks. When formulated as a stochastic multi-layer graph, key elements such as the shortest path require redefinition to account for these complexities. This paper explores the shortest path problem in stochastic multi-layer graphs and introduces a novel algorithm based on the Cellular Goore Game (CGG) to address this challenge. The proposed CGG-based algorithm leverages learning automata and extensive edge sampling to determine the optimal path efficiently. By integrating learning automata and selectively sampling from relevant sections of the graph, the algorithm significantly reduces computational complexity. Experimental results on stochastic multi-layer graphs highlight the effectiveness of the proposed algorithm, demonstrating substantial improvements across multiple metrics, including sampling ratio, shortest path ratio, average iterations, and convergence rate.},
  archive      = {J_SUPERC},
  author       = {Khomami, Mohammad Mehdi Daliri and Meybodi, Mohammad Reza and Rezvanian, Alireza},
  doi          = {10.1007/s11227-024-06786-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--50},
  shortjournal = {J. Supercomput.},
  title        = {A cellular goore game-based algorithm for finding the shortest path in stochastic multi-layer graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User association-based load balancing using reinforcement learning in 5G heterogeneous networks. <em>SUPERC</em>, <em>81</em>(1), 1--26. (<a href='https://doi.org/10.1007/s11227-024-06788-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of heterogeneous networks (HetNets), which include macro and micro Base Stations (BSs), has emerged as an effective solution to address the challenges faced by 5G communication networks. HetNets leverage the strengths of various technologies to enhance coverage, capacity, quality of service (QoS), cost efficiency, and adaptability. Efficient methods for associating user equipment with BSs in HetNets are necessary to maximize overall network performance. This process, known as user association-based load balancing, is crucial due to the increasing number of devices requiring connectivity using limited available spectrum and BSs. This study considers a three-tier downlink HetNet consisting of macro-BSs, pico-BSs, and femto-BSs, operating under a log-distance channel model in both rural and urban areas, in accordance with 3GPP norms. The signal model for the proposed HetNet is devised to determine the signal-to-interference-plus-noise ratio (SINR) and transmission rates for each user association. Load balancing is then performed using the deep Q-learning approach, and the cumulative transmission rate achieved is calculated and tabulated. This approach is compared with the MaxSINR and Q-Learning algorithms. LB (load balancing) was performed for different network scenarios by varying the number of UEs and BSs and introducing mobility in the network. The corresponding results were analyzed and plotted. An extensive survey of the effect of user association LB on improving the cumulative transmission rate of HetNets was conducted successfully, and the variation in performance under different network scenarios was analyzed.},
  archive      = {J_SUPERC},
  author       = {Ramesh, Parameswaran and Bhuvaneswari, P. T. V. and Dhanushree, V. S. and Gokul, G. and Sahana, S.},
  doi          = {10.1007/s11227-024-06788-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--26},
  shortjournal = {J. Supercomput.},
  title        = {User association-based load balancing using reinforcement learning in 5G heterogeneous networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SeqMatcher: Efficient genome sequence matching with AVX-512 extensions. <em>SUPERC</em>, <em>81</em>(1), 1--38. (<a href='https://doi.org/10.1007/s11227-024-06789-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent emergence of long-read sequencing technologies has enabled substantial improvements in accuracy and reduced computational costs. Nonetheless, pairwise sequence alignment remains a time-consuming step in common bioinformatics pipelines, becoming a bottleneck in de novo whole-genome assembly. Speeding up this step requires heuristics and the development of memory-frugal and efficient implementations. A promising candidate for all of the above is Myers’ algorithm. However, the state-of-the-art implementations face scalability challenges when dealing with longer reads and large datasets. To address these challenges, we propose SeqMatcher, a fast and memory-frugal genomics sequence aligner. By leveraging the long registers of AVX-512, SeqMatcher reduces the data movement and memory footprint. In a comprehensive performance evaluation, SeqMatcher achieves speedups of up to 12.32x for the unbanded version and 26.70x for the banded version compared to the non-vectorized implementation, along with energy footprint reductions of up to 2.59x. It also outperforms state-of-the-art implementations by factors of up to 29.21x, 17.56x, 13.47x, 9.12x, and 8.81x compared to Edlib, WFA2-lib, SeqAn, BSAlign, and QuickEd, while improving energy consumption with reductions of up to 6.78x.},
  archive      = {J_SUPERC},
  author       = {Espinosa, Elena and Quislant, Ricardo and Larrosa, Rafael and Plata, Oscar},
  doi          = {10.1007/s11227-024-06789-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {SeqMatcher: Efficient genome sequence matching with AVX-512 extensions},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor subspace learning and folded-concave function regularization for hyperspectral anomaly detection. <em>SUPERC</em>, <em>81</em>(1), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06791-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection focuses on identifying and localizing the anomalous targets in remote sensing. The complex scenarios in hyperspectral images make it more difficult to effectively distinguish anomalous objects from background data, especially in noisy environments. Currently, available low-rank representation models capable of effective denoising often unfold hyperspectral cubic data into two-dimensional form, but this causes the structural knowledge to be lost. To surmount the above disadvantages, we propose a tensor subspace-based learning strategy with folded-concave regularization for hyperspectral anomaly detection. First, hyperspectral data undergo initial preprocessing through dimensional reduction and robust tensor principal component analysis to generate a dictionary representing the background. Then, a tensor subspace learning approach aims to factorize hyperspectral data into the background and anomaly tensors, in which the folded-concave function is leveraged to minimize minor components for denoising. Next, $$l_{F,1}$$ norm on tensor is used to extract abnormal information from hyperspectral data. Finally, comprehensive experiments on several real datasets show that the proposed algorithm performs better than the comparative benchmark methods in detection performance.},
  archive      = {J_SUPERC},
  author       = {Ma, Fei and Hou, Aihua and Yang, Feixia and Xu, Guangxian},
  doi          = {10.1007/s11227-024-06791-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Tensor subspace learning and folded-concave function regularization for hyperspectral anomaly detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic image representation for image recognition and retrieval using multilayer variational auto-encoder, InceptionNet and low-level image features. <em>SUPERC</em>, <em>81</em>(1), 1--40. (<a href='https://doi.org/10.1007/s11227-024-06792-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel image descriptor that enhances performance in image recognition and retrieval by combining deep learning and handcrafted features. Our method integrates high-level semantic features extracted via InceptionResNet-V2 with color and texture features to create a comprehensive representation of image content. The descriptor’s effectiveness is demonstrated through extensive experiments across a range of image recognition and retrieval tasks. Our approach is tested on six benchmark datasets, including Corel-1 K, VS, OT, QT, SUN-397, and ILSVRC-2012 for single-label classification, and COCO and NUS-WIDE for multi-label classification, achieving high performances. The results establish that the proposed method is versatile and robust, excelling in single-label and multi-label recognition as well as image retrieval tasks, and outperforms several state-of-the-art methods. This work provides a significant advancement in image representation, with broad applicability in various computer vision domains.},
  archive      = {J_SUPERC},
  author       = {Giveki, Davar and Esfandyari, Sajad},
  doi          = {10.1007/s11227-024-06792-5},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--40},
  shortjournal = {J. Supercomput.},
  title        = {Semantic image representation for image recognition and retrieval using multilayer variational auto-encoder, InceptionNet and low-level image features},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GA-DE: An integrated meta-heuristic approach for optimizing feedforward neural networks. <em>SUPERC</em>, <em>81</em>(1), 1--42. (<a href='https://doi.org/10.1007/s11227-024-06799-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feedforward neural networks (FNNs) are among the most widely used artificial neural network models, which have consistently demonstrated excellent performance in various fields, such as classification and regression tasks. However, the performance of FNNs does mainly depend on their structure (i.e., the number of hidden layers and that of neurons for each hidden layer) and initial weights, and they are usually required to manually determine via extensive tuning experiments in advance, thereby seriously limiting their practical applicability. To address this issue, this paper proposes an integrated meta-heuristic intelligent algorithm using genetic algorithm (GA) and differential evolution (DE). To satisfy the dynamic adjustment of network structure during the search process, a novel mixed encoding strategy is devised to represent both the structure and initial parameters of network model. Moreover, a combined offspring generation strategy is designed to explore more promising networks using GA and DE. Specifically, GA is utilized to search the optimal network structure, while DE is employed to refine its associated parameters. Following them, the potential information of different network models can be effectively interacted and shared, thus improving the search effectiveness and efficiency of algorithm. Finally, the performance of the proposed algorithm is validated by comparing with eight existing algorithms on twelve commonly used classification datasets and a practical problem, named air quality index prediction. Experimental results demonstrate that the proposed algorithm exhibits superior performance.},
  archive      = {J_SUPERC},
  author       = {Shang, Mengying and Tian, Mengnan and Wang, Xinduan},
  doi          = {10.1007/s11227-024-06799-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--42},
  shortjournal = {J. Supercomput.},
  title        = {GA-DE: An integrated meta-heuristic approach for optimizing feedforward neural networks},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A storage-efficient learned indexing for blockchain systems using a sliding window search enhanced online gradient descent. <em>SUPERC</em>, <em>81</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06805-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With its promise of transparency, security, and decentralization, blockchain technology faces significant challenges related to data storage and query efficiency. Current indexing methods, which often rely on structures like Merkle trees and Patricia tries, contribute to excessive storage overhead and slower query responses, particularly for full nodes that maintain a complete copy of the blockchain. To address this, we introduce a novel-learned indexing approach for blockchain that utilizes a layered structure with a sliding window search enhanced Online Gradient Descent (SWS-OGD) as the inter-block index. The method was implemented across five distinct blockchain environments—Bitcoin, Ethereum, Dogecoin, Litecoin, and IoTeX. Experimental results demonstrate that the proposed method reduces storage costs by up to 99% compared to state-of-the-art approaches, requiring as little as 0.9 KB for 20,000 blocks-a substantial improvement over existing methods. Despite the significant reduction in storage costs, the SWS-OGD method maintains comparable performance in other key metrics, such as query latency. These results ensure that blockchain systems can handle large-scale data queries efficiently, maintaining high performance even as the blockchain grows in size.},
  archive      = {J_SUPERC},
  author       = {Asiamah, Emmanuel Acheampong and Akrasi-Mensah, Nana Kwadwo and Odame, Prince and Keelson, Eliel and Agbemenu, Andrew Selasi and Tchao, Eric Tutu and Al-Khalidi, Mohammed and Klogo, Griffith Selorm},
  doi          = {10.1007/s11227-024-06805-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {A storage-efficient learned indexing for blockchain systems using a sliding window search enhanced online gradient descent},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating and accelerating vision transformers on GPU-based embedded edge AI systems. <em>SUPERC</em>, <em>81</em>(1), 1--21. (<a href='https://doi.org/10.1007/s11227-024-06807-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many current embedded systems comprise heterogeneous computing components including quite powerful GPUs, which enables their application across diverse sectors. This study demonstrates the efficient execution of a medium-sized self-supervised audio spectrogram transformer (SSAST) model on a low-power system-on-chip (SoC). Through comprehensive evaluation, including real time inference scenarios, we show that GPUs outperform multi-core CPUs in inference processes. Optimization techniques such as adjusting batch size, model compilation with TensorRT, and reducing data precision significantly enhance inference time, energy consumption, and memory usage. In particular, negligible accuracy degradation is observed, with post-training quantization to 8-bit integers showing less than 1% loss. This research underscores the feasibility of deploying transformer neural networks on low-power embedded devices, ensuring efficiency in time, energy, and memory, while maintaining the accuracy of the results.},
  archive      = {J_SUPERC},
  author       = {Martin-Salinas, Ignacio and Badia, Jose M. and Valls, Oscar and Leon, German and del Amor, Rocio and Belloch, Jose A. and Amor-Martin, Adrian and Naranjo, Valery},
  doi          = {10.1007/s11227-024-06807-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {Evaluating and accelerating vision transformers on GPU-based embedded edge AI systems},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The expected values and variances for degree-based topological indices in random spiro chains. <em>SUPERC</em>, <em>81</em>(1), 1--17. (<a href='https://doi.org/10.1007/s11227-024-06808-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a general method of calculating the expected values and variances for degree-based topological indices in random spiro chains are obtained. Based on the general method, the explicit analytical expressions for the expected values and variances of some important degree-based topological indices in random spiro chains are presented, in which some known results are included. Besides, the expected values and variances for degree-based topological indices in random spiro chains are compared. In the end, the extremal values and the average values for degree-based topological indices of a spiro chain with n hexagons are determined.},
  archive      = {J_SUPERC},
  author       = {Zhang, Weilin and You, Lihua and Liu, Hechao and Fang, Xiaona},
  doi          = {10.1007/s11227-024-06808-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--17},
  shortjournal = {J. Supercomput.},
  title        = {The expected values and variances for degree-based topological indices in random spiro chains},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSCANet: A two-stream context aggregation network for weakly-supervised temporal action localization. <em>SUPERC</em>, <em>81</em>(1), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06810-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised temporal action localization classifies and localizes actions in uncropped videos by using only video-level labels. Many current methods employ feature extractors initially intended for post-cropped video action classification. The accuracy of localization decreases when feature extractors of this type are used, because they may introduce redundant information into the action localization task. To overcome the aforementioned constraints, we propose a WSTAL technique based on the two-stream context aggregation network (TSCANet), which consists of two main modules: a multistage temporal feature aggregation module (MSTFA) and a feature alignment module (FA). The MSTFA enables TSCANet to rapidly expand the receptive field and acquire temporal dependencies between long-distance segments by stacking dilated convolutional layers. Therefore, MSTFA allows the model to better aggregate temporal information in optical flow features to reduce redundant information in the original features. To avoid inconsistencies between the enhanced optical flow and RGB flow features, this study designed an FA to calibrate RGB features using optimized optical flow features through a mutual learning approach. On THUMOS14 and ActivityNet datasets, many comparative tests are carried out, and an improved localization performance is attained. In particular, localization at low t-IoU thresholds outperforms many of the existing WSTAL methods.},
  archive      = {J_SUPERC},
  author       = {Zhang, Haiping and Lin, Haixiang and Wang, Dongjing and Xu, Dongyang and Zhou, Fuxing and Guan, Liming and Yu, Dongjing and Fang, Xujian},
  doi          = {10.1007/s11227-024-06810-6},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {TSCANet: A two-stream context aggregation network for weakly-supervised temporal action localization},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on site selection of emergency material reserve based on set pair analysis and TOPSIS integration method: A case study of hebei province, china. <em>SUPERC</em>, <em>81</em>(1), 1--38. (<a href='https://doi.org/10.1007/s11227-024-06813-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency material reserve is a key link in emergency management, and its site selection is scientific and rational, which directly affects the efficiency of emergency response, disaster rescue and social stability. To solve this site selection problem, a multi-criteria decision-making (MCDM) model named maximizing deviation G1 set pair analysis technique for order preferences by similarity to an ideal solution (MGSPA-TOPSIS) is proposed in this paper. First, the evaluation criteria system is constructed. Then, we use maximizing deviation and order relation analysis (G1) to assign subjective and objective weights, and use game theory to determine the final weights. Finally, this paper uses the combination of set pair analysis (SPA) and technique for order preference by similarity to ideal solution (TOPSIS) to sort, and takes 11 prefecture-level cities in Hebei Province as the research object. The final research results show that Shijiazhuang is the most suitable city for building emergency material reserve in Hebei Province. In the process of sensitivity analysis, the number of traffic practitioners is confirmed as the most important criteria, and by adjusting its value range to [0.1449, 0.2782], it is found that the change of the value of this criteria will not affect the stability of the model ranking. In addition, through large-scale experiments, the incidence of rank reversal in MGSPA-TOPSIS model remains below 20%. It is significantly lower than TOPSIS, preference ranking organization method for enrichment evaluations (PROMETHEE) and the set pair analysis technique for order preferences by similarity to an ideal solution (SPA-TOPSIS) decision model. The stability and robustness of MGSPA-TOPSIS model are further verified.},
  archive      = {J_SUPERC},
  author       = {Kong, Dekun and Yang, Wenguang},
  doi          = {10.1007/s11227-024-06813-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--38},
  shortjournal = {J. Supercomput.},
  title        = {Research on site selection of emergency material reserve based on set pair analysis and TOPSIS integration method: A case study of hebei province, china},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid blockchain and federated learning attention-based BERT transformer framework for medical records management. <em>SUPERC</em>, <em>81</em>(1), 1--34. (<a href='https://doi.org/10.1007/s11227-024-06816-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of federated learning, attention-based models like BERT, and blockchain technology presents a transformative approach for managing medical records. This paper introduces a hybrid framework combining the latter technologies to solve critical challenges pertaining to the secure management of healthcare data. Federated learning provides a distributed learning of machine models, where sensitive patient data does not need to be transferred, while BERT models improve the precision in processing medical records using natural language understanding. Blockchain adds a layer of security by recording model updates transparently to ensure tamper-proofing and transactions. A concrete methodology for the implementation of the introduced framework including the design of the smart contract in Solidity is provided to secure recording the model updates. Various tests assessing the performance of the proposed system show a significant improvement in data privacy, model security and precision, compared to the other systems. This hybrid methodology offers advances in handling medical records and elaborates a new benchmark in integrating AI and blockchain for healthcare. This framework thus redefines secure and collaborative healthcare data management, setting the stage for further enhancements in privacy-focused AI applications in medical contexts.},
  archive      = {J_SUPERC},
  author       = {Mnasri, Sami and Salah, Dorsaf and Idoudi, Hanen},
  doi          = {10.1007/s11227-024-06816-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--34},
  shortjournal = {J. Supercomput.},
  title        = {A hybrid blockchain and federated learning attention-based BERT transformer framework for medical records management},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating uncertainty methods for distributed deep learning on novel architectures. <em>SUPERC</em>, <em>81</em>(1), 1--15. (<a href='https://doi.org/10.1007/s11227-024-06818-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has become a cornerstone for advancements in computer vision, yielding models capable of remarkable performance on complex tasks. Despite these achievements, DL models often exhibit undue confidence; for example, when encountering out-of-distribution (OOD) inputs during inference, they may misclassify with high confidence. For many DL applications, these errors are critical and make accurate uncertainty estimates necessary. Our research focuses on implementing and evaluating different uncertainty assessment techniques for DL models. Our findings show each method’s computational advantages and challenges, providing researchers with invaluable insight. Furthermore, we present different real-world use cases of uncertainty estimations, such as image classification, scientific visualization (SciVis), detection of adversarial attacks on classification, and performance improvement on active learning classifiers. These tests used traditional High-Performance Computing (HPC) platforms alongside cutting edge AI accelerators. With their unique architectures, these platforms presented varying efficiencies in applying uncertainty estimation.},
  archive      = {J_SUPERC},
  author       = {Guerrero-Pantoja, David and Pautsch, Erick and Almeida, Clara and Rizzi, Silvio and Thiruvathukal, George K. and Pantoja, Maria},
  doi          = {10.1007/s11227-024-06818-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--15},
  shortjournal = {J. Supercomput.},
  title        = {Accelerating uncertainty methods for distributed deep learning on novel architectures},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning. <em>SUPERC</em>, <em>81</em>(1), 1--32. (<a href='https://doi.org/10.1007/s11227-024-06820-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing reliance on electric vehicles (EVs) necessitates advanced predictive models to enhance performance and sustainability, especially against climate change driven by fossil fuel combustion. This study advances the field using cutting-edge machine learning techniques to model and predict various EV characteristics and performance metrics. Using a comprehensive dataset with parameters such as model year, make, model type, vehicle class, motor power, and energy consumption metrics, we tested classification and regression models to forecast categorical features (vehicle make, category) and continuous features (energy consumption, range, charge time, motor power). The models were assessed using key performance indicators like accuracy, recall, F1 score, precision, MAE, RMSE, and R2. The random forest and Naive Bayes classifiers excelled in classification tasks, achieving accuracies of 95.58% and 100%, respectively. The Linear Regression model showed superior performance in predicting energy consumption in city driving conditions, with an R2 value of 0.9982. The K neighbors regressor was most effective in predicting range and motor power, with R2 values of 0.9800 and 0.9300, and the Huber regressor was most effective in predicting charge time. The study demonstrates the analytical models’ proficiency in projecting vehicular attributes and performance metrics by dividing the data into 70% for training and 30% for validation. The research provides crucial insights for policymakers, highlighting the potential of increased EV adoption to significantly decrease greenhouse gas emissions from the transportation sector, aiding in climate change mitigation.},
  archive      = {J_SUPERC},
  author       = {Khan, Ajmal and Iqbal, Naveed and Kaleem, Zeeshan and Qarnain, Zul and Bait-Suwailam, Mohammed M.},
  doi          = {10.1007/s11227-024-06820-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--32},
  shortjournal = {J. Supercomput.},
  title        = {A multi-model approach for predicting electric vehicle specifications and energy consumption using machine learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved PBFT consensus algorithm based on reputation and gaming. <em>SUPERC</em>, <em>81</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06822-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology provides a reliable and efficient environment for digital asset transactions. Consensus algorithms are the cornerstone of its security and accuracy. However, there are still security problems and performance bottlenecks associated with blockchain consensus algorithms in the context of current digital asset transactions, an improved PBFT algorithm (GamePBFT) based on reputation and game was proposed on the basis of Practical Byzantine Fault Tolerance (PBFT).Better applied to digital asset trading, we establish a reputation model that enables the dynamic reward and punishment of nodes according to their consensus behavior in this paper. Furthermore, a game model is constructed, which allows for the minimum number of nodes to participate in the consensus and the highest efficiency of eliminating malicious nodes. This can resist some common attacks, reduce the complexity of the algorithm, and improve the security and consensus efficiency of the algorithm. Finally, the results of the simulated node digital transaction scenario demonstrate that the improved consensus algorithm exhibits a notable enhancement over the PBFT consensus algorithm in terms of consensus latency, communication overhead, throughput, and security.},
  archive      = {J_SUPERC},
  author       = {Li, Zhe and Wang, Jinsong and Li, Yi},
  doi          = {10.1007/s11227-024-06822-2},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {An improved PBFT consensus algorithm based on reputation and gaming},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STPNet: A recurrent neural network for spatiotemporal processes predictive learning. <em>SUPERC</em>, <em>81</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06823-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal process prediction can assist in future spatiotemporal planning and decision-making. However, existing deep learning models still have improvement potential in expressing the complex relationships between spatially interrelated features in time series for spatiotemporal processes. In this paper, a spatiotemporal process prediction model (STPNet) is proposed and it is constructed by a novel stacked module, namely spatiotemporal attention unit (STA-LSTM unit). Compare with units in other spatiotemporal prediction models, the STA-LSTM unit combines the gating mechanism with the attention strategy to present the relationships of historical information and the dependency relationship between spatial features. Comprehensive experiments were conducted on three representative datasets, MovingMNIST, KTH Action, and Radar Echo, and results indicate that STPNet is highly applicable and effective in learning long-term dynamic features, making it suitable for a wide range of sequence-to-sequence spatiotemporal process prediction tasks.},
  archive      = {J_SUPERC},
  author       = {Chen, Zeqiang and Li, Zhiqing and Tang, Xu and Chen, Lai and Chen, Nengcheng},
  doi          = {10.1007/s11227-024-06823-1},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {STPNet: A recurrent neural network for spatiotemporal processes predictive learning},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neighbor full sum distinguishing total coloring of planar graphs. <em>SUPERC</em>, <em>81</em>(1), 1--13. (<a href='https://doi.org/10.1007/s11227-024-06825-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neighbor full sum distinguishing total coloring of a graph G is a proper total coloring $$\phi$$ such that no two adjacent vertices u and v of G satisfy $$\omega (u)=\omega (v)$$ , where for any $$v \in V(G)$$ , $$\omega (v)=\phi (v)+\sum _{e\ni v}\phi (e)+\sum _{u\in N(v)}\phi (u)$$ and N(v) = $$\{u \in V(G) | uv \in E(G)\}$$ . The minimum number of colors required for the coloring is called neighbor full sum distinguishing total chromatic number, denoted by $$ftndi_\Sigma (G)$$ . In this paper, we show that $$ftndi_{\Sigma} (G) \le \Delta (G)+3$$ if G is a normal planar graph with girth $$g(G)\ge 6$$ and maximum degree $$\Delta (G) \ge 10$$ .},
  archive      = {J_SUPERC},
  author       = {Yue, Zhongzheng and Wen, Fei and Li, Zhijun},
  doi          = {10.1007/s11227-024-06825-z},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--13},
  shortjournal = {J. Supercomput.},
  title        = {Neighbor full sum distinguishing total coloring of planar graphs},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic multi-objective optimization algorithm based on probability-driven prediction and correlation-guided individual transfer. <em>SUPERC</em>, <em>81</em>(1), 1--47. (<a href='https://doi.org/10.1007/s11227-024-06832-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge in addressing dynamic multi-objective optimization problems (DMOPs) is the rapid tracking of optimal solutions. Although methods based on transfer learning have shown remarkable performance in tackling DMOPs, most existing methods overlook the potential relationships between individuals within the population and those from historical environments. Consequently, they fail to adequately exploit historical information. To this end, this study proposes a dynamic multi-objective optimization algorithm based on probability-driven prediction and correlation-guided individual transfer (PDP&CGIT), which consists of two strategies: probability-driven prediction (PDP) and correlation-guided individual transfer (CGIT). Specifically, the PDP strategy analyzes the distribution of population characteristics and constructs a discriminative predictor based on a probability-annotation matrix to classify high-quality solutions from numerous randomly generated solutions within the decision space. Moreover, from the perspective of individual evolution, the CGIT strategy analyzes the correlation between current elite individuals and those from the previous moment. It learns the dynamic change pattern of the individuals and transfers this pattern to new environments. This is to maintain the diversity and distribution of the population. By integrating the advantages of these two strategies, PDP&CGIT can efficiently respond to environmental changes. Extensive experiments were performed to compare the proposed PDP&CGIT with five state-of-the-art algorithms across the FDA, F, and DF test suites. The results demonstrated the superiority of PDP&CGIT.},
  archive      = {J_SUPERC},
  author       = {Ge, Fangzhen and Zhao, Xuan and Chen, Debao and Shen, Longfeng and Liu, Huaiyu},
  doi          = {10.1007/s11227-024-06832-0},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--47},
  shortjournal = {J. Supercomput.},
  title        = {A dynamic multi-objective optimization algorithm based on probability-driven prediction and correlation-guided individual transfer},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A geometric algebra-enhanced network for skin lesion detection with diagnostic prior. <em>SUPERC</em>, <em>81</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06833-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic intelligent skin lesion recognition is crucial for elevating detection accuracy, enhancing diagnostic efficiency, and mitigating the risk of melanoma mortality. Despite advances, current methods often fall short in accuracy and acceptance among clinicians and patients. To improve clinical credibility, we propose an integrated system that incorporates medical diagnostic priors, structured into four distinct modules: skin area focus module, skin feature extraction module, anomaly feature attention module, and skin diagnostic interpretation module. These modules correspond to the clinical diagnostic steps in real-world settings. To obtain more structural information and richer features to assist in skin lesion classification, we developed neural networks and an attention module grounded in geometric algebra. Our skin lesion detection network is designed to be parameter-efficient and computationally light, with the parameters of the geometric algebra-based network and the attention mechanism reduced to 25% of their original size. Evaluations on the ISIC2020 public skin image dataset reveal that our approach outperforms existing methods. The method achieves an accuracy of 98.5% and an area under the curve of 98.8%, improving by 2.5% and 1.2% over the baseline.},
  archive      = {J_SUPERC},
  author       = {Wang, Fei and Ju, Ming and Zhu, Xianxun and Zhu, Qiuyu and Wang, Haiquan and Qian, Chunhua and Wang, Rui},
  doi          = {10.1007/s11227-024-06833-z},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {A geometric algebra-enhanced network for skin lesion detection with diagnostic prior},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource allocation based on optimized cellular network AP layout for visible light communication heterogeneous network. <em>SUPERC</em>, <em>81</em>(1), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06834-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible light communication (VLC) emerges as a promising wireless communication method to address the growing shortage of radio frequency resources. However, VLC faces challenges such as unstable data transmission, restricted coverage, and significant channel fading. To enhance data transmission quality, VLC can be integrated with traditional wireless communication methods within a heterogeneous network. This approach leverages the strengths of diverse technologies to achieve comprehensive indoor coverage and high-speed communication. A critical aspect of studying these heterogeneous networks is resource allocation. Three well-known resource management algorithms—maximum carrier-to-interference ratio (Max C/I), proportional fair (PF), and Maximum-Largest Weighted Delay First (M-LWDF)—are commonly utilized to optimize system throughput and fairness. However, M-LWDF suffers from a lack of fairness, leading to potential resource monopolization, while PF does not adequately account for access delays, limiting throughput improvements. This paper introduces a novel solution: the dynamic weighted proportional fair scheduling algorithm (DWPF), which integrates the strengths of both the M-LWDF and PF algorithms. By enhancing the layout of indoor visible light access points to consider distance effects, the DWPF algorithm achieves a throughput increase to 700 Mbps, with an average delay of approximately 0.006 ms and a utility value of 0.975. Additionally, both packet loss rate and fairness index demonstrate strong performance, ensuring users receive a high-quality communication experience.},
  archive      = {J_SUPERC},
  author       = {Du, Yu and Yang, Liwei and Luo, Yuchuan},
  doi          = {10.1007/s11227-024-06834-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Resource allocation based on optimized cellular network AP layout for visible light communication heterogeneous network},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient quantum circuit contraction using tensor decision diagrams. <em>SUPERC</em>, <em>81</em>(1), 1--25. (<a href='https://doi.org/10.1007/s11227-024-06836-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating quantum circuits efficiently on classical computers is crucial given the limitations of current noisy intermediate-scale quantum devices. This paper adapts and extends two methods used to contract tensor networks within the fast tensor decision diagram (FTDD) framework. The methods, called iterative pairing and block contraction, exploit the advantages of tensor decision diagrams to reduce both the temporal and spatial cost of quantum circuit simulations. The iterative pairing method minimizes intermediate diagram sizes, while the block contraction algorithm efficiently handles circuits with repetitive structures, such as those found in quantum walks and Grover’s algorithm. Experimental results demonstrate that, in some cases, these methods significantly outperform traditional contraction orders like sequential and cotengra in terms of both memory usage and execution time. Furthermore, simulation tools based on decision diagrams, such as FTDD, show superior performance to matrix-based simulation tools, such as Google tensor networks, enabling the simulation of larger circuits more efficiently. These findings show the potential of decision diagram-based approaches to improve the simulation of quantum circuits on classical platforms.},
  archive      = {J_SUPERC},
  author       = {Lopez-Oliva, Vicente and Badia, Jose M. and Castillo, Maribel},
  doi          = {10.1007/s11227-024-06836-w},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Supercomput.},
  title        = {Efficient quantum circuit contraction using tensor decision diagrams},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-image reflection removal via self-supervised diffusion models. <em>SUPERC</em>, <em>81</em>(1), 1--27. (<a href='https://doi.org/10.1007/s11227-024-06837-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reflections often degrade the visual quality of images captured through transparent surfaces, and reflection removal methods suffer from the shortage of paired real-world samples. This paper proposes a hybrid approach that combines cycle consistency with denoising diffusion probabilistic models (DDPM) to effectively remove reflections from single images without requiring paired training data. The method introduces a reflective removal network (RRN) that leverages DDPMs to model the decomposition process and recover the transmission image, and a reflective synthesis network (RSN) that re-synthesizes the input image using the separated components through a nonlinear attention-based mechanism. Experimental results demonstrate the effectiveness of the proposed method on the SIR $$^2$$ , flash-based reflection removal (FRR) dataset, and a newly introduced museum reflection removal (MRR) dataset, showing superior performance compared to state-of-the-art methods.},
  archive      = {J_SUPERC},
  author       = {Lu, Zhengyang and Wang, Weifan and Guo, Tianhao and Wang, Feng},
  doi          = {10.1007/s11227-024-06837-9},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--27},
  shortjournal = {J. Supercomput.},
  title        = {Single-image reflection removal via self-supervised diffusion models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance analysis of user power consumption in NR-unlicensed DRX. <em>SUPERC</em>, <em>81</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11227-024-06839-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Third Generation Partnership Project (3GPP) in Release 16 introduced New Radio in unlicensed spectrum (NR-U) to further enhance the capacity of licensed spectrum. The user equipment’s (UE) power consumption is an important metric identified by researchers in long-term evolution (LTE) and NR, and now in NR-U. In long-term evolution (LTE) and NR, 3GPP has introduced discontinuous reception (DRX) to save the UE’s power consumption and it can also be used in NR-U. In the DRX procedure, UE sleeps when there is no data packet to serve and wakes up at regular periodic intervals to check if there are any data packets in the downlink. The UE can sleep longer and skip most channel monitoring occasions, which helps to save the power of the UE. In this article, we analyze the power consumption of the UE in the DRX mechanism over NR-U networks. We model the DRX using semi-Markov-based modeling to analyze the power consumption of the UE, and the average delay experienced by the UE in the NR-U DRX mechanism. Analytical analysis indicates that power consumption increases with increasing DRX-ON duration and decreases with increasing sleep duration. The power consumption reduces at the cost of delay, i.e., delay increases with an increase in sleep duration.},
  archive      = {J_SUPERC},
  author       = {Rastogi, Eshita and Maheshwari, Mukesh Kumar and Rastogi, Ayush},
  doi          = {10.1007/s11227-024-06839-7},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Supercomput.},
  title        = {Performance analysis of user power consumption in NR-unlicensed DRX},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent decision making algorithm for path planning based on reference linguistic fuzzy set. <em>SUPERC</em>, <em>81</em>(1), 1--23. (<a href='https://doi.org/10.1007/s11227-024-06842-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel path planning algorithm called Reference Linguistic Fuzzy Algorithm (RLFA); moreover, the parametric analysis procedure of the RLFA is described in this paper. It finds the optimal path by calculating the decision value required by path planning. However, most of the research ignores the issue of equal decision scores. The proposed algorithm has been compared to the original distance metrics, the fuzzy synthetic evaluation method, the modified three-way TOPSIS method, and the Generalized TODIM method. Compared with the existing algorithms, the algorithm proposed in this paper improves the reliability of path planning decision making and eliminates the defects of the traditional algorithms, which rely on parameter settings. It combines subjective and objective dual evaluation perspectives to correct the possible bias in the single subjective perspective. This paper is supported by experimental validation, and the results show that the proposed algorithm can achieve the optimal solution under all conditions.},
  archive      = {J_SUPERC},
  author       = {Gan, Lian and Du, YuHong and Wang, Shuai and Ren, WeiJia and Rong, ZiQi and Li, XinLong},
  doi          = {10.1007/s11227-024-06842-y},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Supercomput.},
  title        = {Intelligent decision making algorithm for path planning based on reference linguistic fuzzy set},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy protection in federated learning: A study on the combined strategy of local and global differential privacy. <em>SUPERC</em>, <em>81</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11227-024-06845-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing awareness of data privacy protection and the growing stringency of data security regulations, federated learning (FL) as a distributed machine learning approach has garnered widespread attention. However, in practice, FL faces severe challenges in privacy protection. This paper proposes a method that combines local differential privacy (LDP) and global differential privacy (GDP) in an FL environment. The algorithm addresses data privacy issues in FL while minimizing the impact on model performance. Our approach was evaluated on the MNIST and CIFAR-10 datasets, achieving superior results with 97.30% accuracy on MNIST and 90.18% accuracy on CIFAR-10, outperforming existing methods such as DPSaab and MPC. Additionally, LG-DPPA demonstrated strong resilience to privacy attacks, with a 97.44% membership inference attack (MIA) resistance on MNIST and a low adversarial attack success rate of 12.39% on CIFAR-10. The model maintained low utility loss, at only 1.91 on MNIST and 2.07 on CIFAR-10, highlighting its ability to balance privacy, accuracy, and computational efficiency. Additionally, the paper explores the impact of different privacy budgets and communication rounds on model performance, as well as how to choose appropriate parameter configurations in practical applications. This method is significant for handling sensitive data in FL environments and can also promote the development and application of privacy protection technologies.},
  archive      = {J_SUPERC},
  author       = {Zhu, Libo and Chen, Xiang},
  doi          = {10.1007/s11227-024-06845-9},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Supercomput.},
  title        = {Privacy protection in federated learning: A study on the combined strategy of local and global differential privacy},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPGPT: Natural product-like compound generation with GPT-based chemical language models. <em>SUPERC</em>, <em>81</em>(1), 1--16. (<a href='https://doi.org/10.1007/s11227-024-06860-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural products are substances produced by organisms in nature and often possess biological activity and structural diversity. Drug development based on natural products has been common for many years. However, the intricate structures of these compounds present challenges in terms of structure determination and synthesis, particularly compared to the efficiency of high-throughput screening of synthetic compounds. In recent years, deep learning-based methods have been applied to the generation of molecules. In this study, we trained chemical language models on a natural product dataset and generated natural product-like compounds and verified the performance of the generated compounds as a drug candidate library. The results showed that the distribution of the compounds generated was similar to that of natural products. We also evaluated the effectiveness of the generated compounds as drug candidates. Our method can be used to explore the vast chemical space and reduce the time and cost of drug discovery of natural products.},
  archive      = {J_SUPERC},
  author       = {Sakano, Koh and Furui, Kairi and Ohue, Masahito},
  doi          = {10.1007/s11227-024-06860-w},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {NPGPT: Natural product-like compound generation with GPT-based chemical language models},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovations in mathematical modeling, AI, and optimization techniques. <em>SUPERC</em>, <em>81</em>(1), 1--4. (<a href='https://doi.org/10.1007/s11227-024-06861-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue is dedicated to examining the rapidly evolving fields of artificial intelligence, mathematical modeling, and optimization, with particular emphasis on their growing importance in computational science. It features the most notable papers from the "Mathematical Modeling and Problem Solving" workshop at PDPTA'24, the 30th International Conference on Parallel and Distributed Processing Techniques and Applications. The issue showcases pioneering research in areas such as natural language processing, system optimization, and high-performance computing. The nine selected studies include novel AI-driven methods for chemical compound generation, historical text recognition, and music recommendation, along with advancements in hardware optimization through reconfigurable accelerators and vector register sharing. Additionally, evolutionary and hyper-heuristic algorithms are explored for sophisticated problem-solving in engineering design, and innovative techniques are introduced for high-speed numerical methods in large-scale systems. Collectively, these contributions demonstrate the significance of AI, supercomputing, and advanced algorithms in driving the next generation of scientific discovery.},
  archive      = {J_SUPERC},
  author       = {Ohue, Masahito and Yasuo, Nobuaki and Takata, Masami},
  doi          = {10.1007/s11227-024-06861-9},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--4},
  shortjournal = {J. Supercomput.},
  title        = {Innovations in mathematical modeling, AI, and optimization techniques},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision transformer-based meta loss landscape exploration with actor-critic method. <em>SUPERC</em>, <em>81</em>(1), 1--16. (<a href='https://doi.org/10.1007/s11227-024-06867-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting and mitigating overfitting in deep neural networks remains a critical challenge in modern machine learning. This paper investigates innovative approaches to address these challenges, particularly focusing on vision transformer-based models. By leveraging meta-learning techniques and reinforcement learning frameworks, we introduce transformer-based loss landscape exploration (TLLE), which utilizes the validation loss landscape to guide gradient descent optimization. Unlike conventional methods, TLLE employs the actor-critic algorithm to learn the mapping from model weights to future values, facilitating efficient sample collection and precise value predictions. Experimental results demonstrate the superior performance of TLLE-enhanced transformer models in image classification and segmentation tasks, showcasing the efficacy of our approach in optimizing deep learning models for image analysis.},
  archive      = {J_SUPERC},
  author       = {Zhang, Enzhi and Zhong, Rui and Du, Xingbang and Wahib, Mohamed and Munetomo, Masaharu},
  doi          = {10.1007/s11227-024-06867-3},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--16},
  shortjournal = {J. Supercomput.},
  title        = {Vision transformer-based meta loss landscape exploration with actor-critic method},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AE-UNet: A composite lung CT image segmentation framework using attention mechanism and edge detection. <em>SUPERC</em>, <em>81</em>(1), 1--21. (<a href='https://doi.org/10.1007/s11227-024-06874-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary impediments in lung CT image segmentation stem from the ambiguity in edge definition and the inadequate segmentation accuracy. Addressing these issues, this paper introduces a novel composite lung CT image segmentation framework that integrates an attention mechanism with an edge detection operator. We utilize residual dynamic convolutions as the encoder to augment the network's capability for extracting and representing nuanced lesion features. Sobel edge detection is integrated into the skip connections to facilitate the transmission and utilization of edge information. In particular, we introduce an information fusion attention module for deeper layers, optimizing feature reorganization and utilization by attention mechanisms and dilated convolution. Experimental evaluations on two lung CT datasets reveal that our proposed AE-UNet achieves outstanding segmentation performance, surpassing the best baseline network by an average of 0.93%.},
  archive      = {J_SUPERC},
  author       = {Li, Hongzhi and Ren, Zhanghao and Zhu, Guoqing and Wang, Jiaxi},
  doi          = {10.1007/s11227-024-06874-4},
  journal      = {The Journal of Supercomputing},
  month        = {1},
  number       = {1},
  pages        = {1--21},
  shortjournal = {J. Supercomput.},
  title        = {AE-UNet: A composite lung CT image segmentation framework using attention mechanism and edge detection},
  volume       = {81},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
