<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mp">MP - 113</h2>
<ul>
<li><details>
<summary>
(2025). Correction: Regular packing of rooted hyperforests with root constraints in hypergraphs. <em>MP</em>, <em>213</em>(1), 1279. (<a href='https://doi.org/10.1007/s10107-025-02203-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Hoppenot, Pierre and Martin, Mathis and Szigeti, Zoltán},
  doi          = {10.1007/s10107-025-02203-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1279},
  shortjournal = {Math. Program.},
  title        = {Correction: Regular packing of rooted hyperforests with root constraints in hypergraphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean robust optimization. <em>MP</em>, <em>213</em>(1), 1235-1277. (<a href='https://doi.org/10.1007/s10107-024-02170-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization is a tractable and expressive technique for decision-making under uncertainty, but it can lead to overly conservative decisions when pessimistic assumptions are made on the uncertain parameters. Wasserstein distributionally robust optimization can reduce conservatism by being data-driven, but it often leads to very large problems with prohibitive solution times. We introduce mean robust optimization, a general framework that combines the best of both worlds by providing a trade-off between computational effort and conservatism. We propose uncertainty sets constructed based on clustered data rather than on observed data points directly thereby significantly reducing problem size. By varying the number of clusters, our method bridges between robust and Wasserstein distributionally robust optimization. We show finite-sample performance guarantees and explicitly control the potential additional pessimism introduced by any clustering procedure. In addition, we prove conditions for which, when the uncertainty enters linearly in the constraints, clustering does not affect the optimal solution. We illustrate the efficiency and performance preservation of our method on several numerical examples, obtaining multiple orders of magnitude speedups in solution time with little-to-no effect on the solution quality.},
  archive      = {J_MP},
  author       = {Wang, Irina and Becker, Cole and Van Parys, Bart and Stellato, Bartolomeo},
  doi          = {10.1007/s10107-024-02170-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1235-1277},
  shortjournal = {Math. Program.},
  title        = {Mean robust optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regular packing of rooted hyperforests with root constraints in hypergraphs. <em>MP</em>, <em>213</em>(1), 1211-1233. (<a href='https://doi.org/10.1007/s10107-024-02167-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seminal papers of Edmonds (Combinatorial algorithms, Academic Press, New York, 1973), Nash-Williams (J Lond Math Soc 36:445–450, 1961) and Tutte (J Lond Math Soc 36:221–230, 1961) have laid the foundations of the theories of packing arborescences and packing trees. The directed version has been extensively investigated, resulting in a great number of generalizations. In contrast, the undirected version has been marginally considered. The aim of this paper is to further develop the theories of packing trees and forests. Our main result on graphs characterizes the existence of a packing of k forests, $$F_1, \ldots , F_k$$ , in a graph G such that each vertex of G belongs to exactly h of the forests, the number of connected components of each $$F_i$$ is between $$\ell (i)$$ and $$\ell '(i)$$ and the total number of connected components in the packing is between $$\alpha $$ and $$\beta $$ . Finally, we extend this result to hypergraphs and dypergraphs, the latter giving a generalization of a theorem of Bérczi and Frank (Math Oper Res 43(3):726–753, 2018). As a matter of fact, this research was motivated by the paper of Bérczi and Frank (Math Oper Res 43(3):726–753, 2018).},
  archive      = {J_MP},
  author       = {Hoppenot, Pierre and Martin, Mathis and Szigeti, Zoltán},
  doi          = {10.1007/s10107-024-02167-z},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1211-1233},
  shortjournal = {Math. Program.},
  title        = {Regular packing of rooted hyperforests with root constraints in hypergraphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On rank-monotone graph operations and minimal obstruction graphs for the Lovász–Schrijver SDP hierarchy. <em>MP</em>, <em>213</em>(1), 1169-1209. (<a href='https://doi.org/10.1007/s10107-024-02166-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the lift-and-project rank of the stable set polytopes of graphs with respect to the Lovász–Schrijver SDP operator $${{\,\textrm{LS}\,}}_+$$ , with a particular focus on finding and characterizing the smallest graphs with a given $${{\,\textrm{LS}\,}}_+$$ -rank (the needed number of iterations of the $${{\,\textrm{LS}\,}}_+$$ operator on the fractional stable set polytope to compute the stable set polytope). We introduce a generalized vertex-stretching operation that appears to be promising in generating $${{\,\textrm{LS}\,}}_+$$ -minimal graphs and study its properties. We also provide several new $${{\,\textrm{LS}\,}}_+$$ -minimal graphs, most notably the first known instances of 12-vertex graphs with $${{\,\textrm{LS}\,}}_+$$ -rank 4, which provides the first advance in this direction since Escalante, Montelar, and Nasini’s discovery of a 9-vertex graph with $${{\,\textrm{LS}\,}}_+$$ -rank 3 in 2006.},
  archive      = {J_MP},
  author       = {Au, Yu Hin and Tunçel, Levent},
  doi          = {10.1007/s10107-024-02166-0},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1169-1209},
  shortjournal = {Math. Program.},
  title        = {On rank-monotone graph operations and minimal obstruction graphs for the Lovász–Schrijver SDP hierarchy},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying low rank approximations of third order symmetric tensors. <em>MP</em>, <em>213</em>(1), 1119-1168. (<a href='https://doi.org/10.1007/s10107-024-02165-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a method to certify the approximation quality of a low rank tensor to a given third order symmetric tensor. Under mild assumptions, best low rank approximation is attained if a control parameter is zero or quantified quasi-optimal low rank approximation is obtained if the control parameter is positive. This is based on a primal-dual method for computing a low rank approximation for a given tensor. The certification is derived from the global optimality of the primal and dual problems, and is characterized by easily checkable relations between the primal and the dual solutions together with another rank condition. The theory is verified theoretically for orthogonally decomposable tensors as well as numerically through examples in the general case.},
  archive      = {J_MP},
  author       = {Hu, Shenglong and Sun, Defeng and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-024-02165-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1119-1168},
  shortjournal = {Math. Program.},
  title        = {Quantifying low rank approximations of third order symmetric tensors},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acceleration by stepsize hedging: Silver stepsize schedule for smooth convex optimization. <em>MP</em>, <em>213</em>(1), 1105-1118. (<a href='https://doi.org/10.1007/s10107-024-02164-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a concise, self-contained proof that the Silver Stepsize Schedule proposed in our companion paper directly applies to smooth (non-strongly) convex optimization. Specifically, we show that with these stepsizes, gradient descent computes an $$\varepsilon $$ -minimizer in $$O(\varepsilon ^{-\log _{\rho } 2}) = O(\varepsilon ^{-0.7864})$$ iterations, where $$\rho = 1+\sqrt{2}$$ is the silver ratio. This is intermediate between the textbook unaccelerated rate $$O(\varepsilon ^{-1})$$ and the accelerated rate $$O(\varepsilon ^{-1/2})$$ due to Nesterov in 1983. The Silver Stepsize Schedule is a simple explicit fractal: the i-th stepsize is $$1 + \rho ^{\nu (i)-1}$$ where $$\nu (i)$$ is the 2-adic valuation of i. The design and analysis are conceptually identical to the strongly convex setting in our companion paper, but simplify remarkably in this specific setting.},
  archive      = {J_MP},
  author       = {Altschuler, Jason M. and Parrilo, Pablo A.},
  doi          = {10.1007/s10107-024-02164-2},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1105-1118},
  shortjournal = {Math. Program.},
  title        = {Acceleration by stepsize hedging: Silver stepsize schedule for smooth convex optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A first-order augmented lagrangian method for constrained minimax optimization. <em>MP</em>, <em>213</em>(1), 1063-1104. (<a href='https://doi.org/10.1007/s10107-024-02163-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an operation complexity of $$\mathcal{O}(\varepsilon ^{-4}\log \varepsilon ^{-1})$$ , measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $$\varepsilon $$ -KKT solution of the constrained minimax problems.},
  archive      = {J_MP},
  author       = {Lu, Zhaosong and Mei, Sanyou},
  doi          = {10.1007/s10107-024-02163-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1063-1104},
  shortjournal = {Math. Program.},
  title        = {A first-order augmented lagrangian method for constrained minimax optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended formulations for binary optimal control problems. <em>MP</em>, <em>213</em>(1), 1039-1062. (<a href='https://doi.org/10.1007/s10107-024-02162-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended formulations are an important tool in polyhedral combinatorics. Many combinatorial optimization problems require an exponential number of inequalities when modeled as a linear program in the natural space of variables. However, by adding artificial variables, one can often find a small linear formulation, i.e., one containing a polynomial number of variables and constraints, such that the projection to the original space of variables yields a perfect linear formulation. Motivated by binary optimal control problems with switching constraints, we show that a similar approach can be useful also for optimization problems in function space, in order to model the closed convex hull of feasible controls in a compact way. More specifically, we present small extended formulations for switches with bounded variation and for dwell-time constraints. For general linear switching point constraints, we devise an extended model linearizing the problem, but show that a small extended formulation that is compatible with discretization cannot exist unless P = NP.},
  archive      = {J_MP},
  author       = {Buchheim, Christoph},
  doi          = {10.1007/s10107-024-02162-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1039-1062},
  shortjournal = {Math. Program.},
  title        = {Extended formulations for binary optimal control problems},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved global guarantees for the nonconvex Burer–Monteiro factorization via rank overparameterization. <em>MP</em>, <em>213</em>(1), 1009-1038. (<a href='https://doi.org/10.1007/s10107-024-02160-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider minimizing a twice-differentiable, L-smooth, and $$\mu $$ -strongly convex objective $$\phi $$ over an $$n\times n$$ positive semidefinite matrix $$M\succeq 0$$ , under the assumption that the minimizer $$M^{\star }$$ has low rank $$r^{\star }\ll n$$ . Following the Burer–Monteiro approach, we instead minimize the nonconvex objective $$f(X)=\phi (XX^{T})$$ over a factor matrix X of size $$n\times r$$ . This substantially reduces the number of variables from $$O(n^{2})$$ to as few as O(n) and also enforces positive semidefiniteness for free, but at the cost of giving up the convexity of the original problem. In this paper, we prove that if the search rank $$r\ge r^{\star }$$ is overparameterized by a constant factor with respect to the true rank $$r^{\star }$$ , namely as in $$r>\frac{1}{4}(L/\mu -1)^{2}r^{\star }$$ , then despite nonconvexity, local optimization is guaranteed to globally converge from any initial point to the global optimum. This significantly improves upon a previous rank overparameterization threshold of $$r\ge n$$ , which we show is sharp in the absence of smoothness and strong convexity, but would increase the number of variables back up to $$O(n^{2})$$ . Conversely, without rank overparameterization, we prove that such a global guarantee is possible if and only if $$\phi $$ is almost perfectly conditioned, with a condition number of $$L/\mu <3$$ . Therefore, we conclude that a small amount of overparameterization can lead to large improvements in theoretical guarantees for the nonconvex Burer–Monteiro factorization.},
  archive      = {J_MP},
  author       = {Zhang, Richard Y.},
  doi          = {10.1007/s10107-024-02160-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1009-1038},
  shortjournal = {Math. Program.},
  title        = {Improved global guarantees for the nonconvex Burer–Monteiro factorization via rank overparameterization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact and approximation algorithms for routing a convoy through a graph. <em>MP</em>, <em>213</em>(1), 985-1008. (<a href='https://doi.org/10.1007/s10107-024-02159-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study routing problems of a convoy in a graph, generalizing the shortest path problem (SPP), the travelling salesperson problem (TSP), and the Chinese postman problem (CPP) which are all well-studied in the classical (non-convoy) setting. We assume that each edge in the graph has a length and a speed at which it can be traversed and that our convoy has a given length. While the convoy moves through the graph, parts of it can be located on different edges. For safety requirements, at all time the whole convoy needs to travel at the same speed which is dictated by the slowest edge on which currently a part of the convoy is located. For Convoy-SPP, we give a strongly polynomial time exact algorithm. For Convoy-TSP, we provide an $$O(\log n)$$ -approximation algorithm and an O(1)-approximation algorithm for trees. Both results carry over to Convoy-CPP which—maybe surprisingly—we prove to be $$\textsf{NP}$$ -hard in the convoy setting. This contrasts the non-convoy setting in which the problem is polynomial time solvable.},
  archive      = {J_MP},
  author       = {van Ee, Martijn and Oosterwijk, Tim and Sitters, René and Wiese, Andreas},
  doi          = {10.1007/s10107-024-02159-z},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {985-1008},
  shortjournal = {Math. Program.},
  title        = {Exact and approximation algorithms for routing a convoy through a graph},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebraic combinatorial optimization on the degree of determinants of noncommutative symbolic matrices. <em>MP</em>, <em>213</em>(1), 941-984. (<a href='https://doi.org/10.1007/s10107-024-02158-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the computation of the degrees of minors of a noncommutative symbolic matrix of form $$ A[c] :=\sum _{k=1}^m A_k t^{c_k} x_k, $$ where $$A_k$$ are matrices over a field $$\mathbb {K}$$ , $$x_k$$ are noncommutative variables, $$c_k$$ are integer weights, and t is a commuting variable specifying the degree. This problem extends noncommutative Edmonds’ problem (Ivanyos et al. in Comput Complex 26:717–763, 2017), and can formulate various combinatorial optimization problems. Extending the study by Hirai 2018, and Hirai, Ikeda 2022, we provide novel duality theorems and polyhedral characterization for the maximum degrees of minors of A[c] of all sizes, and develop a strongly polynomial-time algorithm for computing them. This algorithm is viewed as a unified algebraization of the classical Hungarian method for bipartite matching and the weight-splitting algorithm for linear matroid intersection. As applications, we provide polynomial-time algorithms for weighted fractional linear matroid matching and for membership of rank-2 Brascamp–Lieb polytopes.},
  archive      = {J_MP},
  author       = {Hirai, Hiroshi and Iwamasa, Yuni and Oki, Taihei and Soma, Tasuku},
  doi          = {10.1007/s10107-024-02158-0},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {941-984},
  shortjournal = {Math. Program.},
  title        = {Algebraic combinatorial optimization on the degree of determinants of noncommutative symbolic matrices},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A projection-free method for solving convex bilevel optimization problems. <em>MP</em>, <em>213</em>(1), 907-940. (<a href='https://doi.org/10.1007/s10107-024-02157-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When faced with multiple minima of an inner-level convex optimization problem, the convex bilevel optimization problem selects an optimal solution which also minimizes an auxiliary outer-level convex objective of interest. Bilevel optimization requires a different approach compared to single-level optimization problems since the set of minimizers for the inner-level objective is not given explicitly. In this paper, we propose a new projection-free conditional gradient method for convex bilevel optimization which requires only a linear optimization oracle over the base domain. We establish $$O(t^{-1/2})$$ convergence rate guarantees for our method in terms of both inner- and outer-level objectives, and demonstrate how additional assumptions such as quadratic growth and strong convexity result in accelerated rates of up to $$O(t^{-1})$$ and $$O(t^{-2/3})$$ for inner- and outer-levels respectively. Lastly, we conduct a numerical study to demonstrate the performance of our method.},
  archive      = {J_MP},
  author       = {Giang-Tran, Khanh-Hung and Ho-Nguyen, Nam and Lee, Dabeen},
  doi          = {10.1007/s10107-024-02157-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {907-940},
  shortjournal = {Math. Program.},
  title        = {A projection-free method for solving convex bilevel optimization problems},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riemannian trust-region methods for strict saddle functions with complexity guarantees. <em>MP</em>, <em>213</em>(1), 863-905. (<a href='https://doi.org/10.1007/s10107-024-02156-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of minimizing a nonconvex function is in part explained by the presence of saddle points. This slows down optimization algorithms and impacts worst-case complexity guarantees. However, many nonconvex problems of interest possess a favorable structure for optimization, in the sense that saddle points can be escaped efficiently by appropriate algorithms. This strict saddle property has been extensively used in data science to derive good properties for first-order algorithms, such as convergence to second-order critical points. However, the analysis and the design of second-order algorithms in the strict saddle setting have received significantly less attention. In this paper, we consider second-order trust-region methods for a class of strict saddle functions defined on Riemannian manifolds. These functions exhibit (geodesic) strong convexity around minimizers and negative curvature at saddle points. We first show that the standard trust-region method with exact subproblem minimization finds an approximate local minimizer in a number of iterations that depends logarithmically on the accuracy parameter, which significantly improves known results for general nonconvex optimization. We then propose a new inexact variant of the algorithm that explicitly leverages the strict saddle property to compute the most appropriate step at every iteration. Our bounds for the inexact variant also improve over the general nonconvex case, and illustrate the benefit of using strict saddle properties within optimization algorithms.},
  archive      = {J_MP},
  author       = {Goyens, Florentin and Royer, Clément W.},
  doi          = {10.1007/s10107-024-02156-2},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {863-905},
  shortjournal = {Math. Program.},
  title        = {Riemannian trust-region methods for strict saddle functions with complexity guarantees},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From coordinate subspaces over finite fields to ideal multipartite uniform clutters. <em>MP</em>, <em>213</em>(1), 823-861. (<a href='https://doi.org/10.1007/s10107-024-02155-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Take a prime power q, an integer $$n\ge 2$$ , and a coordinate subspace $$S\subseteq GF(q)^n$$ over the Galois field GF(q). One can associate with S an n-partite n-uniform clutter $$\mathcal {C}$$ , where every part has size q and there is a bijection between the vectors in S and the members of $$\mathcal {C}$$ . In this paper, we determine when the clutter $$\mathcal {C}$$ is ideal, a property developed in connection to Packing and Covering problems in the areas of Integer Programming and Combinatorial Optimization. Interestingly, the characterization differs depending on whether q is 2, 4, a higher power of 2, or otherwise. Each characterization uses crucially that idealness is a minor-closed property: first the list of excluded minors is identified, and only then is the global structure determined. A key insight is that idealness of $$\mathcal {C}$$ depends solely on the underlying matroid of S. Our theorems also extend from idealness to the stronger max-flow min-cut property. As a consequence, we prove the Replication and $$\tau =2$$ Conjectures for this class of clutters.},
  archive      = {J_MP},
  author       = {Abdi, Ahmad and Lee, Dabeen},
  doi          = {10.1007/s10107-024-02155-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {823-861},
  shortjournal = {Math. Program.},
  title        = {From coordinate subspaces over finite fields to ideal multipartite uniform clutters},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated-gradient-based generalized Levenberg–Marquardt method with oracle complexity bound and local quadratic convergence. <em>MP</em>, <em>213</em>(1), 771-822. (<a href='https://doi.org/10.1007/s10107-024-02154-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing the sum of a convex function and a composite function appears in various fields. The generalized Levenberg–Marquardt (LM) method, also known as the prox-linear method, has been developed for such optimization problems. The method iteratively solves strongly convex subproblems with a damping term. This study proposes a new generalized LM method for solving the problem with a smooth composite function. The method enjoys three theoretical guarantees: iteration complexity bound, oracle complexity bound, and local convergence under a Hölderian growth condition. The local convergence results include local quadratic convergence under the quadratic growth condition; this is the first to extend the classical result for least-squares problems to a general smooth composite function. In addition, this is the first LM method with both an oracle complexity bound and local quadratic convergence under standard assumptions. These results are achieved by carefully controlling the damping parameter and solving the subproblems by the accelerated proximal gradient method equipped with a particular termination condition. Experimental results show that the proposed method performs well in practice for several instances, including classification with a neural network and nonnegative matrix factorization.},
  archive      = {J_MP},
  author       = {Marumo, Naoki and Okuno, Takayuki and Takeda, Akiko},
  doi          = {10.1007/s10107-024-02154-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {771-822},
  shortjournal = {Math. Program.},
  title        = {Accelerated-gradient-based generalized Levenberg–Marquardt method with oracle complexity bound and local quadratic convergence},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural spectrahedra and semidefinite lifts: Global convex optimization of degree-two polynomial activation neural networks in polynomial-time. <em>MP</em>, <em>213</em>(1), 737-769. (<a href='https://doi.org/10.1007/s10107-024-02153-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of two-layer neural networks with nonlinear activation functions is an important non-convex optimization problem with numerous applications and promising performance in layerwise deep learning. In this paper, we develop exact convex optimization formulations for two-layer neural networks with second degree polynomial activations based on dual relaxations and semidefinite programming. Remarkably, we show that our semidefinite relaxations are always tight. Therefore, the computational complexity for global optimization is polynomial in the input dimension and sample size for all input data. The developed convex formulations are proven to achieve the same globally optimal solution set as their non-convex counterparts. Specifically, globally optimal two-layer neural networks with degree-two polynomial activations can be found by solving a semidefinite program (SDP) and decomposing the solution using a procedure we call Neural Decomposition. Moreover, the choice of regularizers plays a crucial role in the computational tractability of neural network training. We show that the standard weight decay regularization formulation is NP-hard, whereas other simple convex penalties render the problem tractable in polynomial time via convex programming. The techniques go beyond the fully connected architecture to encompass various neural network structures including those with vector outputs and convolutional architectures. We provide extensive numerical simulations showing that the standard backpropagation approach often fails to achieve the global optimum of the training loss. The proposed approach is significantly faster to obtain better test accuracy compared to the standard backpropagation procedure.},
  archive      = {J_MP},
  author       = {Bartan, Burak and Pilanci, Mert},
  doi          = {10.1007/s10107-024-02153-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {737-769},
  shortjournal = {Math. Program.},
  title        = {Neural spectrahedra and semidefinite lifts: Global convex optimization of degree-two polynomial activation neural networks in polynomial-time},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The mixed integer trust region problem. <em>MP</em>, <em>213</em>(1), 699-736. (<a href='https://doi.org/10.1007/s10107-024-02152-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of minimizing a general quadratic function over the mixed integer points in an ellipsoid. This problem is strongly NP-hard, NP-hard to approximate within a constant factor, and optimal solutions can be irrational. In our main result we show that an arbitrarily good solution can be found in polynomial time, if we fix the number of integer variables. This algorithm provides a natural extension to the mixed integer setting, of the polynomial solvability of the trust region problem proven by Ye, Karmarkar, Vavasis, and Zippel. As a result, our findings pave the way for designing efficient trust region methods for mixed integer nonlinear optimization problems. The techniques that we introduce are of independent interest and can be used in other mixed integer nonlinear optimization problems. As an example, we consider the problem of minimizing a general quadratic function over the mixed integer points in a polyhedron. For this problem, we show that a solution satisfying weak bounds with respect to optimality can be computed in polynomial time, provided that the number of integer variables is fixed. It is well known that finding a solution satisfying stronger bounds cannot be done in polynomial time, unless P = NP.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto},
  doi          = {10.1007/s10107-024-02152-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {699-736},
  shortjournal = {Math. Program.},
  title        = {The mixed integer trust region problem},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear distributionally robust optimization. <em>MP</em>, <em>213</em>(1), 639-698. (<a href='https://doi.org/10.1007/s10107-024-02151-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially nonlinear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank–Wolfe (FW) algorithm for generic nonlinear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the nonlinear DRO problem. Finally, we validate our theoretical results on two cases of the entropic and variance risk measures in the context of portfolio selection problems. In particular, we analyze their regularity conditions and “sufficient statistic”, compute the respective FW-oracle in various settings, and confirm the theoretical outcomes through numerical validation.},
  archive      = {J_MP},
  author       = {Sheriff, Mohammed Rayyan and Mohajerin Esfahani, Peyman},
  doi          = {10.1007/s10107-024-02151-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {639-698},
  shortjournal = {Math. Program.},
  title        = {Nonlinear distributionally robust optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALSO-x#: Better convex approximations for distributionally robust chance constrained programs. <em>MP</em>, <em>213</em>(1), 575-638. (<a href='https://doi.org/10.1007/s10107-024-02150-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies distributionally robust chance constrained programs (DRCCPs), where the uncertain constraints must be satisfied with at least a probability of a prespecified threshold for all probability distributions from the Wasserstein ambiguity set. As DRCCPs are often nonconvex and some DRCCPs may not have mixed-integer reformulations, researchers have been developing various convex inner approximations. Recently, ALSO-X has been proven to outperform the conditional value-at-risk (CVaR) approximation of a regular chance constrained program when the deterministic set is convex. In this work, we relax this assumption by introducing a new ALSO-X# method to solve DRCCPs. Namely, in the bilevel structures of ALSO-X and CVaR approximation, we observe that the lower-level ALSO-X is a special case of the lower-level CVaR approximation, and the upper-level CVaR approximation is more restricted than the one in ALSO-X. This observation motivates us to propose ALSO-X#, which has a bilevel structure—in the lower-level problem, we adopt the more general CVaR approximation, and for the upper-level one, we choose the less restricted ALSO-X. We show that ALSO-X# is always better than CVaR approximation and can outperform ALSO-X under regular chance constrained programs and type $$\infty $$ -Wasserstein ambiguity set. We also provide new sufficient conditions under which ALSO-X# outputs an optimal solution to a DRCCP. We apply ALSO-X# to a wireless communication problem and numerically demonstrate that the solution quality can be even better than the exact method.},
  archive      = {J_MP},
  author       = {Jiang, Nan and Xie, Weijun},
  doi          = {10.1007/s10107-024-02150-8},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {575-638},
  shortjournal = {Math. Program.},
  title        = {ALSO-x#: Better convex approximations for distributionally robust chance constrained programs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of trigonometric polynomials with crystallographic symmetry and spectral bounds for set avoiding graphs. <em>MP</em>, <em>213</em>(1), 517-573. (<a href='https://doi.org/10.1007/s10107-024-02149-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a new approach to the optimization of trigonometric polynomials with crystallographic symmetry. This approach widens the bridge between trigonometric and polynomial optimization. The trigonometric polynomials considered are supported on weight lattices associated to crystallographic root systems and are assumed invariant under the associated reflection group. On one hand the invariance allows us to rewrite the objective function in terms of generalized Chebyshev polynomials of the generalized cosines; On the other hand the generalized cosines parameterize a compact basic semi algebraic set, this latter being given by an explicit polynomial matrix inequality. The initial problem thus boils down to a polynomial optimization problem that is straightforwardly written in terms of generalized Chebyshev polynomials. The minimum is to be computed by a converging sequence of lower bounds as given by a hierarchy of relaxations based on the Hol–Scherer Positivstellensatz and indexed by the weighted degree associated to the root system. This new method for trigonometric optimization was motivated by its application to estimate the spectral bound on the chromatic number of set avoiding graphs. We examine cases of the literature where the avoided set affords crystallographic symmetry. In some cases we obtain new analytic proofs for sharp bounds on the chromatic number while in others we compute new lower bounds numerically.},
  archive      = {J_MP},
  author       = {Hubert, Evelyne and Metzlaff, Tobias and Moustrou, Philippe and Riener, Cordian},
  doi          = {10.1007/s10107-024-02149-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {517-573},
  shortjournal = {Math. Program.},
  title        = {Optimization of trigonometric polynomials with crystallographic symmetry and spectral bounds for set avoiding graphs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dyadic linear programming and extensions. <em>MP</em>, <em>213</em>(1), 473-516. (<a href='https://doi.org/10.1007/s10107-024-02146-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rational number is dyadic if it has a finite binary representation $$p/2^k$$ , where p is an integer and k is a nonnegative integer. Dyadic rationals are important for numerical computations because they have an exact representation in floating-point arithmetic on a computer. A vector is dyadic if all its entries are dyadic rationals. We study the problem of finding a dyadic optimal solution to a linear program, if one exists. We show how to solve dyadic linear programs in polynomial time. We give bounds on the size of the support of a solution as well as on the size of the denominators. We identify properties that make the solution of dyadic linear programs possible: closure under addition and negation, and density, and we extend the algorithmic framework beyond the dyadic case.},
  archive      = {J_MP},
  author       = {Abdi, Ahmad and Cornuéjols, Gérard and Guenin, Bertrand and Tunçel, Levent},
  doi          = {10.1007/s10107-024-02146-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {473-516},
  shortjournal = {Math. Program.},
  title        = {Dyadic linear programming and extensions},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive proximal algorithms for convex optimization under local lipschitz continuity of the gradient. <em>MP</em>, <em>213</em>(1), 433-471. (<a href='https://doi.org/10.1007/s10107-024-02143-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backtracking linesearch is the de facto approach for minimizing continuously differentiable functions with locally Lipschitz gradient. In recent years, it has been shown that in the convex setting it is possible to avoid linesearch altogether, and to allow the stepsize to adapt based on a local smoothness estimate without any backtracks or evaluations of the function value. In this work we propose an adaptive proximal gradient method, adaPGM, that uses novel estimates of the local smoothness modulus which leads to less conservative stepsize updates and that can additionally cope with nonsmooth terms. This idea is extended to the primal-dual setting where an adaptive three-term primal-dual algorithm, adaPDM, is proposed which can be viewed as an extension of the PDHG method. Moreover, in this setting the “essentially” fully adaptive variant $$\textsf {adaPDM}^{\textsf {+}}$$ is proposed that avoids evaluating the linear operator norm by invoking a backtracking procedure, that, remarkably, does not require extra gradient evaluations. Numerical simulations demonstrate the effectiveness of the proposed algorithms compared to the state of the art.},
  archive      = {J_MP},
  author       = {Latafat, Puya and Themelis, Andreas and Stella, Lorenzo and Patrinos, Panagiotis},
  doi          = {10.1007/s10107-024-02143-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {433-471},
  shortjournal = {Math. Program.},
  title        = {Adaptive proximal algorithms for convex optimization under local lipschitz continuity of the gradient},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coderivative-based semi-newton method in nonsmooth difference programming. <em>MP</em>, <em>213</em>(1), 385-432. (<a href='https://doi.org/10.1007/s10107-024-02142-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the study of a new class of nonsmooth optimization problems, where the objective is represented as a difference of two generally nonconvex functions. We propose and develop a novel Newton-type algorithm to solving such problems, which is based on the coderivative generated second-order subdifferential (generalized Hessian) and employs advanced tools of variational analysis. Well-posedness properties of the proposed algorithm are derived under fairly general requirements, while constructive convergence rates are established by using additional assumptions including the Kurdyka–Łojasiewicz condition. We provide applications of the main algorithm to solving a general class of nonsmooth nonconvex problems of structured optimization that encompasses, in particular, optimization problems with explicit constraints. Finally, applications and numerical experiments are given for solving practical problems that arise in biochemical models, supervised learning, constrained quadratic programming, etc., where advantages of our algorithms are demonstrated in comparison with some known techniques and results.},
  archive      = {J_MP},
  author       = {Aragón-Artacho, Francisco J. and Mordukhovich, Boris S. and Pérez-Aros, Pedro},
  doi          = {10.1007/s10107-024-02142-8},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {385-432},
  shortjournal = {Math. Program.},
  title        = {Coderivative-based semi-newton method in nonsmooth difference programming},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast convergence of trust-regions for non-isolated minima via analysis of CG on indefinite matrices. <em>MP</em>, <em>213</em>(1), 343-384. (<a href='https://doi.org/10.1007/s10107-024-02140-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-region methods (TR) can converge quadratically to minima where the Hessian is positive definite. However, if the minima are not isolated, then the Hessian there cannot be positive definite. The weaker Polyak–Łojasiewicz (PŁ) condition is compatible with non-isolated minima, and it is enough for many algorithms to preserve good local behavior. Yet, TR with an exact subproblem solver lacks even basic features such as a capture theorem under PŁ. In practice, a popular inexact subproblem solver is the truncated conjugate gradient method (tCG). Empirically, TR-tCG exhibits superlinear convergence under PŁ. We confirm this theoretically. The main mathematical obstacle is that, under PŁ, at points arbitrarily close to minima, the Hessian has vanishingly small, possibly negative eigenvalues. Thus, tCG is applied to ill-conditioned, indefinite systems. Yet, the core theory underlying tCG is that of CG, which assumes a positive definite operator. Accordingly, we develop new tools to analyze the dynamics of CG in the presence of small eigenvalues of any sign, for the regime of interest to TR-tCG.},
  archive      = {J_MP},
  author       = {Rebjock, Quentin and Boumal, Nicolas},
  doi          = {10.1007/s10107-024-02140-w},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {343-384},
  shortjournal = {Math. Program.},
  title        = {Fast convergence of trust-regions for non-isolated minima via analysis of CG on indefinite matrices},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The computational complexity of finding stationary points in non-convex optimization. <em>MP</em>, <em>213</em>(1), 281-341. (<a href='https://doi.org/10.1007/s10107-024-02139-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions f over unrestricted d-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension d of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:},
  archive      = {J_MP},
  author       = {Hollender, Alexandros and Zampetakis, Manolis},
  doi          = {10.1007/s10107-024-02139-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {281-341},
  shortjournal = {Math. Program.},
  title        = {The computational complexity of finding stationary points in non-convex optimization},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated stochastic approximation with state-dependent noise. <em>MP</em>, <em>213</em>(1), 239-280. (<a href='https://doi.org/10.1007/s10107-024-02138-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the “sub-optimality” of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size. We discuss two non-Euclidean accelerated stochastic approximation routines—stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)—which carry a particular duality relationship. We show that both SAGD and SGE, under appropriate conditions, achieve the optimal convergence rate, attaining the optimal iteration and sample complexities simultaneously. However, corresponding assumptions for the SGE algorithm are more general; they allow, for instance, for efficient application of the SGE to statistical estimation problems under heavy tail noises and discontinuous score functions. We also discuss the application of the SGE to problems satisfying quadratic growth conditions, and show how it can be used to recover sparse solutions. Finally, we report on some simulation experiments to illustrate numerical performance of our proposed algorithms in high-dimensional settings.},
  archive      = {J_MP},
  author       = {Ilandarideva, Sasila and Juditsky, Anatoli and Lan, Guanghui and Li, Tianjiao},
  doi          = {10.1007/s10107-024-02138-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {239-280},
  shortjournal = {Math. Program.},
  title        = {Accelerated stochastic approximation with state-dependent noise},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity of chordal conversion for sparse semidefinite programs with small treewidth. <em>MP</em>, <em>213</em>(1), 201-237. (<a href='https://doi.org/10.1007/s10107-024-02137-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If a sparse semidefinite program (SDP), specified over $$n\times n$$ matrices and subject to m linear constraints, has an aggregate sparsity graph G with small treewidth, then chordal conversion will sometimes allow an interior-point method to solve the SDP in just $$O(m+n)$$ time per-iteration, which is a significant speedup over the $$\varOmega (n^{3})$$ time per-iteration for a direct application of the interior-point method. Unfortunately, the speedup is not guaranteed by an O(1) treewidth in G that is independent of m and n, as a diagonal SDP would have treewidth zero but can still necessitate up to $$\varOmega (n^{3})$$ time per-iteration. Instead, we construct an extended aggregate sparsity graph $$\overline{G}\supseteq G$$ by forcing each constraint matrix $$A_{i}$$ to be its own clique in G. We prove that a small treewidth in $$\overline{G}$$ does indeed guarantee that chordal conversion will solve the SDP in $$O(m+n)$$ time per-iteration, to $$\epsilon $$ -accuracy in at most $$O(\sqrt{m+n}\log (1/\epsilon ))$$ iterations. This sufficient condition covers many successful applications of chordal conversion, including the MAX-k-CUT relaxation, the Lovász theta problem, sensor network localization, polynomial optimization, and the AC optimal power flow relaxation, thus allowing theory to match practical experience.},
  archive      = {J_MP},
  author       = {Zhang, Richard Y.},
  doi          = {10.1007/s10107-024-02137-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {201-237},
  shortjournal = {Math. Program.},
  title        = {Complexity of chordal conversion for sparse semidefinite programs with small treewidth},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast convergence to non-isolated minima: Four equivalent conditions for $${\textrm{C}^{2}}$$ functions. <em>MP</em>, <em>213</em>(1), 151-199. (<a href='https://doi.org/10.1007/s10107-024-02136-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization algorithms can see their local convergence rates deteriorate when the Hessian at the optimum is singular. These singularities are inescapable when the optima are non-isolated. Yet, under the right circumstances, several algorithms preserve their favorable rates even when optima form a continuum (e.g., due to over-parameterization). This has been explained under various structural assumptions, including the Polyak–Łojasiewicz condition, Quadratic Growth and the Error Bound. We show that, for cost functions which are twice continuously differentiable ( $$\textrm{C}^2$$ ), those three (local) properties are equivalent. Moreover, we show they are equivalent to the Morse–Bott property, that is, local minima form differentiable submanifolds, and the Hessian of the cost function is positive definite along its normal directions. We leverage this insight to improve local convergence guarantees for safe-guarded Newton-type methods under any (hence all) of the above assumptions. First, for adaptive cubic regularization, we secure quadratic convergence even with inexact subproblem solvers. Second, for trust-region methods, we argue capture can fail with an exact subproblem solver, then proceed to show linear convergence with an inexact one (Cauchy steps).},
  archive      = {J_MP},
  author       = {Rebjock, Quentin and Boumal, Nicolas},
  doi          = {10.1007/s10107-024-02136-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {151-199},
  shortjournal = {Math. Program.},
  title        = {Fast convergence to non-isolated minima: Four equivalent conditions for $${\textrm{C}^{2}}$$ functions},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convexification techniques for fractional programs. <em>MP</em>, <em>213</em>(1), 107-149. (<a href='https://doi.org/10.1007/s10107-024-02131-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a correspondence relating convex hulls of fractional functions with those of polynomial functions over the same domain. Using this result, we develop a number of new reformulations and relaxations for fractional programming problems. First, we relate $$0\mathord {-}1$$ problems involving a ratio of affine functions with the boolean quadric polytope, and use inequalities for the latter to develop tighter formulations for the former. Second, we derive a new formulation to optimize a ratio of quadratic functions over a polytope using copositive programming. Third, we show that univariate fractional functions can be convexified using moment hulls. Fourth, we develop a new hierarchy of relaxations that converges finitely to the simultaneous convex hull of a collection of ratios of affine functions of $$0\mathord {-}1$$ variables. Finally, we demonstrate theoretically and computationally that our techniques close a significant gap relative to state-of-the-art relaxations, require much less computational effort, and can solve larger problem instances.},
  archive      = {J_MP},
  author       = {He, Taotao and Liu, Siyue and Tawarmalani, Mohit},
  doi          = {10.1007/s10107-024-02131-x},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {107-149},
  shortjournal = {Math. Program.},
  title        = {Convexification techniques for fractional programs},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing distortion riskmetrics with distributional uncertainty. <em>MP</em>, <em>213</em>(1), 51-106. (<a href='https://doi.org/10.1007/s10107-024-02128-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of distortion riskmetrics with distributional uncertainty has wide applications in finance and operations research. Distortion riskmetrics include many commonly applied risk measures and deviation measures, which are not necessarily monotone or convex. One of our central findings is a unifying result that allows to convert an optimization of a non-convex distortion riskmetric with distributional uncertainty to a convex one induced from the concave envelope of the distortion function, leading to practical tractability. A sufficient condition to the unifying equivalence result is the novel notion of closedness under concentration, a variation of which is also shown to be necessary for the equivalence. Our results include many special cases that are well studied in the optimization literature, including but not limited to optimizing probabilities, Value-at-Risk, Expected Shortfall, Yaari’s dual utility, and differences between distortion risk measures, under various forms of distributional uncertainty. We illustrate our theoretical results via applications to portfolio optimization, optimization under moment constraints, and preference robust optimization.},
  archive      = {J_MP},
  author       = {Pesenti, Silvana M. and Wang, Qiuqi and Wang, Ruodu},
  doi          = {10.1007/s10107-024-02128-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {51-106},
  shortjournal = {Math. Program.},
  title        = {Optimizing distortion riskmetrics with distributional uncertainty},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear conjugate gradient methods: Worst-case convergence rates via computer-assisted analyses. <em>MP</em>, <em>213</em>(1), 1-49. (<a href='https://doi.org/10.1007/s10107-024-02127-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a computer-assisted approach to the analysis of the worst-case convergence of nonlinear conjugate gradient methods (NCGMs). Those methods are known for their generally good empirical performances for large-scale optimization, while having relatively incomplete analyses. Using our computer-assisted approach, we establish novel complexity bounds for the Polak-Ribière-Polyak (PRP) and the Fletcher-Reeves (FR) NCGMs for smooth strongly convex minimization. In particular, we construct mathematical proofs that establish the first non-asymptotic convergence bound for FR (which is historically the first developed NCGM), and a much improved non-asymptotic convergence bound for PRP. Additionally, we provide simple adversarial examples on which these methods do not perform better than gradient descent with exact line search, leaving very little room for improvements on the same class of problems.},
  archive      = {J_MP},
  author       = {Das Gupta, Shuvomoy and Freund, Robert M. and Sun, Xu Andy and Taylor, Adrien},
  doi          = {10.1007/s10107-024-02127-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1-49},
  shortjournal = {Math. Program.},
  title        = {Nonlinear conjugate gradient methods: Worst-case convergence rates via computer-assisted analyses},
  volume       = {213},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence in distribution of randomized algorithms: The case of partially separable optimization. <em>MP</em>, <em>212</em>(1), 763-798. (<a href='https://doi.org/10.1007/s10107-024-02124-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Markov-chain analysis of blockwise-stochastic algorithms for solving partially block-separable optimization problems. Our main contributions to the extensive literature on these methods are statements about the Markov operators and distributions behind the iterates of stochastic algorithms, and in particular the regularity of Markov operators and rates of convergence of the distributions of the corresponding Markov chains. This provides a detailed characterization of the moments of the sequences beyond just the expected behavior. This also serves as a case study of how randomization restores favorable properties to algorithms that iterations of only partial information destroys. We demonstrate this on stochastic blockwise implementations of the forward–backward and Douglas–Rachford algorithms for nonconvex (and, as a special case, convex), nonsmooth optimization.},
  archive      = {J_MP},
  author       = {Luke, D. Russell},
  doi          = {10.1007/s10107-024-02124-w},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {763-798},
  shortjournal = {Math. Program.},
  title        = {Convergence in distribution of randomized algorithms: The case of partially separable optimization},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The pseudo-boolean polytope and polynomial-size extended formulations for binary polynomial optimization. <em>MP</em>, <em>212</em>(1), 717-761. (<a href='https://doi.org/10.1007/s10107-024-02122-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the goal of obtaining strong relaxations for binary polynomial optimization problems, we introduce the pseudo-Boolean polytope defined as the set of binary points $$z \in \{0,1\}^{V \cup S}$$ satisfying a collection of equalities of the form $$z_s = \prod _{v \in s} \sigma _s(z_v)$$ , for all $$s \in S$$ , where $$\sigma _s(z_v) \in \{z_v, 1-z_v\}$$ , and where S is a multiset of subsets of V. By representing the pseudo-Boolean polytope via a signed hypergraph, we obtain sufficient conditions under which this polytope has a polynomial-size extended formulation. Our new framework unifies and extends all prior results on the existence of polynomial-size extended formulations for the convex hull of the feasible region of binary polynomial optimization problems of degree at least three.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Khajavirad, Aida},
  doi          = {10.1007/s10107-024-02122-y},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {717-761},
  shortjournal = {Math. Program.},
  title        = {The pseudo-boolean polytope and polynomial-size extended formulations for binary polynomial optimization},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the strength of lagrangian duality in multiobjective integer programming. <em>MP</em>, <em>212</em>(1), 683-715. (<a href='https://doi.org/10.1007/s10107-024-02121-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the potential of Lagrangian relaxations to generate quality bounds on non-dominated images of multiobjective integer programs (MOIPs). Under some conditions on the relaxed constraints, we show that a set of Lagrangian relaxations can provide bounds that coincide with every bound generated by the convex hull relaxation. We also provide a guarantee of the relative quality of the Lagrangian bound at unsupported solutions. These results imply that, if the relaxed feasible region is bounded, some Lagrangian bounds will be strictly better than some convex hull bounds. We demonstrate that there exist Lagrangian multipliers which are sparse, satisfy a complementary slackness property, and generate tight relaxations at supported solutions. However, if all constraints are dualized, a relaxation can never be tight at an unsupported solution. These results characterize the strength of the Lagrangian dual at efficient solutions of an MOIP.},
  archive      = {J_MP},
  author       = {Brun, Matthew and Perini, Tyler and Sinha, Saumya and Schaefer, Andrew J.},
  doi          = {10.1007/s10107-024-02121-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {683-715},
  shortjournal = {Math. Program.},
  title        = {On the strength of lagrangian duality in multiobjective integer programming},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New notions of simultaneous diagonalizability of quadratic forms with applications to QCQPs. <em>MP</em>, <em>212</em>(1), 635-682. (<a href='https://doi.org/10.1007/s10107-024-02120-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set of quadratic forms is simultaneously diagonalizable via congruence (SDC) if there exists a basis under which each of the quadratic forms is diagonal. This property appears naturally when analyzing quadratically constrained quadratic programs (QCQPs) and has important implications in globally solving such problems using branch-and-bound methods. This paper extends the reach of the SDC property by studying two new weaker notions of simultaneous diagonalizability. Specifically, we say that a set of quadratic forms is almost SDC (ASDC) if it is the limit of SDC sets and d-restricted SDC (d-RSDC) if it is the restriction of an SDC set in up to d-many additional dimensions. In the context of QCQPs, these properties correspond to problems that may be diagonalized after arbitrarily small perturbations or after the introduction of d additional variables. Our main contributions are complete characterizations of the ASDC pairs and nonsingular triples of symmetric matrices, as well as a sufficient condition for the 1-RSDC property for pairs of symmetric matrices. Surprisingly, we show that every singular symmetric pair is ASDC and that almost every symmetric pair is 1-RSDC. We accompany our theoretical results with preliminary numerical experiments applying these constructions to solve QCQPs within branch-and-bound schemes.},
  archive      = {J_MP},
  author       = {Wang, Alex L. and Jiang, Rujun},
  doi          = {10.1007/s10107-024-02120-0},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {635-682},
  shortjournal = {Math. Program.},
  title        = {New notions of simultaneous diagonalizability of quadratic forms with applications to QCQPs},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural iterative rounding for generalized k-median problems. <em>MP</em>, <em>212</em>(1), 581-634. (<a href='https://doi.org/10.1007/s10107-024-02119-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers approximation algorithms for generalized k-median problems. These problems can be informally described as k-median with a constant number of extra constraints, and includes k-median with outliers, and knapsack median. Our first contribution is a pseudo-approximation algorithm for generalized k-median that outputs a 6.387-approximate solution, with a constant number of fractional variables. The algorithm builds on the iterative rounding framework introduced by Krishnaswamy, Li, and Sandeep for k-median with outliers as reported (Krishnaswamy et al. in: Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, 2018). The main technical innovation is allowing richer constraint sets in the iterative rounding and using the structure of the resulting extreme points. Using our pseudo-approximation algorithm, we give improved approximation algorithms for k-median with outliers and knapsack median. This involves combining our pseudo-approximation with pre- and post-processing steps to round a constant number of fractional variables at a small increase in cost. Our algorithms achieve approximation ratios $$6.994 + \epsilon $$ and $$6.387 + \epsilon $$ for k-median with outliers and knapsack median, respectively. These improve on the best-known approximation ratio $$7.081 + \epsilon $$ for both problems as reported (Krishnaswamy et al. in: Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, 2018).},
  archive      = {J_MP},
  author       = {Gupta, Anupam and Moseley, Benjamin and Zhou, Rudy},
  doi          = {10.1007/s10107-024-02119-7},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {581-634},
  shortjournal = {Math. Program.},
  title        = {Structural iterative rounding for generalized k-median problems},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix discrepancy and the log-rank conjecture. <em>MP</em>, <em>212</em>(1), 567-579. (<a href='https://doi.org/10.1007/s10107-024-02117-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an $$m\times n$$ binary matrix M with $$|M|=p\cdot mn$$ (where |M| denotes the number of 1 entries), define the discrepancy of M as $${{\,\textrm{disc}\,}}(M)=\displaystyle \max \nolimits _{X\subset [m], Y\subset [n]}\big ||M[X\times Y]|-p|X|\cdot |Y|\big |$$ . Using semidefinite programming and spectral techniques, we prove that if $${{\,\textrm{rank}\,}}(M)\le r$$ and $$p\le 1/2$$ , then $$\begin{aligned}{{\,\textrm{disc}\,}}(M)\ge \Omega (mn)\cdot \min \left\{ p,\frac{p^{1/2}}{\sqrt{r}}\right\} .\end{aligned}$$ We use this result to obtain a modest improvement of Lovett’s best known upper bound on the log-rank conjecture. We prove that any $$m\times n$$ binary matrix M of rank at most r contains an $$(m\cdot 2^{-O(\sqrt{r})})\times (n\cdot 2^{-O(\sqrt{r})})$$ sized all-1 or all-0 submatrix, which implies that the deterministic communication complexity of any Boolean function of rank r is at most $$O(\sqrt{r})$$ .},
  archive      = {J_MP},
  author       = {Sudakov, Benny and Tomon, István},
  doi          = {10.1007/s10107-024-02117-9},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {567-579},
  shortjournal = {Math. Program.},
  title        = {Matrix discrepancy and the log-rank conjecture},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributional utility preference robust optimization models in multi-attribute decision making. <em>MP</em>, <em>212</em>(1), 519-565. (<a href='https://doi.org/10.1007/s10107-024-02114-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility preference robust optimization (PRO) has recently been proposed to deal with optimal decision-making problems where the decision maker’s (DM’s) preference over gains and losses is ambiguous. In this paper, we take a step further to investigate the case that the DM’s preference is random. We propose to use a random utility function to describe the DM’s preference and develop distributional utility preference robust optimization (DUPRO) models when the distribution of the random utility function is ambiguous. We concentrate on data-driven problems where samples of the random parameters are obtainable but the sample size may be relatively small. In the case when the random utility functions are of piecewise linear structure, we propose a bootstrap method to construct the ambiguity set and demonstrate how the resulting DUPRO can be solved by a mixed-integer linear program. The piecewise linear structure is versatile in its ability to incorporate classical non-parametric utility assessment methods into the sample generation of a random utility function. Next, we expand the proposed DUPRO models and computational schemes to address general cases where the random utility functions are not necessarily piecewise linear. We show how the DUPRO models with piecewise linear random utility functions can serve as approximations for the DUPRO models with general random utility functions and allow us to quantify the approximation errors. Finally, we carry out some performance studies of the proposed bootstrap-based DUPRO model and report the preliminary numerical test results. This paper is the first attempt to use distributionally robust optimization methods for PRO problems.},
  archive      = {J_MP},
  author       = {Hu, Jian and Zhang, Dali and Xu, Huifu and Zhang, Sainan},
  doi          = {10.1007/s10107-024-02114-y},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {519-565},
  shortjournal = {Math. Program.},
  title        = {Distributional utility preference robust optimization models in multi-attribute decision making},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified smoothing approach for best hyperparameter selection problem using a bilevel optimization strategy. <em>MP</em>, <em>212</em>(1), 479-518. (<a href='https://doi.org/10.1007/s10107-024-02113-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strongly motivated from applications in various fields including machine learning, the methodology of sparse optimization has been developed intensively so far. Especially, the advancement of algorithms for solving problems with nonsmooth regularizers has been remarkable. However, those algorithms suppose that weight parameters of regularizers, called hyperparameters hereafter, are pre-fixed, but it is a crucial matter how the best hyperparameter should be selected. In this paper, we focus on the hyperparameter selection of regularizers related to the $$\ell _p$$ function with $$0<p\le 1$$ and apply a bilevel programming strategy, wherein we need to solve a bilevel problem, whose lower-level problem is nonsmooth, possibly nonconvex and non-Lipschitz. Recently, for solving a bilevel problem for hyperparameter selection of the pure $$\ell _p\ (0<p \le 1)$$ regularizer Okuno et al. discovered new necessary optimality conditions, called SB(scaled bilevel)-KKT conditions, and further proposed a smoothing-type algorithm using a specific smoothing function. However, this optimality measure is loose in the sense that there could be many points that satisfy the SB-KKT conditions. In this work, we propose new bilevel KKT conditions, which are new necessary optimality conditions tighter than the ones proposed by Okuno et al. Moreover, we propose a unified smoothing approach using smoothing functions that belong to the Chen-Mangasarian class, and then prove that generated iteration points accumulate at bilevel KKT points under milder constraint qualifications. Another contribution is that our approach and analysis are applicable to a wider class of regularizers. Numerical comparisons demonstrate which smoothing functions work well for hyperparameter optimization via bilevel optimization approach.},
  archive      = {J_MP},
  author       = {Alcantara, Jan Harold and Nguyen, Chieu Thanh and Okuno, Takayuki and Takeda, Akiko and Chen, Jein-Shan},
  doi          = {10.1007/s10107-024-02113-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {479-518},
  shortjournal = {Math. Program.},
  title        = {Unified smoothing approach for best hyperparameter selection problem using a bilevel optimization strategy},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On supervalid inequalities for binary interdiction games. <em>MP</em>, <em>212</em>(1), 437-478. (<a href='https://doi.org/10.1007/s10107-024-02111-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervalid inequalities are a specific type of constraints often used within the branch-and-cut framework to strengthen the linear relaxation of mixed-integer programs. These inequalities share the particular characteristic of potentially removing feasible integer solutions as long as they are already dominated by an incumbent solution. This paper focuses on supervalid inequalities for solving binary interdiction games. Specifically, we provide a general characterization of inequalities that are derived from bipartitions of the leader’s strategy set and develop an algorithmic approach to use them. This includes the design of two verification subroutines that we apply for separation purposes. We provide three general examples in which we apply our results to solve binary interdiction games targeting shortest paths, spanning trees, and vertex covers. Finally, we prove that the separation procedure is efficient for the class of interdiction games defined on greedoids—a type of set system that generalizes many others such as matroids and antimatroids.},
  archive      = {J_MP},
  author       = {Wei, Ningji and Walteros, Jose L.},
  doi          = {10.1007/s10107-024-02111-1},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {437-478},
  shortjournal = {Math. Program.},
  title        = {On supervalid inequalities for binary interdiction games},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A trust region-type normal map-based semismooth newton method for nonsmooth nonconvex composite optimization. <em>MP</em>, <em>212</em>(1), 389-435. (<a href='https://doi.org/10.1007/s10107-024-02110-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel trust region method for solving a class of nonsmooth, nonconvex composite-type optimization problems. The approach embeds inexact semismooth Newton steps for finding zeros of a normal map-based stationarity measure for the problem in a trust region framework. Based on a new merit function and acceptance mechanism, global convergence and transition to fast local q-superlinear convergence are established under standard conditions. In addition, we verify that the proposed trust region globalization is compatible with the Kurdyka–Łojasiewicz inequality yielding finer convergence results. Experiments on sparse logistic regression, image compression, and a constrained log-determinant problem illustrate the efficiency of the proposed algorithm.},
  archive      = {J_MP},
  author       = {Ouyang, Wenqing and Milzarek, Andre},
  doi          = {10.1007/s10107-024-02110-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {389-435},
  shortjournal = {Math. Program.},
  title        = {A trust region-type normal map-based semismooth newton method for nonsmooth nonconvex composite optimization},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the geometry and refined rate of primal–dual hybrid gradient for linear programming. <em>MP</em>, <em>212</em>(1), 349-387. (<a href='https://doi.org/10.1007/s10107-024-02109-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence behaviors of primal–dual hybrid gradient (PDHG) for solving linear programming (LP). PDHG is the base algorithm of a new general-purpose first-order method LP solver, PDLP, which aims to scale up LP by taking advantage of modern computing architectures. Despite its numerical success, the theoretical understanding of PDHG for LP is still very limited; the previous complexity result relies on the global Hoffman constant of the KKT system, which is known to be very loose and uninformative. In this work, we aim to develop a fundamental understanding of the convergence behaviors of PDHG for LP and to develop a refined complexity rate that does not rely on the global Hoffman constant. We show that there are two major stages of PDHG for LP: in Stage I, PDHG identifies active variables and the length of the first stage is driven by a certain quantity which measures how close the non-degeneracy part of the LP instance is to degeneracy; in Stage II, PDHG effectively solves a homogeneous linear inequality system, and the complexity of the second stage is driven by a well-behaved local sharpness constant of the system. This finding is closely related to the concept of partial smoothness in non-smooth optimization, and it is the first complexity result of finite time identification without the non-degeneracy assumption. An interesting implication of our results is that degeneracy itself does not slow down the convergence of PDHG for LP, but near-degeneracy does.},
  archive      = {J_MP},
  author       = {Lu, Haihao and Yang, Jinwen},
  doi          = {10.1007/s10107-024-02109-9},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {349-387},
  shortjournal = {Math. Program.},
  title        = {On the geometry and refined rate of primal–dual hybrid gradient for linear programming},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A slope generalization of attouch theorem. <em>MP</em>, <em>212</em>(1), 319-348. (<a href='https://doi.org/10.1007/s10107-024-02108-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classical result of variational analysis, known as Attouch theorem, establishes an equivalence between epigraphical convergence of a sequence of proper convex lower semicontinuous functions and graphical convergence of the corresponding subdifferential maps up to a normalization condition which fixes the integration constant. In this work, we show that in finite dimensions and under a mild boundedness assumption, we can replace subdifferentials (sets of vectors) by slopes (scalars, corresponding to the distance of the subdifferentials to zero) and still obtain the same characterization: namely, the epigraphical convergence of functions is equivalent to the epigraphical convergence of their slopes. This surprising result goes in line with recent developments on slope determination (Boulmezaoud et al. in SIAM J Optim 28(3):2049–2066, 2018; Pérez-Aros et al. in Math Program 190(1–2):561-583, 2021) and slope sensitivity (Daniilidis and Drusvyatskiy in Proc Am Math Soc 151(11):4751-4756, 2023) for convex functions.},
  archive      = {J_MP},
  author       = {Daniilidis, Aris and Salas, David and Tapia-García, Sebastián},
  doi          = {10.1007/s10107-024-02108-w},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {319-348},
  shortjournal = {Math. Program.},
  title        = {A slope generalization of attouch theorem},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On solving a rank regularized minimization problem via equivalent factorized column-sparse regularized models. <em>MP</em>, <em>212</em>(1), 273-318. (<a href='https://doi.org/10.1007/s10107-024-02103-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank regularized minimization problem is an ideal model for the low-rank matrix completion/recovery problem. The matrix factorization approach can transform the high-dimensional rank regularized problem to a low-dimensional factorized column-sparse regularized problem. The latter can greatly facilitate fast computations in applicable algorithms, but needs to overcome the simultaneous non-convexity of the loss and regularization functions. In this paper, we consider the factorized column-sparse regularized model. Firstly, we optimize this model with bound constraints, and establish a certain equivalence between the optimized factorization problem and rank regularized problem. Further, we strengthen the optimality condition for stationary points of the factorization problem and define the notion of strong stationary point. Moreover, we establish the equivalence between the factorization problem and its nonconvex relaxation in the sense of global minimizers and strong stationary points. To solve the factorization problem, we design two types of algorithms and give an adaptive method to reduce their computation. The first algorithm is from the relaxation point of view and its iterates own some properties from global minimizers of the factorization problem after finite iterations. We give some analysis on the convergence of its iterates to a strong stationary point. The second algorithm is designed for directly solving the factorization problem. We improve the PALM algorithm introduced by Bolte et al. (Math Program Ser A 146:459–494, 2014) for the factorization problem and give its improved convergence results. Finally, we conduct numerical experiments to show the promising performance of the proposed model and algorithms for low-rank matrix completion.},
  archive      = {J_MP},
  author       = {Li, Wenjing and Bian, Wei and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-024-02103-1},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {273-318},
  shortjournal = {Math. Program.},
  title        = {On solving a rank regularized minimization problem via equivalent factorized column-sparse regularized models},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for symmetry handling. <em>MP</em>, <em>212</em>(1), 217-271. (<a href='https://doi.org/10.1007/s10107-024-02102-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling symmetries in optimization problems is essential for devising efficient solution methods. In this article, we present a general framework that captures many of the already existing symmetry handling methods. While these methods are mostly discussed independently from each other, our framework allows to apply different methods simultaneously and thus outperforming their individual effect. Moreover, most existing symmetry handling methods only apply to binary variables. Our framework allows to easily generalize these methods to general variable types. Numerical experiments confirm that our novel framework is superior to the state-of-the-art symmetry handling methods as implemented in the solver SCIP on a broad set of instances.},
  archive      = {J_MP},
  author       = {van Doornmalen, Jasper and Hojny, Christopher},
  doi          = {10.1007/s10107-024-02102-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {217-271},
  shortjournal = {Math. Program.},
  title        = {A unified framework for symmetry handling},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized scaling for the constrained maximum-entropy sampling problem. <em>MP</em>, <em>212</em>(1), 177-216. (<a href='https://doi.org/10.1007/s10107-024-02101-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The best practical techniques for exact solution of instances of the constrained maximum-entropy sampling problem, a discrete-optimization problem arising in the design of experiments, are via a branch-and-bound framework, working with a variety of concave continuous relaxations of the objective function. A standard and computationally-important bound-enhancement technique in this context is (ordinary) scaling, via a single positive parameter. Scaling adjusts the shape of continuous relaxations to reduce the gaps between the upper bounds and the optimal value. We extend this technique to generalized scaling, employing a positive vector of parameters, which allows much more flexibility and thus potentially reduces the gaps further. We give mathematical results aimed at supporting algorithmic methods for computing optimal generalized scalings, and we give computational results demonstrating the performance of generalized scaling on benchmark problem instances.},
  archive      = {J_MP},
  author       = {Chen, Zhongzhu and Fampa, Marcia and Lee, Jon},
  doi          = {10.1007/s10107-024-02101-3},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {177-216},
  shortjournal = {Math. Program.},
  title        = {Generalized scaling for the constrained maximum-entropy sampling problem},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal heavy-ball method for nonconvex optimization under hölder continuous hessians. <em>MP</em>, <em>212</em>(1), 147-175. (<a href='https://doi.org/10.1007/s10107-024-02100-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new first-order method for minimizing nonconvex functions with Lipschitz continuous gradients and Hölder continuous Hessians. The proposed algorithm is a heavy-ball method equipped with two particular restart mechanisms. It finds a solution where the gradient norm is less than $$\varepsilon $$ in $$O(H_{\nu }^{\frac{1}{2 + 2 \nu }} \varepsilon ^{- \frac{4 + 3 \nu }{2 + 2 \nu }})$$ function and gradient evaluations, where $$\nu \in [0, 1]$$ and $$H_{\nu }$$ are the Hölder exponent and constant, respectively. This complexity result covers the classical bound of $$O(\varepsilon ^{-2})$$ for $$\nu = 0$$ and the state-of-the-art bound of $$O(\varepsilon ^{-7/4})$$ for $$\nu = 1$$ . Our algorithm is $$\nu $$ -independent and thus universal; it automatically achieves the above complexity bound with the optimal $$\nu \in [0, 1]$$ without knowledge of $$H_{\nu }$$ . In addition, the algorithm does not require other problem-dependent parameters as input, including the gradient’s Lipschitz constant or the target accuracy $$\varepsilon $$ . Numerical results illustrate that the proposed method is promising.},
  archive      = {J_MP},
  author       = {Marumo, Naoki and Takeda, Akiko},
  doi          = {10.1007/s10107-024-02100-4},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {147-175},
  shortjournal = {Math. Program.},
  title        = {Universal heavy-ball method for nonconvex optimization under hölder continuous hessians},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tight $$(1.5+\epsilon )$$ -approximation for unsplittable capacitated vehicle routing on trees. <em>MP</em>, <em>212</em>(1), 115-146. (<a href='https://doi.org/10.1007/s10107-024-02094-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the unsplittable capacitated vehicle routing problem (UCVRP) on trees, we are given a rooted tree with edge weights and a subset of vertices of the tree called terminals. Each terminal is associated with a positive demand between 0 and 1. The goal is to find a minimum length collection of tours starting and ending at the root of the tree such that the demand of each terminal is covered by a single tour (i.e., the demand cannot be split), and the total demand of the terminals in each tour does not exceed the capacity of 1. For the special case when all terminals have equal demands, a long line of research culminated in a quasi-polynomial time approximation scheme [Jayaprakash and Salavatipour, TALG 2023] and a polynomial time approximation scheme [Mathieu and Zhou, TALG 2023]. In this work, we study the general case when the terminals have arbitrary demands. Our main contribution is a polynomial time $$(1.5+\epsilon )$$ -approximation algorithm for the UCVRP on trees. This is the first improvement upon the 2-approximation algorithm more than 30 years ago. Our approximation ratio is essentially best possible, since it is NP-hard to approximate the UCVRP on trees to better than a 1.5 factor.},
  archive      = {J_MP},
  author       = {Mathieu, Claire and Zhou, Hang},
  doi          = {10.1007/s10107-024-02094-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {115-146},
  shortjournal = {Math. Program.},
  title        = {A tight $$(1.5+\epsilon )$$ -approximation for unsplittable capacitated vehicle routing on trees},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stable set polytopes with high lift-and-project ranks for the Lovász–Schrijver SDP operator. <em>MP</em>, <em>212</em>(1), 79-114. (<a href='https://doi.org/10.1007/s10107-024-02093-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the lift-and-project rank of the stable set polytopes of graphs with respect to the Lovász–Schrijver SDP operator $${{\,\textrm{LS}\,}}_+$$ . In particular, we focus on a search for relatively small graphs with high $${{\,\textrm{LS}\,}}_+$$ -rank (i.e., the least number of iterations of the $${{\,\textrm{LS}\,}}_+$$ operator on the fractional stable set polytope to compute the stable set polytope). We provide families of graphs whose $${{\,\textrm{LS}\,}}_+$$ -rank is asymptotically a linear function of its number of vertices, which is the best possible up to improvements in the constant factor. This improves upon the previous best result in this direction from 1999, which yielded graphs whose $${{\,\textrm{LS}\,}}_+$$ -rank only grew with the square root of the number of vertices.},
  archive      = {J_MP},
  author       = {Au, Yu Hin and Tunçel, Levent},
  doi          = {10.1007/s10107-024-02093-0},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {79-114},
  shortjournal = {Math. Program.},
  title        = {Stable set polytopes with high lift-and-project ranks for the Lovász–Schrijver SDP operator},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The complexity of first-order optimization methods from a metric perspective. <em>MP</em>, <em>212</em>(1), 49-78. (<a href='https://doi.org/10.1007/s10107-024-02091-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A central tool for understanding first-order optimization algorithms is the Kurdyka–Łojasiewicz inequality. Standard approaches to such methods rely crucially on this inequality to leverage sufficient decrease conditions involving gradients or subgradients. However, the KL property fundamentally concerns not subgradients but rather “slope”, a purely metric notion. By highlighting this view, and avoiding any use of subgradients, we present a simple and concise complexity analysis for first-order optimization algorithms on metric spaces. This subgradient-free perspective also frames a short and focused proof of the KL property for nonsmooth semi-algebraic functions.},
  archive      = {J_MP},
  author       = {Lewis, A. S. and Tian, Tonghua},
  doi          = {10.1007/s10107-024-02091-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {49-78},
  shortjournal = {Math. Program.},
  title        = {The complexity of first-order optimization methods from a metric perspective},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal methods for convex nested stochastic composite optimization. <em>MP</em>, <em>212</em>(1), 1-48. (<a href='https://doi.org/10.1007/s10107-024-02090-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convex nested stochastic composite optimization (NSCO) has received considerable interest for its applications in reinforcement learning and risk-averse optimization. However, existing NSCO algorithms have worse stochastic oracle complexities, by orders of magnitude, than those for simpler stochastic optimization problems without nested structures. Additionally, these algorithms require all outer-layer functions to be smooth, a condition violated by some important applications. This raises a question regarding whether the nested composition make stochastic optimization more difficult in terms of oracle complexity. In this paper, we answer the question by developing order-optimal algorithms for convex NSCO problems constructed from an arbitrary composition of smooth, structured non-smooth, and general non-smooth layer functions. When all outer-layer functions are smooth, we propose a stochastic sequential dual (SSD) method to achieve an oracle complexity of $$\mathcal {O}(1/\epsilon ^2)$$ (resp., $$\mathcal {O}(1/\epsilon )$$ ) when the problem is convex (resp., strongly convex). If any outer-layer function is non-smooth, we propose a non-smooth stochastic sequential dual (nSSD) method to achieve an $$\mathcal {O}(1/\epsilon ^2)$$ oracle complexity. We provide a lower complexity bound to show the latter $$\mathcal {O}(1/\epsilon ^2)$$ complexity to be unimprovable, even under a strongly convex setting. All these complexity results seem to be new in the literature, and they indicate that convex NSCO problems have the same order of oracle complexity as problems without nested composition, except in the strongly convex and outer non-smooth cases.},
  archive      = {J_MP},
  author       = {Zhang, Zhe and Lan, Guanghui},
  doi          = {10.1007/s10107-024-02090-3},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Math. Program.},
  title        = {Optimal methods for convex nested stochastic composite optimization},
  volume       = {212},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Submodular maximization and its generalization through an intersection cut lens. <em>MP</em>, <em>211</em>(1), 341-377. (<a href='https://doi.org/10.1007/s10107-024-02059-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a mixed-integer set $$\mathcal {S}:=\{(x,t) \in \{0,1\}^n \times \mathbb {R}: f(x) \ge t\}$$ arising in the submodular maximization problem, where f is a submodular function defined over $$\{0,1\}^n$$ . We use intersection cuts to tighten a polyhedral outer approximation of $$\mathcal {S}$$ . We construct a continuous extension $$\bar{\textsf{F}}_f$$ of f, which is convex and defined over the entire space $$\mathbb {R}^n$$ . We show that the epigraph $${{\,\textrm{epi}\,}}(\bar{\textsf{F}}_f)$$ of $$\bar{\textsf{F}}_f$$ is an $$\mathcal {S}$$ -free set, and characterize maximal $$\mathcal {S}$$ -free sets containing $${{\,\textrm{epi}\,}}(\bar{\textsf{F}}_f)$$ . We propose a hybrid discrete Newton algorithm to compute an intersection cut efficiently and exactly. Our results are generalized to the hypograph or the superlevel set of a submodular-supermodular function over the Boolean hypercube, which is a model for discrete nonconvexity. A consequence of these results is intersection cuts for Boolean multilinear constraints. We evaluate our techniques on max cut, pseudo Boolean maximization, and Bayesian D-optimal design problems within a MIP solver.},
  archive      = {J_MP},
  author       = {Xu, Liding and Liberti, Leo},
  doi          = {10.1007/s10107-024-02059-2},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {341-377},
  shortjournal = {Math. Program.},
  title        = {Submodular maximization and its generalization through an intersection cut lens},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaining or losing perspective for convex multivariate functions on box domains. <em>MP</em>, <em>211</em>(1), 319-339. (<a href='https://doi.org/10.1007/s10107-024-02087-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer nonlinear optimization formulations of the disjunction between the origin and a polytope via a binary indicator variable is broadly used in nonlinear combinatorial optimization for modeling a fixed cost associated with carrying out a group of activities and a convex cost function associated with the levels of the activities. The perspective relaxation of such models is often used to solve to global optimality in a branch-and-bound context, but it typically requires suitable conic solvers and is not compatible with general-purpose NLP software in the presence of other classes of constraints. This motivates the investigation of when simpler but weaker relaxations may be adequate. Comparing the volume (i.e., Lebesgue measure) of the relaxations as a measure of tightness, we lift some of the results related to the simplex case to the box case. In order to compare the volumes of different relaxations in the box case, it is necessary to find an appropriate concave upper bound that preserves the convexity and is minimal, which is more difficult than in the simplex case. To address the challenge beyond the simplex case, the triangulation approach is used.},
  archive      = {J_MP},
  author       = {Xu, Luze and Lee, Jon},
  doi          = {10.1007/s10107-024-02087-y},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {319-339},
  shortjournal = {Math. Program.},
  title        = {Gaining or losing perspective for convex multivariate functions on box domains},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsity penalized mean–variance portfolio selection: Analysis and computation. <em>MP</em>, <em>211</em>(1), 281-318. (<a href='https://doi.org/10.1007/s10107-024-02161-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of mean–variance portfolio selection regularized with an $$\ell _0$$ -penalty term to control the sparsity of the portfolio. We analyze the structure of local and global minimizers and use our results in the design of a Branch-and-Bound algorithm coupled with an advanced start heuristic. Extensive computational results with real data as well as comparisons with an off-the-shelf and state-of-the-art (MIQP) solver are reported.},
  archive      = {J_MP},
  author       = {Şen, Buse and Akkaya, Deniz and Pınar, Mustafa Ç.},
  doi          = {10.1007/s10107-024-02161-5},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {281-318},
  shortjournal = {Math. Program.},
  title        = {Sparsity penalized mean–variance portfolio selection: Analysis and computation},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global optimization for cardinality-constrained minimum sum-of-squares clustering via semidefinite programming. <em>MP</em>, <em>211</em>(1), 245-279. (<a href='https://doi.org/10.1007/s10107-023-02021-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has been recently extended to exploit prior knowledge on the cardinality of each cluster. Such knowledge is used to increase performance as well as solution quality. In this paper, we propose a global optimization approach based on the branch-and-cut technique to solve the cardinality-constrained MSSC. For the lower bound routine, we use the semidefinite programming (SDP) relaxation recently proposed by Rujeerapaiboon et al. (SIAM J Optim 29(2):1211–1239, 2019). However, this relaxation can be used in a branch-and-cut method only for small-size instances. Therefore, we derive a new SDP relaxation that scales better with the instance size and the number of clusters. In both cases, we strengthen the bound by adding polyhedral cuts. Benefiting from a tailored branching strategy which enforces pairwise constraints, we reduce the complexity of the problems arising in the children nodes. For the upper bound, instead, we present a local search procedure that exploits the solution of the SDP relaxation solved at each node. Computational results show that the proposed algorithm globally solves, for the first time, real-world instances of size 10 times larger than those solved by state-of-the-art exact methods.},
  archive      = {J_MP},
  author       = {Piccialli, Veronica and Sudoso, Antonio M.},
  doi          = {10.1007/s10107-023-02021-8},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {245-279},
  shortjournal = {Math. Program.},
  title        = {Global optimization for cardinality-constrained minimum sum-of-squares clustering via semidefinite programming},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended convergence analysis of the scholtes-type regularization for cardinality-constrained optimization problems. <em>MP</em>, <em>211</em>(1), 207-243. (<a href='https://doi.org/10.1007/s10107-024-02082-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the convergence analysis of the Scholtes-type regularization method for cardinality-constrained optimization problems. Its behavior is clarified in the vicinity of saddle points, and not just of minimizers as it has been done in the literature before. This becomes possible by using as an intermediate step the recently introduced regularized continuous reformulation of a cardinality-constrained optimization problem. We show that the Scholtes-type regularization method is well-defined locally around a nondegenerate T-stationary point of this regularized continuous reformulation. Moreover, the nondegenerate Karush–Kuhn–Tucker points of the corresponding Scholtes-type regularization converge to a T-stationary point having the same index, i.e. its topological type persists. As consequence, we conclude that the global structure of the Scholtes-type regularization essentially coincides with that of CCOP.},
  archive      = {J_MP},
  author       = {Lämmel, Sebastian and Shikhman, Vladimir},
  doi          = {10.1007/s10107-024-02082-3},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {207-243},
  shortjournal = {Math. Program.},
  title        = {Extended convergence analysis of the scholtes-type regularization for cardinality-constrained optimization problems},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On convergence of iterative thresholding algorithms to approximate sparse solution for composite nonconvex optimization. <em>MP</em>, <em>211</em>(1), 181-206. (<a href='https://doi.org/10.1007/s10107-024-02068-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to find an approximate true sparse solution of an underdetermined linear system. For this purpose, we propose two types of iterative thresholding algorithms with the continuation technique and the truncation technique respectively. We introduce a notion of limited shrinkage thresholding operator and apply it, together with the restricted isometry property, to show that the proposed algorithms converge to an approximate true sparse solution within a tolerance relevant to the noise level and the limited shrinkage magnitude. Applying the obtained results to nonconvex regularization problems with SCAD, MCP and $$\ell _p$$ penalty ( $$0\le p \le 1$$ ) and utilizing the recovery bound theory, we establish the convergence of their proximal gradient algorithms to an approximate global solution of nonconvex regularization problems. The established results include the existing convergence theory for $$\ell _1$$ or $$\ell _0$$ regularization problems for finding a true sparse solution as special cases. Preliminary numerical results show that our proposed algorithms can find approximate true sparse solutions that are much better than stationary solutions that are found by using the standard proximal gradient algorithm.},
  archive      = {J_MP},
  author       = {Hu, Yaohua and Hu, Xinlin and Yang, Xiaoqi},
  doi          = {10.1007/s10107-024-02068-1},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {181-206},
  shortjournal = {Math. Program.},
  title        = {On convergence of iterative thresholding algorithms to approximate sparse solution for composite nonconvex optimization},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A slightly lifted convex relaxation for nonconvex quadratic programming with ball constraints. <em>MP</em>, <em>211</em>(1), 157-179. (<a href='https://doi.org/10.1007/s10107-024-02076-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally optimizing a nonconvex quadratic over the intersection of m balls in $$\mathbb {R}^n$$ is known to be polynomial-time solvable for fixed m. Moreover, when $$m=1$$ , the standard semidefinite relaxation is exact. When $$m=2$$ , it has been shown recently that an exact relaxation can be constructed using a disjunctive semidefinite formulation based essentially on two copies of the $$m=1$$ case. However, there is no known explicit, tractable, exact convex representation for $$m \ge 3$$ . In this paper, we construct a new, polynomially sized semidefinite relaxation for all m, which does not employ a disjunctive approach. We show that our relaxation is exact for $$m=2$$ . Then, for $$m \ge 3$$ , we demonstrate empirically that it is fast and strong compared to existing relaxations. The key idea of the relaxation is a simple lifting of the original problem into dimension $$n\, +\, 1$$ . Extending this construction: (i) we show that nonconvex quadratic programming over $$\Vert x\Vert \le \min \{ 1, g + h^T x \}$$ has an exact semidefinite representation; and (ii) we construct a new relaxation for quadratic programming over the intersection of two ellipsoids, which globally solves all instances of a benchmark collection from the literature.},
  archive      = {J_MP},
  author       = {Burer, Samuel},
  doi          = {10.1007/s10107-024-02076-1},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {157-179},
  shortjournal = {Math. Program.},
  title        = {A slightly lifted convex relaxation for nonconvex quadratic programming with ball constraints},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polarized consensus-based dynamics for optimization and sampling. <em>MP</em>, <em>211</em>(1), 125-155. (<a href='https://doi.org/10.1007/s10107-024-02095-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose polarized consensus-based dynamics in order to make consensus-based optimization (CBO) and sampling (CBS) applicable for objective functions with several global minima or distributions with many modes, respectively. For this, we “polarize” the dynamics with a localizing kernel and the resulting model can be viewed as a bounded confidence model for opinion formation in the presence of common objective. Instead of being attracted to a common weighted mean as in the original consensus-based methods, which prevents the detection of more than one minimum or mode, in our method every particle is attracted to a weighted mean which gives more weight to nearby particles. We prove that in the mean-field regime the polarized CBS dynamics are unbiased for Gaussian targets. We also prove that in the zero temperature limit and for sufficiently well-behaved strongly convex objectives the solution of the Fokker–Planck equation converges in the Wasserstein-2 distance to a Dirac measure at the minimizer. Finally, we propose a computationally more efficient generalization which works with a predefined number of clusters and improves upon our polarized baseline method for high-dimensional optimization.},
  archive      = {J_MP},
  author       = {Bungert, Leon and Roith, Tim and Wacker, Philipp},
  doi          = {10.1007/s10107-024-02095-y},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {125-155},
  shortjournal = {Math. Program.},
  title        = {Polarized consensus-based dynamics for optimization and sampling},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex envelopes of bounded monomials on two-variable cones. <em>MP</em>, <em>211</em>(1), 93-123. (<a href='https://doi.org/10.1007/s10107-025-02212-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an n-variate monomial function that is restricted both in value by lower and upper bounds and in domain by two homogeneous linear inequalities. Monomial functions are building blocks for the class of Mixed Integer Nonlinear Optimization problems, which has many practical applications. We show that the upper envelope of the function in the given domain, for $$\textrm{n}\ge 2$$ , is given by a conic inequality, and present the lower envelope for $$\mathrm {n=2}$$ . We also discuss branching rules that maintain these convex envelopes and their applicability in a branch-and-bound framework, then derive the volume of the convex hull for $$\mathrm {n=2}$$ .},
  archive      = {J_MP},
  author       = {Belotti, Pietro},
  doi          = {10.1007/s10107-025-02212-5},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {93-123},
  shortjournal = {Math. Program.},
  title        = {Convex envelopes of bounded monomials on two-variable cones},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A radial basis function method for noisy global optimisation. <em>MP</em>, <em>211</em>(1), 49-92. (<a href='https://doi.org/10.1007/s10107-024-02125-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel response surface method for global optimisation of an expensive and noisy (black-box) objective function, where error bounds on the deviation of the observed noisy function values from their true counterparts are available. The method is based on Gutmann’s well-established RBF method for minimising an expensive and deterministic objective function, which has become popular both from a theoretical and practical perspective. To construct suitable radial basis function approximants to the objective function and to determine new sample points for successive evaluation of the expensive noisy objective, the method uses a regularised least-squares criterion. In particular, new points are defined by means of a target value, analogous to the original RBF method. We provide essential convergence results, and provide a numerical illustration of the method by means of a simple test problem.},
  archive      = {J_MP},
  author       = {Banholzer, Dirk and Fliege, Jörg and Werner, Ralf},
  doi          = {10.1007/s10107-024-02125-9},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {49-92},
  shortjournal = {Math. Program.},
  title        = {A radial basis function method for noisy global optimisation},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the tightness of an SDP relaxation for homogeneous QCQP with three real or four complex homogeneous constraints. <em>MP</em>, <em>211</em>(1), 5-48. (<a href='https://doi.org/10.1007/s10107-024-02105-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of minimizing a general homogeneous quadratic function, subject to three real or four complex homogeneous quadratic inequality or equality constraints. For this problem, we present a sufficient and necessary test condition to detect whether its standard semi-definite programming (SDP) relaxation is tight or not. This test condition is based on only an optimal solution pair of the SDP relaxation and its dual. When the tightness is confirmed, a global optimal solution of the original problem is found simultaneously in polynomial-time. While the tightness does not hold, the SDP relaxation and its dual are proved to have the unique optimal solutions. Moreover, the Lagrangian version of such the test condition is specified for non-homogeneous cases. Based on the Lagrangian version, it is proved that several latest sufficient conditions to test the SDP tightness are contained by our test condition under the situation of two constraints. Thirdly, as an application of the test condition, S-lemma and Yuan’s lemma are generalized to three real and four complex quadratic forms first under certain exact conditions, which improves some classical results in literature. Finally, a counterexample is presented to show that the test condition cannot be simply extended to four real or five complex homogeneous quadratic constraints.},
  archive      = {J_MP},
  author       = {Ai, Wenbao and Liang, Wei and Yuan, Jianhua},
  doi          = {10.1007/s10107-024-02105-z},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {5-48},
  shortjournal = {Math. Program.},
  title        = {On the tightness of an SDP relaxation for homogeneous QCQP with three real or four complex homogeneous constraints},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Special issue: Global optimization. <em>MP</em>, <em>211</em>(1), 1-3. (<a href='https://doi.org/10.1007/s10107-025-02225-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Csendes, Tibor and G.-Tóth, Boglárka and Locatelli, Marco},
  doi          = {10.1007/s10107-025-02225-0},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Math. Program.},
  title        = {Special issue: Global optimization},
  volume       = {211},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplicative auction algorithm for approximate maximum weight bipartite matching. <em>MP</em>, <em>210</em>(1), 881-894. (<a href='https://doi.org/10.1007/s10107-024-02066-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an auction algorithm using multiplicative instead of constant weight updates to compute a $$(1-\varepsilon )$$ -approximate maximum weight matching (MWM) in a bipartite graph with n vertices and m edges in time $$O(m\varepsilon ^{-1})$$ , beating the running time of the fastest known approximation algorithm of Duan and Pettie [JACM ’14] that runs in $$O(m\varepsilon ^{-1}\log \varepsilon ^{-1})$$ . Our algorithm is very simple and it can be extended to give a dynamic data structure that maintains a $$(1-\varepsilon )$$ -approximate maximum weight matching under (1) one-sided vertex deletions (with incident edges) and (2) one-sided vertex insertions (with incident edges sorted by weight) to the other side. The total time time used is $$O(m\varepsilon ^{-1})$$ , where m is the sum of the number of initially existing and inserted edges.},
  archive      = {J_MP},
  author       = {Zheng, Da Wei and Henzinger, Monika},
  doi          = {10.1007/s10107-024-02066-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {881-894},
  shortjournal = {Math. Program.},
  title        = {Multiplicative auction algorithm for approximate maximum weight bipartite matching},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast combinatorial algorithm for the bilevel knapsack problem with interdiction constraints. <em>MP</em>, <em>210</em>(1), 847-879. (<a href='https://doi.org/10.1007/s10107-024-02133-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the bilevel knapsack problem with interdiction constraints, a fundamental bilevel integer programming problem which generalizes the 0–1 knapsack problem. In this problem, there are two knapsacks and n items. The objective is to select some items to pack into the first knapsack such that the maximum profit attainable from packing some of the remaining items into the second knapsack is minimized. We present a combinatorial branch-and-bound algorithm which outperforms the current state-of-the-art solution method in computational experiments for 99% of the instances reported in the literature. On many of the harder instances, our algorithm is orders of magnitude faster, which enabled it to solve 53 of the 72 previously unsolved instances. Our result relies fundamentally on a new dynamic programming algorithm which computes very strong lower bounds. This dynamic program solves a relaxation of the problem from bilevel to 2n-level where the items are processed in an online fashion. The relaxation is easier to solve but approximates the original problem surprisingly well in practice. We believe that this same technique may be useful for other interdiction problems.},
  archive      = {J_MP},
  author       = {Weninger, Noah and Fukasawa, Ricardo},
  doi          = {10.1007/s10107-024-02133-9},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {847-879},
  shortjournal = {Math. Program.},
  title        = {A fast combinatorial algorithm for the bilevel knapsack problem with interdiction constraints},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constant-competitiveness for random assignment matroid secretary without knowing the matroid. <em>MP</em>, <em>210</em>(1), 815-846. (<a href='https://doi.org/10.1007/s10107-024-02177-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Matroid Secretary Conjecture is a notorious open problem in online optimization. It claims the existence of an O(1)-competitive algorithm for the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid appear one-by-one, revealing their weight at appearance, and the task is to select elements online with the goal to get an independent set of largest possible weight. O(1)-competitive MSP algorithms have so far only been obtained for restricted matroid classes and for MSP variations, including Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights equal to the ground set size of the matroid, which then get assigned randomly to the elements of the ground set. Unfortunately, these approaches heavily rely on knowing the full matroid upfront. This is an arguably undesirable requirement, and there are good reasons to believe that an approach towards resolving the MSP Conjecture should not rely on it. Thus, both Soto (SIAM Journal on Computing 42(1): 178-211, 2013.) and Oveis Gharan and Vondrák (Algorithmica 67(4): 472-497, 2013.) raised as an open question whether RA-MSP admits an O(1)-competitive algorithm even without knowing the matroid upfront. In this work, we answer this question affirmatively. Our result makes RA-MSP the first well-known MSP variant with an O(1)-competitive algorithm that does not need to know the underlying matroid upfront and without any restriction on the underlying matroid. Our approach is based on first approximately learning the rank-density curve of the matroid, which we then exploit algorithmically.},
  archive      = {J_MP},
  author       = {Santiago, Richard and Sergeev, Ivan and Zenklusen, Rico},
  doi          = {10.1007/s10107-024-02177-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {815-846},
  shortjournal = {Math. Program.},
  title        = {Constant-competitiveness for random assignment matroid secretary without knowing the matroid},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cut-sufficient directed 2-commodity multiflow topologies. <em>MP</em>, <em>210</em>(1), 793-814. (<a href='https://doi.org/10.1007/s10107-025-02195-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multicommodity network flows, a supply–demand graph pair (G, H) (called a multiflow topology) is cut-sufficient if, for all capacity and demand weights, the cut condition is enough to guarantee the existence of a feasible multiflow. We characterize cut-sufficiency for two classes of directed 2-commodity flows: roundtrip demands, where H is a 2-cycle, and 2-path demands, where H is a directed path of length two. We then extend these characterizations to some larger demand graphs, namely directed stars and directed triangles. To obtain such characterizations, we introduce a theory of relevant minors. Unlike the undirected setting, for directed graphs the cut-sufficient topologies are not minor-closed. They are however relevant-minor-closed. A single forbidden relevant minor characterizes roundtrip cut-sufficiency, and two suffice for the other classes. We also provide a partial characterization in the case of two independent demands (2-matching demands), showing that one of two relevant minors exists if the weights that break cut-sufficiency have unit demand values. As an application of our results, we show that recognizing cut-sufficiency for directed multiflow topologies is co-NP-hard, even for roundtrip demands. This is in contrast to undirected 2-commodity flows, for which topologies are always cut-sufficient.},
  archive      = {J_MP},
  author       = {Poremba, Joseph and Shepherd, F. Bruce},
  doi          = {10.1007/s10107-025-02195-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {793-814},
  shortjournal = {Math. Program.},
  title        = {Cut-sufficient directed 2-commodity multiflow topologies},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards an optimal contention resolution scheme for matchings. <em>MP</em>, <em>210</em>(1), 761-792. (<a href='https://doi.org/10.1007/s10107-024-02178-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study contention resolution schemes for matchings. Given a fractional matching x and a random set R(x) where each edge e appears independently with probability $$x_e$$ , we want to select a matching $$M \subseteq R(x)$$ such that $$\Pr [e \in M \mid e \in R(x)] \ge c$$ , for c as large as possible. We call such a selection method a c-balanced contention resolution scheme. Our main results are (i) an asymptotically optimal $$\simeq 0.544$$ -balanced contention resolution scheme for general matchings when $$\Vert x\Vert _\infty \rightarrow 0$$ , and (ii) a 0.509-balanced contention resolution scheme for bipartite matchings (without any restriction on x). To the best of our knowledge, this result establishes for the first time, in any natural relaxation of a combinatorial optimization problem, a separation between (i) offline and random order online contention resolution schemes, and (ii) monotone and non-monotone contention resolution schemes.},
  archive      = {J_MP},
  author       = {Nuti, Pranav and Vondrák, Jan},
  doi          = {10.1007/s10107-024-02178-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {761-792},
  shortjournal = {Math. Program.},
  title        = {Towards an optimal contention resolution scheme for matchings},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances on strictly $$\Delta $$ -modular IPs. <em>MP</em>, <em>210</em>(1), 731-760. (<a href='https://doi.org/10.1007/s10107-024-02148-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been significant work recently on integer programs (IPs) $$\min \{c^\top x :Ax\le b,\,x\in \mathbb {Z}^n\}$$ with a constraint marix A with bounded subdeterminants. This is motivated by a well-known conjecture claiming that, for any constant $$\Delta \in \mathbb {Z}_{>0}$$ , $$\Delta $$ -modular IPs are efficiently solvable, which are IPs where the constraint matrix $$A\in \mathbb {Z}^{m\times n}$$ has full column rank and all $$n\times n$$ minors of A are within $$\{-\Delta , \dots , \Delta \}$$ . Previous progress on this question, in particular for $$\Delta =2$$ , relies on algorithms that solve an important special case, namely strictly $$\Delta $$ -modular IPs, which further restrict the $$n\times n$$ minors of A to be within $$\{-\Delta , 0, \Delta \}$$ . Even for $$\Delta =2$$ , such problems include well-known combinatorial optimization problems like the minimum odd/even cut problem. The conjecture remains open even for strictly $$\Delta $$ -modular IPs. Prior advances were restricted to prime $$\Delta $$ , which allows for employing strong number-theoretic results. In this work, we make first progress beyond the prime case by presenting techniques not relying on such strong number-theoretic prime results. In particular, our approach implies that there is a randomized algorithm to check feasibility of strictly $$\Delta $$ -modular IPs in strongly polynomial time if $$\Delta \le 4$$ .},
  archive      = {J_MP},
  author       = {Nägele, Martin and Nöbel, Christian and Santiago, Richard and Zenklusen, Rico},
  doi          = {10.1007/s10107-024-02148-2},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {731-760},
  shortjournal = {Math. Program.},
  title        = {Advances on strictly $$\Delta $$ -modular IPs},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the polyhedral geometry of stochastic linear bilevel programming. <em>MP</em>, <em>210</em>(1), 695-730. (<a href='https://doi.org/10.1007/s10107-024-02097-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear bilevel programming problems whose lower-level objective is given by a random cost vector with known distribution. We consider the case where this distribution is nonatomic, allowing to reformulate the problem of the leader using the Bayesian approach in the sense of Salas and Svensson (SIAM J Optim 33(3):2311–2340, 2023), with a decision-dependent distribution that concentrates on the vertices of the feasible set of the follower’s problem. We call this a vertex-supported belief. We prove that this formulation is piecewise affine over the so-called chamber complex of the feasible set of the high-point relaxation. We propose two algorithmic approaches to solve general problems enjoying this last property. The first one is based on enumerating the vertices of the chamber complex. This approach is not scalable, but we present it as a computational baseline and for its theoretical interest. The second one is a Monte-Carlo approximation scheme based on the fact that randomly drawn points of the domain lie, with probability 1, in the interior of full-dimensional chambers, where the problem (restricted to this chamber) can be reduced to a linear program. Finally, we evaluate these methods through computational experiments showing both approaches’ advantages and challenges.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Salas, David and Svensson, Anton},
  doi          = {10.1007/s10107-024-02097-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {695-730},
  shortjournal = {Math. Program.},
  title        = {Exploiting the polyhedral geometry of stochastic linear bilevel programming},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressing branch-and-bound trees. <em>MP</em>, <em>210</em>(1), 669-694. (<a href='https://doi.org/10.1007/s10107-024-02080-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A branch-and-bound (BB) tree certifies a dual bound on the value of an integer program. In this work, we introduce the tree compression problem (TCP): Given a BB tree T that certifies a dual bound, can we obtain a smaller tree with the same (or stronger) bound by either (1) applying a different disjunction at some node in T or (2) removing leaves from T? We believe such post-hoc analysis of BB trees may assist in identifying helpful general disjunctions in BB algorithms. We initiate our study by considering computational complexity and limitations of TCP. We then conduct experiments to evaluate the compressibility of realistic branch-and-bound trees generated by commonly-used branching strategies, using both an exact and a heuristic compression algorithm.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Paat, Joseph and Xavier, Álinson S.},
  doi          = {10.1007/s10107-024-02080-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {669-694},
  shortjournal = {Math. Program.},
  title        = {Compressing branch-and-bound trees},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A characterization of maximal homogeneous-quadratic-free sets. <em>MP</em>, <em>210</em>(1), 641-668. (<a href='https://doi.org/10.1007/s10107-024-02092-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intersection cut framework was introduced by Balas in 1971 as a method for generating cutting planes in integer optimization. In this framework, one uses a full-dimensional convex S-free set, where S is the feasible region of the integer program, to derive a cut separating S from a non-integral vertex of a linear relaxation of S. Among all S-free sets, it is the inclusion-wise maximal ones that yield the strongest cuts. Recently, this framework has been extended beyond the integer case in order to obtain cutting planes in non-linear settings. In this work, we consider the specific setting when S is defined by a homogeneous quadratic inequality. In this ‘quadratic-free’ setting, every function $$\Gamma : D^m \rightarrow D^n$$ , where $$D^k$$ is the unit sphere in $$\mathbb {R}^k$$ , generates a representation of a quadratic-free set. While not every $$\Gamma $$ generates a maximal quadratic free set, it is the case that every full-dimensional maximal quadratic free set is generated by some $$\Gamma $$ . Our main result shows that the corresponding quadratic-free set is full-dimensional and maximal if and only if $$\Gamma $$ is non-expansive and satisfies a technical condition. This result yields a broader class of maximal S-free sets than previously known. Our result stems from a new characterization of maximal S-free sets (for general S beyond the quadratic setting) based on sequences that ‘expose’ inequalities defining the S-free set.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Paat, Joseph and Serrano, Felipe},
  doi          = {10.1007/s10107-024-02092-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {641-668},
  shortjournal = {Math. Program.},
  title        = {A characterization of maximal homogeneous-quadratic-free sets},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition of probability marginals for security games in max-flow/min-cut systems. <em>MP</em>, <em>210</em>(1), 611-640. (<a href='https://doi.org/10.1007/s10107-024-02144-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set system $$(E, \mathcal {P})$$ with $$\rho \in [0, 1]^E$$ and $$\pi \in [0,1]^{\mathcal {P}}$$ , our goal is to find a probability distribution for a random set $$S \subseteq E$$ such that $$\textbf{Pr}\left[ e \in S\right] = \rho _e$$ for all $$e \in E$$ and $$\textbf{Pr}\left[ P \cap S \ne \emptyset \right] \ge \pi _P$$ for all $$P \in \mathcal {P}$$ . We extend the results of Dahan, Amin, and Jaillet [6] who studied this problem motivated by a security game in a directed acyclic graph (DAG). We focus on the setting where $$\pi $$ is of the affine form $$\pi _P = 1 - \sum _{e \in P} \mu _e$$ for $$\mu \in [0, 1]^E$$ . A necessary condition for the existence of the desired distribution is that $$\sum _{e \in P} \rho _e \ge \pi _P$$ for all $$P \in \mathcal {P}$$ . We show that this condition is sufficient if and only if $$\mathcal {P}$$ has the weak max-flow/min-cut property. We further provide an efficient combinatorial algorithm for computing the corresponding distribution in the special case where $$(E, \mathcal {P})$$ is an abstract network. As a consequence, equilibria for the security game in [6] can be efficiently computed in a wide variety of settings (including arbitrary digraphs). As a subroutine of our algorithm, we provide a combinatorial algorithm for computing shortest paths in abstract networks, partially answering an open question by McCormick [20]. We further show that a conservation law proposed in [6] for the requirement vector $$\pi $$ in DAGs can be reduced to the setting of affine requirements described above.},
  archive      = {J_MP},
  author       = {Matuschke, Jannik},
  doi          = {10.1007/s10107-024-02144-6},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {611-640},
  shortjournal = {Math. Program.},
  title        = {Decomposition of probability marginals for security games in max-flow/min-cut systems},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal general factor problem and jump system intersection. <em>MP</em>, <em>210</em>(1), 591-610. (<a href='https://doi.org/10.1007/s10107-024-02098-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the optimal general factor problem, given a graph $$G=(V, E)$$ and a set $$B(v) \subseteq {\mathbb {Z}}$$ of integers for each $$v \in V$$ , we seek for an edge subset F of maximum cardinality subject to $$d_F(v) \in B(v)$$ for $$v \in V$$ , where $$d_F(v)$$ denotes the number of edges in F incident to v. A recent crucial work by Dudycz and Paluch shows that this problem can be solved in polynomial time if each B(v) has no gap of length more than one. While their algorithm is very simple, its correctness proof is quite complicated. In this paper, we formulate the optimal general factor problem as the jump system intersection, and reveal when the algorithm by Dudycz and Paluch can be applied to this abstract form of the problem. By using this abstraction, we give another correctness proof of the algorithm, which is simpler than the original one. We also extend our result to the valuated case.},
  archive      = {J_MP},
  author       = {Kobayashi, Yusuke},
  doi          = {10.1007/s10107-024-02098-9},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {591-610},
  shortjournal = {Math. Program.},
  title        = {Optimal general factor problem and jump system intersection},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monoidal strengthening of simple $$\mathcal {V}$$ -polyhedral disjunctive cuts. <em>MP</em>, <em>210</em>(1), 567-590. (<a href='https://doi.org/10.1007/s10107-024-02185-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disjunctive cutting planes can tighten a relaxation of a mixed-integer linear program. Traditionally, such cuts are obtained by solving a higher-dimensional linear program, whose additional variables cause the procedure to be computationally prohibitive. Adopting a $$\mathcal {V}$$ -polyhedral perspective is a practical alternative that enables the separation of disjunctive cuts via a linear program with only as many variables as the original problem. The drawback is that the classical approach of monoidal strengthening cannot be directly employed without the values of the extra variables appearing in the extended formulation, which constitute a certificate of validity of the cut. We derive how to compute this certificate from a solution to the linear program generating $$\mathcal {V}$$ -polyhedral disjunctive cuts. We then present computational experiments with monoidal strengthening of cuts from disjunctions with as many as 64 terms. Some instances are dramatically impacted, with strengthening increasing the gap closed by the cuts from 0 to 100%. However, for larger disjunctions, monoidal strengthening appears to be less effective, for which we identify a potential cause. Lastly, the certificates of validity also enable us to verify which disjunctive cuts are equivalent to intersection cuts, which happens increasingly rarely for larger disjunctions.},
  archive      = {J_MP},
  author       = {Kazachkov, Aleksandr M. and Balas, Egon},
  doi          = {10.1007/s10107-024-02185-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {567-590},
  shortjournal = {Math. Program.},
  title        = {Monoidal strengthening of simple $$\mathcal {V}$$ -polyhedral disjunctive cuts},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The polyhedral geometry of truthful auctions. <em>MP</em>, <em>210</em>(1), 539-566. (<a href='https://doi.org/10.1007/s10107-024-02168-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difference set of an outcome in an auction is the set of types that the auction mechanism maps to the outcome. We give a complete characterization of the geometry of the difference sets that can appear for a dominant strategy incentive compatible multi-unit auction showing that they correspond to regular subdivisions of the unit cube. Similarly, we describe the geometry for affine maximizers for n players and m items, showing that they correspond to regular subdivisions of the m-fold product of $$(n-1)$$ -dimensional simplices. These observations are then used to construct mechanisms that are robust in the sense that the sets of items allocated to the players change only slightly when the players’ reported types are changed slightly.},
  archive      = {J_MP},
  author       = {Joswig, Michael and Klimm, Max and Spitz, Sylvain},
  doi          = {10.1007/s10107-024-02168-y},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {539-566},
  shortjournal = {Math. Program.},
  title        = {The polyhedral geometry of truthful auctions},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A $$\frac{4}{3}$$ -approximation algorithm for half-integral cycle cut instances of the TSP. <em>MP</em>, <em>210</em>(1), 511-538. (<a href='https://doi.org/10.1007/s10107-025-02193-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing conjecture for the traveling salesman problem (TSP) states that the integrality gap of the standard linear programming relaxation of the TSP (sometimes called the Subtour LP or the Held-Karp bound) is at most 4/3 for symmetric instances of the TSP obeying the triangle inequality; that is, the cost of an optimal tour is at most 4/3 times the value of the value of the corresponding linear program. There is a variety of evidence in support of the conjecture (see, for instance, Goemans in Math Program 69:335–349, 1995; Benoit and Boyd in Math Oper Res 33:921–931, 2008). It has long been known that the integrality gap is at most 3/2 (Wolsey in Math Program Study 13:121–134, 1980; Shmoys and Williamson in Inf Process Lett 35:281–285, 1990). Despite significant efforts by the community, the conjecture remains open. In this paper we consider the half-integral case, in which a feasible solution to the LP has solution values in $$\{0, 1/2, 1\}$$ . Such instances have been conjectured to be the most difficult instances for the overall four-thirds conjecture (Schalekamp et al. in Math Oper Res 39(2):403–417, 2014). Karlin et al. (in: Proceedings of the 52nd Annual ACM Symposium on the the Theory of Computing, ACM, New York, 2020), in a breakthrough result, were able to show that in the half-integral case, the integrality gap is at most 1.49993; Gupta et al. (in: Integer Programming and Combinatorial Optimization. Lecture Notes in Computer Science, 2022. https://arxiv.org/abs/2111.09290 ) showed a slight improvement of this result to 1.4983. Additionally, this result led to the first significant progress on the overall conjecture in decades; the same authors showed the integrality gap of the Subtour LP is at most $$1.5-\epsilon $$ for some $$\epsilon >10^{-36}$$ Karlin et al. in 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS). https://doi.org/10.1109/FOCS54457.2022.00084 . With the improvements on the 3/2 bound remaining very incremental, even in the half-integral case, we turn the question around and look for a large class of half-integral instances for which we can prove that the 4/3 conjecture is correct, preferably one containing the known worst-case instances. In Karlin et al.’s work on the half-integral case, they perform induction on a hierarchy of critical tight sets in the support graph of the LP solution, in which some of the sets correspond to cycle cuts and the others to degree cuts. Here we show that if all the sets in the hierarchy correspond to cycle cuts, then we can find a distribution of tours whose expected cost is at most 4/3 times the value of the half-integral LP solution; sampling from the distribution gives us a randomized 4/3-approximation algorithm. We note that two important bad cases with an integrality gap of 4/3 have a half-integral LP solution in which all the critical tight sets in the hierarchy are cycle cuts; thus our result is tight. Our overall approach is novel. Most recent work has focused on showing that some variation of the Christofides-Serdyukov algorithm (Christofides in “Worst case analysis of a new heuristic for the traveling salesman problem”. Report 388, Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, 1976; Serdyukov in Upravlyaemye Sistemy 17:76–79, 1978) that combines a randomly sampled spanning tree plus a T-join (or a matching) can be shown to give a bound better than 1.5. Here we show that for any point in a region of “patterns” of edges incident to each cycle cut, we can give a distribution of patterns connecting all the child cycle cuts such that the distribution of patterns for each child also falls in the region. This region gives rise to a distribution on Eulerian tours in which each edge in the support of the LP is used at most four-thirds of its LP value of the time, which then gives the result.},
  archive      = {J_MP},
  author       = {Jin, Billy and Klein, Nathan and Williamson, David P.},
  doi          = {10.1007/s10107-025-02193-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {511-538},
  shortjournal = {Math. Program.},
  title        = {A $$\frac{4}{3}$$ -approximation algorithm for half-integral cycle cut instances of the TSP},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive kill-and-restart and preemptive strategies for non-clairvoyant scheduling. <em>MP</em>, <em>210</em>(1), 457-509. (<a href='https://doi.org/10.1007/s10107-024-02118-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study kill-and-restart and preemptive strategies for the fundamental scheduling problem of minimizing the sum of weighted completion times on a single machine in the non-clairvoyant setting. First, we show a lower bound of 3 for any deterministic non-clairvoyant kill-and-restart strategy. Then, we give for any $$b > 1$$ a tight analysis for the natural b-scaling kill-and-restart strategy as well as for a randomized variant of it. In particular, we show a competitive ratio of $$(1+3\sqrt{3})\approx 6.197$$ for the deterministic and of $$\approx 3.032$$ for the randomized strategy, by making use of the largest eigenvalue of a Toeplitz matrix. In addition, we show that the preemptive Weighted Shortest Elapsed Time First (WSETF) rule is 2-competitive when jobs are released online, matching the lower bound for the unit weight case with trivial release dates for any non-clairvoyant algorithm. Using this result as well as the competitiveness of round-robin for multiple machines, we prove performance guarantees smaller than 10 for adaptions of the b-scaling strategy to online release dates and unweighted jobs on identical parallel machines.},
  archive      = {J_MP},
  author       = {Jäger, Sven and Sagnol, Guillaume and Schmidt genannt Waldschmidt, Daniel and Warode, Philipp},
  doi          = {10.1007/s10107-024-02118-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {457-509},
  shortjournal = {Math. Program.},
  title        = {Competitive kill-and-restart and preemptive strategies for non-clairvoyant scheduling},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the correlation gap of matroids. <em>MP</em>, <em>210</em>(1), 407-456. (<a href='https://doi.org/10.1007/s10107-024-02116-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set function can be extended to the unit cube in various ways; the correlation gap measures the ratio between two natural extensions. This quantity has been identified as the performance guarantee in a range of approximation algorithms and mechanism design settings. It is known that the correlation gap of a monotone submodular function is at least $$1-1/e$$ , and this is tight for simple matroid rank functions. We initiate a fine-grained study of the correlation gap of matroid rank functions. In particular, we present an improved lower bound on the correlation gap as parametrized by the rank and girth of the matroid. We also show that for any matroid, the correlation gap of its weighted rank function is minimized under uniform weights. Such improved lower bounds have direct applications for submodular maximization under matroid constraints, mechanism design, and contention resolution schemes.},
  archive      = {J_MP},
  author       = {Husić, Edin and Koh, Zhuan Khye and Loho, Georg and Végh, László A.},
  doi          = {10.1007/s10107-024-02116-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {407-456},
  shortjournal = {Math. Program.},
  title        = {On the correlation gap of matroids},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReLU neural networks of polynomial size for exact maximum flow computation. <em>MP</em>, <em>210</em>(1), 377-406. (<a href='https://doi.org/10.1007/s10107-024-02096-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the expressive power of artificial neural networks with rectified linear units. In order to study them as a model of real-valued computation, we introduce the concept of Max-Affine Arithmetic Programs and show equivalence between them and neural networks concerning natural complexity measures. We then use this result to show that two fundamental combinatorial optimization problems can be solved with polynomial-size neural networks. First, we show that for any undirected graph with n nodes, there is a neural network (with fixed weights and biases) of size $$\mathcal {O}(n^3)$$ that takes the edge weights as input and computes the value of a minimum spanning tree of the graph. Second, we show that for any directed graph with n nodes and m arcs, there is a neural network of size $$\mathcal {O}(m^2n^2)$$ that takes the arc capacities as input and computes a maximum flow. Our results imply that these two problems can be solved with strongly polynomial time algorithms that solely use affine transformations and maxima computations, but no comparison-based branchings.},
  archive      = {J_MP},
  author       = {Hertrich, Christoph and Sering, Leon},
  doi          = {10.1007/s10107-024-02096-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {377-406},
  shortjournal = {Math. Program.},
  title        = {ReLU neural networks of polynomial size for exact maximum flow computation},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing for strategy diversity in the design of video games. <em>MP</em>, <em>210</em>(1), 335-376. (<a href='https://doi.org/10.1007/s10107-024-02126-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of designing a linear program that has diverse solutions as the right-hand side varies. This problem arises in video game settings where designers aim to have players use different “weapons” or “tactics” as they progress. We model this design question as a choice over the constraint matrix A and cost vector c to maximize the number of possible supports of unique optimal solutions (what we call “loadouts”) of Linear Programs $$\max \{c^\top x \mid Ax \le b, x \ge 0\}$$ with nonnegative data considered over all resource vectors b. We provide an upper bound on the optimal number of loadouts and provide a family of constructions that have an asymptotically optimal number of loadouts. The upper bound is based on a connection between our problem and the study of triangulations of point sets arising from polyhedral combinatorics, and specifically the combinatorics of the cyclic polytope. Our asymptotically optimal construction also draws inspiration from the properties of the cyclic polytope.},
  archive      = {J_MP},
  author       = {Hanguir, Oussama and Ma, Will and Han, Jiangze and Ryan, Christopher Thomas},
  doi          = {10.1007/s10107-024-02126-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {335-376},
  shortjournal = {Math. Program.},
  title        = {Optimizing for strategy diversity in the design of video games},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilization of capacitated matching games. <em>MP</em>, <em>210</em>(1), 313-334. (<a href='https://doi.org/10.1007/s10107-024-02169-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An edge-weighted, vertex-capacitated graph $$G$$ is called stable if the value of a maximum-weight capacity-matching equals the value of a maximum-weight fractional capacity-matching. Stable graphs play a key role in characterizing the existence of stable solutions for popular combinatorial games that involve the structure of matchings in graphs, such as network bargaining games and cooperative matching games. The vertex-stabilizer problem asks to compute a minimum number of players to block (i.e., vertices of $$G$$ to remove) in order to ensure stability for such games. The problem has been shown to be solvable in polynomial-time, for unit-capacity graphs. This stays true also if we impose the restriction that the set of players to block must not intersect with a given specified maximum matching of $$G$$ . In this work, we investigate these algorithmic problems in the more general setting of arbitrary capacities. We show that the vertex-stabilizer problem with the additional restriction of avoiding a given maximum matching remains polynomial-time solvable. Differently, without this restriction, the vertex-stabilizer problem becomes NP-hard and even hard to approximate, in contrast to the unit-capacity case.},
  archive      = {J_MP},
  author       = {Gerstbrein, Matthew and Sanità, Laura and Verberk, Lucy},
  doi          = {10.1007/s10107-024-02169-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {313-334},
  shortjournal = {Math. Program.},
  title        = {Stabilization of capacitated matching games},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An update-and-stabilize framework for the minimum-norm-point problem. <em>MP</em>, <em>210</em>(1), 281-311. (<a href='https://doi.org/10.1007/s10107-024-02077-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the minimum-norm-point (MNP) problem over polyhedra, a well-studied problem that encompasses linear programming. We present a general algorithmic framework that combines two fundamental approaches for this problem: active set methods and first order methods. Our algorithm performs first order update steps, followed by iterations that aim to ‘stabilize’ the current iterate with additional projections, i.e., find a locally optimal solution whilst keeping the current tight inequalities. Such steps have been previously used in active set methods for the nonnegative least squares (NNLS) problem. We bound on the number of iterations polynomially in the dimension and in the associated circuit imbalance measure. In particular, the algorithm is strongly polynomial for network flow instances. Classical NNLS algorithms such as the Lawson–Hanson algorithm are special instantiations of our framework; as a consequence, we obtain convergence bounds for these algorithms. Our preliminary computational experiments show promising practical performance.},
  archive      = {J_MP},
  author       = {Fujishige, Satoru and Kitahara, Tomonari and Végh, László A.},
  doi          = {10.1007/s10107-024-02077-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {281-311},
  shortjournal = {Math. Program.},
  title        = {An update-and-stabilize framework for the minimum-norm-point problem},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Configuration balancing for stochastic requests. <em>MP</em>, <em>210</em>(1), 243-279. (<a href='https://doi.org/10.1007/s10107-024-02132-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The configuration balancing problem with stochastic requests generalizes well-studied resource allocation problems such as load balancing and virtual circuit routing. There are given m resources and n requests; each request has multiple possible configurations, each of which increases the load of each resource by some amount. The goal is to select one configuration for each request to minimize the makespan: the load of the most-loaded resource. In the stochastic setting, the amount by which a configuration increases the resource load is uncertain until the configuration is chosen, but we are given a probability distribution. We develop both offline and online algorithms for configuration balancing with stochastic requests. When the requests are known offline, we give a non-adaptive policy for configuration balancing with stochastic requests that $$O(\frac{\log m}{\log \log m})$$ -approximates the optimal adaptive policy, which matches a known lower bound for the special case of load balancing on identical machines. When requests arrive online in a list, we give a non-adaptive policy that is $$O(\log m)$$ competitive. Again, this result is asymptotically tight due to information-theoretic lower bounds for special cases (e.g., for load balancing on unrelated machines). Finally, we show how to leverage adaptivity in the special case of load balancing on related machines to obtain a constant-factor approximation offline and an $$O(\log \log m)$$ -approximation online. A crucial technical ingredient in all of our results is a new structural characterization of the optimal adaptive policy that allows us to limit the correlations between its decisions.},
  archive      = {J_MP},
  author       = {Eberle, Franziska and Gupta, Anupam and Megow, Nicole and Moseley, Benjamin and Zhou, Rudy},
  doi          = {10.1007/s10107-024-02132-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {243-279},
  shortjournal = {Math. Program.},
  title        = {Configuration balancing for stochastic requests},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From approximate to exact integer programming. <em>MP</em>, <em>210</em>(1), 223-241. (<a href='https://doi.org/10.1007/s10107-024-02084-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate integer programming is the following: For a given convex body $$K \subseteq {\mathbb {R}}^n$$ , either determine whether $$K \cap {\mathbb {Z}}^n$$ is empty, or find an integer point in the convex body $$2\cdot (K - c) +c$$ which is K, scaled by 2 from its center of gravity c. Approximate integer programming can be solved in time $$2^{O(n)}$$ while the fastest known methods for exact integer programming run in time $$2^{O(n)} \cdot n^n$$ . So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results. First, we show that an integer point $$x^* \in (K \cap {\mathbb {Z}}^n)$$ can be found in time $$2^{O(n)}$$ , provided that the remainders of each component $$x_i^* \mod \ell $$ for some arbitrarily fixed $$\ell \ge 5(n+1)$$ of $$x^*$$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $$2^{O(n)}n^n$$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (Integer programming, lattice algorithms, and deterministic, vol. Estimation. Georgia Institute of Technology, Atlanta, 2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carathéodory theorem that might be of interest on its own. Our second method concerns integer programming problems in equation-standard form $$Ax = b, 0 \le x \le u, \, x \in {\mathbb {Z}}^n$$ . Such a problem can be reduced to the solution of $$\prod _i O(\log u_i +1)$$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $$0 \le x_i \le p(n)$$ can be solved in time $$(\log n)^{O(n)}$$ . For these problems, the best running time so far was $$n^n \cdot 2^{O(n)}$$ .},
  archive      = {J_MP},
  author       = {Dadush, Daniel and Eisenbrand, Friedrich and Rothvoss, Thomas},
  doi          = {10.1007/s10107-024-02084-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {223-241},
  shortjournal = {Math. Program.},
  title        = {From approximate to exact integer programming},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monoidal strengthening and unique lifting in MIQCPs. <em>MP</em>, <em>210</em>(1), 189-222. (<a href='https://doi.org/10.1007/s10107-024-02112-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the recently proposed maximal quadratic-free sets and the well-known monoidal strengthening procedure, we show how to improve intersection cuts for quadratically-constrained optimization problems by exploiting integrality requirements. We provide an explicit construction that allows an efficient implementation of the strengthened cuts along with computational results showing their improvements over the standard intersection cuts. We also show that, in our setting, there is unique lifting which implies that our strengthening procedure is generating the best possible cut coefficients for the integer variables.},
  archive      = {J_MP},
  author       = {Chmiela, Antonia and Muñoz, Gonzalo and Serrano, Felipe},
  doi          = {10.1007/s10107-024-02112-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {189-222},
  shortjournal = {Math. Program.},
  title        = {Monoidal strengthening and unique lifting in MIQCPs},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A linear time algorithm for linearizing quadratic and higher-order shortest path problems. <em>MP</em>, <em>210</em>(1), 165-188. (<a href='https://doi.org/10.1007/s10107-024-02086-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An instance of the NP-hard Quadratic Shortest Path Problem (QSPP) is called linearizable iff it is equivalent to an instance of the classic Shortest Path Problem (SPP) on the same input digraph. The linearization problem for the QSPP (LinQSPP) decides whether a given QSPP instance is linearizable and determines the corresponding SPP instance in the positive case. We provide a novel linear time algorithm for the LinQSPP on acyclic digraphs which runs considerably faster than the previously best algorithm. The algorithm is based on a new insight revealing that the linearizability of the QSPP for acyclic digraphs can be seen as a local property. Our approach extends to the more general higher-order shortest path problem.},
  archive      = {J_MP},
  author       = {Çela, Eranda and Klinz, Bettina and Lendl, Stefan and Woeginger, Gerhard J. and Wulf, Lasse},
  doi          = {10.1007/s10107-024-02086-z},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {165-188},
  shortjournal = {Math. Program.},
  title        = {A linear time algorithm for linearizing quadratic and higher-order shortest path problems},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inapproximability of shortest paths on perfect matching polytopes. <em>MP</em>, <em>210</em>(1), 147-163. (<a href='https://doi.org/10.1007/s10107-023-02025-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the computational problem of finding short paths in the skeleton of the perfect matching polytope of a bipartite graph. We prove that unless $${\textsf {P}}={\textsf {NP}}$$ , there is no polynomial-time algorithm that computes a path of constant length between two vertices at distance two of the perfect matching polytope of a bipartite graph. Conditioned on $${\textsf {P}}\ne {\textsf {NP}}$$ , this disproves a conjecture by Ito et al. (SIAM J Discrete Math 36(2):1102–1123, 2022). Assuming the Exponential Time Hypothesis we prove the stronger result that there exists no polynomial-time algorithm computing a path of length at most $$\left( \frac{1}{4}-o(1)\right) \log N / \log \log N$$ between two vertices at distance two of the perfect matching polytope of an N-vertex bipartite graph. These results remain true if the bipartite graph is restricted to be of maximum degree three. The above has the following interesting implication for the performance of pivot rules for the simplex algorithm on simply-structured combinatorial polytopes: If $${\textsf {P}}\ne {\textsf {NP}}$$ , then for every simplex pivot rule executable in polynomial time and every constant $$k \in {\mathbb {N}}$$ there exists a linear program on a perfect matching polytope and a starting vertex of the polytope such that the optimal solution can be reached in two monotone non-degenerate steps from the starting vertex, yet the pivot rule will require at least k non-degenerate steps to reach the optimal solution. This result remains true in the more general setting of pivot rules for so-called circuit-augmentation algorithms.},
  archive      = {J_MP},
  author       = {Cardinal, Jean and Steiner, Raphael},
  doi          = {10.1007/s10107-023-02025-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {147-163},
  shortjournal = {Math. Program.},
  title        = {Inapproximability of shortest paths on perfect matching polytopes},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recycling valid inequalities for robust combinatorial optimization with budgeted uncertainty. <em>MP</em>, <em>210</em>(1), 97-146. (<a href='https://doi.org/10.1007/s10107-024-02135-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust combinatorial optimization with budgeted uncertainty is one of the most popular approaches for integrating uncertainty into optimization problems. The existence of a compact reformulation for (mixed-integer) linear programs and positive complexity results give the impression that these problems are relatively easy to solve. However, the practical performance of the reformulation is quite poor when solving robust integer problems, in particular due to its weak linear relaxation. To overcome this issue, we propose procedures to derive new classes of valid inequalities for robust combinatorial optimization problems. For this, we recycle valid inequalities of the underlying deterministic problem such that the additional variables from the robust formulation are incorporated. The valid inequalities to be recycled may either be readily available model constraints or actual cutting planes, where we can benefit from decades of research on valid inequalities for classical optimization problems. We first demonstrate the strength of the inequalities theoretically, by proving that recycling yields a facet-defining inequality in many cases, even if the original valid inequality was not facet-defining. Afterwards, we show in an extensive computational study that using recycled inequalities can lead to a significant improvement of the computation time when solving robust optimization problems.},
  archive      = {J_MP},
  author       = {Büsing, Christina and Gersing, Timo and Koster, Arie M. C. A.},
  doi          = {10.1007/s10107-024-02135-7},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {97-146},
  shortjournal = {Math. Program.},
  title        = {Recycling valid inequalities for robust combinatorial optimization with budgeted uncertainty},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearly optimal randomized algorithm for explorable heap selection. <em>MP</em>, <em>210</em>(1), 75-96. (<a href='https://doi.org/10.1007/s10107-024-02145-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explorable heap selection is the problem of selecting the nth smallest value in a binary heap. The key values can only be accessed by traversing through the underlying infinite binary tree, and the complexity of the algorithm is measured by the total distance traveled in the tree (each edge has unit cost). This problem was originally proposed as a model to study search strategies for the branch-and-bound algorithm with storage restrictions by Karp, Saks and Widgerson (FOCS ’86), who gave deterministic and randomized $$n\cdot \exp (O(\sqrt{\log {n}}))$$ time algorithms using $$O(\log (n)^{2.5})$$ and $$O(\sqrt{\log n})$$ space respectively. We present a new randomized algorithm with running time $$O(n\log (n)^3)$$ against an oblivious adversary using $$O(\log n)$$ space, substantially improving the previous best randomized running time at the expense of slightly increased space usage. We also show an $$\Omega (\log (n)n/\log (\log (n)))$$ lower bound for any algorithm that solves the problem in the same amount of space, indicating that our algorithm is nearly optimal.},
  archive      = {J_MP},
  author       = {Borst, Sander and Dadush, Daniel and Huiberts, Sophie and Kashaev, Danish},
  doi          = {10.1007/s10107-024-02145-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {75-96},
  shortjournal = {Math. Program.},
  title        = {A nearly optimal randomized algorithm for explorable heap selection},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient separation of RLT cuts for implicit and explicit bilinear terms. <em>MP</em>, <em>210</em>(1), 47-74. (<a href='https://doi.org/10.1007/s10107-024-02104-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reformulation–linearization technique (RLT) is a prominent approach to constructing tight linear relaxations of non-convex continuous and mixed-integer optimization problems. The goal of this paper is to extend the applicability and improve the performance of RLT for bilinear product relations. First, we present a method for detecting bilinear product relations implicitly contained in mixed-integer linear programs, which is based on analyzing linear constraints with binary variables, thus enabling the application of bilinear RLT to a new class of problems. Strategies for filtering product relations are discussed and tested. Our second contribution addresses the high computational cost of RLT cut separation, which presents one of the major difficulties in applying RLT efficiently in practice. We propose a new RLT cutting plane separation algorithm which identifies combinations of linear constraints and bound factors that are expected to yield an inequality that is violated by the current relaxation solution. This algorithm is applicable to RLT cuts generated for all types of bilinear terms, including but not limited to the detected implicit products. A detailed computational study based on independent implementations in two solvers evaluates the performance impact of the proposed methods.},
  archive      = {J_MP},
  author       = {Bestuzheva, Ksenia and Gleixner, Ambros and Achterberg, Tobias},
  doi          = {10.1007/s10107-024-02104-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {47-74},
  shortjournal = {Math. Program.},
  title        = {Efficient separation of RLT cuts for implicit and explicit bilinear terms},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information complexity of mixed-integer convex optimization. <em>MP</em>, <em>210</em>(1), 3-45. (<a href='https://doi.org/10.1007/s10107-024-02099-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the information complexity of mixed-integer convex optimization under different types of oracles. We establish new lower bounds for the standard first-order oracle, improving upon the previous best known lower bound. This leaves only a lower order linear term (in the dimension) as the gap between the lower and upper bounds. This is derived as a corollary of a more fundamental “transfer” result that shows how lower bounds on information complexity of continuous convex optimization under different oracles can be transferred to the mixed-integer setting in a black-box manner. Further, we (to the best of our knowledge) initiate the study of, and obtain the first set of results on, information complexity under oracles that only reveal partial first-order information, e.g., where one can only make a binary query over the function value or subgradient at a given point. We give algorithms for (mixed-integer) convex optimization that work under these less informative oracles. We also give lower bounds showing that, for some of these oracles, every algorithm requires more iterations to achieve a target error compared to when complete first-order information is available. That is, these oracles are provably less informative than full first-order oracles for the purpose of optimization.},
  archive      = {J_MP},
  author       = {Basu, Amitabh and Jiang, Hongyi and Kerger, Phillip and Molinaro, Marco},
  doi          = {10.1007/s10107-024-02099-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {3-45},
  shortjournal = {Math. Program.},
  title        = {Information complexity of mixed-integer convex optimization},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Special issue: Integer programming and combinatorial optimization (IPCO) 2023. <em>MP</em>, <em>210</em>(1), 1-2. (<a href='https://doi.org/10.1007/s10107-025-02205-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Kaibel, Volker},
  doi          = {10.1007/s10107-025-02205-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Math. Program.},
  title        = {Special issue: Integer programming and combinatorial optimization (IPCO) 2023},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the directional asymptotic approach in optimization theory. <em>MP</em>, <em>209</em>(1), 859-937. (<a href='https://doi.org/10.1007/s10107-024-02089-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a starting point of our research, we show that, for a fixed order $$\gamma \ge 1$$ , each local minimizer of a rather general nonsmooth optimization problem in Euclidean spaces is either M-stationary in the classical sense (corresponding to stationarity of order 1), satisfies stationarity conditions in terms of a coderivative construction of order $$\gamma $$ , or is asymptotically stationary with respect to a critical direction as well as order $$\gamma $$ in a certain sense. By ruling out the latter case with a constraint qualification not stronger than directional metric subregularity, we end up with new necessary optimality conditions comprising a mixture of limiting variational tools of orders 1 and $$\gamma $$ . These abstract findings are carved out for the broad class of geometric constraints and $$\gamma :=2$$ , and visualized by examples from complementarity-constrained and nonlinear semidefinite optimization. As a byproduct of the particular setting $$\gamma :=1$$ , our general approach yields new so-called directional asymptotic regularity conditions which serve as constraint qualifications guaranteeing M-stationarity of local minimizers. We compare these new regularity conditions with standard constraint qualifications from nonsmooth optimization. Further, we extend directional concepts of pseudo- and quasi-normality to arbitrary set-valued mappings. It is shown that these properties provide sufficient conditions for the validity of directional asymptotic regularity. Finally, a novel coderivative-like variational tool is used to construct sufficient conditions for the presence of directional asymptotic regularity. For geometric constraints, it is illustrated that all appearing objects can be calculated in terms of initial problem data.},
  archive      = {J_MP},
  author       = {Benko, Matúš and Mehlitz, Patrick},
  doi          = {10.1007/s10107-024-02089-w},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {859-937},
  shortjournal = {Math. Program.},
  title        = {On the directional asymptotic approach in optimization theory},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An asynchronous proximal bundle method. <em>MP</em>, <em>209</em>(1), 825-857. (<a href='https://doi.org/10.1007/s10107-024-02088-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a fully asynchronous proximal bundle method for solving non-smooth, convex optimization problems. The algorithm can be used as a drop-in replacement for classic bundle methods, i.e., the function must be given by a first-order oracle for computing function values and subgradients. The algorithm allows for an arbitrary number of master problem processes computing new candidate points and oracle processes evaluating functions at those candidate points. These processes share information by communication with a single supervisor process that resembles the main loop of a classic bundle method. All processes run in parallel and no explicit synchronization step is required. Instead, the asynchronous and possibly outdated results of the oracle computations can be seen as an inexact function oracle. Hence, we show the convergence of our method under weak assumptions very similar to inexact and incremental bundle methods. In particular, we show how the algorithm learns important structural properties of the functions to control the inaccuracy induced by the asynchronicity automatically such that overall convergence can be guaranteed.},
  archive      = {J_MP},
  author       = {Fischer, Frank},
  doi          = {10.1007/s10107-024-02088-x},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {825-857},
  shortjournal = {Math. Program.},
  title        = {An asynchronous proximal bundle method},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stackelberg risk preference design. <em>MP</em>, <em>209</em>(1), 785-823. (<a href='https://doi.org/10.1007/s10107-024-02083-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk measures are commonly used to capture the risk preferences of decision-makers (DMs). The decisions of DMs can be nudged or manipulated when their risk preferences are influenced by factors such as the availability of information about the uncertainties. This work proposes a Stackelberg risk preference design (STRIPE) problem to capture a designer’s incentive to influence DMs’ risk preferences. STRIPE consists of two levels. In the lower level, individual DMs in a population, known as the followers, respond to uncertainties according to their risk preference types. In the upper level, the leader influences the distribution of the types to induce targeted decisions and steers the follower’s preferences to it. Our analysis centers around the solution concept of approximate Stackelberg equilibrium that yields suboptimal behaviors of the players. We show the existence of the approximate Stackelberg equilibrium. The primitive risk perception gap, defined as the Wasserstein distance between the original and the target type distributions, is important in estimating the optimal design cost. We connect the leader’s optimality compromise on the cost with her ambiguity tolerance on the follower’s approximate solutions leveraging Lipschitzian properties of the lower level solution mapping. To obtain the Stackelberg equilibrium, we reformulate STRIPE into a single-level optimization problem using the spectral representations of law-invariant coherent risk measures. We create a data-driven approach for computation and study its performance guarantees. We apply STRIPE to contract design problems under approximate incentive compatibility. Moreover, we connect STRIPE with meta-learning problems and derive adaptation performance estimates of the meta-parameters.},
  archive      = {J_MP},
  author       = {Liu, Shutian and Zhu, Quanyan},
  doi          = {10.1007/s10107-024-02083-2},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {785-823},
  shortjournal = {Math. Program.},
  title        = {Stackelberg risk preference design},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding global minima via kernel approximations. <em>MP</em>, <em>209</em>(1), 703-784. (<a href='https://doi.org/10.1007/s10107-024-02081-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the global minimization of smooth functions based solely on function evaluations. Algorithms that achieve the optimal number of function evaluations for a given precision level typically rely on explicitly constructing an approximation of the function which is then minimized with algorithms that have exponential running-time complexity. In this paper, we consider an approach that jointly models the function to approximate and finds a global minimum. This is done by using infinite sums of square smooth functions and has strong links with polynomial sum-of-squares hierarchies. Leveraging recent representation properties of reproducing kernel Hilbert spaces, the infinite-dimensional optimization problem can be solved by subsampling in time polynomial in the number of function evaluations, and with theoretical guarantees on the obtained minimum. Given n samples, the computational cost is $$O(n^{3.5})$$ in time, $$O(n^2)$$ in space, and we achieve a convergence rate to the global optimum that is $$O(n^{-m/d + 1/2 + 3/d})$$ where m is the degree of differentiability of the function and d the number of dimensions. The rate is nearly optimal in the case of Sobolev functions and more generally makes the proposed method particularly suitable for functions with many derivatives. Indeed, when m is in the order of d, the convergence rate to the global optimum does not suffer from the curse of dimensionality, which affects only the worst-case constants (that we track explicitly through the paper).},
  archive      = {J_MP},
  author       = {Rudi, Alessandro and Marteau-Ferey, Ulysse and Bach, Francis},
  doi          = {10.1007/s10107-024-02081-4},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {703-784},
  shortjournal = {Math. Program.},
  title        = {Finding global minima via kernel approximations},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A normal fan projection algorithm for low-rank optimization. <em>MP</em>, <em>209</em>(1), 681-702. (<a href='https://doi.org/10.1007/s10107-024-02079-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise a method for minimizing a low-rank quasiconcave objective function over a polytope by first projecting the polytope’s normal fan, then using the projected fan to obtain candidate solutions. When the polytope’s maximal number of nonparallel edges is bounded by a polynomial in its dimension, our method solves the problem in time that is polynomial in the number of variables and exponential in the rank of the objective function. We discuss several problems from previous literature that can be solved efficiently using this method. In all cases, our proposed algorithm matches or improves on the running time of existing problem-specific algorithms, while providing the first polynomial-time algorithm we know of for finding a spanning tree on a graph with multiple edge weight types, such that the product of the different weight types is minimized.},
  archive      = {J_MP},
  author       = {Scott, James R. and Geunes, Joseph},
  doi          = {10.1007/s10107-024-02079-y},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {681-702},
  shortjournal = {Math. Program.},
  title        = {A normal fan projection algorithm for low-rank optimization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample complexity analysis for adaptive optimization algorithms with stochastic oracles. <em>MP</em>, <em>209</em>(1), 651-679. (<a href='https://doi.org/10.1007/s10107-024-02078-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several classical adaptive optimization algorithms, such as line search and trust-region methods, have been recently extended to stochastic settings where function values, gradients, and Hessians in some cases, are estimated via stochastic oracles. Unlike the majority of stochastic methods, these methods do not use a pre-specified sequence of step size parameters, but adapt the step size parameter according to the estimated progress of the algorithm and use it to dictate the accuracy required from the stochastic oracles. The requirements on the stochastic oracles are, thus, also adaptive and the oracle costs can vary from iteration to iteration. The step size parameters in these methods can increase and decrease based on the perceived progress, but unlike the deterministic case they are not bounded away from zero due to possible oracle failures, and bounds on the step size parameter have not been previously derived. This creates obstacles in the total complexity analysis of such methods, because the oracle costs are typically decreasing in the step size parameter, and could be arbitrarily large as the step size parameter goes to 0. Thus, until now only the total iteration complexity of these methods has been analyzed. In this paper, we derive a lower bound on the step size parameter that holds with high probability for a large class of adaptive stochastic methods. We then use this lower bound to derive a framework for analyzing the expected and high probability total oracle complexity of any method in this class. Finally, we apply this framework to analyze the total sample complexity of two particular algorithms, STORM (Blanchet et al. in INFORMS J Optim 1(2):92–119, 2019) and SASS (Jin et al. in High probability complexity bounds for adaptive step search based on stochastic oracles, 2021. https://doi.org/10.48550/ARXIV.2106.06454 ), in the expected risk minimization problem.},
  archive      = {J_MP},
  author       = {Jin, Billy and Scheinberg, Katya and Xie, Miaolan},
  doi          = {10.1007/s10107-024-02078-z},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {651-679},
  shortjournal = {Math. Program.},
  title        = {Sample complexity analysis for adaptive optimization algorithms with stochastic oracles},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perseus: A simple and optimal high-order method for variational inequalities. <em>MP</em>, <em>209</em>(1), 609-650. (<a href='https://doi.org/10.1007/s10107-024-02075-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper settles an open and challenging question pertaining to the design of simple and optimal high-order methods for solving smooth and monotone variational inequalities (VIs). A VI involves finding $$x^\star \in {\mathcal {X}}$$ such that $$\langle F(x), x - x^\star \rangle \ge 0$$ for all $$x \in {\mathcal {X}}$$ . We consider the setting in which $$F: {\mathbb {R}}^d \rightarrow {\mathbb {R}}^d$$ is smooth with up to $$(p-1)^{\text {th}}$$ -order derivatives. For $$p = 2$$ , the cubic regularization of Newton’s method has been extended to VIs with a global rate of $$O(\epsilon ^{-1})$$ (Nesterov in Cubic regularization of Newton’s method for convex problems with constraints, Tech. rep., Université catholique de Louvain, Center for Operations Research and Econometrics (CORE), 2006). An improved rate of $$O(\epsilon ^{-2/3}\log \log (1/\epsilon ))$$ can be obtained via an alternative second-order method, but this method requires a nontrivial line-search procedure as an inner loop. Similarly, the existing high-order methods based on line-search procedures have been shown to achieve a rate of $$O(\epsilon ^{-2/(p+1)}\log \log (1/\epsilon ))$$ (Bullins and Lai in SIAM J Optim 32(3):2208–2229, 2022; Jiang and Mokhtari in Generalized optimistic methods for convex–concave saddle point problems, 2022; Lin and Jordan in Math Oper Res 48(4):2353–2382, 2023). As emphasized by Nesterov (Lectures on convex optimization, vol 137, Springer, Berlin, 2018), however, such procedures do not necessarily imply the practical applicability in large-scale applications, and it is desirable to complement these results with a simple high-order VI method that retains the optimality of the more complex methods. We propose a $$p^{\text {th}}$$ -order method that does not require any line search procedure and provably converges to a weak solution at a rate of $$O(\epsilon ^{-2/(p+1)})$$ . We prove that our $$p^{\text {th}}$$ -order method is optimal in the monotone setting by establishing a lower bound of $$\Omega (\epsilon ^{-2/(p+1)})$$ under a generalized linear span assumption. A restarted version of our $$p^{\text {th}}$$ -order method attains a linear rate for smooth and $$p^{\text {th}}$$ -order uniformly monotone VIs and another restarted version of our $$p^{\text {th}}$$ -order method attains a local superlinear rate for smooth and strongly monotone VIs. Further, the similar $$p^{\text {th}}$$ -order method achieves a global rate of $$O(\epsilon ^{-2/p})$$ for solving smooth and nonmonotone VIs satisfying the Minty condition. Two restarted versions attain a global linear rate under additional $$p^{\text {th}}$$ -order uniform Minty condition and a local superlinear rate under additional strong Minty condition.},
  archive      = {J_MP},
  author       = {Lin, Tianyi and Jordan, Michael I.},
  doi          = {10.1007/s10107-024-02075-2},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {609-650},
  shortjournal = {Math. Program.},
  title        = {Perseus: A simple and optimal high-order method for variational inequalities},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-convex scenario optimization. <em>MP</em>, <em>209</em>(1), 557-608. (<a href='https://doi.org/10.1007/s10107-024-02074-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scenario optimization is an approach to data-driven decision-making that has been introduced some fifteen years ago and has ever since then grown fast. Its most remarkable feature is that it blends the heuristic nature of data-driven methods with a rigorous theory that allows one to gain factual, reliable, insight in the solution. The usability of the scenario theory, however, has been restrained thus far by the obstacle that most results are standing on the assumption of convexity. With this paper, we aim to free the theory from this limitation. Specifically, we focus on the body of results that are known under the name of “wait-and-judge” and show that its fundamental achievements maintain their validity in a non-convex setup. While optimization is a major center of attention, this paper travels beyond it and into data-driven decision making. Adopting such a broad framework opens the door to building a new theory of truly vast applicability.},
  archive      = {J_MP},
  author       = {Garatti, Simone and Campi, Marco C.},
  doi          = {10.1007/s10107-024-02074-3},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {557-608},
  shortjournal = {Math. Program.},
  title        = {Non-convex scenario optimization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated first-order methods for a class of semidefinite programs. <em>MP</em>, <em>209</em>(1), 503-556. (<a href='https://doi.org/10.1007/s10107-024-02073-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new storage-optimal first-order method, CertSDP, for solving a special class of semidefinite programs (SDPs) to high accuracy. The class of SDPs that we consider, the exact QMP-like SDPs, is characterized by low-rank solutions, a priori knowledge of the restriction of the SDP solution to a small subspace, and standard regularity assumptions such as strict complementarity. Crucially, we show how to use a certificate of strict complementarity to construct a low-dimensional strongly convex minimax problem whose optimizer coincides with a factorization of the SDP optimizer. From an algorithmic standpoint, we show how to construct the necessary certificate and how to solve the minimax problem efficiently. Our algorithms for strongly convex minimax problems with inexact prox maps may be of independent interest. We accompany our theoretical results with preliminary numerical experiments suggesting that CertSDP significantly outperforms current state-of-the-art methods on large sparse exact QMP-like SDPs.},
  archive      = {J_MP},
  author       = {Wang, Alex L. and Kılınç-Karzan, Fatma},
  doi          = {10.1007/s10107-024-02073-4},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {503-556},
  shortjournal = {Math. Program.},
  title        = {Accelerated first-order methods for a class of semidefinite programs},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sum-of-squares relaxations for polynomial min–max problems over simple sets. <em>MP</em>, <em>209</em>(1), 475-501. (<a href='https://doi.org/10.1007/s10107-024-02072-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider min–max optimization problems for polynomial functions, where a multivariate polynomial is maximized with respect to a subset of variables, and the resulting maximal value is minimized with respect to the remaining variables. When the variables belong to simple sets (e.g., a hypercube, the Euclidean hypersphere, or a ball), we derive a sum-of-squares formulation based on a primal-dual approach. In the simplest setting, we provide a convergence proof when the degree of the relaxation tends to infinity and observe empirically that it can be finitely convergent in several situations. Moreover, our formulation leads to an interesting link with feasibility certificates for polynomial inequalities based on Putinar’s Positivstellensatz.},
  archive      = {J_MP},
  author       = {Bach, Francis},
  doi          = {10.1007/s10107-024-02072-5},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {475-501},
  shortjournal = {Math. Program.},
  title        = {Sum-of-squares relaxations for polynomial min–max problems over simple sets},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence rates for sums-of-squares hierarchies with correlative sparsity. <em>MP</em>, <em>209</em>(1), 435-473. (<a href='https://doi.org/10.1007/s10107-024-02071-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work derives upper bounds on the convergence rate of the moment-sum-of-squares hierarchy with correlative sparsity for global minimization of polynomials on compact basic semialgebraic sets. The main conclusion is that both sparse hierarchies based on the Schmüdgen and Putinar Positivstellensätze enjoy a polynomial rate of convergence that depends on the size of the largest clique in the sparsity graph but not on the ambient dimension. Interestingly, the sparse bounds outperform the best currently available bounds for the dense hierarchy when the maximum clique size is sufficiently small compared to the ambient dimension and the performance is measured by the running time of an interior point method required to obtain a bound on the global minimum of a given accuracy.},
  archive      = {J_MP},
  author       = {Korda, Milan and Magron, Victor and Ríos-Zertuche, Rodolfo},
  doi          = {10.1007/s10107-024-02071-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {435-473},
  shortjournal = {Math. Program.},
  title        = {Convergence rates for sums-of-squares hierarchies with correlative sparsity},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyhedral properties of RLT relaxations of nonconvex quadratic programs and their implications on exact relaxations. <em>MP</em>, <em>209</em>(1), 397-433. (<a href='https://doi.org/10.1007/s10107-024-02070-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear programming relaxations of nonconvex quadratic programs given by the reformulation–linearization technique (RLT), referred to as RLT relaxations. We investigate the relations between the polyhedral properties of the feasible regions of a quadratic program and its RLT relaxation. We establish various connections between recession directions, boundedness, and vertices of the two feasible regions. Using these properties, we present a complete description of the set of instances that admit an exact RLT relaxation. We then give a thorough discussion of how our results can be converted into simple algorithmic procedures to construct instances of quadratic programs with exact, inexact, or unbounded RLT relaxations.},
  archive      = {J_MP},
  author       = {Qiu, Yuzhou and Yıldırım, E. Alper},
  doi          = {10.1007/s10107-024-02070-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {397-433},
  shortjournal = {Math. Program.},
  title        = {Polyhedral properties of RLT relaxations of nonconvex quadratic programs and their implications on exact relaxations},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The Chvátal–Gomory procedure for integer SDPs with applications in combinatorial optimization. <em>MP</em>, <em>209</em>(1), 323-395. (<a href='https://doi.org/10.1007/s10107-024-02069-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the well-known Chvátal–Gomory (CG) procedure for the class of integer semidefinite programs (ISDPs). We prove several results regarding the hierarchy of relaxations obtained by iterating this procedure. We also study different formulations of the elementary closure of spectrahedra. A polyhedral description of the elementary closure for a specific type of spectrahedra is derived by exploiting total dual integrality for SDPs. Moreover, we show how to exploit (strengthened) CG cuts in a branch-and-cut framework for ISDPs. Different from existing algorithms in the literature, the separation routine in our approach exploits both the semidefinite and the integrality constraints. We provide separation routines for several common classes of binary SDPs resulting from combinatorial optimization problems. In the second part of the paper we present a comprehensive application of our approach to the quadratic traveling salesman problem (QTSP). Based on the algebraic connectivity of the directed Hamiltonian cycle, two ISDPs that model the QTSP are introduced. We show that the CG cuts resulting from these formulations contain several well-known families of cutting planes. Numerical results illustrate the practical strength of the CG cuts in our branch-and-cut algorithm, which outperforms alternative ISDP solvers and is able to solve large QTSP instances to optimality.},
  archive      = {J_MP},
  author       = {de Meijer, Frank and Sotirov, Renata},
  doi          = {10.1007/s10107-024-02069-0},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {323-395},
  shortjournal = {Math. Program.},
  title        = {The Chvátal–Gomory procedure for integer SDPs with applications in combinatorial optimization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized minimum 0-extension problem and discrete convexity. <em>MP</em>, <em>209</em>(1), 279-322. (<a href='https://doi.org/10.1007/s10107-024-02064-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a fixed finite metric space $$(V,\mu )$$ , the minimum 0-extension problem, denoted as $$\mathtt{0\hbox {-}Ext}[{\mu }]$$ , is equivalent to the following optimization problem: minimize function of the form $$\min \nolimits _{x\in V^n} \sum _i f_i(x_i) + \sum _{ij} c_{ij}\hspace{0.5pt}\mu (x_i,x_j)$$ where $$f_i:V\rightarrow \mathbb {R}$$ are functions given by $$f_i(x_i)=\sum _{v\in V} c_{vi}\hspace{0.5pt}\mu (x_i,v)$$ and $$c_{ij},c_{vi}$$ are given nonnegative costs. The computational complexity of $$\mathtt{0\hbox {-}Ext}[{\mu }]$$ has been recently established by Karzanov and by Hirai: if metric $$\mu $$ is orientable modular then $$\mathtt{0\hbox {-}Ext}[{\mu }]$$ can be solved in polynomial time, otherwise $$\mathtt{0\hbox {-}Ext}[{\mu }]$$ is NP-hard. To prove the tractability part, Hirai developed a theory of discrete convex functions on orientable modular graphs generalizing several known classes of functions in discrete convex analysis, such as $$L^\natural $$ -convex functions. We consider a more general version of the problem in which unary functions $$f_i(x_i)$$ can additionally have terms of the form $$c_{uv;i}\hspace{0.5pt}\mu (x_i,\{u,v\})$$ for $$\{u,\!\hspace{0.5pt}\hspace{0.5pt}v\}\in F$$ , where set $$F\subseteq \left( {\begin{array}{c}V\\ 2\end{array}}\right) $$ is fixed. We extend the complexity classification above by providing an explicit condition on $$(\mu ,F)$$ for the problem to be tractable. In order to prove the tractability part, we generalize Hirai’s theory and define a larger class of discrete convex functions. It covers, in particular, another well-known class of functions, namely submodular functions on an integer lattice. Finally, we improve the complexity of Hirai’s algorithm for solving $$\mathtt{0\hbox {-}Ext}[{\mu }]$$ on orientable modular graphs.},
  archive      = {J_MP},
  author       = {Dvorak, Martin and Kolmogorov, Vladimir},
  doi          = {10.1007/s10107-024-02064-5},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {279-322},
  shortjournal = {Math. Program.},
  title        = {Generalized minimum 0-extension problem and discrete convexity},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized nash equilibrium problems with mixed-integer variables. <em>MP</em>, <em>209</em>(1), 231-277. (<a href='https://doi.org/10.1007/s10107-024-02063-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider generalized Nash equilibrium problems (GNEPs) with non-convex strategy spaces and non-convex cost functions. This general class of games includes the important case of games with mixed-integer variables for which only a few results are known in the literature. We present a new approach to characterize equilibria via a convexification technique using the Nikaido–Isoda function. To any given instance of the GNEP, we construct a set of convexified instances and show that a feasible strategy profile is an equilibrium for the original instance if and only if it is an equilibrium for any convexified instance and the convexified cost functions coincide with the initial ones. We develop this convexification approach along three dimensions: We first show that for quasi-linear models, where a convexified instance exists in which for fixed strategies of the opponent players, the cost function of every player is linear and the respective strategy space is polyhedral, the convexification reduces the GNEP to a standard (non-linear) optimization problem. Secondly, we derive two complete characterizations of those GNEPs for which the convexification leads to a jointly constrained or a jointly convex GNEP, respectively. These characterizations require new concepts related to the interplay of the convex hull operator applied to restricted subsets of feasible strategies and may be interesting on their own. Note that this characterization is also computationally relevant as jointly convex GNEPs have been extensively studied in the literature. Finally, we demonstrate the applicability of our results by presenting a numerical study regarding the computation of equilibria for three classes of GNEPs related to integral network flows and discrete market equilibria.},
  archive      = {J_MP},
  author       = {Harks, Tobias and Schwarz, Julian},
  doi          = {10.1007/s10107-024-02063-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {231-277},
  shortjournal = {Math. Program.},
  title        = {Generalized nash equilibrium problems with mixed-integer variables},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hessian barrier algorithms for non-convex conic optimization. <em>MP</em>, <em>209</em>(1), 171-229. (<a href='https://doi.org/10.1007/s10107-024-02062-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key problem in mathematical imaging, signal processing and computational statistics is the minimization of non-convex objective functions that may be non-differentiable at the relative boundary of the feasible set. This paper proposes a new family of first- and second-order interior-point methods for non-convex optimization problems with linear and conic constraints, combining logarithmically homogeneous barriers with quadratic and cubic regularization respectively. Our approach is based on a potential-reduction mechanism and, under the Lipschitz continuity of the corresponding derivative with respect to the local barrier-induced norm, attains a suitably defined class of approximate first- or second-order KKT points with worst-case iteration complexity $$O(\varepsilon ^{-2})$$ (first-order) and $$O(\varepsilon ^{-3/2})$$ (second-order), respectively. Based on these findings, we develop new path-following schemes attaining the same complexity, modulo adjusting constants. These complexity bounds are known to be optimal in the unconstrained case, and our work shows that they are upper bounds in the case with complicated constraints as well. To the best of our knowledge, this work is the first which achieves these worst-case complexity bounds under such weak conditions for general conic constrained non-convex optimization problems.},
  archive      = {J_MP},
  author       = {Dvurechensky, Pavel and Staudigl, Mathias},
  doi          = {10.1007/s10107-024-02062-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {171-229},
  shortjournal = {Math. Program.},
  title        = {Hessian barrier algorithms for non-convex conic optimization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated tight lyapunov analysis for first-order methods. <em>MP</em>, <em>209</em>(1), 133-170. (<a href='https://doi.org/10.1007/s10107-024-02061-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a methodology for establishing the existence of quadratic Lyapunov inequalities for a wide range of first-order methods used to solve convex optimization problems. In particular, we consider (i) classes of optimization problems of finite-sum form with (possibly strongly) convex and possibly smooth functional components, (ii) first-order methods that can be written as a linear system on state-space form in feedback interconnection with the subdifferentials of the functional components of the objective function, and (iii) quadratic Lyapunov inequalities that can be used to draw convergence conclusions. We present a necessary and sufficient condition for the existence of a quadratic Lyapunov inequality within a predefined class of Lyapunov inequalities, which amounts to solving a small-sized semidefinite program. We showcase our methodology on several first-order methods that fit the framework. Most notably, our methodology allows us to significantly extend the region of parameter choices that allow for duality gap convergence in the Chambolle–Pock method when the linear operator is the identity mapping.},
  archive      = {J_MP},
  author       = {Upadhyaya, Manu and Banert, Sebastian and Taylor, Adrien B. and Giselsson, Pontus},
  doi          = {10.1007/s10107-024-02061-8},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {133-170},
  shortjournal = {Math. Program.},
  title        = {Automated tight lyapunov analysis for first-order methods},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex hulls of monomial curves, and a sparse positivstellensatz. <em>MP</em>, <em>209</em>(1), 113-131. (<a href='https://doi.org/10.1007/s10107-024-02060-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the closed convex hull K of a monomial curve given parametrically as $$(t^{m_1},\ldots ,t^{m_n})$$ , with the parameter t varying in an interval I. We show, using constructive arguments, that K admits a lifted semidefinite description by $$\mathcal {O}(d)$$ linear matrix inequalities (LMIs), each of size $$\left\lfloor \frac{n}{2} \right\rfloor +1$$ , where $$d= \max \{m_1,\ldots ,m_n\}$$ is the degree of the curve. On the dual side, we show that if a univariate polynomial p(t) of degree d with at most $$2k+1$$ monomials is non-negative on $${\mathbb {R}}_+$$ , then p admits a representation $$p = t^0 \sigma _0 + \cdots + t^{d-k} \sigma _{d-k}$$ , where the polynomials $$\sigma _0,\ldots ,\sigma _{d-k}$$ are sums of squares and $$\deg (\sigma _i) \le 2k$$ . The latter is a univariate positivstellensatz for sparse polynomials, with non-negativity of p being certified by sos polynomials whose degree only depends on the sparsity of p. Our results fit into the general attempt of formulating polynomial optimization problems as semidefinite problems with LMIs of small size. Such small-size descriptions are much more tractable from a computational viewpoint.},
  archive      = {J_MP},
  author       = {Averkov, Gennadiy and Scheiderer, Claus},
  doi          = {10.1007/s10107-024-02060-9},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {113-131},
  shortjournal = {Math. Program.},
  title        = {Convex hulls of monomial curves, and a sparse positivstellensatz},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of smooth parametrizations on nonconvex optimization landscapes. <em>MP</em>, <em>209</em>(1), 63-111. (<a href='https://doi.org/10.1007/s10107-024-02058-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new tools to study landscapes in nonconvex optimization. Given one optimization problem, we pair it with another by smoothly parametrizing the domain. This is either for practical purposes (e.g., to use smooth optimization algorithms with good guarantees) or for theoretical purposes (e.g., to reveal that the landscape satisfies a strict saddle property). In both cases, the central question is: how do the landscapes of the two problems relate? More precisely: how do desirable points such as local minima and critical points in one problem relate to those in the other problem? A key finding in this paper is that these relations are often determined by the parametrization itself, and are almost entirely independent of the cost function. Accordingly, we introduce a general framework to study parametrizations by their effect on landscapes. The framework enables us to obtain new guarantees for an array of problems, some of which were previously treated on a case-by-case basis in the literature. Applications include: optimizing low-rank matrices and tensors through factorizations; solving semidefinite programs via the Burer–Monteiro approach; training neural networks by optimizing their weights and biases; and quotienting out symmetries.},
  archive      = {J_MP},
  author       = {Levin, Eitan and Kileel, Joe and Boumal, Nicolas},
  doi          = {10.1007/s10107-024-02058-3},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {63-111},
  shortjournal = {Math. Program.},
  title        = {The effect of smooth parametrizations on nonconvex optimization landscapes},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Level constrained first order methods for function constrained optimization. <em>MP</em>, <em>209</em>(1), 1-61. (<a href='https://doi.org/10.1007/s10107-024-02057-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new feasible proximal gradient method for constrained optimization where both the objective and constraint functions are given by summation of a smooth, possibly nonconvex function and a convex simple function. The algorithm converts the original problem into a sequence of convex subproblems. Formulating those subproblems requires the evaluation of at most one gradient-value of the original objective and constraint functions. Either exact or approximate subproblems solutions can be computed efficiently in many cases. An important feature of the algorithm is the constraint level parameter. By carefully increasing this level for each subproblem, we provide a simple solution to overcome the challenge of bounding the Lagrangian multipliers and show that the algorithm follows a strictly feasible solution path till convergence to the stationary point. We develop a simple, proximal gradient descent type analysis, showing that the complexity bound of this new algorithm is comparable to gradient descent for the unconstrained setting which is new in the literature. Exploiting this new design and analysis technique, we extend our algorithms to some more challenging constrained optimization problems where (1) the objective is a stochastic or finite-sum function, and (2) structured nonsmooth functions replace smooth components of both objective and constraint functions. Complexity results for these problems also seem to be new in the literature. Finally, our method can also be applied to convex function constrained problems where we show complexities similar to the proximal gradient method.},
  archive      = {J_MP},
  author       = {Boob, Digvijay and Deng, Qi and Lan, Guanghui},
  doi          = {10.1007/s10107-024-02057-4},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Math. Program.},
  title        = {Level constrained first order methods for function constrained optimization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
